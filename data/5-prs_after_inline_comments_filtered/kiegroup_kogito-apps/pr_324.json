{"pr_number": 324, "pr_title": "KOGITO-2750 - add explainability-core and explainability-integrationtests to kogito-apps", "pr_createdAt": "2020-07-15T09:48:51Z", "pr_url": "https://github.com/kiegroup/kogito-apps/pull/324", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1NjY3Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462456676", "bodyText": "If the two strings have different length then the impact is just 1? Is this correct?", "author": "r00ta", "createdAt": "2020-07-29T17:12:38Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility class providing different methods to evaluate explainability.\n+ */\n+public class ExplainabilityMetrics {\n+\n+    /**\n+     * Measure the explainability of an explanation as per paper \"Towards Quantification of Explainability in Explainable\n+     * Artificial Intelligence Methods\" by Islam et al.\n+     *\n+     * @param inputCognitiveChunks  the no. of cognitive chunks (pieces of information) required to generate the\n+     *                              explanation (e.g. the no. of explanation inputs)\n+     * @param outputCognitiveChunks the no. of cognitive chunks generated within the explanation itself\n+     * @param interactionRatio      the ratio of interaction (between 0 and 1) required by the explanation\n+     * @return the quantitative explainability measure\n+     */\n+    public static double quantifyExplainability(int inputCognitiveChunks, int outputCognitiveChunks, double interactionRatio) {\n+        return inputCognitiveChunks + outputCognitiveChunks > 0 ? 0.333 / (double) inputCognitiveChunks\n+                + 0.333 / (double) outputCognitiveChunks + 0.333 * (1d - interactionRatio) : 0;\n+    }\n+\n+    /**\n+     * Calculate the impact of dropping the most important features (given by {@link Saliency#getTopFeatures(int)} from the input.\n+     * Highly important features would have rather high impact.\n+     *\n+     * @param model       the model to be explained\n+     * @param prediction  a prediction\n+     * @param topFeatures the list of important features that should be dropped\n+     * @return the saliency impact\n+     */\n+    public static double saliencyImpact(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+        List<String> importantFeatureNames = topFeatures.stream().map(f -> f.getFeature().getName()).collect(Collectors.toList());\n+\n+        List<Feature> newFeatures = new LinkedList<>();\n+        for (Feature feature : prediction.getInput().getFeatures()) {\n+            Feature newFeature = DataUtils.dropFeature(feature, importantFeatureNames);\n+            newFeatures.add(newFeature);\n+        }\n+        PredictionInput predictionInput = new PredictionInput(newFeatures);\n+        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n+        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        double impact = 0d;\n+        double size = predictionOutput.getOutputs().size();\n+        for (int i = 0; i < size; i++) {\n+            Output original = prediction.getOutput().getOutputs().get(i);\n+            Output modified = predictionOutput.getOutputs().get(i);\n+            impact += 0.5 * DataUtils.euclideanDistance(new double[]{original.getScore()}, new double[]{modified.getScore()});\n+            String x = original.getValue().asString();\n+            String y = modified.getValue().asString();\n+            if (x.length() == y.length()) {\n+                impact += DataUtils.hammingDistance(x, y);\n+            } else {\n+                impact += 1d;\n+            }", "originalCommit": "22658493f480efbdc99adb5b5cc055a1fe3f160f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjg4ODQwNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462888406", "bodyText": "I am struggling at finding the original paper where I had found this impact definition, I'll keep digging...\nAnyway the idea is similar to the one described in this paper where the impact is 1 when either the output without the important features is different from the original one or when its score has changed by at least 0.5 (in a 0..1 range), except that instead of having a discrete impact we calculate the distance between the changed/original output values and between changed/original scores, giving more weight to a changed output than to a changed score (hence the 0.5 on score).\nIn case the (hamming) distance cannot be computed (e.g. when their lengths differ) it's just set to 1 if the output value changed.", "author": "tteofili", "createdAt": "2020-07-30T10:00:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1NjY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njc2Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462456763", "bodyText": "Why 0.5?", "author": "r00ta", "createdAt": "2020-07-29T17:12:46Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility class providing different methods to evaluate explainability.\n+ */\n+public class ExplainabilityMetrics {\n+\n+    /**\n+     * Measure the explainability of an explanation as per paper \"Towards Quantification of Explainability in Explainable\n+     * Artificial Intelligence Methods\" by Islam et al.\n+     *\n+     * @param inputCognitiveChunks  the no. of cognitive chunks (pieces of information) required to generate the\n+     *                              explanation (e.g. the no. of explanation inputs)\n+     * @param outputCognitiveChunks the no. of cognitive chunks generated within the explanation itself\n+     * @param interactionRatio      the ratio of interaction (between 0 and 1) required by the explanation\n+     * @return the quantitative explainability measure\n+     */\n+    public static double quantifyExplainability(int inputCognitiveChunks, int outputCognitiveChunks, double interactionRatio) {\n+        return inputCognitiveChunks + outputCognitiveChunks > 0 ? 0.333 / (double) inputCognitiveChunks\n+                + 0.333 / (double) outputCognitiveChunks + 0.333 * (1d - interactionRatio) : 0;\n+    }\n+\n+    /**\n+     * Calculate the impact of dropping the most important features (given by {@link Saliency#getTopFeatures(int)} from the input.\n+     * Highly important features would have rather high impact.\n+     *\n+     * @param model       the model to be explained\n+     * @param prediction  a prediction\n+     * @param topFeatures the list of important features that should be dropped\n+     * @return the saliency impact\n+     */\n+    public static double saliencyImpact(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+        List<String> importantFeatureNames = topFeatures.stream().map(f -> f.getFeature().getName()).collect(Collectors.toList());\n+\n+        List<Feature> newFeatures = new LinkedList<>();\n+        for (Feature feature : prediction.getInput().getFeatures()) {\n+            Feature newFeature = DataUtils.dropFeature(feature, importantFeatureNames);\n+            newFeatures.add(newFeature);\n+        }\n+        PredictionInput predictionInput = new PredictionInput(newFeatures);\n+        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n+        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        double impact = 0d;\n+        double size = predictionOutput.getOutputs().size();\n+        for (int i = 0; i < size; i++) {\n+            Output original = prediction.getOutput().getOutputs().get(i);\n+            Output modified = predictionOutput.getOutputs().get(i);\n+            impact += 0.5 * DataUtils.euclideanDistance(new double[]{original.getScore()}, new double[]{modified.getScore()});", "originalCommit": "22658493f480efbdc99adb5b5cc055a1fe3f160f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjg4ODg4MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462888881", "bodyText": "see above comment", "author": "tteofili", "createdAt": "2020-07-30T10:01:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1Njc2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1ODI3NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462458275", "bodyText": "Isnt't better to directly instantiate a Feature object without a mock?", "author": "r00ta", "createdAt": "2020-07-29T17:15:08Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability;\n+\n+import java.security.SecureRandom;\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    static {\n+        random.setSeed(4);\n+    }\n+\n+    public static PredictionProvider getFeaturePassModel(int featureIndex) {\n+        return inputs -> {\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+            for (PredictionInput predictionInput : inputs) {\n+                List<Feature> features = predictionInput.getFeatures();\n+                Feature feature = features.get(featureIndex);\n+                PredictionOutput predictionOutput = new PredictionOutput(\n+                        List.of(new Output(\"feature-\" + featureIndex, feature.getType(), feature.getValue(),\n+                                           1d)));\n+                predictionOutputs.add(predictionOutput);\n+            }\n+            return predictionOutputs;\n+        };\n+    }\n+\n+    public static PredictionProvider getSumSkipModel(int skipFeatureIndex) {\n+        return inputs -> {\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+            for (PredictionInput predictionInput : inputs) {\n+                List<Feature> features = predictionInput.getFeatures();\n+                double result = 0;\n+                for (int i = 0; i < features.size(); i++) {\n+                    if (skipFeatureIndex != i) {\n+                        result += features.get(i).getValue().asNumber();\n+                    }\n+                }\n+                PredictionOutput predictionOutput = new PredictionOutput(\n+                        List.of(new Output(\"sum-but\" + skipFeatureIndex, Type.NUMBER, new Value<>(result), 1d)));\n+                predictionOutputs.add(predictionOutput);\n+            }\n+            return predictionOutputs;\n+        };\n+    }\n+\n+    public static PredictionProvider getEvenFeatureModel(int featureIndex) {\n+        return inputs -> {\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+            for (PredictionInput predictionInput : inputs) {\n+                List<Feature> features = predictionInput.getFeatures();\n+                Feature feature = features.get(featureIndex);\n+                double v = feature.getValue().asNumber();\n+                PredictionOutput predictionOutput = new PredictionOutput(\n+                        List.of(new Output(\"feature-\" + featureIndex, Type.BOOLEAN, new Value<>(v % 2 == 0), 1d)));\n+                predictionOutputs.add(predictionOutput);\n+            }\n+            return predictionOutputs;\n+        };\n+    }\n+\n+    public static PredictionProvider getEvenSumModel(int skipFeatureIndex) {\n+        return inputs -> {\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+            for (PredictionInput predictionInput : inputs) {\n+                List<Feature> features = predictionInput.getFeatures();\n+                double result = 0;\n+                for (int i = 0; i < features.size(); i++) {\n+                    if (skipFeatureIndex != i) {\n+                        result += features.get(i).getValue().asNumber();\n+                    }\n+                }\n+                PredictionOutput predictionOutput = new PredictionOutput(\n+                        List.of(new Output(\"sum-even-but\" + skipFeatureIndex, Type.BOOLEAN, new Value<>(((int) result) % 2 == 0), 1d)));\n+                predictionOutputs.add(predictionOutput);\n+            }\n+            return predictionOutputs;\n+        };\n+    }\n+\n+    public static PredictionProvider getDummyTextClassifier() {\n+        return new PredictionProvider() {\n+            private final List<String> blackList = Arrays.asList(\"money\", \"$\", \"\u00a3\", \"bitcoin\");\n+\n+            @Override\n+            public List<PredictionOutput> predict(List<PredictionInput> inputs) {\n+                List<PredictionOutput> outputs = new LinkedList<>();\n+                for (PredictionInput input : inputs) {\n+                    boolean spam = false;\n+                    for (Feature f : input.getFeatures()) {\n+                        if (!spam && Type.TEXT.equals(f.getType())) {\n+                            String s = f.getValue().asString();\n+                            String[] words = s.split(\" \");\n+                            for (String w : words) {\n+                                if (blackList.contains(w)) {\n+                                    spam = true;\n+                                    break;\n+                                }\n+                            }\n+                        }\n+                    }\n+                    Output output = new Output(\"spam\", Type.BOOLEAN, new Value<>(spam), 1d);\n+                    outputs.add(new PredictionOutput(List.of(output)));\n+                }\n+                return outputs;\n+            }\n+        };\n+    }\n+\n+    public static Feature getMockedNumericFeature() {\n+        return getMockedNumericFeature(1d);\n+    }\n+\n+    public static Feature getMockedFeature(Type type, Value<?> v) {\n+        Feature f = mock(Feature.class);\n+        when(f.getType()).thenReturn(type);\n+        when(f.getName()).thenReturn(\"f-\" + type.name());\n+        when(f.getValue()).thenReturn(v);\n+        return f;", "originalCommit": "22658493f480efbdc99adb5b5cc055a1fe3f160f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjg3MDQ4Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462870487", "bodyText": "Feature constructor is package local to prevent users to instantiate them themselves while possibly messing up Types  and Values (e.g. Type.BOOLEAN and new Value<Double>(1d)).\nFeature creation is exposed via FeatureFactory however I prefer to not depend on the FeatureFactory impl in the tests, as that might hide some bugs iteself.", "author": "tteofili", "createdAt": "2020-07-30T09:28:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1ODI3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ2NzE0Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462467142", "bodyText": "This is checking that the last entry.getValue() is >= 0.9 right? Isnt't better to rewrite it?", "author": "r00ta", "createdAt": "2020-07-29T17:29:52Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class LimeStabilityTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.setSeed(4);\n+    }\n+\n+    @Test\n+    void testStabilityWithNumericData() {\n+        PredictionProvider sumSkipModel = TestUtils.getSumSkipModel(0);\n+        List<Feature> featureList = new LinkedList<>();\n+        for (int i = 0; i < 5; i++) {\n+            featureList.add(TestUtils.getMockedNumericFeature(i));\n+        }\n+        assertStable(sumSkipModel, featureList);\n+    }\n+\n+    private void assertStable(PredictionProvider sumSkipModel, List<Feature> featureList) {\n+        PredictionInput input = new PredictionInput(featureList);\n+        List<PredictionOutput> predictionOutputs = sumSkipModel.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, predictionOutputs.get(0));\n+        List<Saliency> saliencies = new LinkedList<>();\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        for (int i = 0; i < 100; i++) {\n+            Saliency saliency = limeExplainer.explain(prediction, sumSkipModel);\n+            saliencies.add(saliency);\n+        }\n+        List<String> names = new LinkedList<>();\n+        saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n+        Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        boolean topFeature = false;\n+        for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n+            topFeature = entry.getValue() >= 0.9;\n+        }\n+        assertTrue(topFeature);", "originalCommit": "22658493f480efbdc99adb5b5cc055a1fe3f160f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjg3MjYwNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462872605", "bodyText": "the proper check is that at least one entry matches the condition, hence yes, I'll fix it.", "author": "tteofili", "createdAt": "2020-07-30T09:32:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ2NzE0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ3MjI5NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462472294", "bodyText": "This is always true unless ExplainabilityMetrics.classificationFidelity throws an exception. If this is the intended check, could you use assertDoesNotThrow?", "author": "r00ta", "createdAt": "2020-07-29T17:38:35Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/ExplainabilityMetricsTest.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+class ExplainabilityMetricsTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.setSeed(4);\n+    }\n+\n+    @Test\n+    void testExplainabilityNoExplanation() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(0, 0, 0);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertEquals(0, v);\n+    }\n+\n+    @Test\n+    void testExplainabilityNoExplanationWithInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(0, 0, 1);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertEquals(0, v);\n+    }\n+\n+    @Test\n+    void testExplainabilitySameIOChunksNoInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(10, 10, 0);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertThat(v).isBetween(0d, 1d);\n+    }\n+\n+    @Test\n+    void testExplainabilitySameIOChunksWithInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(10, 10, 0.5);\n+        assertEquals(0.2331, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testExplainabilityDifferentIOChunksNoInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(3, 9, 0);\n+        assertEquals(0.481, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testExplainabilityDifferentIOChunksInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(3, 9, 0.5);\n+        assertEquals(0.3145, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testFidelityWithTextClassifier() {\n+        List<Pair<Saliency, Prediction>> pairs = new LinkedList<>();\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        PredictionProvider model = TestUtils.getDummyTextClassifier();\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newTextFeature(\"f-0\", \"brown fox\"));\n+        features.add(FeatureFactory.newTextFeature(\"f-1\", \"money\"));\n+        PredictionInput input = new PredictionInput(features);\n+        Prediction prediction = new Prediction(input, model.predict(List.of(input)).get(0));\n+        pairs.add(Pair.of(limeExplainer.explain(prediction, model), prediction));\n+        double v = ExplainabilityMetrics.classificationFidelity(pairs);\n+        assertThat(v).isBetween(0d, 1d);", "originalCommit": "22658493f480efbdc99adb5b5cc055a1fe3f160f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjg3NDIyNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462874227", "bodyText": "the above assertion is meant to check that the value returned by ExplainabilityMetrics.classificationFidelity is in the expected range of values, which I think is correct. If it throws an Exception that would be an unexpected behaviour and the test should go in error instead of failing.", "author": "tteofili", "createdAt": "2020-07-30T09:35:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ3MjI5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjkyNTk3Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462925977", "bodyText": "Hi @tteofili , I'm more referring to the fact that ExplainabilityMetrics.classificationFidelity returns always a number between 0 and 1 by contract, regardless the inputs (could you double check?). Meaning that we can change the implementation of ExplainabilityMetrics.classificationFidelity and this test completely and this test would anyway pass. That's why I was wondering if the real check is assertDoesNotThrow, since this is the only way for this test to fail.", "author": "r00ta", "createdAt": "2020-07-30T11:17:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ3MjI5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk4MzIwNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462983206", "bodyText": "ok, done ;)", "author": "tteofili", "createdAt": "2020-07-30T13:09:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ3MjI5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ3MjM0MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462472341", "bodyText": "This is always true unless ExplainabilityMetrics.classificationFidelity throws an exception. If this is the intended check, could you use assertDoesNotThrow?", "author": "r00ta", "createdAt": "2020-07-29T17:38:40Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/ExplainabilityMetricsTest.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+class ExplainabilityMetricsTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.setSeed(4);\n+    }\n+\n+    @Test\n+    void testExplainabilityNoExplanation() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(0, 0, 0);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertEquals(0, v);\n+    }\n+\n+    @Test\n+    void testExplainabilityNoExplanationWithInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(0, 0, 1);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertEquals(0, v);\n+    }\n+\n+    @Test\n+    void testExplainabilitySameIOChunksNoInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(10, 10, 0);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertThat(v).isBetween(0d, 1d);\n+    }\n+\n+    @Test\n+    void testExplainabilitySameIOChunksWithInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(10, 10, 0.5);\n+        assertEquals(0.2331, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testExplainabilityDifferentIOChunksNoInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(3, 9, 0);\n+        assertEquals(0.481, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testExplainabilityDifferentIOChunksInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(3, 9, 0.5);\n+        assertEquals(0.3145, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testFidelityWithTextClassifier() {\n+        List<Pair<Saliency, Prediction>> pairs = new LinkedList<>();\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        PredictionProvider model = TestUtils.getDummyTextClassifier();\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newTextFeature(\"f-0\", \"brown fox\"));\n+        features.add(FeatureFactory.newTextFeature(\"f-1\", \"money\"));\n+        PredictionInput input = new PredictionInput(features);\n+        Prediction prediction = new Prediction(input, model.predict(List.of(input)).get(0));\n+        pairs.add(Pair.of(limeExplainer.explain(prediction, model), prediction));\n+        double v = ExplainabilityMetrics.classificationFidelity(pairs);\n+        assertThat(v).isBetween(0d, 1d);\n+    }\n+\n+    @Test\n+    void testFidelityWithEvenSumModel() {\n+        List<Pair<Saliency, Prediction>> pairs = new LinkedList<>();\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        PredictionProvider model = TestUtils.getEvenSumModel(1);\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f-1\", 1));\n+        features.add(FeatureFactory.newNumericalFeature(\"f-2\", 2));\n+        features.add(FeatureFactory.newNumericalFeature(\"f-3\", 3));\n+        PredictionInput input = new PredictionInput(features);\n+        Prediction prediction = new Prediction(input, model.predict(List.of(input)).get(0));\n+        pairs.add(Pair.of(limeExplainer.explain(prediction, model), prediction));\n+        double v = ExplainabilityMetrics.classificationFidelity(pairs);\n+        assertThat(v).isBetween(0d, 1d);", "originalCommit": "22658493f480efbdc99adb5b5cc055a1fe3f160f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjg3NDcxMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462874712", "bodyText": "same as above.", "author": "tteofili", "createdAt": "2020-07-30T09:35:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ3MjM0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ5Nzg0NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462497845", "bodyText": "assertArrayEquals(new double[size], linearModel.getWeights()); or check that all the elements are zero?", "author": "r00ta", "createdAt": "2020-07-29T18:21:18Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/LinearModelTest.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+class LinearModelTest {\n+\n+    @Test\n+    void testEmptyFitClassificationDoesNothing() {\n+        int size = 10;\n+        LinearModel linearModel = new LinearModel(size, true);\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        linearModel.fit(trainingSet);\n+        assertEquals(Arrays.toString(new double[size]), Arrays.toString(linearModel.getWeights()));", "originalCommit": "22658493f480efbdc99adb5b5cc055a1fe3f160f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjg3NTYwOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462875609", "bodyText": "the former, correct, thanks.", "author": "tteofili", "createdAt": "2020-07-30T09:37:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ5Nzg0NQ=="}], "type": "inlineReview"}, {"oid": "d4747fa0d127fcb8d42de2b291ee6b64e8850cfb", "url": "https://github.com/kiegroup/kogito-apps/commit/d4747fa0d127fcb8d42de2b291ee6b64e8850cfb", "message": "Merge branch 'master' of github.com:kiegroup/kogito-apps into KOGITO-2750", "committedDate": "2020-07-30T08:18:06Z", "type": "commit"}, {"oid": "05a0c983f07534f628268f71af2887ec4bbe9b3f", "url": "https://github.com/kiegroup/kogito-apps/commit/05a0c983f07534f628268f71af2887ec4bbe9b3f", "message": "KOGITO-2750 - adjusted assertion in LSTest", "committedDate": "2020-07-30T09:35:22Z", "type": "commit"}, {"oid": "5d6ed0c155472be3380e8a54843b7d4b6f2204f9", "url": "https://github.com/kiegroup/kogito-apps/commit/5d6ed0c155472be3380e8a54843b7d4b6f2204f9", "message": "KOGITO-2750 - adjusted assertion in LMTest", "committedDate": "2020-07-30T09:37:13Z", "type": "commit"}, {"oid": "55ebd5a47b3442f3aa118b99d2c876ae6052db6a", "url": "https://github.com/kiegroup/kogito-apps/commit/55ebd5a47b3442f3aa118b99d2c876ae6052db6a", "message": "KOGITO-2750 - checking classification fidelity doesn't throw an Exception", "committedDate": "2020-07-30T13:02:18Z", "type": "commit"}, {"oid": "0e90dd8d1688ed879d0795179e13a305d2d30dd8", "url": "https://github.com/kiegroup/kogito-apps/commit/0e90dd8d1688ed879d0795179e13a305d2d30dd8", "message": "KOGITO-2750 - add explainability core library and ITs to kogito-apps", "committedDate": "2020-07-14T15:22:20Z", "type": "commit"}, {"oid": "49e59994f0e585ef5f06d8fad6f8f1c38d40b1de", "url": "https://github.com/kiegroup/kogito-apps/commit/49e59994f0e585ef5f06d8fad6f8f1c38d40b1de", "message": "KOGITO-2750 - added missing AL headers", "committedDate": "2020-07-15T09:43:29Z", "type": "commit"}, {"oid": "cec3a5d5da960b00a14624535e1886102c27fbe6", "url": "https://github.com/kiegroup/kogito-apps/commit/cec3a5d5da960b00a14624535e1886102c27fbe6", "message": "KOGITO-2750 - fixed typo in README", "committedDate": "2020-07-15T09:59:24Z", "type": "commit"}, {"oid": "92e39d5446821fc262025f9e7c11794be87945ee", "url": "https://github.com/kiegroup/kogito-apps/commit/92e39d5446821fc262025f9e7c11794be87945ee", "message": "KOGITO-2750 - adjusted param in test", "committedDate": "2020-07-15T09:59:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0Mzk4MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r454943980", "bodyText": "private static final", "author": "r00ta", "createdAt": "2020-07-15T10:13:53Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LinearModel.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.stream.IntStream;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A linear model implementation based on perceptron algorithm.\n+ */\n+public class LinearModel {\n+\n+    private final Logger logger = LoggerFactory.getLogger(getClass());", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc2MTIxMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455761210", "bodyText": "+1", "author": "tteofili", "createdAt": "2020-07-16T12:51:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0Mzk4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0NjQ2MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r454946460", "bodyText": "Do we need this?", "author": "r00ta", "createdAt": "2020-07-15T10:18:40Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/HttpHelper.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+import java.io.IOException;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.client.config.RequestConfig;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpGet;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.entity.ContentType;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClientBuilder;\n+import org.apache.http.util.EntityUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Helper class to connect to a remote endpoint.\n+ */\n+public class HttpHelper {\n+\n+    private static final CloseableHttpClient httpclient = createHttpClient();\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(HttpHelper.class);\n+\n+    private ObjectMapper mapper = new ObjectMapper();\n+\n+    private String baseHost;\n+\n+    public HttpHelper(String baseHost) {\n+        this.baseHost = baseHost;\n+    }\n+\n+    private static CloseableHttpClient createHttpClient() {\n+        int timeout = 60;\n+        RequestConfig config = RequestConfig.custom()\n+                .setConnectTimeout(timeout * 1000)\n+                .setConnectionRequestTimeout(timeout * 1000)\n+                .setSocketTimeout(timeout * 1000).build();\n+        return HttpClientBuilder.create().setDefaultRequestConfig(config).build();\n+    }\n+\n+    public String doGet(String path) throws IOException {\n+        HttpGet request = new HttpGet(baseHost + path);\n+        HttpResponse response = null;\n+        response = httpclient.execute(request);\n+        HttpEntity entity = response.getEntity();\n+        if (entity != null) {\n+            String result = EntityUtils.toString(entity);\n+            LOGGER.debug(\"Get request returned \" + result);\n+            return result;\n+        }\n+\n+        return null;\n+    }\n+\n+    public String doPost(String path, String params) throws IOException {\n+\n+        HttpPost post = new HttpPost(baseHost + path);\n+        LOGGER.debug(\"Going to post to: \" + path + \"\\n with: \" + params);\n+        post.setEntity(new StringEntity(params, ContentType.APPLICATION_JSON));\n+        CloseableHttpResponse response = httpclient.execute(post);\n+        String result = EntityUtils.toString(response.getEntity());\n+        LOGGER.debug(\"I've got \" + result);\n+        return result;\n+    }\n+}", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1NDk3Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455754973", "bodyText": "I was not 100% sure about whether to bring this and RemoteDMNModel along in kogito-apps as they will most probably be replaced by a proper wiring to a /predict endpoint in kogito.\nI realize it is actually best to have explainability-core to be completely model agnostic (see also other comments wrt other DMN related classes).", "author": "tteofili", "createdAt": "2020-07-16T12:40:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0NjQ2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0Nzc2NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r454947764", "bodyText": "I think this comes directly from the PoC and might not be what we will do for the stable implementation?", "author": "r00ta", "createdAt": "2020-07-15T10:21:08Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/dmn/RemoteDMNModel.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model.dmn;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.HttpHelper;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link BlackBoxModel} implementation of a remote (HTTP/HTTPS) DMN service.\n+ */\n+public class RemoteDMNModel implements BlackBoxModel {\n+\n+    private final Logger logger = LoggerFactory.getLogger(getClass());\n+\n+    private final HttpHelper httpHelper;\n+    private final List<TypedData> inputStructure;\n+    private final List<TypedData> outputStructure;\n+    private final String modelName;\n+\n+    public RemoteDMNModel(HttpHelper httpHelper, List<TypedData> inputStructure, List<TypedData> outputStructure, String modelName) {\n+        this.httpHelper = httpHelper;\n+        this.inputStructure = inputStructure;\n+        this.outputStructure = outputStructure;\n+        this.modelName = modelName;\n+    }\n+\n+    private JSONObject toKogitoRequestJson(List<TypedData> inputStructure, List<Feature> features) {\n+        JSONObject json = new JSONObject();\n+        for (TypedData input : inputStructure) {\n+            if (input.value != null) { // is a built in type\n+                Value value = features.stream().filter(x -> x.getName().equals(input.inputName)).findFirst().get().getValue();\n+                json.put(input.inputName, input.typeRef.equals(\"string\") ? value.asString() : value.asNumber());\n+            } else {\n+                json.put(input.inputName, toKogitoRequestJson(input.components, features));\n+            }\n+        }\n+        return json;\n+    }\n+\n+    @Override\n+    public List<PredictionOutput> predict(List<PredictionInput> inputs) {\n+        List<PredictionOutput> result = new ArrayList<>();\n+        for (PredictionInput input : inputs) {\n+            String request = toKogitoRequestJson(inputStructure, input.getFeatures()).toString();\n+            String response = null;\n+            try {\n+                response = httpHelper.doPost(\"/\" + modelName + \"?tracing=false\", request);\n+            } catch (IOException e) {\n+                e.printStackTrace();\n+            }\n+            logger.debug(request);\n+            Map<String, Object> outcome = null;\n+            try {\n+                outcome = new ObjectMapper().readValue(response, new HashMap<String, Object>().getClass());\n+            } catch (JsonProcessingException e) {\n+                e.printStackTrace();\n+            }\n+            result.add(new PredictionOutput(flattenDmnResult(outcome, outputStructure.stream().map(x -> x.inputName).collect(Collectors.toList()))));\n+        }\n+        return result;\n+    }", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1NTExNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455755116", "bodyText": "+1", "author": "tteofili", "createdAt": "2020-07-16T12:40:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0Nzc2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0OTE0MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r454949140", "bodyText": "I personally would remove all the communication between services from this library and delegate it to the service, wdyt?", "author": "r00ta", "createdAt": "2020-07-15T10:23:42Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/dmn/RemoteDMNModel.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model.dmn;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.HttpHelper;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@link BlackBoxModel} implementation of a remote (HTTP/HTTPS) DMN service.\n+ */\n+public class RemoteDMNModel implements BlackBoxModel {", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1NTIzMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455755233", "bodyText": "+1", "author": "tteofili", "createdAt": "2020-07-16T12:41:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0OTE0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk1NDM3MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r454954370", "bodyText": "I think debug should be better", "author": "danielezonca", "createdAt": "2020-07-15T10:33:26Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global.pdp;\n+\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.DataSeries;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.global.GlobalExplainer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Generates the partial dependence plot for a given feature.\n+ * While a strict PD implementation would need the whole training set used to train the model, this implementation seeks\n+ * to reproduce an approximate version of the training data by means of data distribution information (min, max, mean,\n+ * stdDev).\n+ */\n+public class PartialDependencePlotExplainer implements GlobalExplainer<Collection<DataSeries>> {\n+\n+    private static final int TABLE_SIZE = 100;\n+\n+    private final Logger logger = LoggerFactory.getLogger(getClass());\n+\n+    @Override\n+    public Collection<DataSeries> explain(BlackBoxModel model) {\n+        long start = System.currentTimeMillis();\n+\n+        Collection<DataSeries> pdps = new LinkedList<>();\n+        try {\n+            DataDistribution dataDistribution = model.getDataDistribution();\n+            int noOfFeatures = model.getInputShape().getFeatures().size();\n+\n+            List<FeatureDistribution> featureDistributions = dataDistribution.getFeatureDistributions();\n+            for (int featureIndex = 0; featureIndex < noOfFeatures; featureIndex++) {\n+                for (int outputIndex = 0; outputIndex < model.getOutputShape().getOutputs().size(); outputIndex++) {\n+                    double[] featureXSvalues = DataUtils.generateSamples(featureDistributions.get(featureIndex).getMin(),\n+                                                                         featureDistributions.get(featureIndex).getMax(), TABLE_SIZE);\n+\n+                    double[][] trainingData = new double[noOfFeatures][TABLE_SIZE];\n+                    for (int i = 0; i < noOfFeatures; i++) {\n+                        double[] featureData = DataUtils.generateData(featureDistributions.get(i).getMean(),\n+                                                                      featureDistributions.get(i).getStdDev(), TABLE_SIZE);\n+                        trainingData[i] = featureData;\n+                    }\n+\n+                    double[] marginalImpacts = new double[featureXSvalues.length];\n+                    for (int i = 0; i < featureXSvalues.length; i++) {\n+                        List<PredictionInput> predictionInputs = new LinkedList<>();\n+                        double xs = featureXSvalues[i];\n+                        double[] inputs = new double[noOfFeatures];\n+                        inputs[featureIndex] = xs;\n+                        for (int j = 0; j < TABLE_SIZE; j++) {\n+                            for (int f = 0; f < noOfFeatures; f++) {\n+                                if (f != featureIndex) {\n+                                    inputs[f] = trainingData[f][j];\n+                                }\n+                            }\n+                            PredictionInput input = new PredictionInput(DataUtils.doublesToFeatures(inputs));\n+                            predictionInputs.add(input);\n+                        }\n+\n+                        // prediction requests are batched per value of feature 'Xs' under analysis\n+                        for (PredictionOutput predictionOutput : model.predict(predictionInputs)) {\n+                            Output output = predictionOutput.getOutputs().get(outputIndex);\n+                            marginalImpacts[i] += output.getScore() / (double) TABLE_SIZE;\n+                        }\n+                    }\n+                    DataSeries dataSeries = new DataSeries(model.getInputShape().getFeatures().get(featureIndex),\n+                                                           featureXSvalues, marginalImpacts);\n+                    pdps.add(dataSeries);\n+                }\n+            }\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+        long end = System.currentTimeMillis();\n+        logger.info(\"explanation time: {}ms\", (end - start));", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc2MTA5NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455761095", "bodyText": "+1", "author": "tteofili", "createdAt": "2020-07-16T12:50:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk1NDM3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk1NTE0OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r454955149", "bodyText": "Why don't add NUMBER to switch block and remove this addition if? Is it needed?", "author": "danielezonca", "createdAt": "2020-07-15T10:34:58Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ *\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * get the input and output predictions transformed into a numerical training set\n+     * @return a numerical training set\n+     */\n+    List<Pair<double[], Double>> getEncodedTrainingSet() {\n+        List<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        List<List<Double>> columnData;\n+        List<PredictionInput> flatInputs = DataUtils.linearizeInputs(perturbedInputs);\n+        if (!flatInputs.isEmpty() && !predictedOutputs.isEmpty() && !targetInput.getFeatures().isEmpty() && originalOutput != null) {\n+            columnData = getColumnData(flatInputs);\n+\n+            int pi = 0;\n+            for (Output output : predictedOutputs) {\n+                double[] x = new double[columnData.size()];\n+                int i = 0;\n+                for (List<Double> column : columnData) {\n+                    x[i] = column.get(pi);\n+                    i++;\n+                }\n+                double y;\n+                if (Type.NUMBER.equals(originalOutput.getType()) || Type.BOOLEAN.equals(originalOutput.getType())) {\n+                    y = output.getValue().asNumber();\n+                } else {\n+                    Object originalObject = originalOutput.getValue().getUnderlyingObject();\n+                    Object outputObject = output.getValue().getUnderlyingObject();\n+                    if (originalObject == null || outputObject == null) {\n+                        y = originalObject == outputObject ? 1d : 0d;\n+                    } else {\n+                        y = originalObject.equals(outputObject) ? 1d : 0d;\n+                    }\n+                }\n+                Pair<double[], Double> sample = new ImmutablePair<>(x, y);\n+                trainingSet.add(sample);\n+\n+                pi++;\n+            }\n+        }\n+        return trainingSet;\n+    }\n+\n+    private List<List<Double>> getColumnData(List<PredictionInput> perturbedInputs) {\n+        List<Type> featureTypes = targetInput.getFeatures().stream().map(Feature::getType).collect(Collectors.toList());\n+        List<List<Double>> columnData = new LinkedList<>();\n+\n+        for (int t = 0; t < featureTypes.size(); t++) {\n+            if (!Type.NUMBER.equals(featureTypes.get(t))) {", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1NTUzMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455755533", "bodyText": "good point :) thanks", "author": "tteofili", "createdAt": "2020-07-16T12:41:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk1NTE0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk5OTg1OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r454999859", "bodyText": "What does this imply?", "author": "danielezonca", "createdAt": "2020-07-15T12:04:34Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) optimised for tabular data and decision models.\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private final Logger logger = LoggerFactory.getLogger(getClass());\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, BlackBoxModel model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        PredictionInput originalInput = prediction.getInput();\n+        List<Feature> inputFeatures = originalInput.getFeatures();\n+        PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+        int noOfInputFeatures = inputFeatures.size();\n+        int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+        double[] weights = new double[noOfOutputFeatures];\n+\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            boolean separableDataset = false;\n+\n+            List<PredictionInput> perturbedInputs = new LinkedList<>();\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+\n+            boolean classification = false;\n+            int tries = 3;\n+            Map<Double, Long> rawClassesBalance = new HashMap<>();\n+            Output currentOutput = actualOutputs.get(o);\n+            while (!separableDataset && tries > 0) {\n+                List<PredictionInput> perturbed = getPerturbedInputs(originalInput, noOfInputFeatures, noOfSamples);\n+                List<PredictionOutput> perturbedOutputs = model.predict(perturbed);\n+\n+                Object fv = currentOutput != null && currentOutput.getValue() != null ? currentOutput.getValue().getUnderlyingObject() : null;\n+\n+                int finalO = o;\n+                rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                        .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                        && fv == null) || output.getValue().getUnderlyingObject().equals(fv)) ? 1d : 0d))\n+                        .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n+\n+                if (rawClassesBalance.size() > 1) {\n+                    Long max = rawClassesBalance.values().stream().max(Long::compareTo).get();\n+                    if ((double) max / (double) perturbed.size() < 0.9) {\n+                        separableDataset = true;\n+                        classification = rawClassesBalance.size() == 2;\n+                    } else {\n+                        tries--;\n+                    }\n+                } else {\n+                    tries--;\n+                }\n+                if (tries == 0 || separableDataset) {\n+                    perturbedInputs.addAll(perturbed);\n+                    predictionOutputs.addAll(perturbedOutputs);\n+                }\n+            }\n+            if (!separableDataset) {\n+                logger.warn(\"the perturbed inputs / outputs dataset is not (easily) separable: {}\", rawClassesBalance);\n+            }", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk5OTk2MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r454999961", "bodyText": "debug?", "author": "danielezonca", "createdAt": "2020-07-15T12:04:46Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) optimised for tabular data and decision models.\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private final Logger logger = LoggerFactory.getLogger(getClass());\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, BlackBoxModel model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        PredictionInput originalInput = prediction.getInput();\n+        List<Feature> inputFeatures = originalInput.getFeatures();\n+        PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+        int noOfInputFeatures = inputFeatures.size();\n+        int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+        double[] weights = new double[noOfOutputFeatures];\n+\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            boolean separableDataset = false;\n+\n+            List<PredictionInput> perturbedInputs = new LinkedList<>();\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+\n+            boolean classification = false;\n+            int tries = 3;\n+            Map<Double, Long> rawClassesBalance = new HashMap<>();\n+            Output currentOutput = actualOutputs.get(o);\n+            while (!separableDataset && tries > 0) {\n+                List<PredictionInput> perturbed = getPerturbedInputs(originalInput, noOfInputFeatures, noOfSamples);\n+                List<PredictionOutput> perturbedOutputs = model.predict(perturbed);\n+\n+                Object fv = currentOutput != null && currentOutput.getValue() != null ? currentOutput.getValue().getUnderlyingObject() : null;\n+\n+                int finalO = o;\n+                rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                        .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                        && fv == null) || output.getValue().getUnderlyingObject().equals(fv)) ? 1d : 0d))\n+                        .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n+\n+                if (rawClassesBalance.size() > 1) {\n+                    Long max = rawClassesBalance.values().stream().max(Long::compareTo).get();\n+                    if ((double) max / (double) perturbed.size() < 0.9) {\n+                        separableDataset = true;\n+                        classification = rawClassesBalance.size() == 2;\n+                    } else {\n+                        tries--;\n+                    }\n+                } else {\n+                    tries--;\n+                }\n+                if (tries == 0 || separableDataset) {\n+                    perturbedInputs.addAll(perturbed);\n+                    predictionOutputs.addAll(perturbedOutputs);\n+                }\n+            }\n+            if (!separableDataset) {\n+                logger.warn(\"the perturbed inputs / outputs dataset is not (easily) separable: {}\", rawClassesBalance);\n+            }\n+            List<Output> predictedOutputs = new LinkedList<>();\n+            for (int i = 0; i < perturbedInputs.size(); i++) {\n+                Output output = predictionOutputs.get(i).getOutputs().get(o);\n+                predictedOutputs.add(output);\n+            }\n+\n+            Output originalOutput = prediction.getOutput().getOutputs().get(o);\n+\n+            DatasetEncoder datasetEncoder = new DatasetEncoder(perturbedInputs, predictedOutputs, targetInput, originalOutput);\n+            Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+\n+            double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+\n+            LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), classification);\n+            linearModel.fit(trainingSet, sampleWeights);\n+            for (int i = 0; i < weights.length; i++) {\n+                weights[i] += linearModel.getWeights()[i] / (double) actualOutputs.size();\n+            }\n+            logger.debug(\"weights updated for output {}\", currentOutput);\n+        }\n+        for (int i = 0; i < weights.length; i++) {\n+            FeatureImportance featureImportance = new FeatureImportance(linearizedTargetInputFeatures.get(i), weights[i]);\n+            saliencies.add(featureImportance);\n+        }\n+        long end = System.currentTimeMillis();\n+        logger.info(\"explanation time: {}ms\", (end - start));", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxNTEzOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455015138", "bodyText": "Why this? This means that empty string and null are equivalent", "author": "danielezonca", "createdAt": "2020-07-15T12:32:19Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Value.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Wrapper class for any kind of value part of a prediction input or output.\n+ * @param <S>\n+ */\n+public class Value<S> {\n+\n+    private final S underlyingObject;\n+\n+    public Value(S underlyingObject) {\n+        this.underlyingObject = underlyingObject;\n+    }\n+\n+    public String asString() {\n+        if (underlyingObject == null) {\n+            return \"\";", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1NjIzMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455756231", "bodyText": "this is wrong, thanks for catching it :)", "author": "tteofili", "createdAt": "2020-07-16T12:42:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxNTEzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxNTg4OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455015889", "bodyText": "Can you review this class? It is named DMN but it is not using any DMN class at all. Is it maybe a generic data types utils class?", "author": "danielezonca", "createdAt": "2020-07-15T12:33:38Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/dmn/DMNUtils.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model.dmn;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+\n+/**\n+ * Utility class to handle DMN types for input and output.\n+ */\n+public class DMNUtils {", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1Njc3NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455756774", "bodyText": "yes, this is used to convert TypedData into and from PredictionInputs and PredictionOutputs.\nAnyway this stuff belongs to the explanation-service hence dropping it from the current PR.", "author": "tteofili", "createdAt": "2020-07-16T12:43:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxNTg4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxNzM3OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455017378", "bodyText": "What is this class? I do not expect any DMN specific class in this library expect as test", "author": "danielezonca", "createdAt": "2020-07-15T12:36:11Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/dmn/DecisionModelWrapper.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model.dmn;\n+\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.dmn.api.core.DMNContext;\n+import org.kie.dmn.api.core.DMNDecisionResult;\n+import org.kie.dmn.api.core.DMNResult;\n+import org.kie.dmn.api.core.DMNType;\n+import org.kie.dmn.api.core.ast.DecisionNode;\n+import org.kie.dmn.api.core.ast.InputDataNode;\n+import org.kie.dmn.model.api.Decision;\n+import org.kie.kogito.decision.DecisionModel;\n+\n+/**\n+ * {@link BlackBoxModel} implementation based on a Kogito {@link DecisionModel}.\n+ */\n+public class DecisionModelWrapper implements BlackBoxModel {", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1NzA1Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455757056", "bodyText": "see above, moving it to explainability-integrationtests-dmn.", "author": "tteofili", "createdAt": "2020-07-16T12:44:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxNzM3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxODc2MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455018760", "bodyText": "This should not be in the core (and in general we can leverage on quarkus features for that)", "author": "danielezonca", "createdAt": "2020-07-15T12:38:40Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/HttpHelper.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+import java.io.IOException;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.client.config.RequestConfig;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpGet;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.entity.ContentType;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClientBuilder;\n+import org.apache.http.util.EntityUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Helper class to connect to a remote endpoint.\n+ */\n+public class HttpHelper {", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1NzE2MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455757161", "bodyText": "+1", "author": "tteofili", "createdAt": "2020-07-16T12:44:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxODc2MA=="}], "type": "inlineReview"}, {"oid": "ba21264f71a85203adaab370cdc4528be4fd67f6", "url": "https://github.com/kiegroup/kogito-apps/commit/ba21264f71a85203adaab370cdc4528be4fd67f6", "message": "KOGITO-2750 - fixes according to Jacopo's and Daniele's comments", "committedDate": "2020-07-15T15:21:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEyNjg4NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455126885", "bodyText": "Is this supposed to be not deterministic?", "author": "r00ta", "createdAt": "2020-07-15T15:08:40Z", "path": "explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/LoanEligibilityDmnLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.explainability.integrationtests.dmn;\n+\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.dmn.DecisionModelWrapper;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.junit.jupiter.api.RepeatedTest;\n+import org.kie.dmn.api.core.DMNRuntime;\n+import org.kie.kogito.decision.DecisionModel;\n+import org.kie.kogito.dmn.DMNKogito;\n+import org.kie.kogito.dmn.DmnDecisionModel;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+public class LoanEligibilityDmnLimeExplainerTest {\n+\n+    @RepeatedTest(10)", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1OTk1NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455759954", "bodyText": "Such ITs are currently repeated as they used to be the first gate to stability of LIME explanations.\nCurrently we also have other tests covering the stability parts.\nHowever there's some non determinism in how LIME perturb features and hence the repeated test.\nI am fine to move them to single execution tests.", "author": "tteofili", "createdAt": "2020-07-16T12:49:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEyNjg4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEyOTI2MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455129261", "bodyText": "Is there a specific reason why the integration tests are in separated modules? We might put them in the core and service modules and add the maven plugin to run them if they match a specific regex (like we are already doing for the trusty service and the data index) see here \n  \n    \n      kogito-apps/data-index/data-index-service/pom.xml\n    \n    \n         Line 159\n      in\n      8516df2\n    \n    \n    \n    \n\n        \n          \n           <goal>integration-test</goal>", "author": "r00ta", "createdAt": "2020-07-15T15:12:12Z", "path": "explainability/explainability-integrationtests/explainability-integrationtests-dmn/src/test/java/org/kie/kogito/explainability/explainability/integrationtests/dmn/LoanEligibilityDmnLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc1ODkzMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455758930", "bodyText": "the main reason to have them in separate modules is that dependencies needed to run DMN and PMML dependencies within the same JVM are not compatible, in the sense that they use two different and not compatible versions of drools (at least in the current state of kie-pmml-new vs kogito-dmn).", "author": "tteofili", "createdAt": "2020-07-16T12:47:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEyOTI2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEyOTg0OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455129848", "bodyText": "pdps?", "author": "r00ta", "createdAt": "2020-07-15T15:13:05Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global.pdp;\n+\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.DataSeries;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.global.GlobalExplainer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Generates the partial dependence plot for a given feature.\n+ * While a strict PD implementation would need the whole training set used to train the model, this implementation seeks\n+ * to reproduce an approximate version of the training data by means of data distribution information (min, max, mean,\n+ * stdDev).\n+ */\n+public class PartialDependencePlotExplainer implements GlobalExplainer<Collection<DataSeries>> {\n+\n+    private static final int TABLE_SIZE = 100;\n+\n+    private final Logger logger = LoggerFactory.getLogger(getClass());\n+\n+    @Override\n+    public Collection<DataSeries> explain(BlackBoxModel model) {\n+        long start = System.currentTimeMillis();\n+\n+        Collection<DataSeries> pdps = new LinkedList<>();", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc2MDMyNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455760326", "bodyText": "partial dependency plots.", "author": "tteofili", "createdAt": "2020-07-16T12:49:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEyOTg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEzMDM4Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455130387", "bodyText": "log?", "author": "r00ta", "createdAt": "2020-07-15T15:13:52Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global.pdp;\n+\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.DataSeries;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.global.GlobalExplainer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Generates the partial dependence plot for a given feature.\n+ * While a strict PD implementation would need the whole training set used to train the model, this implementation seeks\n+ * to reproduce an approximate version of the training data by means of data distribution information (min, max, mean,\n+ * stdDev).\n+ */\n+public class PartialDependencePlotExplainer implements GlobalExplainer<Collection<DataSeries>> {\n+\n+    private static final int TABLE_SIZE = 100;\n+\n+    private final Logger logger = LoggerFactory.getLogger(getClass());\n+\n+    @Override\n+    public Collection<DataSeries> explain(BlackBoxModel model) {\n+        long start = System.currentTimeMillis();\n+\n+        Collection<DataSeries> pdps = new LinkedList<>();\n+        try {\n+            DataDistribution dataDistribution = model.getDataDistribution();\n+            int noOfFeatures = model.getInputShape().getFeatures().size();\n+\n+            List<FeatureDistribution> featureDistributions = dataDistribution.getFeatureDistributions();\n+            for (int featureIndex = 0; featureIndex < noOfFeatures; featureIndex++) {\n+                for (int outputIndex = 0; outputIndex < model.getOutputShape().getOutputs().size(); outputIndex++) {\n+                    double[] featureXSvalues = DataUtils.generateSamples(featureDistributions.get(featureIndex).getMin(),\n+                                                                         featureDistributions.get(featureIndex).getMax(), TABLE_SIZE);\n+\n+                    double[][] trainingData = new double[noOfFeatures][TABLE_SIZE];\n+                    for (int i = 0; i < noOfFeatures; i++) {\n+                        double[] featureData = DataUtils.generateData(featureDistributions.get(i).getMean(),\n+                                                                      featureDistributions.get(i).getStdDev(), TABLE_SIZE);\n+                        trainingData[i] = featureData;\n+                    }\n+\n+                    double[] marginalImpacts = new double[featureXSvalues.length];\n+                    for (int i = 0; i < featureXSvalues.length; i++) {\n+                        List<PredictionInput> predictionInputs = new LinkedList<>();\n+                        double xs = featureXSvalues[i];\n+                        double[] inputs = new double[noOfFeatures];\n+                        inputs[featureIndex] = xs;\n+                        for (int j = 0; j < TABLE_SIZE; j++) {\n+                            for (int f = 0; f < noOfFeatures; f++) {\n+                                if (f != featureIndex) {\n+                                    inputs[f] = trainingData[f][j];\n+                                }\n+                            }\n+                            PredictionInput input = new PredictionInput(DataUtils.doublesToFeatures(inputs));\n+                            predictionInputs.add(input);\n+                        }\n+\n+                        // prediction requests are batched per value of feature 'Xs' under analysis\n+                        for (PredictionOutput predictionOutput : model.predict(predictionInputs)) {\n+                            Output output = predictionOutput.getOutputs().get(outputIndex);\n+                            marginalImpacts[i] += output.getScore() / (double) TABLE_SIZE;\n+                        }\n+                    }\n+                    DataSeries dataSeries = new DataSeries(model.getInputShape().getFeatures().get(featureIndex),\n+                                                           featureXSvalues, marginalImpacts);\n+                    pdps.add(dataSeries);\n+                }\n+            }\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc2MDg5NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455760895", "bodyText": "imho, as per the local case, we need to throw a GlobalExplainabilityException.", "author": "tteofili", "createdAt": "2020-07-16T12:50:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEzMDM4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEzMDUyOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455130529", "bodyText": "private static final?", "author": "r00ta", "createdAt": "2020-07-15T15:14:08Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global.pdp;\n+\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.DataSeries;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.global.GlobalExplainer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Generates the partial dependence plot for a given feature.\n+ * While a strict PD implementation would need the whole training set used to train the model, this implementation seeks\n+ * to reproduce an approximate version of the training data by means of data distribution information (min, max, mean,\n+ * stdDev).\n+ */\n+public class PartialDependencePlotExplainer implements GlobalExplainer<Collection<DataSeries>> {\n+\n+    private static final int TABLE_SIZE = 100;\n+\n+    private final Logger logger = LoggerFactory.getLogger(getClass());", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc2MTAxMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455761010", "bodyText": "+1", "author": "tteofili", "createdAt": "2020-07-16T12:50:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEzMDUyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEzNDMzMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455134332", "bodyText": "I don't think assert is a good idea here :/ Throw an illegal argument exception (or my personal preference is anyway to use a factory if an exception can be raised)", "author": "r00ta", "createdAt": "2020-07-15T15:19:25Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/DataSeries.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+public class DataSeries {\n+\n+    private final double[] x;\n+    private final double[] y;\n+    private final Feature feature;\n+\n+    public DataSeries(Feature feature, double[] x, double[] y) {\n+        assert x.length == y.length : \"x and y lengths do not match\";", "originalCommit": "92e39d5446821fc262025f9e7c11794be87945ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTc2MjYwMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455762601", "bodyText": "I do not expect this class to be instantiated by customers / external users hence not having a Factory / Builder with proper checks. The reason for using assert in first place is that it was an internal check I put in place while I was developing the PDP implementation.\nI'm fine to drop it anyway.", "author": "tteofili", "createdAt": "2020-07-16T12:53:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTEzNDMzMg=="}], "type": "inlineReview"}, {"oid": "280d51791ae5c12fa073072891d724974f9abcb7", "url": "https://github.com/kiegroup/kogito-apps/commit/280d51791ae5c12fa073072891d724974f9abcb7", "message": "KOGITO-2750 - incorporated more changes from PR review, explicit handling is required when dataset is not separable", "committedDate": "2020-07-16T12:31:07Z", "type": "commit"}, {"oid": "19385d8744d1a4bc9274c6b6e37f7cbce2e3809e", "url": "https://github.com/kiegroup/kogito-apps/commit/19385d8744d1a4bc9274c6b6e37f7cbce2e3809e", "message": "KOGITO-2750 - incorporated more changes from PR review, added GlobalExplantionException for GlobalExplainers", "committedDate": "2020-07-16T13:18:23Z", "type": "commit"}, {"oid": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "url": "https://github.com/kiegroup/kogito-apps/commit/abbfbac86aaf495013f28d4943e8a8118f2f181c", "message": "KOGITO-2750 - minor fix with OptionalDouble avoiding NSEException", "committedDate": "2020-07-16T13:40:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0MDYyOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455840628", "bodyText": "Don't shoot on me :) I'm not sure about the documentation policy of the project but I'd suggest to start always with capital letter and end the sentence with the dot (also for all the other classes). Do you have more info @jiripetrlik @danielezonca ?", "author": "r00ta", "createdAt": "2020-07-16T14:42:36Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * get the input and output predictions transformed into a numerical training set", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyMzQwMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455923400", "bodyText": "We do not have a proper policy so fine for me both upper or lower case. Usually we use upper case but no strong opinion", "author": "danielezonca", "createdAt": "2020-07-16T16:40:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0MDYyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTk2NDQ4Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455964483", "bodyText": "Ok thanks Daniele, I would suggest to align all the docs so that the first letter is capital with a final dot", "author": "r00ta", "createdAt": "2020-07-16T17:48:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0MDYyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0MzU1OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455843558", "bodyText": "I wonder if BlackBoxModel is the most comprehensive name here, since this class is going to be extended by the consumer of the library and implement the mechanism to execute the prediction (in our case, the BlackBoxModelImpl would make http calls to the kogito-runtimes application so it's not just executing the model). For that reason, what about PredictionProvider or something like this?", "author": "r00ta", "createdAt": "2020-07-16T14:46:33Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/BlackBoxModel.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+import java.util.List;\n+\n+/**\n+ * A black box model capable of performing predictions.\n+ * This can be using different kinds of underlying functions, like DMN, PMML, or any other machine learning model.\n+ */\n+public interface BlackBoxModel {", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM1MzgzNA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456353834", "bodyText": "I had dropped the previous much overloaded Model in favor of BlackBoxModel because I wanted to highlight that the library is expected to work with any kind of model, regardless of implementation.\nPredictionProvider sounds good to me to highlight the fact that it is not necessarily a model instance (e.g. loaded in memory from disk), the only thing I am not sure is that, in its current state, it doesn't only provide predictions but also information about feature wise data distribution.\nThis leads to me to think that it might be useful to decouple the prediction API from the data distribution API, also because not all the providers are also able to provide data distribution information.\nSo PredictionProvider will only have the predict API.", "author": "tteofili", "createdAt": "2020-07-17T10:16:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0MzU1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQwMTQyNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456401425", "bodyText": "Makes sense to me", "author": "r00ta", "createdAt": "2020-07-17T12:09:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0MzU1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0Nzg5MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455847890", "bodyText": "Is this covering all the possible cases?", "author": "r00ta", "createdAt": "2020-07-16T14:52:18Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Value.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Wrapper class for any kind of value part of a prediction input or output.\n+ * @param <S>\n+ */\n+public class Value<S> {\n+\n+    private final S underlyingObject;\n+\n+    public Value(S underlyingObject) {\n+        this.underlyingObject = underlyingObject;\n+    }\n+\n+    public String asString() {\n+        return String.valueOf(underlyingObject);\n+    }\n+\n+    public double asNumber() {\n+        if (underlyingObject != null) {\n+            return underlyingObject instanceof Boolean ? (Boolean) underlyingObject ? 1d : 0d : Double.parseDouble(asString());\n+        } else {\n+            return Double.NaN;\n+        }\n+    }\n+\n+    public S getUnderlyingObject() {\n+        return underlyingObject;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Value{\" + underlyingObject + '}';\n+    }\n+\n+    public double[] asVector() {\n+        double[] doubles;\n+        try {\n+            doubles = (double[]) underlyingObject;\n+        } catch (ClassCastException cce) {\n+            if (underlyingObject instanceof String) {\n+                int noOfWords = ((String) underlyingObject).split(\" \").length;\n+                doubles = new double[noOfWords];\n+                Arrays.fill(doubles, 1);\n+            } else {\n+                try {\n+                    double v = asNumber();\n+                    doubles = new double[1];\n+                    doubles[0] = v;\n+                } catch (Exception e) {\n+                    doubles = new double[0];\n+                }\n+            }\n+        }\n+        return doubles;", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMxNzM1OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456317358", "bodyText": "not all possible cases yet.\nHere're the ones I see:\n\nwe could have a String representation of a vector, right now it is blindly converted into an arrays of 1s\nwe could have a binary, a ByteBuffer, that could be parsed as a double[]\netc.\nIt probably makes sense to have a VectorValue interface that users should leverage to define how a specific object is encoded/decoded into/from a double[].", "author": "tteofili", "createdAt": "2020-07-17T09:04:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0Nzg5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQwMjQwMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456402402", "bodyText": "I'm a bit concerned about that because if the developer is using some dmn models (or whatever :) ) that we do not support, we are not catching the exception that is going to be raised here", "author": "r00ta", "createdAt": "2020-07-17T12:11:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0Nzg5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUxMjUxMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456512513", "bodyText": "as far as I can see, the problem here is that we eventually do not correctly parse a vector feature, or skip parts of it.\nThe right fix here is a more thorough (and pluggable) encoding / decoding mechanism for vector values.\nNote though that this is anyway an edge case where a model holds an entire vector into a single feature, whereas the good practice is to use a feature for each coordinate (value) in a vector (e.g. you have 100 numerical features for a 100-dimensional vector), which we correctly handle already.\nI've created FAI-234 ticket for this purpose.", "author": "tteofili", "createdAt": "2020-07-17T15:24:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0Nzg5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0ODc3OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455848779", "bodyText": "I'd remove those comments since the method names are already clear. Keep only force desired XYZ ones", "author": "r00ta", "createdAt": "2020-07-16T14:53:30Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,518 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.math.BigDecimal;\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        // get the mean", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMxNzY3Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456317672", "bodyText": "ok", "author": "tteofili", "createdAt": "2020-07-17T09:05:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg0ODc3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1MDcyMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455850722", "bodyText": "Are the casts (double) needed?", "author": "r00ta", "createdAt": "2020-07-16T14:55:58Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility class providing different methods to evaluate explainability.\n+ */\n+public class ExplainabilityMetrics {\n+\n+    /**\n+     * measure the explainability of an explanation as per paper \"Towards Quantification of Explainability in Explainable\n+     * Artificial Intelligence Methods\" by Islam et al.\n+     *\n+     * @param inputCognitiveChunks  the no. of cognitive chunks (pieces of information) required to generate the\n+     *                              explanation (e.g. the no. of explanation inputs)\n+     * @param outputCognitiveChunks the no. of cognitive chunks generated within the explanation itself\n+     * @param interactionRatio      the ratio of interaction (between 0 and 1) required by the explanation\n+     * @return the quantitative explainability measure\n+     */\n+    public static double quantifyExplainability(int inputCognitiveChunks, int outputCognitiveChunks, double interactionRatio) {\n+        return inputCognitiveChunks + outputCognitiveChunks > 0 ? 0.333 / (double) inputCognitiveChunks", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkyNDQ4Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455924483", "bodyText": "It is not needed because 0.333 is already floating point but I prefer to keep the cast to preserve floating point division even if we change 0.333 to 1 or similar", "author": "danielezonca", "createdAt": "2020-07-16T16:42:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1MDcyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODMwMjczMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458302733", "bodyText": "@tteofili have a look at this please", "author": "r00ta", "createdAt": "2020-07-21T18:26:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1MDcyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1MTM2NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455851364", "bodyText": "Check condition directly in the if?", "author": "r00ta", "createdAt": "2020-07-16T14:56:51Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility class providing different methods to evaluate explainability.\n+ */\n+public class ExplainabilityMetrics {\n+\n+    /**\n+     * measure the explainability of an explanation as per paper \"Towards Quantification of Explainability in Explainable\n+     * Artificial Intelligence Methods\" by Islam et al.\n+     *\n+     * @param inputCognitiveChunks  the no. of cognitive chunks (pieces of information) required to generate the\n+     *                              explanation (e.g. the no. of explanation inputs)\n+     * @param outputCognitiveChunks the no. of cognitive chunks generated within the explanation itself\n+     * @param interactionRatio      the ratio of interaction (between 0 and 1) required by the explanation\n+     * @return the quantitative explainability measure\n+     */\n+    public static double quantifyExplainability(int inputCognitiveChunks, int outputCognitiveChunks, double interactionRatio) {\n+        return inputCognitiveChunks + outputCognitiveChunks > 0 ? 0.333 / (double) inputCognitiveChunks\n+                + 0.333 / (double) outputCognitiveChunks + 0.333 * (1d - interactionRatio) : 0;\n+    }\n+\n+    /**\n+     * Calculate the impact of dropping the most important features (given by {@link Saliency#getTopFeatures(int)} from the input.\n+     * Highly important features would have rather high impact.\n+     *\n+     * @param model      the model to be explained\n+     * @param prediction a prediction\n+     * @param topFeatures the list of important features that should be dropped\n+     * @return the saliency impact\n+     */\n+    public static double saliencyImpact(BlackBoxModel model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+        String[] importantFeatureNames = topFeatures.stream().map(f -> f.getFeature().getName()).toArray(String[]::new);\n+\n+        List<Feature> newFeatures = new LinkedList<>();\n+        for (Feature feature : prediction.getInput().getFeatures()) {\n+            Feature newFeature = DataUtils.dropFeature(feature, importantFeatureNames);\n+            newFeatures.add(newFeature);\n+        }\n+        PredictionInput predictionInput = new PredictionInput(newFeatures);\n+        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n+        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        double impact = 0;\n+        double size = predictionOutput.getOutputs().size();\n+        for (int i = 0; i < size; i++) {\n+            Output original = prediction.getOutput().getOutputs().get(i);\n+            Output modified = predictionOutput.getOutputs().get(i);\n+            impact += DataUtils.euclideanDistance(new double[]{original.getScore()}, new double[]{modified.getScore()});\n+            impact += DataUtils.hammingDistance(original.getValue().asString(), modified.getValue().asString());\n+        }\n+        return impact / size;\n+    }\n+\n+    /**\n+     * calculate fidelity of boolean classification outputs using saliency predictor function = sign(sum(saliency.scores))\n+     * see papers:\n+     * - Guidotti Riccardo, et al. \"A survey of methods for explaining black box models.\" ACM computing surveys (2018).\n+     * - Bodria, Francesco, et al. \"Explainability Methods for Natural Language Processing: Applications to Sentiment Analysis (Discussion Paper).\"\n+     *\n+     * @param pairs pairs composed by the saliency and the related prediction\n+     * @return the fidelity accuracy\n+     */\n+    public static double classificationFidelity(List<Pair<Saliency, Prediction>> pairs) {\n+        double acc = 0;\n+        double evals = 0;\n+        for (Pair<Saliency, Prediction> pair : pairs) {\n+            Saliency saliency = pair.getLeft();\n+            Prediction prediction = pair.getRight();\n+            for (Output output : prediction.getOutput().getOutputs()) {\n+                Type type = output.getType();\n+                if (Type.BOOLEAN.equals(type)) {\n+                    double predictorOutput = saliency.getPerFeatureImportance().stream().map(FeatureImportance::getScore).mapToDouble(d -> d).sum();\n+                    double v = output.getValue().asNumber();\n+                    boolean match = (v >= 0 && predictorOutput >= 0) || (v < 0 && predictorOutput < 0);\n+                    if (match) {", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1NDUxNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455854517", "bodyText": "Is it possible that pairs or prediction.getOutput().getOutputs() are empty? if so, an exception is going to be raised because of return 0/0", "author": "r00ta", "createdAt": "2020-07-16T15:01:02Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility class providing different methods to evaluate explainability.\n+ */\n+public class ExplainabilityMetrics {\n+\n+    /**\n+     * measure the explainability of an explanation as per paper \"Towards Quantification of Explainability in Explainable\n+     * Artificial Intelligence Methods\" by Islam et al.\n+     *\n+     * @param inputCognitiveChunks  the no. of cognitive chunks (pieces of information) required to generate the\n+     *                              explanation (e.g. the no. of explanation inputs)\n+     * @param outputCognitiveChunks the no. of cognitive chunks generated within the explanation itself\n+     * @param interactionRatio      the ratio of interaction (between 0 and 1) required by the explanation\n+     * @return the quantitative explainability measure\n+     */\n+    public static double quantifyExplainability(int inputCognitiveChunks, int outputCognitiveChunks, double interactionRatio) {\n+        return inputCognitiveChunks + outputCognitiveChunks > 0 ? 0.333 / (double) inputCognitiveChunks\n+                + 0.333 / (double) outputCognitiveChunks + 0.333 * (1d - interactionRatio) : 0;\n+    }\n+\n+    /**\n+     * Calculate the impact of dropping the most important features (given by {@link Saliency#getTopFeatures(int)} from the input.\n+     * Highly important features would have rather high impact.\n+     *\n+     * @param model      the model to be explained\n+     * @param prediction a prediction\n+     * @param topFeatures the list of important features that should be dropped\n+     * @return the saliency impact\n+     */\n+    public static double saliencyImpact(BlackBoxModel model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+        String[] importantFeatureNames = topFeatures.stream().map(f -> f.getFeature().getName()).toArray(String[]::new);\n+\n+        List<Feature> newFeatures = new LinkedList<>();\n+        for (Feature feature : prediction.getInput().getFeatures()) {\n+            Feature newFeature = DataUtils.dropFeature(feature, importantFeatureNames);\n+            newFeatures.add(newFeature);\n+        }\n+        PredictionInput predictionInput = new PredictionInput(newFeatures);\n+        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n+        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        double impact = 0;\n+        double size = predictionOutput.getOutputs().size();\n+        for (int i = 0; i < size; i++) {\n+            Output original = prediction.getOutput().getOutputs().get(i);\n+            Output modified = predictionOutput.getOutputs().get(i);\n+            impact += DataUtils.euclideanDistance(new double[]{original.getScore()}, new double[]{modified.getScore()});\n+            impact += DataUtils.hammingDistance(original.getValue().asString(), modified.getValue().asString());\n+        }\n+        return impact / size;\n+    }\n+\n+    /**\n+     * calculate fidelity of boolean classification outputs using saliency predictor function = sign(sum(saliency.scores))\n+     * see papers:\n+     * - Guidotti Riccardo, et al. \"A survey of methods for explaining black box models.\" ACM computing surveys (2018).\n+     * - Bodria, Francesco, et al. \"Explainability Methods for Natural Language Processing: Applications to Sentiment Analysis (Discussion Paper).\"\n+     *\n+     * @param pairs pairs composed by the saliency and the related prediction\n+     * @return the fidelity accuracy\n+     */\n+    public static double classificationFidelity(List<Pair<Saliency, Prediction>> pairs) {\n+        double acc = 0;\n+        double evals = 0;\n+        for (Pair<Saliency, Prediction> pair : pairs) {\n+            Saliency saliency = pair.getLeft();\n+            Prediction prediction = pair.getRight();\n+            for (Output output : prediction.getOutput().getOutputs()) {", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODU4ODExMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458588112", "bodyText": "theoretically this is possible, although not really plausible in reality, but nevertheless I think it's worth guarding against possible 0 by 0 division, thanks!", "author": "tteofili", "createdAt": "2020-07-22T07:24:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1NDUxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1NTA4Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455855087", "bodyText": "move constants to property so that it's clear what they are for?", "author": "r00ta", "createdAt": "2020-07-16T15:01:49Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LinearModel.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.stream.IntStream;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A linear model implementation based on perceptron algorithm.\n+ */\n+public class LinearModel {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LinearModel.class);\n+\n+    private final double[] weights;\n+    private final boolean classification;\n+    private double bias;\n+\n+    public LinearModel(int size, boolean classification) {\n+        this.bias = 0;\n+        this.weights = new double[size];\n+        this.classification = classification;\n+    }\n+\n+    public double fit(Collection<Pair<double[], Double>> trainingSet) {\n+        double[] sampleWeights = new double[trainingSet.size()];\n+        Arrays.fill(sampleWeights, 1);\n+        return fit(trainingSet, sampleWeights);\n+    }\n+\n+    public double fit(Collection<Pair<double[], Double>> trainingSet, double[] sampleWeights) {\n+        double floss = 1d;\n+        if (trainingSet.isEmpty()) {\n+            logger.warn(\"fitting an empty training set\");\n+        } else {\n+            double lr = 0.01;\n+            int e = 0;\n+            while (floss > 0.1 && e < 15) {", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1NzE5Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455857192", "bodyText": "Even if the seed is fixed and these tests are deterministic, it is impossible to understand what are the features really tested by these tests. wdyt?", "author": "r00ta", "createdAt": "2020-07-16T15:04:51Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,303 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.apache.commons.lang3.RandomStringUtils;\n+\n+import static org.junit.jupiter.api.Assertions.fail;\n+\n+public class TestUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    static {\n+        random.setSeed(4);\n+    }\n+\n+    public static BlackBoxModel getFeaturePassModel(int featureIndex) {\n+        return new BlackBoxModel() {\n+            @Override\n+            public List<PredictionOutput> predict(List<PredictionInput> inputs) {\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+                for (PredictionInput predictionInput : inputs) {\n+                    List<Feature> features = predictionInput.getFeatures();\n+                    Feature feature = features.get(featureIndex);\n+                    PredictionOutput predictionOutput = new PredictionOutput(\n+                            List.of(new Output(\"feature-\" + featureIndex, feature.getType(), feature.getValue(),\n+                                               1d)));\n+                    predictionOutputs.add(predictionOutput);\n+                }\n+                return predictionOutputs;\n+            }\n+\n+            @Override\n+            public DataDistribution getDataDistribution() {\n+                return DataUtils.generateRandomDataDistribution(featureIndex + 1);\n+            }\n+\n+            @Override\n+            public PredictionInput getInputShape() {\n+                List<Feature> features = new LinkedList<>();\n+                features.add(FeatureFactory.newNumericalFeature(\"f1\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f2\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f3\", Double.NaN));\n+                return new PredictionInput(features);\n+            }\n+\n+            @Override\n+            public PredictionOutput getOutputShape() {\n+                return new PredictionOutput(List.of(new Output(\"feature-\" + featureIndex, Type.NUMBER, new Value<>(Double.NaN), 1d)));\n+            }\n+        };\n+    }\n+\n+    public static BlackBoxModel getSumSkipModel(int skipFeatureIndex) {\n+        return new BlackBoxModel() {\n+            @Override\n+            public List<PredictionOutput> predict(List<PredictionInput> inputs) {\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+                for (PredictionInput predictionInput : inputs) {\n+                    List<Feature> features = predictionInput.getFeatures();\n+                    double result = 0;\n+                    for (int i = 0; i < features.size(); i++) {\n+                        if (skipFeatureIndex != i) {\n+                            result += features.get(i).getValue().asNumber();\n+                        }\n+                    }\n+                    PredictionOutput predictionOutput = new PredictionOutput(\n+                            List.of(new Output(\"sum-but\" + skipFeatureIndex, Type.NUMBER, new Value<>(result), 1d)));\n+                    predictionOutputs.add(predictionOutput);\n+                }\n+                return predictionOutputs;\n+            }\n+\n+            @Override\n+            public DataDistribution getDataDistribution() {\n+                return DataUtils.generateRandomDataDistribution(skipFeatureIndex + 1);\n+            }\n+\n+            @Override\n+            public PredictionInput getInputShape() {\n+                List<Feature> features = new LinkedList<>();\n+                features.add(FeatureFactory.newNumericalFeature(\"f1\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f2\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f3\", Double.NaN));\n+                return new PredictionInput(features);\n+            }\n+\n+            @Override\n+            public PredictionOutput getOutputShape() {\n+                return new PredictionOutput(List.of(new Output(\"o\", Type.NUMBER, new Value<>(Double.NaN), 1d)));\n+            }\n+        };\n+    }\n+\n+    public static BlackBoxModel getEvenFeatureModel(int featureIndex) {\n+        return new BlackBoxModel() {\n+            @Override\n+            public List<PredictionOutput> predict(List<PredictionInput> inputs) {\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+                for (PredictionInput predictionInput : inputs) {\n+                    List<Feature> features = predictionInput.getFeatures();\n+                    Feature feature = features.get(featureIndex);\n+                    double v = feature.getValue().asNumber();\n+                    PredictionOutput predictionOutput = new PredictionOutput(\n+                            List.of(new Output(\"feature-\" + featureIndex, Type.BOOLEAN, new Value<>(v % 2 == 0), 1d)));\n+                    predictionOutputs.add(predictionOutput);\n+                }\n+                return predictionOutputs;\n+            }\n+\n+            @Override\n+            public DataDistribution getDataDistribution() {\n+                return DataUtils.generateRandomDataDistribution(featureIndex + 1);\n+            }\n+\n+            @Override\n+            public PredictionInput getInputShape() {\n+                List<Feature> features = new LinkedList<>();\n+                features.add(FeatureFactory.newNumericalFeature(\"f1\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f2\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f3\", Double.NaN));\n+                return new PredictionInput(features);\n+            }\n+\n+            @Override\n+            public PredictionOutput getOutputShape() {\n+                return new PredictionOutput(List.of(new Output(\"o\", Type.NUMBER, new Value<>(Double.NaN), 1d)));\n+            }\n+        };\n+    }\n+\n+    public static BlackBoxModel getEvenSumModel(int skipFeatureIndex) {\n+        return new BlackBoxModel() {\n+            @Override\n+            public List<PredictionOutput> predict(List<PredictionInput> inputs) {\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+                for (PredictionInput predictionInput : inputs) {\n+                    List<Feature> features = predictionInput.getFeatures();\n+                    double result = 0;\n+                    for (int i = 0; i < features.size(); i++) {\n+                        if (skipFeatureIndex != i) {\n+                            result += features.get(i).getValue().asNumber();\n+                        }\n+                    }\n+                    PredictionOutput predictionOutput = new PredictionOutput(\n+                            List.of(new Output(\"sum-even-but\" + skipFeatureIndex, Type.BOOLEAN, new Value<>(((int) result) % 2 == 0), 1d)));\n+                    predictionOutputs.add(predictionOutput);\n+                }\n+                return predictionOutputs;\n+            }\n+\n+            @Override\n+            public DataDistribution getDataDistribution() {\n+                return DataUtils.generateRandomDataDistribution(skipFeatureIndex + 1);\n+            }\n+\n+            @Override\n+            public PredictionInput getInputShape() {\n+                List<Feature> features = new LinkedList<>();\n+                features.add(FeatureFactory.newNumericalFeature(\"f1\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f2\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f3\", Double.NaN));\n+                return new PredictionInput(features);\n+            }\n+\n+            @Override\n+            public PredictionOutput getOutputShape() {\n+                return new PredictionOutput(List.of(new Output(\"o\", Type.NUMBER, new Value<>(Double.NaN), 1d)));\n+            }\n+        };\n+    }\n+\n+    public static BlackBoxModel getDummyTextClassifier() {\n+        return new BlackBoxModel() {\n+            private final List<String> blackList = Arrays.asList(\"money\", \"$\", \"\u00a3\", \"bitcoin\");\n+            @Override\n+            public List<PredictionOutput> predict(List<PredictionInput> inputs) {\n+                List<PredictionOutput> outputs = new LinkedList<>();\n+                for (PredictionInput input : inputs) {\n+                    boolean spam = false;\n+                    for (Feature f : input.getFeatures()) {\n+                        if (!spam && Type.TEXT.equals(f.getType())) {\n+                            String s = f.getValue().asString();\n+                            String[] words = s.split(\" \");\n+                            for (String w : words) {\n+                                if (blackList.contains(w)) {\n+                                    spam = true;\n+                                    break;\n+                                }\n+                            }\n+                        }\n+                    }\n+                    Output output = new Output(\"spam-classification\", Type.BOOLEAN, new Value<>(spam), 1d);\n+                    outputs.add(new PredictionOutput(List.of(output)));\n+                }\n+                return outputs;\n+            }\n+\n+            @Override\n+            public DataDistribution getDataDistribution() {\n+                return DataUtils.generateRandomDataDistribution(3);\n+            }\n+\n+            @Override\n+            public PredictionInput getInputShape() {\n+                List<Feature> features = new LinkedList<>();\n+                features.add(FeatureFactory.newNumericalFeature(\"f1\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f2\", Double.NaN));\n+                features.add(FeatureFactory.newNumericalFeature(\"f3\", Double.NaN));\n+                return new PredictionInput(features);\n+            }\n+\n+            @Override\n+            public PredictionOutput getOutputShape() {\n+                return new PredictionOutput(List.of(new Output(\"o\", Type.NUMBER, new Value<>(Double.NaN), 1d)));\n+            }\n+        };\n+    }\n+\n+    public static Feature getRandomFeature() {\n+        Feature f;\n+        int r = random.nextInt(12);", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1ODc1Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455858756", "bodyText": "why?", "author": "r00ta", "createdAt": "2020-07-16T15:06:53Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global.pdp;\n+\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.PrintWriter;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.DataSeries;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n+class PartialDependencePlotExplainerTest {\n+\n+    @Test\n+    void testPdpTextClassifier() throws Exception {\n+        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+        BlackBoxModel modelInfo = TestUtils.getDummyTextClassifier();\n+        Collection<DataSeries> pdps = partialDependencePlotProvider.explain(modelInfo);\n+        assertNotNull(pdps);\n+        for (DataSeries dataSeries : pdps) {\n+            writeAsciiGraph(dataSeries, new PrintWriter(new File(\"target/pdp\" + dataSeries.getFeature().getName() + \".txt\")));\n+        }", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg1OTQ5MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455859490", "bodyText": "Unit tests should be deterministic by definition, I would avoid using random", "author": "r00ta", "createdAt": "2020-07-16T15:07:49Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DatasetEncoderTest.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.security.SecureRandom;\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DatasetEncoderTest {\n+\n+    private final static SecureRandom random = new SecureRandom();", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2MTc3OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455861778", "bodyText": "I would avoid using random in every tests (and all the other classes) even if the seed is set, wdyt?", "author": "r00ta", "createdAt": "2020-07-16T15:10:50Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.mockito.Mockito.mock;\n+\n+class LimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testEmptyPrediction() throws Exception {\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        PredictionOutput output = mock(PredictionOutput.class);\n+        PredictionInput input = mock(PredictionInput.class);\n+        Prediction prediction = new Prediction(input, output);\n+        BlackBoxModel model = mock(BlackBoxModel.class);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+        assertNotNull(saliency);\n+    }\n+\n+    @Test\n+    void testNonEmptyInput() throws Exception {\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        PredictionOutput output = mock(PredictionOutput.class);\n+        List<Feature> features = new LinkedList<>();\n+        for (int i = 0; i < 4; i++) {\n+            features.add(TestUtils.getRandomFeature());", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2MzQ2Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455863467", "bodyText": "Can you refactor the entire class so to remove duplicated code? For example moving String name to a property in the class and using a reusable method to do the assertions", "author": "r00ta", "createdAt": "2020-07-16T15:13:09Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/FeatureFactoryTest.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.Locale;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n+class FeatureFactoryTest {\n+\n+    @Test\n+    void testTimeFeature() {\n+        String name = \"some-name\";\n+        LocalTime time = LocalTime.now();\n+        Feature feature = FeatureFactory.newTimeFeature(name, time);\n+        assertNotNull(feature);\n+        assertNotNull(feature.getName());\n+        assertNotNull(feature.getType());\n+        assertEquals(Type.TIME, feature.getType());\n+        assertNotNull(feature.getValue());\n+        assertEquals(time, feature.getValue().getUnderlyingObject());\n+    }\n+\n+    @Test\n+    void testCategoricalFeature() {\n+        String name = \"some-name\";\n+        String category = \"FIXED-CAT\";\n+        Feature feature = FeatureFactory.newCategoricalFeature(name, category);\n+        assertNotNull(feature);\n+        assertNotNull(feature.getName());\n+        assertNotNull(feature.getType());\n+        assertEquals(Type.CATEGORICAL, feature.getType());\n+        assertNotNull(feature.getValue());\n+        assertEquals(category, feature.getValue().getUnderlyingObject());\n+    }\n+\n+    @Test\n+    void testNumberFeature() {\n+        String name = \"some-name\";\n+        Number number = 0.1d;\n+        Feature feature = FeatureFactory.newNumericalFeature(name, number);\n+        assertNotNull(feature);\n+        assertNotNull(feature.getName());\n+        assertNotNull(feature.getType());\n+        assertEquals(Type.NUMBER, feature.getType());\n+        assertNotNull(feature.getValue());\n+        assertEquals(number, feature.getValue().getUnderlyingObject());", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMyNDE3Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456324177", "bodyText": "sure, makes sense.", "author": "tteofili", "createdAt": "2020-07-17T09:18:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2MzQ2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2MzYyNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455863625", "bodyText": "random unit test", "author": "r00ta", "createdAt": "2020-07-16T15:13:22Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/DataUtilsTest.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.security.SecureRandom;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+class DataUtilsTest {\n+\n+    private final static SecureRandom random = new SecureRandom();", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMzOTM4Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456339387", "bodyText": "good point, I'll remove the randomized parts.", "author": "tteofili", "createdAt": "2020-07-17T09:47:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2MzYyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2Mzc0OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455863748", "bodyText": "random unit test", "author": "r00ta", "createdAt": "2020-07-16T15:13:31Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/ExplainabilityMetricsTest.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.security.SecureRandom;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.*;\n+\n+class ExplainabilityMetricsTest {\n+\n+    private static final SecureRandom random = new SecureRandom();", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMzOTQzOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456339439", "bodyText": "good point, I'll remove the randomized parts.", "author": "tteofili", "createdAt": "2020-07-17T09:47:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2Mzc0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2MzgyMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455863822", "bodyText": "random unit test", "author": "r00ta", "createdAt": "2020-07-16T15:13:38Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/LinearModelTest.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.security.SecureRandom;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.LinkedList;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class LinearModelTest {\n+\n+    private final static SecureRandom random = new SecureRandom();", "originalCommit": "abbfbac86aaf495013f28d4943e8a8118f2f181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjMzOTg1NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456339854", "bodyText": "randomization here is needed for a more functional test rather than unit test.\nI'll move that stuff in a different (integration) test.", "author": "tteofili", "createdAt": "2020-07-17T09:48:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg2MzgyMg=="}], "type": "inlineReview"}, {"oid": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "url": "https://github.com/kiegroup/kogito-apps/commit/f9b30620f5caf4cceb159693741ebe9903ffe80f", "message": "KOGITO-2750 - fixed SonarCloud reported bugs", "committedDate": "2020-07-16T15:21:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTU1NjQwMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455556403", "bodyText": "Side note, in general it is better to use runtime exception because checked exceptions don't fit well with lambda/stream. I will let you decide what you prefer, it is just a comment :)", "author": "danielezonca", "createdAt": "2020-07-16T07:08:31Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/LocalExplanationException.java", "diffHunk": "@@ -0,0 +1,12 @@\n+package org.kie.kogito.explainability.local;\n+\n+/**\n+ * Exception representing errors happened during the process of generating a local explanation.\n+ */\n+public class LocalExplanationException extends Exception {", "originalCommit": "ba21264f71a85203adaab370cdc4528be4fd67f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ2MTc3MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456461770", "bodyText": "ok", "author": "tteofili", "createdAt": "2020-07-17T14:01:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTU1NjQwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTU1NzExNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455557115", "bodyText": "Is there any reason why this class is not public (same question for the constructor and methods)?", "author": "danielezonca", "createdAt": "2020-07-16T07:09:57Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {", "originalCommit": "ba21264f71a85203adaab370cdc4528be4fd67f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM0MDc4Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456340787", "bodyText": "it is expected to be used by LimeExplainer rather than users, hence the package local constructor and methods, similar to SampleWeighter.", "author": "tteofili", "createdAt": "2020-07-17T09:50:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTU1NzExNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTU2NzI1OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455567259", "bodyText": "Please consider to use assertj to replace this and other assertTrue based on simple expressions.\nYou can express condition logic directly in the assertion to obtain better error reporting\nassertThat(v).isPositive();\nassertThat(v).isGreaterThanOrEqualTo(0);", "author": "danielezonca", "createdAt": "2020-07-16T07:29:39Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.RepeatedTest;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    public static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @RepeatedTest(10)\n+    void testMapOneFeatureToOutputRegression() throws Exception {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        BlackBoxModel model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertTrue(v > 0);", "originalCommit": "ba21264f71a85203adaab370cdc4528be4fd67f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM0MTA0NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456341044", "bodyText": "thanks for the suggestion, I'll do that.", "author": "tteofili", "createdAt": "2020-07-17T09:50:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTU2NzI1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkxMTg2Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r455911862", "bodyText": "Side note, in general it is better to use runtime exception because checked exceptions don't fit well with lambda/stream. I will let you decide what you prefer, it is just a comment :)", "author": "danielezonca", "createdAt": "2020-07-16T16:22:05Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/GlobalExplanationException.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global;\n+\n+/**\n+ * Exception representing errors happened during the process of generating a global explanation.\n+ */\n+public class GlobalExplanationException extends Exception {", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ2MjAzNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456462037", "bodyText": "ok", "author": "tteofili", "createdAt": "2020-07-17T14:02:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTkxMTg2Mg=="}], "type": "inlineReview"}, {"oid": "084e416d024995b4a678b5643ad57c863bbf87bc", "url": "https://github.com/kiegroup/kogito-apps/commit/084e416d024995b4a678b5643ad57c863bbf87bc", "message": "KOGITO-2750 - dropped unneeded explicit version in commons-lang3", "committedDate": "2020-07-17T08:22:53Z", "type": "commit"}, {"oid": "510e4e81a92cd39095336b2680dc425b1fca351e", "url": "https://github.com/kiegroup/kogito-apps/commit/510e4e81a92cd39095336b2680dc425b1fca351e", "message": "KOGITO-2750 - fixed javadoc style, start with uc letter and end with a dot", "committedDate": "2020-07-17T08:29:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2NDIyNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456364226", "bodyText": "Please describe T.", "author": "jiripetrlik", "createdAt": "2020-07-17T10:39:18Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/GlobalExplainer.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global;\n+\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+\n+/**\n+ * A global explainability method\n+ * @param <T>", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2NTI1NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456365255", "bodyText": "Is it good to hard code series length? Is there any reason to not make this configurable?", "author": "jiripetrlik", "createdAt": "2020-07-17T10:41:50Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global.pdp;\n+\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.global.GlobalExplainer;\n+import org.kie.kogito.explainability.global.GlobalExplanationException;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.DataSeries;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Generates the partial dependence plot for a given feature.\n+ * While a strict PD implementation would need the whole training set used to train the model, this implementation seeks\n+ * to reproduce an approximate version of the training data by means of data distribution information (min, max, mean,\n+ * stdDev).\n+ */\n+public class PartialDependencePlotExplainer implements GlobalExplainer<Collection<DataSeries>> {\n+\n+    private static final int SERIES_LENGTH = 100;", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ3MjIxOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456472218", "bodyText": "sure, I think it is ok to make it configurable.", "author": "tteofili", "createdAt": "2020-07-17T14:19:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2NTI1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2NTk4Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456365987", "bodyText": "Please also make methods of this class public.", "author": "jiripetrlik", "createdAt": "2020-07-17T10:43:32Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * get the input and output predictions transformed into a numerical training set\n+     *\n+     * @return a numerical training set\n+     */\n+    List<Pair<double[], Double>> getEncodedTrainingSet() {", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ4NTc2MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456485760", "bodyText": "DatasetEncoder is expected to be used by LimeExplainer only, hence the package level visibility of both class and methods.\nSame as per class and constructor I think it's better not to make stuff public unless needed by consumers, as reducing the surface API is usually more expensive.", "author": "tteofili", "createdAt": "2020-07-17T14:41:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2NTk4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2NjQ0OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456366448", "bodyText": "Shouldn't we throw exception or log something here?", "author": "jiripetrlik", "createdAt": "2020-07-17T10:44:38Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * get the input and output predictions transformed into a numerical training set\n+     *\n+     * @return a numerical training set\n+     */\n+    List<Pair<double[], Double>> getEncodedTrainingSet() {\n+        List<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        List<List<Double>> columnData;\n+        List<PredictionInput> flatInputs = DataUtils.linearizeInputs(perturbedInputs);\n+        if (!flatInputs.isEmpty() && !predictedOutputs.isEmpty() && !targetInput.getFeatures().isEmpty() && originalOutput != null) {\n+            columnData = getColumnData(flatInputs);\n+\n+            int pi = 0;\n+            for (Output output : predictedOutputs) {\n+                double[] x = new double[columnData.size()];\n+                int i = 0;\n+                for (List<Double> column : columnData) {\n+                    x[i] = column.get(pi);\n+                    i++;\n+                }\n+                double y;\n+                if (Type.NUMBER.equals(originalOutput.getType()) || Type.BOOLEAN.equals(originalOutput.getType())) {\n+                    y = output.getValue().asNumber();\n+                } else {\n+                    Object originalObject = originalOutput.getValue().getUnderlyingObject();\n+                    Object outputObject = output.getValue().getUnderlyingObject();\n+                    if (originalObject == null || outputObject == null) {\n+                        y = originalObject == outputObject ? 1d : 0d;\n+                    } else {\n+                        y = originalObject.equals(outputObject) ? 1d : 0d;\n+                    }\n+                }\n+                Pair<double[], Double> sample = new ImmutablePair<>(x, y);\n+                trainingSet.add(sample);\n+\n+                pi++;\n+            }\n+        }\n+        return trainingSet;\n+    }\n+\n+    private List<List<Double>> getColumnData(List<PredictionInput> perturbedInputs) {\n+        List<Type> featureTypes = targetInput.getFeatures().stream().map(Feature::getType).collect(Collectors.toList());\n+        List<List<Double>> columnData = new LinkedList<>();\n+\n+        for (int t = 0; t < featureTypes.size(); t++) {\n+            Feature originalFeature = targetInput.getFeatures().get(t);\n+            switch (featureTypes.get(t)) {\n+                case NUMBER:\n+                    encodeNumbers(perturbedInputs, targetInput, columnData, t);\n+                    break;\n+                case TEXT:\n+                    encodeText(perturbedInputs, columnData, t, originalFeature);\n+                    break;\n+                case CATEGORICAL:\n+                case BINARY:\n+                case TIME:\n+                case URI:\n+                case DURATION:\n+                case VECTOR:\n+                case CURRENCY:\n+                    encodeEquals(perturbedInputs, columnData, t, originalFeature);\n+                    break;\n+                case BOOLEAN:\n+                    // boolean are automatically encoded as 1s or 0s\n+                    List<Double> featureValues = new LinkedList<>();\n+                    for (PredictionInput pi : perturbedInputs) {\n+                        featureValues.add(pi.getFeatures().get(t).getValue().asNumber());\n+                    }\n+                    columnData.add(featureValues);\n+                    break;\n+                case UNDEFINED:\n+                    break;", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODMwMjYzNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458302636", "bodyText": "@tteofili have a look at this please", "author": "r00ta", "createdAt": "2020-07-21T18:26:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2NjQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODU5NzMwMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458597302", "bodyText": "after having thought about this I think UNDEFINED should be handled the same way as non text, non numeric features, hence moving it so that it's handled by encodeEquals method.", "author": "tteofili", "createdAt": "2020-07-22T07:41:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2NjQ0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2Njg3Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456366876", "bodyText": "Please split the line to make this comment more readable.", "author": "jiripetrlik", "createdAt": "2020-07-17T10:45:36Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) optimised for tabular data and decision models.\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODMwMjY2NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458302664", "bodyText": "@tteofili have a look at this please", "author": "r00ta", "createdAt": "2020-07-21T18:26:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2Njg3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2OTI1NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456369254", "bodyText": "Please remove.", "author": "jiripetrlik", "createdAt": "2020-07-17T10:51:18Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global.pdp;\n+\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.PrintWriter;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.DataSeries;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n+class PartialDependencePlotExplainerTest {\n+\n+    @Test\n+    void testPdpTextClassifier() throws Exception {\n+        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+        BlackBoxModel modelInfo = TestUtils.getDummyTextClassifier();\n+        Collection<DataSeries> pdps = partialDependencePlotProvider.explain(modelInfo);\n+        assertNotNull(pdps);\n+        for (DataSeries dataSeries : pdps) {\n+            writeAsciiGraph(dataSeries, new PrintWriter(new File(\"target/pdp\" + dataSeries.getFeature().getName() + \".txt\")));\n+        }\n+    }\n+\n+    private void writeAsciiGraph(DataSeries dataSeries, PrintWriter out) {\n+        double[] outputs = dataSeries.getY();\n+        double max = DoubleStream.of(outputs).max().getAsDouble();\n+        double min = DoubleStream.of(outputs).min().getAsDouble();\n+        outputs = Arrays.stream(outputs).map(d -> d * max / min).toArray();\n+        double curMax = 1 + DoubleStream.of(outputs).max().getAsDouble();\n+        ;", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2OTc0Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456369747", "bodyText": "Please use public for test methods.", "author": "jiripetrlik", "createdAt": "2020-07-17T10:52:36Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DatasetEncoderTest.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.security.SecureRandom;\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DatasetEncoderTest {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    @Test\n+    void testEmptyDatasetEncoding() {", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ3MDQ3Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456470476", "bodyText": "this is no longer required since junit5 onwards.", "author": "tteofili", "createdAt": "2020-07-17T14:16:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM2OTc0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM3MDE0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456370146", "bodyText": "Please remove newlines.", "author": "jiripetrlik", "createdAt": "2020-07-17T10:53:36Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputRegression() throws Exception {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        BlackBoxModel model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertTrue(v > 0);\n+    }\n+\n+    @Test\n+    void testUnusedFeatureRegression() throws Exception {\n+        int idx = 2;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 10));\n+        BlackBoxModel model = TestUtils.getSumSkipModel(idx);\n+        PredictionInput input = new PredictionInput(features);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> perFeatureImportance = saliency.getPerFeatureImportance();\n+\n+        perFeatureImportance.sort((t1, t2) -> (int) (t2.getScore() - t1.getScore()));\n+        assertTrue(perFeatureImportance.get(0).getScore() > 0);\n+        assertTrue(perFeatureImportance.get(1).getScore() > 0);\n+        assertEquals(features.get(idx).getName(), perFeatureImportance.get(2).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertTrue(v > 0);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputClassification() throws Exception {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 3));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 2));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 7));\n+        PredictionInput input = new PredictionInput(features);\n+        BlackBoxModel model = TestUtils.getEvenFeatureModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getPositiveFeatures(1);\n+        assertFalse(topFeatures.isEmpty());\n+        assertEquals(features.get(idx).getName(), topFeatures.get(0).getFeature().getName());\n+    }\n+\n+    @Test\n+    void testTextSpamClassification() throws Exception {\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newTextFeature(\"f1\",\"we go here and there\"));\n+        features.add(FeatureFactory.newTextFeature(\"f2\", \"please give me some money\"));\n+        features.add(FeatureFactory.newTextFeature(\"f3\", \"dear friend, please reply\"));\n+        PredictionInput input = new PredictionInput(features);\n+        BlackBoxModel model = TestUtils.getDummyTextClassifier();\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getPositiveFeatures(1);\n+        assertEquals(\"money (f2)\", topFeatures.get(0).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertTrue(v > 0);\n+    }\n+\n+    @Test\n+    void testUnusedFeatureClassification() throws Exception {\n+        int idx = 2;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\",6));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\",3));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\",5));\n+        BlackBoxModel model = TestUtils.getEvenSumModel(idx);\n+        PredictionInput input = new PredictionInput(features);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> perFeatureImportance = saliency.getNegativeFeatures(3);\n+        assertFalse(perFeatureImportance.stream().map(fi -> fi.getFeature().getName()).collect(Collectors.toList()).contains(features.get(idx).getName()));\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getNegativeFeatures(2));\n+        assertTrue(v >= 0);\n+    }\n+\n+", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM3Mjg3NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456372875", "bodyText": "As many of tests in this lib are stochastic and results depend on random numbers generator I would suggest to create some logic which allows us to run these tests also with different seed. I mean to have fixed default value, but also possibility to change seed using some env. variable etc. This will allow us to test this lib more robust. I can for example do few runs with with different seed to see whether these methods are really robust or the results are within some tollerance. What do you think?", "author": "jiripetrlik", "createdAt": "2020-07-17T10:59:47Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.BlackBoxModel;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.mockito.Mockito.mock;\n+\n+class LimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);", "originalCommit": "f9b30620f5caf4cceb159693741ebe9903ffe80f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQwODYyOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r456408628", "bodyText": "I have a quite strong opinion on using random in unit tests. If internally the library is using random, then I agree with @jiripetrlik that it's good to use different and fixed seeds during the initialization of the tests (and use a test factory to make it more clean from a code perspective). But I really think we should not generate random data upfront for our tests (for example in this class with features.add(TestUtils.getRandomFeature());), even if the seed is fixed because it's really impossible to understand what are the scenarios that are covered by the tests and the tests are not repeatable.", "author": "r00ta", "createdAt": "2020-07-17T12:25:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM3Mjg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODAzNDQzMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458034432", "bodyText": "@r00ta Yes, completely agree with you. It is not good to have completely random unit tests. My suggestion was about possibility to simply change the seed for tests and try it also with different  seed if needed.", "author": "jiripetrlik", "createdAt": "2020-07-21T11:45:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM3Mjg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2ODExNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458168117", "bodyText": "I have dropped the randomization in all tests.\nThere's some randomness in the way LIME picks the feature to perturb, that has to be made fixed in tests via setting a random seed.\nAlso in general I agree with you, just note the randomization in tests that work on numeric and text data is sometimes useful in order to capture edge cases (btw that's what Apache Lucene does for example, see [1,2]) and strange combinations (e.g. wrt certain text encoding/locale scenarios) especially while developing a library (you have less control on what the user inputs to it).\n[1] : https://labs.carrotsearch.com/randomizedtesting.html\n[2] : https://www.youtube.com/watch?v=zD57QKzqdCw", "author": "tteofili", "createdAt": "2020-07-21T15:03:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM3Mjg3NQ=="}], "type": "inlineReview"}, {"oid": "4fc03590e3fdb2fac9daf028580b13da88b47cb2", "url": "https://github.com/kiegroup/kogito-apps/commit/4fc03590e3fdb2fac9daf028580b13da88b47cb2", "message": "KOGITO-2750 - moved BBM to PredictionProvider, factored out DataDistribution stuff into PPMetadata, made some randomized tests deterministic", "committedDate": "2020-07-17T14:00:41Z", "type": "commit"}, {"oid": "b8c5605060f15166609e7cb15d42c845b9d2edcb", "url": "https://github.com/kiegroup/kogito-apps/commit/b8c5605060f15166609e7cb15d42c845b9d2edcb", "message": "KOGITO-2750 - fixed DMN dependency for ITs", "committedDate": "2020-07-17T14:03:15Z", "type": "commit"}, {"oid": "ccd7712661f4cfab246dc6d02b57f49ae64d8a53", "url": "https://github.com/kiegroup/kogito-apps/commit/ccd7712661f4cfab246dc6d02b57f49ae64d8a53", "message": "KOGITO-2750 - dropped local kie-pmml property", "committedDate": "2020-07-17T14:06:54Z", "type": "commit"}, {"oid": "46ecc253c3dd335267d39e2f42f27f88f05d9e19", "url": "https://github.com/kiegroup/kogito-apps/commit/46ecc253c3dd335267d39e2f42f27f88f05d9e19", "message": "KOGITO-2750 - added TODO in pmml-its to move to kogito-pmml dependencies asap", "committedDate": "2020-07-17T14:09:05Z", "type": "commit"}, {"oid": "c2d9c9c0f23d1aafbc13cb5baa16632f19565ab9", "url": "https://github.com/kiegroup/kogito-apps/commit/c2d9c9c0f23d1aafbc13cb5baa16632f19565ab9", "message": "KOGITO-2750 - moved local/gloabl exceptions to non checked", "committedDate": "2020-07-17T14:14:05Z", "type": "commit"}, {"oid": "12443d0632bfc3965022a80535aba031846c825b", "url": "https://github.com/kiegroup/kogito-apps/commit/12443d0632bfc3965022a80535aba031846c825b", "message": "KOGITO-2750 - made PDP series length configurable", "committedDate": "2020-07-17T14:23:51Z", "type": "commit"}, {"oid": "dd93be9e644e7dfc9a4bda113dec81066abb5964", "url": "https://github.com/kiegroup/kogito-apps/commit/dd93be9e644e7dfc9a4bda113dec81066abb5964", "message": "KOGITO-2750 - dropped unneeded resteasy dependencies in expl-core", "committedDate": "2020-07-17T14:28:48Z", "type": "commit"}, {"oid": "a65c09909c64ca9acee6d894943f7c4529b354ec", "url": "https://github.com/kiegroup/kogito-apps/commit/a65c09909c64ca9acee6d894943f7c4529b354ec", "message": "KOGITO-2750 - fixed bug reported by SonarCloud", "committedDate": "2020-07-17T15:33:21Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI1Nzg4NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r457257884", "bodyText": "If trainingSet.isEmpty() is true this function is going to return 1. Is this the correct behaviour (even if atm the return value is never used)?", "author": "r00ta", "createdAt": "2020-07-20T10:24:36Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LinearModel.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.stream.IntStream;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A linear model implementation based on perceptron algorithm.\n+ */\n+public class LinearModel {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LinearModel.class);\n+\n+    private final double[] weights;\n+    private final boolean classification;\n+    private double bias;\n+\n+    public LinearModel(int size, boolean classification) {\n+        this.bias = 0;\n+        this.weights = new double[size];\n+        this.classification = classification;\n+    }\n+\n+    public double fit(Collection<Pair<double[], Double>> trainingSet) {\n+        double[] sampleWeights = new double[trainingSet.size()];\n+        Arrays.fill(sampleWeights, 1);\n+        return fit(trainingSet, sampleWeights);\n+    }\n+\n+    public double fit(Collection<Pair<double[], Double>> trainingSet, double[] sampleWeights) {\n+        double floss = 1d;\n+        if (trainingSet.isEmpty()) {\n+            logger.warn(\"fitting an empty training set\");\n+        } else {", "originalCommit": "a65c09909c64ca9acee6d894943f7c4529b354ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE0Mzc4Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458143783", "bodyText": "the initial value should be NaN instead of 1, other than that the return value is used in tests to make sure it converges.\nI'll make sure to use it also inside LimeExplainer as a sanity check that the linear model is a good fit.", "author": "tteofili", "createdAt": "2020-07-21T14:32:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI1Nzg4NA=="}], "type": "inlineReview"}, {"oid": "b7dbb7a784881ed79a0572559a8531899b7601bb", "url": "https://github.com/kiegroup/kogito-apps/commit/b7dbb7a784881ed79a0572559a8531899b7601bb", "message": "KOGITO-2750 - improved test coverage per DU", "committedDate": "2020-07-21T14:15:42Z", "type": "commit"}, {"oid": "60b89530758efdbf5f77ce50e4aa0da1763f7456", "url": "https://github.com/kiegroup/kogito-apps/commit/60b89530758efdbf5f77ce50e4aa0da1763f7456", "message": "KOGITO-2750 - removed some randomization in tests", "committedDate": "2020-07-21T14:43:27Z", "type": "commit"}, {"oid": "8e94256c23a5ea80926ce3679c96acfe7d6606b5", "url": "https://github.com/kiegroup/kogito-apps/commit/8e94256c23a5ea80926ce3679c96acfe7d6606b5", "message": "KOGITO-2750 - removed some randomization in tests", "committedDate": "2020-07-21T14:45:27Z", "type": "commit"}, {"oid": "06059952b6466fcf8e98e906ddec18c38542a792", "url": "https://github.com/kiegroup/kogito-apps/commit/06059952b6466fcf8e98e906ddec18c38542a792", "message": "KOGITO-2750 - removed some randomization in tests", "committedDate": "2020-07-21T14:52:42Z", "type": "commit"}, {"oid": "99afa482e89ef18463501fc6109b664c440fc50f", "url": "https://github.com/kiegroup/kogito-apps/commit/99afa482e89ef18463501fc6109b664c440fc50f", "message": "KOGITO-2750 - removed some randomization in tests", "committedDate": "2020-07-21T14:56:51Z", "type": "commit"}, {"oid": "0ef1dca0d13f3284ade1f7e41135d7cec9dbd3c7", "url": "https://github.com/kiegroup/kogito-apps/commit/0ef1dca0d13f3284ade1f7e41135d7cec9dbd3c7", "message": "KOGITO-2750 - fix seed where needed, use assertJ for better numerical comparisons", "committedDate": "2020-07-21T15:06:38Z", "type": "commit"}, {"oid": "96de93f98a3f2eddc848cf91b83c119f98dd3a81", "url": "https://github.com/kiegroup/kogito-apps/commit/96de93f98a3f2eddc848cf91b83c119f98dd3a81", "message": "KOGITO-2750 - fixed some wront parent poms", "committedDate": "2020-07-22T07:21:28Z", "type": "commit"}, {"oid": "fae503a2d0d14e8329538e58b2b1c9d1e6149aa6", "url": "https://github.com/kiegroup/kogito-apps/commit/fae503a2d0d14e8329538e58b2b1c9d1e6149aa6", "message": "KOGITO-2750 - avoid 0/0 division in EM#classificationFidelity", "committedDate": "2020-07-22T07:27:35Z", "type": "commit"}, {"oid": "2bd93abb449b44b5241f97fb0617224610df00ce", "url": "https://github.com/kiegroup/kogito-apps/commit/2bd93abb449b44b5241f97fb0617224610df00ce", "message": "KOGITO-2750 - moved some params to constants in LM", "committedDate": "2020-07-22T07:30:39Z", "type": "commit"}, {"oid": "8a6dbc6ef50cae4aca46569a2dac9d5284aea477", "url": "https://github.com/kiegroup/kogito-apps/commit/8a6dbc6ef50cae4aca46569a2dac9d5284aea477", "message": "KOGITO-2750 - dropped TU#getRandomFeature", "committedDate": "2020-07-22T07:32:11Z", "type": "commit"}, {"oid": "4b2c2a9559ce08ae5b7d3c0542296805de36a896", "url": "https://github.com/kiegroup/kogito-apps/commit/4b2c2a9559ce08ae5b7d3c0542296805de36a896", "message": "KOGITO-2750 - use encodeEquals for undefined features in DE", "committedDate": "2020-07-22T07:40:56Z", "type": "commit"}, {"oid": "1a33dfbbc0edf5b6584a42f6eefb5f75fbbb6fb2", "url": "https://github.com/kiegroup/kogito-apps/commit/1a33dfbbc0edf5b6584a42f6eefb5f75fbbb6fb2", "message": "KOGITO-2750 - minor fix to LE javadoc", "committedDate": "2020-07-22T07:44:12Z", "type": "commit"}, {"oid": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "url": "https://github.com/kiegroup/kogito-apps/commit/a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "message": "KOGITO-2750 - minor fixes", "committedDate": "2020-07-22T08:09:38Z", "type": "commit"}, {"oid": "88868b312f67fe6762462735aa1b95dcaf144c69", "url": "https://github.com/kiegroup/kogito-apps/commit/88868b312f67fe6762462735aa1b95dcaf144c69", "message": "KOGITO-2750 - added some comments to LE, for easier code reading", "committedDate": "2020-07-22T09:13:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY0NjI2MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458646261", "bodyText": "What about a refactoring like\n    private List<List<Double>> getColumnData(List<PredictionInput> perturbedInputs) {\n        List<List<Double>> columnData = new LinkedList<>();\n\n        for (int t = 0; t < targetInput.getFeatures().size(); t++) {\n            Feature originalFeature = targetInput.getFeatures().get(t);\n            switch (originalFeature.getType()) {\n\nso that we avoid to open a stream and iterate on targetInput", "author": "r00ta", "createdAt": "2020-07-22T09:04:18Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * Get the input and output predictions transformed into a numerical training set.\n+     *\n+     * @return a numerical training set\n+     */\n+    List<Pair<double[], Double>> getEncodedTrainingSet() {\n+        List<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        List<List<Double>> columnData;\n+        List<PredictionInput> flatInputs = DataUtils.linearizeInputs(perturbedInputs);\n+        if (!flatInputs.isEmpty() && !predictedOutputs.isEmpty() && !targetInput.getFeatures().isEmpty() && originalOutput != null) {\n+            columnData = getColumnData(flatInputs);\n+\n+            int pi = 0;\n+            for (Output output : predictedOutputs) {\n+                double[] x = new double[columnData.size()];\n+                int i = 0;\n+                for (List<Double> column : columnData) {\n+                    x[i] = column.get(pi);\n+                    i++;\n+                }\n+                double y;\n+                if (Type.NUMBER.equals(originalOutput.getType()) || Type.BOOLEAN.equals(originalOutput.getType())) {\n+                    y = output.getValue().asNumber();\n+                } else {\n+                    Object originalObject = originalOutput.getValue().getUnderlyingObject();\n+                    Object outputObject = output.getValue().getUnderlyingObject();\n+                    if (originalObject == null || outputObject == null) {\n+                        y = originalObject == outputObject ? 1d : 0d;\n+                    } else {\n+                        y = originalObject.equals(outputObject) ? 1d : 0d;\n+                    }\n+                }\n+                Pair<double[], Double> sample = new ImmutablePair<>(x, y);\n+                trainingSet.add(sample);\n+\n+                pi++;\n+            }\n+        }\n+        return trainingSet;\n+    }\n+\n+    private List<List<Double>> getColumnData(List<PredictionInput> perturbedInputs) {\n+        List<Type> featureTypes = targetInput.getFeatures().stream().map(Feature::getType).collect(Collectors.toList());\n+        List<List<Double>> columnData = new LinkedList<>();\n+\n+        for (int t = 0; t < featureTypes.size(); t++) {\n+            Feature originalFeature = targetInput.getFeatures().get(t);\n+            switch (featureTypes.get(t)) {\n+                case NUMBER:", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgyNzQwMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458827400", "bodyText": "ok", "author": "tteofili", "createdAt": "2020-07-22T14:18:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY0NjI2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1MjIwMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458652201", "bodyText": "What's the gain of sorting and then using a binary search? this thing is going to be O(nlogn) instead of O(n) with a simple linear scan", "author": "r00ta", "createdAt": "2020-07-22T09:14:16Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * Get the input and output predictions transformed into a numerical training set.\n+     *\n+     * @return a numerical training set\n+     */\n+    List<Pair<double[], Double>> getEncodedTrainingSet() {\n+        List<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        List<List<Double>> columnData;\n+        List<PredictionInput> flatInputs = DataUtils.linearizeInputs(perturbedInputs);\n+        if (!flatInputs.isEmpty() && !predictedOutputs.isEmpty() && !targetInput.getFeatures().isEmpty() && originalOutput != null) {\n+            columnData = getColumnData(flatInputs);\n+\n+            int pi = 0;\n+            for (Output output : predictedOutputs) {\n+                double[] x = new double[columnData.size()];\n+                int i = 0;\n+                for (List<Double> column : columnData) {\n+                    x[i] = column.get(pi);\n+                    i++;\n+                }\n+                double y;\n+                if (Type.NUMBER.equals(originalOutput.getType()) || Type.BOOLEAN.equals(originalOutput.getType())) {\n+                    y = output.getValue().asNumber();\n+                } else {\n+                    Object originalObject = originalOutput.getValue().getUnderlyingObject();\n+                    Object outputObject = output.getValue().getUnderlyingObject();\n+                    if (originalObject == null || outputObject == null) {\n+                        y = originalObject == outputObject ? 1d : 0d;\n+                    } else {\n+                        y = originalObject.equals(outputObject) ? 1d : 0d;\n+                    }\n+                }\n+                Pair<double[], Double> sample = new ImmutablePair<>(x, y);\n+                trainingSet.add(sample);\n+\n+                pi++;\n+            }\n+        }\n+        return trainingSet;\n+    }\n+\n+    private List<List<Double>> getColumnData(List<PredictionInput> perturbedInputs) {\n+        List<Type> featureTypes = targetInput.getFeatures().stream().map(Feature::getType).collect(Collectors.toList());\n+        List<List<Double>> columnData = new LinkedList<>();\n+\n+        for (int t = 0; t < featureTypes.size(); t++) {\n+            Feature originalFeature = targetInput.getFeatures().get(t);\n+            switch (featureTypes.get(t)) {\n+                case NUMBER:\n+                    encodeNumbers(perturbedInputs, targetInput, columnData, t);\n+                    break;\n+                case TEXT:\n+                    encodeText(perturbedInputs, columnData, originalFeature);\n+                    break;\n+                case CATEGORICAL:\n+                case BINARY:\n+                case TIME:\n+                case URI:\n+                case DURATION:\n+                case VECTOR:\n+                case CURRENCY:\n+                case UNDEFINED:\n+                    encodeEquals(perturbedInputs, columnData, t, originalFeature);\n+                    break;\n+                case BOOLEAN:\n+                    // boolean are automatically encoded as 1s or 0s\n+                    List<Double> featureValues = new LinkedList<>();\n+                    for (PredictionInput pi : perturbedInputs) {\n+                        featureValues.add(pi.getFeatures().get(t).getValue().asNumber());\n+                    }\n+                    columnData.add(featureValues);\n+                    break;\n+            }\n+        }\n+        return columnData;\n+    }\n+\n+    private static void encodeNumbers(List<PredictionInput> predictionInputs, PredictionInput originalInputs, List<List<Double>> columnData, int t) {\n+        // find maximum and minimum values\n+        double[] doubles = new double[predictionInputs.size() + 1];\n+        int i = 0;\n+        for (PredictionInput pi : predictionInputs) {\n+            Feature feature = pi.getFeatures().get(t);\n+            doubles[i] = feature.getValue().asNumber();\n+            i++;\n+        }\n+        Feature feature = originalInputs.getFeatures().get(t);\n+        double originalValue = feature.getValue().asNumber();\n+        doubles[i] = originalValue;\n+        double min = DoubleStream.of(doubles).min().getAsDouble();\n+        double max = DoubleStream.of(doubles).max().getAsDouble();\n+        // feature scaling + kernel based clustering\n+        double threshold = DataUtils.gaussianKernel((originalValue - min) / (max - min));\n+        List<Double> featureValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min))\n+                .map(d -> Double.isNaN(d) ? 1 : d).boxed().map(DataUtils::gaussianKernel)\n+                .map(d -> (d - threshold < 1e-3) ? 1d : 0d).collect(Collectors.toList());\n+        columnData.add(featureValues);\n+    }\n+\n+    private static void encodeText(List<PredictionInput> predictionInputs, List<List<Double>> columnData, Feature originalFeature) {\n+        String originalString = originalFeature.getValue().asString();\n+        String[] words = originalString.split(\" \");\n+        for (String word : words) {\n+            List<Double> featureValues = new LinkedList<>();\n+            for (PredictionInput pi : predictionInputs) {\n+                Feature feature = pi.getFeatures().stream().filter(f -> f.getName().equals(originalFeature.getName())).findFirst().orElse(null);\n+                double featureValue;\n+                if (feature != null && feature.getName().equals(originalFeature.getName())) {\n+                    String perturbedString = feature.getValue().asString();\n+                    String[] perturbedWords = perturbedString.split(\" \");\n+                    Arrays.sort(perturbedWords);\n+                    featureValue = Arrays.binarySearch(perturbedWords, word) >= 0 ? 1d : 0d;", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5NzE5OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458797198", "bodyText": "agreed", "author": "tteofili", "createdAt": "2020-07-22T13:37:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1MjIwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NDYwMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458654603", "bodyText": "There might be models without inputs, get(0) without checks on the size is dangerous", "author": "r00ta", "createdAt": "2020-07-22T09:18:27Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        try {\n+            PredictionInput originalInput = prediction.getInput();\n+            List<Feature> inputFeatures = originalInput.getFeatures();\n+            PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgxMDk1MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458810951", "bodyText": "there shouldn't be predictions without inputs as well as there shouldn't be inputs without features, that wouldn't make much sense.\nAnyway I'll add some checks to avoid ugly exceptions in case of malformed inputs.", "author": "tteofili", "createdAt": "2020-07-22T13:55:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NDYwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NTY2Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458655667", "bodyText": "This method is pretty big, would it be possible to refactor it with some private methods so that it's clear what are the steps that the algorithm is making? If this does not make sense to you, ignore it.", "author": "r00ta", "createdAt": "2020-07-22T09:20:04Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI0MDAwMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459240000", "bodyText": "I have abstracted the dataset encoding and sample weighting responsibilities in different classes exactly because of that, let me see if I can refactor more portions of the method body in private methods or separate classes.", "author": "tteofili", "createdAt": "2020-07-23T06:34:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NTY2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NzUyNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458657526", "bodyText": "make this configurable?", "author": "r00ta", "createdAt": "2020-07-22T09:23:04Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        try {\n+            PredictionInput originalInput = prediction.getInput();\n+            List<Feature> inputFeatures = originalInput.getFeatures();\n+            PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);\n+            List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+            List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+            int noOfInputFeatures = inputFeatures.size();\n+            int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+            double[] weights = new double[noOfOutputFeatures];\n+\n+            for (int o = 0; o < actualOutputs.size(); o++) {\n+                boolean separableDataset = false;\n+\n+                List<PredictionInput> perturbedInputs = new LinkedList<>();\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+\n+                boolean classification = false;\n+                Output currentOutput = actualOutputs.get(o);\n+                if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                    Map<Double, Long> rawClassesBalance = new HashMap<>();\n+                    int tries = 3;", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgyOTk5Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458829993", "bodyText": "in general, why not, my only concern is trying not letting users shoot in their own feet by giving them too much flexibility in the configuration :) anyway I think a reasonable default would work, so yes.", "author": "tteofili", "createdAt": "2020-07-22T14:22:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1NzUyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY2MDc1NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458660754", "bodyText": "Why linkedlist?", "author": "r00ta", "createdAt": "2020-07-22T09:28:32Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg3NzQ2MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458877460", "bodyText": "because prior to linearizing the inputs/features we don't know how many items the List will contain and hence using e.g. an ArrayList with a fixed size constructor is not possible.", "author": "tteofili", "createdAt": "2020-07-22T15:25:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY2MDc1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcxODMwMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458718302", "bodyText": "why do we add the perturbed inputs/outputs if tries == 0? at the end if separableDataset is false this operation is without effects", "author": "r00ta", "createdAt": "2020-07-22T11:17:18Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        try {\n+            PredictionInput originalInput = prediction.getInput();\n+            List<Feature> inputFeatures = originalInput.getFeatures();\n+            PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);\n+            List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+            List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+            int noOfInputFeatures = inputFeatures.size();\n+            int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+            double[] weights = new double[noOfOutputFeatures];\n+\n+            for (int o = 0; o < actualOutputs.size(); o++) {\n+                boolean separableDataset = false;\n+\n+                List<PredictionInput> perturbedInputs = new LinkedList<>();\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+\n+                boolean classification = false;\n+                Output currentOutput = actualOutputs.get(o);\n+                if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                    Map<Double, Long> rawClassesBalance = new HashMap<>();\n+                    int tries = 3;\n+                    while (!separableDataset && tries > 0) {\n+                        List<PredictionInput> perturbed = getPerturbedInputs(originalInput, noOfInputFeatures, noOfSamples);\n+                        List<PredictionOutput> perturbedOutputs = model.predict(perturbed);\n+\n+                        Value<?> fv = currentOutput.getValue();\n+\n+                        int finalO = o;\n+                        rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                                .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                                && fv.getUnderlyingObject() == null) || (output.getValue().getUnderlyingObject() != null && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n+                                .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                        logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n+\n+                        if (rawClassesBalance.size() > 1) {\n+                            Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n+                            if ((double) max / (double) perturbed.size() < 0.99) {\n+                                separableDataset = true;\n+                                classification = rawClassesBalance.size() == 2;\n+                            } else {\n+                                tries--;\n+                            }\n+                        } else {\n+                            tries--;\n+                        }\n+                        if (tries == 0 || separableDataset) {", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg3NTMyOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458875328", "bodyText": "prior to throwing an Exception, when the dataset is not easily separable the impl used to try to train linear classifier anyway. I'll fix it.", "author": "tteofili", "createdAt": "2020-07-22T15:22:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcxODMwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcxOTEzNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458719136", "bodyText": "what about a refactoring like\n                    for (int tries = MAX_RETRY; tries > 0; tries--){\n                        List<PredictionInput> perturbed = getPerturbedInputs(originalInput, noOfInputFeatures, noOfSamples);\n                        List<PredictionOutput> perturbedOutputs = model.predict(perturbed);\n\n                        Value<?> fv = currentOutput.getValue();\n\n                        int finalO = o;\n                        rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n                                .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n                                && fv.getUnderlyingObject() == null) || (output.getValue().getUnderlyingObject() != null && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n                                .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n                        logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n\n                        if (rawClassesBalance.size() > 1) {\n                            Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n                            if ((double) max / (double) perturbed.size() < 0.99) {\n                                separableDataset = true;\n                                classification = rawClassesBalance.size() == 2;\n                                perturbedInputs.addAll(perturbed);\n                                predictionOutputs.addAll(perturbedOutputs);\n                            } \n                        } \n                    }\n``` ?", "author": "r00ta", "createdAt": "2020-07-22T11:19:08Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        try {\n+            PredictionInput originalInput = prediction.getInput();\n+            List<Feature> inputFeatures = originalInput.getFeatures();\n+            PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);\n+            List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+            List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+            int noOfInputFeatures = inputFeatures.size();\n+            int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+            double[] weights = new double[noOfOutputFeatures];\n+\n+            for (int o = 0; o < actualOutputs.size(); o++) {\n+                boolean separableDataset = false;\n+\n+                List<PredictionInput> perturbedInputs = new LinkedList<>();\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+\n+                boolean classification = false;\n+                Output currentOutput = actualOutputs.get(o);\n+                if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                    Map<Double, Long> rawClassesBalance = new HashMap<>();\n+                    int tries = 3;\n+                    while (!separableDataset && tries > 0) {\n+                        List<PredictionInput> perturbed = getPerturbedInputs(originalInput, noOfInputFeatures, noOfSamples);\n+                        List<PredictionOutput> perturbedOutputs = model.predict(perturbed);\n+\n+                        Value<?> fv = currentOutput.getValue();\n+\n+                        int finalO = o;\n+                        rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                                .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                                && fv.getUnderlyingObject() == null) || (output.getValue().getUnderlyingObject() != null && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n+                                .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                        logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n+\n+                        if (rawClassesBalance.size() > 1) {\n+                            Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n+                            if ((double) max / (double) perturbed.size() < 0.99) {\n+                                separableDataset = true;\n+                                classification = rawClassesBalance.size() == 2;\n+                            } else {\n+                                tries--;\n+                            }\n+                        } else {\n+                            tries--;\n+                        }\n+                        if (tries == 0 || separableDataset) {\n+                            perturbedInputs.addAll(perturbed);\n+                            predictionOutputs.addAll(perturbedOutputs);\n+                        }\n+                    }", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI0MjU1NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459242555", "bodyText": "sounds good, I'd only add a break statement in the \"succeeding\" block to avoid always running the whole cycle three times.", "author": "tteofili", "createdAt": "2020-07-23T06:41:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcxOTEzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyMDg0NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458720845", "bodyText": "cast not needed", "author": "r00ta", "createdAt": "2020-07-22T11:22:54Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        try {\n+            PredictionInput originalInput = prediction.getInput();\n+            List<Feature> inputFeatures = originalInput.getFeatures();\n+            PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);\n+            List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+            List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+            int noOfInputFeatures = inputFeatures.size();\n+            int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+            double[] weights = new double[noOfOutputFeatures];\n+\n+            for (int o = 0; o < actualOutputs.size(); o++) {\n+                boolean separableDataset = false;\n+\n+                List<PredictionInput> perturbedInputs = new LinkedList<>();\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+\n+                boolean classification = false;\n+                Output currentOutput = actualOutputs.get(o);\n+                if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                    Map<Double, Long> rawClassesBalance = new HashMap<>();\n+                    int tries = 3;\n+                    while (!separableDataset && tries > 0) {\n+                        List<PredictionInput> perturbed = getPerturbedInputs(originalInput, noOfInputFeatures, noOfSamples);\n+                        List<PredictionOutput> perturbedOutputs = model.predict(perturbed);\n+\n+                        Value<?> fv = currentOutput.getValue();\n+\n+                        int finalO = o;\n+                        rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                                .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                                && fv.getUnderlyingObject() == null) || (output.getValue().getUnderlyingObject() != null && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n+                                .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                        logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n+\n+                        if (rawClassesBalance.size() > 1) {\n+                            Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n+                            if ((double) max / (double) perturbed.size() < 0.99) {\n+                                separableDataset = true;\n+                                classification = rawClassesBalance.size() == 2;\n+                            } else {\n+                                tries--;\n+                            }\n+                        } else {\n+                            tries--;\n+                        }\n+                        if (tries == 0 || separableDataset) {\n+                            perturbedInputs.addAll(perturbed);\n+                            predictionOutputs.addAll(perturbedOutputs);\n+                        }\n+                    }\n+                    if (!separableDataset) {\n+                        throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n+                    }\n+                    List<Output> predictedOutputs = new LinkedList<>();\n+                    for (int i = 0; i < perturbedInputs.size(); i++) {\n+                        Output output = predictionOutputs.get(i).getOutputs().get(o);\n+                        predictedOutputs.add(output);\n+                    }\n+\n+                    Output originalOutput = prediction.getOutput().getOutputs().get(o);\n+\n+                    DatasetEncoder datasetEncoder = new DatasetEncoder(perturbedInputs, predictedOutputs, targetInput, originalOutput);\n+                    Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+\n+                    double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+\n+                    LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), classification);\n+                    double loss = linearModel.fit(trainingSet, sampleWeights);\n+                    if (!Double.isNaN(loss)) {\n+                        for (int i = 0; i < weights.length; i++) {\n+                            weights[i] += linearModel.getWeights()[i] / (double) actualOutputs.size();", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyMTczNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458721737", "bodyText": "weights = Arrays.stream(linearModel.getWeights()).map(x -> x / actualOutputs.size()).toArray();?", "author": "r00ta", "createdAt": "2020-07-22T11:24:46Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        try {\n+            PredictionInput originalInput = prediction.getInput();\n+            List<Feature> inputFeatures = originalInput.getFeatures();\n+            PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);\n+            List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+            List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+            int noOfInputFeatures = inputFeatures.size();\n+            int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+            double[] weights = new double[noOfOutputFeatures];\n+\n+            for (int o = 0; o < actualOutputs.size(); o++) {\n+                boolean separableDataset = false;\n+\n+                List<PredictionInput> perturbedInputs = new LinkedList<>();\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+\n+                boolean classification = false;\n+                Output currentOutput = actualOutputs.get(o);\n+                if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                    Map<Double, Long> rawClassesBalance = new HashMap<>();\n+                    int tries = 3;\n+                    while (!separableDataset && tries > 0) {\n+                        List<PredictionInput> perturbed = getPerturbedInputs(originalInput, noOfInputFeatures, noOfSamples);\n+                        List<PredictionOutput> perturbedOutputs = model.predict(perturbed);\n+\n+                        Value<?> fv = currentOutput.getValue();\n+\n+                        int finalO = o;\n+                        rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                                .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                                && fv.getUnderlyingObject() == null) || (output.getValue().getUnderlyingObject() != null && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n+                                .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                        logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n+\n+                        if (rawClassesBalance.size() > 1) {\n+                            Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n+                            if ((double) max / (double) perturbed.size() < 0.99) {\n+                                separableDataset = true;\n+                                classification = rawClassesBalance.size() == 2;\n+                            } else {\n+                                tries--;\n+                            }\n+                        } else {\n+                            tries--;\n+                        }\n+                        if (tries == 0 || separableDataset) {\n+                            perturbedInputs.addAll(perturbed);\n+                            predictionOutputs.addAll(perturbedOutputs);\n+                        }\n+                    }\n+                    if (!separableDataset) {\n+                        throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n+                    }\n+                    List<Output> predictedOutputs = new LinkedList<>();\n+                    for (int i = 0; i < perturbedInputs.size(); i++) {\n+                        Output output = predictionOutputs.get(i).getOutputs().get(o);\n+                        predictedOutputs.add(output);\n+                    }\n+\n+                    Output originalOutput = prediction.getOutput().getOutputs().get(o);\n+\n+                    DatasetEncoder datasetEncoder = new DatasetEncoder(perturbedInputs, predictedOutputs, targetInput, originalOutput);\n+                    Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+\n+                    double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+\n+                    LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), classification);\n+                    double loss = linearModel.fit(trainingSet, sampleWeights);\n+                    if (!Double.isNaN(loss)) {\n+                        for (int i = 0; i < weights.length; i++) {\n+                            weights[i] += linearModel.getWeights()[i] / (double) actualOutputs.size();", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI0MzkwMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459243900", "bodyText": "sounds good", "author": "tteofili", "createdAt": "2020-07-23T06:44:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyMTczNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyMjk4Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458722986", "bodyText": "I don't 100% like big try/catch(Exception) 'cause it means we don't really control what is going on there, is there a specify reason why we have to catch everything?", "author": "r00ta", "createdAt": "2020-07-22T11:27:26Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ *\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * no. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * no. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        try {\n+            PredictionInput originalInput = prediction.getInput();\n+            List<Feature> inputFeatures = originalInput.getFeatures();\n+            PredictionInput targetInput = DataUtils.linearizeInputs(List.of(originalInput)).get(0);\n+            List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+            List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+            int noOfInputFeatures = inputFeatures.size();\n+            int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+            double[] weights = new double[noOfOutputFeatures];\n+\n+            for (int o = 0; o < actualOutputs.size(); o++) {\n+                boolean separableDataset = false;\n+\n+                List<PredictionInput> perturbedInputs = new LinkedList<>();\n+                List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+\n+                boolean classification = false;\n+                Output currentOutput = actualOutputs.get(o);\n+                if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                    Map<Double, Long> rawClassesBalance = new HashMap<>();\n+                    int tries = 3;\n+                    while (!separableDataset && tries > 0) {\n+                        List<PredictionInput> perturbed = getPerturbedInputs(originalInput, noOfInputFeatures, noOfSamples);\n+                        List<PredictionOutput> perturbedOutputs = model.predict(perturbed);\n+\n+                        Value<?> fv = currentOutput.getValue();\n+\n+                        int finalO = o;\n+                        rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                                .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                                && fv.getUnderlyingObject() == null) || (output.getValue().getUnderlyingObject() != null && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n+                                .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                        logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n+\n+                        if (rawClassesBalance.size() > 1) {\n+                            Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n+                            if ((double) max / (double) perturbed.size() < 0.99) {\n+                                separableDataset = true;\n+                                classification = rawClassesBalance.size() == 2;\n+                            } else {\n+                                tries--;\n+                            }\n+                        } else {\n+                            tries--;\n+                        }\n+                        if (tries == 0 || separableDataset) {\n+                            perturbedInputs.addAll(perturbed);\n+                            predictionOutputs.addAll(perturbedOutputs);\n+                        }\n+                    }\n+                    if (!separableDataset) {\n+                        throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n+                    }\n+                    List<Output> predictedOutputs = new LinkedList<>();\n+                    for (int i = 0; i < perturbedInputs.size(); i++) {\n+                        Output output = predictionOutputs.get(i).getOutputs().get(o);\n+                        predictedOutputs.add(output);\n+                    }\n+\n+                    Output originalOutput = prediction.getOutput().getOutputs().get(o);\n+\n+                    DatasetEncoder datasetEncoder = new DatasetEncoder(perturbedInputs, predictedOutputs, targetInput, originalOutput);\n+                    Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+\n+                    double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+\n+                    LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), classification);\n+                    double loss = linearModel.fit(trainingSet, sampleWeights);\n+                    if (!Double.isNaN(loss)) {\n+                        for (int i = 0; i < weights.length; i++) {\n+                            weights[i] += linearModel.getWeights()[i] / (double) actualOutputs.size();\n+                        }\n+                        logger.debug(\"weights updated for output {}\", currentOutput);\n+                    }\n+                } else {\n+                    logger.debug(\"skipping explanation of empty output {}\", currentOutput);\n+                }\n+            }\n+            for (int i = 0; i < weights.length; i++) {\n+                FeatureImportance featureImportance = new FeatureImportance(linearizedTargetInputFeatures.get(i), weights[i]);\n+                saliencies.add(featureImportance);\n+            }\n+        } catch (Exception e) {", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTMyNzExNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459327116", "bodyText": "apart personal taste I think it's good to carefully consider expected failures only, I'll drop the generic try/catch(Exception) block.", "author": "tteofili", "createdAt": "2020-07-23T09:34:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyMjk4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyNDQwMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458724401", "bodyText": "Move to constant?", "author": "r00ta", "createdAt": "2020-07-22T11:30:28Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+/**\n+ * Utility class to generate weights for the LIME encoded training set, given a prediction.\n+ */\n+class SampleWeighter {\n+\n+    static double[] getSampleWeights(PredictionInput targetInput, Collection<Pair<double[], Double>> training) {\n+        int noOfFeatures = targetInput.getFeatures().size();\n+        double[] x = new double[noOfFeatures];\n+        Arrays.fill(x, 1);\n+\n+        return training.stream().map(Pair::getLeft).map(\n+                d -> DataUtils.euclideanDistance(x, d)).map(d -> DataUtils.exponentialSmoothingKernel(d, 0.75 *", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI0NDE1Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459244153", "bodyText": "ok", "author": "tteofili", "createdAt": "2020-07-23T06:45:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyNDQwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyNDYzNA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458724634", "bodyText": "Capital (and in the following methods) : )", "author": "r00ta", "createdAt": "2020-07-22T11:30:55Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Feature.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+/**\n+ * A feature represents fixed portions of an input, having a name, a {@link Type} and an associated {@link Value}.\n+ */\n+public class Feature {\n+\n+    private final String name;\n+    private final Type type;\n+    private final Value value;\n+\n+    Feature(String name, Type type, Value value) {\n+        this.name = name;\n+        this.type = type;\n+        this.value = value;\n+    }\n+\n+    /**\n+     * the name of the feature", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyNDgzMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458724830", "bodyText": "Capital", "author": "r00ta", "createdAt": "2020-07-22T11:31:22Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/FeatureDistribution.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+/**\n+ * The data distribution for a given feature.\n+ */\n+public class FeatureDistribution {\n+\n+    private final double min;\n+    private final double max;\n+    private final double mean;\n+    private final double stdDev;\n+\n+    public FeatureDistribution(double min, double max, double mean, double stdDev) {\n+        this.min = min;\n+        this.max = max;\n+        this.mean = mean;\n+        this.stdDev = stdDev;\n+    }\n+\n+    /**\n+     * get minimum value for this feature", "originalCommit": "a27bacc8c139c607a3cc2ccdf31d4efa1eb0ad44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyODQ4MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458728481", "bodyText": "Could you add a test for complex nested (more than 1 level) structures created with newCompositeFeature?", "author": "r00ta", "createdAt": "2020-07-22T11:38:48Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/model/FeatureFactoryTest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.Locale;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+\n+class FeatureFactoryTest {", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI2MTM2Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459261366", "bodyText": "sure :)", "author": "tteofili", "createdAt": "2020-07-23T07:28:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyODQ4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcyOTkwOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458729908", "bodyText": "capital", "author": "r00ta", "createdAt": "2020-07-22T11:41:34Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+import java.util.List;\n+\n+/**\n+ * A provider of predictions.\n+ * This can be any model, service or function, like (local / remote) DMN, PMML services or any other ML model.\n+ */\n+public interface PredictionProvider {\n+\n+    /**\n+     * perform a batch of predictions, given a batch of inputs.", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczMDQyNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458730426", "bodyText": "capital", "author": "r00ta", "createdAt": "2020-07-22T11:42:31Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProviderMetadata.java", "diffHunk": "@@ -0,0 +1,28 @@\n+package org.kie.kogito.explainability.model;\n+\n+/**\n+ * Metadata about a given {@link PredictionProvider}.\n+ */\n+public interface PredictionProviderMetadata {\n+\n+    /**\n+     * fetch the data distribution associated to this model", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczMjg3MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458732871", "bodyText": "Are these the build types we support atm right? I know the explainability applies to all the models, but we also have to consider that we have to target DMN and its types to properly perturb the inputs.\nafaik there are a couple of fancy build in types like \"years and months duration\" that we will have to support as well. I'm not saying we should support all of them now in this PR, but it might be good to create a ticket for that to keep track. wdyt? cc @danielezonca", "author": "r00ta", "createdAt": "2020-07-22T11:47:23Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Type.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+/**\n+ * Allowed data types.\n+ */\n+public enum Type {\n+\n+    TEXT(\"text\"),\n+\n+    CATEGORICAL(\"categorical\"),\n+\n+    BINARY(\"binary\"),\n+\n+    NUMBER(\"number\"),\n+\n+    BOOLEAN(\"boolean\"),\n+\n+    URI(\"uri\"),\n+\n+    TIME(\"time\"),\n+\n+    DURATION(\"duration\"),\n+\n+    VECTOR(\"vector\"),\n+\n+    UNDEFINED(\"undefined\"),\n+\n+    COMPOSITE(\"composite\"),\n+\n+    CURRENCY(\"currency\");", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI0OTMwMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459249300", "bodyText": "Here the idea is simplify the integration of an external \"engine\" with explainable-service: instead of just accept plain array of double and ask to do all the conversion on engine side we will support a richer set of data types.\nI am not sure about how far we want to go with this and we need to find a tradeoff: it is always possible to add a new type or manually convert the value.\nIn general I agree we should try to support all builtin DMN types so feel free to create a ticket to track missing types", "author": "danielezonca", "createdAt": "2020-07-23T06:58:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczMjg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTMyOTg2OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459329868", "bodyText": "when coming with this initial set of types to support I have looked at some DMN models as well as trying to think what generally makes sense or is commonly used in ML models in terms of features. Any possible enrichment to the supported data types is welcome I'd say.", "author": "tteofili", "createdAt": "2020-07-23T09:39:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczMjg3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczNzU3Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458737573", "bodyText": "why not using underlyingObject  instanceof double[] ?", "author": "r00ta", "createdAt": "2020-07-22T11:56:38Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Value.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Wrapper class for any kind of value part of a prediction input or output.\n+ * @param <S>\n+ */\n+public class Value<S> {\n+\n+    private final S underlyingObject;\n+\n+    public Value(S underlyingObject) {\n+        this.underlyingObject = underlyingObject;\n+    }\n+\n+    public String asString() {\n+        return String.valueOf(underlyingObject);\n+    }\n+\n+    public double asNumber() {\n+        if (underlyingObject != null) {\n+            return underlyingObject instanceof Boolean ? (Boolean) underlyingObject ? 1d : 0d : Double.parseDouble(asString());\n+        } else {\n+            return Double.NaN;\n+        }\n+    }\n+\n+    public S getUnderlyingObject() {\n+        return underlyingObject;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Value{\" + underlyingObject + '}';\n+    }\n+\n+    public double[] asVector() {\n+        double[] doubles;\n+        try {\n+            doubles = (double[]) underlyingObject;", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczODIxNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458738215", "bodyText": "why can it fail with an Exception?", "author": "r00ta", "createdAt": "2020-07-22T11:57:58Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Value.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * Wrapper class for any kind of value part of a prediction input or output.\n+ * @param <S>\n+ */\n+public class Value<S> {\n+\n+    private final S underlyingObject;\n+\n+    public Value(S underlyingObject) {\n+        this.underlyingObject = underlyingObject;\n+    }\n+\n+    public String asString() {\n+        return String.valueOf(underlyingObject);\n+    }\n+\n+    public double asNumber() {\n+        if (underlyingObject != null) {\n+            return underlyingObject instanceof Boolean ? (Boolean) underlyingObject ? 1d : 0d : Double.parseDouble(asString());\n+        } else {\n+            return Double.NaN;\n+        }\n+    }\n+\n+    public S getUnderlyingObject() {\n+        return underlyingObject;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Value{\" + underlyingObject + '}';\n+    }\n+\n+    public double[] asVector() {\n+        double[] doubles;\n+        try {\n+            doubles = (double[]) underlyingObject;\n+        } catch (ClassCastException cce) {\n+            if (underlyingObject instanceof String) {\n+                int noOfWords = ((String) underlyingObject).split(\" \").length;\n+                doubles = new double[noOfWords];\n+                Arrays.fill(doubles, 1);\n+            } else {\n+                try {\n+                    double v = asNumber();\n+                    doubles = new double[1];\n+                    doubles[0] = v;\n+                } catch (Exception e) {\n+                    doubles = new double[0];\n+                }", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM0MTQ1OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459341459", "bodyText": "because asNumber throws a NumberFormatException if the underlyingObject cannot be parsed as a number. Maybe a good idea is to make asNumber return NaN in such cases and avoid throwing NFE.", "author": "tteofili", "createdAt": "2020-07-23T10:01:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczODIxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczODU2NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458738564", "bodyText": "rename to setSeed?", "author": "r00ta", "createdAt": "2020-07-22T11:58:41Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczODk2Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458738962", "bodyText": "why is it bounded to 10?", "author": "r00ta", "createdAt": "2020-07-22T11:59:25Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2NDcyNA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459364724", "bodyText": "to generate data less prune to underflow, 100 or 1000 would be fine as well though.", "author": "tteofili", "createdAt": "2020-07-23T10:49:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczODk2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczOTE4MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458739181", "bodyText": "cast not needed", "author": "r00ta", "createdAt": "2020-07-22T11:59:49Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0MTQzNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458741436", "bodyText": "Initialize to \"\" so that you can skip the assignments at lines 186 and 189?", "author": "r00ta", "createdAt": "2020-07-22T12:04:16Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NTY2Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458745662", "bodyText": "This is going to remove at max 2 words, is this intended?", "author": "r00ta", "createdAt": "2020-07-22T12:12:39Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM2ODQ0Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459368443", "bodyText": "this is one of those very sensitive parameters in LIME, I think it's worth opening an investigation issue to assess a good default; this setting was the result of my experiments with our models, but it's worth investigating a bit more.", "author": "tteofili", "createdAt": "2020-07-23T10:57:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NTY2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM3Njg0MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459376840", "bodyText": "I've created FAI-236 to handle this.", "author": "tteofili", "createdAt": "2020-07-23T11:16:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NTY2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NjkzMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458746933", "bodyText": "If stringValue ends with \" \", an exception is going to be raised by random.nextInt(0) at line 179. Could you fix it and add a test?", "author": "r00ta", "createdAt": "2020-07-22T12:14:58Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM4NDYzMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459384631", "bodyText": "ok", "author": "tteofili", "createdAt": "2020-07-23T11:34:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NjkzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NzUwMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458747503", "bodyText": "can you rename v?", "author": "r00ta", "createdAt": "2020-07-22T12:16:04Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0NzYzMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458747631", "bodyText": "rename ov?", "author": "r00ta", "createdAt": "2020-07-22T12:16:18Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0OTA4Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458749083", "bodyText": "Not sure if it's the comment that is not aligned with the actual implementation, but Locale.getDefault is not going to return always EUR", "author": "r00ta", "createdAt": "2020-07-22T12:19:07Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM4NTg0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459385846", "bodyText": "yes, the comment is wrong, as that depends on the machine the code is running actually.", "author": "tteofili", "createdAt": "2020-07-23T11:37:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0OTA4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0OTg0OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458749849", "bodyText": "Not sure if I get it, but if the input was already MIDNIGHT this is not going to perturb the data right?", "author": "r00ta", "createdAt": "2020-07-22T12:20:31Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM4NzA4MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459387080", "bodyText": "correct", "author": "tteofili", "createdAt": "2020-07-23T11:39:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc0OTg0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1MjUzMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458752530", "bodyText": "Same as in another comment: we don't need to sort, this is slower than a linear search for this particular use case", "author": "r00ta", "createdAt": "2020-07-22T12:25:31Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1MzM1NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458753354", "bodyText": "Why do we look for \" (\"?", "author": "r00ta", "createdAt": "2020-07-22T12:26:57Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDg2NDc5Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r460864796", "bodyText": "this is suboptimal, I know, but the reason why this happens is because LIME creates word level text features from a full text feature by splitting the text at whitespaces, the name of such features becomes word (feature-name).", "author": "tteofili", "createdAt": "2020-07-27T12:48:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1MzM1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDkzODg4Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r460938886", "bodyText": "as a side note, this and other feature processing functions will be better structured in a dedicated API in FAI-238.", "author": "tteofili", "createdAt": "2020-07-27T14:38:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1MzM1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1Mzg4Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458753882", "bodyText": "Same comments above", "author": "r00ta", "createdAt": "2020-07-22T12:27:56Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // flip the boolean value\n+                    f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                }\n+                break;\n+            case TIME:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set to midnight\n+                    f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                }\n+                break;\n+            case DURATION:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the duration to 0\n+                    f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                }\n+                break;\n+            case CURRENCY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the currency to EUR\n+                    f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                }", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1NDY5Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458754692", "bodyText": "with this the last value of the array is always excluded", "author": "r00ta", "createdAt": "2020-07-22T12:29:26Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // flip the boolean value\n+                    f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                }\n+                break;\n+            case TIME:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set to midnight\n+                    f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                }\n+                break;\n+            case DURATION:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the duration to 0\n+                    f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                }\n+                break;\n+            case CURRENCY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the currency to EUR\n+                    f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    String category = feature.getValue().asString();\n+                    if (!\"0\".equals(category)) {\n+                        category = \"0\";\n+                    } else {\n+                        category = \"1\";\n+                    }\n+                    f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                }\n+                break;\n+            case BINARY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // randomly set a non zero value to zero (or decrease it by 1)\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        int idx = random.nextInt(values.length - 1);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1NTI4Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458755282", "bodyText": "An exception is going to be raised if the array is composed by only one element, can you also add a test for that?", "author": "r00ta", "createdAt": "2020-07-22T12:30:24Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // flip the boolean value\n+                    f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                }\n+                break;\n+            case TIME:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set to midnight\n+                    f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                }\n+                break;\n+            case DURATION:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the duration to 0\n+                    f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                }\n+                break;\n+            case CURRENCY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the currency to EUR\n+                    f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    String category = feature.getValue().asString();\n+                    if (!\"0\".equals(category)) {\n+                        category = \"0\";\n+                    } else {\n+                        category = \"1\";\n+                    }\n+                    f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                }\n+                break;\n+            case BINARY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // randomly set a non zero value to zero (or decrease it by 1)\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        int idx = random.nextInt(values.length - 1);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1NzI5NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458757295", "bodyText": "Is this the hamming distance? afaik if the two strings have different lenght then it is not defined", "author": "r00ta", "createdAt": "2020-07-22T12:33:55Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // flip the boolean value\n+                    f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                }\n+                break;\n+            case TIME:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set to midnight\n+                    f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                }\n+                break;\n+            case DURATION:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the duration to 0\n+                    f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                }\n+                break;\n+            case CURRENCY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the currency to EUR\n+                    f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    String category = feature.getValue().asString();\n+                    if (!\"0\".equals(category)) {\n+                        category = \"0\";\n+                    } else {\n+                        category = \"1\";\n+                    }\n+                    f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                }\n+                break;\n+            case BINARY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // randomly set a non zero value to zero (or decrease it by 1)\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        int idx = random.nextInt(values.length - 1);\n+                        if (values[idx] != 0) {\n+                            values[idx] = 0;\n+                        } else {\n+                            values[idx]--;\n+                        }\n+                    }\n+                    f = FeatureFactory.newVectorFeature(featureName, values);\n+                }\n+                break;\n+            case UNDEFINED:\n+                f = dropFeature((Feature) feature.getValue().getUnderlyingObject(), names);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static double hammingDistance(double[] x, double[] y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            if (x[i] != y[i]) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length - y.length);\n+    }\n+\n+    public static double hammingDistance(String x, String y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length(), y.length()); i++) {\n+            if (x.charAt(i) != y.charAt(i)) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length() - y.length());\n+    }\n+", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQyMDY3NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459420674", "bodyText": "correct, I'll fix it.", "author": "tteofili", "createdAt": "2020-07-23T12:45:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1NzI5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1Nzc3Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458757777", "bodyText": "Math.PI?", "author": "r00ta", "createdAt": "2020-07-22T12:34:46Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // flip the boolean value\n+                    f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                }\n+                break;\n+            case TIME:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set to midnight\n+                    f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                }\n+                break;\n+            case DURATION:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the duration to 0\n+                    f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                }\n+                break;\n+            case CURRENCY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the currency to EUR\n+                    f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    String category = feature.getValue().asString();\n+                    if (!\"0\".equals(category)) {\n+                        category = \"0\";\n+                    } else {\n+                        category = \"1\";\n+                    }\n+                    f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                }\n+                break;\n+            case BINARY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // randomly set a non zero value to zero (or decrease it by 1)\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        int idx = random.nextInt(values.length - 1);\n+                        if (values[idx] != 0) {\n+                            values[idx] = 0;\n+                        } else {\n+                            values[idx]--;\n+                        }\n+                    }\n+                    f = FeatureFactory.newVectorFeature(featureName, values);\n+                }\n+                break;\n+            case UNDEFINED:\n+                f = dropFeature((Feature) feature.getValue().getUnderlyingObject(), names);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static double hammingDistance(double[] x, double[] y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            if (x[i] != y[i]) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length - y.length);\n+    }\n+\n+    public static double hammingDistance(String x, String y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length(), y.length()); i++) {\n+            if (x.charAt(i) != y.charAt(i)) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length() - y.length());\n+    }\n+\n+    public static double euclideanDistance(double[] x, double[] y) {\n+        double e = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            e += Math.pow(x[i] - y[i], 2);\n+        }\n+        return Math.sqrt(e);\n+    }\n+\n+    public static double gowerDistance(double[] x, double[] y, double lambda) {\n+        return euclideanDistance(x, y) + lambda * hammingDistance(x, y);\n+    }\n+\n+    public static double gaussianKernel(double x) {\n+        return Math.exp(-Math.pow(x, 2) / 2) / Math.sqrt(3.14);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1ODI5OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458758298", "bodyText": "why 1000?", "author": "r00ta", "createdAt": "2020-07-22T12:35:40Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // flip the boolean value\n+                    f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                }\n+                break;\n+            case TIME:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set to midnight\n+                    f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                }\n+                break;\n+            case DURATION:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the duration to 0\n+                    f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                }\n+                break;\n+            case CURRENCY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the currency to EUR\n+                    f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    String category = feature.getValue().asString();\n+                    if (!\"0\".equals(category)) {\n+                        category = \"0\";\n+                    } else {\n+                        category = \"1\";\n+                    }\n+                    f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                }\n+                break;\n+            case BINARY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // randomly set a non zero value to zero (or decrease it by 1)\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        int idx = random.nextInt(values.length - 1);\n+                        if (values[idx] != 0) {\n+                            values[idx] = 0;\n+                        } else {\n+                            values[idx]--;\n+                        }\n+                    }\n+                    f = FeatureFactory.newVectorFeature(featureName, values);\n+                }\n+                break;\n+            case UNDEFINED:\n+                f = dropFeature((Feature) feature.getValue().getUnderlyingObject(), names);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static double hammingDistance(double[] x, double[] y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            if (x[i] != y[i]) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length - y.length);\n+    }\n+\n+    public static double hammingDistance(String x, String y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length(), y.length()); i++) {\n+            if (x.charAt(i) != y.charAt(i)) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length() - y.length());\n+    }\n+\n+    public static double euclideanDistance(double[] x, double[] y) {\n+        double e = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            e += Math.pow(x[i] - y[i], 2);\n+        }\n+        return Math.sqrt(e);\n+    }\n+\n+    public static double gowerDistance(double[] x, double[] y, double lambda) {\n+        return euclideanDistance(x, y) + lambda * hammingDistance(x, y);\n+    }\n+\n+    public static double gaussianKernel(double x) {\n+        return Math.exp(-Math.pow(x, 2) / 2) / Math.sqrt(3.14);\n+    }\n+\n+    public static double exponentialSmoothingKernel(double x, double sigma) {\n+        return Math.sqrt(Math.exp(-(Math.pow(x, 2)) / Math.pow(sigma, 2)));\n+    }\n+\n+    public static FeatureDistribution getFeatureDistribution(double[] doubles) {\n+        double min = DoubleStream.of(doubles).min().orElse(0);\n+        double max = DoubleStream.of(doubles).max().orElse(0);\n+        double mean = getMean(doubles);\n+        double stdDev = getStdDev(doubles, mean);\n+        return new FeatureDistribution(min, max, mean, stdDev);\n+    }\n+\n+    public static DataDistribution generateRandomDataDistribution(int size) {\n+        List<FeatureDistribution> featureDistributions = new LinkedList<>();\n+        for (int i = 0; i < size; i++) {\n+            double[] doubles = generateData(random.nextDouble(), random.nextDouble(), 1000);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQyNDIzOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459424238", "bodyText": "good point, I've made it configurable.", "author": "tteofili", "createdAt": "2020-07-23T12:51:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1ODI5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1ODc2Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458758763", "bodyText": "why linkedlist?", "author": "r00ta", "createdAt": "2020-07-22T12:36:29Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // flip the boolean value\n+                    f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                }\n+                break;\n+            case TIME:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set to midnight\n+                    f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                }\n+                break;\n+            case DURATION:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the duration to 0\n+                    f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                }\n+                break;\n+            case CURRENCY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the currency to EUR\n+                    f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    String category = feature.getValue().asString();\n+                    if (!\"0\".equals(category)) {\n+                        category = \"0\";\n+                    } else {\n+                        category = \"1\";\n+                    }\n+                    f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                }\n+                break;\n+            case BINARY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // randomly set a non zero value to zero (or decrease it by 1)\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        int idx = random.nextInt(values.length - 1);\n+                        if (values[idx] != 0) {\n+                            values[idx] = 0;\n+                        } else {\n+                            values[idx]--;\n+                        }\n+                    }\n+                    f = FeatureFactory.newVectorFeature(featureName, values);\n+                }\n+                break;\n+            case UNDEFINED:\n+                f = dropFeature((Feature) feature.getValue().getUnderlyingObject(), names);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static double hammingDistance(double[] x, double[] y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            if (x[i] != y[i]) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length - y.length);\n+    }\n+\n+    public static double hammingDistance(String x, String y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length(), y.length()); i++) {\n+            if (x.charAt(i) != y.charAt(i)) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length() - y.length());\n+    }\n+\n+    public static double euclideanDistance(double[] x, double[] y) {\n+        double e = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            e += Math.pow(x[i] - y[i], 2);\n+        }\n+        return Math.sqrt(e);\n+    }\n+\n+    public static double gowerDistance(double[] x, double[] y, double lambda) {\n+        return euclideanDistance(x, y) + lambda * hammingDistance(x, y);\n+    }\n+\n+    public static double gaussianKernel(double x) {\n+        return Math.exp(-Math.pow(x, 2) / 2) / Math.sqrt(3.14);\n+    }\n+\n+    public static double exponentialSmoothingKernel(double x, double sigma) {\n+        return Math.sqrt(Math.exp(-(Math.pow(x, 2)) / Math.pow(sigma, 2)));\n+    }\n+\n+    public static FeatureDistribution getFeatureDistribution(double[] doubles) {\n+        double min = DoubleStream.of(doubles).min().orElse(0);\n+        double max = DoubleStream.of(doubles).max().orElse(0);\n+        double mean = getMean(doubles);\n+        double stdDev = getStdDev(doubles, mean);\n+        return new FeatureDistribution(min, max, mean, stdDev);\n+    }\n+\n+    public static DataDistribution generateRandomDataDistribution(int size) {\n+        List<FeatureDistribution> featureDistributions = new LinkedList<>();\n+        for (int i = 0; i < size; i++) {\n+            double[] doubles = generateData(random.nextDouble(), random.nextDouble(), 1000);\n+            FeatureDistribution featureDistribution = DataUtils.getFeatureDistribution(doubles);\n+            featureDistributions.add(featureDistribution);\n+        }\n+        return new DataDistribution(featureDistributions);\n+    }\n+\n+    public static List<PredictionInput> linearizeInputs(List<PredictionInput> predictionInputs) {\n+        List<PredictionInput> newInputs = new LinkedList<>();\n+        for (PredictionInput predictionInput : predictionInputs) {\n+            List<Feature> originalFeatures = predictionInput.getFeatures();\n+            List<Feature> flattenedFeatures = getLinearizedFeatures(originalFeatures);\n+            newInputs.add(new PredictionInput(flattenedFeatures));\n+        }\n+        return newInputs;\n+    }\n+\n+    public static List<Feature> getLinearizedFeatures(List<Feature> originalFeatures) {\n+        List<Feature> flattenedFeatures = new LinkedList<>();", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQyMTgyNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459421827", "bodyText": "same as before", "author": "tteofili", "createdAt": "2020-07-23T12:47:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1ODc2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1OTg5OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458759898", "bodyText": "What about all the other supported types? can you add a test using for example Boolean and other?", "author": "r00ta", "createdAt": "2020-07-22T12:38:32Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,473 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void seed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / (double) data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbDrop(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue;\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                        for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                            int dropIdx = random.nextInt(words.size());\n+                            words.remove(dropIdx);\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    } else {\n+                        newStringValue = \"\";\n+                    }\n+                } else {\n+                    newStringValue = \"\";\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double ov = feature.getValue().asNumber();\n+                boolean intValue = ov % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double v = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (ov != 0d) {\n+                    v = v * ov + ov;\n+                }\n+                if (intValue) {\n+                    v = (int) v;\n+                    if (v == ov) {\n+                        v = (int) v * 10;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, v);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                // set to midnight\n+                f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to EUR\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                // do nothing\n+                f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, String... names) {\n+        Arrays.sort(names);\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = Arrays.stream(names).map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // flip the boolean value\n+                    f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                }\n+                break;\n+            case TIME:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set to midnight\n+                    f = FeatureFactory.newTimeFeature(featureName, LocalTime.MIDNIGHT);\n+                }\n+                break;\n+            case DURATION:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the duration to 0\n+                    f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                }\n+                break;\n+            case CURRENCY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set the currency to EUR\n+                    f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    String category = feature.getValue().asString();\n+                    if (!\"0\".equals(category)) {\n+                        category = \"0\";\n+                    } else {\n+                        category = \"1\";\n+                    }\n+                    f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                }\n+                break;\n+            case BINARY:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (Arrays.binarySearch(names, feature.getName()) >= 0) {\n+                    // randomly set a non zero value to zero (or decrease it by 1)\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        int idx = random.nextInt(values.length - 1);\n+                        if (values[idx] != 0) {\n+                            values[idx] = 0;\n+                        } else {\n+                            values[idx]--;\n+                        }\n+                    }\n+                    f = FeatureFactory.newVectorFeature(featureName, values);\n+                }\n+                break;\n+            case UNDEFINED:\n+                f = dropFeature((Feature) feature.getValue().getUnderlyingObject(), names);\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static double hammingDistance(double[] x, double[] y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            if (x[i] != y[i]) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length - y.length);\n+    }\n+\n+    public static double hammingDistance(String x, String y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length(), y.length()); i++) {\n+            if (x.charAt(i) != y.charAt(i)) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length() - y.length());\n+    }\n+\n+    public static double euclideanDistance(double[] x, double[] y) {\n+        double e = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            e += Math.pow(x[i] - y[i], 2);\n+        }\n+        return Math.sqrt(e);\n+    }\n+\n+    public static double gowerDistance(double[] x, double[] y, double lambda) {\n+        return euclideanDistance(x, y) + lambda * hammingDistance(x, y);\n+    }\n+\n+    public static double gaussianKernel(double x) {\n+        return Math.exp(-Math.pow(x, 2) / 2) / Math.sqrt(3.14);\n+    }\n+\n+    public static double exponentialSmoothingKernel(double x, double sigma) {\n+        return Math.sqrt(Math.exp(-(Math.pow(x, 2)) / Math.pow(sigma, 2)));\n+    }\n+\n+    public static FeatureDistribution getFeatureDistribution(double[] doubles) {\n+        double min = DoubleStream.of(doubles).min().orElse(0);\n+        double max = DoubleStream.of(doubles).max().orElse(0);\n+        double mean = getMean(doubles);\n+        double stdDev = getStdDev(doubles, mean);\n+        return new FeatureDistribution(min, max, mean, stdDev);\n+    }\n+\n+    public static DataDistribution generateRandomDataDistribution(int size) {\n+        List<FeatureDistribution> featureDistributions = new LinkedList<>();\n+        for (int i = 0; i < size; i++) {\n+            double[] doubles = generateData(random.nextDouble(), random.nextDouble(), 1000);\n+            FeatureDistribution featureDistribution = DataUtils.getFeatureDistribution(doubles);\n+            featureDistributions.add(featureDistribution);\n+        }\n+        return new DataDistribution(featureDistributions);\n+    }\n+\n+    public static List<PredictionInput> linearizeInputs(List<PredictionInput> predictionInputs) {\n+        List<PredictionInput> newInputs = new LinkedList<>();\n+        for (PredictionInput predictionInput : predictionInputs) {\n+            List<Feature> originalFeatures = predictionInput.getFeatures();\n+            List<Feature> flattenedFeatures = getLinearizedFeatures(originalFeatures);\n+            newInputs.add(new PredictionInput(flattenedFeatures));\n+        }\n+        return newInputs;\n+    }\n+\n+    public static List<Feature> getLinearizedFeatures(List<Feature> originalFeatures) {\n+        List<Feature> flattenedFeatures = new LinkedList<>();\n+        for (Feature f : originalFeatures) {\n+            linearizeFeature(flattenedFeatures, f);\n+        }\n+        return flattenedFeatures;\n+    }\n+\n+    static void linearizeFeature(List<Feature> flattenedFeatures, Feature f) {\n+        if (Type.UNDEFINED.equals(f.getType())) {\n+            linearizeFeature(flattenedFeatures, (Feature) f.getValue().getUnderlyingObject());\n+        } else if (Type.COMPOSITE.equals(f.getType())) {\n+            List<Feature> features = (List<Feature>) f.getValue().getUnderlyingObject();\n+            for (Feature feature : features) {\n+                linearizeFeature(flattenedFeatures, feature);\n+            }\n+        } else {\n+            if (Type.TEXT.equals(f.getType())) {\n+                for (String w : f.getValue().asString().split(\" \")) {\n+                    Feature outputFeature = FeatureFactory.newTextFeature(w + \" (\" + f.getName() + \")\", w);\n+                    flattenedFeatures.add(outputFeature);\n+                }\n+            } else {\n+                flattenedFeatures.add(f);\n+            }\n+        }\n+    }\n+}", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQyNDY3Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459424672", "bodyText": "the other supported types do not have to be linearized, I'll add tests.", "author": "tteofili", "createdAt": "2020-07-23T12:52:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc1OTg5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2MDA0OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458760048", "bodyText": "capital", "author": "r00ta", "createdAt": "2020-07-22T12:38:47Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility class providing different methods to evaluate explainability.\n+ */\n+public class ExplainabilityMetrics {\n+\n+    /**\n+     * measure the explainability of an explanation as per paper \"Towards Quantification of Explainability in Explainable", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "68e1b2e63368bd09a887f54f2320896b005c558f", "url": "https://github.com/kiegroup/kogito-apps/commit/68e1b2e63368bd09a887f54f2320896b005c558f", "message": "KOGITO-2750 - dropped useless dependency", "committedDate": "2020-07-22T12:51:14Z", "type": "commit"}, {"oid": "0e4ecaaefc8387d527fdf3929e314fde7610ad30", "url": "https://github.com/kiegroup/kogito-apps/commit/0e4ecaaefc8387d527fdf3929e314fde7610ad30", "message": "KOGITO-2750 - more efficient string matching in DE#encodeText", "committedDate": "2020-07-22T12:51:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2ODE2Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458768162", "bodyText": "With the current implementation  ExplainabilityMetrics.classificationFidelity(pairs); always returns 0 for these inputs, if this is what it was intended to be tested, can you assert that it's equal to zero?", "author": "r00ta", "createdAt": "2020-07-22T12:52:39Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/ExplainabilityMetricsTest.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class ExplainabilityMetricsTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testExplainabilityNoExplanation() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(0, 0, 0);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertEquals(0, v);\n+    }\n+\n+    @Test\n+    void testExplainabilityNoExplanationWithInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(0, 0, 1);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertEquals(0, v);\n+    }\n+\n+    @Test\n+    void testExplainabilitySameIOChunksNoInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(10, 10, 0);\n+        assertFalse(Double.isNaN(v));\n+        assertFalse(Double.isInfinite(v));\n+        assertThat(v).isBetween(0d, 1d);\n+    }\n+\n+    @Test\n+    void testExplainabilitySameIOChunksWithInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(10, 10, 0.5);\n+        assertEquals(0.2331, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testExplainabilityDifferentIOChunksNoInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(3, 9, 0);\n+        assertEquals(0.481, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testExplainabilityDifferentIOChunksInteraction() {\n+        double v = ExplainabilityMetrics.quantifyExplainability(3, 9, 0.5);\n+        assertEquals(0.3145, v, 1e-5);\n+    }\n+\n+    @Test\n+    void testFidelity() {\n+        List<Pair<Saliency, Prediction>> pairs = new LinkedList<>();\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        PredictionProvider model = TestUtils.getDummyTextClassifier();\n+        for (int i = 0; i < 10; i++) {\n+            List<Feature> features = new LinkedList<>();\n+            features.add(FeatureFactory.newTextFeature(\"f-1\", \"foo bar\"));\n+            features.add(FeatureFactory.newTextFeature(\"f-2\", \"bar foo\"));\n+            features.add(FeatureFactory.newTextFeature(\"f-3\", \"brow fox\"));\n+            features.add(FeatureFactory.newTextFeature(\"f-4\", \"lazy dog\"));\n+            features.add(FeatureFactory.newTextFeature(\"f-5\", \"money\"));\n+            PredictionInput input = new PredictionInput(features);\n+            Prediction prediction = new Prediction(input, model.predict(List.of(input)).get(0));\n+            pairs.add(Pair.of(limeExplainer.explain(prediction, model), prediction));\n+        }\n+        double v = ExplainabilityMetrics.classificationFidelity(pairs);\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+}", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2OTI2OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458769268", "bodyText": "There are no meaningful tests for this method, if this is intended to be public and exposed by the library can you add some?", "author": "r00ta", "createdAt": "2020-07-22T12:54:35Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility class providing different methods to evaluate explainability.\n+ */\n+public class ExplainabilityMetrics {\n+\n+    /**\n+     * measure the explainability of an explanation as per paper \"Towards Quantification of Explainability in Explainable\n+     * Artificial Intelligence Methods\" by Islam et al.\n+     *\n+     * @param inputCognitiveChunks  the no. of cognitive chunks (pieces of information) required to generate the\n+     *                              explanation (e.g. the no. of explanation inputs)\n+     * @param outputCognitiveChunks the no. of cognitive chunks generated within the explanation itself\n+     * @param interactionRatio      the ratio of interaction (between 0 and 1) required by the explanation\n+     * @return the quantitative explainability measure\n+     */\n+    public static double quantifyExplainability(int inputCognitiveChunks, int outputCognitiveChunks, double interactionRatio) {\n+        return inputCognitiveChunks + outputCognitiveChunks > 0 ? 0.333 / (double) inputCognitiveChunks\n+                + 0.333 / (double) outputCognitiveChunks + 0.333 * (1d - interactionRatio) : 0;\n+    }\n+\n+    /**\n+     * Calculate the impact of dropping the most important features (given by {@link Saliency#getTopFeatures(int)} from the input.\n+     * Highly important features would have rather high impact.\n+     *\n+     * @param model       the model to be explained\n+     * @param prediction  a prediction\n+     * @param topFeatures the list of important features that should be dropped\n+     * @return the saliency impact\n+     */\n+    public static double saliencyImpact(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+        String[] importantFeatureNames = topFeatures.stream().map(f -> f.getFeature().getName()).toArray(String[]::new);\n+\n+        List<Feature> newFeatures = new LinkedList<>();\n+        for (Feature feature : prediction.getInput().getFeatures()) {\n+            Feature newFeature = DataUtils.dropFeature(feature, importantFeatureNames);\n+            newFeatures.add(newFeature);\n+        }\n+        PredictionInput predictionInput = new PredictionInput(newFeatures);\n+        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n+        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        double impact = 0;\n+        double size = predictionOutput.getOutputs().size();\n+        for (int i = 0; i < size; i++) {\n+            Output original = prediction.getOutput().getOutputs().get(i);\n+            Output modified = predictionOutput.getOutputs().get(i);\n+            impact += DataUtils.euclideanDistance(new double[]{original.getScore()}, new double[]{modified.getScore()});\n+            impact += DataUtils.hammingDistance(original.getValue().asString(), modified.getValue().asString());\n+        }\n+        return impact / size;\n+    }\n+\n+    /**\n+     * calculate fidelity (accuracy) of boolean classification outputs using saliency predictor function = sign(sum(saliency.scores))\n+     * see papers:\n+     * - Guidotti Riccardo, et al. \"A survey of methods for explaining black box models.\" ACM computing surveys (2018).\n+     * - Bodria, Francesco, et al. \"Explainability Methods for Natural Language Processing: Applications to Sentiment Analysis (Discussion Paper).\"\n+     *\n+     * @param pairs pairs composed by the saliency and the related prediction\n+     * @return the fidelity accuracy\n+     */\n+    public static double classificationFidelity(List<Pair<Saliency, Prediction>> pairs) {\n+        double acc = 0;\n+        double evals = 0;\n+        for (Pair<Saliency, Prediction> pair : pairs) {\n+            Saliency saliency = pair.getLeft();\n+            Prediction prediction = pair.getRight();\n+            for (Output output : prediction.getOutput().getOutputs()) {\n+                Type type = output.getType();\n+                if (Type.BOOLEAN.equals(type)) {\n+                    double predictorOutput = saliency.getPerFeatureImportance().stream().map(FeatureImportance::getScore).mapToDouble(d -> d).sum();\n+                    double v = output.getValue().asNumber();\n+                    if ((v >= 0 && predictorOutput >= 0) || (v < 0 && predictorOutput < 0)) {\n+                        acc++;\n+                    }\n+                    evals++;\n+                }\n+            }\n+        }\n+        return evals == 0 ? 0 : acc / evals;\n+    }\n+}", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQ0NDg1Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459444852", "bodyText": "this is tested in ExplainabilityMetricsTest, I'll add more tests there and in ITs.", "author": "tteofili", "createdAt": "2020-07-23T13:23:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc2OTI2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc3MTk2Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458771962", "bodyText": "are these comparable? any link to the paper/documentation?", "author": "r00ta", "createdAt": "2020-07-22T12:59:01Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility class providing different methods to evaluate explainability.\n+ */\n+public class ExplainabilityMetrics {\n+\n+    /**\n+     * measure the explainability of an explanation as per paper \"Towards Quantification of Explainability in Explainable\n+     * Artificial Intelligence Methods\" by Islam et al.\n+     *\n+     * @param inputCognitiveChunks  the no. of cognitive chunks (pieces of information) required to generate the\n+     *                              explanation (e.g. the no. of explanation inputs)\n+     * @param outputCognitiveChunks the no. of cognitive chunks generated within the explanation itself\n+     * @param interactionRatio      the ratio of interaction (between 0 and 1) required by the explanation\n+     * @return the quantitative explainability measure\n+     */\n+    public static double quantifyExplainability(int inputCognitiveChunks, int outputCognitiveChunks, double interactionRatio) {\n+        return inputCognitiveChunks + outputCognitiveChunks > 0 ? 0.333 / (double) inputCognitiveChunks\n+                + 0.333 / (double) outputCognitiveChunks + 0.333 * (1d - interactionRatio) : 0;\n+    }\n+\n+    /**\n+     * Calculate the impact of dropping the most important features (given by {@link Saliency#getTopFeatures(int)} from the input.\n+     * Highly important features would have rather high impact.\n+     *\n+     * @param model       the model to be explained\n+     * @param prediction  a prediction\n+     * @param topFeatures the list of important features that should be dropped\n+     * @return the saliency impact\n+     */\n+    public static double saliencyImpact(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+        String[] importantFeatureNames = topFeatures.stream().map(f -> f.getFeature().getName()).toArray(String[]::new);\n+\n+        List<Feature> newFeatures = new LinkedList<>();\n+        for (Feature feature : prediction.getInput().getFeatures()) {\n+            Feature newFeature = DataUtils.dropFeature(feature, importantFeatureNames);\n+            newFeatures.add(newFeature);\n+        }\n+        PredictionInput predictionInput = new PredictionInput(newFeatures);\n+        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n+        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        double impact = 0;\n+        double size = predictionOutput.getOutputs().size();\n+        for (int i = 0; i < size; i++) {\n+            Output original = prediction.getOutput().getOutputs().get(i);\n+            Output modified = predictionOutput.getOutputs().get(i);\n+            impact += DataUtils.euclideanDistance(new double[]{original.getScore()}, new double[]{modified.getScore()});\n+            impact += DataUtils.hammingDistance(original.getValue().asString(), modified.getValue().asString());", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQ1MzUwNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459453506", "bodyText": "this is the Gower distance d_c(x_c) + lambda*d_n(x_n) (in which the lambda parameter is equals to 1) where x_c are categorical / text values whereas x_n are numeric values in an vector x holding mixed types of data.\nThe idea is to measure how far the outputs end up when you mask the most important features, if your explanation is good, most influential features will produce very different results (with respect to the original), when masked.\nI'll try to find back the link to this specific paper / literature.", "author": "tteofili", "createdAt": "2020-07-23T13:36:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc3MTk2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc3NjY4Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458776686", "bodyText": "use a do/while to remove (Double.isNaN(finalLoss) that is used just to get in the loop for the first time?", "author": "r00ta", "createdAt": "2020-07-22T13:06:54Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LinearModel.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.stream.IntStream;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A linear model implementation based on perceptron algorithm.\n+ */\n+public class LinearModel {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LinearModel.class);\n+    private static final double GOOD_LOSS_THRESHOLD = 0.1;\n+    private static final int MAX_NO_EPOCHS = 15;\n+    private static final double INITIAL_LEARNING_RATE = 0.01;\n+    private static final double DECAY_RATE = 0.01;\n+\n+    private final double[] weights;\n+    private final boolean classification;\n+    private double bias;\n+\n+    public LinearModel(int size, boolean classification) {\n+        this.bias = 0;\n+        this.weights = new double[size];\n+        this.classification = classification;\n+    }\n+\n+    public double fit(Collection<Pair<double[], Double>> trainingSet) {\n+        double[] sampleWeights = new double[trainingSet.size()];\n+        Arrays.fill(sampleWeights, 1);\n+        return fit(trainingSet, sampleWeights);\n+    }\n+\n+    public double fit(Collection<Pair<double[], Double>> trainingSet, double[] sampleWeights) {\n+        double finalLoss = Double.NaN;\n+        if (trainingSet.isEmpty()) {\n+            logger.warn(\"fitting an empty training set\");\n+        } else {\n+            double lr = INITIAL_LEARNING_RATE;\n+            int e = 0;\n+            while ((Double.isNaN(finalLoss) || finalLoss > GOOD_LOSS_THRESHOLD) && e < MAX_NO_EPOCHS) {", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQ1NDEzMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459454132", "bodyText": "no please, do/while no :)", "author": "tteofili", "createdAt": "2020-07-23T13:37:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc3NjY4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc3OTc3Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458779776", "bodyText": "the name of the method is a bit misleading, rename to checkAndHandleInfinite?", "author": "r00ta", "createdAt": "2020-07-22T13:11:51Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/LinearModel.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.stream.IntStream;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A linear model implementation based on perceptron algorithm.\n+ */\n+public class LinearModel {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LinearModel.class);\n+    private static final double GOOD_LOSS_THRESHOLD = 0.1;\n+    private static final int MAX_NO_EPOCHS = 15;\n+    private static final double INITIAL_LEARNING_RATE = 0.01;\n+    private static final double DECAY_RATE = 0.01;\n+\n+    private final double[] weights;\n+    private final boolean classification;\n+    private double bias;\n+\n+    public LinearModel(int size, boolean classification) {\n+        this.bias = 0;\n+        this.weights = new double[size];\n+        this.classification = classification;\n+    }\n+\n+    public double fit(Collection<Pair<double[], Double>> trainingSet) {\n+        double[] sampleWeights = new double[trainingSet.size()];\n+        Arrays.fill(sampleWeights, 1);\n+        return fit(trainingSet, sampleWeights);\n+    }\n+\n+    public double fit(Collection<Pair<double[], Double>> trainingSet, double[] sampleWeights) {\n+        double finalLoss = Double.NaN;\n+        if (trainingSet.isEmpty()) {\n+            logger.warn(\"fitting an empty training set\");\n+        } else {\n+            double lr = INITIAL_LEARNING_RATE;\n+            int e = 0;\n+            while ((Double.isNaN(finalLoss) || finalLoss > GOOD_LOSS_THRESHOLD) && e < MAX_NO_EPOCHS) {\n+                double loss = 0;\n+                int i = 0;\n+                for (Pair<double[], Double> sample : trainingSet) {\n+                    double[] doubles = sample.getLeft();\n+                    double predictedOutput = predict(doubles);\n+                    double targetOutput = sample.getRight();\n+                    double diff = checkFinite(targetOutput - predictedOutput);\n+                    if (diff != 0) { // avoid null updates to save computation\n+                        loss += Math.abs(diff) / trainingSet.size();\n+                        for (int j = 0; j < weights.length; j++) {\n+                            double v = lr * diff * doubles[j];\n+                            if (trainingSet.size() == sampleWeights.length) {\n+                                v *= sampleWeights[i];\n+                            }\n+                            v = checkFinite(v);\n+                            weights[j] += v;\n+                            bias += lr * diff * sampleWeights[i];\n+                        }\n+                    }\n+                    i++;\n+                }\n+                lr *= (1d / (1d + DECAY_RATE * e)); // learning rate decay\n+\n+                finalLoss = loss;\n+                e++;\n+                logger.debug(\"epoch {}, loss: {}\", e, loss);\n+            }\n+        }\n+        return finalLoss;\n+    }\n+\n+    private double checkFinite(double diff) {", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc4NTM1Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458785356", "bodyText": "Why do we need a mock here? Feature and Value do not have any real dependency to be mocked", "author": "r00ta", "createdAt": "2020-07-22T13:20:09Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability;\n+\n+import java.security.SecureRandom;\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+public class TestUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    static {\n+        random.setSeed(4);\n+    }\n+\n+    public static PredictionProvider getFeaturePassModel(int featureIndex) {\n+        return inputs -> {\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+            for (PredictionInput predictionInput : inputs) {\n+                List<Feature> features = predictionInput.getFeatures();\n+                Feature feature = features.get(featureIndex);\n+                PredictionOutput predictionOutput = new PredictionOutput(\n+                        List.of(new Output(\"feature-\" + featureIndex, feature.getType(), feature.getValue(),\n+                                           1d)));\n+                predictionOutputs.add(predictionOutput);\n+            }\n+            return predictionOutputs;\n+        };\n+    }\n+\n+    public static PredictionProvider getSumSkipModel(int skipFeatureIndex) {\n+        return inputs -> {\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+            for (PredictionInput predictionInput : inputs) {\n+                List<Feature> features = predictionInput.getFeatures();\n+                double result = 0;\n+                for (int i = 0; i < features.size(); i++) {\n+                    if (skipFeatureIndex != i) {\n+                        result += features.get(i).getValue().asNumber();\n+                    }\n+                }\n+                PredictionOutput predictionOutput = new PredictionOutput(\n+                        List.of(new Output(\"sum-but\" + skipFeatureIndex, Type.NUMBER, new Value<>(result), 1d)));\n+                predictionOutputs.add(predictionOutput);\n+            }\n+            return predictionOutputs;\n+        };\n+    }\n+\n+    public static PredictionProvider getEvenFeatureModel(int featureIndex) {\n+        return inputs -> {\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+            for (PredictionInput predictionInput : inputs) {\n+                List<Feature> features = predictionInput.getFeatures();\n+                Feature feature = features.get(featureIndex);\n+                double v = feature.getValue().asNumber();\n+                PredictionOutput predictionOutput = new PredictionOutput(\n+                        List.of(new Output(\"feature-\" + featureIndex, Type.BOOLEAN, new Value<>(v % 2 == 0), 1d)));\n+                predictionOutputs.add(predictionOutput);\n+            }\n+            return predictionOutputs;\n+        };\n+    }\n+\n+    public static PredictionProvider getEvenSumModel(int skipFeatureIndex) {\n+        return inputs -> {\n+            List<PredictionOutput> predictionOutputs = new LinkedList<>();\n+            for (PredictionInput predictionInput : inputs) {\n+                List<Feature> features = predictionInput.getFeatures();\n+                double result = 0;\n+                for (int i = 0; i < features.size(); i++) {\n+                    if (skipFeatureIndex != i) {\n+                        result += features.get(i).getValue().asNumber();\n+                    }\n+                }\n+                PredictionOutput predictionOutput = new PredictionOutput(\n+                        List.of(new Output(\"sum-even-but\" + skipFeatureIndex, Type.BOOLEAN, new Value<>(((int) result) % 2 == 0), 1d)));\n+                predictionOutputs.add(predictionOutput);\n+            }\n+            return predictionOutputs;\n+        };\n+    }\n+\n+    public static PredictionProvider getDummyTextClassifier() {\n+        return new PredictionProvider() {\n+            private final List<String> blackList = Arrays.asList(\"money\", \"$\", \"\u00a3\", \"bitcoin\");\n+\n+            @Override\n+            public List<PredictionOutput> predict(List<PredictionInput> inputs) {\n+                List<PredictionOutput> outputs = new LinkedList<>();\n+                for (PredictionInput input : inputs) {\n+                    boolean spam = false;\n+                    for (Feature f : input.getFeatures()) {\n+                        if (!spam && Type.TEXT.equals(f.getType())) {\n+                            String s = f.getValue().asString();\n+                            String[] words = s.split(\" \");\n+                            for (String w : words) {\n+                                if (blackList.contains(w)) {\n+                                    spam = true;\n+                                    break;\n+                                }\n+                            }\n+                        }\n+                    }\n+                    Output output = new Output(\"spam\", Type.BOOLEAN, new Value<>(spam), 1d);\n+                    outputs.add(new PredictionOutput(List.of(output)));\n+                }\n+                return outputs;\n+            }\n+        };\n+    }\n+\n+    public static Feature getMockedNumericFeature() {\n+        return getMockedNumericFeature(1d);\n+    }\n+\n+    public static Feature getMockedTextFeature(String s) {\n+        Feature f = mock(Feature.class);\n+        when(f.getType()).thenReturn(Type.TEXT);\n+        when(f.getName()).thenReturn(\"f-text\");\n+        Value<String> value = mock(Value.class);\n+        when(value.getUnderlyingObject()).thenReturn(s);\n+        when(value.asNumber()).thenReturn(Double.NaN);\n+        when(value.asString()).thenReturn(s);\n+        when(f.getValue()).thenReturn(value);\n+        return f;\n+    }\n+\n+    public static Feature getMockedNumericFeature(double d) {\n+        Feature f = mock(Feature.class);\n+        when(f.getType()).thenReturn(Type.NUMBER);\n+        when(f.getName()).thenReturn(\"f-num\");\n+        Value<Double> value = mock(Value.class);\n+        when(value.getUnderlyingObject()).thenReturn(d);\n+        when(value.asNumber()).thenReturn(d);\n+        when(value.asString()).thenReturn(String.valueOf(d));\n+        when(f.getValue()).thenReturn(value);\n+        return f;\n+    }", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQ1NjA5MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459456090", "bodyText": "in order to avoid depending on FeatureFactory which may have bugs itself.", "author": "tteofili", "createdAt": "2020-07-23T13:39:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc4NTM1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc4NzI5MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458787290", "bodyText": "why these checks?", "author": "r00ta", "createdAt": "2020-07-22T13:22:51Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputRegression() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQ1NzE2Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459457162", "bodyText": "because that particular model simply lets one fixed input feature be passed as the output, all other features should have way low importance, when compared with the top one.", "author": "tteofili", "createdAt": "2020-07-23T13:41:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc4NzI5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc4ODY4OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458788688", "bodyText": "This is false only if an exception is raised. Is this what was intended to be checked?", "author": "r00ta", "createdAt": "2020-07-22T13:24:53Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputRegression() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testUnusedFeatureRegression() {\n+        int idx = 2;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 10));\n+        PredictionProvider model = TestUtils.getSumSkipModel(idx);\n+        PredictionInput input = new PredictionInput(features);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> perFeatureImportance = saliency.getPerFeatureImportance();\n+\n+        perFeatureImportance.sort((t1, t2) -> (int) (t2.getScore() - t1.getScore()));\n+        assertTrue(perFeatureImportance.get(0).getScore() > 0);\n+        assertTrue(perFeatureImportance.get(1).getScore() > 0);\n+        assertEquals(features.get(idx).getName(), perFeatureImportance.get(2).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc4ODg1NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458788855", "bodyText": "same as above", "author": "r00ta", "createdAt": "2020-07-22T13:25:06Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputRegression() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testUnusedFeatureRegression() {\n+        int idx = 2;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 10));\n+        PredictionProvider model = TestUtils.getSumSkipModel(idx);\n+        PredictionInput input = new PredictionInput(features);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> perFeatureImportance = saliency.getPerFeatureImportance();\n+\n+        perFeatureImportance.sort((t1, t2) -> (int) (t2.getScore() - t1.getScore()));\n+        assertTrue(perFeatureImportance.get(0).getScore() > 0);\n+        assertTrue(perFeatureImportance.get(1).getScore() > 0);\n+        assertEquals(features.get(idx).getName(), perFeatureImportance.get(2).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputClassification() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 3));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 2));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 7));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getEvenFeatureModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getPositiveFeatures(1);\n+        assertFalse(topFeatures.isEmpty());\n+        assertEquals(features.get(idx).getName(), topFeatures.get(0).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc4ODk0OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458788949", "bodyText": "same as above", "author": "r00ta", "createdAt": "2020-07-22T13:25:12Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputRegression() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testUnusedFeatureRegression() {\n+        int idx = 2;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 10));\n+        PredictionProvider model = TestUtils.getSumSkipModel(idx);\n+        PredictionInput input = new PredictionInput(features);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> perFeatureImportance = saliency.getPerFeatureImportance();\n+\n+        perFeatureImportance.sort((t1, t2) -> (int) (t2.getScore() - t1.getScore()));\n+        assertTrue(perFeatureImportance.get(0).getScore() > 0);\n+        assertTrue(perFeatureImportance.get(1).getScore() > 0);\n+        assertEquals(features.get(idx).getName(), perFeatureImportance.get(2).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputClassification() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 3));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 2));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 7));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getEvenFeatureModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getPositiveFeatures(1);\n+        assertFalse(topFeatures.isEmpty());\n+        assertEquals(features.get(idx).getName(), topFeatures.get(0).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testTextSpamClassification() {\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newTextFeature(\"f1\",\"we go here and there\"));\n+        features.add(FeatureFactory.newTextFeature(\"f2\", \"please give me some money\"));\n+        features.add(FeatureFactory.newTextFeature(\"f3\", \"dear friend, please reply\"));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getDummyTextClassifier();\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getPositiveFeatures(1);\n+        assertEquals(\"money (f2)\", topFeatures.get(0).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc4OTA0NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458789044", "bodyText": "same as above", "author": "r00ta", "createdAt": "2020-07-22T13:25:20Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputRegression() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testUnusedFeatureRegression() {\n+        int idx = 2;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 10));\n+        PredictionProvider model = TestUtils.getSumSkipModel(idx);\n+        PredictionInput input = new PredictionInput(features);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> perFeatureImportance = saliency.getPerFeatureImportance();\n+\n+        perFeatureImportance.sort((t1, t2) -> (int) (t2.getScore() - t1.getScore()));\n+        assertTrue(perFeatureImportance.get(0).getScore() > 0);\n+        assertTrue(perFeatureImportance.get(1).getScore() > 0);\n+        assertEquals(features.get(idx).getName(), perFeatureImportance.get(2).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputClassification() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 3));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 2));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 7));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getEvenFeatureModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getPositiveFeatures(1);\n+        assertFalse(topFeatures.isEmpty());\n+        assertEquals(features.get(idx).getName(), topFeatures.get(0).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testTextSpamClassification() {\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newTextFeature(\"f1\",\"we go here and there\"));\n+        features.add(FeatureFactory.newTextFeature(\"f2\", \"please give me some money\"));\n+        features.add(FeatureFactory.newTextFeature(\"f3\", \"dear friend, please reply\"));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getDummyTextClassifier();\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getPositiveFeatures(1);\n+        assertEquals(\"money (f2)\", topFeatures.get(0).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThanOrEqualTo(0);\n+    }\n+\n+    @Test\n+    void testUnusedFeatureClassification() {\n+        int idx = 2;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\",6));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\",3));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\",5));\n+        PredictionProvider model = TestUtils.getEvenSumModel(idx);\n+        PredictionInput input = new PredictionInput(features);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> perFeatureImportance = saliency.getNegativeFeatures(3);\n+        assertFalse(perFeatureImportance.stream().map(fi -> fi.getFeature().getName()).collect(Collectors.toList()).contains(features.get(idx).getName()));\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getNegativeFeatures(2));\n+        assertThat(v).isGreaterThanOrEqualTo(0);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5MDkzMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458790930", "bodyText": "These POJOs do not have any business logic, is there a specific reason why mock is used?", "author": "r00ta", "createdAt": "2020-07-22T13:28:07Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.mockito.Mockito.mock;\n+\n+class LimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.seed(4);\n+    }\n+\n+    @Test\n+    void testEmptyPrediction() {\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        PredictionOutput output = mock(PredictionOutput.class);\n+        PredictionInput input = mock(PredictionInput.class);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTUwODQ0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459508446", "bodyText": "to avoid unnecessary boiler plate code as this is a test for an empty prediction.", "author": "tteofili", "createdAt": "2020-07-23T14:50:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5MDkzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5Mjg4Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458792887", "bodyText": "capital", "author": "r00ta", "createdAt": "2020-07-22T13:30:58Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/Output.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.model;\n+\n+/**\n+ * A single output/decision value generated by a {@link PredictionProvider} and incorporated in a {@link PredictionOutput}.\n+ */\n+public class Output {\n+\n+    private final Value value;\n+    private final Type type;\n+    private final double score;\n+    private final String name;\n+\n+    public Output(String name, Type type, Value value, double score) {\n+        this.name = name;\n+        this.value = value;\n+        this.type = type;\n+        this.score = score;\n+    }\n+\n+    /**\n+     * get the output name", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5NTQxMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458795411", "bodyText": "Is it possible to set the seed here so that the test is somehow deterministic? As @jiripetrlik suggested, It might be good to test with different seeds.\nThe same for all the following tests", "author": "r00ta", "createdAt": "2020-07-22T13:34:45Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/DataUtilsTest.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+class DataUtilsTest {\n+\n+    @Test\n+    public void testDataGeneration() {\n+        double mean = 0.5;\n+        double stdDeviation = 0.1;\n+        int size = 100;\n+        double[] data = DataUtils.generateData(mean, stdDeviation, size);\n+        // check the sum of deviations from mean is zero\n+        double sum = 0;\n+        for (double d : data) {\n+            sum += d - mean;\n+        }\n+        assertEquals(0, sum, 1e-4);\n+    }", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTUxMTg4Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459511886", "bodyText": "I've opened FAI-237 for this and other tests requiring test with multiple different seeds.", "author": "tteofili", "createdAt": "2020-07-23T14:54:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5NTQxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5NzU3Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458797573", "bodyText": "Isnt't' always true (if there are no Exceptions)?", "author": "r00ta", "createdAt": "2020-07-22T13:37:45Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/LinearModelTest.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class LinearModelTest {\n+\n+    @Test\n+    void testEmptyFitClassificationDoesNothing() {\n+        int size = 10;\n+        LinearModel linearModel = new LinearModel(size, true);\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        linearModel.fit(trainingSet);\n+        assertEquals(Arrays.toString(new double[size]), Arrays.toString(linearModel.getWeights()));\n+    }\n+\n+    @Test\n+    void testEmptyFitRegressionDoesNothing() {\n+        int size = 10;\n+        LinearModel linearModel = new LinearModel(size, false);\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        linearModel.fit(trainingSet);\n+        assertEquals(Arrays.toString(new double[size]), Arrays.toString(linearModel.getWeights()));\n+    }\n+\n+    @Test\n+    void testRegressionFit() {\n+        int size = 10;\n+        LinearModel linearModel = new LinearModel(size, false);\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        for (int i = 0; i < 100; i++) {\n+            double[] x = new double[size];\n+            for (int j = 0; j < size; j++) {\n+                x[j] = (double) i / (1d * j + i);\n+            }\n+            Double y = DoubleStream.of(x).sum();\n+            trainingSet.add(new ImmutablePair<>(x, y));\n+        }\n+        assertThat(linearModel.fit(trainingSet)).isLessThan(1d);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTUxMzM1NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r459513354", "bodyText": "nope, this happens also with an empty dataset, and I think it is good to define the expectation here, regardless of the actual implementation internal behaviour.", "author": "tteofili", "createdAt": "2020-07-23T14:56:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5NzU3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODc5NzY2NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458797665", "bodyText": "Isnt't' always true (if there are no Exceptions)?", "author": "r00ta", "createdAt": "2020-07-22T13:37:52Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/LinearModelTest.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class LinearModelTest {\n+\n+    @Test\n+    void testEmptyFitClassificationDoesNothing() {\n+        int size = 10;\n+        LinearModel linearModel = new LinearModel(size, true);\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        linearModel.fit(trainingSet);\n+        assertEquals(Arrays.toString(new double[size]), Arrays.toString(linearModel.getWeights()));\n+    }\n+\n+    @Test\n+    void testEmptyFitRegressionDoesNothing() {\n+        int size = 10;\n+        LinearModel linearModel = new LinearModel(size, false);\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        linearModel.fit(trainingSet);\n+        assertEquals(Arrays.toString(new double[size]), Arrays.toString(linearModel.getWeights()));\n+    }\n+\n+    @Test\n+    void testRegressionFit() {\n+        int size = 10;\n+        LinearModel linearModel = new LinearModel(size, false);\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        for (int i = 0; i < 100; i++) {\n+            double[] x = new double[size];\n+            for (int j = 0; j < size; j++) {\n+                x[j] = (double) i / (1d * j + i);\n+            }\n+            Double y = DoubleStream.of(x).sum();\n+            trainingSet.add(new ImmutablePair<>(x, y));\n+        }\n+        assertThat(linearModel.fit(trainingSet)).isLessThan(1d);\n+    }\n+\n+    @Test\n+    void testClassificationFit() {\n+        int size = 10;\n+        LinearModel linearModel = new LinearModel(size, true);\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        for (int i = 0; i < 100; i++) {\n+            double[] x = new double[size];\n+            for (int j = 0; j < size; j++) {\n+                x[j] = (double) i / (1d * j + i);\n+            }\n+            Double y = i % 2 == 0 ? 1d : 0d;\n+            trainingSet.add(new ImmutablePair<>(x, y));\n+        }\n+        assertThat(linearModel.fit(trainingSet)).isLessThan(1d);", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODgwNTA3Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r458805073", "bodyText": "Add a link to documentation?", "author": "r00ta", "createdAt": "2020-07-22T13:48:11Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.global.pdp;\n+\n+import java.util.Collection;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.kie.kogito.explainability.global.GlobalExplainer;\n+import org.kie.kogito.explainability.global.GlobalExplanationException;\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PartialDependenceGraph;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.PredictionProviderMetadata;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Generates the partial dependence plot for a given feature.\n+ * While a strict PD implementation would need the whole training set used to train the model, this implementation seeks\n+ * to reproduce an approximate version of the training data by means of data distribution information (min, max, mean,\n+ * stdDev).\n+ */\n+public class PartialDependencePlotExplainer implements GlobalExplainer<Collection<PartialDependenceGraph>> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(PartialDependencePlotExplainer.class);\n+    public static final int DEFAULT_SERIES_LENGTH = 100;\n+\n+    private final int seriesLength;\n+\n+    /**\n+     * Create a PDP provider.\n+     *\n+     * @param seriesLength the no. of data points sampled for each given feature.\n+     */\n+    public PartialDependencePlotExplainer(int seriesLength) {\n+        this.seriesLength = seriesLength;\n+    }\n+\n+    /**\n+     * Create a PDP provider.\n+     *\n+     * Each feature is sampled {@code DEFAULT_SERIES_LENGTH} times.\n+     */\n+    public PartialDependencePlotExplainer() {\n+        this(DEFAULT_SERIES_LENGTH);\n+    }\n+\n+    @Override\n+    public Collection<PartialDependenceGraph> explain(PredictionProvider model, PredictionProviderMetadata metadata) {", "originalCommit": "88868b312f67fe6762462735aa1b95dcaf144c69", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2994a0cafc4166e7eb5bfc95b7c14fafa24eca8e", "url": "https://github.com/kiegroup/kogito-apps/commit/2994a0cafc4166e7eb5bfc95b7c14fafa24eca8e", "message": "KOGITO-2750 - guard vs empty inputs / features", "committedDate": "2020-07-22T14:11:57Z", "type": "commit"}, {"oid": "341f9a394afcff1583c3c6bb4cc8ed05cf9a276f", "url": "https://github.com/kiegroup/kogito-apps/commit/341f9a394afcff1583c3c6bb4cc8ed05cf9a276f", "message": "KOGITO-2750 - guard vs empty inputs / features", "committedDate": "2020-07-22T14:17:51Z", "type": "commit"}, {"oid": "7a2f48bf1efe175ed62c750d21376570e42a7fd8", "url": "https://github.com/kiegroup/kogito-apps/commit/7a2f48bf1efe175ed62c750d21376570e42a7fd8", "message": "KOGITO-2750 - make no of retries in LE configurable", "committedDate": "2020-07-22T15:19:31Z", "type": "commit"}, {"oid": "228190790fc4b8db2ba9ca800a0054e4855df22f", "url": "https://github.com/kiegroup/kogito-apps/commit/228190790fc4b8db2ba9ca800a0054e4855df22f", "message": "KOGITO-2750 - avoid useless addAll calls when datasets is not separable", "committedDate": "2020-07-22T15:23:15Z", "type": "commit"}, {"oid": "cd9e18d2414f68bccdd41457bbb3f39fa7bc9b2d", "url": "https://github.com/kiegroup/kogito-apps/commit/cd9e18d2414f68bccdd41457bbb3f39fa7bc9b2d", "message": "KOGITO-2750 - refactored dataset separation cycle in LE", "committedDate": "2020-07-23T06:44:12Z", "type": "commit"}, {"oid": "6e77a78d404c732cfa611d7585fc20498d344a94", "url": "https://github.com/kiegroup/kogito-apps/commit/6e77a78d404c732cfa611d7585fc20498d344a94", "message": "KOGITO-2750 - updating weights in a stream", "committedDate": "2020-07-23T06:45:57Z", "type": "commit"}, {"oid": "3af462e072a6bc96d1d0e0a8363ea630bd0812b9", "url": "https://github.com/kiegroup/kogito-apps/commit/3af462e072a6bc96d1d0e0a8363ea630bd0812b9", "message": "KOGITO-2750 - moved sigma to a constant in SW", "committedDate": "2020-07-23T06:46:30Z", "type": "commit"}, {"oid": "d3574f4bf385b9fa863e9e12abb569004e537ce7", "url": "https://github.com/kiegroup/kogito-apps/commit/d3574f4bf385b9fa863e9e12abb569004e537ce7", "message": "KOGITO-2750 - capital letter in Feature javadoc", "committedDate": "2020-07-23T06:46:58Z", "type": "commit"}, {"oid": "a56c02493d267bff6c9adf52d1b335e19cca2cf1", "url": "https://github.com/kiegroup/kogito-apps/commit/a56c02493d267bff6c9adf52d1b335e19cca2cf1", "message": "KOGITO-2750 - capital letter in FeatureDistribution javadoc", "committedDate": "2020-07-23T06:47:22Z", "type": "commit"}, {"oid": "cbdfe14443aa9877059bf424d4a3e3eb76c1750d", "url": "https://github.com/kiegroup/kogito-apps/commit/cbdfe14443aa9877059bf424d4a3e3eb76c1750d", "message": "KOGITO-2750 - added test for composite feature creation, some refactoring", "committedDate": "2020-07-23T07:27:02Z", "type": "commit"}, {"oid": "bafeee8355d7babe642660dc6f73492bf287dc3e", "url": "https://github.com/kiegroup/kogito-apps/commit/bafeee8355d7babe642660dc6f73492bf287dc3e", "message": "KOGITO-2750 - capital letter javadoc fix", "committedDate": "2020-07-23T07:28:40Z", "type": "commit"}, {"oid": "a70179516f49f36d0bde8c22b9a3d52d04cc2d7b", "url": "https://github.com/kiegroup/kogito-apps/commit/a70179516f49f36d0bde8c22b9a3d52d04cc2d7b", "message": "KOGITO-2750 - capital letter javadoc fix", "committedDate": "2020-07-23T07:28:58Z", "type": "commit"}, {"oid": "d48a7a40cdd0653e8db2e34f10feb4942319c76e", "url": "https://github.com/kiegroup/kogito-apps/commit/d48a7a40cdd0653e8db2e34f10feb4942319c76e", "message": "KOGITO-2750 - drop generic try/catch(Exception) blocks in PDPE e LE", "committedDate": "2020-07-23T09:36:11Z", "type": "commit"}, {"oid": "25e2a285a0bd54aa6f6f0d5c29b37e5bfa62c1f6", "url": "https://github.com/kiegroup/kogito-apps/commit/25e2a285a0bd54aa6f6f0d5c29b37e5bfa62c1f6", "message": "KOGITO-2750 - improved Value#asVector logic, added ValueTest", "committedDate": "2020-07-23T10:47:18Z", "type": "commit"}, {"oid": "4f03e62298652de3d667d8924365e133b07eef83", "url": "https://github.com/kiegroup/kogito-apps/commit/4f03e62298652de3d667d8924365e133b07eef83", "message": "KOGITO-2750 - DU#seed to DU#setSeed", "committedDate": "2020-07-23T10:47:49Z", "type": "commit"}, {"oid": "0d6a82f0cd3c2a2fa394a7561502d311c66d8057", "url": "https://github.com/kiegroup/kogito-apps/commit/0d6a82f0cd3c2a2fa394a7561502d311c66d8057", "message": "KOGITO-2750 - minor fixes in DU", "committedDate": "2020-07-23T10:52:34Z", "type": "commit"}, {"oid": "3921698f52ea0a6e18d6ef0596b67a5e5afecde6", "url": "https://github.com/kiegroup/kogito-apps/commit/3921698f52ea0a6e18d6ef0596b67a5e5afecde6", "message": "KOGITO-2750 - minor fixes in DU", "committedDate": "2020-07-23T10:53:21Z", "type": "commit"}, {"oid": "e7d6a18c20090fbd5aab7f09959d6620433da22d", "url": "https://github.com/kiegroup/kogito-apps/commit/e7d6a18c20090fbd5aab7f09959d6620433da22d", "message": "KOGITO-2750 - improved Value#asVector logic, added ValueTest", "committedDate": "2020-07-23T11:13:22Z", "type": "commit"}, {"oid": "512ed7ffaa2e2016219d14cb19a52947a90bf0be", "url": "https://github.com/kiegroup/kogito-apps/commit/512ed7ffaa2e2016219d14cb19a52947a90bf0be", "message": "KOGITO-2750 - fixed bug in text perturbation, add more tests", "committedDate": "2020-07-23T11:35:34Z", "type": "commit"}, {"oid": "b1db70429cb13fe758cd008d89949cd0ff890b4a", "url": "https://github.com/kiegroup/kogito-apps/commit/b1db70429cb13fe758cd008d89949cd0ff890b4a", "message": "KOGITO-2750 - minor fix in the comment", "committedDate": "2020-07-23T11:38:05Z", "type": "commit"}, {"oid": "bb6b4fa37bca37bdf5e0f20a79b069413a9c3e74", "url": "https://github.com/kiegroup/kogito-apps/commit/bb6b4fa37bca37bdf5e0f20a79b069413a9c3e74", "message": "KOGITO-2750 - renaming a couple of variables", "committedDate": "2020-07-23T11:39:32Z", "type": "commit"}, {"oid": "8f209f8c2bf8996eccf375f302189e8fc1a8eac1", "url": "https://github.com/kiegroup/kogito-apps/commit/8f209f8c2bf8996eccf375f302189e8fc1a8eac1", "message": "KOGITO-2750 - dropped Arrays#binarySearch in favor of Collection#contains", "committedDate": "2020-07-23T11:52:26Z", "type": "commit"}, {"oid": "cce247cb0c19f21ff61c7c03b2851664fce4308e", "url": "https://github.com/kiegroup/kogito-apps/commit/cce247cb0c19f21ff61c7c03b2851664fce4308e", "message": "KOGITO-2750 - fixed vector perturbation strategy", "committedDate": "2020-07-23T11:59:23Z", "type": "commit"}, {"oid": "e49c99ac91650d2611873433f1985397d8a27982", "url": "https://github.com/kiegroup/kogito-apps/commit/e49c99ac91650d2611873433f1985397d8a27982", "message": "KOGITO-2750 - hamming distnace between diff length inputs should return NaN", "committedDate": "2020-07-23T12:46:55Z", "type": "commit"}, {"oid": "32d51f2b59968b868a549d3a8c5e7a517b5ddc98", "url": "https://github.com/kiegroup/kogito-apps/commit/32d51f2b59968b868a549d3a8c5e7a517b5ddc98", "message": "KOGITO-2750 - make the noOfSamples configurable in rand distr generation", "committedDate": "2020-07-23T12:50:18Z", "type": "commit"}, {"oid": "754ad069b24d7f55951ebd17538619bd5537d3fa", "url": "https://github.com/kiegroup/kogito-apps/commit/754ad069b24d7f55951ebd17538619bd5537d3fa", "message": "KOGITO-2750 - added more tests to feature linearization", "committedDate": "2020-07-23T13:09:41Z", "type": "commit"}, {"oid": "08731b596e011ddbdab28f56cb6d212ce4aad832", "url": "https://github.com/kiegroup/kogito-apps/commit/08731b596e011ddbdab28f56cb6d212ce4aad832", "message": "KOGITO-2750 - added more tests to feature linearization", "committedDate": "2020-07-23T13:15:43Z", "type": "commit"}, {"oid": "41b87f8141b9f12debb56aa2bf320f935b034feb", "url": "https://github.com/kiegroup/kogito-apps/commit/41b87f8141b9f12debb56aa2bf320f935b034feb", "message": "KOGITO-2750 - javadoc starting with capital letter", "committedDate": "2020-07-23T13:16:26Z", "type": "commit"}, {"oid": "eb46c7cbcba63486bfeb5a92411a4c91f0c8bbec", "url": "https://github.com/kiegroup/kogito-apps/commit/eb46c7cbcba63486bfeb5a92411a4c91f0c8bbec", "message": "KOGITO-2750 - tests for fidelity metric", "committedDate": "2020-07-23T13:24:04Z", "type": "commit"}, {"oid": "eae0b9a8987ba0c537c39165ea70b2ecf862ef92", "url": "https://github.com/kiegroup/kogito-apps/commit/eae0b9a8987ba0c537c39165ea70b2ecf862ef92", "message": "KOGITO-2750 - fixed featureDrop impl, adjusted some tests", "committedDate": "2020-07-23T14:48:51Z", "type": "commit"}, {"oid": "7e1bb069bf22173b06e8f45d4e5ce7df2efd9eff", "url": "https://github.com/kiegroup/kogito-apps/commit/7e1bb069bf22173b06e8f45d4e5ce7df2efd9eff", "message": "KOGITO-2750 - capital lettere in javadoc fix", "committedDate": "2020-07-23T14:50:49Z", "type": "commit"}, {"oid": "ca8f52c54a03d4b28a2a6a3b0efadc21e2bf911b", "url": "https://github.com/kiegroup/kogito-apps/commit/ca8f52c54a03d4b28a2a6a3b0efadc21e2bf911b", "message": "KOGITO-2750 - added seed in DUTest", "committedDate": "2020-07-23T14:52:35Z", "type": "commit"}, {"oid": "2a1ec3b364e9b5693dcf82e01a77a43dc0e9dc94", "url": "https://github.com/kiegroup/kogito-apps/commit/2a1ec3b364e9b5693dcf82e01a77a43dc0e9dc94", "message": "KOGITO-2750 - added link to PDP chapter in javadoc", "committedDate": "2020-07-23T14:57:55Z", "type": "commit"}, {"oid": "eafa209c412990ae1a899527f473962264d05217", "url": "https://github.com/kiegroup/kogito-apps/commit/eafa209c412990ae1a899527f473962264d05217", "message": "KOGITO-2750 - minor fix in perturb switch", "committedDate": "2020-07-23T14:59:51Z", "type": "commit"}, {"oid": "1cbd7127fb5fe806c0dbfe61ff95705be18fcf68", "url": "https://github.com/kiegroup/kogito-apps/commit/1cbd7127fb5fe806c0dbfe61ff95705be18fcf68", "message": "KOGITO-2750 - minor fixes", "committedDate": "2020-07-23T15:08:20Z", "type": "commit"}, {"oid": "e289999c51c23215152de8bfbb3899f15036c43c", "url": "https://github.com/kiegroup/kogito-apps/commit/e289999c51c23215152de8bfbb3899f15036c43c", "message": "KOGITO-2750 - minor fixes to fidelity tests", "committedDate": "2020-07-27T09:58:35Z", "type": "commit"}, {"oid": "706a1924b6bfa7e4fe52874aefcf310f78b00247", "url": "https://github.com/kiegroup/kogito-apps/commit/706a1924b6bfa7e4fe52874aefcf310f78b00247", "message": "Merge branch 'master' of github.com:kiegroup/kogito-apps into KOGITO-2750", "committedDate": "2020-07-27T10:01:51Z", "type": "commit"}, {"oid": "66d84b9dd89b877079f18873a097fa3522365b9a", "url": "https://github.com/kiegroup/kogito-apps/commit/66d84b9dd89b877079f18873a097fa3522365b9a", "message": "KOGITO-2750 - int * int to double conversion fix", "committedDate": "2020-07-27T14:31:40Z", "type": "commit"}, {"oid": "83499bafd46b612d933c31b8e2dd7355b3c71508", "url": "https://github.com/kiegroup/kogito-apps/commit/83499bafd46b612d933c31b8e2dd7355b3c71508", "message": "KOGITO-2750 - moved explainability-core deps use version from kogito-bom", "committedDate": "2020-07-27T15:01:00Z", "type": "commit"}, {"oid": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "url": "https://github.com/kiegroup/kogito-apps/commit/8ab120a13b777f71f58bbebefcfbc12d81d98483", "message": "KOGITO-2750 - dropped useless ctcr in LEException", "committedDate": "2020-07-27T15:01:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwMDY1Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461400656", "bodyText": "A comment on the type handling: at the moment in some parts of the pull request there are some logics around the types. All those logics are handled with a switch statement: I think that it would be much much easier to read and expecially maintain if we go for a strategy pattern. If a new type comes in, we just add a class instead of adding a case in all the switches (with the risk of missing some of them).\nSince this pr is big and the refactoring might not be trivial, we might do that in another ticket if you @tteofili @danielezonca @jiripetrlik think it makes sense.", "author": "r00ta", "createdAt": "2020-07-28T08:15:02Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * Get the input and output predictions transformed into a numerical training set.\n+     *\n+     * @return a numerical training set\n+     */\n+    List<Pair<double[], Double>> getEncodedTrainingSet() {\n+        List<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        List<List<Double>> columnData;\n+        List<PredictionInput> flatInputs = DataUtils.linearizeInputs(perturbedInputs);\n+        if (!flatInputs.isEmpty() && !predictedOutputs.isEmpty() && !targetInput.getFeatures().isEmpty() && originalOutput != null) {\n+            columnData = getColumnData(flatInputs);\n+\n+            int pi = 0;\n+            for (Output output : predictedOutputs) {\n+                double[] x = new double[columnData.size()];\n+                int i = 0;\n+                for (List<Double> column : columnData) {\n+                    x[i] = column.get(pi);\n+                    i++;\n+                }\n+                double y;\n+                if (Type.NUMBER.equals(originalOutput.getType()) || Type.BOOLEAN.equals(originalOutput.getType())) {\n+                    y = output.getValue().asNumber();\n+                } else {\n+                    Object originalObject = originalOutput.getValue().getUnderlyingObject();\n+                    Object outputObject = output.getValue().getUnderlyingObject();\n+                    if (originalObject == null || outputObject == null) {\n+                        y = originalObject == outputObject ? 1d : 0d;\n+                    } else {\n+                        y = originalObject.equals(outputObject) ? 1d : 0d;\n+                    }\n+                }\n+                Pair<double[], Double> sample = new ImmutablePair<>(x, y);\n+                trainingSet.add(sample);\n+\n+                pi++;\n+            }\n+        }\n+        return trainingSet;\n+    }\n+\n+    private List<List<Double>> getColumnData(List<PredictionInput> perturbedInputs) {\n+        List<List<Double>> columnData = new LinkedList<>();\n+\n+        for (int t = 0; t < targetInput.getFeatures().size(); t++) {\n+            Feature originalFeature = targetInput.getFeatures().get(t);\n+            switch (originalFeature.getType()) {\n+                case NUMBER:\n+                    encodeNumbers(perturbedInputs, targetInput, columnData, t);\n+                    break;\n+                case TEXT:\n+                    encodeText(perturbedInputs, columnData, originalFeature);\n+                    break;\n+                case CATEGORICAL:\n+                case BINARY:\n+                case TIME:\n+                case URI:\n+                case DURATION:\n+                case VECTOR:\n+                case CURRENCY:\n+                case UNDEFINED:\n+                    encodeEquals(perturbedInputs, columnData, t, originalFeature);\n+                    break;\n+                case BOOLEAN:\n+                    // boolean are automatically encoded as 1s or 0s\n+                    List<Double> featureValues = new LinkedList<>();\n+                    for (PredictionInput pi : perturbedInputs) {\n+                        featureValues.add(pi.getFeatures().get(t).getValue().asNumber());\n+                    }\n+                    columnData.add(featureValues);\n+                    break;\n+            }", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQ3MDExMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461470110", "bodyText": "sure, that's what I proposed as well in another comment above, I've created FAI-238 to track that.", "author": "tteofili", "createdAt": "2020-07-28T10:09:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwMDY1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwMTIwMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461401202", "bodyText": "Add default case and handle the unsupported case?", "author": "r00ta", "createdAt": "2020-07-28T08:16:00Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * Get the input and output predictions transformed into a numerical training set.\n+     *\n+     * @return a numerical training set\n+     */\n+    List<Pair<double[], Double>> getEncodedTrainingSet() {\n+        List<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        List<List<Double>> columnData;\n+        List<PredictionInput> flatInputs = DataUtils.linearizeInputs(perturbedInputs);\n+        if (!flatInputs.isEmpty() && !predictedOutputs.isEmpty() && !targetInput.getFeatures().isEmpty() && originalOutput != null) {\n+            columnData = getColumnData(flatInputs);\n+\n+            int pi = 0;\n+            for (Output output : predictedOutputs) {\n+                double[] x = new double[columnData.size()];\n+                int i = 0;\n+                for (List<Double> column : columnData) {\n+                    x[i] = column.get(pi);\n+                    i++;\n+                }\n+                double y;\n+                if (Type.NUMBER.equals(originalOutput.getType()) || Type.BOOLEAN.equals(originalOutput.getType())) {\n+                    y = output.getValue().asNumber();\n+                } else {\n+                    Object originalObject = originalOutput.getValue().getUnderlyingObject();\n+                    Object outputObject = output.getValue().getUnderlyingObject();\n+                    if (originalObject == null || outputObject == null) {\n+                        y = originalObject == outputObject ? 1d : 0d;\n+                    } else {\n+                        y = originalObject.equals(outputObject) ? 1d : 0d;\n+                    }\n+                }\n+                Pair<double[], Double> sample = new ImmutablePair<>(x, y);\n+                trainingSet.add(sample);\n+\n+                pi++;\n+            }\n+        }\n+        return trainingSet;\n+    }\n+\n+    private List<List<Double>> getColumnData(List<PredictionInput> perturbedInputs) {\n+        List<List<Double>> columnData = new LinkedList<>();\n+\n+        for (int t = 0; t < targetInput.getFeatures().size(); t++) {\n+            Feature originalFeature = targetInput.getFeatures().get(t);\n+            switch (originalFeature.getType()) {\n+                case NUMBER:\n+                    encodeNumbers(perturbedInputs, targetInput, columnData, t);\n+                    break;\n+                case TEXT:\n+                    encodeText(perturbedInputs, columnData, originalFeature);\n+                    break;\n+                case CATEGORICAL:\n+                case BINARY:\n+                case TIME:\n+                case URI:\n+                case DURATION:\n+                case VECTOR:\n+                case CURRENCY:\n+                case UNDEFINED:\n+                    encodeEquals(perturbedInputs, columnData, t, originalFeature);\n+                    break;\n+                case BOOLEAN:\n+                    // boolean are automatically encoded as 1s or 0s\n+                    List<Double> featureValues = new LinkedList<>();\n+                    for (PredictionInput pi : perturbedInputs) {\n+                        featureValues.add(pi.getFeatures().get(t).getValue().asNumber());\n+                    }\n+                    columnData.add(featureValues);\n+                    break;", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwMTgxNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461401816", "bodyText": "move threshold to constant?", "author": "r00ta", "createdAt": "2020-07-28T08:17:03Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/DatasetEncoder.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.apache.commons.lang3.tuple.ImmutablePair;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+\n+/**\n+ * Encoder algorithm to transform perturbed inputs and outputs into a training set that the {@link LinearModel} can use.\n+ * The target inputs and output are needed in order to distinguish when the value of a certain feature corresponds or\n+ * is close to the one of the prediction to be explained.\n+ */\n+class DatasetEncoder {\n+\n+    private final List<PredictionInput> perturbedInputs;\n+    private final List<Output> predictedOutputs;\n+    private final PredictionInput targetInput;\n+    private final Output originalOutput;\n+\n+    DatasetEncoder(List<PredictionInput> perturbedInputs, List<Output> perturbedOutputs,\n+                   PredictionInput targetInput, Output targetOutput) {\n+        this.perturbedInputs = perturbedInputs;\n+        this.predictedOutputs = perturbedOutputs;\n+        this.targetInput = targetInput;\n+        this.originalOutput = targetOutput;\n+    }\n+\n+    /**\n+     * Get the input and output predictions transformed into a numerical training set.\n+     *\n+     * @return a numerical training set\n+     */\n+    List<Pair<double[], Double>> getEncodedTrainingSet() {\n+        List<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        List<List<Double>> columnData;\n+        List<PredictionInput> flatInputs = DataUtils.linearizeInputs(perturbedInputs);\n+        if (!flatInputs.isEmpty() && !predictedOutputs.isEmpty() && !targetInput.getFeatures().isEmpty() && originalOutput != null) {\n+            columnData = getColumnData(flatInputs);\n+\n+            int pi = 0;\n+            for (Output output : predictedOutputs) {\n+                double[] x = new double[columnData.size()];\n+                int i = 0;\n+                for (List<Double> column : columnData) {\n+                    x[i] = column.get(pi);\n+                    i++;\n+                }\n+                double y;\n+                if (Type.NUMBER.equals(originalOutput.getType()) || Type.BOOLEAN.equals(originalOutput.getType())) {\n+                    y = output.getValue().asNumber();\n+                } else {\n+                    Object originalObject = originalOutput.getValue().getUnderlyingObject();\n+                    Object outputObject = output.getValue().getUnderlyingObject();\n+                    if (originalObject == null || outputObject == null) {\n+                        y = originalObject == outputObject ? 1d : 0d;\n+                    } else {\n+                        y = originalObject.equals(outputObject) ? 1d : 0d;\n+                    }\n+                }\n+                Pair<double[], Double> sample = new ImmutablePair<>(x, y);\n+                trainingSet.add(sample);\n+\n+                pi++;\n+            }\n+        }\n+        return trainingSet;\n+    }\n+\n+    private List<List<Double>> getColumnData(List<PredictionInput> perturbedInputs) {\n+        List<List<Double>> columnData = new LinkedList<>();\n+\n+        for (int t = 0; t < targetInput.getFeatures().size(); t++) {\n+            Feature originalFeature = targetInput.getFeatures().get(t);\n+            switch (originalFeature.getType()) {\n+                case NUMBER:\n+                    encodeNumbers(perturbedInputs, targetInput, columnData, t);\n+                    break;\n+                case TEXT:\n+                    encodeText(perturbedInputs, columnData, originalFeature);\n+                    break;\n+                case CATEGORICAL:\n+                case BINARY:\n+                case TIME:\n+                case URI:\n+                case DURATION:\n+                case VECTOR:\n+                case CURRENCY:\n+                case UNDEFINED:\n+                    encodeEquals(perturbedInputs, columnData, t, originalFeature);\n+                    break;\n+                case BOOLEAN:\n+                    // boolean are automatically encoded as 1s or 0s\n+                    List<Double> featureValues = new LinkedList<>();\n+                    for (PredictionInput pi : perturbedInputs) {\n+                        featureValues.add(pi.getFeatures().get(t).getValue().asNumber());\n+                    }\n+                    columnData.add(featureValues);\n+                    break;\n+            }\n+        }\n+        return columnData;\n+    }\n+\n+    private static void encodeNumbers(List<PredictionInput> predictionInputs, PredictionInput originalInputs, List<List<Double>> columnData, int t) {\n+        // find maximum and minimum values\n+        double[] doubles = new double[predictionInputs.size() + 1];\n+        int i = 0;\n+        for (PredictionInput pi : predictionInputs) {\n+            Feature feature = pi.getFeatures().get(t);\n+            doubles[i] = feature.getValue().asNumber();\n+            i++;\n+        }\n+        Feature feature = originalInputs.getFeatures().get(t);\n+        double originalValue = feature.getValue().asNumber();\n+        doubles[i] = originalValue;\n+        double min = DoubleStream.of(doubles).min().getAsDouble();\n+        double max = DoubleStream.of(doubles).max().getAsDouble();\n+        // feature scaling + kernel based clustering\n+        double threshold = DataUtils.gaussianKernel((originalValue - min) / (max - min));\n+        List<Double> featureValues = DoubleStream.of(doubles).map(d -> (d - min) / (max - min))\n+                .map(d -> Double.isNaN(d) ? 1 : d).boxed().map(DataUtils::gaussianKernel)\n+                .map(d -> (d - threshold < 1e-3) ? 1d : 0d).collect(Collectors.toList());", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwNDA5NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461404094", "bodyText": "minor thing: all caps letters?", "author": "r00ta", "createdAt": "2020-07-28T08:21:08Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ * <p>\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwNDY1Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461404657", "bodyText": "which code block is this comment referring to?", "author": "r00ta", "createdAt": "2020-07-28T08:22:04Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ * <p>\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * No. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * No. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    /**\n+     * No. of retries while trying to find a (linearly) separable dataset\n+     */\n+    private final int noOfRetries;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+        this.noOfRetries = noOfRetries;\n+    }\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+        this.noOfRetries = 3;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        PredictionInput originalInput = prediction.getInput();\n+        List<Feature> inputFeatures = originalInput.getFeatures();\n+\n+        if (inputFeatures.size() > 0) {\n+            // in case of composite / nested features, \"linearize\" the features\n+            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+            if (linearizedInputs.size() > 0) {\n+                PredictionInput targetInput = linearizedInputs.get(0);\n+                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+\n+                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+                int noOfInputFeatures = inputFeatures.size();\n+                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+                double[] weights = new double[noOfOutputFeatures];\n+\n+                // iterate through the different outputs in the prediction and explain each one separately\n+                for (int o = 0; o < actualOutputs.size(); o++) {\n+                    boolean separableDataset = false;\n+\n+                    List<PredictionInput> trainingInputs = new LinkedList<>();\n+                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n+\n+                    Output currentOutput = actualOutputs.get(o);\n+                    // do not explain the current output if it is 'null'\n+                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n+\n+                            /*\n+                            perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n+                            it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n+                            feature importance scores.\n+                             */", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQ3MTU0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461471546", "bodyText": "it refers to: https://github.com/tteofili/kogito-apps/blob/KOGITO-2750/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java#L123-L157\nI realize there's an indent issue, I'll fix it.", "author": "tteofili", "createdAt": "2020-07-28T10:11:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwNDY1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwNjM2Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461406366", "bodyText": "can you intent/split this line? it's a bit hard to read/understand", "author": "r00ta", "createdAt": "2020-07-28T08:24:52Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ * <p>\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * No. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * No. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    /**\n+     * No. of retries while trying to find a (linearly) separable dataset\n+     */\n+    private final int noOfRetries;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+        this.noOfRetries = noOfRetries;\n+    }\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+        this.noOfRetries = 3;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        PredictionInput originalInput = prediction.getInput();\n+        List<Feature> inputFeatures = originalInput.getFeatures();\n+\n+        if (inputFeatures.size() > 0) {\n+            // in case of composite / nested features, \"linearize\" the features\n+            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+            if (linearizedInputs.size() > 0) {\n+                PredictionInput targetInput = linearizedInputs.get(0);\n+                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+\n+                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+                int noOfInputFeatures = inputFeatures.size();\n+                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+                double[] weights = new double[noOfOutputFeatures];\n+\n+                // iterate through the different outputs in the prediction and explain each one separately\n+                for (int o = 0; o < actualOutputs.size(); o++) {\n+                    boolean separableDataset = false;\n+\n+                    List<PredictionInput> trainingInputs = new LinkedList<>();\n+                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n+\n+                    Output currentOutput = actualOutputs.get(o);\n+                    // do not explain the current output if it is 'null'\n+                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n+\n+                            /*\n+                            perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n+                            it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n+                            feature importance scores.\n+                             */\n+\n+                        boolean classification = false;\n+\n+                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n+                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n+                            // perturb the inputs\n+                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n+\n+                            // perform predictions on the perturbed inputs\n+                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n+\n+                            // calculate the no. of samples belonging to each output class\n+                            Value<?> fv = currentOutput.getValue();\n+                            int finalO = o;\n+                            rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                                    .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                                    && fv.getUnderlyingObject() == null) || (output.getValue().getUnderlyingObject() != null && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n+                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                            logger.debug(\"raw samples per class: {}\", rawClassesBalance);", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwNjc0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461406746", "bodyText": "move to constant?", "author": "r00ta", "createdAt": "2020-07-28T08:25:27Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.LinearModel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * An implementation of LIME algorithm (Ribeiro et al., 2016) that handles tabular data, text data, complex hierarchically\n+ * organized data, etc. seamlessly.\n+ * <p>\n+ * Differences with respect to the original (python) implementation:\n+ * - the linear (interpretable) model is based on a perceptron algorithm instead of Lasso + Ridge regression\n+ * - perturbing numerical features is done by sampling from a normal distribution centered around the value of the feature value associated with the prediction to be explained\n+ * - numerical features are max-min scaled and clustered via a gaussian kernel\n+ */\n+public class LimeExplainer implements LocalExplainer<Saliency> {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(LimeExplainer.class);\n+\n+    /**\n+     * No. of samples to be generated for the local linear model training\n+     */\n+    private final int noOfSamples;\n+\n+    /**\n+     * No. of perturbations to perform on a prediction\n+     */\n+    private final int noOfPerturbations;\n+\n+    /**\n+     * No. of retries while trying to find a (linearly) separable dataset\n+     */\n+    private final int noOfRetries;\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+        this.noOfRetries = noOfRetries;\n+    }\n+\n+    public LimeExplainer(int noOfSamples, int noOfPerturbations) {\n+        this.noOfSamples = noOfSamples;\n+        this.noOfPerturbations = noOfPerturbations;\n+        this.noOfRetries = 3;\n+    }\n+\n+    @Override\n+    public Saliency explain(Prediction prediction, PredictionProvider model) {\n+\n+        long start = System.currentTimeMillis();\n+\n+        List<FeatureImportance> saliencies = new LinkedList<>();\n+        PredictionInput originalInput = prediction.getInput();\n+        List<Feature> inputFeatures = originalInput.getFeatures();\n+\n+        if (inputFeatures.size() > 0) {\n+            // in case of composite / nested features, \"linearize\" the features\n+            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+            if (linearizedInputs.size() > 0) {\n+                PredictionInput targetInput = linearizedInputs.get(0);\n+                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+\n+                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+                int noOfInputFeatures = inputFeatures.size();\n+                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n+                double[] weights = new double[noOfOutputFeatures];\n+\n+                // iterate through the different outputs in the prediction and explain each one separately\n+                for (int o = 0; o < actualOutputs.size(); o++) {\n+                    boolean separableDataset = false;\n+\n+                    List<PredictionInput> trainingInputs = new LinkedList<>();\n+                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n+\n+                    Output currentOutput = actualOutputs.get(o);\n+                    // do not explain the current output if it is 'null'\n+                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n+                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n+\n+                            /*\n+                            perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n+                            it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n+                            feature importance scores.\n+                             */\n+\n+                        boolean classification = false;\n+\n+                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n+                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n+                            // perturb the inputs\n+                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n+\n+                            // perform predictions on the perturbed inputs\n+                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n+\n+                            // calculate the no. of samples belonging to each output class\n+                            Value<?> fv = currentOutput.getValue();\n+                            int finalO = o;\n+                            rawClassesBalance = perturbedOutputs.stream().map(p -> p.getOutputs().get(finalO)).map(output -> (Type.NUMBER\n+                                    .equals(output.getType())) ? output.getValue().asNumber() : (((output.getValue().getUnderlyingObject() == null\n+                                    && fv.getUnderlyingObject() == null) || (output.getValue().getUnderlyingObject() != null && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n+                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting()));\n+                            logger.debug(\"raw samples per class: {}\", rawClassesBalance);\n+\n+                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n+                            if (rawClassesBalance.size() > 1) {\n+                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n+                                if ((double) max / (double) perturbedInputs.size() < 0.99) {", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQwNzgzMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461407832", "bodyText": "indent/split?", "author": "r00ta", "createdAt": "2020-07-28T08:27:21Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/SampleWeighter.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+/**\n+ * Utility class to generate weights for the LIME encoded training set, given a prediction.\n+ */\n+class SampleWeighter {\n+\n+    private static final double SIGMA = 0.75;\n+\n+    static double[] getSampleWeights(PredictionInput targetInput, Collection<Pair<double[], Double>> training) {\n+        int noOfFeatures = targetInput.getFeatures().size();\n+        double[] x = new double[noOfFeatures];\n+        Arrays.fill(x, 1);\n+\n+        return training.stream().map(Pair::getLeft).map(\n+                d -> DataUtils.euclideanDistance(x, d)).map(d -> DataUtils.exponentialSmoothingKernel(d, SIGMA *\n+                Math.sqrt(noOfFeatures))).mapToDouble(Double::doubleValue).toArray();\n+    }", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxMjE5Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461412197", "bodyText": "Just for my understanding: what is the difference of sampling from a normal distribution and this procedure?", "author": "r00ta", "createdAt": "2020-07-28T08:34:25Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,470 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void setSeed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQ3ODg0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461478846", "bodyText": "there's no difference, in fact that is used exactly for sampling from a standard normal distribution in https://github.com/tteofili/kogito-apps/blob/KOGITO-2750/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java#L216", "author": "tteofili", "createdAt": "2020-07-28T10:26:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxMjE5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTUwMzQwOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461503408", "bodyText": "Ok, since there is no difference wdyt @tteofili  if we change it to something like\nRandom r = new Random();\ndouble sample = r.nextGaussian()*targetStandardDeviation+targetMean;\n\n?", "author": "r00ta", "createdAt": "2020-07-28T11:15:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxMjE5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU0NjE3OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461546179", "bodyText": "the current code is slightly more accurate with respect to r.nextGaussian()*targetStandardDeviation+targetMean, not sure why it is the case but there's a difference in precision wrt to desired mean and stdDev of the generated data of 1e-6 (with current code) vs 1e-2 (with r.nextGaussian()*targetStandardDeviation+targetMean).\nSo if it is not a problem, I'd prefer to keep the current code (slightly slower but more precise).", "author": "tteofili", "createdAt": "2020-07-28T12:38:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxMjE5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTcwNjQ1Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461706452", "bodyText": "Hi @tteofili , I've called generateData(0, 10, 500) and I've plotted the data, but it does not look a gaussian: it's not symmetric at all.\n\nIf it's important that we sample from a normal distribution maybe it's better to go for  r.nextGaussian()*targetStandardDeviation+targetMean even if the noise is bigger than the other method, because at least we sample from a normal distribution. If the distribution is not that important as the mean and the std deviation, forget my comments.\nbtw, what is the size of the sample you are generating for your comparison?", "author": "r00ta", "createdAt": "2020-07-28T16:17:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxMjE5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjI1NjUyMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r462256521", "bodyText": "both are important for the numerical data perturbation procedure, hence I would mix them together, by generating the initial values ofdouble[] with r.nextGaussian()*targetStandardDeviation+targetMean and then adjusting mean and stdDeviation with the current procedure.", "author": "tteofili", "createdAt": "2020-07-29T12:22:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxMjE5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxNDMyNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461414326", "bodyText": "If I'm not wrong, if stringValue.endswith(' ') == true this piece of code will throw an exception since 1/2 = 0 and random.nextInt(0) will throw an IllegalArgumentException or something. Can you add a test for that if this is correct?", "author": "r00ta", "createdAt": "2020-07-28T08:38:05Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,470 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void setSeed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbFeatures(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue = \"\";\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        if (!words.isEmpty()) {\n+                            int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                            for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                                int dropIdx = random.nextInt(words.size());\n+                                words.remove(dropIdx);\n+                            }\n+                        }\n+                        newStringValue = String.join(\" \", words);", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTYwMDE1Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461600152", "bodyText": "I think this is guarded by !words.isEmpty(), anyway there're tests for such text features at https://github.com/tteofili/kogito-apps/blob/KOGITO-2750/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/utils/DataUtilsTest.java#L155-L197", "author": "tteofili", "createdAt": "2020-07-28T13:57:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxNDMyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxNTc0MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461415740", "bodyText": "Just for my understanding: this line of code does not ensure that the feature is perturbed right? Should we create a ticket to investigate and improve the perturbation of such types?", "author": "r00ta", "createdAt": "2020-07-28T08:40:32Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,470 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void setSeed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbFeatures(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue = \"\";\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        if (!words.isEmpty()) {\n+                            int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                            for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                                int dropIdx = random.nextInt(words.size());\n+                                words.remove(dropIdx);\n+                            }\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    }\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double originalFeatureValue = feature.getValue().asNumber();\n+                boolean intValue = originalFeatureValue % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double normalDistributionSample = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (originalFeatureValue != 0d) {\n+                    normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                }\n+                if (intValue) {\n+                    normalDistributionSample = (int) normalDistributionSample;\n+                    if (normalDistributionSample == originalFeatureValue) {\n+                        normalDistributionSample = (int) normalDistributionSample * 10d;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, normalDistributionSample);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                LocalTime featureValue = (LocalTime) feature.getValue().getUnderlyingObject();\n+                f = FeatureFactory.newTimeFeature(featureName, featureValue.minusHours(random.nextInt(24)));\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to machine default locale\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU1MzI4NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461553284", "bodyText": "yes, agreed, I've created FAI-243 for this.", "author": "tteofili", "createdAt": "2020-07-28T12:49:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxNTc0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxNzA1MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461417051", "bodyText": "Check if the strings have different length?", "author": "r00ta", "createdAt": "2020-07-28T08:42:40Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,470 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void setSeed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbFeatures(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue = \"\";\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        if (!words.isEmpty()) {\n+                            int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                            for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                                int dropIdx = random.nextInt(words.size());\n+                                words.remove(dropIdx);\n+                            }\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    }\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double originalFeatureValue = feature.getValue().asNumber();\n+                boolean intValue = originalFeatureValue % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double normalDistributionSample = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (originalFeatureValue != 0d) {\n+                    normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                }\n+                if (intValue) {\n+                    normalDistributionSample = (int) normalDistributionSample;\n+                    if (normalDistributionSample == originalFeatureValue) {\n+                        normalDistributionSample = (int) normalDistributionSample * 10d;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, normalDistributionSample);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                LocalTime featureValue = (LocalTime) feature.getValue().getUnderlyingObject();\n+                f = FeatureFactory.newTimeFeature(featureName, featureValue.minusHours(random.nextInt(24)));\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to machine default locale\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                if (feature.getValue().getUnderlyingObject() instanceof Feature) {\n+                    f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                } else {\n+                    f = feature;\n+                }\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, List<String> names) {\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = names.stream().map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (names.contains(featureName)) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newBooleanFeature(featureName, null);\n+                }\n+                break;\n+            case TIME:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newTimeFeature(featureName, null);\n+                }\n+                break;\n+            case DURATION:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newDurationFeature(featureName, null);\n+                }\n+                break;\n+            case CURRENCY:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newCurrencyFeature(featureName, null);\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (names.contains(featureName)) {\n+                    String category = feature.getValue().asString();\n+                    f = FeatureFactory.newCategoricalFeature(featureName, \"\");\n+                }\n+                break;\n+            case BINARY:\n+                if (names.contains(featureName)) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (names.contains(featureName)) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (names.contains(featureName)) {\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        Arrays.fill(values, 0);\n+                    }\n+                    f = FeatureFactory.newVectorFeature(featureName, values);\n+                }\n+                break;\n+            case UNDEFINED:\n+                if (feature.getValue().getUnderlyingObject() instanceof Feature) {\n+                    f = dropFeature((Feature) feature.getValue().getUnderlyingObject(), names);\n+                } else {\n+                    f = FeatureFactory.newObjectFeature(featureName, null);\n+                }\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static double hammingDistance(double[] x, double[] y) {\n+        if (x.length != y.length) {\n+            return Double.NaN;\n+        } else {\n+            double h = 0d;\n+            for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+                if (x[i] != y[i]) {\n+                    h++;\n+                }\n+            }\n+            return h;\n+        }\n+    }\n+\n+    public static double hammingDistance(String x, String y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length(), y.length()); i++) {\n+            if (x.charAt(i) != y.charAt(i)) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length() - y.length());\n+    }", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxNzE4OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461417189", "bodyText": "Math.min not needed anymore", "author": "r00ta", "createdAt": "2020-07-28T08:42:54Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,470 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void setSeed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbFeatures(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue = \"\";\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        if (!words.isEmpty()) {\n+                            int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                            for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                                int dropIdx = random.nextInt(words.size());\n+                                words.remove(dropIdx);\n+                            }\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    }\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double originalFeatureValue = feature.getValue().asNumber();\n+                boolean intValue = originalFeatureValue % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double normalDistributionSample = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (originalFeatureValue != 0d) {\n+                    normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                }\n+                if (intValue) {\n+                    normalDistributionSample = (int) normalDistributionSample;\n+                    if (normalDistributionSample == originalFeatureValue) {\n+                        normalDistributionSample = (int) normalDistributionSample * 10d;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, normalDistributionSample);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                LocalTime featureValue = (LocalTime) feature.getValue().getUnderlyingObject();\n+                f = FeatureFactory.newTimeFeature(featureName, featureValue.minusHours(random.nextInt(24)));\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to machine default locale\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                if (feature.getValue().getUnderlyingObject() instanceof Feature) {\n+                    f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                } else {\n+                    f = feature;\n+                }\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, List<String> names) {\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = names.stream().map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (names.contains(featureName)) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newBooleanFeature(featureName, null);\n+                }\n+                break;\n+            case TIME:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newTimeFeature(featureName, null);\n+                }\n+                break;\n+            case DURATION:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newDurationFeature(featureName, null);\n+                }\n+                break;\n+            case CURRENCY:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newCurrencyFeature(featureName, null);\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (names.contains(featureName)) {\n+                    String category = feature.getValue().asString();\n+                    f = FeatureFactory.newCategoricalFeature(featureName, \"\");\n+                }\n+                break;\n+            case BINARY:\n+                if (names.contains(featureName)) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (names.contains(featureName)) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (names.contains(featureName)) {\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        Arrays.fill(values, 0);\n+                    }\n+                    f = FeatureFactory.newVectorFeature(featureName, values);\n+                }\n+                break;\n+            case UNDEFINED:\n+                if (feature.getValue().getUnderlyingObject() instanceof Feature) {\n+                    f = dropFeature((Feature) feature.getValue().getUnderlyingObject(), names);\n+                } else {\n+                    f = FeatureFactory.newObjectFeature(featureName, null);\n+                }\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static double hammingDistance(double[] x, double[] y) {\n+        if (x.length != y.length) {\n+            return Double.NaN;\n+        } else {\n+            double h = 0d;\n+            for (int i = 0; i < Math.min(x.length, y.length); i++) {", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxNzM2Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461417363", "bodyText": "Same as above for hamming distance?", "author": "r00ta", "createdAt": "2020-07-28T08:43:13Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/DataUtils.java", "diffHunk": "@@ -0,0 +1,470 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.utils;\n+\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.security.SecureRandom;\n+import java.time.Duration;\n+import java.time.LocalTime;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Currency;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.DoubleStream;\n+\n+import org.kie.kogito.explainability.model.DataDistribution;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureDistribution;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.Type;\n+\n+/**\n+ * Utility methods to handle and manipulate data.\n+ */\n+public class DataUtils {\n+\n+    private final static SecureRandom random = new SecureRandom();\n+\n+    public static void setSeed(long seed) {\n+        random.setSeed(seed);\n+    }\n+\n+    /**\n+     * Generate a dataset of a certain size, given mean and standard deviation.\n+     * Samples are generated randomly, actual mean {@code m} and standard deviation {@code d} are calculated.\n+     * Then all numbers are multiplied by the same number so that the standard deviation also gets\n+     * multiplied by the same number, hence we multiply each random number by {@code stdDeviation / d}.\n+     * The resultant set has standard deviation {@code stdDeviation} and mean {@code m1=m*stdDeviation/d}.\n+     * If a same number is added to all values the mean also changes by the same number so we add {@code mean - m1} to\n+     * all numbers.\n+     *\n+     * @param mean         desired mean\n+     * @param stdDeviation desired standard deviation\n+     * @param size         size of the array\n+     * @return the generated data\n+     */\n+    public static double[] generateData(double mean, double stdDeviation, int size) {\n+        double[] data = new double[size];\n+        // generate random data\n+        for (int i = 0; i < size; i++) {\n+            double g = 1d / (1d + random.nextInt(10));\n+            data[i] = g;\n+        }\n+\n+        double m = getMean(data);\n+        double d = getStdDev(data, m);\n+\n+        // force desired standard deviation\n+        double d1 = stdDeviation / d;\n+        for (int i = 0; i < size; i++) {\n+            data[i] *= d1;\n+        }\n+\n+        // get the new mean\n+        double m1 = m * stdDeviation / d;\n+\n+        // force desired mean\n+        for (int i = 0; i < size; i++) {\n+            data[i] += mean - m1;\n+        }\n+\n+        return data;\n+    }\n+\n+    private static double getMean(double[] data) {\n+        double m = 0;\n+        for (double datum : data) {\n+            m += datum;\n+        }\n+        m = m / data.length;\n+        return m;\n+    }\n+\n+    private static double getStdDev(double[] data, double mean) {\n+        double d = 0;\n+        for (double datum : data) {\n+            d += Math.pow(datum - mean, 2);\n+        }\n+        d /= data.length;\n+        d = Math.sqrt(d);\n+        return d;\n+    }\n+\n+    /**\n+     * Generate equally {@code size} sampled values between {@code min} and {@code max}.\n+     *\n+     * @param min  minimum value\n+     * @param max  maximum value\n+     * @param size dataset size\n+     * @return the generated data\n+     */\n+    public static double[] generateSamples(double min, double max, int size) {\n+        double[] data = new double[size];\n+        double val = min;\n+        double sum = max / size;\n+        for (int i = 0; i < size; i++) {\n+            data[i] = val;\n+            val += sum;\n+        }\n+        return data;\n+    }\n+\n+    public static List<Feature> doublesToFeatures(double[] inputs) {\n+        return DoubleStream.of(inputs).mapToObj(DataUtils::doubleToFeature).collect(Collectors.toList());\n+    }\n+\n+    public static Feature doubleToFeature(double d) {\n+        return FeatureFactory.newNumericalFeature(String.valueOf(d), d);\n+    }\n+\n+    public static PredictionInput perturbFeatures(PredictionInput input, int noOfSamples, int noOfPerturbations) {\n+        List<Feature> originalFeatures = input.getFeatures();\n+        List<Feature> newFeatures = new ArrayList<>(originalFeatures);\n+        PredictionInput perturbedInput = new PredictionInput(newFeatures);\n+        int perturbationSize = Math.min(noOfPerturbations, originalFeatures.size());\n+        int[] indexesToBePerturbed = random.ints(0, perturbedInput.getFeatures().size()).distinct().limit(perturbationSize).toArray();\n+        // TODO : perturbing a composite / nested feature must be done by considering to only perturb #noOfPerturbations features\n+        for (int value : indexesToBePerturbed) {\n+            perturbedInput.getFeatures().set(value, perturbFeature(\n+                    perturbedInput.getFeatures().get(value), noOfSamples));\n+        }\n+        return perturbedInput;\n+    }\n+\n+    private static Feature perturbFeature(Feature feature, int noOfSamples) {\n+        Type type = feature.getType();\n+        Feature f;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    if (random.nextBoolean()) {\n+                        featuresMap.put(cf.getName(), perturbFeature(cf, noOfSamples));\n+                    } else {\n+                        featuresMap.put(cf.getName(), cf);\n+                    }\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                String newStringValue = \"\";\n+                // randomly drop entire string or parts of it\n+                if (random.nextBoolean()) {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        if (!words.isEmpty()) {\n+                            int featuresToDrop = random.nextInt(Math.min(2, words.size() / 2));\n+                            for (int i = 0; i < 1 + featuresToDrop; i++) {\n+                                int dropIdx = random.nextInt(words.size());\n+                                words.remove(dropIdx);\n+                            }\n+                        }\n+                        newStringValue = String.join(\" \", words);\n+                    }\n+                }\n+                f = FeatureFactory.newTextFeature(featureName, newStringValue);\n+                break;\n+            case NUMBER:\n+                double originalFeatureValue = feature.getValue().asNumber();\n+                boolean intValue = originalFeatureValue % 1 == 0;\n+\n+                // sample from normal distribution and center around feature value\n+                int pickIdx = random.nextInt(noOfSamples - 1);\n+                double normalDistributionSample = DataUtils.generateData(0, 1, noOfSamples)[pickIdx];\n+                if (originalFeatureValue != 0d) {\n+                    normalDistributionSample = normalDistributionSample * originalFeatureValue + originalFeatureValue;\n+                }\n+                if (intValue) {\n+                    normalDistributionSample = (int) normalDistributionSample;\n+                    if (normalDistributionSample == originalFeatureValue) {\n+                        normalDistributionSample = (int) normalDistributionSample * 10d;\n+                    }\n+                }\n+                f = FeatureFactory.newNumericalFeature(featureName, normalDistributionSample);\n+                break;\n+            case BOOLEAN:\n+                // flip the boolean value\n+                f = FeatureFactory.newBooleanFeature(featureName, !Boolean.getBoolean(feature.getValue().asString()));\n+                break;\n+            case TIME:\n+                LocalTime featureValue = (LocalTime) feature.getValue().getUnderlyingObject();\n+                f = FeatureFactory.newTimeFeature(featureName, featureValue.minusHours(random.nextInt(24)));\n+                break;\n+            case DURATION:\n+                // set the duration to 0\n+                f = FeatureFactory.newDurationFeature(featureName, Duration.of(0, ChronoUnit.SECONDS));\n+                break;\n+            case CURRENCY:\n+                // set the currency to machine default locale\n+                f = FeatureFactory.newCurrencyFeature(featureName, Currency.getInstance(Locale.getDefault()));\n+                break;\n+            case CATEGORICAL:\n+                String category = feature.getValue().asString();\n+                if (!\"0\".equals(category)) {\n+                    category = \"0\";\n+                } else {\n+                    category = \"1\";\n+                }\n+                f = FeatureFactory.newCategoricalFeature(featureName, category);\n+                break;\n+            case BINARY:\n+                // set an empty buffer\n+                ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                break;\n+            case URI:\n+                // set an empty URI\n+                f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                break;\n+            case VECTOR:\n+                // randomly set a non zero value to zero (or decrease it by 1)\n+                double[] values = feature.getValue().asVector();\n+                if (values.length > 1) {\n+                    int idx = random.nextInt(values.length - 1);\n+                    if (values[idx] != 0) {\n+                        values[idx] = 0;\n+                    } else {\n+                        values[idx]--;\n+                    }\n+                }\n+                f = FeatureFactory.newVectorFeature(featureName, values);\n+                break;\n+            case UNDEFINED:\n+                if (feature.getValue().getUnderlyingObject() instanceof Feature) {\n+                    f = perturbFeature((Feature) feature.getValue().getUnderlyingObject(), noOfSamples);\n+                } else {\n+                    f = feature;\n+                }\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static Feature dropFeature(Feature feature, List<String> names) {\n+        Type type = feature.getType();\n+        Feature f = feature;\n+        String featureName = feature.getName();\n+        switch (type) {\n+            case COMPOSITE:\n+                List<Feature> composite = (List<Feature>) feature.getValue().getUnderlyingObject();\n+                Map<String, Object> featuresMap = new HashMap<>();\n+                for (Feature cf : composite) {\n+                    featuresMap.put(cf.getName(), dropFeature(cf, names));\n+                }\n+                f = FeatureFactory.newCompositeFeature(featureName, featuresMap);\n+                break;\n+            case TEXT:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newTextFeature(featureName, \"\");\n+                } else {\n+                    String stringValue = feature.getValue().asString();\n+                    if (stringValue.indexOf(' ') != -1) {\n+                        List<String> words = new ArrayList<>(Arrays.asList(stringValue.split(\" \")));\n+                        List<String> matchingWords = names.stream().map(n -> n.contains(\" (\") ? n.substring(0, n.indexOf(\" (\")) : \"\").filter(words::contains).collect(Collectors.toList());\n+                        if (words.removeAll(matchingWords)) {\n+                            stringValue = String.join(\" \", words);\n+                        }\n+                    }\n+                    f = FeatureFactory.newTextFeature(featureName, stringValue);\n+                }\n+                break;\n+            case NUMBER:\n+                if (names.contains(featureName)) {\n+                    if (feature.getValue().asNumber() == 0) {\n+                        f = FeatureFactory.newNumericalFeature(featureName, Double.NaN);\n+                    } else {\n+                        f = FeatureFactory.newNumericalFeature(featureName, 0);\n+                    }\n+                }\n+                break;\n+            case BOOLEAN:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newBooleanFeature(featureName, null);\n+                }\n+                break;\n+            case TIME:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newTimeFeature(featureName, null);\n+                }\n+                break;\n+            case DURATION:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newDurationFeature(featureName, null);\n+                }\n+                break;\n+            case CURRENCY:\n+                if (names.contains(featureName)) {\n+                    f = FeatureFactory.newCurrencyFeature(featureName, null);\n+                }\n+                break;\n+            case CATEGORICAL:\n+                if (names.contains(featureName)) {\n+                    String category = feature.getValue().asString();\n+                    f = FeatureFactory.newCategoricalFeature(featureName, \"\");\n+                }\n+                break;\n+            case BINARY:\n+                if (names.contains(featureName)) {\n+                    // set an empty buffer\n+                    ByteBuffer byteBuffer = ByteBuffer.allocate(0);\n+                    f = FeatureFactory.newBinaryFeature(featureName, byteBuffer);\n+                }\n+                break;\n+            case URI:\n+                if (names.contains(featureName)) {\n+                    // set an empty URI\n+                    f = FeatureFactory.newURIFeature(featureName, URI.create(\"\"));\n+                }\n+                break;\n+            case VECTOR:\n+                if (names.contains(featureName)) {\n+                    double[] values = feature.getValue().asVector();\n+                    if (values.length > 0) {\n+                        Arrays.fill(values, 0);\n+                    }\n+                    f = FeatureFactory.newVectorFeature(featureName, values);\n+                }\n+                break;\n+            case UNDEFINED:\n+                if (feature.getValue().getUnderlyingObject() instanceof Feature) {\n+                    f = dropFeature((Feature) feature.getValue().getUnderlyingObject(), names);\n+                } else {\n+                    f = FeatureFactory.newObjectFeature(featureName, null);\n+                }\n+                break;\n+            default:\n+                throw new IllegalStateException(\"Unexpected value: \" + type);\n+        }\n+        return f;\n+    }\n+\n+    public static double hammingDistance(double[] x, double[] y) {\n+        if (x.length != y.length) {\n+            return Double.NaN;\n+        } else {\n+            double h = 0d;\n+            for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+                if (x[i] != y[i]) {\n+                    h++;\n+                }\n+            }\n+            return h;\n+        }\n+    }\n+\n+    public static double hammingDistance(String x, String y) {\n+        double h = 0;\n+        for (int i = 0; i < Math.min(x.length(), y.length()); i++) {\n+            if (x.charAt(i) != y.charAt(i)) {\n+                h++;\n+            }\n+        }\n+        return h + (double) (x.length() - y.length());\n+    }\n+\n+    public static double euclideanDistance(double[] x, double[] y) {\n+        double e = 0;\n+        for (int i = 0; i < Math.min(x.length, y.length); i++) {\n+            e += Math.pow(x[i] - y[i], 2);\n+        }", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTUzODgzNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461538837", "bodyText": "sure", "author": "tteofili", "createdAt": "2020-07-28T12:25:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQxNzM2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQyMzEwMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461423102", "bodyText": "Following the discussion of the previous comment  all other features should have way low importance, when compared with the top one., wouldn't it be better to check the percentage here? In theory these checks might pass if topFeatures.get(1).getScore() == topFeatures.get(0).getScore(), which is not the expected behaviour iiuc", "author": "r00ta", "createdAt": "2020-07-28T08:52:23Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.setSeed(4);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputRegression() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU3MjM5Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461572393", "bodyText": "hmm, now I realize the check is wrong, thanks for pointing it out, I'll fix it.", "author": "tteofili", "createdAt": "2020-07-28T13:19:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQyMzEwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQyNDI4NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461424284", "bodyText": "this is always true, isn't it? Same for all the following tests", "author": "r00ta", "createdAt": "2020-07-28T08:54:20Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/DummyModelsLimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureFactory;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+import org.kie.kogito.explainability.utils.ExplainabilityMetrics;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class DummyModelsLimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.setSeed(4);\n+    }\n+\n+    @Test\n+    void testMapOneFeatureToOutputRegression() {\n+        int idx = 1;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 0.1));\n+        PredictionInput input = new PredictionInput(features);\n+        PredictionProvider model = TestUtils.getFeaturePassModel(idx);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+\n+        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> topFeatures = saliency.getTopFeatures(3);\n+        assertEquals(topFeatures.get(0).getFeature().getName(), features.get(idx).getName());\n+        assertTrue(topFeatures.get(1).getScore() < topFeatures.get(0).getScore() * 10);\n+        assertTrue(topFeatures.get(2).getScore() < topFeatures.get(0).getScore() * 10);\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThan(0);\n+    }\n+\n+    @Test\n+    void testUnusedFeatureRegression() {\n+        int idx = 2;\n+        List<Feature> features = new LinkedList<>();\n+        features.add(FeatureFactory.newNumericalFeature(\"f1\", 100));\n+        features.add(FeatureFactory.newNumericalFeature(\"f2\", 20));\n+        features.add(FeatureFactory.newNumericalFeature(\"f3\", 10));\n+        PredictionProvider model = TestUtils.getSumSkipModel(idx);\n+        PredictionInput input = new PredictionInput(features);\n+        List<PredictionOutput> outputs = model.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, outputs.get(0));\n+        LimeExplainer limeExplainer = new LimeExplainer(1000, 1);\n+        Saliency saliency = limeExplainer.explain(prediction, model);\n+\n+        assertNotNull(saliency);\n+        List<FeatureImportance> perFeatureImportance = saliency.getPerFeatureImportance();\n+\n+        perFeatureImportance.sort((t1, t2) -> (int) (t2.getScore() - t1.getScore()));\n+        assertTrue(perFeatureImportance.get(0).getScore() > 0);\n+        assertTrue(perFeatureImportance.get(1).getScore() > 0);\n+        assertEquals(features.get(idx).getName(), perFeatureImportance.get(2).getFeature().getName());\n+        double v = ExplainabilityMetrics.saliencyImpact(model, prediction, saliency.getTopFeatures(1));\n+        assertThat(v).isGreaterThan(0);", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTU3NTMyMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461575321", "bodyText": "no, it can be 0 when dropping features has no effect in the model prediction output.\nIf the impact it's greater than 0 it means that the drop of the top k features caused some change in the output.", "author": "tteofili", "createdAt": "2020-07-28T13:23:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQyNDI4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQyNzAyNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461427025", "bodyText": "Assertions.assertThrows(LocalExplanationException.class, () -> limeExplainer.explain(prediction, model)); ?", "author": "r00ta", "createdAt": "2020-07-28T08:58:37Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.local.LocalExplanationException;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.mock;\n+\n+class LimeExplainerTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.setSeed(4);\n+    }\n+\n+    @Test\n+    void testEmptyPrediction() {\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        PredictionOutput output = mock(PredictionOutput.class);\n+        PredictionInput input = mock(PredictionInput.class);\n+        Prediction prediction = new Prediction(input, output);\n+        PredictionProvider model = mock(PredictionProvider.class);\n+        try {\n+            limeExplainer.explain(prediction, model);\n+            fail(\"explaining an empty prediction should throw an exception\");\n+        } catch (LocalExplanationException e) {\n+            // do nothing\n+        }", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQyNzU5Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/324#discussion_r461427596", "bodyText": "refactor so to remove duplicated code?", "author": "r00ta", "createdAt": "2020-07-28T08:59:33Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.kogito.explainability.local.lime;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+import org.kie.kogito.explainability.TestUtils;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.utils.DataUtils;\n+\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+class LimeStabilityTest {\n+\n+    @BeforeAll\n+    static void setUpBefore() {\n+        DataUtils.setSeed(4);\n+    }\n+\n+    @Test\n+    void testStabilityWithNumericData() {\n+        PredictionProvider sumSkipModel = TestUtils.getSumSkipModel(0);\n+        List<Feature> featureList = new LinkedList<>();\n+        for (int i = 0; i < 5; i++) {\n+            featureList.add(TestUtils.getMockedNumericFeature(i));\n+        }\n+        PredictionInput input = new PredictionInput(featureList);\n+        List<PredictionOutput> predictionOutputs = sumSkipModel.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, predictionOutputs.get(0));\n+        List<Saliency> saliencies = new LinkedList<>();\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        for (int i = 0; i < 100; i++) {\n+            Saliency saliency = limeExplainer.explain(prediction, sumSkipModel);\n+            saliencies.add(saliency);\n+        }\n+        List<String> names = new LinkedList<>();\n+        saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n+        Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        boolean topFeature = false;\n+        for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n+            topFeature = entry.getValue() >= 0.9;\n+        }\n+        assertTrue(topFeature);\n+    }\n+\n+    @Test\n+    void testStabilityWithTextData() {\n+        PredictionProvider sumSkipModel = TestUtils.getDummyTextClassifier();\n+        List<Feature> featureList = new LinkedList<>();\n+        for (int i = 0; i < 4; i++) {\n+            featureList.add(TestUtils.getMockedTextFeature(\"foo \"+i));\n+        }\n+        featureList.add(TestUtils.getMockedTextFeature(\"money\"));\n+        PredictionInput input = new PredictionInput(featureList);\n+        List<PredictionOutput> predictionOutputs = sumSkipModel.predict(List.of(input));\n+        Prediction prediction = new Prediction(input, predictionOutputs.get(0));\n+        List<Saliency> saliencies = new LinkedList<>();\n+        LimeExplainer limeExplainer = new LimeExplainer(10, 1);\n+        for (int i = 0; i < 100; i++) {\n+            Saliency saliency = limeExplainer.explain(prediction, sumSkipModel);\n+            saliencies.add(saliency);\n+        }\n+        List<String> names = new LinkedList<>();\n+        saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n+        Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        boolean topFeature = false;\n+        for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n+            topFeature = entry.getValue() >= 0.9;\n+        }\n+        assertTrue(topFeature);\n+    }", "originalCommit": "8ab120a13b777f71f58bbebefcfbc12d81d98483", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fcda194d297a9a679b355201ec005bce54046341", "url": "https://github.com/kiegroup/kogito-apps/commit/fcda194d297a9a679b355201ec005bce54046341", "message": "KOGITO-2750 - added some missing javadoc, minor fixes", "committedDate": "2020-07-28T10:06:15Z", "type": "commit"}, {"oid": "ec558272c1a218cd73ae99d061c530ee4b560ddb", "url": "https://github.com/kiegroup/kogito-apps/commit/ec558272c1a218cd73ae99d061c530ee4b560ddb", "message": "KOGITO-2750 - refactoring of constants, array length checks, minor fixes", "committedDate": "2020-07-28T13:06:32Z", "type": "commit"}, {"oid": "a534dffe10f2e073282f66581eea86addfe38c15", "url": "https://github.com/kiegroup/kogito-apps/commit/a534dffe10f2e073282f66581eea86addfe38c15", "message": "KOGITO-2750 - fixing test assertion for dummy model test", "committedDate": "2020-07-28T13:21:40Z", "type": "commit"}, {"oid": "5c160e2e789a066ecf4a2941f4cd26b2e48ca45e", "url": "https://github.com/kiegroup/kogito-apps/commit/5c160e2e789a066ecf4a2941f4cd26b2e48ca45e", "message": "KOGITO-2750 - raw class count indent / comments", "committedDate": "2020-07-28T13:34:42Z", "type": "commit"}, {"oid": "c2467ee106f66364718f7fcbe156186111147a65", "url": "https://github.com/kiegroup/kogito-apps/commit/c2467ee106f66364718f7fcbe156186111147a65", "message": "KOGITO-2750 - indent, javadoc, comment improvements", "committedDate": "2020-07-28T13:47:07Z", "type": "commit"}, {"oid": "f6d13c8a859a091e6bb1f427f143e6eda62af2a9", "url": "https://github.com/kiegroup/kogito-apps/commit/f6d13c8a859a091e6bb1f427f143e6eda62af2a9", "message": "KOGITO-2750 - indent, javadoc, comment improvements", "committedDate": "2020-07-28T13:50:48Z", "type": "commit"}, {"oid": "070585fede15e551859bf2aa2e913f4d85be8622", "url": "https://github.com/kiegroup/kogito-apps/commit/070585fede15e551859bf2aa2e913f4d85be8622", "message": "KOGITO-2750 - improved test expecting exception", "committedDate": "2020-07-28T13:57:58Z", "type": "commit"}, {"oid": "c8bac0bf5e41422dea6b5b6bbb6b1a113bd6234c", "url": "https://github.com/kiegroup/kogito-apps/commit/c8bac0bf5e41422dea6b5b6bbb6b1a113bd6234c", "message": "KOGITO-2750 - remove duplicate code in LSTest", "committedDate": "2020-07-28T13:59:20Z", "type": "commit"}, {"oid": "c217d0f80bbc4720ccc648db315759a7fe249b26", "url": "https://github.com/kiegroup/kogito-apps/commit/c217d0f80bbc4720ccc648db315759a7fe249b26", "message": "Merge branch 'master' of github.com:kiegroup/kogito-apps into KOGITO-2750", "committedDate": "2020-07-28T14:00:57Z", "type": "commit"}, {"oid": "e701bf5017ecb839c162ff896e13286ad2ae814d", "url": "https://github.com/kiegroup/kogito-apps/commit/e701bf5017ecb839c162ff896e13286ad2ae814d", "message": "KOGITO-2750 - minor fixes", "committedDate": "2020-07-28T14:30:21Z", "type": "commit"}, {"oid": "485c8118a3564789388688ba17d8655fa3247c7b", "url": "https://github.com/kiegroup/kogito-apps/commit/485c8118a3564789388688ba17d8655fa3247c7b", "message": "KOGITO-2750 - removed unused imports", "committedDate": "2020-07-29T07:40:41Z", "type": "commit"}, {"oid": "67076c49ba6e35a926b10cea9b3038ace480bd47", "url": "https://github.com/kiegroup/kogito-apps/commit/67076c49ba6e35a926b10cea9b3038ace480bd47", "message": "KOGITO-2750 - adjusted data generation procedure", "committedDate": "2020-07-29T12:29:22Z", "type": "commit"}, {"oid": "ea55f82afad55088cf5b58b834d1034388aa71e5", "url": "https://github.com/kiegroup/kogito-apps/commit/ea55f82afad55088cf5b58b834d1034388aa71e5", "message": "KOGITO-2750 - minor fixes", "committedDate": "2020-07-29T13:55:34Z", "type": "commit"}, {"oid": "22658493f480efbdc99adb5b5cc055a1fe3f160f", "url": "https://github.com/kiegroup/kogito-apps/commit/22658493f480efbdc99adb5b5cc055a1fe3f160f", "message": "KOGITO-2750 - added more tests to DETest", "committedDate": "2020-07-29T14:21:50Z", "type": "commit"}]}