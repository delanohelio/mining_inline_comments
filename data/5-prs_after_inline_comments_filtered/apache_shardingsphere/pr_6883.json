{"pr_number": 6883, "pr_title": "Refactor RdbmsConfiguration", "pr_createdAt": "2020-08-16T14:40:43Z", "pr_url": "https://github.com/apache/shardingsphere/pull/6883", "timeline": [{"oid": "a970d7cc7521ceaab1dd6274dc85d840f39ae803", "url": "https://github.com/apache/shardingsphere/commit/a970d7cc7521ceaab1dd6274dc85d840f39ae803", "message": "Refactor RdbmsConfiguraton(#6687)", "committedDate": "2020-08-16T09:27:43Z", "type": "commit"}, {"oid": "b18ea513d21c2521f9a4d7c2050346ea9a547cc3", "url": "https://github.com/apache/shardingsphere/commit/b18ea513d21c2521f9a4d7c2050346ea9a547cc3", "message": "Refactor SyncConfiguration", "committedDate": "2020-08-16T10:58:29Z", "type": "commit"}, {"oid": "262b97899bf9442b6bfe9ae9a19e4db34bb6ad0d", "url": "https://github.com/apache/shardingsphere/commit/262b97899bf9442b6bfe9ae9a19e4db34bb6ad0d", "message": "Refactor InventoryDataTaskSplitter & SyncTaskFactory", "committedDate": "2020-08-16T11:44:35Z", "type": "commit"}, {"oid": "7c5ff48bdc66b04a84fbefe45d69870b0204310a", "url": "https://github.com/apache/shardingsphere/commit/7c5ff48bdc66b04a84fbefe45d69870b0204310a", "message": "Refactor DumperConfiguration", "committedDate": "2020-08-16T12:14:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTIwMzk3OA==", "url": "https://github.com/apache/shardingsphere/pull/6883#discussion_r471203978", "bodyText": "parameter do not have to align.", "author": "Lucas-307", "createdAt": "2020-08-17T02:40:34Z", "path": "shardingsphere-scaling/shardingsphere-scaling-core/src/main/java/org/apache/shardingsphere/scaling/core/job/preparer/resumer/SyncPositionResumer.java", "diffHunk": "@@ -44,79 +45,79 @@\n  * Synchronize position resumer.\n  */\n public final class SyncPositionResumer {\n-    \n+\n     private final SyncTaskFactory syncTaskFactory = new DefaultSyncTaskFactory();\n-    \n+\n     /**\n      * Resume position from resume from break-point manager.\n      *\n-     * @param shardingScalingJob sharding scaling job\n-     * @param dataSourceManager dataSource manager\n+     * @param shardingScalingJob      sharding scaling job\n+     * @param dataSourceManager       dataSource manager", "originalCommit": "7c5ff48bdc66b04a84fbefe45d69870b0204310a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTIwNDAxMA==", "url": "https://github.com/apache/shardingsphere/pull/6883#discussion_r471204010", "bodyText": "parameter do not have to align.", "author": "Lucas-307", "createdAt": "2020-08-17T02:40:42Z", "path": "shardingsphere-scaling/shardingsphere-scaling-core/src/main/java/org/apache/shardingsphere/scaling/core/job/preparer/resumer/SyncPositionResumer.java", "diffHunk": "@@ -44,79 +45,79 @@\n  * Synchronize position resumer.\n  */\n public final class SyncPositionResumer {\n-    \n+\n     private final SyncTaskFactory syncTaskFactory = new DefaultSyncTaskFactory();\n-    \n+\n     /**\n      * Resume position from resume from break-point manager.\n      *\n-     * @param shardingScalingJob sharding scaling job\n-     * @param dataSourceManager dataSource manager\n+     * @param shardingScalingJob      sharding scaling job\n+     * @param dataSourceManager       dataSource manager\n      * @param resumeBreakPointManager resume from break-point manager\n      */\n     public void resumePosition(final ShardingScalingJob shardingScalingJob, final DataSourceManager dataSourceManager, final ResumeBreakPointManager resumeBreakPointManager) {\n         resumeInventoryPosition(shardingScalingJob, dataSourceManager, resumeBreakPointManager);\n         resumeIncrementalPosition(shardingScalingJob, resumeBreakPointManager);\n     }\n-    \n+\n     private void resumeInventoryPosition(final ShardingScalingJob shardingScalingJob, final DataSourceManager dataSourceManager, final ResumeBreakPointManager resumeBreakPointManager) {\n         List<ScalingTask<InventoryPosition>> allInventoryDataTasks = getAllInventoryDataTasks(shardingScalingJob, dataSourceManager, resumeBreakPointManager);\n         for (Collection<ScalingTask<InventoryPosition>> each : JobPrepareUtil.groupInventoryDataTasks(shardingScalingJob.getSyncConfigurations().get(0).getConcurrency(), allInventoryDataTasks)) {\n             shardingScalingJob.getInventoryDataTasks().add(syncTaskFactory.createInventoryDataSyncTaskGroup(each));\n         }\n     }\n-    \n+\n     private List<ScalingTask<InventoryPosition>> getAllInventoryDataTasks(\n             final ShardingScalingJob shardingScalingJob, final DataSourceManager dataSourceManager, final ResumeBreakPointManager resumeBreakPointManager) {\n         List<ScalingTask<InventoryPosition>> result = new LinkedList<>();\n         for (SyncConfiguration each : shardingScalingJob.getSyncConfigurations()) {\n             MetaDataManager metaDataManager = new MetaDataManager(dataSourceManager.getDataSource(each.getDumperConfiguration().getDataSourceConfiguration()));\n             for (Entry<String, PositionManager<InventoryPosition>> entry : getInventoryPositionMap(each.getDumperConfiguration(), resumeBreakPointManager).entrySet()) {\n-                result.add(syncTaskFactory.createInventoryDataSyncTask(newSyncConfiguration(each, metaDataManager, entry)));\n+                result.add(syncTaskFactory.createInventoryDataSyncTask(newInventoryDumperConfiguration(each.getDumperConfiguration(), metaDataManager, entry), each.getImporterConfiguration()));\n             }\n         }\n         return result;\n     }\n-    \n-    private SyncConfiguration newSyncConfiguration(final SyncConfiguration syncConfiguration, final MetaDataManager metaDataManager, final Entry<String, PositionManager<InventoryPosition>> entry) {\n+\n+    private InventoryDumperConfiguration newInventoryDumperConfiguration(final DumperConfiguration dumperConfiguration, final MetaDataManager metaDataManager,\n+                                                                final Entry<String, PositionManager<InventoryPosition>> entry) {\n         String[] splitTable = entry.getKey().split(\"#\");\n-        RdbmsConfiguration splitDumperConfig = RdbmsConfiguration.clone(syncConfiguration.getDumperConfiguration());\n+        InventoryDumperConfiguration splitDumperConfig = new InventoryDumperConfiguration(dumperConfiguration);\n         splitDumperConfig.setTableName(splitTable[0].split(\"\\\\.\")[1]);\n         splitDumperConfig.setPositionManager(entry.getValue());\n         if (2 == splitTable.length) {\n             splitDumperConfig.setSpiltNum(Integer.parseInt(splitTable[1]));\n         }\n         splitDumperConfig.setPrimaryKey(metaDataManager.getTableMetaData(splitDumperConfig.getTableName()).getPrimaryKeyColumns().get(0));\n-        return new SyncConfiguration(syncConfiguration.getConcurrency(), syncConfiguration.getTableNameMap(),\n-                splitDumperConfig, RdbmsConfiguration.clone(syncConfiguration.getImporterConfiguration()));\n+        return splitDumperConfig;\n     }\n-    \n+\n     private Map<String, PositionManager<InventoryPosition>> getInventoryPositionMap(\n-            final RdbmsConfiguration dumperConfiguration, final ResumeBreakPointManager resumeBreakPointManager) {\n+            final DumperConfiguration dumperConfiguration, final ResumeBreakPointManager resumeBreakPointManager) {\n         Pattern pattern = Pattern.compile(String.format(\"%s\\\\.\\\\w+(#\\\\d+)?\", dumperConfiguration.getDataSourceName()));\n         return resumeBreakPointManager.getInventoryPositionManagerMap().entrySet().stream()\n                 .filter(entry -> pattern.matcher(entry.getKey()).find())\n                 .collect(Collectors.toMap(Entry::getKey, Map.Entry::getValue));\n     }\n-    \n+\n     private void resumeIncrementalPosition(final ShardingScalingJob shardingScalingJob, final ResumeBreakPointManager resumeBreakPointManager) {\n         for (SyncConfiguration each : shardingScalingJob.getSyncConfigurations()) {\n             each.getDumperConfiguration().setPositionManager(resumeBreakPointManager.getIncrementalPositionManagerMap().get(each.getDumperConfiguration().getDataSourceName()));\n-            shardingScalingJob.getIncrementalDataTasks().add(syncTaskFactory.createIncrementalDataSyncTask(each));\n+            shardingScalingJob.getIncrementalDataTasks().add(syncTaskFactory.createIncrementalDataSyncTask(each.getConcurrency(), each.getDumperConfiguration(), each.getImporterConfiguration()));\n         }\n     }\n-    \n+\n     /**\n      * Persist position.\n      *\n-     * @param shardingScalingJob sharding scaling job\n+     * @param shardingScalingJob      sharding scaling job", "originalCommit": "7c5ff48bdc66b04a84fbefe45d69870b0204310a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTIwNDUxNw==", "url": "https://github.com/apache/shardingsphere/pull/6883#discussion_r471204517", "bodyText": "Please remove Cloneable interface. and impl clone() function in other way.", "author": "Lucas-307", "createdAt": "2020-08-17T02:43:03Z", "path": "shardingsphere-scaling/shardingsphere-scaling-core/src/main/java/org/apache/shardingsphere/scaling/core/config/DumperConfiguration.java", "diffHunk": "@@ -17,51 +17,25 @@\n \n package org.apache.shardingsphere.scaling.core.config;\n \n-import lombok.EqualsAndHashCode;\n import lombok.Getter;\n import lombok.Setter;\n-import lombok.SneakyThrows;\n import org.apache.shardingsphere.scaling.core.job.position.PositionManager;\n \n import java.util.Map;\n-import java.util.Set;\n \n /**\n- * Relational database management system configuration.\n+ * Dumper configuration.\n  */\n @Setter\n @Getter\n-@EqualsAndHashCode\n-public final class RdbmsConfiguration implements Cloneable {\n-    \n+public class DumperConfiguration implements Cloneable {", "originalCommit": "7c5ff48bdc66b04a84fbefe45d69870b0204310a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTIwNTgyOA==", "url": "https://github.com/apache/shardingsphere/pull/6883#discussion_r471205828", "bodyText": "how about replace SuppressWarnings with generics? or should we extract positionManager to context?", "author": "Lucas-307", "createdAt": "2020-08-17T02:49:08Z", "path": "shardingsphere-scaling/shardingsphere-scaling-core/src/main/java/org/apache/shardingsphere/scaling/core/config/DumperConfiguration.java", "diffHunk": "@@ -17,51 +17,25 @@\n \n package org.apache.shardingsphere.scaling.core.config;\n \n-import lombok.EqualsAndHashCode;\n import lombok.Getter;\n import lombok.Setter;\n-import lombok.SneakyThrows;\n import org.apache.shardingsphere.scaling.core.job.position.PositionManager;\n \n import java.util.Map;\n-import java.util.Set;\n \n /**\n- * Relational database management system configuration.\n+ * Dumper configuration.\n  */\n @Setter\n @Getter\n-@EqualsAndHashCode\n-public final class RdbmsConfiguration implements Cloneable {\n-    \n+public class DumperConfiguration implements Cloneable {\n+\n     private String dataSourceName;\n-    \n+\n     private DataSourceConfiguration dataSourceConfiguration;\n-    \n-    private String tableName;\n-    \n-    private Map<String, Set<String>> shardingColumnsMap;\n-    \n-    private String primaryKey;\n-    \n+\n     @SuppressWarnings(\"rawtypes\")\n     private PositionManager positionManager;", "originalCommit": "7c5ff48bdc66b04a84fbefe45d69870b0204310a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "26cbd1c083175bc6b7084a1c31ff8da48f0d2f60", "url": "https://github.com/apache/shardingsphere/commit/26cbd1c083175bc6b7084a1c31ff8da48f0d2f60", "message": "For checkstyle", "committedDate": "2020-08-17T10:29:10Z", "type": "commit"}, {"oid": "80d8e614177f8bad292082af510a2bdebdbe3f59", "url": "https://github.com/apache/shardingsphere/commit/80d8e614177f8bad292082af510a2bdebdbe3f59", "message": "For checkstyle", "committedDate": "2020-08-17T10:52:08Z", "type": "commit"}]}