{"pr_number": 235, "pr_title": "DEVX-1560: Running Average KStreams tutorial", "pr_createdAt": "2020-03-03T23:40:03Z", "pr_url": "https://github.com/confluentinc/kafka-tutorials/pull/235", "timeline": [{"oid": "e95cba8cef9fd4966dd20ef089f3de37e2e9b8dd", "url": "https://github.com/confluentinc/kafka-tutorials/commit/e95cba8cef9fd4966dd20ef089f3de37e2e9b8dd", "message": "Implemented the rest of harness", "committedDate": "2020-03-17T18:36:22Z", "type": "forcePushed"}, {"oid": "585c100b5d5c90f14c8649ac225fc23b7e671a6f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/585c100b5d5c90f14c8649ac225fc23b7e671a6f", "message": "Implemented the rest of harness", "committedDate": "2020-03-17T18:55:43Z", "type": "forcePushed"}, {"oid": "35de66bfbf93c8a3a1e15e99bebca7b50b1a3cae", "url": "https://github.com/confluentinc/kafka-tutorials/commit/35de66bfbf93c8a3a1e15e99bebca7b50b1a3cae", "message": "Initial commit of running average example\n\nReverted old stuff and committing only that matters", "committedDate": "2020-03-23T20:01:22Z", "type": "commit"}, {"oid": "35de66bfbf93c8a3a1e15e99bebca7b50b1a3cae", "url": "https://github.com/confluentinc/kafka-tutorials/commit/35de66bfbf93c8a3a1e15e99bebca7b50b1a3cae", "message": "Initial commit of running average example\n\nReverted old stuff and committing only that matters", "committedDate": "2020-03-23T20:01:22Z", "type": "forcePushed"}, {"oid": "061ba02d2dde23b5691b99a56c2851ad58a57d54", "url": "https://github.com/confluentinc/kafka-tutorials/commit/061ba02d2dde23b5691b99a56c2851ad58a57d54", "message": "Fixing output to file and runner", "committedDate": "2020-03-24T20:12:28Z", "type": "commit"}, {"oid": "5be242d57b9dc572af60587e8dd0e3a3451a2796", "url": "https://github.com/confluentinc/kafka-tutorials/commit/5be242d57b9dc572af60587e8dd0e3a3451a2796", "message": "Minor fixes", "committedDate": "2020-03-27T15:56:43Z", "type": "commit"}, {"oid": "180092aea810519ec634a85f9927b453ba410171", "url": "https://github.com/confluentinc/kafka-tutorials/commit/180092aea810519ec634a85f9927b453ba410171", "message": "Tweaking production configuration", "committedDate": "2020-03-27T22:29:30Z", "type": "commit"}, {"oid": "9629b2a89be6f6a7a35322900c4a6acc6bad477a", "url": "https://github.com/confluentinc/kafka-tutorials/commit/9629b2a89be6f6a7a35322900c4a6acc6bad477a", "message": "Update _data/tutorials.yaml\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T04:31:32Z", "type": "commit"}, {"oid": "5d4bcd3755d34f4becc03077d049b67b070a67b4", "url": "https://github.com/confluentinc/kafka-tutorials/commit/5d4bcd3755d34f4becc03077d049b67b070a67b4", "message": "Update _includes/tutorials/aggregating-average/kstreams/markup/dev/make-avro-schema-countsum.adoc\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T04:31:49Z", "type": "commit"}, {"oid": "a809e1eaa081e153845fa614f632088c9cb09abb", "url": "https://github.com/confluentinc/kafka-tutorials/commit/a809e1eaa081e153845fa614f632088c9cb09abb", "message": "Update _includes/tutorials/aggregating-average/kstreams/markup/dev/make-topology.adoc\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T04:32:02Z", "type": "commit"}, {"oid": "5e531df7fb1bf211efd3d727337dc2a96548281f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/5e531df7fb1bf211efd3d727337dc2a96548281f", "message": "Update _data/tutorials.yaml\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T04:39:30Z", "type": "commit"}, {"oid": "c3e14022d0604a24c890c2ed458169a8baa7c949", "url": "https://github.com/confluentinc/kafka-tutorials/commit/c3e14022d0604a24c890c2ed458169a8baa7c949", "message": "Update _data/tutorials.yaml\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T04:39:49Z", "type": "commit"}, {"oid": "778848f464e2b39a879d0a8d5141054f015c1f12", "url": "https://github.com/confluentinc/kafka-tutorials/commit/778848f464e2b39a879d0a8d5141054f015c1f12", "message": "Update _data/tutorials.yaml\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T04:40:04Z", "type": "commit"}, {"oid": "97623ee262176b25408fc461008764a5280365a1", "url": "https://github.com/confluentinc/kafka-tutorials/commit/97623ee262176b25408fc461008764a5280365a1", "message": "Changing order of execution of producer and consumer", "committedDate": "2020-03-30T04:50:13Z", "type": "commit"}, {"oid": "cda03dad6218e4f247726dffaf6549d2f5d4db2a", "url": "https://github.com/confluentinc/kafka-tutorials/commit/cda03dad6218e4f247726dffaf6549d2f5d4db2a", "message": "Update _includes/tutorials/aggregating-average/kstreams/markup/dev/run-producer.adoc\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T15:43:03Z", "type": "commit"}, {"oid": "17359cc713eae044da0b12c652a7c7ee5ef38497", "url": "https://github.com/confluentinc/kafka-tutorials/commit/17359cc713eae044da0b12c652a7c7ee5ef38497", "message": "Update .semaphore/semaphore.yml\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T15:43:21Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDMzNTc0NQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/235#discussion_r400335745", "bodyText": "running the test harness locally the streams app wouldn't shut down changing streams.close() to streams.close(Duration.ofSeconds(5)); fixes that.  Otherwise, the main thread will block forever, waiting for streams to stop.", "author": "bbejeck", "createdAt": "2020-03-30T16:40:21Z", "path": "_includes/tutorials/aggregating-average/kstreams/code/src/main/java/io/confluent/developer/RunningAverage.java", "diffHunk": "@@ -0,0 +1,211 @@\n+package io.confluent.developer;\n+\n+import com.typesafe.config.Config;\n+import com.typesafe.config.ConfigFactory;\n+\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.NewTopic;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.stream.Stream;\n+\n+import io.confluent.demo.CountAndSum;\n+import io.confluent.demo.Rating;\n+import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;\n+import io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde;\n+\n+import static io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG;\n+import static java.lang.Integer.parseInt;\n+import static java.lang.Short.parseShort;\n+import static java.util.Optional.ofNullable;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.kafka.common.serialization.Serdes.Double;\n+import static org.apache.kafka.common.serialization.Serdes.Long;\n+import static org.apache.kafka.streams.StreamsConfig.APPLICATION_ID_CONFIG;\n+import static org.apache.kafka.streams.StreamsConfig.BOOTSTRAP_SERVERS_CONFIG;\n+import static org.apache.kafka.streams.StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG;\n+import static org.apache.kafka.streams.StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG;\n+import static org.apache.kafka.streams.StreamsConfig.REPLICATION_FACTOR_CONFIG;\n+import static org.apache.kafka.streams.kstream.Grouped.with;\n+\n+public class RunningAverage {\n+\n+  //region buildStreamsProperties\n+  protected Properties buildStreamsProperties(Properties envProps) {\n+    Properties config = new Properties();\n+    config.putAll(envProps);\n+\n+    config.put(APPLICATION_ID_CONFIG, envProps.getProperty(\"application.id\"));\n+    config.put(BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(\"bootstrap.servers\"));\n+    config.put(DEFAULT_KEY_SERDE_CLASS_CONFIG, Long().getClass());\n+    config.put(DEFAULT_VALUE_SERDE_CLASS_CONFIG, Double().getClass());\n+    config.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, envProps.getProperty(\"schema.registry.url\"));\n+\n+    config.put(REPLICATION_FACTOR_CONFIG, envProps.getProperty(\"default.topic.replication.factor\"));\n+    config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, envProps.getProperty(\"offset.reset.policy\"));\n+\n+    config.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+\n+    return config;\n+  }\n+  //endregion\n+\n+  //region createTopics\n+\n+  /**\n+   * Create topics using AdminClient API\n+   */\n+  private void createTopics(Properties envProps) {\n+    Map<String, Object> config = new HashMap<>();\n+\n+    config.put(\"bootstrap.servers\", envProps.getProperty(\"bootstrap.servers\"));\n+    AdminClient client = AdminClient.create(config);\n+\n+    List<NewTopic> topics = new ArrayList<>();\n+\n+    topics.add(new NewTopic(\n+        envProps.getProperty(\"input.ratings.topic.name\"),\n+        parseInt(envProps.getProperty(\"input.ratings.topic.partitions\")),\n+        parseShort(envProps.getProperty(\"input.ratings.topic.replication.factor\"))));\n+\n+    topics.add(new NewTopic(\n+        envProps.getProperty(\"output.rating-averages.topic.name\"),\n+        parseInt(envProps.getProperty(\"output.rating-averages.topic.partitions\")),\n+        parseShort(envProps.getProperty(\"output.rating-averages.topic.replication.factor\"))));\n+\n+    client.createTopics(topics);\n+    client.close();\n+\n+  }\n+  //endregion\n+\n+  private void run() {\n+\n+    Properties envProps = this.loadEnvProperties();\n+    Properties streamProps = this.buildStreamsProperties(envProps);\n+    Topology topology = this.buildTopology(new StreamsBuilder(), envProps);\n+\n+    this.createTopics(envProps);\n+\n+    final KafkaStreams streams = new KafkaStreams(topology, streamProps);\n+    final CountDownLatch latch = new CountDownLatch(1);\n+\n+    // Attach shutdown handler to catch Control-C.\n+    Runtime.getRuntime().addShutdownHook(new Thread(\"streams-shutdown-hook\") {\n+      @Override\n+      public void run() {\n+        streams.close();", "originalCommit": "17359cc713eae044da0b12c652a7c7ee5ef38497", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM3NDUzMA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/235#discussion_r400374530", "bodyText": "this one nice @bbejeck\nThanks", "author": "gAmUssA", "createdAt": "2020-03-30T17:40:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDMzNTc0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM4NTE3OQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/235#discussion_r400385179", "bodyText": "done", "author": "gAmUssA", "createdAt": "2020-03-30T17:57:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDMzNTc0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDMzNjkzNQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/235#discussion_r400336935", "bodyText": "running the test-harness locally failed for me, but adding   streams.cleanUp();  before streams.start()  fixes the issue.", "author": "bbejeck", "createdAt": "2020-03-30T16:42:07Z", "path": "_includes/tutorials/aggregating-average/kstreams/code/src/main/java/io/confluent/developer/RunningAverage.java", "diffHunk": "@@ -0,0 +1,211 @@\n+package io.confluent.developer;\n+\n+import com.typesafe.config.Config;\n+import com.typesafe.config.ConfigFactory;\n+\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.NewTopic;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.KGroupedStream;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.stream.Stream;\n+\n+import io.confluent.demo.CountAndSum;\n+import io.confluent.demo.Rating;\n+import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;\n+import io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde;\n+\n+import static io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG;\n+import static java.lang.Integer.parseInt;\n+import static java.lang.Short.parseShort;\n+import static java.util.Optional.ofNullable;\n+import static java.util.stream.Collectors.toMap;\n+import static org.apache.kafka.common.serialization.Serdes.Double;\n+import static org.apache.kafka.common.serialization.Serdes.Long;\n+import static org.apache.kafka.streams.StreamsConfig.APPLICATION_ID_CONFIG;\n+import static org.apache.kafka.streams.StreamsConfig.BOOTSTRAP_SERVERS_CONFIG;\n+import static org.apache.kafka.streams.StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG;\n+import static org.apache.kafka.streams.StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG;\n+import static org.apache.kafka.streams.StreamsConfig.REPLICATION_FACTOR_CONFIG;\n+import static org.apache.kafka.streams.kstream.Grouped.with;\n+\n+public class RunningAverage {\n+\n+  //region buildStreamsProperties\n+  protected Properties buildStreamsProperties(Properties envProps) {\n+    Properties config = new Properties();\n+    config.putAll(envProps);\n+\n+    config.put(APPLICATION_ID_CONFIG, envProps.getProperty(\"application.id\"));\n+    config.put(BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(\"bootstrap.servers\"));\n+    config.put(DEFAULT_KEY_SERDE_CLASS_CONFIG, Long().getClass());\n+    config.put(DEFAULT_VALUE_SERDE_CLASS_CONFIG, Double().getClass());\n+    config.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, envProps.getProperty(\"schema.registry.url\"));\n+\n+    config.put(REPLICATION_FACTOR_CONFIG, envProps.getProperty(\"default.topic.replication.factor\"));\n+    config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, envProps.getProperty(\"offset.reset.policy\"));\n+\n+    config.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+\n+    return config;\n+  }\n+  //endregion\n+\n+  //region createTopics\n+\n+  /**\n+   * Create topics using AdminClient API\n+   */\n+  private void createTopics(Properties envProps) {\n+    Map<String, Object> config = new HashMap<>();\n+\n+    config.put(\"bootstrap.servers\", envProps.getProperty(\"bootstrap.servers\"));\n+    AdminClient client = AdminClient.create(config);\n+\n+    List<NewTopic> topics = new ArrayList<>();\n+\n+    topics.add(new NewTopic(\n+        envProps.getProperty(\"input.ratings.topic.name\"),\n+        parseInt(envProps.getProperty(\"input.ratings.topic.partitions\")),\n+        parseShort(envProps.getProperty(\"input.ratings.topic.replication.factor\"))));\n+\n+    topics.add(new NewTopic(\n+        envProps.getProperty(\"output.rating-averages.topic.name\"),\n+        parseInt(envProps.getProperty(\"output.rating-averages.topic.partitions\")),\n+        parseShort(envProps.getProperty(\"output.rating-averages.topic.replication.factor\"))));\n+\n+    client.createTopics(topics);\n+    client.close();\n+\n+  }\n+  //endregion\n+\n+  private void run() {\n+\n+    Properties envProps = this.loadEnvProperties();\n+    Properties streamProps = this.buildStreamsProperties(envProps);\n+    Topology topology = this.buildTopology(new StreamsBuilder(), envProps);\n+\n+    this.createTopics(envProps);\n+\n+    final KafkaStreams streams = new KafkaStreams(topology, streamProps);\n+    final CountDownLatch latch = new CountDownLatch(1);\n+\n+    // Attach shutdown handler to catch Control-C.\n+    Runtime.getRuntime().addShutdownHook(new Thread(\"streams-shutdown-hook\") {\n+      @Override\n+      public void run() {\n+        streams.close();\n+        latch.countDown();\n+      }\n+    });\n+\n+    try {\n+      streams.start();", "originalCommit": "17359cc713eae044da0b12c652a7c7ee5ef38497", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM1NDY1MQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/235#discussion_r400354651", "bodyText": "snap. I added this but for some reasons, this change isn't there. I agree I will fix it", "author": "gAmUssA", "createdAt": "2020-03-30T17:09:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDMzNjkzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM4NTEzNA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/235#discussion_r400385134", "bodyText": "done", "author": "gAmUssA", "createdAt": "2020-03-30T17:57:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDMzNjkzNQ=="}], "type": "inlineReview"}, {"oid": "53edd2d8e0d97aa19d03b98c9fee18ed6a28eb4e", "url": "https://github.com/confluentinc/kafka-tutorials/commit/53edd2d8e0d97aa19d03b98c9fee18ed6a28eb4e", "message": "Update index.html\n\nCo-Authored-By: Colin Hicks <colin.hicks@confluent.io>", "committedDate": "2020-03-30T17:33:55Z", "type": "commit"}, {"oid": "340c7ee4e393ef866d2502366b14871ead81b251", "url": "https://github.com/confluentinc/kafka-tutorials/commit/340c7ee4e393ef866d2502366b14871ead81b251", "message": "Bump cp version", "committedDate": "2020-03-30T17:56:16Z", "type": "commit"}, {"oid": "815e9c860ab92fd1efaca1704b16a164e807349e", "url": "https://github.com/confluentinc/kafka-tutorials/commit/815e9c860ab92fd1efaca1704b16a164e807349e", "message": "Small fixed to make test reliable", "committedDate": "2020-03-30T17:56:16Z", "type": "commit"}]}