{"pr_number": 1406, "pr_title": "Add cache limit for pending blocks", "pr_createdAt": "2020-09-30T09:25:49Z", "pr_url": "https://github.com/hyperledger/besu/pull/1406", "timeline": [{"oid": "a95e58e57dbe159d13895393be1fb560eeb94c9d", "url": "https://github.com/hyperledger/besu/commit/a95e58e57dbe159d13895393be1fb560eeb94c9d", "message": "add cache limit for pending blocks\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-09-30T09:23:54Z", "type": "commit"}, {"oid": "b73db8efffadc1b5809be501058157a418632ab2", "url": "https://github.com/hyperledger/besu/commit/b73db8efffadc1b5809be501058157a418632ab2", "message": "fix test\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-09-30T12:53:54Z", "type": "commit"}, {"oid": "8a1cf811df724f76c92b3ae38ec20f778462eb41", "url": "https://github.com/hyperledger/besu/commit/8a1cf811df724f76c92b3ae38ec20f778462eb41", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-09-30T12:54:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzUzNTE5Nw==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r497535197", "bodyText": "Probably should make it clear in the variable name that this is a default like DEFAULT_PENDING_BLOCKS_CACHE_SIZE", "author": "RatanRSur", "createdAt": "2020-09-30T14:02:36Z", "path": "ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/sync/state/PendingBlocks.java", "diffHunk": "@@ -27,24 +27,49 @@\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.stream.Collectors;\n \n+import com.google.common.cache.Cache;\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.RemovalListener;\n+\n public class PendingBlocks {\n \n-  private final Map<Hash, Block> pendingBlocks = new ConcurrentHashMap<>();\n+  // If more than 100 behind, Besu switch to full synchronization mode. 150 because it is possible\n+  // to have multiple versions of the same block number\n+  private static final int CACHE_PENDING_BLOCKS_SIZE = 150;", "originalCommit": "8a1cf811df724f76c92b3ae38ec20f778462eb41", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyMTgwNg==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499621806", "bodyText": "Removed", "author": "matkt", "createdAt": "2020-10-05T14:02:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzUzNTE5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU0NDEzNA==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r497544134", "bodyText": "Can this be private?", "author": "RatanRSur", "createdAt": "2020-09-30T14:14:32Z", "path": "ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/sync/state/PendingBlocks.java", "diffHunk": "@@ -64,27 +89,33 @@ public boolean registerPendingBlock(final Block pendingBlock) {\n    * Stop tracking the given block.\n    *\n    * @param block the block that is no longer pending\n-   * @return true if this block was removed\n    */\n-  public boolean deregisterPendingBlock(final Block block) {\n+  public void deregisterPendingBlock(final Block block) {\n+    pendingBlocks.invalidate(block.getHash());\n+  }\n+\n+  /**\n+   * Stop keeping this block in the list of pending blocks by parent hash\n+   *\n+   * @param block the block that is no longer pending\n+   */\n+  public void removePendingBlockByParentHashForBlock(final Block block) {", "originalCommit": "8a1cf811df724f76c92b3ae38ec20f778462eb41", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyMTczNQ==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499621735", "bodyText": "Removed", "author": "matkt", "createdAt": "2020-10-05T14:01:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU0NDEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MzI5OQ==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r497553299", "bodyText": "Can you point me to where this switch happens?", "author": "RatanRSur", "createdAt": "2020-09-30T14:26:14Z", "path": "ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/sync/state/PendingBlocks.java", "diffHunk": "@@ -27,24 +27,49 @@\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.stream.Collectors;\n \n+import com.google.common.cache.Cache;\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.RemovalListener;\n+\n public class PendingBlocks {\n \n-  private final Map<Hash, Block> pendingBlocks = new ConcurrentHashMap<>();\n+  // If more than 100 behind, Besu switch to full synchronization mode. 150 because it is possible\n+  // to have multiple versions of the same block number", "originalCommit": "8a1cf811df724f76c92b3ae38ec20f778462eb41", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYyMzI4OA==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499623288", "bodyText": "the implementation has changed and is no longer based on this behavior. The node does not restart a FullSync if the distance to the head chain is >100 but when it connects to a new peer.", "author": "matkt", "createdAt": "2020-10-05T14:04:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MzI5OQ=="}], "type": "inlineReview"}, {"oid": "12461a2635f4202d465710e6851b434505e1cb2b", "url": "https://github.com/hyperledger/besu/commit/12461a2635f4202d465710e6851b434505e1cb2b", "message": "update cache implementation (add limit per peer)\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-10-05T13:45:00Z", "type": "commit"}, {"oid": "b18c5dd1e250d0c7a0764968b4596a1dae128ffb", "url": "https://github.com/hyperledger/besu/commit/b18c5dd1e250d0c7a0764968b4596a1dae128ffb", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-10-05T14:06:39Z", "type": "commit"}, {"oid": "0082df205d522b21cec66c1ef16537c28d68ba88", "url": "https://github.com/hyperledger/besu/commit/0082df205d522b21cec66c1ef16537c28d68ba88", "message": "clean code\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-10-05T14:12:04Z", "type": "commit"}, {"oid": "2150ed673052177abe3777fa1376c32a29f3e961", "url": "https://github.com/hyperledger/besu/commit/2150ed673052177abe3777fa1376c32a29f3e961", "message": "merge with master\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-10-05T14:13:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYzMzQwNw==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499633407", "bodyText": "I'm not sure we need a REORG_CACHE_SIZE_MUTIPLICATOR. Couldn't we leave it the size of the inverval (40 in this case) and use a bounded priority queue? The highest priority blocks would be those that are lowest in block height and then higher priority if they were sent more recently.", "author": "RatanRSur", "createdAt": "2020-10-05T14:18:46Z", "path": "ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/sync/state/PendingBlocksManager.java", "diffHunk": "@@ -27,35 +30,54 @@\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.stream.Collectors;\n \n-public class PendingBlocks {\n+import org.apache.tuweni.bytes.Bytes;\n \n-  private final Map<Hash, Block> pendingBlocks = new ConcurrentHashMap<>();\n+public class PendingBlocksManager {\n+\n+  private static final int REORG_CACHE_SIZE_FACTOR = 2;\n+\n+  private final PendingBlockCache pendingBlocks;\n   private final Map<Hash, Set<Hash>> pendingBlocksByParentHash = new ConcurrentHashMap<>();\n \n+  public PendingBlocksManager(final SynchronizerConfiguration synchronizerConfiguration) {\n+    pendingBlocks =\n+        new PendingBlockCache(\n+            (Math.abs(synchronizerConfiguration.getBlockPropagationRange().lowerEndpoint())\n+                    + Math.abs(\n+                        synchronizerConfiguration.getBlockPropagationRange().upperEndpoint()))\n+                * REORG_CACHE_SIZE_FACTOR);", "originalCommit": "2150ed673052177abe3777fa1376c32a29f3e961", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY4MjE2Mw==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499682163", "bodyText": "I don't think a queue is the best choice in this case because in my opinion we need to stay on a Map to be able to search for a block by its hash and not just browse the elements. But a priority mechanism could be a good idea.  I can add this mechanism to my cache by creating a custom comparator and instead of refusing to add a block, I will replace the one that has the highest number and which is the older. What do you think ?", "author": "matkt", "createdAt": "2020-10-05T15:24:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYzMzQwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcyMzY0NQ==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499723645", "bodyText": "I checked the SortedMap and knowing that the order must depend on the nodeId, the block Number and the timestamp. It would seem easier to get the lowest priority block using code like this when trying to add a new block (I need to verify that it works).\nprivate Optional<ImmutablePendingBlock> getLowestPriorityBlock(\n      final ImmutablePendingBlock pendingBlock) {\n    \n\n    // get all blocks from the nodeId\n    final Stream<ImmutablePendingBlock> nodeIdBlocks =\n        values().stream().filter(value -> value.nodeId() == pendingBlock.nodeId());\n\n    // get the oldest block\n    final Optional<ImmutablePendingBlock> oldestBlock =\n        nodeIdBlocks.filter(value -> value.nodeId() == pendingBlock.nodeId())\n            .max(Comparator.comparingLong(o -> o.block().getHeader().getNumber())).stream()\n            .findFirst();\n    \n    // filter by number and timestamp\n    return oldestBlock.flatMap(\n        immutablePendingBlock ->\n            nodeIdBlocks\n                .filter(\n                    block ->\n                        block.block().getHeader().getNumber()\n                            == immutablePendingBlock.block().getHeader().getNumber())\n                .min(Comparator.comparingLong(o -> o.block().getHeader().getTimestamp())));\n  }\n\nIn addition, the sorting on a SortedMap seems to be done only on the key during insertion. You have to browse the whole map if you want to sort by value.", "author": "matkt", "createdAt": "2020-10-05T16:26:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYzMzQwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcyNjM0Ng==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499726346", "bodyText": "What do you think about using a queue anyways since it's going to be max of 40 blocks. O(n) with n=40 shouldn't be too bad when searching for hashes and it would make the code less complicated I think. Not sure.", "author": "RatanRSur", "createdAt": "2020-10-05T16:31:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYzMzQwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTczNjA5MQ==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499736091", "bodyText": "not necessarily 40 because if we are looking for a block we will not only search for a single peer but for all the peers so 40 * nbPeers. I will continue to search and see if another solution is possible. The initial idea of \u200b\u200bhaving only a simple implementation that refuse the new blocks was precisely to not impact performance by sorting everytime. Because the case where we have more than 40 blocks will be relatively rare but the sort will be done each time.", "author": "matkt", "createdAt": "2020-10-05T16:47:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYzMzQwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTczODUwNg==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499738506", "bodyText": "another solution would be to add a priority queue for each peer next to the global map. and when adding check in this queue. maybe that's the solution. it will just be necessary to work in the synchronization of these two component. But it doesn't seem complicated because there is already \"pendingBlocksByParentHash\" which is synchronized.\nbut that may be a bit too much", "author": "matkt", "createdAt": "2020-10-05T16:52:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYzMzQwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc0NTU1NQ==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r499745555", "bodyText": "I think I may have a way to simplify the code like this\nprivate Optional<ImmutablePendingBlock> getLowestPriorityBlock(\n      final ImmutablePendingBlock pendingBlock) {\n    final Comparator<ImmutablePendingBlock> comparator =\n        Comparator.comparing(s -> s.block().getHeader().getNumber());\n    return values().stream()\n        .filter(value -> value.nodeId() == pendingBlock.nodeId())\n        .min(comparator.reversed().thenComparing(s -> s.block().getHeader().getTimestamp()));\n  }", "author": "matkt", "createdAt": "2020-10-05T17:04:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTYzMzQwNw=="}], "type": "inlineReview"}, {"oid": "dc2daff5e8309b387c7579db90b01a03f265e5ee", "url": "https://github.com/hyperledger/besu/commit/dc2daff5e8309b387c7579db90b01a03f265e5ee", "message": "change cache eviction mechanism (remove lowest priority block)\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-10-06T13:06:45Z", "type": "commit"}, {"oid": "380eeb17bc927d56d6e6f44febb678f88d69ac4e", "url": "https://github.com/hyperledger/besu/commit/380eeb17bc927d56d6e6f44febb678f88d69ac4e", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-10-06T14:38:32Z", "type": "commit"}, {"oid": "47f012f25b9a1280d9cde83d95ad2c79fe10db82", "url": "https://github.com/hyperledger/besu/commit/47f012f25b9a1280d9cde83d95ad2c79fe10db82", "message": "add tests\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-10-07T09:34:16Z", "type": "commit"}, {"oid": "d96645df9f9e769c34d744aac8dadc515cd1a0f9", "url": "https://github.com/hyperledger/besu/commit/d96645df9f9e769c34d744aac8dadc515cd1a0f9", "message": "merge master\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-10-07T09:35:47Z", "type": "commit"}, {"oid": "23e9955cf6a5c235308f07599ae07ad4c18f6e35", "url": "https://github.com/hyperledger/besu/commit/23e9955cf6a5c235308f07599ae07ad4c18f6e35", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-10-07T09:36:14Z", "type": "commit"}, {"oid": "22aa0cd0954ccfb1137c41425391dbc73b24a641", "url": "https://github.com/hyperledger/besu/commit/22aa0cd0954ccfb1137c41425391dbc73b24a641", "message": "clean code\n\nSigned-off-by: Karim TAAM <karim.t2am@gmail.com>", "committedDate": "2020-10-07T09:43:26Z", "type": "commit"}, {"oid": "c3e49e14b60f3881163016315c23c2c5373c6432", "url": "https://github.com/hyperledger/besu/commit/c3e49e14b60f3881163016315c23c2c5373c6432", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-10-09T08:17:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ5NjUxMg==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r502496512", "bodyText": "I think I'm missing something, why do we need the reversed? Don't we want to keep the lowest block numbers?", "author": "RatanRSur", "createdAt": "2020-10-09T15:08:37Z", "path": "ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/sync/state/cache/PendingBlockCache.java", "diffHunk": "@@ -34,25 +37,39 @@ public PendingBlockCache(final long cacheSizePerPeer) {\n    *\n    * @return the previous value associated with the specified key, or {@code null} if there was no\n    *     mapping for the hash\n-   * @throws IndexOutOfBoundsException if the limit of the number of blocks has been reached for\n-   *     this nodeId\n    */\n   @Override\n   public ImmutablePendingBlock putIfAbsent(\n-      final Hash hash, final ImmutablePendingBlock pendingBlock) throws IndexOutOfBoundsException {\n-    if (getPeerWeight(pendingBlock.nodeId()) >= cacheSizePerPeer) {\n-      throw new IndexOutOfBoundsException();\n+      final Hash hash, final ImmutablePendingBlock pendingBlock) {\n+    final ImmutablePendingBlock foundBlock = super.putIfAbsent(hash, pendingBlock);\n+    if (foundBlock == null) {\n+      removeLowestPriorityBlockWhenCacheFull(pendingBlock.nodeId());\n     }\n-    return super.putIfAbsent(hash, pendingBlock);\n+    return foundBlock;\n   }\n \n   /**\n-   * Returns the number of pending blocks from a node that are stored in the cache\n+   * Removes the lowest priority block if a peer has reached the cache limit it is allowed to use\n+   * The highest priority blocks are those that are lowest in block height and then higher priority\n+   * if they were sent more recently.\n    *\n-   * @param nodeId the peer ID\n-   * @return the number of elements in the cache coming from this node\n+   * @param nodeId id of the peer\n    */\n-  private long getPeerWeight(final Bytes nodeId) {\n-    return values().stream().filter(value -> value.nodeId() == nodeId).count();\n+  private void removeLowestPriorityBlockWhenCacheFull(final Bytes nodeId) {\n+    final List<ImmutablePendingBlock> blockByNodeId =\n+        values().stream().filter(value -> value.nodeId() == nodeId).collect(Collectors.toList());\n+    if (blockByNodeId.size() > cacheSizePerPeer) {\n+      blockByNodeId.stream()\n+          .min(getComparatorByBlockNumber().reversed().thenComparing(getComparatorByTimeStamp()))", "originalCommit": "c3e49e14b60f3881163016315c23c2c5373c6432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjUxOTY2Ng==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r502519666", "bodyText": "Yes The minimum will be done on the result after the two comparators.\n\nSorting by block number is by ascending\nReversing order (now it's descending)\nSorting by timestamp is also by ascending .\nGet the minimum\n\nOtherwise the result would be the smallest number block with the smallest timestamp\nLive sample code : sample code to execute\nfinal List<Block> list = new ArrayList<>();\nlist.add(new Block(4,111111));\nlist.add(new Block(1,2222222));\nlist.add(new Block(4,2222222));\nlist.add(new Block(3,3333333));\nWithout reversed :\nBlock{number=1, timestamp=2222222}\nWith reversed:\nBlock{number=4, timestamp=111111}", "author": "matkt", "createdAt": "2020-10-09T15:45:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ5NjUxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU1OTIxMg==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r502559212", "bodyText": "Right, that's what I thought we wanted. If there's a reorg and a node is sending us new blocks we want to make sure that we keep the ones that are lower because they're the ones we're going to need to import sooner.", "author": "RatanRSur", "createdAt": "2020-10-09T16:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ5NjUxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU1OTY3NA==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r502559674", "bodyText": "They're also the ones we can throw out sooner when they fall out of our import range.", "author": "RatanRSur", "createdAt": "2020-10-09T16:58:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ5NjUxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2ODA0MA==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r502568040", "bodyText": "yes that's what this code does.  we get the block that we want to replace", "author": "matkt", "createdAt": "2020-10-09T17:15:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ5NjUxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI4MjYxMw==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r503282613", "bodyText": "Step by step :\nAt the beginning :\nlist.add(new Block(4,111111));\nlist.add(new Block(1,2222222));\nlist.add(new Block(4,2222222));\nlist.add(new Block(3,3333333));\n1- After getComparatorByBlockNumber:\nBlock{number=1, timestamp=2222222}\nBlock{number=3, timestamp=3333333}\nBlock{number=4, timestamp=111111}\nBlock{number=4, timestamp=2222222}\n2- After reversed :\nBlock{number=4, timestamp=2222222}\nBlock{number=4, timestamp=111111}\nBlock{number=3, timestamp=3333333}\nBlock{number=1, timestamp=2222222}\n3- After getComparatorByTimeStamp :\nBlock{number=4, timestamp=111111}\nBlock{number=4, timestamp=2222222}\nBlock{number=3, timestamp=3333333}\nBlock{number=1, timestamp=2222222}\n4- After min\nBlock{number=4, timestamp=111111}\n-> Replace Block{number=4, timestamp=111111} (lowest priority)", "author": "matkt", "createdAt": "2020-10-12T13:05:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ5NjUxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM1NDI5Nw==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r503354297", "bodyText": "Oh yeah, you're right :)", "author": "RatanRSur", "createdAt": "2020-10-12T14:58:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ5NjUxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2MjQwNA==", "url": "https://github.com/hyperledger/besu/pull/1406#discussion_r502562404", "bodyText": "(optional) Regardless of the outcome of the other thread, if you want you can also represent this with stream operations:\n    values().stream()\n        .filter(value -> value.nodeId() == nodeId)\n        .sorted(comparatorThatHasTheHighestPriorityFirst)\n        .skip(cacheSizePerPeer)\n        .forEach(value -> remove(value.block().getHash()));", "author": "RatanRSur", "createdAt": "2020-10-09T17:03:56Z", "path": "ethereum/eth/src/main/java/org/hyperledger/besu/ethereum/eth/sync/state/cache/PendingBlockCache.java", "diffHunk": "@@ -34,25 +37,39 @@ public PendingBlockCache(final long cacheSizePerPeer) {\n    *\n    * @return the previous value associated with the specified key, or {@code null} if there was no\n    *     mapping for the hash\n-   * @throws IndexOutOfBoundsException if the limit of the number of blocks has been reached for\n-   *     this nodeId\n    */\n   @Override\n   public ImmutablePendingBlock putIfAbsent(\n-      final Hash hash, final ImmutablePendingBlock pendingBlock) throws IndexOutOfBoundsException {\n-    if (getPeerWeight(pendingBlock.nodeId()) >= cacheSizePerPeer) {\n-      throw new IndexOutOfBoundsException();\n+      final Hash hash, final ImmutablePendingBlock pendingBlock) {\n+    final ImmutablePendingBlock foundBlock = super.putIfAbsent(hash, pendingBlock);\n+    if (foundBlock == null) {\n+      removeLowestPriorityBlockWhenCacheFull(pendingBlock.nodeId());\n     }\n-    return super.putIfAbsent(hash, pendingBlock);\n+    return foundBlock;\n   }\n \n   /**\n-   * Returns the number of pending blocks from a node that are stored in the cache\n+   * Removes the lowest priority block if a peer has reached the cache limit it is allowed to use\n+   * The highest priority blocks are those that are lowest in block height and then higher priority\n+   * if they were sent more recently.\n    *\n-   * @param nodeId the peer ID\n-   * @return the number of elements in the cache coming from this node\n+   * @param nodeId id of the peer\n    */\n-  private long getPeerWeight(final Bytes nodeId) {\n-    return values().stream().filter(value -> value.nodeId() == nodeId).count();\n+  private void removeLowestPriorityBlockWhenCacheFull(final Bytes nodeId) {\n+    final List<ImmutablePendingBlock> blockByNodeId =\n+        values().stream().filter(value -> value.nodeId() == nodeId).collect(Collectors.toList());\n+    if (blockByNodeId.size() > cacheSizePerPeer) {\n+      blockByNodeId.stream()\n+          .min(getComparatorByBlockNumber().reversed().thenComparing(getComparatorByTimeStamp()))", "originalCommit": "c3e49e14b60f3881163016315c23c2c5373c6432", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "789d757f5450f0535149b8549b6714618fe726b2", "url": "https://github.com/hyperledger/besu/commit/789d757f5450f0535149b8549b6714618fe726b2", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-10-12T16:22:57Z", "type": "commit"}, {"oid": "8a78e468faec83b197f0f52e4b5bc315dec727f6", "url": "https://github.com/hyperledger/besu/commit/8a78e468faec83b197f0f52e4b5bc315dec727f6", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-10-13T08:29:55Z", "type": "commit"}, {"oid": "024cdbff18a968afb65329b77cc84f7a62206384", "url": "https://github.com/hyperledger/besu/commit/024cdbff18a968afb65329b77cc84f7a62206384", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-10-13T17:02:19Z", "type": "commit"}, {"oid": "ca324e92afe9c41a0b98311be55a2a0a43d7d817", "url": "https://github.com/hyperledger/besu/commit/ca324e92afe9c41a0b98311be55a2a0a43d7d817", "message": "Merge branch 'master' into feature/add-cache-limit-for-pending-blocks", "committedDate": "2020-10-14T12:34:38Z", "type": "commit"}]}