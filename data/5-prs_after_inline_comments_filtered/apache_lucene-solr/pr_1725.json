{"pr_number": 1725, "pr_title": "LUCENE-9449 Skip docs with _doc sort and \"after\"", "pr_createdAt": "2020-08-07T15:49:24Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1725", "timeline": [{"oid": "3fbc44a1642bc2d61f32f82a9c3f58f153aa24a8", "url": "https://github.com/apache/lucene-solr/commit/3fbc44a1642bc2d61f32f82a9c3f58f153aa24a8", "message": "LUCENE-9449 Skip docs with _doc sort and \"after\"\n\nEnhance DocComparator to provide an iterator over competitive documents\nwhen searching with \"after\" FieldDoc.\nThis iterator can quickly position on the desired \"after\" document,\nand skip all documents before \"after\" or even whole segments\nthat contain only documents before \"after\".\n\nRelated to LUCENE-9280", "committedDate": "2020-08-07T15:42:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3MzE0Mg==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r468773142", "bodyText": "Can we force the in to be a FieldComparator.DocComparator ?", "author": "jimczi", "createdAt": "2020-08-11T18:15:31Z", "path": "lucene/core/src/java/org/apache/lucene/search/FilteringDocLeafComparator.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.search;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+\n+import java.io.IOException;\n+\n+/**\n+ * This comparator is used when there is sort by _doc asc together with \"after\" FieldDoc.\n+ * The comparator provides an iterator that can quickly skip to the desired \"after\" document.\n+ */\n+public class FilteringDocLeafComparator implements FilteringLeafFieldComparator {\n+    private final FieldComparator.DocComparator in;\n+    private DocIdSetIterator topValueIterator; // iterator that starts from topValue if possible\n+    private final int minDoc;\n+    private final int maxDoc;\n+    private final int docBase;\n+    private boolean iteratorUpdated = false;\n+\n+    public FilteringDocLeafComparator(LeafFieldComparator in, LeafReaderContext context) {", "originalCommit": "3fbc44a1642bc2d61f32f82a9c3f58f153aa24a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3MzkyMg==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r468773922", "bodyText": "Do we really need to add the hasAfter ? Can we check the if the topValue in the DocComparator is greater than 0 instead ?", "author": "jimczi", "createdAt": "2020-08-11T18:17:01Z", "path": "lucene/core/src/java/org/apache/lucene/search/FilteringFieldComparator.java", "diffHunk": "@@ -68,10 +68,12 @@ public int compareValues(T first, T second) {\n    * @param comparator \u2013 comparator to wrap\n    * @param reverse \u2013 if this sort is reverse\n    * @param singleSort \u2013 true if this sort is based on a single field and there are no other sort fields for tie breaking\n+   * @param hasAfter \u2013 true if this sort has after FieldDoc\n    * @return comparator wrapped as a filtering comparator or the original comparator if the filtering functionality\n    * is not implemented for it\n    */\n-  public static FieldComparator<?> wrapToFilteringComparator(FieldComparator<?> comparator, boolean reverse, boolean singleSort) {\n+  public static FieldComparator<?> wrapToFilteringComparator(FieldComparator<?> comparator, boolean reverse, boolean singleSort,\n+      boolean hasAfter) {", "originalCommit": "3fbc44a1642bc2d61f32f82a9c3f58f153aa24a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NTUyNA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r469565524", "bodyText": "At that moment topValue is not set yet, it will be set later in the constructor of PagingFieldCollector.", "author": "mayya-sharipova", "createdAt": "2020-08-12T21:46:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3MzkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NDM4MQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r468774381", "bodyText": "Can we avoid adding hasAfter here ? See my comment below.", "author": "jimczi", "createdAt": "2020-08-11T18:17:50Z", "path": "lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java", "diffHunk": "@@ -160,18 +160,20 @@ private FieldValueHitQueue(SortField[] fields, int size, boolean filterNonCompet\n    *          The number of hits to retain. Must be greater than zero.\n    * @param filterNonCompetitiveDocs\n    *    {@code true} If comparators should be allowed to filter non-competitive documents, {@code false} otherwise\n+   * @param hasAfter\n+   *    {@code true} If this sort has \"after\" FieldDoc\n    */\n   public static <T extends FieldValueHitQueue.Entry> FieldValueHitQueue<T> create(SortField[] fields, int size,\n-      boolean filterNonCompetitiveDocs) {\n+      boolean filterNonCompetitiveDocs, boolean hasAfter) {", "originalCommit": "3fbc44a1642bc2d61f32f82a9c3f58f153aa24a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NDU5Ng==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r468774596", "bodyText": "Not sure that hasAfter is really needed here.", "author": "jimczi", "createdAt": "2020-08-11T18:18:16Z", "path": "lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java", "diffHunk": "@@ -121,7 +121,7 @@ protected boolean lessThan(final Entry hitA, final Entry hitB) {\n   }\n   \n   // prevent instantiation and extension.\n-  private FieldValueHitQueue(SortField[] fields, int size, boolean filterNonCompetitiveDocs) {\n+  private FieldValueHitQueue(SortField[] fields, int size, boolean filterNonCompetitiveDocs, boolean hasAfter) {", "originalCommit": "3fbc44a1642bc2d61f32f82a9c3f58f153aa24a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NjYzMg==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r469566632", "bodyText": "At this point of time, topValue for comparators is not set yet, that's why we need hasAfter.\nAs an alternative to this implementation, we can pass FieldDoc after to FieldValueHitQueue.create and setTopValue during FieldValueHitQueue creation.", "author": "mayya-sharipova", "createdAt": "2020-08-12T21:49:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NDU5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NDczOQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r468774739", "bodyText": "Not sure that hasAfter is really needed here.", "author": "jimczi", "createdAt": "2020-08-11T18:18:31Z", "path": "lucene/core/src/java/org/apache/lucene/search/FieldValueHitQueue.java", "diffHunk": "@@ -95,8 +95,8 @@ protected boolean lessThan(final Entry hitA, final Entry hitB) {\n    */\n   private static final class MultiComparatorsFieldValueHitQueue<T extends FieldValueHitQueue.Entry> extends FieldValueHitQueue<T> {\n \n-    public MultiComparatorsFieldValueHitQueue(SortField[] fields, int size, boolean filterNonCompetitiveDocs) {\n-      super(fields, size, filterNonCompetitiveDocs);\n+    public MultiComparatorsFieldValueHitQueue(SortField[] fields, int size, boolean filterNonCompetitiveDocs, boolean hasAfter) {", "originalCommit": "3fbc44a1642bc2d61f32f82a9c3f58f153aa24a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTc4MQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r468775781", "bodyText": "Maybe rename to AfterDocLeafComparator ?", "author": "jimczi", "createdAt": "2020-08-11T18:20:17Z", "path": "lucene/core/src/java/org/apache/lucene/search/FilteringDocLeafComparator.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.search;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+\n+import java.io.IOException;\n+\n+/**\n+ * This comparator is used when there is sort by _doc asc together with \"after\" FieldDoc.\n+ * The comparator provides an iterator that can quickly skip to the desired \"after\" document.\n+ */\n+public class FilteringDocLeafComparator implements FilteringLeafFieldComparator {", "originalCommit": "3fbc44a1642bc2d61f32f82a9c3f58f153aa24a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2ODExOQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r469568119", "bodyText": "I like AfterDocLeafComparator, but I renamed to FilteringAfterDocLeafComparator for consistency with all other filtering comparators. Please let me know if you still like it to be renamed", "author": "mayya-sharipova", "createdAt": "2020-08-12T21:53:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc3NTc4MQ=="}], "type": "inlineReview"}, {"oid": "5fcddf791993bce00984f4bd7d6d2fd57184d59f", "url": "https://github.com/apache/lucene-solr/commit/5fcddf791993bce00984f4bd7d6d2fd57184d59f", "message": "Address feedback", "committedDate": "2020-08-12T21:35:25Z", "type": "commit"}, {"oid": "fabfca569b34b28d0a7a7c452e38139c8d67ef00", "url": "https://github.com/apache/lucene-solr/commit/fabfca569b34b28d0a7a7c452e38139c8d67ef00", "message": "Implement filtering functionality in DocComparator", "committedDate": "2020-08-20T19:26:14Z", "type": "commit"}, {"oid": "fabfca569b34b28d0a7a7c452e38139c8d67ef00", "url": "https://github.com/apache/lucene-solr/commit/fabfca569b34b28d0a7a7c452e38139c8d67ef00", "message": "Implement filtering functionality in DocComparator", "committedDate": "2020-08-20T19:26:14Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIzMjA2NQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r474232065", "bodyText": "I don't understand why this function is needed ? Can't you just pass the information when the DocComparator is created in the SortField ?", "author": "jimczi", "createdAt": "2020-08-20T19:44:50Z", "path": "lucene/core/src/java/org/apache/lucene/search/FieldComparator.java", "diffHunk": "@@ -136,6 +136,13 @@ public int compareValues(T first, T second) {\n     }\n   }\n \n+  /**\n+   * Informs the comparator that sorting is done in reverse.\n+   * This is necessary only for skipping functionality.\n+   */\n+  public void setReverse() {", "originalCommit": "fabfca569b34b28d0a7a7c452e38139c8d67ef00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUwNDE0Nw==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r477504147", "bodyText": "addressed in 746c8fa", "author": "mayya-sharipova", "createdAt": "2020-08-26T18:31:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIzMjA2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIzOTM0Ng==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r474239346", "bodyText": "Is  it really needed ? Maybe we should set GREATER_THAN_OR_EQUAL_TO every time a TOP_SCORES collection reaches  the total hits threshold ?", "author": "jimczi", "createdAt": "2020-08-20T19:59:13Z", "path": "lucene/core/src/java/org/apache/lucene/search/FilteringLeafFieldComparator.java", "diffHunk": "@@ -32,8 +33,22 @@\n   DocIdSetIterator competitiveIterator() throws IOException;\n \n   /**\n-   * Informs this leaf comparator that it is allowed to start updating its competitive iterator.\n-   * This method is called from a collector when queue becomes full and threshold is reached.\n+   * Informs this leaf comparator that hits threshold is reached.\n+   * This method is called from a collector when hits threshold is reached.\n+   * For some filtering comparators (e.g. {@code FilteringDocLeafComparator} reaching\n+   * hits threshold is enough to start updating their iterators, even when queue is not yet full.\n    */\n-  void setCanUpdateIterator() throws IOException;\n+  void setHitsThresholdReached() throws IOException;\n+\n+  /**\n+   * Informs this leaf comparator that queue has become full.\n+   * This method is called from a collector when queue becomes full.\n+   */\n+  void setQueueFull() throws IOException;\n+\n+  /**\n+   * Returns {@code true} if the competitive iterator is updated.\n+   * This tells the calling collector that it can update the {@code TotalHits.Relation} to {GREATER_THAN_OR_EQUAL_TO}\n+   */\n+  boolean iteratorUpdated() throws IOException;", "originalCommit": "fabfca569b34b28d0a7a7c452e38139c8d67ef00", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI0MTE5MQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r474241191", "bodyText": "We should be able to early terminate here if the total hits threshold has been reached. If it's not reached yet, we can early terminate later in setHitsThresholdReached.", "author": "jimczi", "createdAt": "2020-08-20T20:02:50Z", "path": "lucene/core/src/java/org/apache/lucene/search/comparators/DocComparator.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.search.comparators;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.FilteringLeafFieldComparator;\n+import org.apache.lucene.search.LeafFieldComparator;\n+import org.apache.lucene.search.Scorable;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Comparator that sorts by asc _doc\n+ */\n+public class DocComparator extends FieldComparator<Integer> {\n+    private final int[] docIDs;\n+    private int topValue;\n+    private boolean topValueSet;\n+    private boolean reverse = false; // only used to check if skipping functionality should be enabled\n+\n+    /** Creates a new comparator based on document ids for {@code numHits} */\n+    public DocComparator(int numHits) {\n+        docIDs = new int[numHits];\n+    }\n+\n+    @Override\n+    public int compare(int slot1, int slot2) {\n+        // No overflow risk because docIDs are non-negative\n+        return docIDs[slot1] - docIDs[slot2];\n+    }\n+\n+\n+    @Override\n+    public LeafFieldComparator getLeafComparator(LeafReaderContext context) {\n+        // TODO: can we \"map\" our docIDs to the current\n+        // reader? saves having to then subtract on every\n+        // compare call\n+        return new DocLeafComparator(context);\n+    }\n+\n+    @Override\n+    public void setTopValue(Integer value) {\n+        topValue = value;\n+        topValueSet = true;\n+    }\n+\n+    @Override\n+    public Integer value(int slot) {\n+        return Integer.valueOf(docIDs[slot]);\n+    }\n+\n+    @Override\n+    public void setReverse() {\n+        reverse = true;\n+    }\n+\n+\n+    /**\n+     * DocLeafComparator with skipping functionality.\n+     * When sort by _doc asc and \"after\" document is set,\n+     * the comparator provides an iterator that can quickly skip to the desired \"after\" document.\n+     */\n+    private class DocLeafComparator implements FilteringLeafFieldComparator {\n+        private final int docBase;\n+        private int bottom;\n+\n+        private final boolean enableSkipping;\n+        private final int minDoc;\n+        private final int maxDoc;\n+        private DocIdSetIterator topValueIterator; // iterator that starts from topValue\n+\n+        private boolean iteratorUpdated = false;\n+\n+        public DocLeafComparator(LeafReaderContext context) {\n+            this.docBase = context.docBase;\n+            // skipping functionality is enabled if topValue is set and sort is asc\n+            this.enableSkipping = topValueSet && reverse == false ? true: false;\n+            if (enableSkipping) {\n+                this.minDoc = topValue + 1;\n+                this.maxDoc = context.reader().maxDoc();\n+                this.topValueIterator = DocIdSetIterator.all(maxDoc);\n+            } else {\n+                this.minDoc = -1;\n+                this.maxDoc = -1;\n+                this.topValueIterator = null;\n+            }\n+        }\n+\n+        @Override\n+        public void setBottom(int slot) {\n+            bottom = docIDs[slot];", "originalCommit": "fabfca569b34b28d0a7a7c452e38139c8d67ef00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI0NDE5OA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r474244198", "bodyText": "Any query sorted by doc id can early terminate after N matches. That's an important aspect of the optimization since it can be handled by the hits threshold transparently. If there is no after value, the threshold should be an upper bound of the number of document that we will collect in the comparator.", "author": "jimczi", "createdAt": "2020-08-20T20:09:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI0MTE5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUwOTI4Nw==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r477509287", "bodyText": "@jimczi  Thank you for your comment. I would like to clarify something:\n\ncan early terminate after N matches\n\nWhat's the way to terminate after N matches here? Is it to update an iterator to an empty iterator?\nIsn't this termination already handled in TopFieldCollector with the code around canEarlyTerminate?\nIs the plan to remove the code around canEarlyTerminate in TopFieldCollector? Should we do after we also handle the case on early termination with the same index and query sort?", "author": "mayya-sharipova", "createdAt": "2020-08-26T18:41:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI0MTE5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDAzOTkzMQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r480039931", "bodyText": "What's the way to terminate after N matches here? Is it to update an iterator to an empty iterator?\n\nI think so, yes. Updating to an empty iterator is what we do for constant score queries for instance.\n\nIsn't this termination already handled in TopFieldCollector with the code around canEarlyTerminate?\n\nThe code is only for sorted index and while I think that we should move this code in the sort comparator, I agree that it's out of the scope of this PR. Early termination should be handled in the field comparator so that we don't need to add new logic in the main collector.", "author": "jimczi", "createdAt": "2020-08-31T10:38:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI0MTE5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM4NjA4Nw==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r480386087", "bodyText": "@jimczi Thanks for the feedback. I have added an early termination after N matches for DocComparator in 21de242.\n\nThe code is only for sorted index\n\nWe also have an early termination in a collector based on _doc order.   I can remove this code later once I can make sure that all queries use DefaultBulkScorer that uses collector's iterator.", "author": "mayya-sharipova", "createdAt": "2020-08-31T20:39:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI0MTE5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM5OTM3OA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r480399378", "bodyText": "Right, sorry I forgot that we added the early termination logic for _doc order in the collector. Maybe that's ok to leave it as it is then. We can revise after we ensure that all bulk scorer uses the collector's iterator ?", "author": "jimczi", "createdAt": "2020-08-31T21:07:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI0MTE5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTAxMTEyNg==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r481011126", "bodyText": "@jimczi That sounds good to me.  Thank you for the feedback.  Do you have any further comments for this PR?", "author": "mayya-sharipova", "createdAt": "2020-09-01T09:48:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI0MTE5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI1MzEwNQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r474253105", "bodyText": "That seems redundant. I think we can add a single method: setHitsThresholdReached(int). We have all the other contexts needed in the LeafFieldComparator. The complexity is that setBottom and setHitsThresholdReached(int) are called on the leaves even though they are global events. Maybe forcing the hierarchy of the filtering fields to use a SimpleFieldComparator could simplify things ? This way you don't have to repeat redundant informations (hits threshold and queue full) on each leave.", "author": "jimczi", "createdAt": "2020-08-20T20:26:43Z", "path": "lucene/core/src/java/org/apache/lucene/search/FilteringLeafFieldComparator.java", "diffHunk": "@@ -32,8 +33,22 @@\n   DocIdSetIterator competitiveIterator() throws IOException;\n \n   /**\n-   * Informs this leaf comparator that it is allowed to start updating its competitive iterator.\n-   * This method is called from a collector when queue becomes full and threshold is reached.\n+   * Informs this leaf comparator that hits threshold is reached.\n+   * This method is called from a collector when hits threshold is reached.\n+   * For some filtering comparators (e.g. {@code FilteringDocLeafComparator} reaching\n+   * hits threshold is enough to start updating their iterators, even when queue is not yet full.\n    */\n-  void setCanUpdateIterator() throws IOException;\n+  void setHitsThresholdReached() throws IOException;\n+\n+  /**\n+   * Informs this leaf comparator that queue has become full.\n+   * This method is called from a collector when queue becomes full.\n+   */\n+  void setQueueFull() throws IOException;", "originalCommit": "fabfca569b34b28d0a7a7c452e38139c8d67ef00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUwNDMzNw==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r477504337", "bodyText": "addressed in 746c8fa", "author": "mayya-sharipova", "createdAt": "2020-08-26T18:31:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI1MzEwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI1NDMzMw==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r474254333", "bodyText": "See my previous comment, I think we should call setHitsThresholdReached once, when the threshold is reached.\nSame for setQueueFull that is already call in setBottom. Said differently, this part could be entirely removed ;).", "author": "jimczi", "createdAt": "2020-08-20T20:29:20Z", "path": "lucene/core/src/java/org/apache/lucene/search/TopFieldCollector.java", "diffHunk": "@@ -150,11 +150,15 @@ public void setScorer(Scorable scorer) throws IOException {\n       if (minScoreAcc != null) {\n         updateGlobalMinCompetitiveScore(scorer);\n       }\n-      if (filteringLeafComparator != null && queueFull && hitsThresholdChecker.isThresholdReached()) {\n-        // if queue became full and hitsThreshold was reached in previous segments,\n-        // notify this segment's leaf comparator that its competitive iterator can be updated\n-        filteringLeafComparator.setCanUpdateIterator();\n-        totalHitsRelation = TotalHits.Relation.GREATER_THAN_OR_EQUAL_TO;\n+\n+      if (filteringLeafComparator != null && hitsThresholdChecker.isThresholdReached()) {\n+        // hitsThreshold was reached in previous segments, notify this segment's leaf comparator about it\n+        filteringLeafComparator.setHitsThresholdReached();\n+        // if queue became full in previous segments, notify this segment's leaf comparator about it\n+        if (queueFull) filteringLeafComparator.setQueueFull();\n+        if (filteringLeafComparator.iteratorUpdated()) {\n+          totalHitsRelation = TotalHits.Relation.GREATER_THAN_OR_EQUAL_TO;\n+        }", "originalCommit": "fabfca569b34b28d0a7a7c452e38139c8d67ef00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzUwNDQzNg==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r477504436", "bodyText": "addressed in 746c8fa", "author": "mayya-sharipova", "createdAt": "2020-08-26T18:32:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDI1NDMzMw=="}], "type": "inlineReview"}, {"oid": "746c8fac88011c61b5e1ed083229724a45993a49", "url": "https://github.com/apache/lucene-solr/commit/746c8fac88011c61b5e1ed083229724a45993a49", "message": "Address feedback 2\n\n- Redesign numeric comparators so by default they provide skipping\nfunctionality. This resuled in moving comparators to a separate\npackage.\n\n- Remove unnecessary filtering comparator classes, as by default\ncomparators provide skipping functionality\n\n- Remove unncessary checks in TopFieldCollector", "committedDate": "2020-08-26T15:47:46Z", "type": "commit"}, {"oid": "21de24296019674f655e1754687a9eed27f0c4c6", "url": "https://github.com/apache/lucene-solr/commit/21de24296019674f655e1754687a9eed27f0c4c6", "message": "DocComparator return empty iterator after topN hits", "committedDate": "2020-08-31T20:27:24Z", "type": "commit"}, {"oid": "26534c5f4ecc5feae42f7fa1f5946b2ecfa03ca5", "url": "https://github.com/apache/lucene-solr/commit/26534c5f4ecc5feae42f7fa1f5946b2ecfa03ca5", "message": "Merge remote-tracking branch 'upstream/master' into sort-by-doc-optim", "committedDate": "2020-08-31T20:34:33Z", "type": "commit"}, {"oid": "4252fcd88f3b93c1e0b66a8a130e9278115d660e", "url": "https://github.com/apache/lucene-solr/commit/4252fcd88f3b93c1e0b66a8a130e9278115d660e", "message": "Add package info", "committedDate": "2020-08-31T20:58:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM4MTY1NA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r481381654", "bodyText": "Should it be activated only if the comparator is used as the primary sort ?", "author": "jimczi", "createdAt": "2020-09-01T19:30:00Z", "path": "lucene/core/src/java/org/apache/lucene/search/comparators/DocComparator.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.search.comparators;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.LeafFieldComparator;\n+import org.apache.lucene.search.Scorable;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Comparator that sorts by asc _doc\n+ */\n+public class DocComparator extends FieldComparator<Integer> {\n+    private final int[] docIDs;\n+    private final boolean enableSkipping; // if skipping functionality should be enabled\n+    private int bottom;\n+    private int topValue;\n+    private boolean topValueSet;\n+    private boolean bottomValueSet;\n+    private boolean hitsThresholdReached;\n+\n+    /** Creates a new comparator based on document ids for {@code numHits} */\n+    public DocComparator(int numHits, boolean reverse) {\n+        this.docIDs = new int[numHits];\n+        // skipping functionality is enabled if we are sorting by _doc in asc order", "originalCommit": "4252fcd88f3b93c1e0b66a8a130e9278115d660e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ0MzU0NA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r481443544", "bodyText": "@jimczi Thanks Jim. We also had an implicit protection for a primary sort in MultiLeafFieldComparator.java, but I agree it is good to explicitly indicate a primary sort.\nAddressed in 485fe4f", "author": "mayya-sharipova", "createdAt": "2020-09-01T21:30:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM4MTY1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ3MzAxMg==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r481473012", "bodyText": "We also had an implicit protection for a primary sort\n\nOk I see so the expectation is that setHitsThresholdReached is only called on the primary sort and we use it as a signal to enable skipping.\n\nAddressed in 485fe4f\n\nI was thinking that we could use the information exposed in SortField#getComparator, we don't need to add a new callback. However, I think we can rely on what you describe above, setHitsThresholdReached and competitiveIterator are the callbacks that we need to enable the optimization. Sorry for the back and forth but I we probably don't need 485fe4f ;).", "author": "jimczi", "createdAt": "2020-09-01T22:44:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM4MTY1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjEwNTYyMA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r482105620", "bodyText": "@jimczi Thanks for the feedback.\n\nI was thinking that we could use the information exposed in SortField#getComparator, we don't need to add a new callback\n\nGood point, I haven't noticed that before, I've refactored the code to use sortPos from this function. Addressed in 92fa246\n\nHowever, I think we can rely on what you describe above, setHitsThresholdReached and competitiveIterator are the callbacks that we need to enable the optimization.   ... we probably don't need 485fe4f\n\nDoing sort optimization only on primary sort in MultiLeafFieldComparator is implicit and some refactoring of it may bring wrong result. So I think it is good to have extra protection", "author": "mayya-sharipova", "createdAt": "2020-09-02T14:18:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM4MTY1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM4MjUzMA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r481382530", "bodyText": "Can you add a comment explaining that early termination is already implemented in the collector but we'll remove in a follow up ?", "author": "jimczi", "createdAt": "2020-09-01T19:31:41Z", "path": "lucene/core/src/java/org/apache/lucene/search/comparators/DocComparator.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.search.comparators;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.apache.lucene.search.DocIdSetIterator;\n+import org.apache.lucene.search.FieldComparator;\n+import org.apache.lucene.search.LeafFieldComparator;\n+import org.apache.lucene.search.Scorable;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Comparator that sorts by asc _doc\n+ */\n+public class DocComparator extends FieldComparator<Integer> {\n+    private final int[] docIDs;\n+    private final boolean enableSkipping; // if skipping functionality should be enabled\n+    private int bottom;\n+    private int topValue;\n+    private boolean topValueSet;\n+    private boolean bottomValueSet;\n+    private boolean hitsThresholdReached;\n+\n+    /** Creates a new comparator based on document ids for {@code numHits} */\n+    public DocComparator(int numHits, boolean reverse) {\n+        this.docIDs = new int[numHits];\n+        // skipping functionality is enabled if we are sorting by _doc in asc order\n+        this.enableSkipping = (reverse == false);\n+    }\n+\n+    @Override\n+    public int compare(int slot1, int slot2) {\n+        // No overflow risk because docIDs are non-negative\n+        return docIDs[slot1] - docIDs[slot2];\n+    }\n+\n+\n+    @Override\n+    public LeafFieldComparator getLeafComparator(LeafReaderContext context) {\n+        // TODO: can we \"map\" our docIDs to the current\n+        // reader? saves having to then subtract on every\n+        // compare call\n+        return new DocLeafComparator(context);\n+    }\n+\n+    @Override\n+    public void setTopValue(Integer value) {\n+        topValue = value;\n+        topValueSet = true;\n+    }\n+\n+    @Override\n+    public Integer value(int slot) {\n+        return Integer.valueOf(docIDs[slot]);\n+    }\n+\n+\n+    /**\n+     * DocLeafComparator with skipping functionality.\n+     * When sort by _doc asc, after collecting top N matches and enough hits, the comparator\n+     * can skip all the following documents.\n+     * When sort by _doc asc and \"top\" document is set after which search should start,\n+     * the comparator provides an iterator that can quickly skip to the desired \"top\" document.\n+     */\n+    private class DocLeafComparator implements LeafFieldComparator {\n+        private final int docBase;\n+        private final int minDoc;\n+        private final int maxDoc;\n+        private DocIdSetIterator competitiveIterator; // iterator that starts from topValue\n+\n+        public DocLeafComparator(LeafReaderContext context) {\n+            this.docBase = context.docBase;\n+            if (enableSkipping) {\n+                this.minDoc = topValue + 1;\n+                this.maxDoc = context.reader().maxDoc();\n+                this.competitiveIterator = DocIdSetIterator.all(maxDoc);\n+            } else {\n+                this.minDoc = -1;\n+                this.maxDoc = -1;\n+                this.competitiveIterator = null;\n+            }\n+        }\n+\n+        @Override\n+        public void setBottom(int slot) {\n+            bottom = docIDs[slot];\n+            bottomValueSet = true;\n+            updateIterator();\n+        }\n+\n+        @Override\n+        public int compareBottom(int doc) {\n+            // No overflow risk because docIDs are non-negative\n+            return bottom - (docBase + doc);\n+        }\n+\n+        @Override\n+        public int compareTop(int doc) {\n+            int docValue = docBase + doc;\n+            return Integer.compare(topValue, docValue);\n+        }\n+\n+        @Override\n+        public void copy(int slot, int doc) throws IOException {\n+            docIDs[slot] = docBase + doc;\n+        }\n+\n+        @Override\n+        public void setScorer(Scorable scorer) throws IOException {\n+            // update an iterator on a new segment\n+            updateIterator();\n+        }\n+\n+        @Override\n+        public DocIdSetIterator competitiveIterator() {\n+            if (enableSkipping == false) {\n+                return null;\n+            } else {\n+                return new DocIdSetIterator() {\n+                    private int doc;\n+\n+                    @Override\n+                    public int nextDoc() throws IOException {\n+                        return doc = competitiveIterator.nextDoc();\n+                    }\n+\n+                    @Override\n+                    public int docID() {\n+                        return doc;\n+                    }\n+\n+                    @Override\n+                    public long cost() {\n+                        return competitiveIterator.cost();\n+                    }\n+\n+                    @Override\n+                    public int advance(int target) throws IOException {\n+                        return doc = competitiveIterator.advance(target);\n+                    }\n+                };\n+            }\n+        }\n+\n+        @Override\n+        public void setHitsThresholdReached() {\n+            hitsThresholdReached = true;\n+            updateIterator();\n+        }\n+\n+        private void updateIterator() {\n+            if (enableSkipping == false || hitsThresholdReached == false) return;\n+            if (bottomValueSet) {\n+                // since we've collected top N matches, we can early terminate", "originalCommit": "4252fcd88f3b93c1e0b66a8a130e9278115d660e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ0MTY2NA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r481441664", "bodyText": "addressed in 485fe4f", "author": "mayya-sharipova", "createdAt": "2020-09-01T21:26:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTM4MjUzMA=="}], "type": "inlineReview"}, {"oid": "485fe4f532bada2926ad0d38a58496b1d5e93f23", "url": "https://github.com/apache/lucene-solr/commit/485fe4f532bada2926ad0d38a58496b1d5e93f23", "message": "Enable skipping functionality only on primary sort\n\nAdd a note to remove early termination in collector", "committedDate": "2020-09-01T21:24:40Z", "type": "commit"}, {"oid": "a7c4e8592b0929464e5758f865c977a67d97ccd7", "url": "https://github.com/apache/lucene-solr/commit/a7c4e8592b0929464e5758f865c977a67d97ccd7", "message": "Revert \"Enable skipping functionality only on primary sort\"\n\nThis reverts commit 485fe4f532bada2926ad0d38a58496b1d5e93f23.", "committedDate": "2020-09-02T13:32:10Z", "type": "commit"}, {"oid": "92fa246c52ad5e25f7388e2ae0fadf173cc347da", "url": "https://github.com/apache/lucene-solr/commit/92fa246c52ad5e25f7388e2ae0fadf173cc347da", "message": "Enable skipping functionality only on primary sort\n\nAdd a note to remove early termination in collector", "committedDate": "2020-09-02T14:34:33Z", "type": "commit"}, {"oid": "92fa246c52ad5e25f7388e2ae0fadf173cc347da", "url": "https://github.com/apache/lucene-solr/commit/92fa246c52ad5e25f7388e2ae0fadf173cc347da", "message": "Enable skipping functionality only on primary sort\n\nAdd a note to remove early termination in collector", "committedDate": "2020-09-02T14:34:33Z", "type": "forcePushed"}, {"oid": "27ff5193874ad417a66b5bcfad8291f631a8ca24", "url": "https://github.com/apache/lucene-solr/commit/27ff5193874ad417a66b5bcfad8291f631a8ca24", "message": "Adding documentation to leaf comparators", "committedDate": "2020-09-02T17:49:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzUzMTgyNw==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r483531827", "bodyText": "why do you need that many documents ? 100 should be enough, no ?", "author": "jimczi", "createdAt": "2020-09-04T10:28:35Z", "path": "lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping.java", "diffHunk": "@@ -290,5 +299,114 @@ public void testFloatSortOptimization() throws IOException {\n     dir.close();\n   }\n \n+  public void testDocSortOptimizationWithAfter() throws IOException {\n+    final Directory dir = newDirectory();\n+    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n+    final int numDocs = atLeast(1500);\n+    for (int i = 0; i < numDocs; ++i) {\n+      final Document doc = new Document();\n+      writer.addDocument(doc);\n+      if ((i > 0) && (i % 500 == 0)) {\n+        writer.commit();\n+      }\n+    }\n+    final IndexReader reader = DirectoryReader.open(writer);\n+    IndexSearcher searcher = new IndexSearcher(reader);\n+    final int numHits = 3;\n+    final int totalHitsThreshold = 3;\n+    final int searchAfter = 1400;\n+\n+    // sort by _doc with search after should trigger optimization\n+    {\n+      final Sort sort = new Sort(FIELD_DOC);\n+      FieldDoc after = new FieldDoc(searchAfter, Float.NaN, new Integer[]{searchAfter});\n+      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n+      searcher.search(new MatchAllDocsQuery(), collector);\n+      TopDocs topDocs = collector.topDocs();\n+      assertEquals(topDocs.scoreDocs.length, numHits);\n+      for (int i = 0; i < numHits; i++) {\n+        int expectedDocID = searchAfter + 1 + i;\n+        assertEquals(expectedDocID, topDocs.scoreDocs[i].doc);\n+      }\n+      assertTrue(collector.isEarlyTerminated());\n+      // check that very few hits were collected, and most hits before searchAfter were skipped\n+      assertTrue(topDocs.totalHits.value < (numDocs - searchAfter));\n+    }\n+\n+    // sort by _doc + _score with search after should trigger optimization\n+    {\n+      final Sort sort = new Sort(FIELD_DOC, FIELD_SCORE);\n+      FieldDoc after = new FieldDoc(searchAfter, Float.NaN, new Object[]{searchAfter, 1.0f});\n+      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n+      searcher.search(new MatchAllDocsQuery(), collector);\n+      TopDocs topDocs = collector.topDocs();\n+      assertEquals(topDocs.scoreDocs.length, numHits);\n+      for (int i = 0; i < numHits; i++) {\n+        int expectedDocID = searchAfter + 1 + i;\n+        assertEquals(expectedDocID, topDocs.scoreDocs[i].doc);\n+      }\n+      assertTrue(collector.isEarlyTerminated());\n+      // assert that very few hits were collected, and most hits before searchAfter were skipped\n+      assertTrue(topDocs.totalHits.value < (numDocs - searchAfter));\n+    }\n+\n+    // sort by _doc desc should not trigger optimization\n+    {\n+      final Sort sort = new Sort(new SortField(null, SortField.Type.DOC, true));\n+      FieldDoc after = new FieldDoc(searchAfter, Float.NaN, new Integer[]{searchAfter});\n+      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n+      searcher.search(new MatchAllDocsQuery(), collector);\n+      TopDocs topDocs = collector.topDocs();\n+      for (int i = 0; i < numHits; i++) {\n+        int expectedDocID = searchAfter - 1 - i;\n+        assertEquals(expectedDocID, topDocs.scoreDocs[i].doc);\n+      }\n+      assertEquals(topDocs.scoreDocs.length, numHits);\n+      // assert that many hits were collected including all hits before searchAfter\n+      assertTrue(topDocs.totalHits.value > searchAfter);\n+\n+    }\n+\n+    writer.close();\n+    reader.close();\n+    dir.close();\n+  }\n+\n+\n+  public void testDocSortOptimization() throws IOException {\n+    final Directory dir = newDirectory();\n+    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n+    final int numDocs = atLeast(1500);", "originalCommit": "27ff5193874ad417a66b5bcfad8291f631a8ca24", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk1MzQwMg==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r484953402", "bodyText": "Addressed in 493d9eb", "author": "mayya-sharipova", "createdAt": "2020-09-08T14:13:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzUzMTgyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzUzMjI2Mg==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r483532262", "bodyText": "Can you add a test with a boolean query or a simple filter ?", "author": "jimczi", "createdAt": "2020-09-04T10:29:34Z", "path": "lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping.java", "diffHunk": "@@ -290,5 +299,114 @@ public void testFloatSortOptimization() throws IOException {\n     dir.close();\n   }\n \n+  public void testDocSortOptimizationWithAfter() throws IOException {\n+    final Directory dir = newDirectory();\n+    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n+    final int numDocs = atLeast(1500);\n+    for (int i = 0; i < numDocs; ++i) {\n+      final Document doc = new Document();\n+      writer.addDocument(doc);\n+      if ((i > 0) && (i % 500 == 0)) {\n+        writer.commit();\n+      }\n+    }\n+    final IndexReader reader = DirectoryReader.open(writer);\n+    IndexSearcher searcher = new IndexSearcher(reader);\n+    final int numHits = 3;\n+    final int totalHitsThreshold = 3;\n+    final int searchAfter = 1400;\n+\n+    // sort by _doc with search after should trigger optimization\n+    {\n+      final Sort sort = new Sort(FIELD_DOC);\n+      FieldDoc after = new FieldDoc(searchAfter, Float.NaN, new Integer[]{searchAfter});\n+      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n+      searcher.search(new MatchAllDocsQuery(), collector);\n+      TopDocs topDocs = collector.topDocs();\n+      assertEquals(topDocs.scoreDocs.length, numHits);\n+      for (int i = 0; i < numHits; i++) {\n+        int expectedDocID = searchAfter + 1 + i;\n+        assertEquals(expectedDocID, topDocs.scoreDocs[i].doc);\n+      }\n+      assertTrue(collector.isEarlyTerminated());\n+      // check that very few hits were collected, and most hits before searchAfter were skipped\n+      assertTrue(topDocs.totalHits.value < (numDocs - searchAfter));\n+    }\n+\n+    // sort by _doc + _score with search after should trigger optimization\n+    {\n+      final Sort sort = new Sort(FIELD_DOC, FIELD_SCORE);\n+      FieldDoc after = new FieldDoc(searchAfter, Float.NaN, new Object[]{searchAfter, 1.0f});\n+      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n+      searcher.search(new MatchAllDocsQuery(), collector);\n+      TopDocs topDocs = collector.topDocs();\n+      assertEquals(topDocs.scoreDocs.length, numHits);\n+      for (int i = 0; i < numHits; i++) {\n+        int expectedDocID = searchAfter + 1 + i;\n+        assertEquals(expectedDocID, topDocs.scoreDocs[i].doc);\n+      }\n+      assertTrue(collector.isEarlyTerminated());\n+      // assert that very few hits were collected, and most hits before searchAfter were skipped\n+      assertTrue(topDocs.totalHits.value < (numDocs - searchAfter));\n+    }\n+\n+    // sort by _doc desc should not trigger optimization\n+    {\n+      final Sort sort = new Sort(new SortField(null, SortField.Type.DOC, true));\n+      FieldDoc after = new FieldDoc(searchAfter, Float.NaN, new Integer[]{searchAfter});\n+      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n+      searcher.search(new MatchAllDocsQuery(), collector);\n+      TopDocs topDocs = collector.topDocs();\n+      for (int i = 0; i < numHits; i++) {\n+        int expectedDocID = searchAfter - 1 - i;\n+        assertEquals(expectedDocID, topDocs.scoreDocs[i].doc);\n+      }\n+      assertEquals(topDocs.scoreDocs.length, numHits);\n+      // assert that many hits were collected including all hits before searchAfter\n+      assertTrue(topDocs.totalHits.value > searchAfter);\n+\n+    }\n+\n+    writer.close();\n+    reader.close();\n+    dir.close();\n+  }\n+\n+\n+  public void testDocSortOptimization() throws IOException {\n+    final Directory dir = newDirectory();\n+    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n+    final int numDocs = atLeast(1500);\n+    for (int i = 0; i < numDocs; ++i) {\n+      final Document doc = new Document();\n+      writer.addDocument(doc);\n+      if ((i > 0) && (i % 500 == 0)) {\n+        writer.commit();\n+      }\n+    }\n+    final IndexReader reader = DirectoryReader.open(writer);\n+    IndexSearcher searcher = new IndexSearcher(reader);\n+    final int numHits = 3;\n+    final int totalHitsThreshold = 3;\n+\n+    // sort by _doc should skip all non-competitive documents\n+    {\n+      final Sort sort = new Sort(FIELD_DOC);\n+      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n+      searcher.search(new MatchAllDocsQuery(), collector);\n+      TopDocs topDocs = collector.topDocs();\n+      assertEquals(topDocs.scoreDocs.length, numHits);\n+      for (int i = 0; i < numHits; i++) {\n+        assertEquals(i, topDocs.scoreDocs[i].doc);\n+      }\n+      assertTrue(collector.isEarlyTerminated());\n+      // check that very few hits were collected\n+      assertTrue(topDocs.totalHits.value < 5);\n+    }", "originalCommit": "27ff5193874ad417a66b5bcfad8291f631a8ca24", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzUzMjc2MA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r483532760", "bodyText": "1500 seems big for a unit test ;)", "author": "jimczi", "createdAt": "2020-09-04T10:30:33Z", "path": "lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping.java", "diffHunk": "@@ -290,5 +299,114 @@ public void testFloatSortOptimization() throws IOException {\n     dir.close();\n   }\n \n+  public void testDocSortOptimizationWithAfter() throws IOException {\n+    final Directory dir = newDirectory();\n+    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n+    final int numDocs = atLeast(1500);", "originalCommit": "27ff5193874ad417a66b5bcfad8291f631a8ca24", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk1MzY4Ng==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r484953686", "bodyText": "Addressed in 493d9eb", "author": "mayya-sharipova", "createdAt": "2020-09-08T14:14:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzUzMjc2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzUzMzEwNQ==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r483533105", "bodyText": "you can try different values of  search after in a loop to increase the coverage?", "author": "jimczi", "createdAt": "2020-09-04T10:31:17Z", "path": "lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping.java", "diffHunk": "@@ -290,5 +299,114 @@ public void testFloatSortOptimization() throws IOException {\n     dir.close();\n   }\n \n+  public void testDocSortOptimizationWithAfter() throws IOException {\n+    final Directory dir = newDirectory();\n+    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n+    final int numDocs = atLeast(1500);\n+    for (int i = 0; i < numDocs; ++i) {\n+      final Document doc = new Document();\n+      writer.addDocument(doc);\n+      if ((i > 0) && (i % 500 == 0)) {\n+        writer.commit();\n+      }\n+    }\n+    final IndexReader reader = DirectoryReader.open(writer);\n+    IndexSearcher searcher = new IndexSearcher(reader);\n+    final int numHits = 3;\n+    final int totalHitsThreshold = 3;\n+    final int searchAfter = 1400;\n+\n+    // sort by _doc with search after should trigger optimization", "originalCommit": "27ff5193874ad417a66b5bcfad8291f631a8ca24", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDk1MzgwOA==", "url": "https://github.com/apache/lucene-solr/pull/1725#discussion_r484953808", "bodyText": "Addressed in 493d9eb", "author": "mayya-sharipova", "createdAt": "2020-09-08T14:14:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzUzMzEwNQ=="}], "type": "inlineReview"}, {"oid": "493d9eb174d30886a248eaa5c2f744f72e98f630", "url": "https://github.com/apache/lucene-solr/commit/493d9eb174d30886a248eaa5c2f744f72e98f630", "message": "Address feedback for test", "committedDate": "2020-09-08T14:10:27Z", "type": "commit"}, {"oid": "45577aa6e7e504c01fbdff38ee35ad9ef36c6380", "url": "https://github.com/apache/lucene-solr/commit/45577aa6e7e504c01fbdff38ee35ad9ef36c6380", "message": "Merge remote-tracking branch 'upstream/master' into sort-by-doc-optim", "committedDate": "2020-09-08T17:52:30Z", "type": "commit"}, {"oid": "e69fa27efb58db462c8baee213bef4b4f3d92585", "url": "https://github.com/apache/lucene-solr/commit/e69fa27efb58db462c8baee213bef4b4f3d92585", "message": "Make a constructor of NumericComparator protected", "committedDate": "2020-09-08T17:54:41Z", "type": "commit"}]}