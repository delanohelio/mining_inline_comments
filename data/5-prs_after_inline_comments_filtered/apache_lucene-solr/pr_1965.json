{"pr_number": 1965, "pr_title": "LUCENE-9572 - TypeAsSynonymFilter gains selective flag transfer and an ignore list.", "pr_createdAt": "2020-10-08T16:15:13Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1965", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg1NTg4NA==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504855884", "bodyText": "This should not call getAttribute and instead use the instance flagsAtt above (instance field). In the next line it's correct.", "author": "uschindler", "createdAt": "2020-10-14T17:37:48Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilter.java", "diffHunk": "@@ -64,9 +82,15 @@ public boolean incrementToken() throws IOException {\n       }\n       termAtt.append(typeAtt.type());\n       posIncrAtt.setPositionIncrement(0);\n+      // control what flags transfer to synonym\n+      int flags = getAttribute(FlagsAttribute.class).getFlags();", "originalCommit": "9a25d7eefe877d5cfde76de065ad26da6d799ad4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2MzQ5OA==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504863498", "bodyText": "that's all bits except the first 1 (01111111111111111...). To invert all bits use -1 or better ~0", "author": "uschindler", "createdAt": "2020-10-14T17:50:38Z", "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -190,7 +196,8 @@ public static void assertTokenStreamContents(TokenStream ts, String[] output, in\n       if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n       if (keywordAtt != null) keywordAtt.setKeyword((i&1) == 0);\n       if (payloadAtt != null) payloadAtt.setPayload(new BytesRef(new byte[] { 0x00, -0x21, 0x12, -0x43, 0x24 }));\n-      \n+      if (flagsAtt != null) flagsAtt.setFlags(Integer.MAX_VALUE); // all 1's", "originalCommit": "9a25d7eefe877d5cfde76de065ad26da6d799ad4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2NzkzNA==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504867934", "bodyText": "oops yeah realized that partway through (when I switched to ~0 for the other file), didn't come back and fix it here.", "author": "gus-asf", "createdAt": "2020-10-14T17:57:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2MzQ5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2MzY0Mg==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504863642", "bodyText": "same here", "author": "uschindler", "createdAt": "2020-10-14T17:50:54Z", "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -294,6 +304,7 @@ public static void assertTokenStreamContents(TokenStream ts, String[] output, in\n     if (posLengthAtt != null) posLengthAtt.setPositionLength(45987653);\n     if (keywordAtt != null) keywordAtt.setKeyword(true);\n     if (payloadAtt != null) payloadAtt.setPayload(new BytesRef(new byte[] { 0x00, -0x21, 0x12, -0x43, 0x24 }));\n+    if (flagsAtt != null) flagsAtt.setFlags(Integer.MAX_VALUE); // all 1's", "originalCommit": "9a25d7eefe877d5cfde76de065ad26da6d799ad4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2NDA2MQ==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504864061", "bodyText": "maybe we should not change this method signature and just add another one, so we do not need to change unrelated files like MinHashFilter?", "author": "uschindler", "createdAt": "2020-10-14T17:51:35Z", "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -125,7 +125,7 @@ public void reflectWith(AttributeReflector reflector) {\n   //     arriving to pos Y have the same endOffset)\n   public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[],", "originalCommit": "9a25d7eefe877d5cfde76de065ad26da6d799ad4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDk5NjE0MQ==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r504996141", "bodyText": "Done, I think what was originally submitted was a bit easier than sorting out all the parameters at the time, but yes nicer to minimize.", "author": "gus-asf", "createdAt": "2020-10-14T21:52:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg2NDA2MQ=="}], "type": "inlineReview"}, {"oid": "3049a5f62383b702c79e84c0504df0a7f0bb7b74", "url": "https://github.com/apache/lucene-solr/commit/3049a5f62383b702c79e84c0504df0a7f0bb7b74", "message": "LUCENE-9572 - TypeAsSynonymFilter gains selective flag transfer capability and an ignore list.", "committedDate": "2020-10-14T18:56:36Z", "type": "commit"}, {"oid": "6c7ac9f0aa3b797fb2bf955973cf1b01e0fdb5bd", "url": "https://github.com/apache/lucene-solr/commit/6c7ac9f0aa3b797fb2bf955973cf1b01e0fdb5bd", "message": "LUCENE-9572 Adjust test methods", "committedDate": "2020-10-14T18:56:36Z", "type": "commit"}, {"oid": "6dbf1eff7bd83ac342167f2dbcaa08d52b1a685f", "url": "https://github.com/apache/lucene-solr/commit/6dbf1eff7bd83ac342167f2dbcaa08d52b1a685f", "message": "LUCENE-9572 update CHANGES.txt", "committedDate": "2020-10-14T19:24:27Z", "type": "commit"}, {"oid": "491632b1b8ac020c6659e7b552a02df99c324acd", "url": "https://github.com/apache/lucene-solr/commit/491632b1b8ac020c6659e7b552a02df99c324acd", "message": "LUCENE-9572 use field", "committedDate": "2020-10-14T19:28:59Z", "type": "commit"}, {"oid": "491632b1b8ac020c6659e7b552a02df99c324acd", "url": "https://github.com/apache/lucene-solr/commit/491632b1b8ac020c6659e7b552a02df99c324acd", "message": "LUCENE-9572 use field", "committedDate": "2020-10-14T19:28:59Z", "type": "forcePushed"}, {"oid": "bfadcc750f3e47b587af6aa04a0b554ec748a34a", "url": "https://github.com/apache/lucene-solr/commit/bfadcc750f3e47b587af6aa04a0b554ec748a34a", "message": "LUCENE-9572 correct \"all 1's\"", "committedDate": "2020-10-14T19:36:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MTczMw==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505041733", "bodyText": "Why not use Set.of() (since Java 11)?", "author": "uschindler", "createdAt": "2020-10-14T22:53:20Z", "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.analysis.miscellaneous;\n+\n+import java.util.Collections;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import org.apache.lucene.analysis.BaseTokenStreamTestCase;\n+import org.apache.lucene.analysis.CannedTokenStream;\n+import org.apache.lucene.analysis.Token;\n+import org.apache.lucene.analysis.TokenStream;\n+\n+/**\n+ * Test that this filter moves the value in type to a synonym token with the same offsets. This is rarely\n+ * useful by itself, but in combination with another filter that updates the type value with an appropriate\n+ * synonym can be used to identify synonyms before tokens are modified by further analysis, and then\n+ * add them at the end, ensuring that the synonym value has not ben subjected to the intervening analysis.\n+ * This typically applies when the analysis would remove characters that should remain in the synonym.\n+ */\n+public class TestTypeAsSynonymFilter extends BaseTokenStreamTestCase {\n+\n+  /**\n+   * Test the straight forward case with the simplest constructor. Simply converts every\n+   * type to a synonym. Typically one wants to also set an ignore list containing \"word\" unless\n+   * that default value is removed by prior analysis.\n+   */\n+  public void testSimple() throws Exception {\n+\n+    Token token = new Token(\"foo\", 0, 2);\n+    token.setType(\"bar\");\n+    Token token2 = new Token(\"foo\", 4, 6);\n+    TokenStream ts = new CannedTokenStream(token, token2);\n+    ts = new TypeAsSynonymFilter(ts);\n+\n+    // \"word\" is the default type!\n+    assertTokenStreamContents(ts, new String[] {\n+        \"foo\", \"bar\",\"foo\",\"word\"},new int[] {0,0,4,4}, new int[]{2,2,6,6}, new int[] {1,0,1,0});\n+  }\n+\n+  /**\n+   * Tests that we can add a prefix to the synonym (for example, to keep it from ever matching user input directly),\n+   * and test that we can ignore a list of type values we don't wish to turn into synonyms.\n+   */\n+  public void testWithPrefixAndIgnore() throws Exception {\n+    Token[] tokens = new Token[] {\n+        new Token(\"foo\", 1, 3),\n+        new Token(\"foo\", 5, 7),\n+        new Token(\"foo\", 9, 11),\n+    } ;\n+    tokens[0].setType(\"bar\");\n+    tokens[2].setType(\"ignoreme\");\n+    TokenStream ts = new CannedTokenStream(tokens);\n+    ts = new TypeAsSynonymFilter(ts,\"pfx_\", Stream.of(\"word\",\"ignoreme\").collect(Collectors.toSet()), 0);", "originalCommit": "bfadcc750f3e47b587af6aa04a0b554ec748a34a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MjQ5Mw==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505042493", "bodyText": "Stream.of(\"word\",\"ignoreme\").collect(Collectors.toSet()) => Set.of(\"word\",\"ignoreme\")", "author": "uschindler", "createdAt": "2020-10-14T22:54:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MTczMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTExOTk3NQ==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505119975", "bodyText": "Ah yeah sure. Originally developed vs 8.4 but now I can use it :)", "author": "gus-asf", "createdAt": "2020-10-15T02:01:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MTczMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM2NDMwMg==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505364302", "bodyText": "In 8.x I'd use: new HashSet(Arrays.asList(\"word\",\"ignoreme\")), but that's a matter of preference. I tend to not use streams if there's no transformations/mappings going on.", "author": "uschindler", "createdAt": "2020-10-15T08:52:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0MTczMw=="}], "type": "inlineReview"}, {"oid": "e0950a37e59cf3bb34a076b95ac3b84378c1e875", "url": "https://github.com/apache/lucene-solr/commit/e0950a37e59cf3bb34a076b95ac3b84378c1e875", "message": "LUCENE-9572 Set.of()", "committedDate": "2020-10-15T02:04:11Z", "type": "commit"}, {"oid": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd", "url": "https://github.com/apache/lucene-solr/commit/6916e5f56408bee84e3cdb45beeffcaebb8eaccd", "message": "LUCENE-9572 imports", "committedDate": "2020-10-15T15:09:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4MjQ2MQ==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505682461", "bodyText": "Consider adding the new features to the class comment", "author": "sarowe", "createdAt": "2020-10-15T16:33:36Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilter.java", "diffHunk": "@@ -34,23 +36,39 @@\n   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);", "originalCommit": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4MzgzNQ==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505683835", "bodyText": "Consider adding configuration for the new features to the example Solr configuration.", "author": "sarowe", "createdAt": "2020-10-15T16:35:47Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilterFactory.java", "diffHunk": "@@ -18,12 +18,15 @@\n package org.apache.lucene.analysis.miscellaneous;\n \n import java.util.Map;\n+import java.util.Set;\n \n import org.apache.lucene.analysis.TokenStream;\n import org.apache.lucene.analysis.TokenFilterFactory;\n \n /**\n  * Factory for {@link TypeAsSynonymFilter}.\n+ *\n+ * <p>In Solr this might be used as such", "originalCommit": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4NTE1OQ==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505685159", "bodyText": "There is a method getSet() which you could use instead of get() for the ignoreList; it does the splitting for you, and also supports mixed space/comma separators.", "author": "sarowe", "createdAt": "2020-10-15T16:37:49Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TypeAsSynonymFilterFactory.java", "diffHunk": "@@ -46,10 +49,17 @@\n   public static final String NAME = \"typeAsSynonym\";\n \n   private final String prefix;\n+  private Set<String> ignore = null;\n+  private final int synFlagMask;\n \n   public TypeAsSynonymFilterFactory(Map<String,String> args) {\n     super(args);\n     prefix = get(args, \"prefix\");  // default value is null\n+    String ignoreList = get(args, \"ignore\");\n+    synFlagMask = getInt(args,\"synFlagsMask\", ~0);\n+    if (ignoreList != null) {\n+      ignore = Set.of(ignoreList.split(\",\"));\n+    }", "originalCommit": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcwMzYzNQ==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505703635", "bodyText": "Ah cool.", "author": "gus-asf", "createdAt": "2020-10-15T17:07:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4NTE1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY4NTc2NA==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505685764", "bodyText": "typo: ben", "author": "sarowe", "createdAt": "2020-10-15T16:38:48Z", "path": "lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTypeAsSynonymFilter.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.lucene.analysis.miscellaneous;\n+\n+import java.util.Collections;\n+import java.util.Set;\n+\n+import org.apache.lucene.analysis.BaseTokenStreamTestCase;\n+import org.apache.lucene.analysis.CannedTokenStream;\n+import org.apache.lucene.analysis.Token;\n+import org.apache.lucene.analysis.TokenStream;\n+\n+/**\n+ * Test that this filter moves the value in type to a synonym token with the same offsets. This is rarely\n+ * useful by itself, but in combination with another filter that updates the type value with an appropriate\n+ * synonym can be used to identify synonyms before tokens are modified by further analysis, and then\n+ * add them at the end, ensuring that the synonym value has not ben subjected to the intervening analysis.", "originalCommit": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY5MzU1Mw==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505693553", "bodyText": "Since you put back the original method, I think you can also revert this change?", "author": "sarowe", "createdAt": "2020-10-15T16:51:20Z", "path": "lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java", "diffHunk": "@@ -390,19 +406,19 @@ public static void assertAnalyzesTo(Analyzer a, String input, String[] output, i\n   }\n \n   public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n-    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n+    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads, null);", "originalCommit": "6916e5f56408bee84e3cdb45beeffcaebb8eaccd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcwNDQzMg==", "url": "https://github.com/apache/lucene-solr/pull/1965#discussion_r505704432", "bodyText": "ok", "author": "gus-asf", "createdAt": "2020-10-15T17:08:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY5MzU1Mw=="}], "type": "inlineReview"}, {"oid": "a4a24ac2b35ef60c1b3104ddfd7c69bed4d4b1fe", "url": "https://github.com/apache/lucene-solr/commit/a4a24ac2b35ef60c1b3104ddfd7c69bed4d4b1fe", "message": "LUCENE-9572 feedback from @sarowe and enhance unit test to verify back compat.", "committedDate": "2020-10-15T19:56:41Z", "type": "commit"}, {"oid": "2e7cc33a416582c48186028f0e11f6915f55ba23", "url": "https://github.com/apache/lucene-solr/commit/2e7cc33a416582c48186028f0e11f6915f55ba23", "message": "LUCENE-9572 tweak javadocs on the filter class", "committedDate": "2020-10-15T21:37:08Z", "type": "commit"}]}