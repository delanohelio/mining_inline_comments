{"pr_number": 1909, "pr_title": "LUCENE-9539: Remove caches from SortingCodecReader", "pr_createdAt": "2020-09-22T13:28:31Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1909", "timeline": [{"oid": "f3ea2a8bc34b9a1d6b9960156aae80cac5312b49", "url": "https://github.com/apache/lucene-solr/commit/f3ea2a8bc34b9a1d6b9960156aae80cac5312b49", "message": "LUCENE-9539: Remove caches from SorgingCodecReader\n\nSortingCodecReader keeps all docvalues in memory that are loaded from this reader.\nYet, this reader should only be used for merging which happens sequentially. This makes\ncaching docvalues unnecessary.", "committedDate": "2020-09-22T13:26:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjkyMTI3MA==", "url": "https://github.com/apache/lucene-solr/pull/1909#discussion_r492921270", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * NOTE: This reader should only be used for merging. Pulling fields from this ready might be very costly and memory\n          \n          \n            \n             * NOTE: This reader should only be used for merging. Pulling fields from this reader might be very costly and memory", "author": "jimczi", "createdAt": "2020-09-22T17:45:01Z", "path": "lucene/core/src/java/org/apache/lucene/index/SortingCodecReader.java", "diffHunk": "@@ -41,21 +41,13 @@\n  * {@link Sort}. This can be used to re-sort and index after it's been created by wrapping all\n  * readers of the index with this reader and adding it to a fresh IndexWriter via\n  * {@link IndexWriter#addIndexes(CodecReader...)}.\n+ * NOTE: This reader should only be used for merging. Pulling fields from this ready might be very costly and memory", "originalCommit": "f3ea2a8bc34b9a1d6b9960156aae80cac5312b49", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "703f167f90a071198ccb361ef406ec63e79caf2b", "url": "https://github.com/apache/lucene-solr/commit/703f167f90a071198ccb361ef406ec63e79caf2b", "message": "Update lucene/core/src/java/org/apache/lucene/index/SortingCodecReader.java\n\nCo-authored-by: Jim Ferenczi <jim.ferenczi@elastic.co>", "committedDate": "2020-09-22T19:23:02Z", "type": "commit"}, {"oid": "75ab5d3d42269be3a145f68200dba7850ca77e3f", "url": "https://github.com/apache/lucene-solr/commit/75ab5d3d42269be3a145f68200dba7850ca77e3f", "message": "improve loop readability", "committedDate": "2020-09-22T19:29:38Z", "type": "commit"}, {"oid": "ecbf48851c2f3acc179ac26ff654eb6a34499180", "url": "https://github.com/apache/lucene-solr/commit/ecbf48851c2f3acc179ac26ff654eb6a34499180", "message": "add changes", "committedDate": "2020-09-22T19:46:42Z", "type": "commit"}, {"oid": "22e5447a17862058f2ca44c0ffa0e246f5a41ec1", "url": "https://github.com/apache/lucene-solr/commit/22e5447a17862058f2ca44c0ffa0e246f5a41ec1", "message": "fix naming", "committedDate": "2020-09-22T20:05:36Z", "type": "commit"}, {"oid": "9ad2f2b4433456c1603bbfdeae2f79f7dfff23eb", "url": "https://github.com/apache/lucene-solr/commit/9ad2f2b4433456c1603bbfdeae2f79f7dfff23eb", "message": "try to cache the last pulled DV / Norms to ensure we reuse the instance during merge", "committedDate": "2020-09-23T07:21:51Z", "type": "commit"}, {"oid": "0fa6437128af08c672a506dfbec69f76285b404c", "url": "https://github.com/apache/lucene-solr/commit/0fa6437128af08c672a506dfbec69f76285b404c", "message": "add supporess warning", "committedDate": "2020-09-23T07:25:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzI3OTE3Mg==", "url": "https://github.com/apache/lucene-solr/pull/1909#discussion_r493279172", "bodyText": "I think we might cache norms twice if full-text is indexed, as we'd pull norms once for merging norms, and another time to index impacts in postings for the same field.", "author": "jpountz", "createdAt": "2020-09-23T07:59:31Z", "path": "lucene/core/src/java/org/apache/lucene/index/SortingCodecReader.java", "diffHunk": "@@ -510,4 +457,52 @@ public LeafMetaData getMetaData() {\n     return metaData;\n   }\n \n+  // we try to cache the last used DV or Norms instance since during merge\n+  // this instance is used more than once. We could in addition to this single instance\n+  // also cache the fields that are used for sorting since we do the work twice for these fields\n+  private String cachedField;\n+  private Object cachedObject;\n+  private boolean cacheIsNorms;\n+\n+  private <T> T getOrCreateNorms(String field, IOSupplier<T> supplier) throws IOException {\n+    return getOrCreate(field, true, supplier);\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private synchronized  <T> T getOrCreate(String field, boolean norms, IOSupplier<T> supplier) throws IOException {\n+    if ((field.equals(cachedField) && cacheIsNorms == norms) == false) {\n+      assert assertCreatedOnlyOnce(field, norms);\n+      cachedObject = supplier.get();\n+      cachedField = field;\n+      cacheIsNorms = norms;\n+\n+    }\n+    assert cachedObject != null;\n+    return (T) cachedObject;\n+  }\n+\n+  private final Map<String, Integer> cacheStats = new HashMap<>(); // only with assertions enabled\n+  private boolean assertCreatedOnlyOnce(String field, boolean norms) {\n+    assert Thread.holdsLock(this);\n+    // this is mainly there to make sure we change anything in the way we merge we realize it early\n+    Integer timesCached = cacheStats.compute(field + \"N:\" + norms, (s, i) -> i == null ? 1 : i.intValue() + 1);\n+    if (timesCached > 1) {\n+      assert norms == false :\"[\" + field + \"] norms must not be cached twice\";", "originalCommit": "0fa6437128af08c672a506dfbec69f76285b404c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzQ3NzE0MA==", "url": "https://github.com/apache/lucene-solr/pull/1909#discussion_r493477140", "bodyText": "can you point me to the place where we do this? If that is the case our tests are not good enough here.", "author": "s1monw", "createdAt": "2020-09-23T11:28:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzI3OTE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzQ4MjAxMg==", "url": "https://github.com/apache/lucene-solr/pull/1909#discussion_r493482012", "bodyText": "I think what we do here is we pull the already merged norms instance from disk instead of the one from the source reader. Is that what you mean in PushPostingsWriterBase", "author": "s1monw", "createdAt": "2020-09-23T11:35:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzI3OTE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzQ5MDc1MQ==", "url": "https://github.com/apache/lucene-solr/pull/1909#discussion_r493490751", "bodyText": "Ah I had forgotten we were doing things this way. Then ignore my comment!", "author": "jpountz", "createdAt": "2020-09-23T11:45:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzI3OTE3Mg=="}], "type": "inlineReview"}, {"oid": "0431c5ce4531cce06ee5906a7a37bb27507e9bf7", "url": "https://github.com/apache/lucene-solr/commit/0431c5ce4531cce06ee5906a7a37bb27507e9bf7", "message": "beef up test", "committedDate": "2020-09-23T11:55:33Z", "type": "commit"}]}