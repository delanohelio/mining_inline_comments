{"pr_number": 1195, "pr_title": "SOLR-13101: Log accurate file counts for Push and Pull in CorePushPull", "pr_createdAt": "2020-01-21T21:43:03Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1195", "timeline": [{"oid": "005661753f7c5fc0b974df97cf2b4c3702695dcc", "url": "https://github.com/apache/lucene-solr/commit/005661753f7c5fc0b974df97cf2b4c3702695dcc", "message": "CorePushPull blob interaction log line inaccurate in case of failures. Fix logged file and bytes count to be accurate in both success and failure", "committedDate": "2020-01-21T21:24:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1OTY4Mg==", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369259682", "bodyText": "I considered creating an inner wrapper class for the return values but it seemed like overkill, so I went with returning a pair", "author": "ebehrendt", "createdAt": "2020-01-21T21:45:31Z", "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {", "originalCommit": "005661753f7c5fc0b974df97cf2b4c3702695dcc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI2MDEzNw==", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369260137", "bodyText": "Moved IndexOutput initialization into the try with resources since it can throw an exception and it also implements Closable", "author": "ebehrendt", "createdAt": "2020-01-21T21:46:34Z", "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n       // Synchronously download all Blob blobs (remember we're running on an async thread, so no need to be async twice unless\n       // we eventually want to parallelize downloads of multiple blobs, but for the PoC we don't :)\n+      long filesDownloaded = 0;\n+      long bytesTransferred = 0;\n       for (BlobFile bf: filesToDownload) {\n         log.info(\"About to create \" + bf.getSolrFileName() + \" for core \" + pushPullData.getCoreName() +\n             \" from index on blob \" + pushPullData.getSharedStoreName());\n-        IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n \n-        try (OutputStream outStream = new IndexOutputStream(io);\n-          InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n-          IOUtils.copy(bis, outStream);\n-        }\n+          try (IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);", "originalCommit": "005661753f7c5fc0b974df97cf2b4c3702695dcc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4MDE1OA==", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r370380158", "bodyText": "Looked at the code and OutputStream outStream = new IndexOutputStream(io) was already in the try-with block and will end up closing the IndexOutput you moved. But the change has no affect if close is called twice so no change needed here, just wanted to note that.", "author": "andyvuong", "createdAt": "2020-01-23T22:06:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI2MDEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI2MDg4NA==", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369260884", "bodyText": "Anyone have a recommendation on how to do this more gracefully than return the same values in and outside of the catch? I want to return these values whether exception is thrown or not, but cannot return from a finally.", "author": "ebehrendt", "createdAt": "2020-01-21T21:48:14Z", "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n       // Synchronously download all Blob blobs (remember we're running on an async thread, so no need to be async twice unless\n       // we eventually want to parallelize downloads of multiple blobs, but for the PoC we don't :)\n+      long filesDownloaded = 0;\n+      long bytesTransferred = 0;\n       for (BlobFile bf: filesToDownload) {\n         log.info(\"About to create \" + bf.getSolrFileName() + \" for core \" + pushPullData.getCoreName() +\n             \" from index on blob \" + pushPullData.getSharedStoreName());\n-        IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n \n-        try (OutputStream outStream = new IndexOutputStream(io);\n-          InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n-          IOUtils.copy(bis, outStream);\n-        }\n+          try (IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n+              OutputStream outStream = new IndexOutputStream(io);\n+            InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n+            IOUtils.copy(bis, outStream);\n+            \n+            filesDownloaded++;\n+            bytesTransferred += bf.getFileSize();\n+          } catch (Exception e) {\n+            return new Pair<>(filesDownloaded, bytesTransferred);", "originalCommit": "005661753f7c5fc0b974df97cf2b4c3702695dcc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY5OTA5Mw==", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369699093", "bodyText": "This comment is also out of date (soblb doesn't exist) so we can remove it.", "author": "andyvuong", "createdAt": "2020-01-22T17:28:24Z", "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action ", "originalCommit": "005661753f7c5fc0b974df97cf2b4c3702695dcc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwMzMzNQ==", "url": "https://github.com/apache/lucene-solr/pull/1195#discussion_r369703335", "bodyText": "This will swallow exceptions from requests failing with the blob store. I'd prefer to keep the same behavior and let those errors propagate up.", "author": "andyvuong", "createdAt": "2020-01-22T17:36:53Z", "path": "solr/core/src/java/org/apache/solr/store/blob/metadata/CorePushPull.java", "diffHunk": "@@ -419,45 +433,51 @@ protected String pushFileToBlobStore(CoreStorageClient blob, Directory dir, Stri\n \n     /**\n      * Logs soblb line for push or pull action \n-     * TODO: This is for callers of this method.\n-     * fileAffected and bytesTransferred represent correct values only in case of success\n-     * In case of failure(partial processing) we are not accurate.\n-     * Do we want to change that? If yes, then in case of pull is downloading of files locally to temp folder is considered\n-     * transfer or moving from temp dir to final destination. One option could be to just make them -1 in case of failure.\n      */\n-    private void logBlobAction(String action, long filesAffected, long bytesTransferred, long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n+    private void logBlobAction(String action, long expectedFilesAffected, long actualFilesAffected, long bytesTransferred, boolean isSuccessful,\n+        long requestQueuedTimeMs, int attempt, long startTimeMs) throws Exception {\n       long now = System.nanoTime();\n       long runTime = now - startTimeMs;\n       long startLatency = now - requestQueuedTimeMs;\n \n       String message = String.format(Locale.ROOT,\n             \"PushPullData=[%s] action=%s storageProvider=%s bucketRegion=%s bucketName=%s \"\n-              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s filesAffected=%s localGeneration=%s blobGeneration=%s \",\n+              + \"runTime=%s startLatency=%s bytesTransferred=%s attempt=%s expectedFilesAffected=%s actualFilesAffected=%s isSuccessful=%s \"\n+              + \"localGeneration=%s blobGeneration=%s \",\n           pushPullData.toString(), action, coreStorageClient.getStorageProvider().name(), coreStorageClient.getBucketRegion(),\n-          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, filesAffected,\n-          solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n+          coreStorageClient.getBucketName(), runTime, startLatency, bytesTransferred, attempt, expectedFilesAffected, actualFilesAffected,\n+          isSuccessful, solrServerMetadata.getGeneration(), blobMetadata.getGeneration());\n       log.info(message);\n     }\n \n     /**\n      * Downloads files from the Blob store \n      * @param destDir (temporary) directory into which files should be downloaded.\n      * @param filesToDownload blob files to be downloaded\n+     * @return number of files downloaded and number of bytes transferred successfully\n      */\n     @VisibleForTesting\n-    protected void downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n+    protected Pair<Long, Long> downloadFilesFromBlob(Directory destDir, Collection<? extends BlobFile> filesToDownload) throws Exception {\n       // Synchronously download all Blob blobs (remember we're running on an async thread, so no need to be async twice unless\n       // we eventually want to parallelize downloads of multiple blobs, but for the PoC we don't :)\n+      long filesDownloaded = 0;\n+      long bytesTransferred = 0;\n       for (BlobFile bf: filesToDownload) {\n         log.info(\"About to create \" + bf.getSolrFileName() + \" for core \" + pushPullData.getCoreName() +\n             \" from index on blob \" + pushPullData.getSharedStoreName());\n-        IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n \n-        try (OutputStream outStream = new IndexOutputStream(io);\n-          InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n-          IOUtils.copy(bis, outStream);\n-        }\n+          try (IndexOutput io = destDir.createOutput(bf.getSolrFileName(), DirectoryFactory.IOCONTEXT_NO_CACHE);\n+              OutputStream outStream = new IndexOutputStream(io);\n+            InputStream bis = coreStorageClient.pullStream(bf.getBlobName())) {\n+            IOUtils.copy(bis, outStream);\n+            \n+            filesDownloaded++;\n+            bytesTransferred += bf.getFileSize();\n+          } catch (Exception e) {\n+            return new Pair<>(filesDownloaded, bytesTransferred);", "originalCommit": "005661753f7c5fc0b974df97cf2b4c3702695dcc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "dddb6bdbfe45978583fb9ceb61f814e9c4f0e4e9", "url": "https://github.com/apache/lucene-solr/commit/dddb6bdbfe45978583fb9ceb61f814e9c4f0e4e9", "message": "Move file transfer count data into inner class to preserve incremented values when exception is thrown", "committedDate": "2020-01-23T21:38:32Z", "type": "commit"}]}