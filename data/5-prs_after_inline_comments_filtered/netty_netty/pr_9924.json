{"pr_number": 9924, "pr_title": "Allow a limit to be set on the decompressed buffer size for ZlibDecoders", "pr_createdAt": "2020-01-07T19:28:51Z", "pr_url": "https://github.com/netty/netty/pull/9924", "timeline": [{"oid": "644b1261ea00c4f09345efd935e18c6b23704b8e", "url": "https://github.com/netty/netty/commit/644b1261ea00c4f09345efd935e18c6b23704b8e", "message": "Allow a limit to be set on the decompressed buffer size for ZlibDecoders\n\nMotivation:\nIt is impossible to know in advance how much memory will be needed to\ndecompress a stream of bytes that was compressed using the DEFLATE\nalgorithm. In theory, up to 1032 times the compressed size could be\nneeded. For untrusted input, an attacker could exploit this to exhaust\nthe memory pool.\n\nModifications:\nZlibDecoder and its subclasses now support an optional limit on the size\nof the decompressed buffer. By default, if the limit is reached,\ndecompression stops and a DecompressionException is thrown. Behavior\nupon reaching the limit is modifiable by subclasses in case they desire\nsomething else.\n\nResult:\nThe decompressed buffer can now be limited to a configurable size, thus\nmitigating the possibility of memory pool exhaustion.", "committedDate": "2020-01-07T19:24:13Z", "type": "commit"}, {"oid": "57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "url": "https://github.com/netty/netty/commit/57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "message": "Fix Checkstyle violation", "committedDate": "2020-01-09T18:20:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTExODc0MQ==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369118741", "bodyText": "Can you add to the doc describing what 0 does?", "author": "carl-mastrangelo", "createdAt": "2020-01-21T16:49:07Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/JZlibDecoder.java", "diffHunk": "@@ -35,7 +35,17 @@\n      * @throws DecompressionException if failed to initialize zlib\n      */\n     public JZlibDecoder() {\n-        this(ZlibWrapper.ZLIB);\n+        this(ZlibWrapper.ZLIB, 0);\n+    }\n+\n+    /**\n+     * Creates a new instance with the default wrapper ({@link ZlibWrapper#ZLIB})\n+     * and specified maximum buffer allocation.", "originalCommit": "57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE3OTUzNw==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369179537", "bodyText": "+1", "author": "njhill", "createdAt": "2020-01-21T18:49:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTExODc0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTExODg1MA==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369118850", "bodyText": "same comment", "author": "carl-mastrangelo", "createdAt": "2020-01-21T16:49:19Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/JZlibDecoder.java", "diffHunk": "@@ -44,6 +54,17 @@ public JZlibDecoder() {\n      * @throws DecompressionException if failed to initialize zlib\n      */\n     public JZlibDecoder(ZlibWrapper wrapper) {\n+        this(wrapper, 0);\n+    }\n+\n+    /**\n+     * Creates a new instance with the specified wrapper and maximum buffer allocation.\n+     *\n+     * @throws DecompressionException if failed to initialize zlib\n+     */\n+    public JZlibDecoder(ZlibWrapper wrapper, int maxAllocation) {", "originalCommit": "57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyMDU2Mw==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369120563", "bodyText": "can this be private/final?", "author": "carl-mastrangelo", "createdAt": "2020-01-21T16:52:16Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/ZlibDecoder.java", "diffHunk": "@@ -16,16 +16,72 @@\n package io.netty.handler.codec.compression;\n \n import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufAllocator;\n+import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.ByteToMessageDecoder;\n \n /**\n  * Decompresses a {@link ByteBuf} using the deflate algorithm.\n  */\n public abstract class ZlibDecoder extends ByteToMessageDecoder {\n \n+    /**\n+     * Maximum allowed size of the decompression buffer.\n+     */\n+    protected int maxAllocation;", "originalCommit": "57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMzMjA5OA==", "url": "https://github.com/netty/netty/pull/9924#discussion_r370332098", "bodyText": "I'll make it final but leave it as protected in case a subclass wants to read it for any reason.", "author": "rdicroce", "createdAt": "2020-01-23T20:14:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyMDU2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyMTI2NA==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369121264", "bodyText": "optional: check preferredSize is non-negative?", "author": "carl-mastrangelo", "createdAt": "2020-01-21T16:53:23Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/ZlibDecoder.java", "diffHunk": "@@ -16,16 +16,72 @@\n package io.netty.handler.codec.compression;\n \n import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufAllocator;\n+import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.ByteToMessageDecoder;\n \n /**\n  * Decompresses a {@link ByteBuf} using the deflate algorithm.\n  */\n public abstract class ZlibDecoder extends ByteToMessageDecoder {\n \n+    /**\n+     * Maximum allowed size of the decompression buffer.\n+     */\n+    protected int maxAllocation;\n+\n+    /**\n+     * Same as {@link #ZlibDecoder(int)} with maxAllocation = 0.\n+     */\n+    public ZlibDecoder() {\n+        this(0);\n+    }\n+\n+    /**\n+     * Construct a new ZlibDecoder.\n+     * @param maxAllocation\n+     *          Maximum size of the decompression buffer. Must be &gt;= 0.\n+     *          If zero, maximum size is decided by the {@link ByteBufAllocator}.\n+     */\n+    public ZlibDecoder(int maxAllocation) {\n+        if (maxAllocation < 0) {\n+            throw new IllegalArgumentException(\"maxAllocation must be >= 0\");\n+        }\n+        this.maxAllocation = maxAllocation;\n+    }\n+\n     /**\n      * Returns {@code true} if and only if the end of the compressed stream\n      * has been reached.\n      */\n     public abstract boolean isClosed();\n+\n+    /**\n+     * Allocate or expand the decompression buffer, without exceeding the maximum allocation.\n+     * Calls {@link #maxAllocationReached(ByteBuf)} if the buffer is full and cannot be expanded further.\n+     */\n+    protected ByteBuf prepareDecompressBuffer(ChannelHandlerContext ctx, ByteBuf buffer, int preferredSize) {\n+        if (buffer == null) {\n+            if (maxAllocation == 0) {\n+                return ctx.alloc().heapBuffer(preferredSize);\n+            } else {\n+                return ctx.alloc().heapBuffer(Math.min(preferredSize, maxAllocation), maxAllocation);", "originalCommit": "57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4NTg1NQ==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369185855", "bodyText": "For consistency shouldn't maxAllocationReached be called here in the preferredSize < maxAllocation case?", "author": "njhill", "createdAt": "2020-01-21T19:02:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyMTI2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyNDUwNA==", "url": "https://github.com/netty/netty/pull/9924#discussion_r370324504", "bodyText": "preferredSize was not checked by the existing code, and adding a check will actually duplicate the check because ByteBuf or ByteBufAllocator (whichever is ultimately called) will check that it's non-negative.\nAbout the preferredSize < maxAllocation case, I'm not following you. preferredSize will often be less than maxAllocation since preferredSize is a guesstimate of how much more space is needed to finish decompressing the input. So e.g. maxAllocation might be set to 1 MiB but the decoder estimates it only needs 10 KiB to finish decompressing.", "author": "rdicroce", "createdAt": "2020-01-23T19:56:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyMTI2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMzMzcxNg==", "url": "https://github.com/netty/netty/pull/9924#discussion_r370333716", "bodyText": "@rdicroce apologies, I meant preferredSize > maxAllocation", "author": "njhill", "createdAt": "2020-01-23T20:18:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyMTI2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMzNzM5NA==", "url": "https://github.com/netty/netty/pull/9924#discussion_r370337394", "bodyText": "Since preferredSize is a guesstimate of how much space is needed, it's possible that the compression ratio is poor and we don't need that much space. So e.g. the compressed size could be 100 KiB, and so JdkZlibDecoder and ZlibDecoder estimate they need 200 KiB to decompress. So they pass preferredSize = 200 KiB but then it turns out the decompressed data is only 150 KiB in size. If maxAllocation is 175 KiB, then decompression ought to succeed since 150 < 175, even though 200 > 175.", "author": "rdicroce", "createdAt": "2020-01-23T20:26:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyMTI2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4MDI4OQ==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369180289", "bodyText": "nit: else block not needed", "author": "njhill", "createdAt": "2020-01-21T18:51:07Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/ZlibDecoder.java", "diffHunk": "@@ -16,16 +16,72 @@\n package io.netty.handler.codec.compression;\n \n import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufAllocator;\n+import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.ByteToMessageDecoder;\n \n /**\n  * Decompresses a {@link ByteBuf} using the deflate algorithm.\n  */\n public abstract class ZlibDecoder extends ByteToMessageDecoder {\n \n+    /**\n+     * Maximum allowed size of the decompression buffer.\n+     */\n+    protected int maxAllocation;\n+\n+    /**\n+     * Same as {@link #ZlibDecoder(int)} with maxAllocation = 0.\n+     */\n+    public ZlibDecoder() {\n+        this(0);\n+    }\n+\n+    /**\n+     * Construct a new ZlibDecoder.\n+     * @param maxAllocation\n+     *          Maximum size of the decompression buffer. Must be &gt;= 0.\n+     *          If zero, maximum size is decided by the {@link ByteBufAllocator}.\n+     */\n+    public ZlibDecoder(int maxAllocation) {\n+        if (maxAllocation < 0) {\n+            throw new IllegalArgumentException(\"maxAllocation must be >= 0\");\n+        }\n+        this.maxAllocation = maxAllocation;\n+    }\n+\n     /**\n      * Returns {@code true} if and only if the end of the compressed stream\n      * has been reached.\n      */\n     public abstract boolean isClosed();\n+\n+    /**\n+     * Allocate or expand the decompression buffer, without exceeding the maximum allocation.\n+     * Calls {@link #maxAllocationReached(ByteBuf)} if the buffer is full and cannot be expanded further.\n+     */\n+    protected ByteBuf prepareDecompressBuffer(ChannelHandlerContext ctx, ByteBuf buffer, int preferredSize) {\n+        if (buffer == null) {\n+            if (maxAllocation == 0) {\n+                return ctx.alloc().heapBuffer(preferredSize);\n+            } else {", "originalCommit": "57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4MzAyNQ==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369183025", "bodyText": "I think either the second ensureWritable param should be false or the return should be compared to 3 rather than 1?", "author": "njhill", "createdAt": "2020-01-21T18:56:43Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/ZlibDecoder.java", "diffHunk": "@@ -16,16 +16,72 @@\n package io.netty.handler.codec.compression;\n \n import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufAllocator;\n+import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.ByteToMessageDecoder;\n \n /**\n  * Decompresses a {@link ByteBuf} using the deflate algorithm.\n  */\n public abstract class ZlibDecoder extends ByteToMessageDecoder {\n \n+    /**\n+     * Maximum allowed size of the decompression buffer.\n+     */\n+    protected int maxAllocation;\n+\n+    /**\n+     * Same as {@link #ZlibDecoder(int)} with maxAllocation = 0.\n+     */\n+    public ZlibDecoder() {\n+        this(0);\n+    }\n+\n+    /**\n+     * Construct a new ZlibDecoder.\n+     * @param maxAllocation\n+     *          Maximum size of the decompression buffer. Must be &gt;= 0.\n+     *          If zero, maximum size is decided by the {@link ByteBufAllocator}.\n+     */\n+    public ZlibDecoder(int maxAllocation) {\n+        if (maxAllocation < 0) {\n+            throw new IllegalArgumentException(\"maxAllocation must be >= 0\");\n+        }\n+        this.maxAllocation = maxAllocation;\n+    }\n+\n     /**\n      * Returns {@code true} if and only if the end of the compressed stream\n      * has been reached.\n      */\n     public abstract boolean isClosed();\n+\n+    /**\n+     * Allocate or expand the decompression buffer, without exceeding the maximum allocation.\n+     * Calls {@link #maxAllocationReached(ByteBuf)} if the buffer is full and cannot be expanded further.\n+     */\n+    protected ByteBuf prepareDecompressBuffer(ChannelHandlerContext ctx, ByteBuf buffer, int preferredSize) {\n+        if (buffer == null) {\n+            if (maxAllocation == 0) {\n+                return ctx.alloc().heapBuffer(preferredSize);\n+            } else {\n+                return ctx.alloc().heapBuffer(Math.min(preferredSize, maxAllocation), maxAllocation);\n+            }\n+        }\n+\n+        if (buffer.ensureWritable(preferredSize, true) == 1) {", "originalCommit": "57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyNzEyNg==", "url": "https://github.com/netty/netty/pull/9924#discussion_r370327126", "bodyText": "I'm pretty sure this is correct as-is. The desired behavior is that if capacity < maxAllocation, we want to expand the buffer, even if we can't expand it by the preferredSize. Any expansion at all makes it possible that the decoder will successfully complete the decompression, since preferredSize is just a guesstimate. Hence we want to expand even if the expansion is less than what we'd prefer. If it turns out that's not enough space, then this method will be called again, and the buffer will already have capacity = maxAllocation and remaining = 0, and we'll fail at that point.", "author": "rdicroce", "createdAt": "2020-01-23T20:02:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4MzAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM0NzU3Ng==", "url": "https://github.com/netty/netty/pull/9924#discussion_r370347576", "bodyText": "OK I follow now, I missed that subtlety of ensureWritable, thinking that 1 would only apply to the force == false case. This is the same confusion as the comment above and I see that your logic there is consistent. Sorry!\nIt probably wouldn't harm to add a comment noting that one \"final\" attempt will always still be made with the buffer at maxAllocation even if that is < preferredSize.", "author": "njhill", "createdAt": "2020-01-23T20:51:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4MzAyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4Nzk4Mw==", "url": "https://github.com/netty/netty/pull/9924#discussion_r369187983", "bodyText": "Not sure that the semantics of the method are clear... if it's overridden to not throw then what state will the provided buffer be in, what is the impl expected to do with it and what is it expected to return? Maybe it would make most sense to pass false for the force param of ensureWritable above so that the buffer isn't changed, and also pass preferredSize and ctx to this method as additional parameters?\nnit: and maybe clearer method name would be something like decompressionBufferExhausted?", "author": "njhill", "createdAt": "2020-01-21T19:07:08Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/ZlibDecoder.java", "diffHunk": "@@ -16,16 +16,72 @@\n package io.netty.handler.codec.compression;\n \n import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufAllocator;\n+import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.ByteToMessageDecoder;\n \n /**\n  * Decompresses a {@link ByteBuf} using the deflate algorithm.\n  */\n public abstract class ZlibDecoder extends ByteToMessageDecoder {\n \n+    /**\n+     * Maximum allowed size of the decompression buffer.\n+     */\n+    protected int maxAllocation;\n+\n+    /**\n+     * Same as {@link #ZlibDecoder(int)} with maxAllocation = 0.\n+     */\n+    public ZlibDecoder() {\n+        this(0);\n+    }\n+\n+    /**\n+     * Construct a new ZlibDecoder.\n+     * @param maxAllocation\n+     *          Maximum size of the decompression buffer. Must be &gt;= 0.\n+     *          If zero, maximum size is decided by the {@link ByteBufAllocator}.\n+     */\n+    public ZlibDecoder(int maxAllocation) {\n+        if (maxAllocation < 0) {\n+            throw new IllegalArgumentException(\"maxAllocation must be >= 0\");\n+        }\n+        this.maxAllocation = maxAllocation;\n+    }\n+\n     /**\n      * Returns {@code true} if and only if the end of the compressed stream\n      * has been reached.\n      */\n     public abstract boolean isClosed();\n+\n+    /**\n+     * Allocate or expand the decompression buffer, without exceeding the maximum allocation.\n+     * Calls {@link #maxAllocationReached(ByteBuf)} if the buffer is full and cannot be expanded further.\n+     */\n+    protected ByteBuf prepareDecompressBuffer(ChannelHandlerContext ctx, ByteBuf buffer, int preferredSize) {\n+        if (buffer == null) {\n+            if (maxAllocation == 0) {\n+                return ctx.alloc().heapBuffer(preferredSize);\n+            } else {\n+                return ctx.alloc().heapBuffer(Math.min(preferredSize, maxAllocation), maxAllocation);\n+            }\n+        }\n+\n+        if (buffer.ensureWritable(preferredSize, true) == 1) {\n+            return maxAllocationReached(buffer);\n+        }\n+\n+        return buffer;\n+    }\n+\n+    /**\n+     * Called when the decompression buffer cannot be expanded further.\n+     * Default implementation throws an exception, but subclasses can override to change behavior.\n+     */\n+    protected ByteBuf maxAllocationReached(ByteBuf buffer) {", "originalCommit": "57e272aa5dbad10cc0dfd38a92f8eabdbb2131e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyOTk3OQ==", "url": "https://github.com/netty/netty/pull/9924#discussion_r370329979", "bodyText": "You're right that this probably shouldn't return anything - I'll change that. Can't remember exactly what I was thinking when I did that. My use case for wanting to override this is so that I can potentially log the data that has been decompressed so far before throwing the exception.", "author": "rdicroce", "createdAt": "2020-01-23T20:09:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE4Nzk4Mw=="}], "type": "inlineReview"}, {"oid": "f90f44656fccba7b8c449949fc34af690e0f2f11", "url": "https://github.com/netty/netty/commit/f90f44656fccba7b8c449949fc34af690e0f2f11", "message": "Addressed review comments", "committedDate": "2020-01-23T20:28:42Z", "type": "commit"}, {"oid": "5cf4389f333cc1a8647e05ce3b1d07bb0aa9b387", "url": "https://github.com/netty/netty/commit/5cf4389f333cc1a8647e05ce3b1d07bb0aa9b387", "message": "Fix Checkstyle issue", "committedDate": "2020-01-23T20:44:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyMzk2OQ==", "url": "https://github.com/netty/netty/pull/9924#discussion_r371823969", "bodyText": "nit: final", "author": "normanmaurer", "createdAt": "2020-01-28T14:11:22Z", "path": "codec/src/test/java/io/netty/handler/codec/compression/ZlibTest.java", "diffHunk": "@@ -360,4 +381,34 @@ public void testZLIB_OR_NONE3() throws Exception {\n         stream.close();\n         return out.toByteArray();\n     }\n+\n+    private static class TestByteBufAllocator extends AbstractByteBufAllocator {", "originalCommit": "5cf4389f333cc1a8647e05ce3b1d07bb0aa9b387", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDI2Mw==", "url": "https://github.com/netty/netty/pull/9924#discussion_r371824263", "bodyText": "call chDecoder.finish() and assert the return value", "author": "normanmaurer", "createdAt": "2020-01-28T14:11:52Z", "path": "codec/src/test/java/io/netty/handler/codec/compression/ZlibTest.java", "diffHunk": "@@ -345,6 +351,21 @@ public void testZLIB_OR_NONE3() throws Exception {\n         testCompressLarge(ZlibWrapper.GZIP, ZlibWrapper.ZLIB_OR_NONE);\n     }\n \n+    @Test\n+    public void testMaxAllocation() throws Exception {\n+        int maxAllocation = 1024;\n+        EmbeddedChannel chDecoder = new EmbeddedChannel(createDecoder(ZlibWrapper.NONE, maxAllocation));\n+        TestByteBufAllocator alloc = new TestByteBufAllocator(chDecoder.alloc());\n+        chDecoder.config().setAllocator(alloc);\n+\n+        try {\n+            chDecoder.writeInbound(Unpooled.copiedBuffer(BYTES_LARGE));\n+            fail(\"decompressed size > maxAllocation, so should have thrown exception\");\n+        } catch (DecompressionException e) {\n+            assertEquals(maxAllocation, alloc.getMaxAllocation());\n+        }", "originalCommit": "5cf4389f333cc1a8647e05ce3b1d07bb0aa9b387", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQyMTU0Mw==", "url": "https://github.com/netty/netty/pull/9924#discussion_r372421543", "bodyText": "Good catch - finish() was throwing an exception because the input buffer wasn't being consumed and the decoders weren't marking themselves as finished, so another attempt was being made to read the buffer. I've updated JZlibDecoder and JdkZlibDecoder to consume the buffer and mark themselves as finished at the same time they release the decompression buffer.", "author": "rdicroce", "createdAt": "2020-01-29T14:42:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDI2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDkzMA==", "url": "https://github.com/netty/netty/pull/9924#discussion_r371824930", "bodyText": "nit: protected (as this is an abstract class)", "author": "normanmaurer", "createdAt": "2020-01-28T14:12:56Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/ZlibDecoder.java", "diffHunk": "@@ -16,16 +16,75 @@\n package io.netty.handler.codec.compression;\n \n import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufAllocator;\n+import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.ByteToMessageDecoder;\n \n /**\n  * Decompresses a {@link ByteBuf} using the deflate algorithm.\n  */\n public abstract class ZlibDecoder extends ByteToMessageDecoder {\n \n+    /**\n+     * Maximum allowed size of the decompression buffer.\n+     */\n+    protected final int maxAllocation;\n+\n+    /**\n+     * Same as {@link #ZlibDecoder(int)} with maxAllocation = 0.\n+     */\n+    public ZlibDecoder() {", "originalCommit": "5cf4389f333cc1a8647e05ce3b1d07bb0aa9b387", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTgyNDk2MQ==", "url": "https://github.com/netty/netty/pull/9924#discussion_r371824961", "bodyText": "nit: protected (as this is an abstract class)", "author": "normanmaurer", "createdAt": "2020-01-28T14:13:00Z", "path": "codec/src/main/java/io/netty/handler/codec/compression/ZlibDecoder.java", "diffHunk": "@@ -16,16 +16,75 @@\n package io.netty.handler.codec.compression;\n \n import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufAllocator;\n+import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.ByteToMessageDecoder;\n \n /**\n  * Decompresses a {@link ByteBuf} using the deflate algorithm.\n  */\n public abstract class ZlibDecoder extends ByteToMessageDecoder {\n \n+    /**\n+     * Maximum allowed size of the decompression buffer.\n+     */\n+    protected final int maxAllocation;\n+\n+    /**\n+     * Same as {@link #ZlibDecoder(int)} with maxAllocation = 0.\n+     */\n+    public ZlibDecoder() {\n+        this(0);\n+    }\n+\n+    /**\n+     * Construct a new ZlibDecoder.\n+     * @param maxAllocation\n+     *          Maximum size of the decompression buffer. Must be &gt;= 0.\n+     *          If zero, maximum size is decided by the {@link ByteBufAllocator}.\n+     */\n+    public ZlibDecoder(int maxAllocation) {", "originalCommit": "5cf4389f333cc1a8647e05ce3b1d07bb0aa9b387", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d9f0057bb47801090418afdcde0cb08781a87a8f", "url": "https://github.com/netty/netty/commit/d9f0057bb47801090418afdcde0cb08781a87a8f", "message": "Resolved review comments", "committedDate": "2020-01-29T14:45:55Z", "type": "commit"}, {"oid": "4666459f9be82a1a44582c47200d72e199296a4e", "url": "https://github.com/netty/netty/commit/4666459f9be82a1a44582c47200d72e199296a4e", "message": "Fix checkstyle violation", "committedDate": "2020-01-29T15:15:45Z", "type": "commit"}, {"oid": "9b0378bdd71a3421bfdc35e83c12c93f1df4438b", "url": "https://github.com/netty/netty/commit/9b0378bdd71a3421bfdc35e83c12c93f1df4438b", "message": "Change constructors back to public (AKA fix build)", "committedDate": "2020-01-30T14:40:04Z", "type": "commit"}, {"oid": "3c32693b39568cb40f9c92cfc3a6c513c30f5066", "url": "https://github.com/netty/netty/commit/3c32693b39568cb40f9c92cfc3a6c513c30f5066", "message": "Fix tests", "committedDate": "2020-01-30T16:45:26Z", "type": "commit"}]}