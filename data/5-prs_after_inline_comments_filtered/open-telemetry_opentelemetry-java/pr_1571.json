{"pr_number": 1571, "pr_title": "Make sure forceFlush / shutdown can have callers wait for them to be done by returning CompletableResultCode.", "pr_createdAt": "2020-08-21T05:13:04Z", "pr_url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQzODA0NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474438044", "bodyText": "Shouldn't this always update nextExport?", "author": "iNikem", "createdAt": "2020-08-21T06:39:18Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +160,72 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    ScheduledFuture<?> nextExport = this.nextExport;\n+    if (nextExport != null) {\n+      nextExport.cancel(false);\n+    }\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n+    exportBatch();\n   }\n \n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+  // Timeout is best effort don't need to handle the future return value.\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportBatch() {\n+    List<ReadableSpan> batch = new ArrayList<>(Math.min(maxExportBatchSize, queue.size()));\n+    if (queue.drainTo(batch, maxExportBatchSize) == 0) {\n+      scheduleNextExport();\n+      return;\n     }\n \n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+    List<SpanData> forExport = new ArrayList<>(batch.size());\n+    for (ReadableSpan span : batch) {\n+      forExport.add(span.toSpanData());\n     }\n \n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = spanExporter.export(forExport);\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (!result.isSuccess()) {\n+              logger.log(Level.FINE, \"Exporter failed\");\n+            }\n+            if (queue.size() >= maxExportBatchSize) {\n+              exportBatch();\n+            } else {\n+              scheduleNextExport();\n+            }\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n-    }\n-\n-    private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n-      }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n-    }\n-\n-    private void exportBatches(ArrayList<ReadableSpan> spanList) {\n-      // TODO: Record a counter for pushed spans.\n-      for (int i = 0; i < spanList.size(); ) {\n-        int lastIndexToTake = Math.min(i + maxExportBatchSize, spanList.size());\n-        onBatchExport(createSpanDataForExport(spanList, i, lastIndexToTake));\n-        i = lastIndexToTake;\n-      }\n-    }\n-\n-    private static List<SpanData> createSpanDataForExport(\n-        List<ReadableSpan> spanList, int startIndex, int endIndex) {\n-      List<SpanData> spanDataBuffer = new ArrayList<>(endIndex - startIndex);\n-      for (int i = startIndex; i < endIndex; i++) {\n-        spanDataBuffer.add(spanList.get(i).toSpanData());\n-        // Remove the reference to the ReadableSpan to allow GC to free the memory.\n-        spanList.set(i, null);\n-      }\n-      return Collections.unmodifiableList(spanDataBuffer);\n-    }\n+        });\n+\n+    // Timeout if result doesn't complete soon enough.\n+    executor.schedule(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            result.fail();\n+          }\n+        },\n+        exporterTimeoutMillis,\n+        TimeUnit.MILLISECONDS);\n+  }\n \n-    // Exports the list of SpanData to the SpanExporter.\n-    @SuppressWarnings(\"BooleanParameter\")\n-    private void onBatchExport(final List<SpanData> spans) {\n-      if (exportAvailable.compareAndSet(true, false)) {\n-        try {\n-          final CompletableResultCode result = spanExporter.export(spans);\n-          result.whenComplete(\n-              new Runnable() {\n-                @Override\n-                public void run() {\n-                  if (!result.isSuccess()) {\n-                    logger.log(Level.FINE, \"Exporter failed\");\n-                  }\n-                  exportAvailable.set(true);\n-                }\n-              });\n-          timer.schedule(\n-              new TimerTask() {\n-                @Override\n-                public void run() {\n-                  result.fail();\n-                }\n-              },\n-              exporterTimeoutMillis);\n-        } catch (Exception e) {\n-          logger.log(Level.WARNING, \"Exporter threw an Exception\", e);\n-        }\n-      } else {\n-        logger.log(Level.FINE, \"Exporter busy. Dropping spans.\");\n-      }\n-    }\n+  private ScheduledFuture<?> scheduleNextExport() {", "originalCommit": "36f640a16803f2c3e8d1d8ab65ab061df58cd1a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ0NDQ2NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474444464", "bodyText": "Oops mixed myself up here", "author": "anuraaga", "createdAt": "2020-08-21T06:56:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQzODA0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQzODkxOQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474438919", "bodyText": "Not specific to this PR: Why this timeout is the configuration of BSP and not of the exporter?", "author": "iNikem", "createdAt": "2020-08-21T06:41:52Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +160,72 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    ScheduledFuture<?> nextExport = this.nextExport;\n+    if (nextExport != null) {\n+      nextExport.cancel(false);\n+    }\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n+    exportBatch();\n   }\n \n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+  // Timeout is best effort don't need to handle the future return value.\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportBatch() {\n+    List<ReadableSpan> batch = new ArrayList<>(Math.min(maxExportBatchSize, queue.size()));\n+    if (queue.drainTo(batch, maxExportBatchSize) == 0) {\n+      scheduleNextExport();\n+      return;\n     }\n \n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+    List<SpanData> forExport = new ArrayList<>(batch.size());\n+    for (ReadableSpan span : batch) {\n+      forExport.add(span.toSpanData());\n     }\n \n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = spanExporter.export(forExport);\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (!result.isSuccess()) {\n+              logger.log(Level.FINE, \"Exporter failed\");\n+            }\n+            if (queue.size() >= maxExportBatchSize) {\n+              exportBatch();\n+            } else {\n+              scheduleNextExport();\n+            }\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n-    }\n-\n-    private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n-      }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n-    }\n-\n-    private void exportBatches(ArrayList<ReadableSpan> spanList) {\n-      // TODO: Record a counter for pushed spans.\n-      for (int i = 0; i < spanList.size(); ) {\n-        int lastIndexToTake = Math.min(i + maxExportBatchSize, spanList.size());\n-        onBatchExport(createSpanDataForExport(spanList, i, lastIndexToTake));\n-        i = lastIndexToTake;\n-      }\n-    }\n-\n-    private static List<SpanData> createSpanDataForExport(\n-        List<ReadableSpan> spanList, int startIndex, int endIndex) {\n-      List<SpanData> spanDataBuffer = new ArrayList<>(endIndex - startIndex);\n-      for (int i = startIndex; i < endIndex; i++) {\n-        spanDataBuffer.add(spanList.get(i).toSpanData());\n-        // Remove the reference to the ReadableSpan to allow GC to free the memory.\n-        spanList.set(i, null);\n-      }\n-      return Collections.unmodifiableList(spanDataBuffer);\n-    }\n+        });\n+\n+    // Timeout if result doesn't complete soon enough.", "originalCommit": "36f640a16803f2c3e8d1d8ab65ab061df58cd1a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ0NDM3Nw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474444377", "bodyText": "It's in the spec too ;)\nhttps://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/trace/sdk.md#batching-processor\nI have this issue in case you'd like to add other potential improvements to the spec!\nopen-telemetry/opentelemetry-specification#849", "author": "anuraaga", "createdAt": "2020-08-21T06:55:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQzODkxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQzOTY5NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474439694", "bodyText": "Should benchmark this, but we can save on allocations if we take elements by one, convert them to SpanData and only then put to outgoing forExport. Then we don't need batch.", "author": "iNikem", "createdAt": "2020-08-21T06:44:01Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +160,72 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    ScheduledFuture<?> nextExport = this.nextExport;\n+    if (nextExport != null) {\n+      nextExport.cancel(false);\n+    }\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n+    exportBatch();\n   }\n \n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+  // Timeout is best effort don't need to handle the future return value.\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportBatch() {\n+    List<ReadableSpan> batch = new ArrayList<>(Math.min(maxExportBatchSize, queue.size()));\n+    if (queue.drainTo(batch, maxExportBatchSize) == 0) {", "originalCommit": "36f640a16803f2c3e8d1d8ab65ab061df58cd1a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ3Mjg0Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474472843", "bodyText": "I think poll has to get a lock in the queue at every call while drain only does it once for the entire batch, can only say for sure with a benchmark indeed but pending the benchmark, I lean towards sticking to drainTo.", "author": "anuraaga", "createdAt": "2020-08-21T07:33:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQzOTY5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQzOTkyNQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474439925", "bodyText": "Can we reuse this list and not re-allocate it on every export?", "author": "iNikem", "createdAt": "2020-08-21T06:44:41Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +160,72 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    ScheduledFuture<?> nextExport = this.nextExport;\n+    if (nextExport != null) {\n+      nextExport.cancel(false);\n+    }\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n+    exportBatch();\n   }\n \n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+  // Timeout is best effort don't need to handle the future return value.\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportBatch() {\n+    List<ReadableSpan> batch = new ArrayList<>(Math.min(maxExportBatchSize, queue.size()));\n+    if (queue.drainTo(batch, maxExportBatchSize) == 0) {\n+      scheduleNextExport();\n+      return;\n     }\n \n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+    List<SpanData> forExport = new ArrayList<>(batch.size());", "originalCommit": "36f640a16803f2c3e8d1d8ab65ab061df58cd1a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ4NjE0OA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474486148", "bodyText": "This one we pass to the exporter so we can't reuse, I added a reused ReadableSpan buffer though.", "author": "anuraaga", "createdAt": "2020-08-21T07:49:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQzOTkyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ0MjI2Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474442263", "bodyText": "I am concerned, that if any error situation prevents the runtime to reach this line for one export attempt, then the whole BSP will stop working. It seem that current design (schedule next export when this one finishes) tries to achieve \"fixed delay\". If we switch to \"fixed rate\" we can simplify it. I don't see why \"fixed rate\" is worse than \"fixed delay\".", "author": "iNikem", "createdAt": "2020-08-21T06:50:52Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +160,72 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    ScheduledFuture<?> nextExport = this.nextExport;\n+    if (nextExport != null) {\n+      nextExport.cancel(false);\n+    }\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n+    exportBatch();\n   }\n \n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+  // Timeout is best effort don't need to handle the future return value.\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportBatch() {\n+    List<ReadableSpan> batch = new ArrayList<>(Math.min(maxExportBatchSize, queue.size()));\n+    if (queue.drainTo(batch, maxExportBatchSize) == 0) {\n+      scheduleNextExport();\n+      return;\n     }\n \n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+    List<SpanData> forExport = new ArrayList<>(batch.size());\n+    for (ReadableSpan span : batch) {\n+      forExport.add(span.toSpanData());\n     }\n \n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = spanExporter.export(forExport);\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (!result.isSuccess()) {\n+              logger.log(Level.FINE, \"Exporter failed\");\n+            }\n+            if (queue.size() >= maxExportBatchSize) {\n+              exportBatch();\n+            } else {\n+              scheduleNextExport();", "originalCommit": "36f640a16803f2c3e8d1d8ab65ab061df58cd1a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ3MTU0NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474471544", "bodyText": "I agree with the sentiment, but I think we can be confident in our implementation of CompletableResultCode - so worst case should be the timeout below calling this callback no matter what.\nI think fixed delay tends to be safer by easily preventing concurrent exports (avoid the need to keep track of availability) and is my reading of the spec anyways. Fixed rate would still be ok I think if we didn't have the eager export when queue still has items like on line 200, which makes the time spent on exporting very unpredictable - I noticed the other implementations have this behavior too so kept it here. Also if we went with fixed rate, I don't think we'd be able to do buffer reuse optimization as in https://github.com/open-telemetry/opentelemetry-java/pull/1571/files#r474439925\nI've seen a lot of similar async + scheduled tasks in Armeria and we almost always use this delay pattern to avoid the concurrency issue, and are just confident that callbacks always get called - I'd like to keep it like this but let me know if it's a strong concern.", "author": "anuraaga", "createdAt": "2020-08-21T07:31:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ0MjI2Mw=="}], "type": "inlineReview"}, {"oid": "e1640750a6e321f743a3c598d3fba2d2aa10c5ba", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/e1640750a6e321f743a3c598d3fba2d2aa10c5ba", "message": "forceFlush", "committedDate": "2020-08-21T08:39:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY5MDQxMg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474690412", "bodyText": "Empty if?", "author": "iNikem", "createdAt": "2020-08-21T13:18:24Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +166,102 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n-  }\n-\n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+    forceFlush = true;\n+    // Cancel only returns true once.\n+    if (!nextExport.cancel(false)) {\n+      // Already exporting.", "originalCommit": "e1640750a6e321f743a3c598d3fba2d2aa10c5ba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY5Nzk5Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474697993", "bodyText": "With these recent changes it became much more complicated :(", "author": "iNikem", "createdAt": "2020-08-21T13:30:33Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +166,102 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n-  }\n-\n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+    forceFlush = true;\n+    // Cancel only returns true once.\n+    if (!nextExport.cancel(false)) {\n+      // Already exporting.\n     }\n-\n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n-    }\n-\n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportBatch(result);\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n+        });\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            latch.countDown();\n+          }\n+        });\n+    try {\n+      latch.await(exporterTimeoutMillis, TimeUnit.MILLISECONDS);\n+    } catch (InterruptedException e) {\n+      logger.log(Level.WARNING, \"Interrupted while forcing span flush.\");\n+      Thread.currentThread().interrupt();\n     }\n+  }\n \n-    private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n-      }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n+  // Timeout is best effort don't need to handle the future return value.\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportBatch(final CompletableResultCode result) {\n+    spanBuffer.clear();\n+    if (queue.drainTo(spanBuffer, maxExportBatchSize) == 0) {\n+      result.succeed();\n+      scheduleNextExport();\n+      return;\n     }\n \n-    private void exportBatches(ArrayList<ReadableSpan> spanList) {\n-      // TODO: Record a counter for pushed spans.\n-      for (int i = 0; i < spanList.size(); ) {\n-        int lastIndexToTake = Math.min(i + maxExportBatchSize, spanList.size());\n-        onBatchExport(createSpanDataForExport(spanList, i, lastIndexToTake));\n-        i = lastIndexToTake;\n-      }\n+    List<SpanData> forExport = new ArrayList<>(spanBuffer.size());\n+    for (ReadableSpan span : spanBuffer) {\n+      forExport.add(span.toSpanData());\n     }\n \n-    private static List<SpanData> createSpanDataForExport(\n-        List<ReadableSpan> spanList, int startIndex, int endIndex) {\n-      List<SpanData> spanDataBuffer = new ArrayList<>(endIndex - startIndex);\n-      for (int i = startIndex; i < endIndex; i++) {\n-        spanDataBuffer.add(spanList.get(i).toSpanData());\n-        // Remove the reference to the ReadableSpan to allow GC to free the memory.\n-        spanList.set(i, null);\n-      }\n-      return Collections.unmodifiableList(spanDataBuffer);\n-    }\n+    final CompletableResultCode exportResult = spanExporter.export(forExport);\n+    exportResult.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (!exportResult.isSuccess()) {\n+              logger.log(Level.FINE, \"Exporter failed\");\n+            }\n+            if (queue.size() >= maxExportBatchSize) {\n+              exportBatch(result);\n+            } else if (forceFlush) {\n+              // When we're forcing a flush we want to export even when we don't have a full batch.\n+              forceFlush = false;", "originalCommit": "e1640750a6e321f743a3c598d3fba2d2aa10c5ba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDcwMTE2OA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474701168", "bodyText": "Yeah - I noticed that the forceFlush / shutdown weren't waiting for all the processing anymore in the current code too, though those methods have to be from what I can tell from their javadoc. Not sure of a way around without allowing concurrent exports.", "author": "anuraaga", "createdAt": "2020-08-21T13:34:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY5Nzk5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg1NzA5OA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474857098", "bodyText": "It sure would be nice if we had CompletableFuture here, so we could just have exportBatch return one and we could wait for it to a complete with a timeout. :(", "author": "jkwatson", "createdAt": "2020-08-21T18:23:22Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +166,103 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n-  }\n-\n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n-    }\n-\n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+    forceFlush = true;\n+    // Cancel only returns true once.\n+    if (!nextExport.cancel(false)) {\n+      // Already exporting.\n+      return;\n     }\n-\n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportBatch(result);\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n+        });\n+    final CountDownLatch latch = new CountDownLatch(1);", "originalCommit": "38f76bb5e2284ca293e64a55b0e441f200c8f009", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1NzY2Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474957663", "bodyText": "I got caught up handling forceFlush in a way that tried to respect the delay as much as possible (e.g., canceling the schedule). I realized this is overkill, even if there's a bit of extra churn when flushing it's ok given the use case for the function. Will rework to remove a lot of cruft.", "author": "anuraaga", "createdAt": "2020-08-21T20:48:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg1NzA5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3MTMzMA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474971330", "bodyText": "Needed to also add the waiting here - forceFlush, unlike normal export, does need to block on the export that's what it's designed for. I noticed our tests never actually verified this since they were blocking outside of forceFlush so I tweaked them.\n@jkwatson Do you think I should move this into a join method on CompletableResultCode so it looks like a duck CompletableFuture?", "author": "anuraaga", "createdAt": "2020-08-21T21:09:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg1NzA5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3NTAyNQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474975025", "bodyText": "I don\u2019t think it is a great concern as what you have reads fine to me in the absence of Java 8.", "author": "huntc", "createdAt": "2020-08-21T21:20:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg1NzA5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg2MTc2NQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474861765", "bodyText": "Won't this cause an eventual stack overflow in the situation where the exporter can't keep up with the volume?", "author": "jkwatson", "createdAt": "2020-08-21T18:34:03Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +166,103 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n-  }\n-\n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n-    }\n-\n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+    forceFlush = true;\n+    // Cancel only returns true once.\n+    if (!nextExport.cancel(false)) {\n+      // Already exporting.\n+      return;\n     }\n-\n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportBatch(result);\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n+        });\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            latch.countDown();\n+          }\n+        });\n+    try {\n+      latch.await(exporterTimeoutMillis, TimeUnit.MILLISECONDS);\n+    } catch (InterruptedException e) {\n+      logger.log(Level.WARNING, \"Interrupted while forcing span flush.\");\n+      Thread.currentThread().interrupt();\n     }\n+  }\n \n-    private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n-      }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n+  // Timeout is best effort don't need to handle the future return value.\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportBatch(final CompletableResultCode result) {\n+    spanBuffer.clear();\n+    if (queue.drainTo(spanBuffer, maxExportBatchSize) == 0) {\n+      result.succeed();\n+      scheduleNextExport();\n+      return;\n     }\n \n-    private void exportBatches(ArrayList<ReadableSpan> spanList) {\n-      // TODO: Record a counter for pushed spans.\n-      for (int i = 0; i < spanList.size(); ) {\n-        int lastIndexToTake = Math.min(i + maxExportBatchSize, spanList.size());\n-        onBatchExport(createSpanDataForExport(spanList, i, lastIndexToTake));\n-        i = lastIndexToTake;\n-      }\n+    List<SpanData> forExport = new ArrayList<>(spanBuffer.size());\n+    for (ReadableSpan span : spanBuffer) {\n+      forExport.add(span.toSpanData());\n     }\n \n-    private static List<SpanData> createSpanDataForExport(\n-        List<ReadableSpan> spanList, int startIndex, int endIndex) {\n-      List<SpanData> spanDataBuffer = new ArrayList<>(endIndex - startIndex);\n-      for (int i = startIndex; i < endIndex; i++) {\n-        spanDataBuffer.add(spanList.get(i).toSpanData());\n-        // Remove the reference to the ReadableSpan to allow GC to free the memory.\n-        spanList.set(i, null);\n-      }\n-      return Collections.unmodifiableList(spanDataBuffer);\n-    }\n+    final CompletableResultCode exportResult = spanExporter.export(forExport);\n+    exportResult.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (!exportResult.isSuccess()) {\n+              logger.log(Level.FINE, \"Exporter failed\");\n+            }\n+            if (queue.size() >= maxExportBatchSize) {\n+              exportBatch(result);", "originalCommit": "38f76bb5e2284ca293e64a55b0e441f200c8f009", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg2Mzc5Mg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474863792", "bodyText": "it hurts me that we have to do this to implement the timeout. Especially since it won't actually stop the export from running!", "author": "jkwatson", "createdAt": "2020-08-21T18:38:46Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +166,103 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    forceFlush();\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n-  }\n-\n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n-    }\n-\n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+    forceFlush = true;\n+    // Cancel only returns true once.\n+    if (!nextExport.cancel(false)) {\n+      // Already exporting.\n+      return;\n     }\n-\n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportBatch(result);\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n+        });\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            latch.countDown();\n+          }\n+        });\n+    try {\n+      latch.await(exporterTimeoutMillis, TimeUnit.MILLISECONDS);\n+    } catch (InterruptedException e) {\n+      logger.log(Level.WARNING, \"Interrupted while forcing span flush.\");\n+      Thread.currentThread().interrupt();\n     }\n+  }\n \n-    private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n-      }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n+  // Timeout is best effort don't need to handle the future return value.\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportBatch(final CompletableResultCode result) {\n+    spanBuffer.clear();\n+    if (queue.drainTo(spanBuffer, maxExportBatchSize) == 0) {\n+      result.succeed();\n+      scheduleNextExport();\n+      return;\n     }\n \n-    private void exportBatches(ArrayList<ReadableSpan> spanList) {\n-      // TODO: Record a counter for pushed spans.\n-      for (int i = 0; i < spanList.size(); ) {\n-        int lastIndexToTake = Math.min(i + maxExportBatchSize, spanList.size());\n-        onBatchExport(createSpanDataForExport(spanList, i, lastIndexToTake));\n-        i = lastIndexToTake;\n-      }\n+    List<SpanData> forExport = new ArrayList<>(spanBuffer.size());\n+    for (ReadableSpan span : spanBuffer) {\n+      forExport.add(span.toSpanData());\n     }\n \n-    private static List<SpanData> createSpanDataForExport(\n-        List<ReadableSpan> spanList, int startIndex, int endIndex) {\n-      List<SpanData> spanDataBuffer = new ArrayList<>(endIndex - startIndex);\n-      for (int i = startIndex; i < endIndex; i++) {\n-        spanDataBuffer.add(spanList.get(i).toSpanData());\n-        // Remove the reference to the ReadableSpan to allow GC to free the memory.\n-        spanList.set(i, null);\n-      }\n-      return Collections.unmodifiableList(spanDataBuffer);\n-    }\n+    final CompletableResultCode exportResult = spanExporter.export(forExport);\n+    exportResult.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (!exportResult.isSuccess()) {\n+              logger.log(Level.FINE, \"Exporter failed\");\n+            }\n+            if (queue.size() >= maxExportBatchSize) {\n+              exportBatch(result);\n+            } else if (forceFlush) {\n+              // When we're forcing a flush we want to export even when we don't have a full batch.\n+              forceFlush = false;\n+              exportBatch(result);\n+            } else {\n+              result.succeed();\n+              scheduleNextExport();\n+            }\n+          }\n+        });\n+\n+    // Timeout if result doesn't complete soon enough.\n+    executor.schedule(", "originalCommit": "38f76bb5e2284ca293e64a55b0e441f200c8f009", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk2OTMzMg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474969332", "bodyText": "Nothing can stop an export from running. We\u2019ve no idea what threads it runs on.", "author": "huntc", "createdAt": "2020-08-21T21:03:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg2Mzc5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3MTcyNw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474971727", "bodyText": "If we need to add canceling of ongoing export, we can add a cancel method to CompletableResultCode which cancellable exporters would need to listen for. Can think about it for the future.", "author": "anuraaga", "createdAt": "2020-08-21T21:10:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg2Mzc5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3NTUwNQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474975505", "bodyText": "You can already do it. Fail the result code from here. Exporters should also register for completion and handle accordingly.", "author": "huntc", "createdAt": "2020-08-21T21:21:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg2Mzc5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3NTkyOQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474975929", "bodyText": "The previous code had this functionality given the need to shutdown exports taking too long.", "author": "huntc", "createdAt": "2020-08-21T21:22:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg2Mzc5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3NjkzMA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474976930", "bodyText": "It's an interesting idea to have the exporter also listen on its result, don't think I've seen that pattern before but it sounds like it'd work! In that case yeah this should be ok since we're failing the export result like before in the timeout.", "author": "anuraaga", "createdAt": "2020-08-21T21:25:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg2Mzc5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAxMzc5MA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475013790", "bodyText": "Exporters should subscribe to their completion status by convention. It is the only way they can properly handle their  shutdown method.\nWe should probably add a sentence to the exporter shutdown method to highlight this, and also that there is only ever one completion in flight at any one time.", "author": "huntc", "createdAt": "2020-08-21T23:50:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg2Mzc5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3ODA4Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r474978083", "bodyText": "It\u2019s disappointing that we\u2019ve resorted to blocking a thread again as a solution given the effort I went to removing it in the past. Blocking is generally avoidable.", "author": "huntc", "createdAt": "2020-08-21T21:29:18Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -132,180 +165,131 @@ public boolean isEndRequired() {\n \n   @Override\n   public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n+    nextExport.cancel(false);\n+    forceFlush();\n+    executor.shutdown();\n+    spanExporter.shutdown();\n   }\n \n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n   @Override\n   public void forceFlush() {\n-    worker.forceFlush();\n-  }\n-\n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n-    }\n-\n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n-    }\n-\n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final List<ReadableSpan> spans = new ArrayList<>(queue.size());\n+    queue.drainTo(spans);\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportNextBatch(spans, 0, result);\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n+        });\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            latch.countDown();\n+          }\n+        });\n+    try {\n+      latch.await(exporterTimeoutMillis, TimeUnit.MILLISECONDS);", "originalCommit": "90e80883497c6cc2ef096f6bc00466827af9db8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAxNDc1NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475014754", "bodyText": "To add to this, passing in an executor or Timer (existing impl) that the BSP can share with other parts of an app is important. Thread and their pools are an expensive resource, particularly for embedded environments (like Android ;-) ).\nSharing thread resources does mean that blocking is to be avoided.", "author": "huntc", "createdAt": "2020-08-21T23:55:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3ODA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzNzcyMA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475037720", "bodyText": "I think forceFlush would have to return a CompletableResultCode to allow a caller to wait if it needs to - this would be a huge API change since span processors are defined in the spec itself, both it and the javadoc recommend blocking\nhttps://github.com/open-telemetry/opentelemetry-specification/blob/master/specification/trace/sdk.md#shutdown\nOf course since some languages can't block anyways this does seem like an impractical spec in some sense.\n@jkwatson any appetite for changing forceFlush / shutdown to return completable?", "author": "anuraaga", "createdAt": "2020-08-22T02:58:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3ODA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzNzk0MA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475037940", "bodyText": "I think that's fine. Users who don't care about the result can continue to ignore it. :)", "author": "jkwatson", "createdAt": "2020-08-22T03:01:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3ODA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzODAyNg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475038026", "bodyText": "Ah also just to make sure, to the point of sharing threads allowing a user to provide an executor is interesting - I think we can do it but would probably lose the buffer reuse optimization since it may not be a single thread.\nBut since the point is about blocking shared threads wanted to point out this is blocking the caller, not the processing thread. The method is currently intended to be used when the caller wants that.", "author": "anuraaga", "createdAt": "2020-08-22T03:02:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3ODA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzODA3Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475038073", "bodyText": "@jkwatson Cool - let me try changing the return type, it does also give the option of an async force flush which is nice.", "author": "anuraaga", "createdAt": "2020-08-22T03:03:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk3ODA4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475047065", "bodyText": "I\u2019d really rather we don\u2019t add methods that encourage blocking. My past colleague, Viktor Klang, once said that providing an await on Scala\u2019s Future was a mistake. People WILL abuse this!!!\nPlease remove it.", "author": "huntc", "createdAt": "2020-08-22T05:01:03Z", "path": "sdk/common/src/main/java/io/opentelemetry/sdk/common/export/CompletableResultCode.java", "diffHunk": "@@ -107,4 +149,32 @@ public CompletableResultCode whenComplete(Runnable action) {\n     }\n     return this;\n   }\n+\n+  /**\n+   * Waits for the specified amount of time for this {@link CompletableResultCode} to complete.\n+   *\n+   * @return this {@link CompletableResultCode}\n+   * @throws InterruptedException if the current thread was interrupted while waiting\n+   * @throws TimeoutException if the wait timed out\n+   */\n+  public CompletableResultCode get(long timeout, TimeUnit unit)\n+      throws InterruptedException, TimeoutException {\n+    synchronized (lock) {\n+      if (succeeded != null) {\n+        return this;\n+      }\n+    }\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            latch.countDown();\n+          }\n+        });\n+    if (!latch.await(timeout, unit)) {\n+      throw new TimeoutException();\n+    }\n+    return this;\n+  }", "originalCommit": "66e42b8052ca6798a50680fe3901c8a845d9c959", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0ODU5Ng==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475048596", "bodyText": "Scala has a lot of patterns for asynchronouos programming and I can understand that sentiment, but this is Java, it's used in a lot of codebases, and arguable a majority is just standard Tomcat thread-per-request, block a lot. The CountDownLatch pattern is too tedious for these users if they need to wait for a flush - as a Java API, we need to make sure blocking users have an idiomatic API as well.\nFWIW, I'm a huge proponent of asynchronous programming and it's one of the reasons I've been trying my best to push all the work on CompletableResultCode forward. Even in Armeria, it took me months to finally allow a blocking option for gRPC since async is awesome! But after users continue to have problems because of it, it became obvious that in Java it's not fair to the users to make blocking inconvenient since many need it, so finally changed my mind. I appreciate you pointing out that instead of blocking by default, we should return CompletableResultCode and I think the API is much more flexible thanks to it :) But can't ignore the use cases for blocking here too, hope that makes sense. (rereading that linked issue apparently I saved someone's life that's gotta be worth it? :P)", "author": "anuraaga", "createdAt": "2020-08-22T05:21:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0OTI1OA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475049258", "bodyText": "The Java vs Scala angle on async programming is inaccurate. The world for Java developers is no different from that of Scala developers when it comes to async.\nThis get method will encourage blocking where it is not required. Please reconsider.", "author": "huntc", "createdAt": "2020-08-22T05:30:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1MzAyNA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475053024", "bodyText": "Perhaps as a compromise, let's see if a problem surfaces where a user of Export related code demands the blocking scenario and remove the get for now. Less API surface area to maintain is always a good thing. WDYT?", "author": "huntc", "createdAt": "2020-08-22T06:16:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1NDcyOA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475054728", "bodyText": "forceFlush exists in the first place mainly for FaaS like AWS Lambda. They require blocking processing or risk having the runtime freeze. Ideally the lambda runtime would have a callback to control freeze - I don't see any reason that won't happen someday but we're not there yet and this is just one runtime. Providing a way to wait for spans to process in FaaS is a well understood use case for this API.\nShutdown also, very few shutdown hooks would function without blocking, I believe this is still the case for e.g. Spring when it closes beans.\nWhen CompletableResultCode was only at the exporter I think it was far from the user but the span processor is much closer, and we have well known use cases for these to allow blocking so let's provide support for this. FWIW we're only providing a version with a timeout here, and I don't see a reason to provide a no-timeout version which would be vastly easier to call in the wrong way.", "author": "anuraaga", "createdAt": "2020-08-22T06:38:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1NTM3NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475055374", "bodyText": "I think it is interesting (and slightly worrying) how the scope of CompletableResultCode is widening beyond export code. Presently, it is declared under the common.export package. If you proceed to widen its scope then I suggest at least moving it up a package.", "author": "huntc", "createdAt": "2020-08-22T06:46:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1NjYwNA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475056604", "bodyText": "Thanks for noticing, yeah definitely will move it up.\nJust to confirm you prefer it to reverting forceFlush to void and blocking there? That method must require a way to wait for processing for the use cases I mentioned, so it was either block by default or allow the user to block if they need to. I think you didn't like the former, hence today's commits, and I also agree that giving the option of async or sync is better. But then I'm confused to hear that this change is worrying you \ud83d\ude05", "author": "anuraaga", "createdAt": "2020-08-22T07:02:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1NzQzMw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475057433", "bodyText": "I'm unclear on why forceFlush should block at all. We're forcing a flush downstream, which is fine, but it isn't a shutdown, right? Or have I misunderstood? I've avoided FaaS so I'm a bit ignorant of its quirks, but I'm surprised that an effective shutdown must occur on every execution. If it does though, then calling a shutdown method is more appropriate than just forceFlush (which a shutdown may implicitly perform).\nI concede on the use-cases where shutting down requires blocking via joins so that a \"process\" can exit cleanly.", "author": "huntc", "createdAt": "2020-08-22T07:12:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1NzYxMw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475057613", "bodyText": "Even Akka recommends blocking on shutdown. :-)", "author": "huntc", "createdAt": "2020-08-22T07:14:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1ODIxMQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475058211", "bodyText": "Your surprise is warranted :) But in FaaS it's common to use docker to freeze the process using cgroups when there are no pending requests. When a request comes in it will start back up, but no static initializers or anything run - it's literally back where it was before freeze. So because we don't know how long we'll freeze, we do need a way to make sure spans are sent before - freeze for hours and the trace effectively never finishes. But we can't shutdown since then when we unfreeze all the resources are already shutdown and tracing is stopped. So it's literally a forced flush, but not a shutdown.\nI like the idea of returning async from force flush really and am glad you suggested it, while I know lambda requires blocking it for now, an ideal runtime would allow async control of freeze - such a runtime may already exist or will come eventually. So I'm of the mind of moving CompletableResultCode up hope it sounds ok.", "author": "anuraaga", "createdAt": "2020-08-22T07:22:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1ODQ5MA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475058490", "bodyText": "Instead, how about a separate shutdown method that ensures the related exporter is also shutdown then? With async exporters, you definitely want to instruct it directly to shutdown.", "author": "huntc", "createdAt": "2020-08-22T07:26:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1ODU4Mg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475058582", "bodyText": "I recall @jkwatson mentioning that the NR exporter is already async and will perform activity beyond the export method being called. Another reason for shutdown in a FaaS context?", "author": "huntc", "createdAt": "2020-08-22T07:27:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1ODkwNw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475058907", "bodyText": "Sorry don't quite follow - we have shutdown already which will shutdown the exporters too. But calling this in FaaS isn't good because when the function wakes up everything will be shut down. So we have forceFlush which flushes the spans without shutting down exporters. Think I'm missing something from your suggestion can you clarify?", "author": "anuraaga", "createdAt": "2020-08-22T07:32:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1OTE1NQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475059155", "bodyText": "A force-flush will see that a span processor's buffers are flushed. This has no effect on any async activity being performed by an exporter at the time. Some exporters, like NR's, apparently process exports in the background having immediately returned from the export method.", "author": "huntc", "createdAt": "2020-08-22T07:35:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1OTE5Ng==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475059196", "bodyText": "Perhaps a sync or pause style method is required to convey that the environment is about to suspend.", "author": "huntc", "createdAt": "2020-08-22T07:35:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA1OTcwOA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475059708", "bodyText": "Your earlier suggestion of a join on CompletableResultCode is now quite appealing. If you have join then you shouldn't require get and join's semantics are nice here. Also, force-flush can be async for nearly all use-cases.\nNR's exporter is a separate issue. Anything to be used in a FaaS or shutdown style scenario will need to utilise CompleteableResultCode. Joining force-flush's result code will then \"just work\".", "author": "huntc", "createdAt": "2020-08-22T07:41:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA2MDg5Mg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475060892", "bodyText": "Thanks! I have always considered get and join to be the same, but former has checked exceptions and allows timeout. Are you suggesting we go with join with unchecked exceptions? Or maybe I'm missing a difference in semantics, I've never considered the two  in much depth but let me know if join seems better. I may have to define an exception type if we use unchecked exceptions.", "author": "anuraaga", "createdAt": "2020-08-22T07:57:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA2MTgyNA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475061824", "bodyText": "Are you suggesting we go with join with unchecked exceptions?\n\nYeah.\nUsing get returns a result that we aren't really interested in - it has no real meaning for the context where we're shutting down or flushing. Joining conveys more about what we're trying to do IMHO. The fact that join returns a value is weird to me, but we should be consistent with CompletableFuture I guess.\nExceptions are generally going to be non-recoverable too, so returning an unchecked exception makes sense to me.\nI think the use of join should be rare (as it is with CompletableFuture). But the ideal for the use-cases you mentioned.", "author": "huntc", "createdAt": "2020-08-22T08:09:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA0NzA2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0NjQ5Nw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475346497", "bodyText": "Using Thread.sleep is fragile in tests", "author": "huntc", "createdAt": "2020-08-24T05:12:48Z", "path": "sdk/tracing/src/test/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessorTest.java", "diffHunk": "@@ -171,25 +174,35 @@ void exportMoreSpansThanTheBufferSize() {\n     ReadableSpan span4 = createSampledEndedSpan(SPAN_NAME_1);\n     ReadableSpan span5 = createSampledEndedSpan(SPAN_NAME_1);\n     ReadableSpan span6 = createSampledEndedSpan(SPAN_NAME_1);\n-    List<SpanData> exported = waitingSpanExporter.waitForExport();\n-    assertThat(exported)\n-        .containsExactly(\n-            span1.toSpanData(),\n-            span2.toSpanData(),\n-            span3.toSpanData(),\n-            span4.toSpanData(),\n-            span5.toSpanData(),\n-            span6.toSpanData());\n+\n+    // Give time for the BatchSpanProcessor to attempt to export spans.\n+    Thread.sleep(500);", "originalCommit": "141c05e131c281fceb6c7a17dd17260ceb0db64a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM2MDAwNg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475360006", "bodyText": "I agree - I couldn't find a way around it for this test though.", "author": "anuraaga", "createdAt": "2020-08-24T06:02:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0NjQ5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkyOTkyNg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475929926", "bodyText": "I agree - I couldn't find a way around it for this test though.\n\nI had the same problem in my PR. The test should assert only what it can guarantee. If we aren\u2019t happy with that then we should remove the test entirely, as the required outcome can\u2019t be achieved.\nFlaky tests will cause headaches for some unfortunate soul down the track.", "author": "huntc", "createdAt": "2020-08-24T22:29:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0NjQ5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0NzYyNg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475347626", "bodyText": "Can we pass in the executor here so that the BSP can share resources and leave the executor as an outside concern?", "author": "huntc", "createdAt": "2020-08-24T05:16:49Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -82,31 +83,61 @@\n  */\n public final class BatchSpanProcessor implements SpanProcessor {\n \n+  private static final Logger logger = Logger.getLogger(BatchSpanProcessor.class.getName());\n+\n   private static final String WORKER_THREAD_NAME =\n       BatchSpanProcessor.class.getSimpleName() + \"_WorkerThread\";\n-  private static final String TIMER_THREAD_NAME =\n-      BatchSpanProcessor.class.getSimpleName() + \"_TimerThread\";\n-  private final Worker worker;\n-  private final Thread workerThread;\n+\n+  private static final BoundLongCounter droppedSpans;\n+\n+  static {\n+    Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n+    LongCounter droppedSpansCounter =\n+        meter\n+            .longCounterBuilder(\"droppedSpans\")\n+            .setUnit(\"1\")\n+            .setDescription(\n+                \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n+            .build();\n+    droppedSpans =\n+        droppedSpansCounter.bind(\n+            Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n+  }\n+\n+  private final int maxExportBatchSize;\n+  private final long scheduleDelayMillis;\n+  private final int exporterTimeoutMillis;\n   private final boolean sampled;\n \n+  private final SpanExporter spanExporter;\n+  private final BlockingQueue<ReadableSpan> queue;\n+  private final ScheduledExecutorService executor;\n+\n+  private final List<ReadableSpan> spanBuffer;\n+\n+  private volatile boolean closed;\n+  private volatile ScheduledFuture<?> nextExport;\n+\n   private BatchSpanProcessor(\n       SpanExporter spanExporter,\n       boolean sampled,\n       long scheduleDelayMillis,\n       int maxQueueSize,\n       int maxExportBatchSize,\n       int exporterTimeoutMillis) {\n-    this.worker =\n-        new Worker(\n-            spanExporter,\n-            scheduleDelayMillis,\n-            maxQueueSize,\n-            maxExportBatchSize,\n-            exporterTimeoutMillis);\n-    this.workerThread = new DaemonThreadFactory(WORKER_THREAD_NAME).newThread(worker);\n-    this.workerThread.start();\n+    this.maxExportBatchSize = maxExportBatchSize;\n+    this.scheduleDelayMillis = scheduleDelayMillis;\n+    this.exporterTimeoutMillis = exporterTimeoutMillis;\n     this.sampled = sampled;\n+\n+    this.spanExporter = spanExporter;\n+    queue = new ArrayBlockingQueue<>(maxQueueSize);\n+    executor =\n+        Executors.newSingleThreadScheduledExecutor(new DaemonThreadFactory(WORKER_THREAD_NAME));", "originalCommit": "141c05e131c281fceb6c7a17dd17260ceb0db64a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM1ODYyMQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475358621", "bodyText": "I like the idea of allowing to pass an executor but would like to keep it to a follow up if that's ok, it's a small change since we'd need a fallback anyways, and this PR has enough to digest.", "author": "anuraaga", "createdAt": "2020-08-24T05:58:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0NzYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM2NDk1Nw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475364957", "bodyText": "I don't think there should be a fallback executor. The executor should always be an external concern IMHO. Users should be encouraged to think about these things... :-)", "author": "huntc", "createdAt": "2020-08-24T06:17:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0NzYyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0ODAwNQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475348005", "bodyText": "The executor should be an outside concern", "author": "huntc", "createdAt": "2020-08-24T05:18:28Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -131,181 +164,160 @@ public boolean isEndRequired() {\n   }\n \n   @Override\n-  public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n-  }\n+  public CompletableResultCode shutdown() {\n+    closed = true;\n+    nextExport.cancel(false);\n+\n+    final CompletableResultCode result = new CompletableResultCode();\n+    final CompletableResultCode flushResult = forceFlush();\n+    flushResult.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            executor.shutdown();", "originalCommit": "141c05e131c281fceb6c7a17dd17260ceb0db64a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM1ODg0Mg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475358842", "bodyText": "Ditto, I don't think we should require a user to bring their executor. So if we support it, we would shutdown a fallback executor, or not shutdown otherwise, and I'd like to handle that separately.", "author": "anuraaga", "createdAt": "2020-08-24T05:58:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0ODAwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0ODYzMg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475348632", "bodyText": "I'm thinking that a native array copy would be more efficient here... and then form an array list around that for calling the exporter. WDYT?", "author": "huntc", "createdAt": "2020-08-24T05:21:08Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -131,181 +164,160 @@ public boolean isEndRequired() {\n   }\n \n   @Override\n-  public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n-  }\n+  public CompletableResultCode shutdown() {\n+    closed = true;\n+    nextExport.cancel(false);\n+\n+    final CompletableResultCode result = new CompletableResultCode();\n+    final CompletableResultCode flushResult = forceFlush();\n+    flushResult.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            executor.shutdown();\n+            final CompletableResultCode shutdownResult = spanExporter.shutdown();\n+            shutdownResult.whenComplete(\n+                new Runnable() {\n+                  @Override\n+                  public void run() {\n+                    if (!flushResult.isSuccess() || !shutdownResult.isSuccess()) {\n+                      result.fail();\n+                    } else {\n+                      result.succeed();\n+                    }\n+                  }\n+                });\n+          }\n+        });\n \n-  @Override\n-  public void forceFlush() {\n-    worker.forceFlush();\n+    return result;\n   }\n \n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  @Override\n+  public CompletableResultCode forceFlush() {\n+    if (queue.isEmpty()) {\n+      return CompletableResultCode.ofSuccess();\n     }\n+    final List<ReadableSpan> spans = new ArrayList<>(queue.size());\n+    queue.drainTo(spans);\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportNextBatch(spans, 0, result);\n+          }\n+        });\n+    return result;\n+  }\n \n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportSpans() {\n+    spanBuffer.clear();\n+    if (queue.drainTo(spanBuffer) == 0) {\n+      scheduleNextExport();\n+      return;\n     }\n \n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportNextBatch(spanBuffer, 0, result);\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n-    }\n+        });\n+\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (queue.size() >= maxExportBatchSize) {\n+              executor.submit(\n+                  new Runnable() {\n+                    @Override\n+                    public void run() {\n+                      exportSpans();\n+                    }\n+                  });\n+            } else {\n+              scheduleNextExport();\n+            }\n+          }\n+        });\n+  }\n \n-    private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n-      }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportNextBatch(\n+      final List<ReadableSpan> spans, final int offset, final CompletableResultCode result) {\n+    int num = Math.min(maxExportBatchSize, spans.size() - offset);\n+    final int limit = offset + num;\n+    List<SpanData> forExport = new ArrayList<>(num);\n+    for (int i = offset; i < limit; i++) {\n+      forExport.add(spans.get(i).toSpanData());\n     }", "originalCommit": "141c05e131c281fceb6c7a17dd17260ceb0db64a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM1OTY1Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475359653", "bodyText": "TBH I've never compared performance of preallocated ArrayList with .add vs allocating an array and using Arrays.asList. I'll need to write a JMH to confirm the difference, since i doesn't start at 0 there is some extra cognitive load so I'd like to try that after confirming the perf difference.", "author": "anuraaga", "createdAt": "2020-08-24T06:01:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM0ODYzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTcyODI1MQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475728251", "bodyText": "It feels like there should be a way to compose the things in here more elegantly, but it could be done as a follow-on PR.", "author": "jkwatson", "createdAt": "2020-08-24T16:10:24Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -131,181 +164,160 @@ public boolean isEndRequired() {\n   }\n \n   @Override\n-  public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n-  }\n+  public CompletableResultCode shutdown() {\n+    closed = true;\n+    nextExport.cancel(false);\n+\n+    final CompletableResultCode result = new CompletableResultCode();\n+    final CompletableResultCode flushResult = forceFlush();", "originalCommit": "141c05e131c281fceb6c7a17dd17260ceb0db64a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkyNjUzMA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475926530", "bodyText": "Lambdas ;-)", "author": "huntc", "createdAt": "2020-08-24T22:20:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTcyODI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTczOTA1NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475739054", "bodyText": "maybe numberToExport, rather than just num?", "author": "jkwatson", "createdAt": "2020-08-24T16:27:57Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -131,181 +164,160 @@ public boolean isEndRequired() {\n   }\n \n   @Override\n-  public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n-  }\n+  public CompletableResultCode shutdown() {\n+    closed = true;\n+    nextExport.cancel(false);\n+\n+    final CompletableResultCode result = new CompletableResultCode();\n+    final CompletableResultCode flushResult = forceFlush();\n+    flushResult.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            executor.shutdown();\n+            final CompletableResultCode shutdownResult = spanExporter.shutdown();\n+            shutdownResult.whenComplete(\n+                new Runnable() {\n+                  @Override\n+                  public void run() {\n+                    if (!flushResult.isSuccess() || !shutdownResult.isSuccess()) {\n+                      result.fail();\n+                    } else {\n+                      result.succeed();\n+                    }\n+                  }\n+                });\n+          }\n+        });\n \n-  @Override\n-  public void forceFlush() {\n-    worker.forceFlush();\n+    return result;\n   }\n \n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  @Override\n+  public CompletableResultCode forceFlush() {\n+    if (queue.isEmpty()) {\n+      return CompletableResultCode.ofSuccess();\n     }\n+    final List<ReadableSpan> spans = new ArrayList<>(queue.size());\n+    queue.drainTo(spans);\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportNextBatch(spans, 0, result);\n+          }\n+        });\n+    return result;\n+  }\n \n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportSpans() {\n+    spanBuffer.clear();\n+    if (queue.drainTo(spanBuffer) == 0) {\n+      scheduleNextExport();\n+      return;\n     }\n \n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportNextBatch(spanBuffer, 0, result);\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n-    }\n+        });\n+\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (queue.size() >= maxExportBatchSize) {\n+              executor.submit(\n+                  new Runnable() {\n+                    @Override\n+                    public void run() {\n+                      exportSpans();\n+                    }\n+                  });\n+            } else {\n+              scheduleNextExport();\n+            }\n+          }\n+        });\n+  }\n \n-    private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n-      }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportNextBatch(\n+      final List<ReadableSpan> spans, final int offset, final CompletableResultCode result) {\n+    int num = Math.min(maxExportBatchSize, spans.size() - offset);", "originalCommit": "141c05e131c281fceb6c7a17dd17260ceb0db64a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc0OTUzMw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1571#discussion_r475749533", "bodyText": "What do you think about putting this inside the try block? Seems like it might read a little more cleanly not to have to pre-declare the exportResult.", "author": "jkwatson", "createdAt": "2020-08-24T16:41:11Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -131,181 +164,160 @@ public boolean isEndRequired() {\n   }\n \n   @Override\n-  public void shutdown() {\n-    workerThread.interrupt();\n-    worker.shutdown();\n-  }\n+  public CompletableResultCode shutdown() {\n+    closed = true;\n+    nextExport.cancel(false);\n+\n+    final CompletableResultCode result = new CompletableResultCode();\n+    final CompletableResultCode flushResult = forceFlush();\n+    flushResult.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            executor.shutdown();\n+            final CompletableResultCode shutdownResult = spanExporter.shutdown();\n+            shutdownResult.whenComplete(\n+                new Runnable() {\n+                  @Override\n+                  public void run() {\n+                    if (!flushResult.isSuccess() || !shutdownResult.isSuccess()) {\n+                      result.fail();\n+                    } else {\n+                      result.succeed();\n+                    }\n+                  }\n+                });\n+          }\n+        });\n \n-  @Override\n-  public void forceFlush() {\n-    worker.forceFlush();\n+    return result;\n   }\n \n-  // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n-  // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n-  private static final class Worker implements Runnable {\n-\n-    static {\n-      Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n-          meter\n-              .longCounterBuilder(\"droppedSpans\")\n-              .setUnit(\"1\")\n-              .setDescription(\n-                  \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")\n-              .build();\n-      droppedSpans =\n-          droppedSpansCounter.bind(\n-              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n-    }\n-\n-    private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n-    private static final Logger logger = Logger.getLogger(Worker.class.getName());\n-    private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n-    private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n-    private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n-\n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n-\n-    private Worker(\n-        SpanExporter spanExporter,\n-        long scheduleDelayMillis,\n-        int maxQueueSize,\n-        int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n-      this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n-      this.maxExportBatchSize = maxExportBatchSize;\n-      this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  @Override\n+  public CompletableResultCode forceFlush() {\n+    if (queue.isEmpty()) {\n+      return CompletableResultCode.ofSuccess();\n     }\n+    final List<ReadableSpan> spans = new ArrayList<>(queue.size());\n+    queue.drainTo(spans);\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportNextBatch(spans, 0, result);\n+          }\n+        });\n+    return result;\n+  }\n \n-    private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n-      }\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportSpans() {\n+    spanBuffer.clear();\n+    if (queue.drainTo(spanBuffer) == 0) {\n+      scheduleNextExport();\n+      return;\n     }\n \n-    @Override\n-    public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+    final CompletableResultCode result = new CompletableResultCode();\n+    executor.submit(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            exportNextBatch(spanBuffer, 0, result);\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n-        }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n-      }\n-    }\n-\n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n-    }\n+        });\n+\n+    result.whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            if (queue.size() >= maxExportBatchSize) {\n+              executor.submit(\n+                  new Runnable() {\n+                    @Override\n+                    public void run() {\n+                      exportSpans();\n+                    }\n+                  });\n+            } else {\n+              scheduleNextExport();\n+            }\n+          }\n+        });\n+  }\n \n-    private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n-      }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n+  @SuppressWarnings(\"FutureReturnValueIgnored\")\n+  private void exportNextBatch(\n+      final List<ReadableSpan> spans, final int offset, final CompletableResultCode result) {\n+    int num = Math.min(maxExportBatchSize, spans.size() - offset);\n+    final int limit = offset + num;\n+    List<SpanData> forExport = new ArrayList<>(num);\n+    for (int i = offset; i < limit; i++) {\n+      forExport.add(spans.get(i).toSpanData());\n     }\n-\n-    private void exportBatches(ArrayList<ReadableSpan> spanList) {\n-      // TODO: Record a counter for pushed spans.\n-      for (int i = 0; i < spanList.size(); ) {\n-        int lastIndexToTake = Math.min(i + maxExportBatchSize, spanList.size());\n-        onBatchExport(createSpanDataForExport(spanList, i, lastIndexToTake));\n-        i = lastIndexToTake;\n-      }\n+    final CompletableResultCode exportResult;\n+    try {\n+      exportResult = spanExporter.export(forExport);\n+    } catch (Exception e) {\n+      logger.log(Level.FINE, \"Exporter failed\", e);\n+      maybeContinueBatch(spans, limit, result);\n+      return;\n     }\n+    exportResult.whenComplete(", "originalCommit": "141c05e131c281fceb6c7a17dd17260ceb0db64a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "35c74d38d9001dc0d3ccaf32f06a18917b9ba4c4", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/35c74d38d9001dc0d3ccaf32f06a18917b9ba4c4", "message": "Make sure forceFlush / shutdown can have callers wait for them to be done by returning CompletableResultCode.", "committedDate": "2020-08-27T06:28:32Z", "type": "commit"}, {"oid": "ee3b5ee157a5340c61cb00c4e291d77a5341c43d", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/ee3b5ee157a5340c61cb00c4e291d77a5341c43d", "message": "Merge branch 'master' of github.com:open-telemetry/opentelemetry-java into simplify-batch-span-processor", "committedDate": "2020-08-27T06:42:39Z", "type": "commit"}, {"oid": "555df8b12e059c23e6ae87495668cc2dd5efe1e6", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/555df8b12e059c23e6ae87495668cc2dd5efe1e6", "message": "Merge", "committedDate": "2020-08-27T06:52:28Z", "type": "commit"}, {"oid": "555df8b12e059c23e6ae87495668cc2dd5efe1e6", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/555df8b12e059c23e6ae87495668cc2dd5efe1e6", "message": "Merge", "committedDate": "2020-08-27T06:52:28Z", "type": "forcePushed"}, {"oid": "6e3e2ba3e697d1a2cdc5066953520befc76efc59", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/6e3e2ba3e697d1a2cdc5066953520befc76efc59", "message": "Merge branch 'master' of github.com:open-telemetry/opentelemetry-java into simplify-batch-span-processor", "committedDate": "2020-08-28T09:36:23Z", "type": "commit"}]}