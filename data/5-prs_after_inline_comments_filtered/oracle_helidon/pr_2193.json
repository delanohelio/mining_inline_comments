{"pr_number": 2193, "pr_title": "Multipart decoder rework", "pr_createdAt": "2020-07-20T19:49:08Z", "pr_url": "https://github.com/oracle/helidon/pull/2193", "timeline": [{"oid": "869b894f491297361709c1a26e2b210b4077f519", "url": "https://github.com/oracle/helidon/commit/869b894f491297361709c1a26e2b210b4077f519", "message": "MultiPartDecoder implementation update (first pass)", "committedDate": "2020-07-17T00:01:59Z", "type": "commit"}, {"oid": "32cdc33907d7b65158cb9c44cacf34e6160aa357", "url": "https://github.com/oracle/helidon/commit/32cdc33907d7b65158cb9c44cacf34e6160aa357", "message": "Fix TCK tests", "committedDate": "2020-07-17T18:19:30Z", "type": "commit"}, {"oid": "0c778395f88b719ec14ae37e2fd831a92df1564a", "url": "https://github.com/oracle/helidon/commit/0c778395f88b719ec14ae37e2fd831a92df1564a", "message": "fix checkstyle", "committedDate": "2020-07-17T20:52:28Z", "type": "commit"}, {"oid": "493f515209f230b6d09a117df8aeb249fc8562d5", "url": "https://github.com/oracle/helidon/commit/493f515209f230b6d09a117df8aeb249fc8562d5", "message": "update internal doc", "committedDate": "2020-07-20T19:47:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODExOTc5Ng==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r458119796", "bodyText": "This is a ternary operator inside a lambda, so you may want to indent it a bit more", "author": "olotenko", "createdAt": "2020-07-21T14:00:36Z", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -102,11 +103,10 @@ public void subscribe(Subscriber<? super ReadableBodyPart> subscriber) {\n \n             @Override\n             public void request(long n) {\n-                long curr = n <= 0 ?\n-                        partsRequested.getAndSet(-1) :\n-                        partsRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n ? v + n\n-                                : v < 0 ? v\n-                                : Long.MAX_VALUE);\n+                long curr = n <= 0\n+                        ? partsRequested.getAndSet(-1)\n+                        : partsRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n\n+                        ? v + n : v < 0 ? v : Long.MAX_VALUE);", "originalCommit": "0c778395f88b719ec14ae37e2fd831a92df1564a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEyMDcyNg==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r458120726", "bodyText": "Ditto: maybe indent this ternary operator a bit more", "author": "olotenko", "createdAt": "2020-07-21T14:01:51Z", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -426,11 +425,10 @@ public void subscribe(Subscriber<? super DataChunk> sub) {\n                 public void request(long n) {\n                     // Illegal n makes chunksRequested negative, which interacts with drain() to drain the\n                     // entire bufferEntryIterator, and signal onError\n-                    long curr = n <= 0 ? chunksRequested.getAndSet(-1) :\n-                            chunksRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n ? v + n\n-                                    : v < 0 ? v == Long.MIN_VALUE ? n\n-                                    : v\n-                                    : Long.MAX_VALUE);\n+                    long curr = n <= 0\n+                            ? chunksRequested.getAndSet(-1)\n+                            : chunksRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n\n+                            ? v + n : v < 0 ? v == Long.MIN_VALUE ? n : v : Long.MAX_VALUE);", "originalCommit": "0c778395f88b719ec14ae37e2fd831a92df1564a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9", "url": "https://github.com/oracle/helidon/commit/642c2f25d7927a8e6977491cb54ec6fb1a3c39a9", "message": "improve indentation", "committedDate": "2020-07-21T17:21:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyODA1Ng==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460228056", "bodyText": "no need to remove this check, but FYI - the test will always pass for any conforming Publisher: they won't issue more than one of onError/onComplete.", "author": "olotenko", "createdAt": "2020-07-24T18:46:14Z", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {", "originalCommit": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI3ODI5OA==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460278298", "bodyText": "Actually, this is what needs doing: remove the check and the following line setting upstream = CANCELED;. Then the subtle race condition discussed in the comment to drainBoth will disappear: then observing upstream == CANCELED is possible only if onComplete has been observed, which is mutually exclusive with onError.\nAdd upstream = CANCELED; to cleanup.", "author": "olotenko", "createdAt": "2020-07-24T20:41:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyODA1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM3NzMzMg==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460377332", "bodyText": "Well, that won't work. The spec is very particular about not allowing synchronous cancellation, even though concurrent cancellation should be supported by upstream. It is not \"just adding a check\". It is about synchronizing on two variables instead of just one, and the explosion of possible outcomes to bear in mind when proving a correct order of statements.", "author": "olotenko", "createdAt": "2020-07-25T07:33:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyODA1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzMDEyNA==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460230124", "bodyText": "The bit masks shown here are not 100% accurate. The first time deferredInit is called the fourth bit may be set as 0b1111000..., 0b1011000... or 0b1101000.... That is, the first deferredInit is not necessarily after both onSubscribe and subscribe were called - so some of the bits may be zero.\nIt's a bit of a mouthful to explain fully, so maybe enough to refer to the .md file", "author": "olotenko", "createdAt": "2020-07-24T18:50:49Z", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain(throwable);\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set (0b11100000)\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit (0b11110000)\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits (0b00000000)", "originalCommit": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzNTExOA==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460235118", "bodyText": "I think these must be moved to line 289: the cleanup must occur asap. Also, add nulling out to cleanup. Although the objects are small, let's be very clean about the promise to not retain objects for longer than necessary.", "author": "olotenko", "createdAt": "2020-07-24T19:01:37Z", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain(throwable);\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set (0b11100000)\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit (0b11110000)\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits (0b00000000)\n+        // making the contenders counter 0,\n+        // unless there were onError, onComplete, request for parts or downstream cancellation\n+        if (contenders.addAndGet(SUBSCRIPTION_LOCK) > 0) {\n+            drainLoop();\n         }\n     }\n \n-    private void onPartRequest(long requested, long total) {\n-        // require more raw chunks to decode if the decoding has not\n-        // yet started or if more data is required to make progress\n-        if (!parserEventProcessor.isStarted() || parserEventProcessor.isDataRequired()) {\n-            upstream.request(1);\n-        }\n+    private long partsRequested() {\n+        // Returns a negative number, if we are serving outer Subscriber, and we can tell it may\n+        // not issue more requests for parts: either cancelled, or a bad request was observed.\n+        // Otherwise returns a positive number, if serving inner Subscriber, or actual partsRequested.\n+        return bodyPartPublisher != null ? 1 : partsRequested.get();\n     }\n \n-    private void onPartCancel() {\n-        emitter.clearBuffer(this::drainPart);\n+    private void cleanup() {\n+        // drop the reference to parserIterator, but keep it safe for any later invocation of parserIterator\n+        parserIterator = EMPTY_PARSER_ITERATOR;\n+        error = null;\n+        downstream = null; // after cleanup no uses of downstream are reachable\n+        cancelled = true; // after cleanup the processor appears as cancelled\n+        partsRequested.set(-1);\n         releaseChunks();\n+        parser.cleanup();\n     }\n \n-    private void releaseChunks() {\n-        Iterator<DataChunk> it = chunksByIds.values().iterator();\n-        while (it.hasNext()) {\n-            DataChunk next = it.next();\n-            next.release();\n-            it.remove();\n+    /**\n+     * Drain the upstream data if the contenders value is positive.\n+     */\n+    protected void drain() {\n+        // We do not serve the next part until the last chunk of the previous part has been consumed\n+        // (sent to inner Subscriber).\n+        // Signals to outer Subscriber are serialized with the signals to the inner Subscriber.\n+\n+        // drain() is a loop that retrieves ParserEvents one by one, and transitions to the next state,\n+        // unless waiting on the inner or outer subscriber.\n+\n+        // There are three ways to enter drain():\n+        // 1. We are not processing a part and an outer Subscriber has unsatisfied demand for parts\n+        // 2. We are processing a part and an inner Subscriber has unsatisfied demand for chunks of a part\n+        // 3. Upstream is delivering a DataChunk to satisfy the request from outer or inner Subscriber\n+        if (contenders.getAndIncrement() != 0) {\n+            return;\n         }\n+        drainLoop();\n     }\n \n-    private void drainPart(ReadableBodyPart part) {\n-        part.content().subscribe(new Subscriber<DataChunk>() {\n-            @Override\n-            public void onSubscribe(Subscription subscription) {\n-                subscription.request(Long.MAX_VALUE);\n+    /**\n+     * Drain the upstream data in a loop while the contenders value is positive.\n+     */\n+    protected void drainLoop() {\n+        for (int c = 1; c > 0; c = contenders.addAndGet(-c)) {\n+            drainBoth();\n+        }\n+    }\n+\n+    /**\n+     * Drain the upstream data and signal the given error.\n+     *\n+     * @param th the error to signal\n+     */\n+    protected void drain(Throwable th) {\n+        error = th;\n+        drain();\n+    }\n+\n+    /**\n+     * Drain upstream (raw) data and decoded downstream data.\n+     */\n+    protected void drainBoth() {\n+        if (bodyPartPublisher != null && !bodyPartPublisher.drain()) {\n+            return;\n+        }\n+\n+        try {\n+            // Proceed to drain parserIterator only if parts or body part chunks were requested\n+            // ie. bodyPartPublisher != null && partsRequested > 0\n+            // if bodyPartPublisher != null, then we are here when inner Subscriber has unsatisfied demand\n+            long requested = partsRequested();\n+            while (requested >= 0 && parserIterator.hasNext()) {\n+                // It is safe to consume next ParserEvent only the right Subscriber is ready to receive onNext\n+                // i.e partsRequested > 0\n+                if (requested == 0) {\n+                    // This means there was an attempt to deliver onError or onComplete from upstream\n+                    // which are allowed to be issued without request from outer Subscriber.\n+                    // - partsRequested > 0 for valid requests\n+                    // - partsRequested < 0 cancellation or invalid request\n+                    // we wait until demand has been manifested and parserIterator is drained\n+                    return;\n+                }\n+\n+                MimeParser.ParserEvent event = parserIterator.next();\n+                switch (event.type()) {\n+                    case START_PART:\n+                        bodyPartHeaderBuilder = ReadableBodyPartHeaders.builder();\n+                        bodyPartBuilder = ReadableBodyPart.builder();\n+                        break;\n+                    case HEADER:\n+                        MimeParser.HeaderEvent headerEvent = event.asHeaderEvent();\n+                        bodyPartHeaderBuilder.header(headerEvent.name(), headerEvent.value());\n+                        break;\n+                    case END_HEADERS:\n+                        bodyPartPublisher = new DataChunkPublisher();\n+                        downstream.onNext(createPart());\n+                        // exit the parser iterator loop\n+                        // the parser events processing will resume upon inner Subscriber demand\n+                        return;\n+                    case BODY:\n+                        Iterator<BufferEntry> bodyIterator = event.asBodyEvent().body().iterator();\n+                        bodyPartPublisher.nextIterator(bodyIterator);\n+                        if (!bodyPartPublisher.drain()) {\n+                            // the body was not fully drained, exit the parser iterator loop\n+                            // the parser events processing will resume upon inner Subscriber demand\n+                            return;\n+                        }\n+                        break;\n+                    case END_PART:\n+                        bodyPartPublisher.complete(null);\n+                        bodyPartHeaderBuilder = null;\n+                        bodyPartBuilder = null;", "originalCommit": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzOTA1MA==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460239050", "bodyText": "There is a subtle race condition here. I'll propose a fix later.\n(In essence, Dekker idiom is needed - onError concurrent with drainBoth executed by, say, request - may set CANCELED before error, so drainBoth may see error is null, but after reaching this line also see CANCELED, and deliver onComplete)", "author": "olotenko", "createdAt": "2020-07-24T19:10:20Z", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain(throwable);\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set (0b11100000)\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit (0b11110000)\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits (0b00000000)\n+        // making the contenders counter 0,\n+        // unless there were onError, onComplete, request for parts or downstream cancellation\n+        if (contenders.addAndGet(SUBSCRIPTION_LOCK) > 0) {\n+            drainLoop();\n         }\n     }\n \n-    private void onPartRequest(long requested, long total) {\n-        // require more raw chunks to decode if the decoding has not\n-        // yet started or if more data is required to make progress\n-        if (!parserEventProcessor.isStarted() || parserEventProcessor.isDataRequired()) {\n-            upstream.request(1);\n-        }\n+    private long partsRequested() {\n+        // Returns a negative number, if we are serving outer Subscriber, and we can tell it may\n+        // not issue more requests for parts: either cancelled, or a bad request was observed.\n+        // Otherwise returns a positive number, if serving inner Subscriber, or actual partsRequested.\n+        return bodyPartPublisher != null ? 1 : partsRequested.get();\n     }\n \n-    private void onPartCancel() {\n-        emitter.clearBuffer(this::drainPart);\n+    private void cleanup() {\n+        // drop the reference to parserIterator, but keep it safe for any later invocation of parserIterator\n+        parserIterator = EMPTY_PARSER_ITERATOR;\n+        error = null;\n+        downstream = null; // after cleanup no uses of downstream are reachable\n+        cancelled = true; // after cleanup the processor appears as cancelled\n+        partsRequested.set(-1);\n         releaseChunks();\n+        parser.cleanup();\n     }\n \n-    private void releaseChunks() {\n-        Iterator<DataChunk> it = chunksByIds.values().iterator();\n-        while (it.hasNext()) {\n-            DataChunk next = it.next();\n-            next.release();\n-            it.remove();\n+    /**\n+     * Drain the upstream data if the contenders value is positive.\n+     */\n+    protected void drain() {\n+        // We do not serve the next part until the last chunk of the previous part has been consumed\n+        // (sent to inner Subscriber).\n+        // Signals to outer Subscriber are serialized with the signals to the inner Subscriber.\n+\n+        // drain() is a loop that retrieves ParserEvents one by one, and transitions to the next state,\n+        // unless waiting on the inner or outer subscriber.\n+\n+        // There are three ways to enter drain():\n+        // 1. We are not processing a part and an outer Subscriber has unsatisfied demand for parts\n+        // 2. We are processing a part and an inner Subscriber has unsatisfied demand for chunks of a part\n+        // 3. Upstream is delivering a DataChunk to satisfy the request from outer or inner Subscriber\n+        if (contenders.getAndIncrement() != 0) {\n+            return;\n         }\n+        drainLoop();\n     }\n \n-    private void drainPart(ReadableBodyPart part) {\n-        part.content().subscribe(new Subscriber<DataChunk>() {\n-            @Override\n-            public void onSubscribe(Subscription subscription) {\n-                subscription.request(Long.MAX_VALUE);\n+    /**\n+     * Drain the upstream data in a loop while the contenders value is positive.\n+     */\n+    protected void drainLoop() {\n+        for (int c = 1; c > 0; c = contenders.addAndGet(-c)) {\n+            drainBoth();\n+        }\n+    }\n+\n+    /**\n+     * Drain the upstream data and signal the given error.\n+     *\n+     * @param th the error to signal\n+     */\n+    protected void drain(Throwable th) {\n+        error = th;\n+        drain();\n+    }\n+\n+    /**\n+     * Drain upstream (raw) data and decoded downstream data.\n+     */\n+    protected void drainBoth() {\n+        if (bodyPartPublisher != null && !bodyPartPublisher.drain()) {\n+            return;\n+        }\n+\n+        try {\n+            // Proceed to drain parserIterator only if parts or body part chunks were requested\n+            // ie. bodyPartPublisher != null && partsRequested > 0\n+            // if bodyPartPublisher != null, then we are here when inner Subscriber has unsatisfied demand\n+            long requested = partsRequested();\n+            while (requested >= 0 && parserIterator.hasNext()) {\n+                // It is safe to consume next ParserEvent only the right Subscriber is ready to receive onNext\n+                // i.e partsRequested > 0\n+                if (requested == 0) {\n+                    // This means there was an attempt to deliver onError or onComplete from upstream\n+                    // which are allowed to be issued without request from outer Subscriber.\n+                    // - partsRequested > 0 for valid requests\n+                    // - partsRequested < 0 cancellation or invalid request\n+                    // we wait until demand has been manifested and parserIterator is drained\n+                    return;\n+                }\n+\n+                MimeParser.ParserEvent event = parserIterator.next();\n+                switch (event.type()) {\n+                    case START_PART:\n+                        bodyPartHeaderBuilder = ReadableBodyPartHeaders.builder();\n+                        bodyPartBuilder = ReadableBodyPart.builder();\n+                        break;\n+                    case HEADER:\n+                        MimeParser.HeaderEvent headerEvent = event.asHeaderEvent();\n+                        bodyPartHeaderBuilder.header(headerEvent.name(), headerEvent.value());\n+                        break;\n+                    case END_HEADERS:\n+                        bodyPartPublisher = new DataChunkPublisher();\n+                        downstream.onNext(createPart());\n+                        // exit the parser iterator loop\n+                        // the parser events processing will resume upon inner Subscriber demand\n+                        return;\n+                    case BODY:\n+                        Iterator<BufferEntry> bodyIterator = event.asBodyEvent().body().iterator();\n+                        bodyPartPublisher.nextIterator(bodyIterator);\n+                        if (!bodyPartPublisher.drain()) {\n+                            // the body was not fully drained, exit the parser iterator loop\n+                            // the parser events processing will resume upon inner Subscriber demand\n+                            return;\n+                        }\n+                        break;\n+                    case END_PART:\n+                        bodyPartPublisher.complete(null);\n+                        bodyPartHeaderBuilder = null;\n+                        bodyPartBuilder = null;\n+                        bodyPartPublisher = null;\n+                        requested = partsRequested.updateAndGet(v -> v == Long.MAX_VALUE || v < 0 ? v : v - 1);\n+                        break;\n+                    default:\n+                }\n             }\n \n-            @Override\n-            public void onNext(DataChunk item) {\n-                item.release();\n+            // we allow requested <= 0 to reach here, because we want to allow delivery of termination signals\n+            // without requests or cancellations, but ultimately need to make sure we do not request from\n+            // upstream, unless actual demand is observed (requested > 0)\n+            if (requested < 0) {\n+                if (cancelled) {\n+                    upstream.cancel();\n+                    cleanup();\n+                    return;\n+                }\n+                // now is the right time to convert a bad request into an error\n+                // bodyPartPublisher is null, so this error gets delivered only to outer Subscriber\n+                error = new IllegalArgumentException(\"Expecting only positive requests for parts\");\n             }\n \n-            @Override\n-            public void onError(Throwable throwable) {\n+            // ordering the delivery of errors after the delivery of all signals that precede it\n+            // in the order of events emitted by the parser\n+            if (error != null) {\n+                if (bodyPartPublisher != null) {\n+                    bodyPartPublisher.complete(error);\n+                    bodyPartPublisher = null;\n+                }\n+                upstream.cancel();\n+                downstream.onError(error);\n+                cleanup();\n+                return;\n             }\n \n-            @Override\n-            public void onComplete() {\n+            // parserIterator is drained, drop the reference to it, but keep it safe for any later invocations\n+            parserIterator = EMPTY_PARSER_ITERATOR;\n+            if (upstream == SubscriptionHelper.CANCELED) {", "originalCommit": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI3ODYyNQ==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460278625", "bodyText": "(With the change so that onError does not set upstream = CANCELED; the race condition disappears)", "author": "olotenko", "createdAt": "2020-07-24T20:42:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzOTA1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI0MzA3Nw==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460243077", "bodyText": "Move to line 471 and change the condition to:\nif (chunksRequested.get() < 0 && !cancelled && th == null) {\n   th = new IllegalArgumentException(\"Expecting only positive requests for content\");\n}\n\n(Because currently a cancel concurrent with complete will not be distinguishable from bad request)", "author": "olotenko", "createdAt": "2020-07-24T19:19:34Z", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -247,85 +392,148 @@ private BodyPartChunk createPartChunk(BufferEntry entry) {\n             throw new IllegalStateException(\"Parent chunk not found, id=\" + id);\n         }\n         ByteBuffer[] originalBuffers = chunk.data();\n+        // FIXME: the current resource management is not implemented properly and needs to be fixed\n         boolean release = data.limit() == originalBuffers[originalBuffers.length - 1].limit();\n         if (release) {\n             chunksByIds.remove(id);\n         }\n         return new BodyPartChunk(data, release ? chunk : null);\n     }\n \n-    private final class ParserEventProcessor implements MimeParser.EventProcessor {\n+    /**\n+     * Inner publisher that publishes the body part as {@link DataChunk}.\n+     */\n+    protected final class DataChunkPublisher implements Publisher<DataChunk> {\n \n-        private MimeParser.ParserEvent lastEvent = null;\n+        private final AtomicLong chunksRequested = new AtomicLong(Long.MIN_VALUE + 1);\n+        private Iterator<BufferEntry> bufferEntryIterator = EMPTY_BUFFER_ENTRY_ITERATOR;\n+        private boolean cancelled;\n+        private Subscriber<? super DataChunk> subscriber;\n \n         @Override\n-        public void process(MimeParser.ParserEvent event) {\n-            MimeParser.EventType eventType = event.type();\n-            switch (eventType) {\n-                case START_PART:\n-                    bodyPartPublisher = BufferedEmittingPublisher.create();\n-                    bodyPartHeaderBuilder = ReadableBodyPartHeaders.builder();\n-                    bodyPartBuilder = ReadableBodyPart.builder();\n-                    break;\n-                case HEADER:\n-                    MimeParser.HeaderEvent headerEvent = event.asHeaderEvent();\n-                    bodyPartHeaderBuilder.header(headerEvent.name(), headerEvent.value());\n-                    break;\n-                case END_HEADERS:\n-                    bodyParts.add(createPart());\n-                    break;\n-                case CONTENT:\n-                    bodyPartPublisher.emit(createPartChunk(event.asContentEvent().content()));\n-                    break;\n-                case END_PART:\n-                    bodyPartPublisher.complete();\n-                    bodyPartPublisher = null;\n-                    bodyPartHeaderBuilder = null;\n-                    bodyPartBuilder = null;\n-                    break;\n-                default:\n-                // nothing to do\n+        public void subscribe(Subscriber<? super DataChunk> sub) {\n+            if (!chunksRequested.compareAndSet(Long.MIN_VALUE + 1, Long.MIN_VALUE)) {\n+                Multi.<DataChunk>error(new IllegalStateException(\"Only one Subscriber allowed\"))\n+                     .subscribe(subscriber);\n+                return;\n+            }\n+\n+            subscriber = sub;\n+            sub.onSubscribe(new Subscription() {\n+\n+                @Override\n+                public void request(long n) {\n+                    // Illegal n makes chunksRequested negative, which interacts with drain() to drain the\n+                    // entire bufferEntryIterator, and signal onError\n+                    long curr = n <= 0\n+                                ? chunksRequested.getAndSet(-1)\n+                                : chunksRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n\n+                                ? v + n : v < 0 ? v == Long.MIN_VALUE ? n : v : Long.MAX_VALUE);\n+                    if (curr == 0) {\n+                        MultiPartDecoder.this.drain();\n+                    }\n+                }\n+\n+                @Override\n+                public void cancel() {\n+                    cancelled = true;\n+                    // Ensure the part chunks are drained to make the next part available\n+                    if (chunksRequested.getAndSet(-1) == 0) {\n+                        MultiPartDecoder.this.drain();\n+                    }\n+                }\n+            });\n+\n+            if (chunksRequested.compareAndSet(Long.MIN_VALUE, 0)) {\n+                return;\n             }\n-            lastEvent = event;\n+            MultiPartDecoder.this.drain();\n         }\n \n         /**\n-         * Indicate if the parser has received any data.\n-         *\n-         * @return {@code true} if the parser has been offered data,\n-         * {@code false} otherwise\n+         * Set the next buffer entry iterator.\n+         * @param iterator the iterator to set\n          */\n-        boolean isStarted() {\n-            return lastEvent != null;\n+        void nextIterator(Iterator<BufferEntry> iterator) {\n+            // This is invoked only when the previous bufferEntryIterator has been consumed fully,\n+            // and chunksRequested > 0, so no one is calling drain() concurrently\n+            // chunksRequested is modified atomically, so any future invocation of drain() will observe\n+            // bufferEntryIterator normal store (bufferEntryIterator and all of its content is published safely)\n+            bufferEntryIterator = iterator;\n         }\n \n         /**\n-         * Indicate if the parser has reached the end of the message.\n+         * Complete the publisher.\n          *\n-         * @return {@code true} if completed, {@code false} otherwise\n+         * @param th throwable, if not {@code null} signals {@code onError}, otherwise signals {@code onComplete}\n          */\n-        boolean isCompleted() {\n-            return lastEvent.type() == MimeParser.EventType.END_MESSAGE;\n+        void complete(Throwable th) {\n+            if (cancelled) {\n+                subscriber = null;\n+                return;\n+            }\n+            cancelled = true;\n+\n+            // bufferEntryIterator is drained because complete() is invoked only by drain() which proceeds past\n+            // state == BODY only when drain() returned true\n+            if (th != null) {\n+                subscriber.onError(th);\n+            } else if (chunksRequested.get() < 0) {\n+                subscriber.onError(new IllegalArgumentException(\"Expecting only positive requests\"));", "originalCommit": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "dc654b46f20c79c597086f58ac9859a3fd2bfdc3", "url": "https://github.com/oracle/helidon/commit/dc654b46f20c79c597086f58ac9859a3fd2bfdc3", "message": "Fix issue with distinguishing a concurrent onError signal from a concurrent onComplete.", "committedDate": "2020-07-27T21:09:19Z", "type": "commit"}, {"oid": "b1248af3d1283bcc327e823861e1e4ed6bb886d6", "url": "https://github.com/oracle/helidon/commit/b1248af3d1283bcc327e823861e1e4ed6bb886d6", "message": "Incorporate review feedback", "committedDate": "2020-07-27T21:26:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQ4NDkwNQ==", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r461484905", "bodyText": "I apologise I didn't make the comment\n\nAdd upstream = CANCELED; to cleanup\n\nclearer and forgot to add it in the onError synchronization fixup.\nPlease, add upstream = CANCELED somewhere here to drop references to upstream.", "author": "olotenko", "createdAt": "2020-07-28T10:38:25Z", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,231 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        error = throwable;\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits\n+        // making the contenders counter 0,\n+        // unless there were onError, onComplete, request for parts or downstream cancellation\n+        if (contenders.addAndGet(SUBSCRIPTION_LOCK) > 0) {\n+            drainLoop();\n         }\n     }\n \n-    private void onPartRequest(long requested, long total) {\n-        // require more raw chunks to decode if the decoding has not\n-        // yet started or if more data is required to make progress\n-        if (!parserEventProcessor.isStarted() || parserEventProcessor.isDataRequired()) {\n-            upstream.request(1);\n-        }\n+    private long partsRequested() {\n+        // Returns a negative number, if we are serving outer Subscriber, and we can tell it may\n+        // not issue more requests for parts: either cancelled, or a bad request was observed.\n+        // Otherwise returns a positive number, if serving inner Subscriber, or actual partsRequested.\n+        return bodyPartPublisher != null ? 1 : partsRequested.get();\n     }\n \n-    private void onPartCancel() {\n-        emitter.clearBuffer(this::drainPart);\n+    private void cleanup() {\n+        // drop the reference to parserIterator, but keep it safe for any later invocation of parserIterator\n+        parserIterator = EMPTY_PARSER_ITERATOR;\n+        error = null;", "originalCommit": "b1248af3d1283bcc327e823861e1e4ed6bb886d6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a14aa8048a49bba194033e27964dd04afb9c81f9", "url": "https://github.com/oracle/helidon/commit/a14aa8048a49bba194033e27964dd04afb9c81f9", "message": "add upstream = CANCELED to cleanup()", "committedDate": "2020-07-28T17:13:43Z", "type": "commit"}]}