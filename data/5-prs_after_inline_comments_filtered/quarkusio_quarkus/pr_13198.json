{"pr_number": 13198, "pr_title": "Expose metrics for kafka-streams with Micrometer", "pr_createdAt": "2020-11-09T20:56:10Z", "pr_url": "https://github.com/quarkusio/quarkus/pull/13198", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE3ODA1Nw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520178057", "bodyText": "In thinking about this -- these (the new BooleanSupplier and BuildStep) can be placed into the existing Kafka processor to keep things together..", "author": "ebullient", "createdAt": "2020-11-09T23:06:05Z", "path": "extensions/micrometer/deployment/src/main/java/io/quarkus/micrometer/deployment/binder/KafkaStreamsBinderProcessor.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package io.quarkus.micrometer.deployment.binder;\n+\n+import java.util.function.BooleanSupplier;\n+\n+import io.quarkus.arc.deployment.AdditionalBeanBuildItem;\n+import io.quarkus.deployment.annotations.BuildStep;\n+import io.quarkus.micrometer.runtime.MicrometerRecorder;\n+import io.quarkus.micrometer.runtime.config.MicrometerConfig;\n+\n+public class KafkaStreamsBinderProcessor {\n+\n+    static final String KAFKA_STREAMS_CLASS_NAME = \"org.apache.kafka.streams.KafkaStreams\";\n+    static final Class<?> KAFKA_STREAMS_CLASS_CLASS = MicrometerRecorder.getClassForName(KAFKA_STREAMS_CLASS_NAME);\n+\n+    static final String KAFKA_STREAMS_METRICS_PRODUCER_CLASS_NAME = \"io.quarkus.micrometer.runtime.binder.kafkastream.KafkaStreamsMetricsProducer\";\n+\n+    static class KafkaStreamsSupportEnabled implements BooleanSupplier {\n+        MicrometerConfig mConfig;\n+\n+        public boolean getAsBoolean() {\n+            return KAFKA_STREAMS_CLASS_CLASS != null && mConfig.checkBinderEnabledWithDefault(mConfig.binder.kafka);\n+        }\n+    }\n+\n+    @BuildStep(onlyIf = KafkaStreamsBinderProcessor.KafkaStreamsSupportEnabled.class)\n+    AdditionalBeanBuildItem createKafkaStreamsMetricsProducer() {\n+        return AdditionalBeanBuildItem.builder()\n+                .addBeanClass(KAFKA_STREAMS_METRICS_PRODUCER_CLASS_NAME)\n+                .setUnremovable().build();\n+    }\n+\n+}", "originalCommit": "905140c6c1c16ba155c7202e870827f07c0aae76", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIwNTg1Ng==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520205856", "bodyText": "Yes, that makes sense. I will move this BuildItem.", "author": "vonatzigenc", "createdAt": "2020-11-10T00:22:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE3ODA1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIyOTE4OA==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520229188", "bodyText": "After looking at the logic a bit, I am not sure if this should be combined.\nYes, both deal with Kafka, but the Kafka classes come from two different dependencies (org.apache.kafka:kafka-clients and org.apache.kafka:kafka-streams)\nThis must be taken into account especially by the producer.", "author": "vonatzigenc", "createdAt": "2020-11-10T01:32:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE3ODA1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIzNTg5Mw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520235893", "bodyText": "I meant only to put them all in the same file given they are coming from the same general config (measure kafka or not).\nPreserve the test for unique class given the different dependency (e.g. preserve unique BooleanSupplier)\nThe Boolean supplier and BuildStep method are already uniquely named for Streams..", "author": "ebullient", "createdAt": "2020-11-10T01:55:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE3ODA1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxNjEzMQ==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520916131", "bodyText": "I moved  BooleanSupplier and BuildStep into the KafkaBinderProcessor", "author": "vonatzigenc", "createdAt": "2020-11-10T22:31:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE3ODA1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE3ODI0Ng==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520178246", "bodyText": "Thank you for the test! =)", "author": "ebullient", "createdAt": "2020-11-09T23:06:36Z", "path": "extensions/micrometer/deployment/src/test/java/io/quarkus/micrometer/deployment/binder/KafkaStreamsMetricsDisabledTest.java", "diffHunk": "@@ -0,0 +1,35 @@\n+package io.quarkus.micrometer.deployment.binder;\n+\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+import javax.enterprise.inject.Instance;\n+import javax.inject.Inject;\n+\n+import org.jboss.shrinkwrap.api.ShrinkWrap;\n+import org.jboss.shrinkwrap.api.spec.JavaArchive;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.RegisterExtension;\n+\n+import io.quarkus.micrometer.runtime.binder.kafkastream.KafkaStreamsMetricsProducer;\n+import io.quarkus.test.QuarkusUnitTest;\n+\n+public class KafkaStreamsMetricsDisabledTest {\n+\n+    @RegisterExtension\n+    static final QuarkusUnitTest config = new QuarkusUnitTest()\n+            .withConfigurationResource(\"test-logging.properties\")\n+            .overrideConfigKey(\"quarkus.micrometer.binder.kafka.enabled\", \"true\")\n+            .overrideConfigKey(\"quarkus.micrometer.binder-enabled-default\", \"false\")\n+            .overrideConfigKey(\"quarkus.micrometer.registry-enabled-default\", \"false\")\n+            .setArchiveProducer(() -> ShrinkWrap.create(JavaArchive.class));\n+\n+    @Inject\n+    Instance<KafkaStreamsMetricsProducer> instance;\n+\n+    @Test\n+    void testNoInstancePresentIfNoKafkaStreamsClass() {\n+        assertTrue(instance.isUnsatisfied(),\n+                \"No KafkaStreamsMetricsProducer expected, because we don't have dependency to kafka-streams\");\n+    }\n+\n+}", "originalCommit": "905140c6c1c16ba155c7202e870827f07c0aae76", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE3OTI4NA==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520179284", "bodyText": "Again, torn here on the package. ;) Can we keep all things Kafka in one package? The class name is descriptive..", "author": "ebullient", "createdAt": "2020-11-09T23:09:18Z", "path": "extensions/micrometer/runtime/src/main/java/io/quarkus/micrometer/runtime/binder/kafkastream/KafkaStreamsMetricsProducer.java", "diffHunk": "@@ -0,0 +1,41 @@\n+package io.quarkus.micrometer.runtime.binder.kafkastream;", "originalCommit": "905140c6c1c16ba155c7202e870827f07c0aae76", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NTgyNA==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520185824", "bodyText": "@Startup is also unnecessary, because the producer will be driven by MeterBinder discovery (which is essentially at startup).\nI worry a little bit about initialization dependencies.. as resolving the MeterBinder (which is what will trigger this bean to be produced) then requires kafka streams to be started/resolved, which should be fine, but..\nI wonder if we should do something a little more like what the rest of Kafka metrics is doing, so that you have this @Startup bean which waits for KafkaStreams to be created / injected into the constructor..\nWhen that happens, it registers Kafka metrics with the global meter registry.\nAnd then the onStop method is unchanged?", "author": "ebullient", "createdAt": "2020-11-09T23:26:33Z", "path": "extensions/micrometer/runtime/src/main/java/io/quarkus/micrometer/runtime/binder/kafkastream/KafkaStreamsMetricsProducer.java", "diffHunk": "@@ -0,0 +1,41 @@\n+package io.quarkus.micrometer.runtime.binder.kafkastream;\n+\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.event.Observes;\n+import javax.enterprise.inject.Instance;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import javax.inject.Singleton;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+import io.micrometer.core.instrument.binder.kafka.KafkaStreamsMetrics;\n+import io.quarkus.runtime.ShutdownEvent;\n+import io.quarkus.runtime.Startup;\n+\n+@ApplicationScoped\n+public class KafkaStreamsMetricsProducer {\n+\n+    KafkaStreamsMetrics kafkaStreamsMetrics;\n+\n+    @Inject\n+    public KafkaStreamsMetricsProducer(Instance<KafkaStreams> kafkaStreams) {\n+        if (!kafkaStreams.isUnsatisfied()) {\n+            kafkaStreamsMetrics = new KafkaStreamsMetrics(kafkaStreams.get());\n+        }\n+    }\n+\n+    @Produces\n+    @Singleton\n+    @Startup", "originalCommit": "905140c6c1c16ba155c7202e870827f07c0aae76", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIxNDQzMg==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520214432", "bodyText": "I will take a closer look at the producer of KafkaStreamsMetrics.\nBecause of the scheduler in KafkaMetric, the dependency on the state of KafkaStream should not be that delicate.\nBut I will see if I can find a more elegant solution.\nMaybe I can do the coupling similar to smallrye-reactive-messaging via a CDI event.\nBut kafkaStreams is created in the constructor and I don't know how well events work there. Tomorrow I will see if this works or if I see another possibility. Another possibility is to publish the event in @PostConstruct.\nKafkaStreams creation: \n  \n    \n      quarkus/extensions/kafka-streams/runtime/src/main/java/io/quarkus/kafka/streams/runtime/KafkaStreamsProducer.java\n    \n    \n        Lines 63 to 88\n      in\n      9d3ebaf\n    \n    \n    \n    \n\n        \n          \n           public KafkaStreamsProducer(KafkaStreamsSupport kafkaStreamsSupport, KafkaStreamsRuntimeConfig runtimeConfig, \n        \n\n        \n          \n                   Instance<Topology> topology, Instance<KafkaClientSupplier> kafkaClientSupplier, \n        \n\n        \n          \n                   Instance<StateListener> stateListener, Instance<StateRestoreListener> globalStateRestoreListener) { \n        \n\n        \n          \n               shutdown = false; \n        \n\n        \n          \n               // No producer for Topology -> nothing to do \n        \n\n        \n          \n               if (topology.isUnsatisfied()) { \n        \n\n        \n          \n                   LOGGER.debug(\"No Topology producer; Kafka Streams will not be started\"); \n        \n\n        \n          \n                   this.executorService = null; \n        \n\n        \n          \n                   this.kafkaStreams = null; \n        \n\n        \n          \n                   this.kafkaStreamsTopologyManager = null; \n        \n\n        \n          \n                   this.kafkaAdminClient = null; \n        \n\n        \n          \n                   return; \n        \n\n        \n          \n               } \n        \n\n        \n          \n            \n        \n\n        \n          \n               Properties buildTimeProperties = kafkaStreamsSupport.getProperties(); \n        \n\n        \n          \n            \n        \n\n        \n          \n               String bootstrapServersConfig = asString(runtimeConfig.bootstrapServers); \n        \n\n        \n          \n               Properties kafkaStreamsProperties = getStreamsProperties(buildTimeProperties, bootstrapServersConfig, runtimeConfig); \n        \n\n        \n          \n               this.kafkaAdminClient = Admin.create(getAdminClientConfig(kafkaStreamsProperties)); \n        \n\n        \n          \n            \n        \n\n        \n          \n               this.executorService = Executors.newSingleThreadExecutor(); \n        \n\n        \n          \n            \n        \n\n        \n          \n               this.kafkaStreams = initializeKafkaStreams(kafkaStreamsProperties, runtimeConfig, kafkaAdminClient, topology.get(), \n        \n\n        \n          \n                       kafkaClientSupplier, stateListener, globalStateRestoreListener, executorService); \n        \n\n        \n          \n               this.kafkaStreamsTopologyManager = new KafkaStreamsTopologyManager(kafkaAdminClient); \n        \n\n        \n          \n           }", "author": "vonatzigenc", "createdAt": "2020-11-10T00:49:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NTgyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxOTE1NQ==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r520919155", "bodyText": "I changed the logic and adapted it to the existing KafkaEventObserver. For this I had to make adjustments to io.quarkus.kafka.streams.runtime.KafkaStreamsProducer.\n@gunnarmorling can you also look at the changes? Not sure if I should publish the CDI event in the constructor or if the PostConstruct is ok.", "author": "vonatzigenc", "createdAt": "2020-11-10T22:38:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NTgyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAxMTEzNQ==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521011135", "bodyText": "Or @cescoffier  ?", "author": "ebullient", "createdAt": "2020-11-11T01:52:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NTgyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0MzAwNw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521643007", "bodyText": "I think the current approach is fine, firing that event from post-construct.", "author": "gunnarmorling", "createdAt": "2020-11-11T21:15:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NTgyNA=="}], "type": "inlineReview"}, {"oid": "1d392b5dfd222dd60cec0eb2d9a50a6ce7431aa7", "url": "https://github.com/quarkusio/quarkus/commit/1d392b5dfd222dd60cec0eb2d9a50a6ce7431aa7", "message": "Add producer for KafkaStreamsMetrics\n\nSigned-off-by: Christian von Atzigen <christian.vonatzigen@mobi.ch>", "committedDate": "2020-11-10T22:49:33Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwMjQ4Mw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521602483", "bodyText": "So a general question: do we want to have the knowledge about specific APIs like Kafka Streams within the Micrometer extension? I feel it might be better the other way around: pushing the registration of metrics into these modules themselves, as we do it also for Kafka Streams + Health. Not sure though whether there's anything speaking against this?", "author": "gunnarmorling", "createdAt": "2020-11-11T19:55:10Z", "path": "extensions/micrometer/deployment/src/main/java/io/quarkus/micrometer/deployment/binder/KafkaBinderProcessor.java", "diffHunk": "@@ -8,16 +8,21 @@\n import io.quarkus.micrometer.runtime.config.MicrometerConfig;\n \n /**\n- * Add support for Kafka Producer and Consumer instrumentation. Note that\n+ * Add support for Kafka Producer, Consumer and Streams instrumentation. Note that\n  * various bits of support may not be present at deploy time. Avoid referencing\n  * classes that in turn import optional dependencies.\n  */\n public class KafkaBinderProcessor {\n     static final String KAFKA_CONSUMER_CLASS_NAME = \"org.apache.kafka.clients.consumer.Consumer\";\n     static final Class<?> KAFKA_CONSUMER_CLASS_CLASS = MicrometerRecorder.getClassForName(KAFKA_CONSUMER_CLASS_NAME);\n \n+    static final String KAFKA_STREAMS_CLASS_NAME = \"org.apache.kafka.streams.KafkaStreams\";", "originalCommit": "1d392b5dfd222dd60cec0eb2d9a50a6ce7431aa7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxMDEzNA==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521610134", "bodyText": "This isn't knowledge about the API so much as it is a \"is this enabled\" so it can happen automatically. Because we're using OOTB Micrometer-defined meter binders...\nThere is definitely a tug of war here, and it could go either way. The way we managed it for kafka generally is that the micrometer extension knows about the binders, and knows enough to turn them on when a marker class is present (it could be any class.. as long as it is something unique to that dependency).", "author": "ebullient", "createdAt": "2020-11-11T20:10:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwMjQ4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxMjE1Nw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521612157", "bodyText": "For myself, I prefer to see a more of the metrics behavior stay with the metrics extension (as it tends to act as a unit with consistent configuration behavior).. Having metrics spread out all over everywhere I find bothersome, especially as the footprint can be kept to a minimum, and the dependencies are not transitive.", "author": "ebullient", "createdAt": "2020-11-11T20:14:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwMjQ4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNTE1Mg==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521615152", "bodyText": "I see, and as you say there's reasons for both ways.\nI think I'm leaning towards KS -> Metrics/Health as it's done like that for Health already, and it's inline with the open/closed principle which I generally favour: when adding new \"business\" extensions like Kafka Streams, you don't need to \"register\" them in the (cross-cutting concern) Metrics extension, but you can do everything via build items in that extension itself. Same would go for external extensions we don't have any knowledge about at all.", "author": "gunnarmorling", "createdAt": "2020-11-11T20:19:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwMjQ4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNzk2NA==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521617964", "bodyText": "it's less \"registering\" and more \"understanding that micrometer has a meter binder that you should enable\". The way we're doing this (for kafka producer/consumer as well) allows kafka to emit CDI events for \"the thing to be monitored\". The micrometer extension (or maybe some other someday) understands those events and sets up the right binder in response to start (or stop) measuring. Clement and I both thought that kept things very clean between the two.", "author": "ebullient", "createdAt": "2020-11-11T20:25:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwMjQ4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYzODMwNA==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521638304", "bodyText": "Ok, going to resolve this one after quick discussio with @ebullient. We can go with this and always revisit later on if needed.", "author": "gunnarmorling", "createdAt": "2020-11-11T21:06:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwMjQ4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYzODYwMw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521638603", "bodyText": "Gasp, seems I lack rights to resolve? In any case, it is, from my PoV.", "author": "gunnarmorling", "createdAt": "2020-11-11T21:06:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwMjQ4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwNDE0Nw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521604147", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * This observer uses only classes from \"kafka-clients\" and none from \"kafka-streams\n          \n          \n            \n             * This observer uses only classes from \"kafka-clients\" and none from \"kafka-streams\".", "author": "gunnarmorling", "createdAt": "2020-11-11T19:58:24Z", "path": "extensions/micrometer/runtime/src/main/java/io/quarkus/micrometer/runtime/binder/kafka/KafkaEventObserver.java", "diffHunk": "@@ -13,7 +13,17 @@\n import io.micrometer.core.instrument.MeterRegistry;\n import io.micrometer.core.instrument.Metrics;\n import io.micrometer.core.instrument.binder.kafka.KafkaClientMetrics;\n+import io.quarkus.runtime.ShutdownEvent;\n \n+/**\n+ * Observer to create and register KafkaClientMetrics.\n+ *\n+ * This observer uses only classes from \"kafka-clients\" and none from \"kafka-streams", "originalCommit": "1d392b5dfd222dd60cec0eb2d9a50a6ce7431aa7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwNDg1MA==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521604850", "bodyText": "Can be final?", "author": "gunnarmorling", "createdAt": "2020-11-11T19:59:43Z", "path": "extensions/micrometer/runtime/src/main/java/io/quarkus/micrometer/runtime/binder/kafka/KafkaStreamsEventObserver.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package io.quarkus.micrometer.runtime.binder.kafka;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.event.Observes;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.jboss.logging.Logger;\n+\n+import io.micrometer.core.instrument.MeterRegistry;\n+import io.micrometer.core.instrument.Metrics;\n+import io.micrometer.core.instrument.binder.kafka.KafkaStreamsMetrics;\n+import io.quarkus.runtime.ShutdownEvent;\n+\n+/**\n+ * Observer to create and register KafkaStreamsMetrics.\n+ * \n+ * Must be separated from KafkaEventObserver, because they use different dependencies and if only kafka-client is used, the\n+ * classes from kafka-streams aren't loaded.\n+ */\n+@ApplicationScoped\n+public class KafkaStreamsEventObserver {\n+\n+    private static final Logger log = Logger.getLogger(KafkaStreamsEventObserver.class);\n+    MeterRegistry registry = Metrics.globalRegistry;", "originalCommit": "1d392b5dfd222dd60cec0eb2d9a50a6ce7431aa7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY3ODYxNg==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521678616", "bodyText": "Changed it here and in the KafkaEventObserver", "author": "vonatzigenc", "createdAt": "2020-11-11T22:33:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwNDg1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwNjIzMw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521606233", "bodyText": "Why is kafkaStreamsMetrics a map? It seems we only ever put a single object into it? What is the purpose of this?", "author": "gunnarmorling", "createdAt": "2020-11-11T20:02:20Z", "path": "extensions/micrometer/runtime/src/main/java/io/quarkus/micrometer/runtime/binder/kafka/KafkaStreamsEventObserver.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package io.quarkus.micrometer.runtime.binder.kafka;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.event.Observes;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.jboss.logging.Logger;\n+\n+import io.micrometer.core.instrument.MeterRegistry;\n+import io.micrometer.core.instrument.Metrics;\n+import io.micrometer.core.instrument.binder.kafka.KafkaStreamsMetrics;\n+import io.quarkus.runtime.ShutdownEvent;\n+\n+/**\n+ * Observer to create and register KafkaStreamsMetrics.\n+ * \n+ * Must be separated from KafkaEventObserver, because they use different dependencies and if only kafka-client is used, the\n+ * classes from kafka-streams aren't loaded.\n+ */\n+@ApplicationScoped\n+public class KafkaStreamsEventObserver {\n+\n+    private static final Logger log = Logger.getLogger(KafkaStreamsEventObserver.class);\n+    MeterRegistry registry = Metrics.globalRegistry;\n+    Map<Object, KafkaStreamsMetrics> kafkaStreamsMetrics = new HashMap<>();\n+\n+    /**\n+     * Manage bind/close of KafkaStreamsMetrics for the specified KafkaStreams client.\n+     * If kafkaStreams has not been seen before, it will be bound to the\n+     * Micrometer registry and instrumented using a Kafka MeterBinder.\n+     * If the producer has been seen before, the MeterBinder will be closed.\n+     *\n+     * @param kafkaStreams Observed KafkaStreams instance\n+     */\n+    public synchronized void kafkaStreamsCreated(@Observes KafkaStreams kafkaStreams) {\n+        KafkaStreamsMetrics metrics = kafkaStreamsMetrics.remove(kafkaStreams);\n+        if (metrics == null) {\n+            metrics = new KafkaStreamsMetrics(kafkaStreams);\n+            try {\n+                metrics.bindTo(registry);\n+                kafkaStreamsMetrics.put(kafkaStreams, metrics);", "originalCommit": "1d392b5dfd222dd60cec0eb2d9a50a6ce7431aa7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNDI3Ng==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521614276", "bodyText": "to verify by instance equality that you don't see more than one -- this is likely due to making kafka streams observer look like the producer/consumer observer (which is dealing with multiple instances).", "author": "ebullient", "createdAt": "2020-11-11T20:18:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwNjIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYzNzM1Mw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521637353", "bodyText": "In which case would there be more than one KafkaStreams instance?", "author": "gunnarmorling", "createdAt": "2020-11-11T21:04:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwNjIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0MDU3Mw==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521640573", "bodyText": "sounds like not, so this can be simplified to just see the event coming in and act accordingly (and then preserve shutdown for cleanup)", "author": "ebullient", "createdAt": "2020-11-11T21:10:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwNjIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY3OTU2NQ==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521679565", "bodyText": "right, the map is not needed here. I replaced it and adjusted the rest.", "author": "vonatzigenc", "createdAt": "2020-11-11T22:35:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYwNjIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY0MjUxNQ==", "url": "https://github.com/quarkusio/quarkus/pull/13198#discussion_r521642515", "bodyText": "Odd line break here.", "author": "gunnarmorling", "createdAt": "2020-11-11T21:14:35Z", "path": "extensions/micrometer/runtime/src/main/java/io/quarkus/micrometer/runtime/binder/kafka/KafkaEventObserver.java", "diffHunk": "@@ -13,7 +13,17 @@\n import io.micrometer.core.instrument.MeterRegistry;\n import io.micrometer.core.instrument.Metrics;\n import io.micrometer.core.instrument.binder.kafka.KafkaClientMetrics;\n+import io.quarkus.runtime.ShutdownEvent;\n \n+/**\n+ * Observer to create and register KafkaClientMetrics.\n+ *\n+ * This observer uses only classes from \"kafka-clients\" and none from \"kafka-streams\n+ *\n+ * Must be separated from KafkaStreamsEventObserver, because they use different dependencies and if only kafka-client is used,\n+ * the\n+ * classes from kafka-streams aren't loaded.", "originalCommit": "1d392b5dfd222dd60cec0eb2d9a50a6ce7431aa7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "773210e8da602312184e598049c6fba8c6e0806e", "url": "https://github.com/quarkusio/quarkus/commit/773210e8da602312184e598049c6fba8c6e0806e", "message": "Add producer for KafkaStreamsMetrics\n\nSigned-off-by: Christian von Atzigen <christian.vonatzigen@mobi.ch>", "committedDate": "2020-11-12T00:16:10Z", "type": "commit"}, {"oid": "773210e8da602312184e598049c6fba8c6e0806e", "url": "https://github.com/quarkusio/quarkus/commit/773210e8da602312184e598049c6fba8c6e0806e", "message": "Add producer for KafkaStreamsMetrics\n\nSigned-off-by: Christian von Atzigen <christian.vonatzigen@mobi.ch>", "committedDate": "2020-11-12T00:16:10Z", "type": "forcePushed"}]}