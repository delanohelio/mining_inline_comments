{"pr_number": 8237, "pr_title": "Increase kafka client test coverage", "pr_createdAt": "2020-03-28T16:36:43Z", "pr_url": "https://github.com/quarkusio/quarkus/pull/8237", "timeline": [{"oid": "3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3", "url": "https://github.com/quarkusio/quarkus/commit/3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3", "message": "Add test checking the Avro support", "committedDate": "2020-03-31T09:47:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3MjA4Nw==", "url": "https://github.com/quarkusio/quarkus/pull/8237#discussion_r406672087", "bodyText": "Same thought as above: use the Apicurio SerDe?", "author": "gunnarmorling", "createdAt": "2020-04-10T09:02:30Z", "path": "integration-tests/kafka/src/main/java/io/quarkus/it/kafka/avro/AvroEndpoint.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package io.quarkus.it.kafka.avro;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import javax.annotation.PostConstruct;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+\n+import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;\n+import io.confluent.kafka.serializers.KafkaAvroDeserializer;\n+import io.confluent.kafka.serializers.KafkaAvroDeserializerConfig;\n+import io.confluent.kafka.serializers.KafkaAvroSerializer;\n+import io.vertx.core.json.JsonObject;\n+\n+/**\n+ * Endpoint to test the Avro support\n+ */\n+@Path(\"/avro\")\n+public class AvroEndpoint {\n+\n+    private KafkaConsumer<Integer, Pet> consumer;\n+    private KafkaProducer<Integer, Pet> producer;\n+\n+    @PostConstruct\n+    public void init() {\n+        String registry = System.getProperty(\"schema.url\");\n+        producer = createProducer(registry);\n+        consumer = createConsumer(registry);\n+    }\n+\n+    @GET\n+    @Produces(MediaType.APPLICATION_JSON)\n+    public JsonObject get() {\n+        final ConsumerRecords<Integer, Pet> records = consumer.poll(Duration.ofMillis(60000));\n+        if (records.isEmpty()) {\n+            return null;\n+        }\n+        Pet p = records.iterator().next().value();\n+        // We cannot serialize the returned Pet directly, it contains non-serializable object such as the schema.\n+        JsonObject result = new JsonObject();\n+        result.put(\"name\", p.getName());\n+        result.put(\"color\", p.getColor());\n+        return result;\n+    }\n+\n+    @POST\n+    public void send(Pet pet) {\n+        producer.send(new ProducerRecord<>(\"test-avro-producer\", 0, pet));\n+        producer.flush();\n+    }\n+\n+    public static KafkaConsumer<Integer, Pet> createConsumer(String registry) {\n+        Properties props = new Properties();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:19092\");\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, \"test-avro-consumer\");\n+        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());\n+        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class.getName());\n+        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n+        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        props.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, registry);\n+        props.put(KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG, true);\n+        KafkaConsumer<Integer, Pet> consumer = new KafkaConsumer<>(props);\n+        consumer.subscribe(Collections.singletonList(\"test-avro-consumer\"));\n+        return consumer;\n+    }\n+\n+    public static KafkaProducer<Integer, Pet> createProducer(String registry) {\n+        Properties props = new Properties();\n+        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:19092\");\n+        props.put(ProducerConfig.CLIENT_ID_CONFIG, \"test-avro\");\n+        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class.getName());\n+        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());\n+        props.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, registry);", "originalCommit": "3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3MjQ2Nw==", "url": "https://github.com/quarkusio/quarkus/pull/8237#discussion_r406672467", "bodyText": "addSsl, to be consistent with other abbreviation casing in this test?", "author": "gunnarmorling", "createdAt": "2020-04-10T09:03:33Z", "path": "integration-tests/kafka/src/main/java/io/quarkus/it/kafka/sasl/SaslKafkaEndpoint.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package io.quarkus.it.kafka.sasl;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.Properties;\n+\n+import javax.annotation.PostConstruct;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+\n+/**\n+ * Endpoint to check the SSL/SASL connection.\n+ */\n+@Path(\"/sasl\")\n+public class SaslKafkaEndpoint {\n+\n+    private Consumer<Integer, String> consumer;\n+\n+    @PostConstruct\n+    public void create() {\n+        consumer = createConsumer();\n+    }\n+\n+    @GET\n+    public String get() {\n+        final ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(60000));\n+        if (records.isEmpty()) {\n+            return null;\n+        }\n+        return records.iterator().next().value();\n+    }\n+\n+    private static void addSSL(Properties props) {", "originalCommit": "3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3MzYwMg==", "url": "https://github.com/quarkusio/quarkus/pull/8237#discussion_r406673602", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static void addSSL(Properties props) {\n          \n          \n            \n                private static void addSsl(Properties props) {", "author": "gunnarmorling", "createdAt": "2020-04-10T09:06:28Z", "path": "integration-tests/kafka/src/test/java/io/quarkus/it/kafka/SaslKafkaConsumerTest.java", "diffHunk": "@@ -0,0 +1,60 @@\n+package io.quarkus.it.kafka;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Properties;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.Test;\n+\n+import io.quarkus.test.common.QuarkusTestResource;\n+import io.quarkus.test.junit.QuarkusTest;\n+import io.restassured.RestAssured;\n+\n+@QuarkusTest\n+@QuarkusTestResource(KafkaSASLTestResource.class)\n+public class SaslKafkaConsumerTest {\n+\n+    private static void addSSL(Properties props) {", "originalCommit": "3c88d1eb440ce98114a5ca7b0179ce9b8e7492f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "96410f1977e0798604f9a9dd04738ada91018dfd", "url": "https://github.com/quarkusio/quarkus/commit/96410f1977e0798604f9a9dd04738ada91018dfd", "message": "Add test checking the Avro support", "committedDate": "2020-04-12T07:32:23Z", "type": "forcePushed"}, {"oid": "dca5dfd8026730d32ef12df2431fbebb3dd9ceb7", "url": "https://github.com/quarkusio/quarkus/commit/dca5dfd8026730d32ef12df2431fbebb3dd9ceb7", "message": "Add test checking the Avro support", "committedDate": "2020-04-12T08:02:21Z", "type": "forcePushed"}, {"oid": "98762cfcf6c7dc5a43dba3854a193e37bacd354f", "url": "https://github.com/quarkusio/quarkus/commit/98762cfcf6c7dc5a43dba3854a193e37bacd354f", "message": "Add test checking the Avro support", "committedDate": "2020-04-12T12:10:50Z", "type": "forcePushed"}, {"oid": "4a890ce0c1a1976d2ca56bbf07111c97b1647acd", "url": "https://github.com/quarkusio/quarkus/commit/4a890ce0c1a1976d2ca56bbf07111c97b1647acd", "message": "Add test to check the Kafka SASL / SSL support", "committedDate": "2020-04-24T08:21:42Z", "type": "commit"}, {"oid": "937fa105cc728de6d4d8a6241a2713527d8b2fed", "url": "https://github.com/quarkusio/quarkus/commit/937fa105cc728de6d4d8a6241a2713527d8b2fed", "message": "Add test checking the Avro support", "committedDate": "2020-04-24T08:21:42Z", "type": "commit"}, {"oid": "937fa105cc728de6d4d8a6241a2713527d8b2fed", "url": "https://github.com/quarkusio/quarkus/commit/937fa105cc728de6d4d8a6241a2713527d8b2fed", "message": "Add test checking the Avro support", "committedDate": "2020-04-24T08:21:42Z", "type": "forcePushed"}]}