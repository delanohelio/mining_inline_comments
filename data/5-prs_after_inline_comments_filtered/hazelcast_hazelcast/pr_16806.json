{"pr_number": 16806, "pr_title": "SQL: Thread pools (#16805)", "pr_createdAt": "2020-03-26T14:08:40Z", "pr_url": "https://github.com/hazelcast/hazelcast/pull/16806", "timeline": [{"oid": "663b778fa0a3eb80052ab1b3d40fa37e18606653", "url": "https://github.com/hazelcast/hazelcast/commit/663b778fa0a3eb80052ab1b3d40fa37e18606653", "message": "SQL thread pools", "committedDate": "2020-03-26T14:04:45Z", "type": "commit"}, {"oid": "a3914e607053591b447d00dc5d13bb438a9b13c3", "url": "https://github.com/hazelcast/hazelcast/commit/a3914e607053591b447d00dc5d13bb438a9b13c3", "message": "Minors.", "committedDate": "2020-03-26T14:11:16Z", "type": "commit"}, {"oid": "8fb09342b6e66b06d587040b4b8d137d0a11764c", "url": "https://github.com/hazelcast/hazelcast/commit/8fb09342b6e66b06d587040b4b8d137d0a11764c", "message": "Minors.", "committedDate": "2020-03-26T14:12:41Z", "type": "commit"}, {"oid": "e1f504f79698e4cca5f07840c15055c176ba77a2", "url": "https://github.com/hazelcast/hazelcast/commit/e1f504f79698e4cca5f07840c15055c176ba77a2", "message": "Typos.", "committedDate": "2020-03-27T08:51:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399173147", "bodyText": "It's not a good idea to pass null as UncaughtExceptionHandler, all exceptions will be silenced.", "author": "taburet", "createdAt": "2020-03-27T10:37:23Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/worker/QueryFragmentWorkerPool.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.sql.impl.QueryUtils;\n+\n+import java.util.concurrent.ForkJoinPool;\n+import java.util.concurrent.ForkJoinWorkerThread;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import static com.hazelcast.sql.impl.QueryUtils.WORKER_TYPE_FRAGMENT;\n+\n+/**\n+ * Thread pool that executes query fragments.\n+ */\n+public class QueryFragmentWorkerPool {\n+\n+    private final ForkJoinPool pool;\n+\n+    public QueryFragmentWorkerPool(String instanceName, int threadCount) {\n+        pool = new ForkJoinPool(threadCount, new WorkerThreadFactory(instanceName), null, false);", "originalCommit": "e1f504f79698e4cca5f07840c15055c176ba77a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3NDUxNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399174516", "bodyText": "... QueryOperationWorkerPool also silences all exceptions.", "author": "taburet", "createdAt": "2020-03-27T10:39:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTIwMzM2Ng==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399203366", "bodyText": "We do not need anything to handle here since exceptions are handled in other places (e.g. QueryFragmentExecutable.run()).\nEven JDK doesn't use any handler by default.", "author": "devozerov", "createdAt": "2020-03-27T11:36:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTIxNjU3MA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399216570", "bodyText": "JDK doesn't handle uncaught exceptions because it doesn't know what to do with them, there is no good default strategy that works for everyone. To decide on the strategy they provide an extension point.\nQueryFragmentExecutable doesn't handle all exceptions, even basic failed assert is swallowed silently because it results in AssertionError, which is not a subclass of Exception. Besides that, the unschedule() call is not wrapped in try-catch. In any case, it's a very bad practice to leave uncaught exception handlers empty.", "author": "taburet", "createdAt": "2020-03-27T12:03:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTIyMTAzMA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399221030", "bodyText": "Note these are not generic thread pools that execute arbitrary tasks. The semantics is fully under our control. Moreover, FJP re-creates failed threads, when something nasty happens. What kind of handling do you suggest to add here?\nI think that one thing that is definitely worth adding is \"panic\" handler, such as in com.hazelcast.spi.impl.operationexecutor.impl.OperationThread#run, but it should be installed on the thread level, not thread pool.", "author": "devozerov", "createdAt": "2020-03-27T12:12:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI0NDU0OA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399244548", "bodyText": "Yes, it's under our control, but that doesn't mean we should treat all the code base as fully verified and 100% bug free. We can even invoke user code under the hood: every map scan potentially results in accessing user supplied classes, we read attribute values from them.\nThe usual practice is to at least log the errors you can't handle, looks like we can't do nothing more.", "author": "taburet", "createdAt": "2020-03-27T12:57:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI1ODI1Mw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399258253", "bodyText": "The asyncMode parameter is basically a switch between FIFO and LIFO modes, false = LIFO. It should not affect the execution, since we don't fork any tasks, but Executors.newWorkStealingPool sets the parameter to true, probably we should do the same.", "author": "taburet", "createdAt": "2020-03-27T13:20:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI4NjcwOQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399286709", "bodyText": "Added exception handling to both pools. It follows the common approach we use in other pools - to log an error, and possibly handle OOME. It is far from ideal, but it is what it is.", "author": "devozerov", "createdAt": "2020-03-27T14:03:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTI4NzQ1Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399287452", "bodyText": "Regarding asyncMode - great catch, LIFO is dangerous for us because it may lead to starvation. Changed to true.", "author": "devozerov", "createdAt": "2020-03-27T14:04:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE3MzE0Nw=="}], "type": "inlineReview"}, {"oid": "38682e7a951effae2f3a5693415586a14a0c078a", "url": "https://github.com/hazelcast/hazelcast/commit/38682e7a951effae2f3a5693415586a14a0c078a", "message": "Typos.", "committedDate": "2020-03-27T11:39:12Z", "type": "commit"}, {"oid": "c758ffc74823617bad0ce51e6838d2c4fe57ed0c", "url": "https://github.com/hazelcast/hazelcast/commit/c758ffc74823617bad0ce51e6838d2c4fe57ed0c", "message": "Review comments.", "committedDate": "2020-03-27T14:02:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQxODA1OQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399418059", "bodyText": "Minor: make it final?", "author": "petrpleshachkov", "createdAt": "2020-03-27T17:13:01Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/mailbox/InboundBatch.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.mailbox;\n+\n+import com.hazelcast.sql.impl.row.RowBatch;\n+\n+import java.util.UUID;\n+\n+/**\n+ * Mailbox batch received from the remote member.\n+ */\n+public class InboundBatch {", "originalCommit": "8fb09342b6e66b06d587040b4b8d137d0a11764c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1MzA0NQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399653045", "bodyText": "Makes sense, fixed.", "author": "devozerov", "createdAt": "2020-03-28T11:45:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQxODA1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQxOTAxNw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399419017", "bodyText": "Minor: which is available...", "author": "petrpleshachkov", "createdAt": "2020-03-27T17:14:32Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/mailbox/OutboundHandler.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.mailbox;\n+\n+/**\n+ * Core interface for outbound message processing.\n+ */\n+public interface OutboundHandler {\n+    /**\n+     * Handle flow control response from the remote inbound handler.\n+     *\n+     * @param remainingMemory Amount of memory which available on the remote end.", "originalCommit": "8fb09342b6e66b06d587040b4b8d137d0a11764c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1MzAzOA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399653038", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-28T11:45:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQxOTAxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQyMDAwOA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399420008", "bodyText": "Minor: True-> true", "author": "petrpleshachkov", "createdAt": "2020-03-27T17:16:11Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/operation/QueryOperationHandler.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.operation;\n+\n+import java.util.UUID;\n+\n+/**\n+ * Query operation executor.\n+ */\n+public interface QueryOperationHandler {\n+    /**\n+     * Submit operation for execution on a member.\n+     *\n+     * @param memberId ID of the member.\n+     * @param operation Operation to be executed.\n+     * @return {@code True} if operation is triggered, {@code false} if target member is not available.", "originalCommit": "8fb09342b6e66b06d587040b4b8d137d0a11764c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1MzAyMg==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399653022", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-28T11:45:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQyMDAwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQyMDkxMQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399420911", "bodyText": "Minor: and-> an?", "author": "petrpleshachkov", "createdAt": "2020-03-27T17:17:45Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/state/QueryStateCallback.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.state;\n+\n+/**\n+ * Callback to perform various actions on the query state.\n+ */\n+public interface QueryStateCallback {\n+    /**\n+     * Notify the query that fragment execution has finished.\n+     */\n+    void onFragmentFinished();\n+\n+    /**\n+     * Cancel the query with error.\n+     *\n+     * @param e Error.\n+     */\n+    void cancel(Exception e);\n+\n+    /**\n+     * Check whether the query is cancelled. If the query is not cancelled, the method returns with no side effects.\n+     * Otherwise and exception is thrown.", "originalCommit": "8fb09342b6e66b06d587040b4b8d137d0a11764c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1MzAxNw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399653017", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-28T11:44:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQyMDkxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQyODE4Ng==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399428186", "bodyText": "Do we have to send flow control if res is WAIT?", "author": "petrpleshachkov", "createdAt": "2020-03-27T17:29:54Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/worker/QueryFragmentExecutable.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.sql.impl.exec.Exec;\n+import com.hazelcast.sql.impl.exec.IterationResult;\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.mailbox.InboundHandler;\n+import com.hazelcast.sql.impl.mailbox.InboundBatch;\n+import com.hazelcast.sql.impl.mailbox.OutboundHandler;\n+import com.hazelcast.sql.impl.operation.QueryBatchExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryAbstractExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryFlowControlExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperation;\n+import com.hazelcast.sql.impl.state.QueryStateCallback;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentLinkedDeque;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Query fragment executable that advances the top-level operator, consumes data operations, and manages scheduling.\n+ */\n+public class QueryFragmentExecutable implements QueryFragmentScheduleCallback {\n+\n+    private final QueryStateCallback stateCallback;\n+    private final List<Object> arguments;\n+    private final Exec exec;\n+    private final Map<Integer, InboundHandler> inboxes;\n+    private final Map<Integer, Map<UUID, OutboundHandler>> outboxes;\n+    private final QueryFragmentWorkerPool fragmentPool;\n+\n+    /** Operations to be processed. */\n+    private final ConcurrentLinkedDeque<QueryAbstractExchangeOperation> operations = new ConcurrentLinkedDeque<>();\n+\n+    /** Batch count which we used instead of batches.size() (which is O(N)) to prevent starvation. */\n+    private final AtomicInteger operationCount = new AtomicInteger();\n+\n+    /** Schedule flag. */\n+    private final AtomicBoolean scheduled = new AtomicBoolean();\n+\n+    /** Whether the fragment is initialized. */\n+    private volatile boolean initialized;\n+\n+    /** Whether the fragment has completed. */\n+    private volatile boolean completed;\n+\n+    public QueryFragmentExecutable(\n+        QueryStateCallback stateCallback,\n+        List<Object> arguments,\n+        Exec exec,\n+        Map<Integer, InboundHandler> inboxes,\n+        Map<Integer, Map<UUID, OutboundHandler>> outboxes,\n+        QueryFragmentWorkerPool fragmentPool\n+    ) {\n+        this.stateCallback = stateCallback;\n+        this.arguments = arguments;\n+        this.exec = exec;\n+        this.inboxes = inboxes;\n+        this.outboxes = outboxes;\n+        this.fragmentPool = fragmentPool;\n+    }\n+\n+    public Collection<Integer> getInboxEdgeIds() {\n+        return inboxes.keySet();\n+    }\n+\n+    public Collection<Integer> getOutboxEdgeIds() {\n+        return outboxes.keySet();\n+    }\n+\n+    /**\n+     * Add operation to be processed.\n+     */\n+    public void addOperation(QueryAbstractExchangeOperation operation) {\n+        operationCount.incrementAndGet();\n+        operations.addLast(operation);\n+    }\n+\n+    public void run() {\n+        try {\n+            if (completed) {\n+                return;\n+            }\n+\n+            // Setup the executor if needed.\n+            setupExecutor();\n+\n+            // Feed all batches to relevant inboxes first. Set the upper boundary on the number of batches to avoid\n+            // starvation when batches arrive quicker than we are able to process them.\n+            int maxOperationCount = operationCount.get();\n+            int processedBatchCount = 0;\n+\n+            QueryOperation operation;\n+\n+            while ((operation = operations.pollFirst()) != null) {\n+                if (operation instanceof QueryBatchExchangeOperation) {\n+                    QueryBatchExchangeOperation operation0 = (QueryBatchExchangeOperation) operation;\n+\n+                    InboundHandler inbox = inboxes.get(operation0.getEdgeId());\n+                    assert inbox != null;\n+\n+                    InboundBatch batch = new InboundBatch(\n+                        operation0.getBatch(),\n+                        operation0.isLast(),\n+                        operation0.getCallerId()\n+                    );\n+\n+                    inbox.onBatch(batch, operation0.getRemainingMemory());\n+                } else {\n+                    assert operation instanceof QueryFlowControlExchangeOperation;\n+\n+                    QueryFlowControlExchangeOperation operation0 = (QueryFlowControlExchangeOperation) operation;\n+\n+                    Map<UUID, OutboundHandler> edgeOutboxes = outboxes.get(operation0.getEdgeId());\n+                    assert edgeOutboxes != null;\n+\n+                    OutboundHandler outbox = edgeOutboxes.get(operation.getCallerId());\n+                    assert outbox != null;\n+\n+                    outbox.onFlowControl(operation0.getRemainingMemory());\n+                }\n+\n+                if (++processedBatchCount >= maxOperationCount) {\n+                    break;\n+                }\n+            }\n+\n+            operationCount.addAndGet(-1 * processedBatchCount);\n+\n+            IterationResult res = exec.advance();\n+\n+            // Send flow control messages if needed.\n+            if (res != IterationResult.FETCHED_DONE) {\n+                for (InboundHandler inbox : inboxes.values()) {\n+                    inbox.sendFlowControl();", "originalCommit": "c758ffc74823617bad0ce51e6838d2c4fe57ed0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1MDgzMA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399650830", "bodyText": "Yes. E.g. if we have a sort operator which is fetching a stream of rows from the remote operator, then we will return WAIT for all batches except for the last one. Nevertheless, flow control should work during this process as usual.", "author": "devozerov", "createdAt": "2020-03-28T11:20:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQyODE4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQzMTY0Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399431642", "bodyText": "It seems this check is not necessary because it is covered by the scheduled.compareAndSet logic.", "author": "petrpleshachkov", "createdAt": "2020-03-27T17:35:33Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/worker/QueryFragmentExecutable.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.sql.impl.exec.Exec;\n+import com.hazelcast.sql.impl.exec.IterationResult;\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.mailbox.InboundHandler;\n+import com.hazelcast.sql.impl.mailbox.InboundBatch;\n+import com.hazelcast.sql.impl.mailbox.OutboundHandler;\n+import com.hazelcast.sql.impl.operation.QueryBatchExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryAbstractExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryFlowControlExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperation;\n+import com.hazelcast.sql.impl.state.QueryStateCallback;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentLinkedDeque;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Query fragment executable that advances the top-level operator, consumes data operations, and manages scheduling.\n+ */\n+public class QueryFragmentExecutable implements QueryFragmentScheduleCallback {\n+\n+    private final QueryStateCallback stateCallback;\n+    private final List<Object> arguments;\n+    private final Exec exec;\n+    private final Map<Integer, InboundHandler> inboxes;\n+    private final Map<Integer, Map<UUID, OutboundHandler>> outboxes;\n+    private final QueryFragmentWorkerPool fragmentPool;\n+\n+    /** Operations to be processed. */\n+    private final ConcurrentLinkedDeque<QueryAbstractExchangeOperation> operations = new ConcurrentLinkedDeque<>();\n+\n+    /** Batch count which we used instead of batches.size() (which is O(N)) to prevent starvation. */\n+    private final AtomicInteger operationCount = new AtomicInteger();\n+\n+    /** Schedule flag. */\n+    private final AtomicBoolean scheduled = new AtomicBoolean();\n+\n+    /** Whether the fragment is initialized. */\n+    private volatile boolean initialized;\n+\n+    /** Whether the fragment has completed. */\n+    private volatile boolean completed;\n+\n+    public QueryFragmentExecutable(\n+        QueryStateCallback stateCallback,\n+        List<Object> arguments,\n+        Exec exec,\n+        Map<Integer, InboundHandler> inboxes,\n+        Map<Integer, Map<UUID, OutboundHandler>> outboxes,\n+        QueryFragmentWorkerPool fragmentPool\n+    ) {\n+        this.stateCallback = stateCallback;\n+        this.arguments = arguments;\n+        this.exec = exec;\n+        this.inboxes = inboxes;\n+        this.outboxes = outboxes;\n+        this.fragmentPool = fragmentPool;\n+    }\n+\n+    public Collection<Integer> getInboxEdgeIds() {\n+        return inboxes.keySet();\n+    }\n+\n+    public Collection<Integer> getOutboxEdgeIds() {\n+        return outboxes.keySet();\n+    }\n+\n+    /**\n+     * Add operation to be processed.\n+     */\n+    public void addOperation(QueryAbstractExchangeOperation operation) {\n+        operationCount.incrementAndGet();\n+        operations.addLast(operation);\n+    }\n+\n+    public void run() {\n+        try {\n+            if (completed) {\n+                return;\n+            }\n+\n+            // Setup the executor if needed.\n+            setupExecutor();\n+\n+            // Feed all batches to relevant inboxes first. Set the upper boundary on the number of batches to avoid\n+            // starvation when batches arrive quicker than we are able to process them.\n+            int maxOperationCount = operationCount.get();\n+            int processedBatchCount = 0;\n+\n+            QueryOperation operation;\n+\n+            while ((operation = operations.pollFirst()) != null) {\n+                if (operation instanceof QueryBatchExchangeOperation) {\n+                    QueryBatchExchangeOperation operation0 = (QueryBatchExchangeOperation) operation;\n+\n+                    InboundHandler inbox = inboxes.get(operation0.getEdgeId());\n+                    assert inbox != null;\n+\n+                    InboundBatch batch = new InboundBatch(\n+                        operation0.getBatch(),\n+                        operation0.isLast(),\n+                        operation0.getCallerId()\n+                    );\n+\n+                    inbox.onBatch(batch, operation0.getRemainingMemory());\n+                } else {\n+                    assert operation instanceof QueryFlowControlExchangeOperation;\n+\n+                    QueryFlowControlExchangeOperation operation0 = (QueryFlowControlExchangeOperation) operation;\n+\n+                    Map<UUID, OutboundHandler> edgeOutboxes = outboxes.get(operation0.getEdgeId());\n+                    assert edgeOutboxes != null;\n+\n+                    OutboundHandler outbox = edgeOutboxes.get(operation.getCallerId());\n+                    assert outbox != null;\n+\n+                    outbox.onFlowControl(operation0.getRemainingMemory());\n+                }\n+\n+                if (++processedBatchCount >= maxOperationCount) {\n+                    break;\n+                }\n+            }\n+\n+            operationCount.addAndGet(-1 * processedBatchCount);\n+\n+            IterationResult res = exec.advance();\n+\n+            // Send flow control messages if needed.\n+            if (res != IterationResult.FETCHED_DONE) {\n+                for (InboundHandler inbox : inboxes.values()) {\n+                    inbox.sendFlowControl();\n+                }\n+            }\n+\n+            // If executor finished, notify the state.\n+            if (res == IterationResult.FETCHED_DONE) {\n+                completed = true;\n+\n+                stateCallback.onFragmentFinished();\n+            }\n+        } catch (Exception e) {\n+            // Prevent subsequent invocations.\n+            completed = true;\n+\n+            // Notify state about the exception to trigger cancel operation.\n+            stateCallback.cancel(e);\n+        }\n+\n+        // Unschedule the fragment with double-check for new batches.\n+        unschedule();\n+    }\n+\n+    @Override\n+    public boolean schedule() {\n+        // If the fragment is already scheduled, we do not need to do anything else, because executor will re-check queue state\n+        // before exiting.\n+        if (scheduled.get()) {", "originalCommit": "c758ffc74823617bad0ce51e6838d2c4fe57ed0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1Mjk1Ng==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399652956", "bodyText": "CAS is typically implemented as a write operation even if it doesn't change the value, causing contention on the bus. So here we employ test-and-test-and-set rather than test-and-set (CAS), to minimize the number of writes on a shared variable.\nThis should be considered as a micro-optimization, and it is hard to prove that it adds value with some numbers. But in general, it is assumed that there should be fewer fragment execution attempts than batches, so IMO it should pay off.", "author": "devozerov", "createdAt": "2020-03-28T11:44:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQzMTY0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1Mjk4MQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399652981", "bodyText": "BTW, I slightly changed the reschedule algorithm, so that we reach this place even rarer.", "author": "devozerov", "createdAt": "2020-03-28T11:44:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQzMTY0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQzMjQ4Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399432487", "bodyText": "True ->true", "author": "petrpleshachkov", "createdAt": "2020-03-27T17:36:57Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/worker/QueryFragmentScheduleCallback.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+public interface QueryFragmentScheduleCallback {\n+    /**\n+     * Schedule the fragment for execution.\n+     *\n+     * @return {@code True} if the fragment was scheduled, {@code false} if already scheduled.", "originalCommit": "c758ffc74823617bad0ce51e6838d2c4fe57ed0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1MzAwNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399653004", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-28T11:44:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQzMjQ4Nw=="}], "type": "inlineReview"}, {"oid": "5231be152983b59c18d545ab66ce62315fdac0d8", "url": "https://github.com/hazelcast/hazelcast/commit/5231be152983b59c18d545ab66ce62315fdac0d8", "message": "Review comments.", "committedDate": "2020-03-28T11:42:15Z", "type": "commit"}, {"oid": "5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "url": "https://github.com/hazelcast/hazelcast/commit/5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "message": "Fixed race condition leading to missed operations.", "committedDate": "2020-03-29T08:38:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk2OTk5Mw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399969993", "bodyText": "It'd be nice to see a bit mode documentation about local and remote operations.", "author": "petrpleshachkov", "createdAt": "2020-03-30T07:10:07Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/worker/QueryOperationExecutable.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.internal.nio.Packet;\n+import com.hazelcast.sql.impl.operation.QueryOperation;\n+\n+/**\n+ * Operation descriptor.\n+ */\n+public final class QueryOperationExecutable {\n+    private final QueryOperation localOperation;", "originalCommit": "5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3OTAyOQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399979029", "bodyText": "Add JavaDoc.", "author": "devozerov", "createdAt": "2020-03-30T07:28:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk2OTk5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3MTMyNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399971324", "bodyText": "Is null operation allowed here?", "author": "petrpleshachkov", "createdAt": "2020-03-30T07:12:59Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/operation/QueryOperationHandler.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.operation;\n+\n+import java.util.UUID;\n+\n+/**\n+ * Query operation executor.\n+ */\n+public interface QueryOperationHandler {\n+    /**\n+     * Submit operation for execution on a member.\n+     *\n+     * @param memberId ID of the member.\n+     * @param operation Operation to be executed.\n+     * @return {@code true} if operation is triggered, {@code false} if target member is not available.\n+     */\n+    boolean submit(UUID memberId, QueryOperation operation);\n+\n+    /**\n+     * Execute the operation synchronously.\n+     *\n+     * @param operation Operation.\n+     */\n+    void execute(QueryOperation operation);", "originalCommit": "5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3ODk5NA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399978994", "bodyText": "It should not be possible. Fixed the code.", "author": "devozerov", "createdAt": "2020-03-30T07:28:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3MTMyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3MTk5OA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399971998", "bodyText": "It's possible to pass null to the execute. Is it allowed? Is it documented anywhere?", "author": "petrpleshachkov", "createdAt": "2020-03-30T07:14:18Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/worker/QueryOperationWorker.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.internal.nio.Packet;\n+import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.internal.util.concurrent.MPSCQueue;\n+import com.hazelcast.logging.ILogger;\n+import com.hazelcast.sql.HazelcastSqlException;\n+import com.hazelcast.sql.impl.QueryId;\n+import com.hazelcast.sql.impl.QueryUtils;\n+import com.hazelcast.sql.impl.operation.QueryCancelOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperationDeserializationException;\n+import com.hazelcast.sql.impl.operation.QueryOperationHandler;\n+\n+import java.util.UUID;\n+\n+import static com.hazelcast.instance.impl.OutOfMemoryErrorDispatcher.inspectOutOfMemoryError;\n+import static com.hazelcast.sql.impl.QueryUtils.WORKER_TYPE_OPERATION;\n+\n+/**\n+ * Worker responsible for operation processing.\n+ */\n+public class QueryOperationWorker implements Runnable {\n+\n+    private static final Object POISON = new Object();\n+\n+    private final QueryOperationHandler operationHandler;\n+    private final SerializationService ss;\n+    private final Thread thread;\n+    private final MPSCQueue<Object> queue;\n+    private final ILogger logger;\n+\n+    private UUID localMemberId;\n+\n+    public QueryOperationWorker(\n+        QueryOperationHandler operationHandler,\n+        SerializationService ss,\n+        String instanceName,\n+        int index,\n+        ILogger logger\n+    ) {\n+        this.operationHandler = operationHandler;\n+        this.ss = ss;\n+        this.logger = logger;\n+\n+        thread = new Thread(this,  QueryUtils.workerName(instanceName, WORKER_TYPE_OPERATION, index));\n+        queue = new MPSCQueue<>(thread, null);\n+\n+        thread.start();\n+    }\n+\n+    public void init(UUID localMemberId) {\n+        this.localMemberId = localMemberId;\n+    }\n+\n+    public void submit(QueryOperationExecutable task) {\n+        queue.add(task);\n+    }\n+\n+    public void stop() {\n+        queue.clear();\n+        queue.add(POISON);\n+\n+        thread.interrupt();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            run0();\n+        } catch (Throwable t) {\n+            inspectOutOfMemoryError(t);\n+            logger.severe(t);\n+        }\n+    }\n+\n+    private void run0() {\n+        try {\n+            while (true) {\n+                Object task = queue.take();\n+\n+                if (task == POISON) {\n+                    break;\n+                } else {\n+                    assert task instanceof QueryOperationExecutable;\n+\n+                    execute((QueryOperationExecutable) task);\n+                }\n+            }\n+        } catch (InterruptedException e) {\n+            // No-op.\n+        }\n+    }\n+\n+    private void execute(QueryOperationExecutable task) {\n+        QueryOperation operation = task.getLocalOperation();\n+\n+        if (operation == null) {\n+            operation = deserialize(task.getRemoteOperation());\n+        }\n+\n+        operationHandler.execute(operation);", "originalCommit": "5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3ODkxNw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399978917", "bodyText": "It should not be possible. Fixed the code.", "author": "devozerov", "createdAt": "2020-03-30T07:28:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3MTk5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3MjkzMQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399972931", "bodyText": "As part of the exception handling, we cancel the query here. In the else branch we don't do this. Is there any specific reason for this?", "author": "petrpleshachkov", "createdAt": "2020-03-30T07:16:19Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/worker/QueryOperationWorker.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.internal.nio.Packet;\n+import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.internal.util.concurrent.MPSCQueue;\n+import com.hazelcast.logging.ILogger;\n+import com.hazelcast.sql.HazelcastSqlException;\n+import com.hazelcast.sql.impl.QueryId;\n+import com.hazelcast.sql.impl.QueryUtils;\n+import com.hazelcast.sql.impl.operation.QueryCancelOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperationDeserializationException;\n+import com.hazelcast.sql.impl.operation.QueryOperationHandler;\n+\n+import java.util.UUID;\n+\n+import static com.hazelcast.instance.impl.OutOfMemoryErrorDispatcher.inspectOutOfMemoryError;\n+import static com.hazelcast.sql.impl.QueryUtils.WORKER_TYPE_OPERATION;\n+\n+/**\n+ * Worker responsible for operation processing.\n+ */\n+public class QueryOperationWorker implements Runnable {\n+\n+    private static final Object POISON = new Object();\n+\n+    private final QueryOperationHandler operationHandler;\n+    private final SerializationService ss;\n+    private final Thread thread;\n+    private final MPSCQueue<Object> queue;\n+    private final ILogger logger;\n+\n+    private UUID localMemberId;\n+\n+    public QueryOperationWorker(\n+        QueryOperationHandler operationHandler,\n+        SerializationService ss,\n+        String instanceName,\n+        int index,\n+        ILogger logger\n+    ) {\n+        this.operationHandler = operationHandler;\n+        this.ss = ss;\n+        this.logger = logger;\n+\n+        thread = new Thread(this,  QueryUtils.workerName(instanceName, WORKER_TYPE_OPERATION, index));\n+        queue = new MPSCQueue<>(thread, null);\n+\n+        thread.start();\n+    }\n+\n+    public void init(UUID localMemberId) {\n+        this.localMemberId = localMemberId;\n+    }\n+\n+    public void submit(QueryOperationExecutable task) {\n+        queue.add(task);\n+    }\n+\n+    public void stop() {\n+        queue.clear();\n+        queue.add(POISON);\n+\n+        thread.interrupt();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            run0();\n+        } catch (Throwable t) {\n+            inspectOutOfMemoryError(t);\n+            logger.severe(t);\n+        }\n+    }\n+\n+    private void run0() {\n+        try {\n+            while (true) {\n+                Object task = queue.take();\n+\n+                if (task == POISON) {\n+                    break;\n+                } else {\n+                    assert task instanceof QueryOperationExecutable;\n+\n+                    execute((QueryOperationExecutable) task);\n+                }\n+            }\n+        } catch (InterruptedException e) {\n+            // No-op.\n+        }\n+    }\n+\n+    private void execute(QueryOperationExecutable task) {\n+        QueryOperation operation = task.getLocalOperation();\n+\n+        if (operation == null) {\n+            operation = deserialize(task.getRemoteOperation());\n+        }\n+\n+        operationHandler.execute(operation);\n+    }\n+\n+    /**\n+     * Deserializes the packet into operation. If an exception happens, the query is cancelled.\n+     *\n+     * @param packet Packet packet.\n+     * @return Query operation.\n+     */\n+    private QueryOperation deserialize(Packet packet) {\n+        try {\n+            return ss.toObject(packet);\n+        } catch (Exception e) {\n+            if (e.getCause() instanceof QueryOperationDeserializationException) {\n+                QueryOperationDeserializationException error = (QueryOperationDeserializationException) e.getCause();\n+\n+                // We assume that only ID aware operations may hold user data. Other operations contain only HZ classes and\n+                // we should never see deserialization errors for them.\n+                sendDeserializationError(error);", "originalCommit": "5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3ODgxNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399978816", "bodyText": "The \"else\" branch is used for the situation where we cannot even extract the query ID (or the operation doesn't have query ID at all). Without it, we cannot cancel anything.", "author": "devozerov", "createdAt": "2020-03-30T07:28:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3MjkzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk4OTkwNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399989906", "bodyText": "Is there any other mechanism which will eventually cancel the query to avoid resources leak? If yes, I'd add this to the comment.", "author": "petrpleshachkov", "createdAt": "2020-03-30T07:49:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3MjkzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk5MDg4OA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399990888", "bodyText": "No additional mechanisms in this specific PR.", "author": "devozerov", "createdAt": "2020-03-30T07:51:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3MjkzMQ=="}], "type": "inlineReview"}, {"oid": "aa9606f6a17c5a1df5f735431282d4989d9c5e4c", "url": "https://github.com/hazelcast/hazelcast/commit/aa9606f6a17c5a1df5f735431282d4989d9c5e4c", "message": "Review comments.", "committedDate": "2020-03-30T07:28:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3NDkxNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399974914", "bodyText": "!thread.isAlive() ?", "author": "petrpleshachkov", "createdAt": "2020-03-30T07:20:29Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/worker/QueryOperationWorker.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.internal.nio.Packet;\n+import com.hazelcast.internal.serialization.SerializationService;\n+import com.hazelcast.internal.util.concurrent.MPSCQueue;\n+import com.hazelcast.logging.ILogger;\n+import com.hazelcast.sql.HazelcastSqlException;\n+import com.hazelcast.sql.impl.QueryId;\n+import com.hazelcast.sql.impl.QueryUtils;\n+import com.hazelcast.sql.impl.operation.QueryCancelOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperationDeserializationException;\n+import com.hazelcast.sql.impl.operation.QueryOperationHandler;\n+\n+import java.util.UUID;\n+\n+import static com.hazelcast.instance.impl.OutOfMemoryErrorDispatcher.inspectOutOfMemoryError;\n+import static com.hazelcast.sql.impl.QueryUtils.WORKER_TYPE_OPERATION;\n+\n+/**\n+ * Worker responsible for operation processing.\n+ */\n+public class QueryOperationWorker implements Runnable {\n+\n+    private static final Object POISON = new Object();\n+\n+    private final QueryOperationHandler operationHandler;\n+    private final SerializationService ss;\n+    private final Thread thread;\n+    private final MPSCQueue<Object> queue;\n+    private final ILogger logger;\n+\n+    private UUID localMemberId;\n+\n+    public QueryOperationWorker(\n+        QueryOperationHandler operationHandler,\n+        SerializationService ss,\n+        String instanceName,\n+        int index,\n+        ILogger logger\n+    ) {\n+        this.operationHandler = operationHandler;\n+        this.ss = ss;\n+        this.logger = logger;\n+\n+        thread = new Thread(this,  QueryUtils.workerName(instanceName, WORKER_TYPE_OPERATION, index));\n+        queue = new MPSCQueue<>(thread, null);\n+\n+        thread.start();\n+    }\n+\n+    public void init(UUID localMemberId) {\n+        this.localMemberId = localMemberId;\n+    }\n+\n+    public void submit(QueryOperationExecutable task) {\n+        queue.add(task);\n+    }\n+\n+    public void stop() {\n+        queue.clear();\n+        queue.add(POISON);\n+\n+        thread.interrupt();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            run0();\n+        } catch (Throwable t) {\n+            inspectOutOfMemoryError(t);\n+            logger.severe(t);\n+        }\n+    }\n+\n+    private void run0() {\n+        try {\n+            while (true) {\n+                Object task = queue.take();\n+\n+                if (task == POISON) {\n+                    break;\n+                } else {\n+                    assert task instanceof QueryOperationExecutable;\n+\n+                    execute((QueryOperationExecutable) task);\n+                }\n+            }\n+        } catch (InterruptedException e) {\n+            // No-op.\n+        }\n+    }\n+\n+    private void execute(QueryOperationExecutable task) {\n+        QueryOperation operation = task.getLocalOperation();\n+\n+        if (operation == null) {\n+            operation = deserialize(task.getRemoteOperation());\n+        }\n+\n+        operationHandler.execute(operation);\n+    }\n+\n+    /**\n+     * Deserializes the packet into operation. If an exception happens, the query is cancelled.\n+     *\n+     * @param packet Packet packet.\n+     * @return Query operation.\n+     */\n+    private QueryOperation deserialize(Packet packet) {\n+        try {\n+            return ss.toObject(packet);\n+        } catch (Exception e) {\n+            if (e.getCause() instanceof QueryOperationDeserializationException) {\n+                QueryOperationDeserializationException error = (QueryOperationDeserializationException) e.getCause();\n+\n+                // We assume that only ID aware operations may hold user data. Other operations contain only HZ classes and\n+                // we should never see deserialization errors for them.\n+                sendDeserializationError(error);\n+            } else {\n+                // It is not easy to decide how to handle an arbitrary exception. We do not have caller coordinates, so\n+                // we do not know how to notify it. We also cannot panic (i.e. kill local member), because it would be a\n+                // security threat. So the only sensible solution is to log the error.\n+                logger.severe(\"Failed to deserialize query operation received from \" + packet.getConn().getEndPoint()\n+                    + \" (will be ignored)\", e);\n+            }\n+        }\n+\n+        return null;\n+    }\n+\n+    private void sendDeserializationError(QueryOperationDeserializationException e) {\n+        QueryId queryId = e.getQueryId();\n+        UUID callerId = e.getCallerId();\n+\n+        HazelcastSqlException error = HazelcastSqlException.error(\"Failed to deserialize \" + e.getOperationClassName()\n+            + \" received from \" + callerId + \": \" + e.getMessage(), e);\n+\n+        QueryCancelOperation cancelOperation =\n+            new QueryCancelOperation(queryId, error.getCode(), error.getMessage(), localMemberId);\n+\n+        try {\n+            operationHandler.submit(queryId.getMemberId(), cancelOperation);\n+        } catch (Exception ignore) {\n+            // This should never happen, since we do not transmit user objects.\n+        }\n+    }\n+\n+    /**\n+     * For testing only.\n+     */\n+    boolean isThreadTerminated() {\n+        return thread.getState() == Thread.State.TERMINATED;", "originalCommit": "5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk5MTMyMA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399991320", "bodyText": "It doesn't matter much because the method is used for testing only.", "author": "devozerov", "createdAt": "2020-03-30T07:51:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk3NDkxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk4MjA1Mw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399982053", "bodyText": "You can use hazelcastTestSupport#assertOpenEventually which has a timeout to avoid indefinite blocks...", "author": "petrpleshachkov", "createdAt": "2020-03-30T07:34:34Z", "path": "hazelcast/src/test/java/com/hazelcast/sql/impl/worker/QueryFragmentExecutableTest.java", "diffHunk": "@@ -0,0 +1,478 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.logging.NoLogFactory;\n+import com.hazelcast.sql.impl.QueryId;\n+import com.hazelcast.sql.impl.exec.AbstractExec;\n+import com.hazelcast.sql.impl.exec.IterationResult;\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.mailbox.InboundBatch;\n+import com.hazelcast.sql.impl.mailbox.InboundHandler;\n+import com.hazelcast.sql.impl.mailbox.OutboundHandler;\n+import com.hazelcast.sql.impl.operation.QueryAbstractExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryBatchExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryFlowControlExchangeOperation;\n+import com.hazelcast.sql.impl.row.EmptyRowBatch;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+import com.hazelcast.sql.impl.state.QueryStateCallback;\n+import com.hazelcast.test.HazelcastParallelClassRunner;\n+import com.hazelcast.test.HazelcastTestSupport;\n+import com.hazelcast.test.annotation.ParallelJVMTest;\n+import com.hazelcast.test.annotation.QuickTest;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ThreadLocalRandom;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertSame;\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(HazelcastParallelClassRunner.class)\n+@Category({QuickTest.class, ParallelJVMTest.class})\n+public class QueryFragmentExecutableTest extends HazelcastTestSupport {\n+\n+    private QueryFragmentWorkerPool pool;\n+\n+    @After\n+    public void after() {\n+        if (pool != null) {\n+            pool.stop();\n+\n+            pool = null;\n+        }\n+    }\n+\n+    @Test\n+    public void testSetupIsCalledOnlyOnce() {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec().setPayload(new ResultExecPayload(IterationResult.FETCHED));\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.emptyMap(),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        fragmentExecutable.run();\n+        assertEquals(1, exec.getSetupInvocationCount());\n+\n+        fragmentExecutable.run();\n+        assertEquals(1, exec.getSetupInvocationCount());\n+    }\n+\n+    @Test\n+    public void testAdvanceIsCalledUntilCompletion() {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec();\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.emptyMap(),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        exec.setPayload(new ResultExecPayload(IterationResult.WAIT));\n+        fragmentExecutable.run();\n+        fragmentExecutable.run();\n+        assertEquals(2, exec.getAdvanceInvocationCount());\n+\n+        exec.setPayload(new ResultExecPayload(IterationResult.FETCHED));\n+        fragmentExecutable.run();\n+        fragmentExecutable.run();\n+        assertEquals(4, exec.getAdvanceInvocationCount());\n+        assertEquals(0, stateCallback.getFragmentFinishedInvocationCount());\n+\n+        exec.setPayload(new ResultExecPayload(IterationResult.FETCHED_DONE));\n+        fragmentExecutable.run();\n+        fragmentExecutable.run();\n+        assertEquals(5, exec.getAdvanceInvocationCount());\n+        assertEquals(1, stateCallback.getFragmentFinishedInvocationCount());\n+    }\n+\n+    @Test\n+    public void testExceptionDuringExecution() {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec();\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.emptyMap(),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        // Throw an exception.\n+        exec.setPayload(new ExceptionExecPayload());\n+        fragmentExecutable.run();\n+        assertEquals(1, exec.getAdvanceInvocationCount());\n+        assertSame(ExceptionExecPayload.ERROR, stateCallback.getCancelException());\n+\n+        // Make sure that no advance is possible after that.\n+        fragmentExecutable.run();\n+        assertEquals(1, exec.getAdvanceInvocationCount());\n+        assertEquals(0, stateCallback.getFragmentFinishedInvocationCount());\n+    }\n+\n+    @Test\n+    public void testSchedule() throws Exception {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec();\n+\n+        AtomicBoolean flowControlNotified = new AtomicBoolean();\n+\n+        InboundHandler inboundHandler = new InboundHandler() {\n+            @Override\n+            public void onBatch(InboundBatch batch, long remainingMemory) {\n+                // No-op.\n+            }\n+\n+            @Override\n+            public void sendFlowControl() {\n+                flowControlNotified.set(true);\n+            }\n+        };\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.singletonMap(1, inboundHandler),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        CountDownLatch startLatch = new CountDownLatch(1);\n+        CountDownLatch stopLatch = new CountDownLatch(1);\n+\n+        exec.setPayload(() -> {\n+            startLatch.countDown();\n+            stopLatch.await();\n+\n+            return IterationResult.FETCHED;\n+        });\n+\n+        assertTrue(fragmentExecutable.schedule());\n+        startLatch.await();\n+\n+        assertFalse(fragmentExecutable.schedule());\n+        stopLatch.countDown();\n+\n+        assertTrueEventually(() -> assertTrue(flowControlNotified.get()));\n+    }\n+\n+    /**\n+     * Concurrent test which submit messages from different threads and see if all of them are processed.\n+     */\n+    @Test\n+    public void testMessages() throws Exception {\n+        int repeatCount = 100;\n+\n+        for (int i = 0; i < repeatCount; i++) {\n+            // Prepare data structures for messages.\n+            ConcurrentLinkedQueue<Long> inboundQueue = new ConcurrentLinkedQueue<>();\n+            ConcurrentLinkedQueue<Long> outboundQueue = new ConcurrentLinkedQueue<>();\n+\n+            Set<Long> inboundSet = Collections.newSetFromMap(new ConcurrentHashMap<>());\n+            Set<Long> outboundSet = Collections.newSetFromMap(new ConcurrentHashMap<>());\n+\n+            InboundHandler inboundHandler = new InboundHandler() {\n+                @Override\n+                public void onBatch(InboundBatch batch, long remainingMemory) {\n+                    inboundQueue.add(remainingMemory);\n+                }\n+\n+                @Override\n+                public void sendFlowControl() {\n+                    // No-op.\n+                }\n+            };\n+\n+            OutboundHandler outboundHandler = outboundQueue::add;\n+\n+            // Prepare executable.\n+            QueryId queryId = QueryId.create(UUID.randomUUID());\n+            UUID callerId = UUID.randomUUID();\n+            int edgeId = 1;\n+\n+            pool = createPool();\n+\n+            TestStateCallback stateCallback = new TestStateCallback();\n+\n+            TestExec exec = new TestExec().setPayload(() -> {\n+                while (!inboundQueue.isEmpty()) {\n+                    inboundSet.add(inboundQueue.poll());\n+                }\n+\n+                while (!outboundQueue.isEmpty()) {\n+                    outboundSet.add(outboundQueue.poll());\n+                }\n+\n+                return IterationResult.FETCHED;\n+            });\n+\n+            QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+                stateCallback,\n+                Collections.emptyList(),\n+                exec,\n+                Collections.singletonMap(edgeId, inboundHandler),\n+                Collections.singletonMap(edgeId, Collections.singletonMap(callerId, outboundHandler)),\n+                pool\n+            );\n+\n+            assertEquals(1, fragmentExecutable.getInboxEdgeIds().size());\n+            assertEquals(1, fragmentExecutable.getOutboxEdgeIds().size());\n+            assertEquals(edgeId, (int) fragmentExecutable.getInboxEdgeIds().iterator().next());\n+            assertEquals(edgeId, (int) fragmentExecutable.getOutboxEdgeIds().iterator().next());\n+\n+            // Start threads and wait for completion.\n+            int operationCount = 10_000;\n+            int threadCount = 8;\n+\n+            AtomicInteger doneOperationCount = new AtomicInteger();\n+            CountDownLatch doneLatch = new CountDownLatch(threadCount);\n+\n+            Runnable run = () -> {\n+                try {\n+                    while (true) {\n+                        int counter = doneOperationCount.getAndIncrement();\n+\n+                        if (counter >= operationCount) {\n+                            break;\n+                        }\n+\n+                        QueryAbstractExchangeOperation operation;\n+\n+                        if (ThreadLocalRandom.current().nextBoolean()) {\n+                            operation = new QueryBatchExchangeOperation(queryId, edgeId, EmptyRowBatch.INSTANCE, false, counter);\n+                        } else {\n+                            operation = new QueryFlowControlExchangeOperation(queryId, edgeId, counter);\n+                        }\n+\n+                        operation.setCallerId(callerId);\n+\n+                        fragmentExecutable.addOperation(operation);\n+                        fragmentExecutable.schedule();\n+                    }\n+                } finally {\n+                    doneLatch.countDown();\n+                }\n+            };\n+\n+            for (int j = 0; j < threadCount; j++) {\n+                new Thread(run).start();\n+            }\n+\n+            doneLatch.await();", "originalCommit": "5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk5MzExNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399993114", "bodyText": "The release of this latch is part of the test infrastructure, not testing logic. Asserting test code doesn't seem natural. In any case, the timeout worker will cause thread interrupt anyway in case of bugs in the test itself, so we are safe here.", "author": "devozerov", "createdAt": "2020-03-30T07:55:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk4MjA1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk4Mjc2Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399982767", "bodyText": "The same", "author": "petrpleshachkov", "createdAt": "2020-03-30T07:35:59Z", "path": "hazelcast/src/test/java/com/hazelcast/sql/impl/worker/QueryFragmentExecutableTest.java", "diffHunk": "@@ -0,0 +1,478 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.logging.NoLogFactory;\n+import com.hazelcast.sql.impl.QueryId;\n+import com.hazelcast.sql.impl.exec.AbstractExec;\n+import com.hazelcast.sql.impl.exec.IterationResult;\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.mailbox.InboundBatch;\n+import com.hazelcast.sql.impl.mailbox.InboundHandler;\n+import com.hazelcast.sql.impl.mailbox.OutboundHandler;\n+import com.hazelcast.sql.impl.operation.QueryAbstractExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryBatchExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryFlowControlExchangeOperation;\n+import com.hazelcast.sql.impl.row.EmptyRowBatch;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+import com.hazelcast.sql.impl.state.QueryStateCallback;\n+import com.hazelcast.test.HazelcastParallelClassRunner;\n+import com.hazelcast.test.HazelcastTestSupport;\n+import com.hazelcast.test.annotation.ParallelJVMTest;\n+import com.hazelcast.test.annotation.QuickTest;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ThreadLocalRandom;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertSame;\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(HazelcastParallelClassRunner.class)\n+@Category({QuickTest.class, ParallelJVMTest.class})\n+public class QueryFragmentExecutableTest extends HazelcastTestSupport {\n+\n+    private QueryFragmentWorkerPool pool;\n+\n+    @After\n+    public void after() {\n+        if (pool != null) {\n+            pool.stop();\n+\n+            pool = null;\n+        }\n+    }\n+\n+    @Test\n+    public void testSetupIsCalledOnlyOnce() {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec().setPayload(new ResultExecPayload(IterationResult.FETCHED));\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.emptyMap(),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        fragmentExecutable.run();\n+        assertEquals(1, exec.getSetupInvocationCount());\n+\n+        fragmentExecutable.run();\n+        assertEquals(1, exec.getSetupInvocationCount());\n+    }\n+\n+    @Test\n+    public void testAdvanceIsCalledUntilCompletion() {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec();\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.emptyMap(),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        exec.setPayload(new ResultExecPayload(IterationResult.WAIT));\n+        fragmentExecutable.run();\n+        fragmentExecutable.run();\n+        assertEquals(2, exec.getAdvanceInvocationCount());\n+\n+        exec.setPayload(new ResultExecPayload(IterationResult.FETCHED));\n+        fragmentExecutable.run();\n+        fragmentExecutable.run();\n+        assertEquals(4, exec.getAdvanceInvocationCount());\n+        assertEquals(0, stateCallback.getFragmentFinishedInvocationCount());\n+\n+        exec.setPayload(new ResultExecPayload(IterationResult.FETCHED_DONE));\n+        fragmentExecutable.run();\n+        fragmentExecutable.run();\n+        assertEquals(5, exec.getAdvanceInvocationCount());\n+        assertEquals(1, stateCallback.getFragmentFinishedInvocationCount());\n+    }\n+\n+    @Test\n+    public void testExceptionDuringExecution() {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec();\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.emptyMap(),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        // Throw an exception.\n+        exec.setPayload(new ExceptionExecPayload());\n+        fragmentExecutable.run();\n+        assertEquals(1, exec.getAdvanceInvocationCount());\n+        assertSame(ExceptionExecPayload.ERROR, stateCallback.getCancelException());\n+\n+        // Make sure that no advance is possible after that.\n+        fragmentExecutable.run();\n+        assertEquals(1, exec.getAdvanceInvocationCount());\n+        assertEquals(0, stateCallback.getFragmentFinishedInvocationCount());\n+    }\n+\n+    @Test\n+    public void testSchedule() throws Exception {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec();\n+\n+        AtomicBoolean flowControlNotified = new AtomicBoolean();\n+\n+        InboundHandler inboundHandler = new InboundHandler() {\n+            @Override\n+            public void onBatch(InboundBatch batch, long remainingMemory) {\n+                // No-op.\n+            }\n+\n+            @Override\n+            public void sendFlowControl() {\n+                flowControlNotified.set(true);\n+            }\n+        };\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.singletonMap(1, inboundHandler),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        CountDownLatch startLatch = new CountDownLatch(1);\n+        CountDownLatch stopLatch = new CountDownLatch(1);\n+\n+        exec.setPayload(() -> {\n+            startLatch.countDown();\n+            stopLatch.await();\n+\n+            return IterationResult.FETCHED;\n+        });\n+\n+        assertTrue(fragmentExecutable.schedule());\n+        startLatch.await();\n+\n+        assertFalse(fragmentExecutable.schedule());\n+        stopLatch.countDown();\n+\n+        assertTrueEventually(() -> assertTrue(flowControlNotified.get()));\n+    }\n+\n+    /**\n+     * Concurrent test which submit messages from different threads and see if all of them are processed.\n+     */\n+    @Test\n+    public void testMessages() throws Exception {\n+        int repeatCount = 100;\n+\n+        for (int i = 0; i < repeatCount; i++) {\n+            // Prepare data structures for messages.\n+            ConcurrentLinkedQueue<Long> inboundQueue = new ConcurrentLinkedQueue<>();\n+            ConcurrentLinkedQueue<Long> outboundQueue = new ConcurrentLinkedQueue<>();\n+\n+            Set<Long> inboundSet = Collections.newSetFromMap(new ConcurrentHashMap<>());\n+            Set<Long> outboundSet = Collections.newSetFromMap(new ConcurrentHashMap<>());\n+\n+            InboundHandler inboundHandler = new InboundHandler() {\n+                @Override\n+                public void onBatch(InboundBatch batch, long remainingMemory) {\n+                    inboundQueue.add(remainingMemory);\n+                }\n+\n+                @Override\n+                public void sendFlowControl() {\n+                    // No-op.\n+                }\n+            };\n+\n+            OutboundHandler outboundHandler = outboundQueue::add;\n+\n+            // Prepare executable.\n+            QueryId queryId = QueryId.create(UUID.randomUUID());\n+            UUID callerId = UUID.randomUUID();\n+            int edgeId = 1;\n+\n+            pool = createPool();\n+\n+            TestStateCallback stateCallback = new TestStateCallback();\n+\n+            TestExec exec = new TestExec().setPayload(() -> {\n+                while (!inboundQueue.isEmpty()) {\n+                    inboundSet.add(inboundQueue.poll());\n+                }\n+\n+                while (!outboundQueue.isEmpty()) {\n+                    outboundSet.add(outboundQueue.poll());\n+                }\n+\n+                return IterationResult.FETCHED;\n+            });\n+\n+            QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+                stateCallback,\n+                Collections.emptyList(),\n+                exec,\n+                Collections.singletonMap(edgeId, inboundHandler),\n+                Collections.singletonMap(edgeId, Collections.singletonMap(callerId, outboundHandler)),\n+                pool\n+            );\n+\n+            assertEquals(1, fragmentExecutable.getInboxEdgeIds().size());\n+            assertEquals(1, fragmentExecutable.getOutboxEdgeIds().size());\n+            assertEquals(edgeId, (int) fragmentExecutable.getInboxEdgeIds().iterator().next());\n+            assertEquals(edgeId, (int) fragmentExecutable.getOutboxEdgeIds().iterator().next());\n+\n+            // Start threads and wait for completion.\n+            int operationCount = 10_000;\n+            int threadCount = 8;\n+\n+            AtomicInteger doneOperationCount = new AtomicInteger();\n+            CountDownLatch doneLatch = new CountDownLatch(threadCount);\n+\n+            Runnable run = () -> {\n+                try {\n+                    while (true) {\n+                        int counter = doneOperationCount.getAndIncrement();\n+\n+                        if (counter >= operationCount) {\n+                            break;\n+                        }\n+\n+                        QueryAbstractExchangeOperation operation;\n+\n+                        if (ThreadLocalRandom.current().nextBoolean()) {\n+                            operation = new QueryBatchExchangeOperation(queryId, edgeId, EmptyRowBatch.INSTANCE, false, counter);\n+                        } else {\n+                            operation = new QueryFlowControlExchangeOperation(queryId, edgeId, counter);\n+                        }\n+\n+                        operation.setCallerId(callerId);\n+\n+                        fragmentExecutable.addOperation(operation);\n+                        fragmentExecutable.schedule();\n+                    }\n+                } finally {\n+                    doneLatch.countDown();\n+                }\n+            };\n+\n+            for (int j = 0; j < threadCount; j++) {\n+                new Thread(run).start();\n+            }\n+\n+            doneLatch.await();\n+\n+            // Make sure that all batches were drained.\n+            assertTrueEventually(() -> assertTrue(inboundQueue.isEmpty()));\n+            assertTrueEventually(() -> assertTrue(outboundQueue.isEmpty()));\n+\n+            // Make sure that the executor observed all batches.\n+            assertTrueEventually(() -> assertEquals(operationCount, inboundSet.size() + outboundSet.size()));\n+        }\n+    }\n+\n+    /**\n+     * Test that ensures propagation of cancel.\n+     */\n+    @Test\n+    public void testShutdown() throws Exception {\n+        pool = createPool();\n+\n+        TestStateCallback stateCallback = new TestStateCallback();\n+        TestExec exec = new TestExec();\n+\n+        QueryFragmentExecutable fragmentExecutable = new QueryFragmentExecutable(\n+            stateCallback,\n+            Collections.emptyList(),\n+            exec,\n+            Collections.emptyMap(),\n+            Collections.emptyMap(),\n+            pool\n+        );\n+\n+        CountDownLatch startLatch = new CountDownLatch(1);\n+        CountDownLatch blockLatch = new CountDownLatch(1);\n+        AtomicBoolean interruptCaught = new AtomicBoolean();\n+\n+        exec.setPayload(() -> {\n+            startLatch.countDown();\n+\n+            try {\n+                blockLatch.await();\n+            } catch (InterruptedException e) {\n+                interruptCaught.set(true);\n+\n+                Thread.currentThread().interrupt();\n+\n+                throw e;\n+            }\n+\n+            return IterationResult.FETCHED;\n+        });\n+\n+        // Await exec is reached.\n+        assertTrue(fragmentExecutable.schedule());\n+        startLatch.await();", "originalCommit": "5f5e1c9a28091110ce12f774f18fd2d4dfcb7dcb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk5MzkzMQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r399993931", "bodyText": "Likewise, this latch doesn't test any assumptions. Instead, it just positions the threads at proper source code lines.", "author": "devozerov", "createdAt": "2020-03-30T07:56:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTk4Mjc2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDA4ODgyMQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r400088821", "bodyText": "Not 100% sure, but looks like the test doesn't assert the order of operations, it asserts only that they were executed on the same thread. The order guarantee is essential for the pool, so it makes sense to verify it directly.", "author": "taburet", "createdAt": "2020-03-30T10:32:59Z", "path": "hazelcast/src/test/java/com/hazelcast/sql/impl/worker/QueryOperationWorkerPoolTest.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.worker;\n+\n+import com.hazelcast.internal.nio.Packet;\n+import com.hazelcast.internal.serialization.impl.DefaultSerializationServiceBuilder;\n+import com.hazelcast.logging.NoLogFactory;\n+import com.hazelcast.nio.ObjectDataInput;\n+import com.hazelcast.nio.ObjectDataOutput;\n+import com.hazelcast.nio.serialization.DataSerializable;\n+import com.hazelcast.sql.SqlErrorCode;\n+import com.hazelcast.sql.impl.QueryId;\n+import com.hazelcast.sql.impl.operation.QueryBatchExchangeOperation;\n+import com.hazelcast.sql.impl.operation.QueryCancelOperation;\n+import com.hazelcast.sql.impl.operation.QueryExecuteOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperation;\n+import com.hazelcast.sql.impl.operation.QueryOperationHandler;\n+import com.hazelcast.sql.impl.row.HeapRow;\n+import com.hazelcast.sql.impl.row.ListRowBatch;\n+import com.hazelcast.test.HazelcastParallelClassRunner;\n+import com.hazelcast.test.HazelcastTestSupport;\n+import com.hazelcast.test.annotation.ParallelJVMTest;\n+import com.hazelcast.test.annotation.QuickTest;\n+import org.junit.After;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.runner.RunWith;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertSame;\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(HazelcastParallelClassRunner.class)\n+@Category({QuickTest.class, ParallelJVMTest.class})\n+public class QueryOperationWorkerPoolTest extends HazelcastTestSupport {\n+\n+    private static final int THREAD_COUNT = 4;\n+\n+    private QueryOperationWorkerPool pool;\n+\n+    @After\n+    public void after() {\n+        if (pool != null) {\n+            pool.stop();\n+\n+            pool = null;\n+        }\n+    }\n+\n+    @Test\n+    public void testSubmitLocal() {", "originalCommit": "aa9606f6a17c5a1df5f735431282d4989d9c5e4c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDM2NTg5MA==", "url": "https://github.com/hazelcast/hazelcast/pull/16806#discussion_r400365890", "bodyText": "Improved the tests to check for order.", "author": "devozerov", "createdAt": "2020-03-30T17:26:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDA4ODgyMQ=="}], "type": "inlineReview"}, {"oid": "d5d751e9d2043c05df70f7af9563e38dc341e103", "url": "https://github.com/hazelcast/hazelcast/commit/d5d751e9d2043c05df70f7af9563e38dc341e103", "message": "Improved test.", "committedDate": "2020-03-30T17:25:53Z", "type": "commit"}]}