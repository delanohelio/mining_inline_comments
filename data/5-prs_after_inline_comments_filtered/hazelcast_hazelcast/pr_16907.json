{"pr_number": 16907, "pr_title": "SQL: IMap scan operator", "pr_createdAt": "2020-04-21T06:23:39Z", "pr_url": "https://github.com/hazelcast/hazelcast/pull/16907", "timeline": [{"oid": "8a3719490c15ab27a799d8dd0a2a6ad882d76a1a", "url": "https://github.com/hazelcast/hazelcast/commit/8a3719490c15ab27a799d8dd0a2a6ad882d76a1a", "message": "Implemented MapScanExec operator", "committedDate": "2020-04-21T06:12:27Z", "type": "commit"}, {"oid": "3d4ba9286d2c0766e063622d2c0e61216f1f3256", "url": "https://github.com/hazelcast/hazelcast/commit/3d4ba9286d2c0766e063622d2c0e61216f1f3256", "message": "Missing change.", "committedDate": "2020-04-21T06:24:20Z", "type": "commit"}, {"oid": "153a251e623f3e8e4cc5595d69129a8fef2b8af8", "url": "https://github.com/hazelcast/hazelcast/commit/153a251e623f3e8e4cc5595d69129a8fef2b8af8", "message": "Minors.", "committedDate": "2020-04-21T06:25:25Z", "type": "commit"}, {"oid": "0e7ea56a747919a6afc4ec1b2d600fed7c161130", "url": "https://github.com/hazelcast/hazelcast/commit/0e7ea56a747919a6afc4ec1b2d600fed7c161130", "message": "Avoid creation of record stores during iteration.", "committedDate": "2020-04-21T06:34:02Z", "type": "commit"}, {"oid": "d893d2d35bb30ecae40e6a2e0a243965c354735e", "url": "https://github.com/hazelcast/hazelcast/commit/d893d2d35bb30ecae40e6a2e0a243965c354735e", "message": "Fixed SpotBugs.", "committedDate": "2020-04-21T11:49:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjgxMTMzMQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412811331", "bodyText": "Looks like the same can be achieved with RecordStore.getStorage().mutationTolerantIterator(), it's also clearly indicates what kind of iterator we are getting.", "author": "taburet", "createdAt": "2020-04-22T09:11:47Z", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/recordstore/RecordStore.java", "diffHunk": "@@ -292,6 +294,8 @@ boolean merge(MapMergeTypes<Object, Object> mergingEntry,\n \n     void forEach(BiConsumer<Data, Record> consumer, boolean backup, boolean includeExpiredRecords);\n \n+    Iterator<Map.Entry<Data, Record>> iterator();", "originalCommit": "d893d2d35bb30ecae40e6a2e0a243965c354735e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg1MjQ5MA==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412852490", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-04-22T10:11:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjgxMTMzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjgxMzM1Ng==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412813356", "bodyText": "getService().getMapServiceContext()?", "author": "taburet", "createdAt": "2020-04-22T09:14:48Z", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/proxy/MapProxySupport.java", "diffHunk": "@@ -1379,6 +1379,10 @@ protected void handleHazelcastInstanceAwareParams(Object... objects) {\n         }\n     }\n \n+    public MapServiceContext getMapServiceContext() {", "originalCommit": "d893d2d35bb30ecae40e6a2e0a243965c354735e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg1MjM5Ng==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412852396", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-04-22T10:10:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjgxMzM1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjgxNDQ0NQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412814445", "bodyText": "typo: isDestroyed", "author": "taburet", "createdAt": "2020-04-22T09:16:15Z", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/MapContainer.java", "diffHunk": "@@ -390,10 +393,22 @@ public InterceptorRegistry getInterceptorRegistry() {\n         return interceptorRegistry;\n     }\n \n+    /**\n+     * Callback invoked before record store and indexes are destroyed. Ensures that if map iterator observes a non-destroyed\n+     * state, then associated data structures are still valid.\n+     */\n+    public void onBeforeDestroy() {\n+        destroyed = true;\n+    }\n+\n     // callback called when the MapContainer is de-registered from MapService and destroyed - basically on map-destroy\n     public void onDestroy() {\n     }\n \n+    public boolean isDestoyed() {", "originalCommit": "d893d2d35bb30ecae40e6a2e0a243965c354735e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg1MjMyOQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412852329", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-04-22T10:10:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjgxNDQ0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjgzNTM2Mw==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412835363", "bodyText": "Minor: it would be \"cleaner\" to do the hasNext check before checking for migration stamp and destruction. It's not clear from the contract does the hasNext interact with the underlying store or not (which potentially can be destroyed or migrated).", "author": "taburet", "createdAt": "2020-04-22T09:46:14Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/MapScanExec.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec.scan;\n+\n+import com.hazelcast.internal.serialization.InternalSerializationService;\n+import com.hazelcast.internal.util.collection.PartitionIdSet;\n+import com.hazelcast.map.impl.MapContainer;\n+import com.hazelcast.query.impl.getters.Extractors;\n+import com.hazelcast.sql.SqlErrorCode;\n+import com.hazelcast.sql.impl.QueryException;\n+import com.hazelcast.sql.impl.exec.IterationResult;\n+import com.hazelcast.sql.impl.expression.Expression;\n+import com.hazelcast.sql.impl.extract.QueryTargetDescriptor;\n+import com.hazelcast.sql.impl.row.HeapRow;\n+import com.hazelcast.sql.impl.row.ListRowBatch;\n+import com.hazelcast.sql.impl.row.Row;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import com.hazelcast.sql.impl.worker.QueryFragmentContext;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Executor for map scan.\n+ */\n+public class MapScanExec extends AbstractMapScanExec {\n+    /** Batch size. To be moved outside when the memory management is ready. */\n+    static final int BATCH_SIZE = 1024;\n+\n+    private final MapContainer map;\n+    private final PartitionIdSet partitions;\n+\n+    private int migrationStamp;\n+    private MapScanExecIterator recordIterator;\n+\n+    private List<Row> currentRows;\n+\n+    public MapScanExec(\n+        int id,\n+        MapContainer map,\n+        PartitionIdSet partitions,\n+        QueryTargetDescriptor keyDescriptor,\n+        QueryTargetDescriptor valueDescriptor,\n+        List<String> fieldNames,\n+        List<QueryDataType> fieldTypes,\n+        List<Integer> projects,\n+        Expression<Boolean> filter,\n+        InternalSerializationService serializationService\n+    ) {\n+        super(id, map.getName(), keyDescriptor, valueDescriptor, fieldNames, fieldTypes, projects, filter, serializationService);\n+\n+        this.map = map;\n+        this.partitions = partitions;\n+    }\n+\n+    @Override\n+    protected void setup1(QueryFragmentContext ctx) {\n+        migrationStamp = map.getMapServiceContext().getService().getMigrationStamp();\n+        recordIterator = MapScanExecUtils.createIterator(map, partitions);\n+    }\n+\n+    @Override\n+    public IterationResult advance0() {\n+        currentRows = null;\n+\n+        while (recordIterator.tryAdvance()) {\n+            HeapRow row = prepareRow(recordIterator.getKey(), recordIterator.getValue());\n+\n+            if (row != null) {\n+                if (currentRows == null) {\n+                    currentRows = new ArrayList<>(BATCH_SIZE);\n+                }\n+\n+                currentRows.add(row);\n+\n+                if (currentRows.size() == BATCH_SIZE) {\n+                    break;\n+                }\n+            }\n+        }\n+\n+        // Check for concurrent migration\n+        if (!map.getMapServiceContext().getService().validateMigrationStamp(migrationStamp)) {\n+            throw QueryException.error(SqlErrorCode.PARTITION_MIGRATED, \"Map scan failed due to concurrent partition migration \"\n+                + \"(result consistency cannot be guaranteed)\");\n+        }\n+\n+        // Check for concurrent map destroy\n+        if (map.isDestoyed()) {\n+            throw QueryException.error(SqlErrorCode.MAP_DESTROYED, \"IMap has been destroyed concurrently: \" + mapName);\n+        }\n+\n+        boolean done = !recordIterator.hasNext();", "originalCommit": "d893d2d35bb30ecae40e6a2e0a243965c354735e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg1MjI3Mw==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412852273", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-04-22T10:10:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjgzNTM2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTQ3Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412849477", "bodyText": "map.getMapServiceContext().getExistingRecordStore(partitionId, map.getName())? It might be ugly, but otherwise we will duplicate all MapServiceContext methods in MapContainer sooner or later.", "author": "taburet", "createdAt": "2020-04-22T10:06:32Z", "path": "hazelcast/src/main/java/com/hazelcast/map/impl/MapContainer.java", "diffHunk": "@@ -422,6 +437,10 @@ public boolean isPersistWanReplicatedData() {\n         return persistWanReplicatedData;\n     }\n \n+    public RecordStore<?> getExistingRecordStore(int partitionId) {", "originalCommit": "d893d2d35bb30ecae40e6a2e0a243965c354735e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg1MTUzMg==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412851532", "bodyText": "It's just a convenient shortcut. What is the harm of having it?", "author": "devozerov", "createdAt": "2020-04-22T10:09:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTQ3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2MDgxNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412860814", "bodyText": "Because sooner or later that would lead to all MapServiceContext methods duplicated in MapContainer. Currently, there are no methods in MapContainer working with record stores, all such methods are located in MapServiceContext.", "author": "taburet", "createdAt": "2020-04-22T10:23:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTQ3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg2NDQyNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412864426", "bodyText": "getIndexes and getIndexDefinitions do almost the same - get partition container, then some field from it. I honestly do not see any problem with it. It just provides a convenience instead of passing the name form the outside.", "author": "devozerov", "createdAt": "2020-04-22T10:29:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTQ3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjkwNzgxNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412907816", "bodyText": "Indexes is a different story, global ones are managed by MapContainer while stores are not managed by MapContainer. I do see a problem, but it's up to you.", "author": "taburet", "createdAt": "2020-04-22T11:41:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTQ3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE4OTc2Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413189767", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-04-22T17:47:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg0OTQ3Nw=="}], "type": "inlineReview"}, {"oid": "9df077c8d02824f5f26d1ff1407aeba3293d3621", "url": "https://github.com/hazelcast/hazelcast/commit/9df077c8d02824f5f26d1ff1407aeba3293d3621", "message": "Review comments.", "committedDate": "2020-04-22T10:10:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg3OTM2Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412879362", "bodyText": "AFAIU, until all involved record stores are loaded, queries (or some parts of them?) would fail with RetryableHazelcastException. Not sure how RetryableHazelcastException is handled for SQL operations, but there are automatic retries for others. Looks like we need to check the possible \"side effects\" here.", "author": "taburet", "createdAt": "2020-04-22T10:53:56Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/MapScanExecIterator.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec.scan;\n+\n+import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.util.Clock;\n+import com.hazelcast.map.impl.MapContainer;\n+import com.hazelcast.map.impl.record.Record;\n+import com.hazelcast.map.impl.recordstore.RecordStore;\n+import com.hazelcast.sql.SqlErrorCode;\n+import com.hazelcast.sql.impl.QueryException;\n+\n+import java.util.Iterator;\n+import java.util.Map;\n+\n+/**\n+ * Iterator over map partitions..\n+ */\n+@SuppressWarnings(\"rawtypes\")\n+public class MapScanExecIterator {\n+\n+    private final MapContainer map;\n+    private final Iterator<Integer> partsIterator;\n+    private final long now = Clock.currentTimeMillis();\n+\n+    private RecordStore currentRecordStore;\n+    private Iterator<Map.Entry<Data, Record<Object>>> currentRecordStoreIterator;\n+\n+    private Data currentKey;\n+    private Object currentValue;\n+    private Data nextKey;\n+    private Object nextValue;\n+\n+    public MapScanExecIterator(MapContainer map, Iterator<Integer> partsIterator) {\n+        this.map = map;\n+        this.partsIterator = partsIterator;\n+\n+        advance0();\n+    }\n+\n+    public boolean tryAdvance() {\n+        if (hasNext()) {\n+            currentKey = nextKey;\n+            currentValue = nextValue;\n+\n+            advance0();\n+\n+            return true;\n+        } else {\n+            return false;\n+        }\n+    }\n+\n+    public boolean hasNext() {\n+        return nextKey != null;\n+    }\n+\n+    /**\n+     * Get the next key/value pair from the store.\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    private void advance0() {\n+        while (true) {\n+            // Move to the next record store if needed.\n+            if (currentRecordStoreIterator == null) {\n+                if (!partsIterator.hasNext()) {\n+                    nextKey = null;\n+                    nextValue = null;\n+\n+                    return;\n+                } else {\n+                    int nextPart = partsIterator.next();\n+\n+                    boolean isOwned = map.getMapServiceContext().getOwnedPartitions().contains(nextPart);\n+\n+                    if (!isOwned) {\n+                        throw QueryException.error(SqlErrorCode.PARTITION_MIGRATED,\n+                            \"Partition is not owned by member: \" + nextPart);\n+                    }\n+\n+                    currentRecordStore = map.getExistingRecordStore(nextPart);\n+\n+                    if (currentRecordStore == null) {\n+                        // RecordStore might be missing if the associated partition is empty. Just skip it.\n+                        continue;\n+                    }\n+\n+                    currentRecordStore.checkIfLoaded();", "originalCommit": "9df077c8d02824f5f26d1ff1407aeba3293d3621", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjkxNzY3Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412917672", "bodyText": "I'll take a look at it. Perhaps, a separate error code is needed here. Note that naive \"retriable\" semantics from the rest of HZ is not applicable here, because some data might already be returned to the user. So for the moment, I will only throw a special error code, and in the future we will have transparent retries when possible as explained in the PR description.", "author": "devozerov", "createdAt": "2020-04-22T11:58:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg3OTM2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjkyMjMyNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412922324", "bodyText": "Probably that's not a problem after all: in theory, all exceptions should be wrapped into QueryException and it's not marked as retryable.", "author": "taburet", "createdAt": "2020-04-22T12:05:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg3OTM2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzAxMTMzMQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413011331", "bodyText": "Yes, but here I lose the root cause - it is reported as GENERIC error. A separate error code is important here because this condition is potentially retriable. I'd better fix it now.", "author": "devozerov", "createdAt": "2020-04-22T14:03:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg3OTM2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE4OTg5NA==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413189894", "bodyText": "Added a separate error code.", "author": "devozerov", "createdAt": "2020-04-22T17:47:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg3OTM2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYxMjg3Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413612877", "bodyText": "Just some afterthoughts: in theory, we can even \"recover\" from such situations since we still didn't send any data for the partition in question, so it's safe to return IterationResult.WAIT.", "author": "taburet", "createdAt": "2020-04-23T08:22:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg3OTM2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYxNTE0OA==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413615148", "bodyText": "This is dangerous - we do not know how much time the loading will take. So from the user standpoint, it may look like a hang.", "author": "devozerov", "createdAt": "2020-04-23T08:25:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjg3OTM2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjkwMTIxNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412901216", "bodyText": "What does \"generic\" means in extractors context? Looks like all extractors are generic now.", "author": "taburet", "createdAt": "2020-04-22T11:31:17Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/extract/AbstractGenericExtractor.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.extract;\n+\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+\n+/**\n+ * Base class for generic extractors.", "originalCommit": "9df077c8d02824f5f26d1ff1407aeba3293d3621", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjkxOTcyMw==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r412919723", "bodyText": "The idea is that is uses Extractors, capable of extracting data from any underlying object. In the prototype branches (sql and sql-compiler) we have other extractor implementations that either use reflection or cached PortableReader. It is not very clear how we are going to organize it in the end, until we try to cover different edge cases for Java classes, portables, and perhaps the new serialization formats. This is a separate task.", "author": "devozerov", "createdAt": "2020-04-22T12:01:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjkwMTIxNg=="}], "type": "inlineReview"}, {"oid": "fb089e246c1af96c47ebc88b10438592c3200ece", "url": "https://github.com/hazelcast/hazelcast/commit/fb089e246c1af96c47ebc88b10438592c3200ece", "message": "Merge branch 'master' into issues/16906\n\n# Conflicts:\n#\thazelcast/src/main/java/com/hazelcast/sql/impl/SqlDataSerializerHook.java\n#\thazelcast/src/main/java/com/hazelcast/sql/impl/exec/CreateExecPlanNodeVisitor.java\n#\thazelcast/src/main/java/com/hazelcast/sql/impl/plan/node/PlanNodeVisitor.java\n#\thazelcast/src/test/java/com/hazelcast/sql/impl/exec/CreateExecPlanNodeVisitorTest.java\n#\thazelcast/src/test/java/com/hazelcast/sql/impl/plan/node/TestPlanNodeVisitorAdapter.java", "committedDate": "2020-04-22T17:39:56Z", "type": "commit"}, {"oid": "e846b698c8d94f3bfb08dbdbc33e86e4da0b6723", "url": "https://github.com/hazelcast/hazelcast/commit/e846b698c8d94f3bfb08dbdbc33e86e4da0b6723", "message": "Merge with master.", "committedDate": "2020-04-22T17:41:36Z", "type": "commit"}, {"oid": "96d91e014a9e309e96b4355cc4f2502ab4979122", "url": "https://github.com/hazelcast/hazelcast/commit/96d91e014a9e309e96b4355cc4f2502ab4979122", "message": "Special error for map loading.", "committedDate": "2020-04-22T17:44:19Z", "type": "commit"}, {"oid": "ad8108963951a7a0af1decfc0ee289f5dd310e2c", "url": "https://github.com/hazelcast/hazelcast/commit/ad8108963951a7a0af1decfc0ee289f5dd310e2c", "message": "Review comments.", "committedDate": "2020-04-22T17:46:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg0MTQ5Mw==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413841493", "bodyText": "Minor typo: ..", "author": "petrpleshachkov", "createdAt": "2020-04-23T14:25:24Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/MapScanExecIterator.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec.scan;\n+\n+import com.hazelcast.internal.serialization.Data;\n+import com.hazelcast.internal.util.Clock;\n+import com.hazelcast.map.impl.MapContainer;\n+import com.hazelcast.map.impl.record.Record;\n+import com.hazelcast.map.impl.recordstore.RecordStore;\n+import com.hazelcast.spi.exception.RetryableHazelcastException;\n+import com.hazelcast.sql.SqlErrorCode;\n+import com.hazelcast.sql.impl.QueryException;\n+\n+import java.util.Iterator;\n+import java.util.Map;\n+\n+/**\n+ * Iterator over map partitions..", "originalCommit": "ad8108963951a7a0af1decfc0ee289f5dd310e2c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg5NTU0OQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413895549", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-04-23T15:27:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg0MTQ5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg1MjQyMg==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413852422", "bodyText": "In the old query engine we checked the migration timestamp for the whole resultSet and failed the query if the validation failed. In the new engine we rely on the iterative model, so that we may pass a portion of results to the application and it will process it. And then suddenly we throw this exception. What user can do with it? It already has processed some query results and made some critical decisions and cannot rollback that.", "author": "petrpleshachkov", "createdAt": "2020-04-23T14:37:57Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/scan/MapScanExec.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec.scan;\n+\n+import com.hazelcast.internal.serialization.InternalSerializationService;\n+import com.hazelcast.internal.util.collection.PartitionIdSet;\n+import com.hazelcast.map.impl.MapContainer;\n+import com.hazelcast.query.impl.getters.Extractors;\n+import com.hazelcast.sql.SqlErrorCode;\n+import com.hazelcast.sql.impl.QueryException;\n+import com.hazelcast.sql.impl.exec.IterationResult;\n+import com.hazelcast.sql.impl.expression.Expression;\n+import com.hazelcast.sql.impl.extract.QueryTargetDescriptor;\n+import com.hazelcast.sql.impl.row.HeapRow;\n+import com.hazelcast.sql.impl.row.ListRowBatch;\n+import com.hazelcast.sql.impl.row.Row;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import com.hazelcast.sql.impl.worker.QueryFragmentContext;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Executor for map scan.\n+ */\n+public class MapScanExec extends AbstractMapScanExec {\n+    /** Batch size. To be moved outside when the memory management is ready. */\n+    static final int BATCH_SIZE = 1024;\n+\n+    private final MapContainer map;\n+    private final PartitionIdSet partitions;\n+\n+    private int migrationStamp;\n+    private MapScanExecIterator recordIterator;\n+\n+    private List<Row> currentRows;\n+\n+    public MapScanExec(\n+        int id,\n+        MapContainer map,\n+        PartitionIdSet partitions,\n+        QueryTargetDescriptor keyDescriptor,\n+        QueryTargetDescriptor valueDescriptor,\n+        List<String> fieldNames,\n+        List<QueryDataType> fieldTypes,\n+        List<Integer> projects,\n+        Expression<Boolean> filter,\n+        InternalSerializationService serializationService\n+    ) {\n+        super(id, map.getName(), keyDescriptor, valueDescriptor, fieldNames, fieldTypes, projects, filter, serializationService);\n+\n+        this.map = map;\n+        this.partitions = partitions;\n+    }\n+\n+    @Override\n+    protected void setup1(QueryFragmentContext ctx) {\n+        migrationStamp = map.getMapServiceContext().getService().getMigrationStamp();\n+        recordIterator = MapScanExecUtils.createIterator(map, partitions);\n+    }\n+\n+    @Override\n+    public IterationResult advance0() {\n+        currentRows = null;\n+\n+        while (recordIterator.tryAdvance()) {\n+            HeapRow row = prepareRow(recordIterator.getKey(), recordIterator.getValue());\n+\n+            if (row != null) {\n+                if (currentRows == null) {\n+                    currentRows = new ArrayList<>(BATCH_SIZE);\n+                }\n+\n+                currentRows.add(row);\n+\n+                if (currentRows.size() == BATCH_SIZE) {\n+                    break;\n+                }\n+            }\n+        }\n+\n+        boolean done = !recordIterator.hasNext();\n+\n+        // Check for concurrent migration\n+        if (!map.getMapServiceContext().getService().validateMigrationStamp(migrationStamp)) {", "originalCommit": "ad8108963951a7a0af1decfc0ee289f5dd310e2c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg4MzAwNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16907#discussion_r413883006", "bodyText": "We cannot do anything about it - this is the fundamental problem of any distributed system. Consider a single Postgres server + an application talking to it through JDBC. The network glitches, the query is canceled - the is no way to recover from it unless you have some sort of persistence for intermediate results, which is not the case for our engine.\nIf it is important, then the application must adopt somehow - either read the whole result set or use ORDER BY + parameter for offset, or persist the results like it is done in streaming exactly-once, etc. This depends on application needs.", "author": "devozerov", "createdAt": "2020-04-23T15:12:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzg1MjQyMg=="}], "type": "inlineReview"}, {"oid": "4bc21f05dce49b5bc45bd8e7cbac3e6120431bf5", "url": "https://github.com/hazelcast/hazelcast/commit/4bc21f05dce49b5bc45bd8e7cbac3e6120431bf5", "message": "Typo.", "committedDate": "2020-04-23T15:27:05Z", "type": "commit"}]}