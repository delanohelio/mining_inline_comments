{"pr_number": 11422, "pr_title": "Add a HDFS throughput testing tool", "pr_createdAt": "2020-05-12T16:26:40Z", "pr_url": "https://github.com/Alluxio/alluxio/pull/11422", "timeline": [{"oid": "ec771d4ed48c99001aa39309803e08390605c9a4", "url": "https://github.com/Alluxio/alluxio/commit/ec771d4ed48c99001aa39309803e08390605c9a4", "message": "use new benchmark framework", "committedDate": "2020-05-12T04:03:47Z", "type": "commit"}, {"oid": "1e6fa01f8101b493fda23bccc663f6c4ec37c94e", "url": "https://github.com/Alluxio/alluxio/commit/1e6fa01f8101b493fda23bccc663f6c4ec37c94e", "message": "nothings works but it compiles", "committedDate": "2020-05-12T15:20:33Z", "type": "commit"}, {"oid": "1c668b965c4484a8441b98c912f2e1d7cb87efbf", "url": "https://github.com/Alluxio/alluxio/commit/1c668b965c4484a8441b98c912f2e1d7cb87efbf", "message": "pre-test", "committedDate": "2020-05-13T03:04:23Z", "type": "commit"}, {"oid": "54f46b27076424ba986e217cd19857ffc53f7c27", "url": "https://github.com/Alluxio/alluxio/commit/54f46b27076424ba986e217cd19857ffc53f7c27", "message": "adding unit tests", "committedDate": "2020-05-14T14:05:15Z", "type": "commit"}, {"oid": "9c2d1466a4b3ad60da0f68d7ecb78418374ec6d5", "url": "https://github.com/Alluxio/alluxio/commit/9c2d1466a4b3ad60da0f68d7ecb78418374ec6d5", "message": "debug log", "committedDate": "2020-05-15T04:36:16Z", "type": "commit"}, {"oid": "cfbdac466105bd6f692b818895ae2fad1dff0277", "url": "https://github.com/Alluxio/alluxio/commit/cfbdac466105bd6f692b818895ae2fad1dff0277", "message": "debug log", "committedDate": "2020-05-15T04:47:46Z", "type": "commit"}, {"oid": "e6c4d88df0da003efd18358e09996d74fc578c9b", "url": "https://github.com/Alluxio/alluxio/commit/e6c4d88df0da003efd18358e09996d74fc578c9b", "message": "add main()", "committedDate": "2020-05-15T05:12:05Z", "type": "commit"}, {"oid": "756b78869c0a3b45d5e7969bde10cd9620cea091", "url": "https://github.com/Alluxio/alluxio/commit/756b78869c0a3b45d5e7969bde10cd9620cea091", "message": "ufs api", "committedDate": "2020-05-15T05:32:38Z", "type": "commit"}, {"oid": "6810ad9cd34cdd0186192bb27634b38d84e1b896", "url": "https://github.com/Alluxio/alluxio/commit/6810ad9cd34cdd0186192bb27634b38d84e1b896", "message": "change to ufs path", "committedDate": "2020-05-15T06:26:52Z", "type": "commit"}, {"oid": "67afdfcc388deea6195f7cbc832d9502482d8fde", "url": "https://github.com/Alluxio/alluxio/commit/67afdfcc388deea6195f7cbc832d9502482d8fde", "message": "add logging", "committedDate": "2020-05-16T12:55:51Z", "type": "commit"}, {"oid": "1fa0e2e96cc217723d2911069d40531da54718fb", "url": "https://github.com/Alluxio/alluxio/commit/1fa0e2e96cc217723d2911069d40531da54718fb", "message": "fix errs", "committedDate": "2020-05-16T13:00:52Z", "type": "commit"}, {"oid": "578cddf409afeaa1621d5628ea142048e803ee5f", "url": "https://github.com/Alluxio/alluxio/commit/578cddf409afeaa1621d5628ea142048e803ee5f", "message": "add logging", "committedDate": "2020-05-16T13:21:00Z", "type": "commit"}, {"oid": "2ab6325d338a06de2aadb0a798753e824168a578", "url": "https://github.com/Alluxio/alluxio/commit/2ab6325d338a06de2aadb0a798753e824168a578", "message": "err log", "committedDate": "2020-05-16T13:29:51Z", "type": "commit"}, {"oid": "ea9ccb0e6c75bf760c4b20320ca193205f9d7065", "url": "https://github.com/Alluxio/alluxio/commit/ea9ccb0e6c75bf760c4b20320ca193205f9d7065", "message": "hdfs debug logging", "committedDate": "2020-05-17T11:04:51Z", "type": "commit"}, {"oid": "9f6304b789026e2ca447e034323b251ffe9a1f92", "url": "https://github.com/Alluxio/alluxio/commit/9f6304b789026e2ca447e034323b251ffe9a1f92", "message": "is path format wrong?", "committedDate": "2020-05-17T11:40:33Z", "type": "commit"}, {"oid": "43b68348c6875dd1608142ba1f4b4f6ea5758f06", "url": "https://github.com/Alluxio/alluxio/commit/43b68348c6875dd1608142ba1f4b4f6ea5758f06", "message": "grammar", "committedDate": "2020-05-17T11:45:26Z", "type": "commit"}, {"oid": "545de97f833b68a4dc0b827fa3fabd015e93e1b0", "url": "https://github.com/Alluxio/alluxio/commit/545de97f833b68a4dc0b827fa3fabd015e93e1b0", "message": "flushing", "committedDate": "2020-05-17T12:11:31Z", "type": "commit"}, {"oid": "4ecbf6cb23c4a3408cf3211e88c70c6514e8d4d8", "url": "https://github.com/Alluxio/alluxio/commit/4ecbf6cb23c4a3408cf3211e88c70c6514e8d4d8", "message": "read()", "committedDate": "2020-05-17T12:26:59Z", "type": "commit"}, {"oid": "9c14361878dd54a94682022a772dd9b41a60c5c6", "url": "https://github.com/Alluxio/alluxio/commit/9c14361878dd54a94682022a772dd9b41a60c5c6", "message": "read", "committedDate": "2020-05-17T12:39:02Z", "type": "commit"}, {"oid": "2f6eb896bd18b32b8fc755e3c01ec6067dee8deb", "url": "https://github.com/Alluxio/alluxio/commit/2f6eb896bd18b32b8fc755e3c01ec6067dee8deb", "message": "remove READ WRITE mode", "committedDate": "2020-05-18T05:01:37Z", "type": "commit"}, {"oid": "3439a634b1390299edaf6f6562bc78437f31b058", "url": "https://github.com/Alluxio/alluxio/commit/3439a634b1390299edaf6f6562bc78437f31b058", "message": "update class", "committedDate": "2020-05-18T05:22:46Z", "type": "commit"}, {"oid": "55550be1cdd6de2da055f03756690870a70fdf81", "url": "https://github.com/Alluxio/alluxio/commit/55550be1cdd6de2da055f03756690870a70fdf81", "message": "task summary", "committedDate": "2020-05-18T07:28:02Z", "type": "commit"}, {"oid": "343d5d96efc2d0a26fa9c1d4ca5f6d6231662b96", "url": "https://github.com/Alluxio/alluxio/commit/343d5d96efc2d0a26fa9c1d4ca5f6d6231662b96", "message": "serialization", "committedDate": "2020-05-18T08:03:28Z", "type": "commit"}, {"oid": "d77f20d8f07cd44f978a321660d9485ced81a4aa", "url": "https://github.com/Alluxio/alluxio/commit/d77f20d8f07cd44f978a321660d9485ced81a4aa", "message": "add IODefinition", "committedDate": "2020-05-18T08:14:02Z", "type": "commit"}, {"oid": "6dcdebc646a2562d62c98e734c071f4c8e5bd547", "url": "https://github.com/Alluxio/alluxio/commit/6dcdebc646a2562d62c98e734c071f4c8e5bd547", "message": "parse job output", "committedDate": "2020-05-18T08:27:27Z", "type": "commit"}, {"oid": "8b5e9ab30d8eda4e3c26d9e19e5e83e5ce42d1eb", "url": "https://github.com/Alluxio/alluxio/commit/8b5e9ab30d8eda4e3c26d9e19e5e83e5ce42d1eb", "message": "better stats calculation", "committedDate": "2020-05-18T10:18:22Z", "type": "commit"}, {"oid": "98758ffd75b3f9bad9ebe3b166601ddc50bc633a", "url": "https://github.com/Alluxio/alluxio/commit/98758ffd75b3f9bad9ebe3b166601ddc50bc633a", "message": "better stat formatting", "committedDate": "2020-05-18T14:46:15Z", "type": "commit"}, {"oid": "10aec84f7ec8a13106e1431cd990da18edadf8cc", "url": "https://github.com/Alluxio/alluxio/commit/10aec84f7ec8a13106e1431cd990da18edadf8cc", "message": "add graph", "committedDate": "2020-05-19T07:51:11Z", "type": "commit"}, {"oid": "e23643495696dbe4af42ab404f55d0601f5eb06a", "url": "https://github.com/Alluxio/alluxio/commit/e23643495696dbe4af42ab404f55d0601f5eb06a", "message": "fix stat error", "committedDate": "2020-05-19T08:53:36Z", "type": "commit"}, {"oid": "91f1b78b2fd92653352595b4728e863bd8ba870d", "url": "https://github.com/Alluxio/alluxio/commit/91f1b78b2fd92653352595b4728e863bd8ba870d", "message": "deserialize IOTaskSummary", "committedDate": "2020-05-19T10:36:59Z", "type": "commit"}, {"oid": "a11eaec3a4c1f627b39a1df5c20f466fa233a092", "url": "https://github.com/Alluxio/alluxio/commit/a11eaec3a4c1f627b39a1df5c20f466fa233a092", "message": "better graph", "committedDate": "2020-05-19T12:18:26Z", "type": "commit"}, {"oid": "22b94e94a750d829a5368546c6195408bcbe248d", "url": "https://github.com/Alluxio/alluxio/commit/22b94e94a750d829a5368546c6195408bcbe248d", "message": "checkstyle", "committedDate": "2020-05-19T13:52:03Z", "type": "commit"}, {"oid": "96db45cefbc4383ab6f7c7364639fa2bd6da5592", "url": "https://github.com/Alluxio/alluxio/commit/96db45cefbc4383ab6f7c7364639fa2bd6da5592", "message": "fix deserializer", "committedDate": "2020-05-19T14:00:04Z", "type": "commit"}, {"oid": "ba1b1497ce2cb8171f95fd28fe2406ebd50d42cc", "url": "https://github.com/Alluxio/alluxio/commit/ba1b1497ce2cb8171f95fd28fe2406ebd50d42cc", "message": "static deserializer", "committedDate": "2020-05-19T14:11:08Z", "type": "commit"}, {"oid": "ded15217e52f154ab8d35409041773d361beda73", "url": "https://github.com/Alluxio/alluxio/commit/ded15217e52f154ab8d35409041773d361beda73", "message": "distinguish graph series", "committedDate": "2020-05-19T15:19:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMDUyOA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429500528", "bodyText": "never used?", "author": "madanadit", "createdAt": "2020-05-23T01:09:54Z", "path": "core/common/src/main/java/alluxio/util/CommonUtils.java", "diffHunk": "@@ -191,6 +191,16 @@ public static String getWorkerDataDirectory(String storageDir, AlluxioConfigurat\n     return src.toArray(ret);\n   }\n \n+  /**\n+   * Generates a random integer with the given bound.\n+   *\n+   * @param bound the upper bound\n+   * @return a random int\n+   */\n+  public static int randomInt(int bound) {", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMDkxNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429500915", "bodyText": "why is this in a separate line and what is the value?", "author": "madanadit", "createdAt": "2020-05-23T01:14:37Z", "path": "job/server/src/main/java/alluxio/job/plan/io/IODefinition.java", "diffHunk": "@@ -0,0 +1,123 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.RunTaskContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.PlanDefinition;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.JsonSerializable;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.util.ShellUtils;\n+import alluxio.wire.WorkerInfo;\n+import com.google.common.collect.Sets;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The definition for the UFS I/O throughput job, which generates concurrent streams to the UFS.\n+ *\n+ * {@link IOConfig} is the configuration class, each task takes a List<String> as a list of\n+ * command-line arguments to the benchmark command, and each task returns the string output.\n+ * The output will be serialized and deserialized using JSON, collected and merged.\n+ */\n+public class IODefinition implements PlanDefinition<IOConfig, ArrayList<String>, String> {\n+  private static final Logger LOG = LoggerFactory.getLogger(IODefinition.class);\n+\n+  @Override\n+  public Class<IOConfig> getJobConfigClass() {\n+    return IOConfig.class;\n+  }\n+\n+  @Override\n+  public String join(IOConfig config, Map<WorkerInfo, String> taskResults) throws Exception {\n+    if (taskResults.isEmpty()) {\n+      throw new IOException(\"No results from any workers.\");\n+    }\n+    LOG.info(\"join()\");\n+    for(Map.Entry<WorkerInfo, String> entry : taskResults.entrySet()) {\n+      LOG.info(\"worker={}\", entry.getKey());\n+      LOG.info(\"{}\", entry.getValue());", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTI0Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429501243", "bodyText": "this seems to be almost the same as StressBenchDefinition, can we remove the redundancy?", "author": "madanadit", "createdAt": "2020-05-23T01:18:33Z", "path": "job/server/src/main/java/alluxio/job/plan/io/IODefinition.java", "diffHunk": "@@ -0,0 +1,123 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.RunTaskContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.PlanDefinition;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.JsonSerializable;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.util.ShellUtils;\n+import alluxio.wire.WorkerInfo;\n+import com.google.common.collect.Sets;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The definition for the UFS I/O throughput job, which generates concurrent streams to the UFS.\n+ *\n+ * {@link IOConfig} is the configuration class, each task takes a List<String> as a list of\n+ * command-line arguments to the benchmark command, and each task returns the string output.\n+ * The output will be serialized and deserialized using JSON, collected and merged.\n+ */\n+public class IODefinition implements PlanDefinition<IOConfig, ArrayList<String>, String> {\n+  private static final Logger LOG = LoggerFactory.getLogger(IODefinition.class);\n+\n+  @Override\n+  public Class<IOConfig> getJobConfigClass() {\n+    return IOConfig.class;\n+  }\n+\n+  @Override\n+  public String join(IOConfig config, Map<WorkerInfo, String> taskResults) throws Exception {\n+    if (taskResults.isEmpty()) {\n+      throw new IOException(\"No results from any workers.\");\n+    }\n+    LOG.info(\"join()\");\n+    for(Map.Entry<WorkerInfo, String> entry : taskResults.entrySet()) {\n+      LOG.info(\"worker={}\", entry.getKey());\n+      LOG.info(\"{}\", entry.getValue());\n+    }\n+\n+    AtomicReference<IOException> error = new AtomicReference<>(null);\n+    List<IOTaskResult> results = taskResults.entrySet().stream().map(", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTQxMQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429501411", "bodyText": "nit: combine in the if above as if (cnt-- <= 0)", "author": "madanadit", "createdAt": "2020-05-23T01:20:31Z", "path": "job/server/src/main/java/alluxio/job/plan/io/IODefinition.java", "diffHunk": "@@ -0,0 +1,123 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.RunTaskContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.PlanDefinition;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.JsonSerializable;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.util.ShellUtils;\n+import alluxio.wire.WorkerInfo;\n+import com.google.common.collect.Sets;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The definition for the UFS I/O throughput job, which generates concurrent streams to the UFS.\n+ *\n+ * {@link IOConfig} is the configuration class, each task takes a List<String> as a list of\n+ * command-line arguments to the benchmark command, and each task returns the string output.\n+ * The output will be serialized and deserialized using JSON, collected and merged.\n+ */\n+public class IODefinition implements PlanDefinition<IOConfig, ArrayList<String>, String> {\n+  private static final Logger LOG = LoggerFactory.getLogger(IODefinition.class);\n+\n+  @Override\n+  public Class<IOConfig> getJobConfigClass() {\n+    return IOConfig.class;\n+  }\n+\n+  @Override\n+  public String join(IOConfig config, Map<WorkerInfo, String> taskResults) throws Exception {\n+    if (taskResults.isEmpty()) {\n+      throw new IOException(\"No results from any workers.\");\n+    }\n+    LOG.info(\"join()\");\n+    for(Map.Entry<WorkerInfo, String> entry : taskResults.entrySet()) {\n+      LOG.info(\"worker={}\", entry.getKey());\n+      LOG.info(\"{}\", entry.getValue());\n+    }\n+\n+    AtomicReference<IOException> error = new AtomicReference<>(null);\n+    List<IOTaskResult> results = taskResults.entrySet().stream().map(\n+            entry -> {\n+              try {\n+                return JsonSerializable.fromJson(entry.getValue().trim(), new IOTaskResult[0]);\n+              } catch (IOException | ClassNotFoundException e) {\n+                error.set(new IOException(String\n+                        .format(\"Failed to parse task output from %s into result class\",\n+                                entry.getKey().getAddress().getHost()), e));\n+              }\n+              return null;\n+            }).collect(Collectors.toList());\n+\n+    if (error.get() != null) {\n+      throw error.get();\n+    }\n+\n+    return results.get(0).aggregator().aggregate(results).toJson();\n+  }\n+\n+  @Override\n+  public Set<Pair<WorkerInfo, ArrayList<String>>> selectExecutors(\n+          IOConfig config, List<WorkerInfo> jobWorkerInfoList,\n+          SelectExecutorsContext selectExecutorsContext) throws Exception {\n+    Set<Pair<WorkerInfo, ArrayList<String>>> result = Sets.newHashSet();\n+\n+    // Randomly select N workers\n+    Collections.shuffle(jobWorkerInfoList);\n+    int cnt = config.getWorkerNum();\n+    for (WorkerInfo worker : jobWorkerInfoList) {\n+      if (cnt <= 0) {\n+        break;\n+      }\n+      ArrayList<String> args = new ArrayList<>(2);\n+      // Add the worker hostname + worker id as the unique task id for each distributed task.\n+      // The worker id is used since there may be multiple workers on a single host.\n+      args.add(BaseParameters.ID_FLAG);\n+      args.add(worker.getAddress().getHost() + \"-\" + worker.getId());\n+      result.add(new Pair<>(worker, args));\n+      cnt--;\n+    }", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTQ4Nw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429501487", "bodyText": "this is redundant again, a utility function?", "author": "madanadit", "createdAt": "2020-05-23T01:21:22Z", "path": "job/server/src/main/java/alluxio/job/plan/io/IODefinition.java", "diffHunk": "@@ -0,0 +1,123 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.RunTaskContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.PlanDefinition;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.JsonSerializable;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.util.ShellUtils;\n+import alluxio.wire.WorkerInfo;\n+import com.google.common.collect.Sets;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The definition for the UFS I/O throughput job, which generates concurrent streams to the UFS.\n+ *\n+ * {@link IOConfig} is the configuration class, each task takes a List<String> as a list of\n+ * command-line arguments to the benchmark command, and each task returns the string output.\n+ * The output will be serialized and deserialized using JSON, collected and merged.\n+ */\n+public class IODefinition implements PlanDefinition<IOConfig, ArrayList<String>, String> {\n+  private static final Logger LOG = LoggerFactory.getLogger(IODefinition.class);\n+\n+  @Override\n+  public Class<IOConfig> getJobConfigClass() {\n+    return IOConfig.class;\n+  }\n+\n+  @Override\n+  public String join(IOConfig config, Map<WorkerInfo, String> taskResults) throws Exception {\n+    if (taskResults.isEmpty()) {\n+      throw new IOException(\"No results from any workers.\");\n+    }\n+    LOG.info(\"join()\");\n+    for(Map.Entry<WorkerInfo, String> entry : taskResults.entrySet()) {\n+      LOG.info(\"worker={}\", entry.getKey());\n+      LOG.info(\"{}\", entry.getValue());\n+    }\n+\n+    AtomicReference<IOException> error = new AtomicReference<>(null);\n+    List<IOTaskResult> results = taskResults.entrySet().stream().map(\n+            entry -> {\n+              try {\n+                return JsonSerializable.fromJson(entry.getValue().trim(), new IOTaskResult[0]);\n+              } catch (IOException | ClassNotFoundException e) {\n+                error.set(new IOException(String\n+                        .format(\"Failed to parse task output from %s into result class\",\n+                                entry.getKey().getAddress().getHost()), e));\n+              }\n+              return null;\n+            }).collect(Collectors.toList());\n+\n+    if (error.get() != null) {\n+      throw error.get();\n+    }\n+\n+    return results.get(0).aggregator().aggregate(results).toJson();\n+  }\n+\n+  @Override\n+  public Set<Pair<WorkerInfo, ArrayList<String>>> selectExecutors(\n+          IOConfig config, List<WorkerInfo> jobWorkerInfoList,\n+          SelectExecutorsContext selectExecutorsContext) throws Exception {\n+    Set<Pair<WorkerInfo, ArrayList<String>>> result = Sets.newHashSet();\n+\n+    // Randomly select N workers\n+    Collections.shuffle(jobWorkerInfoList);\n+    int cnt = config.getWorkerNum();\n+    for (WorkerInfo worker : jobWorkerInfoList) {\n+      if (cnt <= 0) {\n+        break;\n+      }\n+      ArrayList<String> args = new ArrayList<>(2);", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTU3Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429501572", "bodyText": "same redundancy here", "author": "madanadit", "createdAt": "2020-05-23T01:22:16Z", "path": "job/server/src/main/java/alluxio/job/plan/io/IODefinition.java", "diffHunk": "@@ -0,0 +1,123 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.RunTaskContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.PlanDefinition;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.JsonSerializable;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.util.ShellUtils;\n+import alluxio.wire.WorkerInfo;\n+import com.google.common.collect.Sets;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The definition for the UFS I/O throughput job, which generates concurrent streams to the UFS.\n+ *\n+ * {@link IOConfig} is the configuration class, each task takes a List<String> as a list of\n+ * command-line arguments to the benchmark command, and each task returns the string output.\n+ * The output will be serialized and deserialized using JSON, collected and merged.\n+ */\n+public class IODefinition implements PlanDefinition<IOConfig, ArrayList<String>, String> {\n+  private static final Logger LOG = LoggerFactory.getLogger(IODefinition.class);\n+\n+  @Override\n+  public Class<IOConfig> getJobConfigClass() {\n+    return IOConfig.class;\n+  }\n+\n+  @Override\n+  public String join(IOConfig config, Map<WorkerInfo, String> taskResults) throws Exception {\n+    if (taskResults.isEmpty()) {\n+      throw new IOException(\"No results from any workers.\");\n+    }\n+    LOG.info(\"join()\");\n+    for(Map.Entry<WorkerInfo, String> entry : taskResults.entrySet()) {\n+      LOG.info(\"worker={}\", entry.getKey());\n+      LOG.info(\"{}\", entry.getValue());\n+    }\n+\n+    AtomicReference<IOException> error = new AtomicReference<>(null);\n+    List<IOTaskResult> results = taskResults.entrySet().stream().map(\n+            entry -> {\n+              try {\n+                return JsonSerializable.fromJson(entry.getValue().trim(), new IOTaskResult[0]);\n+              } catch (IOException | ClassNotFoundException e) {\n+                error.set(new IOException(String\n+                        .format(\"Failed to parse task output from %s into result class\",\n+                                entry.getKey().getAddress().getHost()), e));\n+              }\n+              return null;\n+            }).collect(Collectors.toList());\n+\n+    if (error.get() != null) {\n+      throw error.get();\n+    }\n+\n+    return results.get(0).aggregator().aggregate(results).toJson();\n+  }\n+\n+  @Override\n+  public Set<Pair<WorkerInfo, ArrayList<String>>> selectExecutors(\n+          IOConfig config, List<WorkerInfo> jobWorkerInfoList,\n+          SelectExecutorsContext selectExecutorsContext) throws Exception {\n+    Set<Pair<WorkerInfo, ArrayList<String>>> result = Sets.newHashSet();\n+\n+    // Randomly select N workers\n+    Collections.shuffle(jobWorkerInfoList);\n+    int cnt = config.getWorkerNum();\n+    for (WorkerInfo worker : jobWorkerInfoList) {\n+      if (cnt <= 0) {\n+        break;\n+      }\n+      ArrayList<String> args = new ArrayList<>(2);\n+      // Add the worker hostname + worker id as the unique task id for each distributed task.\n+      // The worker id is used since there may be multiple workers on a single host.\n+      args.add(BaseParameters.ID_FLAG);\n+      args.add(worker.getAddress().getHost() + \"-\" + worker.getId());\n+      result.add(new Pair<>(worker, args));\n+      cnt--;\n+    }\n+    return result;\n+  }\n+\n+  @Override\n+  public String runTask(IOConfig config, ArrayList<String> args, RunTaskContext runTaskContext)\n+          throws Exception {\n+    LOG.info(\"args={}\", args);\n+\n+    List<String> command = new ArrayList<>(3 + config.getArgs().size());", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM0NDczNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432344735", "bodyText": "Updated this part to use the new runUfsIOTest class. Now it's different from IODefinition. (They do share a few lines but it's too specific to be a util method)", "author": "jiacheliu3", "createdAt": "2020-05-29T08:48:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTU3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTY0OQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429501649", "bodyText": "can we have a wrapper called alluxio runUfsIOTests over runClass+report?", "author": "madanadit", "createdAt": "2020-05-23T01:23:13Z", "path": "job/server/src/main/java/alluxio/job/plan/io/IODefinition.java", "diffHunk": "@@ -0,0 +1,123 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.RunTaskContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.PlanDefinition;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.JsonSerializable;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.util.ShellUtils;\n+import alluxio.wire.WorkerInfo;\n+import com.google.common.collect.Sets;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The definition for the UFS I/O throughput job, which generates concurrent streams to the UFS.\n+ *\n+ * {@link IOConfig} is the configuration class, each task takes a List<String> as a list of\n+ * command-line arguments to the benchmark command, and each task returns the string output.\n+ * The output will be serialized and deserialized using JSON, collected and merged.\n+ */\n+public class IODefinition implements PlanDefinition<IOConfig, ArrayList<String>, String> {\n+  private static final Logger LOG = LoggerFactory.getLogger(IODefinition.class);\n+\n+  @Override\n+  public Class<IOConfig> getJobConfigClass() {\n+    return IOConfig.class;\n+  }\n+\n+  @Override\n+  public String join(IOConfig config, Map<WorkerInfo, String> taskResults) throws Exception {\n+    if (taskResults.isEmpty()) {\n+      throw new IOException(\"No results from any workers.\");\n+    }\n+    LOG.info(\"join()\");\n+    for(Map.Entry<WorkerInfo, String> entry : taskResults.entrySet()) {\n+      LOG.info(\"worker={}\", entry.getKey());\n+      LOG.info(\"{}\", entry.getValue());\n+    }\n+\n+    AtomicReference<IOException> error = new AtomicReference<>(null);\n+    List<IOTaskResult> results = taskResults.entrySet().stream().map(\n+            entry -> {\n+              try {\n+                return JsonSerializable.fromJson(entry.getValue().trim(), new IOTaskResult[0]);\n+              } catch (IOException | ClassNotFoundException e) {\n+                error.set(new IOException(String\n+                        .format(\"Failed to parse task output from %s into result class\",\n+                                entry.getKey().getAddress().getHost()), e));\n+              }\n+              return null;\n+            }).collect(Collectors.toList());\n+\n+    if (error.get() != null) {\n+      throw error.get();\n+    }\n+\n+    return results.get(0).aggregator().aggregate(results).toJson();\n+  }\n+\n+  @Override\n+  public Set<Pair<WorkerInfo, ArrayList<String>>> selectExecutors(\n+          IOConfig config, List<WorkerInfo> jobWorkerInfoList,\n+          SelectExecutorsContext selectExecutorsContext) throws Exception {\n+    Set<Pair<WorkerInfo, ArrayList<String>>> result = Sets.newHashSet();\n+\n+    // Randomly select N workers\n+    Collections.shuffle(jobWorkerInfoList);\n+    int cnt = config.getWorkerNum();\n+    for (WorkerInfo worker : jobWorkerInfoList) {\n+      if (cnt <= 0) {\n+        break;\n+      }\n+      ArrayList<String> args = new ArrayList<>(2);\n+      // Add the worker hostname + worker id as the unique task id for each distributed task.\n+      // The worker id is used since there may be multiple workers on a single host.\n+      args.add(BaseParameters.ID_FLAG);\n+      args.add(worker.getAddress().getHost() + \"-\" + worker.getId());\n+      result.add(new Pair<>(worker, args));\n+      cnt--;\n+    }\n+    return result;\n+  }\n+\n+  @Override\n+  public String runTask(IOConfig config, ArrayList<String> args, RunTaskContext runTaskContext)\n+          throws Exception {\n+    LOG.info(\"args={}\", args);\n+\n+    List<String> command = new ArrayList<>(3 + config.getArgs().size());\n+    command.add(ServerConfiguration.get(PropertyKey.HOME) + \"/bin/alluxio\");\n+    command.add(\"runClass\");", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM0MzU3Nw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432343577", "bodyText": "I think the report step should be separate as we can combine multiple results to one graph like\n$ bin/alluxio runClass alluxio.stress.cli.report.GenerateReport --input io_4threads.json --input io_8threads.json --input io_16threads.json  --output-dir ./\n\nThe bar graphs will be next to each other providing a better illustration like below", "author": "jiacheliu3", "createdAt": "2020-05-29T08:46:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTY0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTcyMA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429501720", "bodyText": "nit: debug? the same for the other new logs in this file", "author": "madanadit", "createdAt": "2020-05-23T01:24:05Z", "path": "job/server/src/main/java/alluxio/job/plan/stress/StressBenchDefinition.java", "diffHunk": "@@ -68,13 +68,17 @@ public StressBenchDefinition() {\n       args.add(BaseParameters.ID_FLAG);\n       args.add(worker.getAddress().getHost() + \"-\" + worker.getId());\n       result.add(new Pair<>(worker, args));\n+      LOG.info(\"selectExecutors() args={}\", args);", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTc4OQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429501789", "bodyText": "remove this and following our.println?", "author": "madanadit", "createdAt": "2020-05-23T01:25:07Z", "path": "job/server/src/main/java/alluxio/job/plan/stress/StressBenchDefinition.java", "diffHunk": "@@ -68,13 +68,17 @@ public StressBenchDefinition() {\n       args.add(BaseParameters.ID_FLAG);\n       args.add(worker.getAddress().getHost() + \"-\" + worker.getId());\n       result.add(new Pair<>(worker, args));\n+      LOG.info(\"selectExecutors() args={}\", args);\n     }\n     return result;\n   }\n \n   @Override\n   public String runTask(StressBenchConfig config, ArrayList<String> args,\n       RunTaskContext runTaskContext) throws Exception {\n+    LOG.info(\"Args: {}\", args);\n+    System.out.println(\"Running here \"+ args);", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMTgwNw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429501807", "bodyText": "debug?", "author": "madanadit", "createdAt": "2020-05-23T01:25:22Z", "path": "job/server/src/main/java/alluxio/master/job/JobMaster.java", "diffHunk": "@@ -241,6 +241,7 @@ public synchronized void run(JobConfig jobConfig, long jobId)\n     Context forkedCtx = Context.current().fork();\n     Context prevCtx = forkedCtx.attach();\n     try {\n+      LOG.info(\"jobConfig class {}\", jobConfig.getClass().getCanonicalName());", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDA3Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429504073", "bodyText": "?", "author": "madanadit", "createdAt": "2020-05-23T01:55:29Z", "path": "job/server/src/test/java/alluxio/job/plan/io/IODefinitionTest.java", "diffHunk": "@@ -0,0 +1,109 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.ClientContext;\n+import alluxio.client.block.AlluxioBlockStore;\n+import alluxio.client.file.FileSystem;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.JobServerContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.load.LoadDefinition;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.WorkerBenchParameters;\n+import alluxio.underfs.UfsManager;\n+import alluxio.wire.WorkerInfo;\n+import alluxio.wire.WorkerNetAddress;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mockito;\n+import org.powermock.api.mockito.PowerMockito;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import java.lang.reflect.Array;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Matchers.any;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({FileSystem.class, JobServerContext.class, FileSystemContext.class,\n+        AlluxioBlockStore.class})\n+public class IODefinitionTest {\n+    private static final List<WorkerInfo> JOB_WORKERS = new ImmutableList.Builder<WorkerInfo>()\n+            .add(new WorkerInfo().setId(0).setAddress(new WorkerNetAddress().setHost(\"host0\")))\n+            .add(new WorkerInfo().setId(1).setAddress(new WorkerNetAddress().setHost(\"host1\")))\n+            .add(new WorkerInfo().setId(2).setAddress(new WorkerNetAddress().setHost(\"host2\")))\n+            .add(new WorkerInfo().setId(3).setAddress(new WorkerNetAddress().setHost(\"host3\"))).build();\n+\n+    private JobServerContext mJobServerContext;\n+    private FileSystem mMockFileSystem;\n+    private AlluxioBlockStore mMockBlockStore;\n+    private FileSystemContext mMockFsContext;\n+\n+    @Before\n+    public void before() {\n+        mMockFileSystem = PowerMockito.mock(FileSystem.class);\n+        mMockBlockStore = PowerMockito.mock(AlluxioBlockStore.class);\n+        mMockFsContext = PowerMockito.mock(FileSystemContext.class);\n+        PowerMockito.mockStatic(AlluxioBlockStore.class);\n+        PowerMockito.when(AlluxioBlockStore.create(any(FileSystemContext.class)))\n+                .thenReturn(mMockBlockStore);\n+        PowerMockito.when(mMockFsContext.getClientContext())\n+                .thenReturn(ClientContext.create(ServerConfiguration.global()));\n+        // TODO(jiacheng): need to hijack this conf?", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgyNDQ3OA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r431824478", "bodyText": "Please ignore all unit test related stuff here. I will make the tests more meaningful once we are more settled on the functionality.", "author": "jiacheliu3", "createdAt": "2020-05-28T13:14:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDA3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDA4Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429504086", "bodyText": "?", "author": "madanadit", "createdAt": "2020-05-23T01:55:35Z", "path": "job/server/src/test/java/alluxio/job/plan/io/IODefinitionTest.java", "diffHunk": "@@ -0,0 +1,109 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.ClientContext;\n+import alluxio.client.block.AlluxioBlockStore;\n+import alluxio.client.file.FileSystem;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.JobServerContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.load.LoadDefinition;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.WorkerBenchParameters;\n+import alluxio.underfs.UfsManager;\n+import alluxio.wire.WorkerInfo;\n+import alluxio.wire.WorkerNetAddress;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mockito;\n+import org.powermock.api.mockito.PowerMockito;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import java.lang.reflect.Array;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Matchers.any;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({FileSystem.class, JobServerContext.class, FileSystemContext.class,\n+        AlluxioBlockStore.class})\n+public class IODefinitionTest {\n+    private static final List<WorkerInfo> JOB_WORKERS = new ImmutableList.Builder<WorkerInfo>()\n+            .add(new WorkerInfo().setId(0).setAddress(new WorkerNetAddress().setHost(\"host0\")))\n+            .add(new WorkerInfo().setId(1).setAddress(new WorkerNetAddress().setHost(\"host1\")))\n+            .add(new WorkerInfo().setId(2).setAddress(new WorkerNetAddress().setHost(\"host2\")))\n+            .add(new WorkerInfo().setId(3).setAddress(new WorkerNetAddress().setHost(\"host3\"))).build();\n+\n+    private JobServerContext mJobServerContext;\n+    private FileSystem mMockFileSystem;\n+    private AlluxioBlockStore mMockBlockStore;\n+    private FileSystemContext mMockFsContext;\n+\n+    @Before\n+    public void before() {\n+        mMockFileSystem = PowerMockito.mock(FileSystem.class);\n+        mMockBlockStore = PowerMockito.mock(AlluxioBlockStore.class);\n+        mMockFsContext = PowerMockito.mock(FileSystemContext.class);\n+        PowerMockito.mockStatic(AlluxioBlockStore.class);\n+        PowerMockito.when(AlluxioBlockStore.create(any(FileSystemContext.class)))\n+                .thenReturn(mMockBlockStore);\n+        PowerMockito.when(mMockFsContext.getClientContext())\n+                .thenReturn(ClientContext.create(ServerConfiguration.global()));\n+        // TODO(jiacheng): need to hijack this conf?\n+        PowerMockito.when(mMockFsContext.getClusterConf()).thenReturn(ServerConfiguration.global());\n+        PowerMockito.when(mMockFsContext.getPathConf(any(AlluxioURI.class)))\n+                .thenReturn(ServerConfiguration.global());\n+        mJobServerContext = new JobServerContext(mMockFileSystem, mMockFsContext,\n+                Mockito.mock(UfsManager.class));\n+    }\n+\n+    @Test\n+    public void selectExecutor() throws Exception {\n+        Set<WorkerInfo> workerSet = new HashSet<>(JOB_WORKERS);\n+        IOConfig jobConfig = new IOConfig(IOConfig.class.getCanonicalName(),\n+                ImmutableList.of(),\n+                16,\n+                1024,\n+                1,\n+                \"hdfs://namenode:9000/alluxio\");\n+        Set<Pair<WorkerInfo, ArrayList<String>>> assignments =\n+                new IODefinition().selectExecutors(jobConfig,\n+                        new ArrayList<>(JOB_WORKERS),\n+                        new SelectExecutorsContext(1, mJobServerContext));\n+        System.out.println(assignments);\n+        assertEquals(assignments.size(), 1);\n+        for (Pair<WorkerInfo, ArrayList<String>> p : assignments) {\n+            WorkerInfo w = p.getFirst();\n+            assertTrue(workerSet.contains(w));\n+        }\n+    }\n+\n+    // Test join", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDEyOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429504129", "bodyText": "i don't get the TODOs in this file", "author": "madanadit", "createdAt": "2020-05-23T01:56:09Z", "path": "job/server/src/test/java/alluxio/job/plan/io/IODefinitionTest.java", "diffHunk": "@@ -0,0 +1,109 @@\n+package alluxio.job.plan.io;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.ClientContext;\n+import alluxio.client.block.AlluxioBlockStore;\n+import alluxio.client.file.FileSystem;\n+import alluxio.client.file.FileSystemContext;\n+import alluxio.collections.Pair;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.JobServerContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.load.LoadDefinition;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.WorkerBenchParameters;\n+import alluxio.underfs.UfsManager;\n+import alluxio.wire.WorkerInfo;\n+import alluxio.wire.WorkerNetAddress;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mockito;\n+import org.powermock.api.mockito.PowerMockito;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import java.lang.reflect.Array;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Matchers.any;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({FileSystem.class, JobServerContext.class, FileSystemContext.class,\n+        AlluxioBlockStore.class})\n+public class IODefinitionTest {\n+    private static final List<WorkerInfo> JOB_WORKERS = new ImmutableList.Builder<WorkerInfo>()\n+            .add(new WorkerInfo().setId(0).setAddress(new WorkerNetAddress().setHost(\"host0\")))\n+            .add(new WorkerInfo().setId(1).setAddress(new WorkerNetAddress().setHost(\"host1\")))\n+            .add(new WorkerInfo().setId(2).setAddress(new WorkerNetAddress().setHost(\"host2\")))\n+            .add(new WorkerInfo().setId(3).setAddress(new WorkerNetAddress().setHost(\"host3\"))).build();\n+\n+    private JobServerContext mJobServerContext;\n+    private FileSystem mMockFileSystem;\n+    private AlluxioBlockStore mMockBlockStore;\n+    private FileSystemContext mMockFsContext;\n+\n+    @Before\n+    public void before() {\n+        mMockFileSystem = PowerMockito.mock(FileSystem.class);\n+        mMockBlockStore = PowerMockito.mock(AlluxioBlockStore.class);\n+        mMockFsContext = PowerMockito.mock(FileSystemContext.class);\n+        PowerMockito.mockStatic(AlluxioBlockStore.class);\n+        PowerMockito.when(AlluxioBlockStore.create(any(FileSystemContext.class)))\n+                .thenReturn(mMockBlockStore);\n+        PowerMockito.when(mMockFsContext.getClientContext())\n+                .thenReturn(ClientContext.create(ServerConfiguration.global()));\n+        // TODO(jiacheng): need to hijack this conf?\n+        PowerMockito.when(mMockFsContext.getClusterConf()).thenReturn(ServerConfiguration.global());\n+        PowerMockito.when(mMockFsContext.getPathConf(any(AlluxioURI.class)))\n+                .thenReturn(ServerConfiguration.global());\n+        mJobServerContext = new JobServerContext(mMockFileSystem, mMockFsContext,\n+                Mockito.mock(UfsManager.class));\n+    }\n+\n+    @Test\n+    public void selectExecutor() throws Exception {\n+        Set<WorkerInfo> workerSet = new HashSet<>(JOB_WORKERS);\n+        IOConfig jobConfig = new IOConfig(IOConfig.class.getCanonicalName(),\n+                ImmutableList.of(),\n+                16,\n+                1024,\n+                1,\n+                \"hdfs://namenode:9000/alluxio\");\n+        Set<Pair<WorkerInfo, ArrayList<String>>> assignments =\n+                new IODefinition().selectExecutors(jobConfig,\n+                        new ArrayList<>(JOB_WORKERS),\n+                        new SelectExecutorsContext(1, mJobServerContext));\n+        System.out.println(assignments);\n+        assertEquals(assignments.size(), 1);\n+        for (Pair<WorkerInfo, ArrayList<String>> p : assignments) {\n+            WorkerInfo w = p.getFirst();\n+            assertTrue(workerSet.contains(w));\n+        }\n+    }\n+\n+    // Test join\n+\n+    // Test exec command\n+    @Test\n+    public void execCommand() {\n+        Set<WorkerInfo> workerSet = new HashSet<>(JOB_WORKERS);\n+        IOConfig jobConfig = new IOConfig(IOConfig.class.getCanonicalName(),\n+                ImmutableList.of(),\n+                16,\n+                1024,\n+                1,\n+                \"hdfs://namenode:9000/alluxio\");\n+        IODefinition def = new IODefinition();\n+        // TODO(jiacheng): catch ShellUtils?", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDE2NQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429504165", "bodyText": "comment", "author": "madanadit", "createdAt": "2020-05-23T01:56:49Z", "path": "stress/common/src/main/java/alluxio/stress/job/IOConfig.java", "diffHunk": "@@ -0,0 +1,126 @@\n+package alluxio.stress.job;\n+\n+import alluxio.stress.worker.WorkerBenchParameters;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonTypeName;\n+import com.google.common.base.Objects;\n+\n+import java.util.List;\n+\n+/**\n+ * Configuration for the IO throughput test to the UFS.\n+ */\n+@JsonTypeName(IOConfig.NAME)\n+public class IOConfig extends StressBenchConfig {\n+  private static final long serialVersionUID = 7883915266950426998L;\n+  public static final String NAME = \"IO\";\n+  // The number of streams to write to the UFS concurrently\n+  private int mThreadNum;\n+  // Size of data to write in total\n+  // They will be read in the read performance test\n+  private int mDataSize;\n+  // Temp dir to generate test files in\n+  private String mPath;\n+  private int mWorkerNum;", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDIxOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429504219", "bodyText": "nit: combine w/ previous comment \"Size of data to write/read in total\"", "author": "madanadit", "createdAt": "2020-05-23T01:57:34Z", "path": "stress/common/src/main/java/alluxio/stress/job/IOConfig.java", "diffHunk": "@@ -0,0 +1,126 @@\n+package alluxio.stress.job;\n+\n+import alluxio.stress.worker.WorkerBenchParameters;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonTypeName;\n+import com.google.common.base.Objects;\n+\n+import java.util.List;\n+\n+/**\n+ * Configuration for the IO throughput test to the UFS.\n+ */\n+@JsonTypeName(IOConfig.NAME)\n+public class IOConfig extends StressBenchConfig {\n+  private static final long serialVersionUID = 7883915266950426998L;\n+  public static final String NAME = \"IO\";\n+  // The number of streams to write to the UFS concurrently\n+  private int mThreadNum;\n+  // Size of data to write in total\n+  // They will be read in the read performance test", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDM1OQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429504359", "bodyText": "complete the implementation?", "author": "madanadit", "createdAt": "2020-05-23T01:59:24Z", "path": "stress/common/src/test/java/alluxio/stress/job/IOConfigTest.java", "diffHunk": "@@ -0,0 +1,26 @@\n+package alluxio.stress.job;\n+\n+import alluxio.job.plan.replicate.EvictConfig;\n+import alluxio.stress.worker.WorkerBenchParameters;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Test;\n+\n+public class IOConfigTest {\n+    @Test\n+    public void json() throws Exception {\n+        IOConfig config = new IOConfig(IOConfig.class.getCanonicalName(),\n+                ImmutableList.of(),\n+        16,\n+        1024,\n+        1,\n+        \"hdfs://namenode:9000/alluxio\");\n+        ObjectMapper mapper = new ObjectMapper();\n+        String json = mapper.writeValueAsString(config);\n+        System.out.println(json);\n+        IOConfig other = mapper.readValue(json, IOConfig.class);\n+        // TODO(jiacheng): check equality", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDQwMg==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429504402", "bodyText": "?", "author": "madanadit", "createdAt": "2020-05-23T01:59:55Z", "path": "stress/common/src/test/java/alluxio/stress/worker/IOTaskResultTest.java", "diffHunk": "@@ -0,0 +1,43 @@\n+package alluxio.stress.worker;\n+\n+import alluxio.stress.job.IOConfig;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Test;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class IOTaskResultTest {\n+    @Test\n+    public void json() throws Exception {\n+        IOTaskResult result = new IOTaskResult();\n+        result.addPoint(new IOTaskResult.Point(IOConfig.IOMode.READ, 100L, 20));\n+        result.addPoint(new IOTaskResult.Point(IOConfig.IOMode.WRITE, 100L, 5));\n+        ObjectMapper mapper = new ObjectMapper();\n+        String json = mapper.writeValueAsString(result);\n+        System.out.println(json);\n+        IOTaskResult other = mapper.readValue(json, IOTaskResult.class);\n+        // TODO(jiacheng): check equality", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDcwOA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r429504708", "bodyText": "are these any new system requirements for plotting the graphs? or do we include everything we need in the server tarball", "author": "madanadit", "createdAt": "2020-05-23T02:04:06Z", "path": "stress/common/src/main/java/alluxio/stress/worker/IOTaskSummary.java", "diffHunk": "@@ -0,0 +1,360 @@\n+package alluxio.stress.worker;\n+\n+import alluxio.collections.Pair;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.JsonSerializable;\n+import alluxio.stress.Parameters;\n+import alluxio.stress.Summary;\n+import alluxio.stress.graph.BarGraph;\n+import alluxio.stress.graph.Graph;\n+import alluxio.stress.job.IOConfig;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.core.JsonGenerator;\n+import com.fasterxml.jackson.core.JsonParser;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.DeserializationContext;\n+import com.fasterxml.jackson.databind.SerializerProvider;\n+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;\n+import com.fasterxml.jackson.databind.annotation.JsonSerialize;\n+import com.fasterxml.jackson.databind.deser.std.StdDeserializer;\n+import com.fasterxml.jackson.databind.ser.std.StdSerializer;\n+import com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The summary for the UFS I/O throughput test.\n+ */\n+public class IOTaskSummary implements Summary {\n+  private static final Logger LOG = LoggerFactory.getLogger(IOTaskSummary.class);\n+  private List<IOTaskResult.Point> mPoints;\n+  private List<String> mErrors;\n+  private BaseParameters mBaseParameters;\n+  private WorkerBenchParameters mParameters;\n+  private SpeedStat mReadSpeedStat;\n+  private SpeedStat mWriteSpeedStat;\n+\n+  /**\n+   * Used for deserialization.\n+   * */\n+  @JsonCreator\n+  public IOTaskSummary() {}\n+\n+  /**\n+   * @param result the {@link IOTaskResult} to summarize\n+   * */\n+  public IOTaskSummary(IOTaskResult result) {\n+    mPoints = new ArrayList<>(result.getPoints());\n+    mErrors = new ArrayList<>(result.getErrors());\n+    mBaseParameters = result.getBaseParameters();\n+    mParameters = result.getParameters();\n+    calculateStats();\n+  }\n+\n+  /**\n+   * @return the points recorded\n+   * */\n+  public List<IOTaskResult.Point> getPoints() {\n+    return mPoints;\n+  }\n+\n+  /**\n+   * @param points the data points\n+   * */\n+  public void setPoints(List<IOTaskResult.Point> points) {\n+    mPoints = points;\n+  }\n+\n+  /**\n+   * @return the errors recorded\n+   * */\n+  public List<String> getErrors() {\n+    return mErrors;\n+  }\n+\n+  /**\n+   * @param errors the errors\n+   * */\n+  public void setErrors(List<String> errors) {\n+    mErrors = errors;\n+  }\n+\n+  /**\n+   * @return the {@link BaseParameters}\n+   * */\n+  public BaseParameters getBaseParameters() {\n+    return mBaseParameters;\n+  }\n+\n+  /**\n+   * @param baseParameters the {@link BaseParameters}\n+   * */\n+  public void setBaseParameters(BaseParameters baseParameters) {\n+    mBaseParameters = baseParameters;\n+  }\n+\n+  /**\n+   * @return the task specific {@link WorkerBenchParameters}\n+   * */\n+  public WorkerBenchParameters getParameters() {\n+    return mParameters;\n+  }\n+\n+  /**\n+   * @param parameters the {@link WorkerBenchParameters}\n+   * */\n+  public void setParameters(WorkerBenchParameters parameters) {\n+    mParameters = parameters;\n+  }\n+\n+  /**\n+   * @return the {@link SpeedStat} for read speed\n+   * */\n+  public SpeedStat getReadSpeedStat() {\n+    return mReadSpeedStat;\n+  }\n+\n+  /**\n+   * @param stat the {@link SpeedStat} for read stats\n+   * */\n+  public void setReadSpeedStat(SpeedStat stat) {\n+    mReadSpeedStat = stat;\n+  }\n+\n+  /**\n+   * @return the {@link SpeedStat} for write speed\n+   * */\n+  public SpeedStat getWriteSpeedStat() {\n+    return mWriteSpeedStat;\n+  }\n+\n+  /**\n+   * @param stat the {@link SpeedStat} for write stats\n+   * */\n+  public void setWriteSpeedStat(SpeedStat stat) {\n+    mWriteSpeedStat = stat;\n+  }\n+\n+  /**\n+   * An object representation of all the statistics we need\n+   * from this I/O test.\n+   * */\n+  @JsonSerialize(using = StatSerializer.class)\n+  @JsonDeserialize(using = StatDeserializer.class)\n+  public static class SpeedStat implements JsonSerializable {\n+    public double mTotalDuration; // in second\n+    public int mTotalSize; // in MB\n+    public double mMaxSpeed; // in MB/s\n+    public double mMinSpeed; // in MB/s\n+    public double mAvgSpeed; // in MB/s\n+    public double mStdDev; // in MB/s\n+\n+    /**\n+     * An empty constructor.\n+     * */\n+    public SpeedStat() {}\n+\n+    @Override\n+    public String toString() {\n+      return String.format(\"{totalDuration=%ss, totalSize=%sMB, maxSpeed=%sMB/s, \"\n+                      + \"minSpeed=%sMB/s, \" + \"avgSpeed=%sMB/s, stdDev=%s}\",\n+              mTotalDuration, mTotalSize, mMaxSpeed, mMinSpeed, mAvgSpeed, mStdDev);\n+    }\n+  }\n+\n+  /**\n+   * A customized serializer for {@link SpeedStat}.\n+   * All the fields are attached with the unit.\n+   * */\n+  public static class StatSerializer extends StdSerializer<SpeedStat> {\n+    /**\n+     * An empty constructor.\n+     * */\n+    public StatSerializer() {\n+      super(SpeedStat.class);\n+    }\n+\n+    @Override\n+    public void serialize(SpeedStat value, JsonGenerator jgen, SerializerProvider provider)\n+            throws IOException {\n+      jgen.writeStartObject();\n+      jgen.writeStringField(\"totalDuration\", value.mTotalDuration + \"s\");\n+      jgen.writeStringField(\"totalSize\", value.mTotalSize + \"MB\");\n+      jgen.writeStringField(\"maxSpeed\", value.mMaxSpeed + \"MB/s\");\n+      jgen.writeStringField(\"minSpeed\", value.mMinSpeed + \"MB/s\");\n+      jgen.writeStringField(\"avgSpeed\", value.mAvgSpeed + \"MB/s\");\n+      jgen.writeNumberField(\"stdDev\", value.mStdDev);\n+      jgen.writeEndObject();\n+    }\n+  }\n+\n+  /**\n+   * A customized deserializer for {@link SpeedStat}.\n+   * */\n+  public static class StatDeserializer extends StdDeserializer<SpeedStat> {\n+    /**\n+     * An empty constructor.\n+     * */\n+    public StatDeserializer() {\n+      super(SpeedStat.class);\n+    }\n+\n+    private double speedToNumber(String speed) {\n+      return Double.parseDouble(speed.substring(0, speed.length() - \"MB/s\".length()));\n+    }\n+\n+    private double timeToNumber(String time) {\n+      return Double.parseDouble(time.substring(0, time.length() - \"s\".length()));\n+    }\n+\n+    private int sizeToNumber(String size) {\n+      return Integer.parseInt(size.substring(0, size.length() - \"MB\".length()));\n+    }\n+\n+    @Override\n+    public SpeedStat deserialize(JsonParser jp, DeserializationContext ctxt)\n+            throws IOException {\n+      JsonNode node = jp.getCodec().readTree(jp);\n+      SpeedStat stat = new SpeedStat();\n+      stat.mTotalDuration = timeToNumber(node.get(\"totalDuration\").asText());\n+      stat.mTotalSize = sizeToNumber(node.get(\"totalSize\").asText());\n+      stat.mMaxSpeed = speedToNumber(node.get(\"maxSpeed\").asText());\n+      stat.mMinSpeed = speedToNumber(node.get(\"minSpeed\").asText());\n+      stat.mAvgSpeed = speedToNumber(node.get(\"avgSpeed\").asText());\n+      stat.mStdDev = node.get(\"stdDev\").asDouble();\n+\n+      return stat;\n+    }\n+  }\n+\n+  /**\n+   * The points must be valid (duration not equal to 0).\n+   */\n+  private static SpeedStat calculateStat(List<IOTaskResult.Point> points) {\n+    SpeedStat result = new SpeedStat();\n+    if (points.size() == 0) {\n+      return result;\n+    }\n+\n+    double totalDuration = 0.0;\n+    int totalSize = 0;\n+    double[] speeds = new double[points.size()];\n+    double maxSpeed = 0.0;\n+    double minSpeed = Double.MAX_VALUE;\n+    int i = 0;\n+    for (IOTaskResult.Point p : points) {\n+      totalDuration += p.mDuration;\n+      totalSize += p.mDataSizeMB;\n+      double speed = p.mDataSizeMB / p.mDuration;\n+      maxSpeed = Math.max(maxSpeed, speed);\n+      minSpeed = Math.min(minSpeed, speed);\n+      speeds[i++] = p.mDataSizeMB / p.mDuration;\n+    }\n+    double avgSpeed = totalSize / totalDuration;\n+    double var = 0;\n+    for (double s : speeds) {\n+      var += (s - avgSpeed) * (s - avgSpeed);\n+    }\n+\n+    result.mTotalDuration = totalDuration;\n+    result.mTotalSize = totalSize;\n+    result.mMaxSpeed = maxSpeed;\n+    result.mMinSpeed = Double.compare(minSpeed, Double.MAX_VALUE) == 0 ? 0.0 : minSpeed;\n+    result.mAvgSpeed = avgSpeed;\n+    result.mStdDev = Math.sqrt(var);\n+\n+    return result;\n+  }\n+\n+  private void calculateStats() {\n+    List<IOTaskResult.Point> readPoints = mPoints.stream().filter((p) ->\n+            p.mMode == IOConfig.IOMode.READ && p.mDuration > 0)\n+            .collect(Collectors.toList());\n+    mReadSpeedStat = calculateStat(readPoints);\n+\n+    List<IOTaskResult.Point> writePoints = mPoints.stream().filter((p) ->\n+            p.mMode == IOConfig.IOMode.WRITE && p.mDuration > 0)\n+            .collect(Collectors.toList());\n+    mWriteSpeedStat = calculateStat(writePoints);\n+  }\n+\n+  @Override\n+  public GraphGenerator graphGenerator() {\n+    return new GraphGenerator();\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return String.format(\"IOTaskSummary: {Points=%s, Errors=%s}%n\",\n+            mPoints, mErrors);\n+  }\n+\n+  /**\n+   * A graph generator for the statistics collected.\n+   * */\n+  public static final class GraphGenerator extends alluxio.stress.GraphGenerator {\n+    @Override\n+    public List<Graph> generate(List<? extends Summary> results) {\n+      List<Graph> graphs = new ArrayList<>();\n+      // only examine MaxThroughputSummary\n+      List<IOTaskSummary> summaries =\n+              results.stream().map(x -> (IOTaskSummary) x).collect(Collectors.toList());\n+\n+      if (summaries.isEmpty()) {\n+        LOG.info(\"No summaries\");\n+        return graphs;\n+      }\n+\n+      // TODO(jiacheng): how to include params in this?\n+      // first() is the list of common field names, second() is the list of unique field names\n+      Pair<List<String>, List<String>> fieldNames = Parameters.partitionFieldNames(\n+              summaries.stream().map(x -> x.mParameters).collect(Collectors.toList()));\n+      System.out.format(\"FieldNames: %s%n\", fieldNames);\n+\n+      // Split up common description into 100 character chunks, for the sub title\n+      List<String> subTitle = new ArrayList<>(Splitter.fixedLength(100).splitToList(\n+              summaries.get(0).mParameters.getDescription(fieldNames.getFirst())));\n+      System.out.format(\"subtitle: %s%n\", subTitle);\n+\n+      for (IOTaskSummary summary : summaries) {\n+        String series = summary.mParameters.getDescription(fieldNames.getSecond());\n+        subTitle.add(series);\n+      }\n+\n+      BarGraph speedGraph = new BarGraph(\"Read/Write speed\",", "originalCommit": "ded15217e52f154ab8d35409041773d361beda73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjMxOTk3OQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432319979", "bodyText": "There's no new system requirements for plotting. The HTML generation in alluxio.stress.graph.LineGraph/BarGraph wraps its own JS libraries.", "author": "jiacheliu3", "createdAt": "2020-05-29T08:01:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDcwOA=="}], "type": "inlineReview"}, {"oid": "755a5afe636068e0b1a93df869e43c9452244113", "url": "https://github.com/Alluxio/alluxio/commit/755a5afe636068e0b1a93df869e43c9452244113", "message": "resolve some comment and add help msg", "committedDate": "2020-05-29T06:27:39Z", "type": "commit"}, {"oid": "09c85e27cdfeb0e8cd025d9be551be717e12b155", "url": "https://github.com/Alluxio/alluxio/commit/09c85e27cdfeb0e8cd025d9be551be717e12b155", "message": "use command", "committedDate": "2020-05-29T06:43:36Z", "type": "commit"}, {"oid": "3388fa83b83ab9baaab3f59a5a4443ad858b0db5", "url": "https://github.com/Alluxio/alluxio/commit/3388fa83b83ab9baaab3f59a5a4443ad858b0db5", "message": "use buffered io", "committedDate": "2020-05-29T07:17:09Z", "type": "commit"}, {"oid": "f78751df2f68ee4b790ad713eb8067ac86965457", "url": "https://github.com/Alluxio/alluxio/commit/f78751df2f68ee4b790ad713eb8067ac86965457", "message": "close buffered stream", "committedDate": "2020-05-29T07:42:03Z", "type": "commit"}, {"oid": "4f333913de653d6a7ee0178269b1cc8d52f05f61", "url": "https://github.com/Alluxio/alluxio/commit/4f333913de653d6a7ee0178269b1cc8d52f05f61", "message": "refactor to use util methods", "committedDate": "2020-05-29T08:24:55Z", "type": "commit"}, {"oid": "ea596dc58ad53204c4e77e6d2d8f7177822cb73d", "url": "https://github.com/Alluxio/alluxio/commit/ea596dc58ad53204c4e77e6d2d8f7177822cb73d", "message": "resolve the rest of comments", "committedDate": "2020-05-29T08:50:25Z", "type": "commit"}, {"oid": "bcc19580442c79da96a8aa7b9d7adab6efb11ecc", "url": "https://github.com/Alluxio/alluxio/commit/bcc19580442c79da96a8aa7b9d7adab6efb11ecc", "message": "merging master", "committedDate": "2020-05-29T09:06:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM1NjI1NA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432356254", "bodyText": "Any HDFS conf that will affect the IO throughput and I should add it here?", "author": "jiacheliu3", "createdAt": "2020-05-29T09:10:10Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/UfsIOBench.java", "diffHunk": "@@ -0,0 +1,262 @@\n+package alluxio.stress.cli;\n+\n+import alluxio.client.job.JobGrpcClientUtils;\n+import alluxio.conf.AlluxioConfiguration;\n+import alluxio.conf.InstancedConfiguration;\n+import alluxio.conf.PropertyKey;\n+import alluxio.exception.status.UnimplementedException;\n+import alluxio.job.plan.PlanConfig;\n+import alluxio.job.wire.JobInfo;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.TaskResult;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.job.StressBenchConfig;\n+import alluxio.stress.master.MasterBenchParameters;\n+import alluxio.stress.master.MasterBenchTaskResult;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.stress.worker.WorkerBenchParameters;\n+import alluxio.underfs.UfsDirectoryStatus;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.underfs.UnderFileSystemConfiguration;\n+import alluxio.util.CommonUtils;\n+import alluxio.util.ConfigurationUtils;\n+import alluxio.util.FormatUtils;\n+import alluxio.util.ShellUtils;\n+import alluxio.util.executor.ExecutorServiceFactories;\n+import com.beust.jcommander.JCommander;\n+import com.beust.jcommander.ParametersDelegate;\n+import com.google.common.util.concurrent.RateLimiter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.util.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.BufferedOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.net.URI;\n+import java.nio.ByteBuffer;\n+import java.nio.file.Paths;\n+import java.util.*;\n+import java.util.concurrent.*;\n+import java.util.stream.Collectors;\n+\n+public class UfsIOBench extends Benchmark<IOTaskResult> {\n+    private static final Logger LOG = LoggerFactory.getLogger(UfsIOBench.class);\n+    private static final int BUFFER_SIZE = 1024 * 1024;\n+\n+    @ParametersDelegate\n+    private WorkerBenchParameters mParameters = new WorkerBenchParameters();\n+\n+    private final InstancedConfiguration mConf = InstancedConfiguration.defaults();\n+    private final HashMap<String, String> mHdfsConf = new HashMap<>();\n+\n+    @Override\n+    public PlanConfig generateJobConfig(String[] args) {\n+        // remove the cluster flag\n+        List<String> commandArgs =\n+                Arrays.stream(args).filter((s) -> !BaseParameters.CLUSTER_FLAG.equals(s))\n+                        .filter((s) -> !s.isEmpty()).collect(Collectors.toList());\n+\n+        commandArgs.addAll(mBaseParameters.mJavaOpts);\n+        String className = this.getClass().getCanonicalName();\n+        return new IOConfig(className, commandArgs, mParameters);\n+    }\n+\n+    @Override\n+    public IOTaskResult runLocal() throws Exception {\n+        ExecutorService pool =\n+                ExecutorServiceFactories.fixedThreadPool(\"bench-io-thread\", mParameters.mThreads).create();\n+\n+        IOTaskResult result = runIOBench(pool);\n+\n+        pool.shutdownNow();\n+        pool.awaitTermination(30, TimeUnit.SECONDS);\n+\n+        // Aggregate the task results\n+        return result;\n+    }\n+\n+    @Override\n+    public void prepare() throws Exception {\n+        // TODO(jiacheng): any HDFS conf to add?", "originalCommit": "bcc19580442c79da96a8aa7b9d7adab6efb11ecc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM1NjU3NQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432356575", "bodyText": "Moved into util method", "author": "jiacheliu3", "createdAt": "2020-05-29T09:10:48Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/Benchmark.java", "diffHunk": "@@ -91,23 +99,16 @@ public String run(String[] args) throws Exception {\n \n     if (mBaseParameters.mCluster) {\n       // run on job service\n-\n-      // remove the cluster flag\n-      List<String> commandArgs =\n-          Arrays.stream(args).filter((s) -> !BaseParameters.CLUSTER_FLAG.equals(s))\n-              .filter((s) -> !s.isEmpty()).collect(Collectors.toList());\n-\n-      commandArgs.addAll(mBaseParameters.mJavaOpts);\n-\n-      long jobId = JobGrpcClientUtils\n-          .run(new StressBenchConfig(className, commandArgs, 10000, mBaseParameters.mClusterLimit),\n-              0, conf);", "originalCommit": "bcc19580442c79da96a8aa7b9d7adab6efb11ecc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8bc8df9381880995a612da14139e177cd5b843c9", "url": "https://github.com/Alluxio/alluxio/commit/8bc8df9381880995a612da14139e177cd5b843c9", "message": "resolve changed interface", "committedDate": "2020-05-29T10:43:53Z", "type": "commit"}, {"oid": "c905dbea40fd3232375c40da92fa1e0d207abe1f", "url": "https://github.com/Alluxio/alluxio/commit/c905dbea40fd3232375c40da92fa1e0d207abe1f", "message": "checkstyl", "committedDate": "2020-05-29T11:05:33Z", "type": "commit"}, {"oid": "d6dae419ca2535dd678f2098d29de0f6272a0c34", "url": "https://github.com/Alluxio/alluxio/commit/d6dae419ca2535dd678f2098d29de0f6272a0c34", "message": "checkstyle", "committedDate": "2020-05-29T13:15:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY0Nzg5OA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432647898", "bodyText": "consider making this a String and using FormatUtils to parse a byte instead. Then users can specify 1k, 4k, 10M, 10g, etc instead. I think it is more user friendly.", "author": "ZacBlanco", "createdAt": "2020-05-29T17:57:17Z", "path": "stress/common/src/main/java/alluxio/stress/worker/WorkerBenchParameters.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.stress.worker;\n+\n+import alluxio.stress.Parameters;\n+\n+import com.beust.jcommander.Parameter;\n+\n+/**\n+ * Parameters used in the UFS I/O throughput test.\n+ * */\n+public class WorkerBenchParameters extends Parameters {\n+  @Parameter(names = {\"--threads\"}, description = \"the number of threads to use\")\n+  public int mThreads = 16;\n+\n+  @Parameter(names = {\"--io-size\"},\n+          description = \"size of data to write or read in total, in MB\")\n+  public int mDataSize = 4096;", "originalCommit": "d6dae419ca2535dd678f2098d29de0f6272a0c34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk4Mjk3MA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r433982970", "bodyText": "This is a cool idea. However I think using an integer in the unit of MB makes the most sense for this test. It doesn't really mean much running an I/O with KB and i think using int gets us away from annoying decimal sizes. I lean towards keeping it this way. What do you think?", "author": "jiacheliu3", "createdAt": "2020-06-02T15:50:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY0Nzg5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI0NDIwNw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r434244207", "bodyText": "I think Zac was saying to make this a string value, we can we specify like 4m. In the code, we can convert it to an int with FormatUtils.parseSpaceSize like https://github.com/Alluxio/alluxio/blob/master/stress/shell/src/main/java/alluxio/stress/cli/client/StressClientIOBench.java#L239", "author": "gpang", "createdAt": "2020-06-03T00:24:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY0Nzg5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDgwMTA3Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r434801072", "bodyText": "Updated using formatted String now instead of int.", "author": "jiacheliu3", "createdAt": "2020-06-03T19:25:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY0Nzg5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyMjg1Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432722852", "bodyText": "was this intentional?", "author": "gpang", "createdAt": "2020-05-29T20:36:24Z", "path": "job/server/src/main/java/alluxio/job/plan/stress/StressBenchDefinition.java", "diffHunk": "@@ -103,37 +93,13 @@ public String runTask(StressBenchConfig config, ArrayList<String> args,\n     }\n \n     command.addAll(args);\n-\n-    LOG.info(\"running command: \" + String.join(\" \", command));", "originalCommit": "d6dae419ca2535dd678f2098d29de0f6272a0c34", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNDc5OA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432724798", "bodyText": "why can't this just reuse the stress definition? It looks similar?", "author": "gpang", "createdAt": "2020-05-29T20:41:02Z", "path": "job/server/src/main/java/alluxio/job/plan/io/IODefinition.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.job.plan.io;\n+\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.job.RunTaskContext;\n+import alluxio.job.SelectExecutorsContext;\n+import alluxio.job.plan.PlanDefinition;\n+import alluxio.job.util.BenchmarkJobUtils;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.util.ShellUtils;\n+import alluxio.wire.WorkerInfo;\n+\n+import com.google.common.collect.Sets;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * The definition for the UFS I/O throughput job, which generates concurrent streams to the UFS.\n+ *\n+ * {@link IOConfig} is the configuration class, each task takes a List<String> as a list of\n+ * command-line arguments to the benchmark command, and each task returns the string output.\n+ * The output will be serialized and deserialized using JSON, collected and merged.\n+ */\n+public class IODefinition implements PlanDefinition<IOConfig, ArrayList<String>, String> {", "originalCommit": "d6dae419ca2535dd678f2098d29de0f6272a0c34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzkwMzExMw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r433903113", "bodyText": "Now it does look very similar since the StressBenchDefinition#selectExecutors selects k workers with the mClusterLimit parameter....", "author": "jiacheliu3", "createdAt": "2020-06-02T14:05:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNDc5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk3MDIyMA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r433970220", "bodyText": "IODefinition and IOConfig are now removed. I think I misunderstood how to use StressBenchDefinition and StressBenchConfig...", "author": "jiacheliu3", "createdAt": "2020-06-02T15:36:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNDc5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyODAxMg==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432728012", "bodyText": "Why is this debug now?", "author": "gpang", "createdAt": "2020-05-29T20:48:37Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/Benchmark.java", "diffHunk": "@@ -126,8 +142,7 @@ public String run(String[] args) throws Exception {\n       command.addAll(Arrays.asList(args));\n       command.add(BaseParameters.IN_PROCESS_FLAG);\n       command.addAll(mBaseParameters.mJavaOpts);\n-\n-      LOG.info(\"running command: \" + String.join(\" \", command));\n+      LOG.debug(\"running command: \" + String.join(\" \", command));", "originalCommit": "d6dae419ca2535dd678f2098d29de0f6272a0c34", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjczMDY0OA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r432730648", "bodyText": "this test couldn't re-use the existing definition? It someone defeats the purpose with only using a small portion of the existing stress benchmark?", "author": "gpang", "createdAt": "2020-05-29T20:55:18Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/UfsIOBench.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.stress.cli;\n+\n+import alluxio.conf.InstancedConfiguration;\n+import alluxio.job.plan.PlanConfig;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.job.IOConfig;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.stress.worker.WorkerBenchParameters;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.underfs.UnderFileSystemConfiguration;\n+import alluxio.util.CommonUtils;\n+import alluxio.util.executor.ExecutorServiceFactories;\n+\n+import com.beust.jcommander.ParametersDelegate;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.BufferedOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A benchmark tool measuring the IO to UFS.\n+ * */\n+public class UfsIOBench extends Benchmark<IOTaskResult> {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsIOBench.class);\n+  private static final int BUFFER_SIZE = 1024 * 1024;\n+\n+  @ParametersDelegate\n+  private WorkerBenchParameters mParameters = new WorkerBenchParameters();\n+\n+  private final InstancedConfiguration mConf = InstancedConfiguration.defaults();\n+  private final HashMap<String, String> mHdfsConf = new HashMap<>();\n+\n+  @Override\n+  public PlanConfig generateJobConfig(String[] args) {\n+    // remove the cluster flag\n+    List<String> commandArgs =\n+            Arrays.stream(args).filter((s) -> !BaseParameters.CLUSTER_FLAG.equals(s))\n+                    .filter((s) -> !s.isEmpty()).collect(Collectors.toList());\n+\n+    commandArgs.addAll(mBaseParameters.mJavaOpts);\n+    String className = this.getClass().getCanonicalName();\n+    return new IOConfig(className, commandArgs, mParameters);", "originalCommit": "d6dae419ca2535dd678f2098d29de0f6272a0c34", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "694d2cdadd9b07e29a9327ff48c76d2a8aafd345", "url": "https://github.com/Alluxio/alluxio/commit/694d2cdadd9b07e29a9327ff48c76d2a8aafd345", "message": "use StressBenchDefinition", "committedDate": "2020-06-02T14:26:34Z", "type": "commit"}, {"oid": "b3d85ee3ea8ac854357abf40999847c7868b8a64", "url": "https://github.com/Alluxio/alluxio/commit/b3d85ee3ea8ac854357abf40999847c7868b8a64", "message": "migrated to use StressBench job classes", "committedDate": "2020-06-02T15:14:00Z", "type": "commit"}, {"oid": "de80970270527721405c0c7fcf279173a1f564f2", "url": "https://github.com/Alluxio/alluxio/commit/de80970270527721405c0c7fcf279173a1f564f2", "message": "remove from job definition", "committedDate": "2020-06-02T15:28:12Z", "type": "commit"}, {"oid": "b36bdc51823db1df97cc57d504505bd973003bbf", "url": "https://github.com/Alluxio/alluxio/commit/b36bdc51823db1df97cc57d504505bd973003bbf", "message": "resolve comment", "committedDate": "2020-06-02T15:50:40Z", "type": "commit"}, {"oid": "b7c2e488c3b59081d92a4eba2ddf22f85290551b", "url": "https://github.com/Alluxio/alluxio/commit/b7c2e488c3b59081d92a4eba2ddf22f85290551b", "message": "revert unnecessary changes", "committedDate": "2020-06-02T15:59:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk5MzI4MA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r433993280", "bodyText": "I think generics can help remove some boilerplate code here", "author": "jiacheliu3", "createdAt": "2020-06-02T16:00:36Z", "path": "stress/common/src/main/java/alluxio/stress/client/ClientIOTaskResult.java", "diffHunk": "@@ -132,22 +132,17 @@ private long computeLastEndMs() {\n     return new Aggregator();\n   }\n \n-  private static final class Aggregator implements TaskResult.Aggregator {\n+  private static final class Aggregator implements TaskResult.Aggregator<ClientIOTaskResult> {\n     @Override\n-    public ClientIOTaskResult aggregate(Iterable<TaskResult> results) throws Exception {\n-      Iterator<TaskResult> it = results.iterator();\n+    public ClientIOTaskResult aggregate(Iterable<ClientIOTaskResult> results) throws Exception {\n+      Iterator<ClientIOTaskResult> it = results.iterator();\n       if (it.hasNext()) {\n-        TaskResult taskResult = it.next();\n+        ClientIOTaskResult taskResult = it.next();\n         if (it.hasNext()) {\n           throw new IOException(\n               \"ClientIO is a single node test, so multiple task results cannot be aggregated.\");\n         }\n-        if (!(taskResult instanceof ClientIOTaskResult)) {\n-          throw new IOException(\n-              \"TaskResult is not of type ClientIOTaskResult. class: \" + taskResult.getClass()\n-                  .getName());\n-        }\n-        return (ClientIOTaskResult) taskResult;", "originalCommit": "b7c2e488c3b59081d92a4eba2ddf22f85290551b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1174fe168dc37f12b728cc9eb4de302295718e9b", "url": "https://github.com/Alluxio/alluxio/commit/1174fe168dc37f12b728cc9eb4de302295718e9b", "message": "whitespace", "committedDate": "2020-06-02T16:02:01Z", "type": "commit"}, {"oid": "8d8289e4bd954ff52d48b1225ff94d60eb6bb7dc", "url": "https://github.com/Alluxio/alluxio/commit/8d8289e4bd954ff52d48b1225ff94d60eb6bb7dc", "message": "whitespace", "committedDate": "2020-06-02T16:03:58Z", "type": "commit"}, {"oid": "a62658ff9d4bf25734acf786753074b1b18415b5", "url": "https://github.com/Alluxio/alluxio/commit/a62658ff9d4bf25734acf786753074b1b18415b5", "message": "unnecessary annotation", "committedDate": "2020-06-02T16:06:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI0NDY0OQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r434244649", "bodyText": "I think this should be renamed to something like UfsIOParameters? The ony test that uses this class is a test called UfsIOBench.", "author": "gpang", "createdAt": "2020-06-03T00:25:44Z", "path": "stress/common/src/main/java/alluxio/stress/worker/WorkerBenchParameters.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.stress.worker;\n+\n+import alluxio.stress.Parameters;\n+\n+import com.beust.jcommander.Parameter;\n+\n+/**\n+ * Parameters used in the UFS I/O throughput test.\n+ * */\n+public class WorkerBenchParameters extends Parameters {", "originalCommit": "a62658ff9d4bf25734acf786753074b1b18415b5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI0NTMwMw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r434245303", "bodyText": "Can you not reuse the clusterLimit parameter already available in base parameters? Also, the wait time should be non-zero, and probably be at least 5 or 10 seconds, so the distributed task can start on time.\nI feel like this generateJobConfig method doesn't need to be overridden.", "author": "gpang", "createdAt": "2020-06-03T00:28:21Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/UfsIOBench.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.stress.cli;\n+\n+import alluxio.conf.InstancedConfiguration;\n+import alluxio.job.plan.PlanConfig;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.job.StressBenchConfig;\n+import alluxio.stress.worker.IOTaskResult;\n+import alluxio.stress.worker.WorkerBenchParameters;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.underfs.UnderFileSystemConfiguration;\n+import alluxio.util.CommonUtils;\n+import alluxio.util.executor.ExecutorServiceFactories;\n+\n+import com.beust.jcommander.ParametersDelegate;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.BufferedOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * A benchmark tool measuring the IO to UFS.\n+ * */\n+public class UfsIOBench extends Benchmark<IOTaskResult> {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsIOBench.class);\n+  private static final int BUFFER_SIZE = 1024 * 1024;\n+\n+  @ParametersDelegate\n+  private WorkerBenchParameters mParameters = new WorkerBenchParameters();\n+\n+  private final InstancedConfiguration mConf = InstancedConfiguration.defaults();\n+  private final HashMap<String, String> mHdfsConf = new HashMap<>();\n+\n+  @Override\n+  public PlanConfig generateJobConfig(String[] args) {\n+    // remove the cluster flag\n+    List<String> commandArgs =\n+            Arrays.stream(args).filter((s) -> !BaseParameters.CLUSTER_FLAG.equals(s))\n+                    .filter((s) -> !s.isEmpty()).collect(Collectors.toList());\n+\n+    commandArgs.addAll(mBaseParameters.mJavaOpts);\n+    String className = this.getClass().getCanonicalName();\n+    return new StressBenchConfig(className, commandArgs, 0, mParameters.mWorkerNum);", "originalCommit": "a62658ff9d4bf25734acf786753074b1b18415b5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDczNjU4OQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r434736589", "bodyText": "You are right. Keeping this override is an overlook. Removed.\nActually in my test I recorded the duration in each read/write operation so this start time is not used anywhere.", "author": "jiacheliu3", "createdAt": "2020-06-03T17:29:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI0NTMwMw=="}], "type": "inlineReview"}, {"oid": "d61bd151d42da93d90360770690f3f50597cbe51", "url": "https://github.com/Alluxio/alluxio/commit/d61bd151d42da93d90360770690f3f50597cbe51", "message": "resolve comments and spotbugs", "committedDate": "2020-06-03T18:42:16Z", "type": "commit"}, {"oid": "1a95d8921002960c76ed4957b1b2ffe8095fafc7", "url": "https://github.com/Alluxio/alluxio/commit/1a95d8921002960c76ed4957b1b2ffe8095fafc7", "message": "update parameter", "committedDate": "2020-06-03T18:58:16Z", "type": "commit"}, {"oid": "a1a855d31ab6c78431a77c938bc8514cc8a98022", "url": "https://github.com/Alluxio/alluxio/commit/a1a855d31ab6c78431a77c938bc8514cc8a98022", "message": "better format on stat", "committedDate": "2020-06-03T19:03:51Z", "type": "commit"}, {"oid": "bbb80c3c1cd2e026d411830d0033e9d1b6f535d3", "url": "https://github.com/Alluxio/alluxio/commit/bbb80c3c1cd2e026d411830d0033e9d1b6f535d3", "message": "remove extra comment", "committedDate": "2020-06-03T19:09:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM4MjQ2Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r435382463", "bodyText": "Why do serializers and deserializers need to be used? Jackson can just ser/de the classes, with getters/setters, or with public fields, right? That is how all the other results and parameter classes work.", "author": "gpang", "createdAt": "2020-06-04T16:16:03Z", "path": "stress/common/src/main/java/alluxio/stress/worker/IOTaskSummary.java", "diffHunk": "@@ -0,0 +1,371 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.stress.worker;\n+\n+import alluxio.collections.Pair;\n+import alluxio.stress.BaseParameters;\n+import alluxio.stress.JsonSerializable;\n+import alluxio.stress.Parameters;\n+import alluxio.stress.Summary;\n+import alluxio.stress.graph.BarGraph;\n+import alluxio.stress.graph.Graph;\n+import alluxio.util.FormatUtils;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.core.JsonGenerator;\n+import com.fasterxml.jackson.core.JsonParser;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.DeserializationContext;\n+import com.fasterxml.jackson.databind.SerializerProvider;\n+import com.fasterxml.jackson.databind.annotation.JsonDeserialize;\n+import com.fasterxml.jackson.databind.annotation.JsonSerialize;\n+import com.fasterxml.jackson.databind.deser.std.StdDeserializer;\n+import com.fasterxml.jackson.databind.ser.std.StdSerializer;\n+import com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The summary for the UFS I/O throughput test.\n+ */\n+public class IOTaskSummary implements Summary {\n+  private static final Logger LOG = LoggerFactory.getLogger(IOTaskSummary.class);\n+  private List<IOTaskResult.Point> mPoints;\n+  private List<String> mErrors;\n+  private BaseParameters mBaseParameters;\n+  private UfsIOParameters mParameters;\n+  private SpeedStat mReadSpeedStat;\n+  private SpeedStat mWriteSpeedStat;\n+\n+  /**\n+   * Used for deserialization.\n+   * */\n+  @JsonCreator\n+  public IOTaskSummary() {}\n+\n+  /**\n+   * @param result the {@link IOTaskResult} to summarize\n+   * */\n+  public IOTaskSummary(IOTaskResult result) {\n+    mPoints = new ArrayList<>(result.getPoints());\n+    mErrors = new ArrayList<>(result.getErrors());\n+    mBaseParameters = result.getBaseParameters();\n+    mParameters = result.getParameters();\n+    calculateStats();\n+  }\n+\n+  /**\n+   * @return the points recorded\n+   * */\n+  public List<IOTaskResult.Point> getPoints() {\n+    return mPoints;\n+  }\n+\n+  /**\n+   * @param points the data points\n+   * */\n+  public void setPoints(List<IOTaskResult.Point> points) {\n+    mPoints = points;\n+  }\n+\n+  /**\n+   * @return the errors recorded\n+   * */\n+  public List<String> getErrors() {\n+    return mErrors;\n+  }\n+\n+  /**\n+   * @param errors the errors\n+   * */\n+  public void setErrors(List<String> errors) {\n+    mErrors = errors;\n+  }\n+\n+  /**\n+   * @return the {@link BaseParameters}\n+   * */\n+  public BaseParameters getBaseParameters() {\n+    return mBaseParameters;\n+  }\n+\n+  /**\n+   * @param baseParameters the {@link BaseParameters}\n+   * */\n+  public void setBaseParameters(BaseParameters baseParameters) {\n+    mBaseParameters = baseParameters;\n+  }\n+\n+  /**\n+   * @return the task specific {@link UfsIOParameters}\n+   * */\n+  public UfsIOParameters getParameters() {\n+    return mParameters;\n+  }\n+\n+  /**\n+   * @param parameters the {@link UfsIOParameters}\n+   * */\n+  public void setParameters(UfsIOParameters parameters) {\n+    mParameters = parameters;\n+  }\n+\n+  /**\n+   * @return the {@link SpeedStat} for read speed\n+   * */\n+  public SpeedStat getReadSpeedStat() {\n+    return mReadSpeedStat;\n+  }\n+\n+  /**\n+   * @param stat the {@link SpeedStat} for read stats\n+   * */\n+  public void setReadSpeedStat(SpeedStat stat) {\n+    mReadSpeedStat = stat;\n+  }\n+\n+  /**\n+   * @return the {@link SpeedStat} for write speed\n+   * */\n+  public SpeedStat getWriteSpeedStat() {\n+    return mWriteSpeedStat;\n+  }\n+\n+  /**\n+   * @param stat the {@link SpeedStat} for write stats\n+   * */\n+  public void setWriteSpeedStat(SpeedStat stat) {\n+    mWriteSpeedStat = stat;\n+  }\n+\n+  /**\n+   * An object representation of all the statistics we need\n+   * from this I/O test.\n+   * */\n+  @JsonSerialize(using = StatSerializer.class)\n+  @JsonDeserialize(using = StatDeserializer.class)\n+  public static class SpeedStat implements JsonSerializable {\n+    public double mTotalDuration; // in second\n+    public long mTotalSize; // in Bytes\n+    public double mMaxSpeed; // in MB/s\n+    public double mMinSpeed; // in MB/s\n+    public double mAvgSpeed; // in MB/s\n+    public double mStdDev; // in MB/s\n+\n+    /**\n+     * An empty constructor.\n+     * */\n+    public SpeedStat() {}\n+\n+    @Override\n+    public String toString() {\n+      return String.format(\"{totalDuration=%ss, totalSize=%s, maxSpeed=%sMB/s, \"\n+                      + \"minSpeed=%sMB/s, \" + \"avgSpeed=%sMB/s, stdDev=%s}\",\n+              mTotalDuration, FormatUtils.getSizeFromBytes(mTotalSize),\n+              mMaxSpeed, mMinSpeed, mAvgSpeed, mStdDev);\n+    }\n+  }\n+\n+  /**\n+   * A customized serializer for {@link SpeedStat}.\n+   * All the fields are attached with the unit.\n+   * */\n+  public static class StatSerializer extends StdSerializer<SpeedStat> {\n+    private static final long serialVersionUID = -5198319303173120740L;\n+\n+    /**\n+     * An empty constructor.\n+     * */\n+    public StatSerializer() {\n+      super(SpeedStat.class);\n+    }\n+\n+    @Override\n+    public void serialize(SpeedStat value, JsonGenerator jgen, SerializerProvider provider)", "originalCommit": "bbb80c3c1cd2e026d411830d0033e9d1b6f535d3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzNzM4MA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r435637380", "bodyText": "I provided customized ser/de because I need some better formatting on the field, so both the intermediate and final results are much more human readable.\nBefore formatting:\n{\"totalDuration\":\"2.0\",\"totalSize\":\"415236096\",\"maxSpeed\":\"200.0\",\"minSpeed\":\"196.0\",\"avgSpeed\":\"198.0\",\"stdDev\":2.8284271247461903}\n\nAfter  formatting:\n{\"totalDuration\":\"2.0s\",\"totalSize\":\"396.00MB\",\"maxSpeed\":\"200.0MB/s\",\"minSpeed\":\"196.0MB/s\",\"avgSpeed\":\"198.0MB/s\",\"stdDev\":2.8284271247461903}", "author": "jiacheliu3", "createdAt": "2020-06-05T01:07:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM4MjQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzOTU0MQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r435639541", "bodyText": "I see, so is the json intended to be the final human-readable output? Typically, these json files are fed into generate, to get the human-readable output.", "author": "gpang", "createdAt": "2020-06-05T01:17:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM4MjQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MjkyNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r435642925", "bodyText": "Well this json will primarily be read by jason's new UI, which will render a graph. So it doesn't need to be human readable; the cli interface is secondary to the web ui", "author": "madanadit", "createdAt": "2020-06-05T01:32:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM4MjQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MzgzOA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r435643838", "bodyText": "Ah I see what you mean. Yes I intend to use this as the final output, as we are exploring the possibility to move the graph generation logic into out frontend. I think it also makes some sense if the user is reading the results before the GenerateReport step.", "author": "jiacheliu3", "createdAt": "2020-06-05T01:36:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM4MjQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0ODMzNw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r435648337", "bodyText": "Also I think it's slightly more maintainable if we pass data with units to the frontend, as it's a mixture of \"Bytes\", \"MB\", and \"MB/s\".", "author": "jiacheliu3", "createdAt": "2020-06-05T01:54:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM4MjQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNDk4NA==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r435724984", "bodyText": "I am a bit confused. If this json is the final human-readable output, then yes, these values can just be strings. But, if this json is supposed to be data (to be later graphed or displayed), then I think it would make sense for the value to be the scalar primitive.\nIf units are a concern, other results have the units in the name of the field, like \"durationMs\", or \"iompbs\".", "author": "gpang", "createdAt": "2020-06-05T06:57:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM4MjQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAxOTc1Nw==", "url": "https://github.com/Alluxio/alluxio/pull/11422#discussion_r436019757", "bodyText": "I like the idea of unit in field names. I'll update this.", "author": "jiacheliu3", "createdAt": "2020-06-05T16:06:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM4MjQ2Mw=="}], "type": "inlineReview"}, {"oid": "9e6fdfdff56387440579a73994388f69de98e09d", "url": "https://github.com/Alluxio/alluxio/commit/9e6fdfdff56387440579a73994388f69de98e09d", "message": "remove customized ser/de", "committedDate": "2020-06-05T16:16:17Z", "type": "commit"}]}