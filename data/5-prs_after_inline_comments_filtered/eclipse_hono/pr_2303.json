{"pr_number": 2303, "pr_title": "Add Kafka based downstream client", "pr_createdAt": "2020-11-17T13:38:04Z", "pr_url": "https://github.com/eclipse/hono/pull/2303", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzODgxMQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525238811", "bodyText": "this seems to be the most often used method, isn't it? Given that this class is immutable, we should probably create the string representation once during construction instead of concatenating the strings over and over again ...", "author": "sophokles73", "createdAt": "2020-11-17T15:20:29Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/HonoTopic.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.Objects;\n+\n+import org.eclipse.hono.util.CommandConstants;\n+import org.eclipse.hono.util.EventConstants;\n+import org.eclipse.hono.util.TelemetryConstants;\n+\n+/**\n+ * Identifier for Hono's topics. The Kafka topic string is obtained by {@link #toString()}.\n+ */\n+public final class HonoTopic {\n+\n+    private static final String SEPARATOR = \".\";\n+    private static final String NAMESPACE = \"hono\" + SEPARATOR;\n+\n+    private final Type type;\n+    private final String tenantId;\n+\n+    /**\n+     * Creates a new topic from the given topic type and tenant ID.\n+     *\n+     * @param type The type of the topic.\n+     * @param tenantId The ID of the tenant that the topic belongs to.\n+     * @throws NullPointerException if any of the parameters is {@code null}.\n+     */\n+    public HonoTopic(final Type type, final String tenantId) {\n+        Objects.requireNonNull(type);\n+        Objects.requireNonNull(tenantId);\n+\n+        this.type = type;\n+        this.tenantId = tenantId;\n+    }\n+\n+    /**\n+     * Creates a topic instance from the string representation.\n+     *\n+     * @param topicString The string to create a topic from.\n+     * @return The topic or {@code null} if the string does not contain a valid Hono topic.\n+     */\n+    public static HonoTopic fromString(final String topicString) {\n+        if (topicString.startsWith(Type.TELEMETRY.prefix)) {\n+            return new HonoTopic(Type.TELEMETRY, topicString.substring(Type.TELEMETRY.prefix.length()));\n+        } else if (topicString.startsWith(Type.EVENT.prefix)) {\n+            return new HonoTopic(Type.EVENT, topicString.substring(Type.EVENT.prefix.length()));\n+        } else if (topicString.startsWith(Type.COMMAND.prefix)) {\n+            return new HonoTopic(Type.COMMAND, topicString.substring(Type.COMMAND.prefix.length()));\n+        } else if (topicString.startsWith(Type.COMMAND_RESPONSE.prefix)) {\n+            return new HonoTopic(Type.COMMAND_RESPONSE, topicString.substring(Type.COMMAND_RESPONSE.prefix.length()));\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Gets the type of the topic.\n+     *\n+     * @return The type.\n+     */\n+    public Type getType() {\n+        return type;\n+    }\n+\n+    /**\n+     * Gets the tenant ID of the topic.\n+     *\n+     * @return The tenant ID.\n+     */\n+    public String getTenantId() {\n+        return tenantId;\n+    }\n+\n+    /**\n+     * Returns the string representation of the topic as used by the Kafka client.\n+     *\n+     * @return The topic as a string.\n+     */\n+    @Override\n+    public String toString() {", "originalCommit": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAyODc2Ng==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r526028766", "bodyText": "Done.", "author": "b-abel", "createdAt": "2020-11-18T11:53:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzODgxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525239804", "bodyText": "do we really need this in the main source tree or can this go into the test folder?", "author": "sophokles73", "createdAt": "2020-11-17T15:21:42Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/test/FakeProducer.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.test;", "originalCommit": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAyODgwNg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r526028806", "bodyText": "FMPOV this adds a missing feature in the Vert.x Kafka client. The (Apache) Kafka client ships with a great class MockProducer, which cannot be used in Vert.x's client.\nI see it as a fake in the sense of https://martinfowler.com/bliki/TestDouble.html. Although it is used in test scenarios, it is a working implementation, which itself needs to be tested. Also, in practice, if I move it to the test folder, I cannot use it in other modules.", "author": "b-abel", "createdAt": "2020-11-18T11:53:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYzODc0Mg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528638742", "bodyText": "Maybe this could go into the \"test-utils\" module. WDYT?", "author": "b-abel", "createdAt": "2020-11-23T11:33:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2ODQyMw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528668423", "bodyText": "Is this class required by other modules than the adapter-kafka module?", "author": "sophokles73", "createdAt": "2020-11-23T12:29:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ4ODkzNw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529488937", "bodyText": "I think this is useful for all unit tests involving a Kafka client. I expect to have at least one module for a client for backend applications (something like a module application-kafka inside the module clients). And then there will probably be a Kafka client in the command routing component discussed in #2273.", "author": "b-abel", "createdAt": "2020-11-24T11:54:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ5OTg1Ng==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529499856", "bodyText": "Then you should indeed move it to the test-utils module", "author": "sophokles73", "createdAt": "2020-11-24T12:14:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzMyNjE5Mg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r533326192", "bodyText": "@sophokles73 I now found a way to use the MockProducer of the Kafka client in the client of Vert.x. Therefore I removed the FakeProducer after all.", "author": "b-abel", "createdAt": "2020-12-01T11:08:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIzOTgwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0MDA4OA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525240088", "bodyText": "test folder?", "author": "sophokles73", "createdAt": "2020-11-17T15:22:03Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/test/TestHelper.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.test;", "originalCommit": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAyODg0OA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r526028848", "bodyText": "Done.", "author": "b-abel", "createdAt": "2020-11-18T11:53:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0MDA4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0MzA5Mw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525243093", "bodyText": "IMHO these values should be logged to a span but should not be set as tags ... I doubt that you will filter/search spans based on these values, will you?", "author": "sophokles73", "createdAt": "2020-11-17T15:25:01Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/KafkaTracingHelper.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import java.util.Objects;\n+\n+import org.eclipse.hono.kafka.client.HonoTopic;\n+import org.eclipse.hono.tracing.TracingHelper;\n+\n+import io.opentracing.Span;\n+import io.opentracing.SpanContext;\n+import io.opentracing.Tracer;\n+import io.opentracing.noop.NoopSpanContext;\n+import io.opentracing.propagation.Format;\n+import io.opentracing.tag.IntTag;\n+import io.opentracing.tag.Tags;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.kafka.client.producer.KafkaProducerRecord;\n+import io.vertx.kafka.client.producer.RecordMetadata;\n+\n+/**\n+ * A helper class providing Kafka-specific utility methods for interacting with the OpenTracing API.\n+ *\n+ */\n+// TODO align with Kafka tracing support in Vert.x 4.0\n+public final class KafkaTracingHelper {\n+\n+    /**\n+     * An OpenTracing tag that contains the offset of a Kafka record.\n+     */\n+    public static final LongTag TAG_OFFSET = new LongTag(\"offset\");\n+\n+    /**\n+     * An OpenTracing tag that contains the partition of a Kafka record.\n+     */\n+    public static final IntTag TAG_PARTITION = new IntTag(\"partition\");\n+\n+    /**\n+     * An OpenTracing tag that contains the timestamp of a Kafka record.\n+     */\n+    public static final LongTag TAG_TIMESTAMP = new LongTag(\"timestamp\");\n+\n+    private KafkaTracingHelper() {\n+        // prevent instantiation\n+    }\n+\n+    /**\n+     * Creates a new <em>OpenTracing</em> span to trace producing messages to Kafka.\n+     * <p>\n+     * The returned span will already contain the following tags:\n+     * <ul>\n+     * <li>{@link Tags#COMPONENT} - set to <em>hono-client-kafka</em></li>\n+     * <li>{@link Tags#MESSAGE_BUS_DESTINATION} - set to {@code To_<topic>}</li>\n+     * <li>{@link Tags#SPAN_KIND} - set to {@link Tags#SPAN_KIND_PRODUCER}</li>\n+     * <li>{@link Tags#PEER_SERVICE} - set to <em>kafka</em></li>\n+     * </ul>\n+     *\n+     * @param tracer The Tracer to use.\n+     * @param topic The topic from which the operation name is derived.\n+     * @param referenceType The type of reference towards the span context.\n+     * @param parent The span context to set as parent and to derive the sampling priority from (may be null).\n+     * @return The new span.\n+     * @throws NullPointerException if tracer or topic is {@code null}.\n+     */\n+    public static Span newProducerSpan(final Tracer tracer, final HonoTopic topic, final String referenceType,\n+            final SpanContext parent) {\n+        Objects.requireNonNull(tracer);\n+        Objects.requireNonNull(topic);\n+        Objects.requireNonNull(referenceType);\n+\n+        return TracingHelper.buildSpan(tracer, parent, \"To_\" + topic.toString(), referenceType)\n+                .ignoreActiveSpan()\n+                .withTag(Tags.COMPONENT.getKey(), \"hono-client-kafka\")\n+                .withTag(Tags.SPAN_KIND.getKey(), Tags.SPAN_KIND_PRODUCER)\n+                .withTag(Tags.MESSAGE_BUS_DESTINATION.getKey(), topic.toString())\n+                .withTag(Tags.PEER_SERVICE.getKey(), \"kafka\")\n+                .start();\n+    }\n+\n+    /**\n+     * Sets tags from record metadata.\n+     * <p>\n+     * It sets the following tags:\n+     * <ul>\n+     * <li>{@link #TAG_OFFSET}</li>\n+     * <li>{@link #TAG_PARTITION}</li>\n+     * <li>{@link #TAG_TIMESTAMP}</li>\n+     * </ul>\n+     * <p>\n+     * <em>It does not set the topic, as this is expected to be already already set.</em>\n+     *\n+     * @param span The span to set the tags on.\n+     * @param recordMetadata The record metadata.\n+     */\n+    public static void setRecordMetadataTags(final Span span, final RecordMetadata recordMetadata) {", "originalCommit": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAyODkzNg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r526028936", "bodyText": "I'm not sure. I aimed for compatibility with https://github.com/opentracing-contrib/java-kafka-client which does set partition and offset as tags.\nI just learned that Vert.x 4 will soon be released with support for OpenTracing. We may want Hono to take advantage of those APIs. So maybe this implementation should be aligned with the tracing that Vert.x's Kafka client will produce, which seems to be this https://github.com/vert-x3/vertx-kafka-client/blob/master/src/main/java/io/vertx/kafka/client/common/tracing/TraceTags.java\nWDYT?", "author": "b-abel", "createdAt": "2020-11-18T11:54:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0MzA5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0NDQ0Mw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525244443", "bodyText": "this doesn't seem to be kafka specific, is it?", "author": "sophokles73", "createdAt": "2020-11-17T15:25:54Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/LongTag.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import io.opentracing.Span;\n+import io.opentracing.tag.AbstractTag;\n+\n+/**\n+ * An OpenTracing tag type for {@code long} values.\n+ */\n+public class LongTag extends AbstractTag<Long> {", "originalCommit": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ5MDczOA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529490738", "bodyText": "No, it's not. Let's decide on how to proceed with tracing, then I will move it to a more appropriate location.", "author": "b-abel", "createdAt": "2020-11-24T11:57:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0NDQ0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQ5NzY4MA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529497680", "bodyText": "I do not see any reason why we shouldn't move it to the place where our other OpenTracing related (helper) classes are currently located, or is there? FMPOV this should go into org.eclipse.hono.tracing in the hono-core module ...", "author": "sophokles73", "createdAt": "2020-11-24T12:09:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0NDQ0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTcyNTQzMQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529725431", "bodyText": "I agree. The only reason I did not do it yet is that we discussed if we shouldn't drop the tags for the RecordMetadata and if we do so, I would remove the LongTag as it is not used anywhere else.", "author": "b-abel", "createdAt": "2020-11-24T16:49:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI0NDQ0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NTE3OQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525255179", "bodyText": "can we keep the AMQP related beans together?", "author": "sophokles73", "createdAt": "2020-11-17T15:32:51Z", "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -248,11 +281,24 @@ protected ClientConfigProperties getDownstreamSenderFactoryConfigDefaults() {\n      */\n     @Qualifier(Constants.QUALIFIER_MESSAGING)\n     @Bean\n+    @ConditionalOnAmqpMessaging\n     @Scope(\"prototype\")\n     public HonoConnection downstreamConnection() {\n         return HonoConnection.newConnection(vertx(), downstreamSenderFactoryConfig());\n     }\n \n+    /**\n+     * Exposes a factory for creating producers for sending downstream messages via the Kafka cluster.\n+     *\n+     * @return The factory.\n+     */\n+    @Bean\n+    @Scope(\"prototype\")\n+    @ConditionalOnKafkaMessaging\n+    public CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory() {\n+        return CachingKafkaProducerFactory.sharedProducerFactory(vertx());\n+    }\n+", "originalCommit": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAzMjA5Nw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r526032097", "bodyText": "Done.", "author": "b-abel", "createdAt": "2020-11-18T11:59:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NTE3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NzI5OA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525257298", "bodyText": "IMHO we do not need the conditional annotations because we only instantiate the beans directly by invoking the methods explicitly ...", "author": "sophokles73", "createdAt": "2020-11-17T15:35:02Z", "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -266,13 +312,30 @@ public HonoConnection downstreamConnection() {\n      */\n     @Qualifier(TelemetryConstants.TELEMETRY_ENDPOINT)\n     @Bean\n+    @ConditionalOnAmqpMessaging", "originalCommit": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAyOTA5MQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r526029091", "bodyText": "Do you want to remove Spring Boot? Otherwise, we could refactor ProtonBasedDownstreamSender into two classes, one implementing TelemetrySender and one implementing EventSender and then look up the beans from the ApplicationContext, like you do it with the DeviceConnectionClient. This would remove the ugly if-else block from setCollaborators() and instead take advantage of conditional bean instantiation based on config properties (which are used by the conditional annotations).", "author": "b-abel", "createdAt": "2020-11-18T11:54:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NzI5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcwNjk2Mg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r527706962", "bodyText": "Another option for the conditional bean creation would be to use profiles. This is probably the more common way to handle it with Spring Boot. Quarkus has a concept of profiles as well: https://quarkus.io/guides/config#configuration-profiles", "author": "b-abel", "createdAt": "2020-11-20T13:57:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NzI5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NzIyMw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529387223", "bodyText": "Otherwise, we could refactor ProtonBasedDownstreamSender into two classes, one implementing TelemetrySender and one implementing EventSender and then look up the beans from the ApplicationContext, like you do it with the DeviceConnectionClient.\n\nThis is what #2326 provides.", "author": "b-abel", "createdAt": "2020-11-24T10:02:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NzI5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUwMTM0MQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529501341", "bodyText": "I do not mind the if-else block in setCollaborators for the time being. We will most probably need to do something like that for the Quarkus adapters anyway, as it doesn't support conditional instantiation based on runtime configuration ...", "author": "sophokles73", "createdAt": "2020-11-24T12:16:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI1NzI5OA=="}], "type": "inlineReview"}, {"oid": "c59af806cf4ace9108aa356c0a1793bd046040dd", "url": "https://github.com/eclipse/hono/commit/c59af806cf4ace9108aa356c0a1793bd046040dd", "message": "[#8] Add KafkaConsumerConfigProperties.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2020-11-23T09:03:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2MzkyNA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528663924", "bodyText": "If we want to be able to create fake producers then I guess we should have a KafkaProducerFactory interface which can be mocked for test cases ...", "author": "sophokles73", "createdAt": "2020-11-23T12:20:22Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/CachingKafkaProducerFactory.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import org.apache.kafka.common.errors.AuthorizationException;\n+import org.apache.kafka.common.errors.OutOfOrderSequenceException;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.errors.UnsupportedForMessageFormatException;\n+import org.apache.kafka.common.errors.UnsupportedVersionException;\n+import org.eclipse.hono.kafka.client.test.FakeProducer;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+import io.vertx.core.Vertx;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+\n+/**\n+ * A factory for creating Kafka producers.\n+ * <p>\n+ * This implementation provides no synchronization and should not be used by multiple threads.\n+ * <p>\n+ * Created producers are being cached.\n+ * <p>\n+ * Producers are closed and removed from the cache if they throw a {@link #isFatalError(Throwable) fatal exception}. A\n+ * following invocation of {@link #getOrCreateProducer(String, Map)} will then return a new instance.\n+ *\n+ * @param <K> The type for the record key serialization.\n+ * @param <V> The type for the record value serialization.\n+ */\n+public class CachingKafkaProducerFactory<K, V> {\n+\n+    private final Map<String, KafkaProducer<K, V>> activeProducers = new HashMap<>();\n+    private final BiFunction<String, Map<String, String>, KafkaProducer<K, V>> producerInstanceSupplier;\n+\n+    /**\n+     * Creates a new producer factory.\n+     *\n+     * @param producerInstanceSupplier The function that provides new producer instances.\n+     */\n+    private CachingKafkaProducerFactory(\n+            final BiFunction<String, Map<String, String>, KafkaProducer<K, V>> producerInstanceSupplier) {\n+        this.producerInstanceSupplier = producerInstanceSupplier;\n+    }\n+\n+    /**\n+     * Creates an instance of the factory which produces {@link KafkaProducer#createShared(Vertx, String, Map) shared\n+     * producers}.\n+     * <p>\n+     * Config must always be the same for the same key in {@link #getOrCreateProducer(String, Map)}.\n+     *\n+     * @param vertx The Vert.x instance to use.\n+     * @param <K> The type for the record key serialization.\n+     * @param <V> The type for the record value serialization.\n+     * @return An instance of the factory.\n+     */\n+    public static <K, V> CachingKafkaProducerFactory<K, V> sharedProducerFactory(final Vertx vertx) {\n+        return new CachingKafkaProducerFactory<>((name, config) -> KafkaProducer.createShared(vertx, name, config));\n+    }\n+\n+    /**\n+     * Creates an instance of the factory which produces {@link FakeProducer}s.\n+     * <p>\n+     * This is intended for tests only.\n+     *\n+     * @param <K> The type for the record key serialization.\n+     * @param <V> The type for the record value serialization.\n+     * @return An instance of the factory.\n+     */\n+    public static <K, V> CachingKafkaProducerFactory<K, V> testProducerFactory() {", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NjQzNQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528666435", "bodyText": "FMPOV this method should never return null ...", "author": "sophokles73", "createdAt": "2020-11-23T12:25:07Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/KafkaConsumerConfigProperties.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Configuration properties for Kafka consumers.\n+ * <p>\n+ * This class is intended to be as agnostic to the provided properties as possible in order to be forward-compatible\n+ * with changes in new versions of the Kafka client. It only sets a couple of properties that are important for Hono to\n+ * provide the expected quality of service.\n+ *\n+ * @see <a href=\"https://kafka.apache.org/documentation/#consumerconfigs\">Kafka Consumer Configs</a>\n+ * @see <a href=\"https://www.eclipse.org/hono/docs/api/kafka\">Documentation of Hono's Kafka-based APIs</a>\n+ */\n+// TODO check link to Hono documentation after the API specs are on master\n+public class KafkaConsumerConfigProperties {\n+\n+    private final Logger log = LoggerFactory.getLogger(KafkaConsumerConfigProperties.class);\n+\n+    private Map<String, String> consumerConfig;\n+    private String clientId;\n+\n+    /**\n+     * Sets the Kafka consumer config properties to be used.\n+     *\n+     * @param consumerConfig The config properties.\n+     * @throws NullPointerException if the config is {@code null}.\n+     */\n+    public void setConsumerConfig(final Map<String, String> consumerConfig) {\n+        this.consumerConfig = Objects.requireNonNull(consumerConfig);\n+    }\n+\n+    /**\n+     * Sets the client ID that is passed to the Kafka server to allow application specific server-side request logging.\n+     * <p>\n+     * If the config set in {@link #setConsumerConfig(Map)} already contains a value for key {@code client.id}, that one\n+     * will be used and the parameter here will be ignored.\n+     *\n+     * @param clientId The client ID to set.\n+     * @throws NullPointerException if the client ID is {@code null}.\n+     */\n+    public final void setClientId(final String clientId) {\n+        this.clientId = Objects.requireNonNull(clientId);\n+    }\n+\n+    /**\n+     * Gets the Kafka consumer configuration to which additional properties were applied. The following properties are\n+     * set here to the given configuration:\n+     * <ul>\n+     * <li>{@code key.deserializer=org.apache.kafka.common.serialization.StringDeserializer}: defines how message keys\n+     * are deserialized</li>\n+     * <li>{@code value.deserializer=io.vertx.kafka.client.serialization.BufferDeserializer}: defines how message values\n+     * are deserialized</li>\n+     * <li>{@code client.id} if the property is not already present in the configuration and a value has been set with\n+     * {@link #setClientId(String)}, this value will be taken</li>\n+     * </ul>\n+     *\n+     * @return a copy of the consumer configuration with the applied properties or {@code null} if no consumer", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4ODU4Ng==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529388586", "bodyText": "What are you aiming at? Would you prefer an empty map or do you think an exception should be thrown?", "author": "b-abel", "createdAt": "2020-11-24T10:03:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NjQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQzNDYxMA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529434610", "bodyText": "Such methods usually return an empty map, I'd say. Would that work in this context?", "author": "sophokles73", "createdAt": "2020-11-24T10:41:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NjQzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NjYxNA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528666614", "bodyText": "same here", "author": "sophokles73", "createdAt": "2020-11-23T12:25:28Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/KafkaProducerConfigProperties.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Configuration properties for Kafka producers.\n+ * <p>\n+ * This class is intended to be as agnostic to the provided properties as possible in order to be forward-compatible\n+ * with changes in new versions of the Kafka client. It only sets a couple of properties that are important for Hono to\n+ * provide the expected quality of service.\n+ *\n+ * @see <a href=\"https://kafka.apache.org/documentation/#producerconfigs\">Kafka Producer Configs</a>\n+ * @see <a href=\"https://www.eclipse.org/hono/docs/api/kafka\">Documentation of Hono's Kafka-based APIs</a>\n+ */\n+// TODO check link to Hono documentation after the API specs are on master\n+public class KafkaProducerConfigProperties {\n+\n+    private final Logger log = LoggerFactory.getLogger(KafkaProducerConfigProperties.class);\n+\n+    private Map<String, String> producerConfig;\n+    private String clientId;\n+\n+    /**\n+     * Sets the Kafka producer config properties to be used.\n+     *\n+     * @param producerConfig The config properties.\n+     * @throws NullPointerException if the config is {@code null}.\n+     */\n+    public void setProducerConfig(final Map<String, String> producerConfig) {\n+        this.producerConfig = Objects.requireNonNull(producerConfig);\n+    }\n+\n+    /**\n+     * Sets the client ID that is passed to the Kafka server to allow application specific server-side request logging.\n+     * <p>\n+     * If the config set in {@link #setProducerConfig(Map)} already contains a value for key {@code client.id}, that one\n+     * will be used and the parameter here will be ignored.\n+     *\n+     * @param clientId The client ID to set.\n+     * @throws NullPointerException if the client ID is {@code null}.\n+     */\n+    public final void setClientId(final String clientId) {\n+        this.clientId = Objects.requireNonNull(clientId);\n+    }\n+\n+    /**\n+     * Gets the Kafka producer configuration to which additional properties were applied. The following properties are\n+     * set here to the given configuration:\n+     * <ul>\n+     * <li>{@code enable.idempotence=true}: enables idempotent producer behavior</li>\n+     * <li>{@code key.serializer=org.apache.kafka.common.serialization.StringSerializer}: defines how message keys are\n+     * serialized</li>\n+     * <li>{@code value.serializer=io.vertx.kafka.client.serialization.BufferSerializer}: defines how message values are\n+     * serialized</li>\n+     *\n+     * <li>{@code client.id} if the property is not already present in the configuration and a value has been set with\n+     * {@link #setClientId(String)}, this value will be taken</li>\n+     * </ul>\n+     *\n+     * @return a copy of the producer configuration with the applied properties or {@code null} if no producer", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NzcwMA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528667700", "bodyText": "IMHO this should use KafkaHeader.header(key, value) instead ...", "author": "sophokles73", "createdAt": "2020-11-23T12:27:31Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/KafkaHeaderInjectAdapter.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map.Entry;\n+\n+import io.opentracing.propagation.TextMap;\n+import io.vertx.kafka.client.producer.KafkaHeader;\n+import io.vertx.kafka.client.producer.impl.KafkaHeaderImpl;\n+\n+/**\n+ * An adapter for injecting properties as a new {@link KafkaHeader} to a list of Vert.x Kafka producer headers.\n+ *\n+ */\n+public class KafkaHeaderInjectAdapter implements TextMap {\n+\n+    private final List<KafkaHeader> headers;\n+\n+    /**\n+     * Creates an adapter for a list of {@link KafkaHeader} objects.\n+     *\n+     * @param headers The list of {@link KafkaHeader} objects.\n+     */\n+    public KafkaHeaderInjectAdapter(final List<KafkaHeader> headers) {\n+        this.headers = headers;\n+    }\n+\n+    @Override\n+    public Iterator<Entry<String, String>> iterator() {\n+        throw new UnsupportedOperationException();\n+    }\n+\n+    @Override\n+    public void put(final String key, final String value) {\n+        headers.add(new KafkaHeaderImpl(key, value));", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY2NzgwNA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528667804", "bodyText": "final ?", "author": "sophokles73", "createdAt": "2020-11-23T12:27:45Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/KafkaHeaderInjectAdapter.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map.Entry;\n+\n+import io.opentracing.propagation.TextMap;\n+import io.vertx.kafka.client.producer.KafkaHeader;\n+import io.vertx.kafka.client.producer.impl.KafkaHeaderImpl;\n+\n+/**\n+ * An adapter for injecting properties as a new {@link KafkaHeader} to a list of Vert.x Kafka producer headers.\n+ *\n+ */\n+public class KafkaHeaderInjectAdapter implements TextMap {", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3NTc3NQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r528675775", "bodyText": "does this work (i.e. doesn't throw a runtime exception) if no hono.kafka properties are set at all?", "author": "sophokles73", "createdAt": "2020-11-23T12:42:26Z", "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -134,14 +141,24 @@ protected void setCollaborators(\n             adapter.setCommandConsumerFactory(commandConsumerFactory(adapterProperties, samplerFactory, commandRouterClient));\n         }\n \n+        final KafkaProducerConfigProperties kafkaProducerConfig = kafkaProducerConfig();", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NjYwNg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529386606", "bodyText": "Yes. That is the case when KafkaProducerConfigProperties.getProducerConfig() returns null (see discussion above).\nBut I would prefer to use the change in #2326 which would make this construct obsolete.", "author": "b-abel", "createdAt": "2020-11-24T10:01:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODY3NTc3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI4MDcxOA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r525280718", "bodyText": "How about final EncodeException e?", "author": "kaniyan", "createdAt": "2020-11-17T16:03:31Z", "path": "clients/adapter-kafka/src/main/java/org/eclipse/hono/adapter/client/telemetry/kafka/AbstractKafkaBasedDownstreamSender.java", "diffHunk": "@@ -0,0 +1,288 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.adapter.client.telemetry.kafka;\n+\n+import java.net.HttpURLConnection;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+import org.eclipse.hono.client.ServerErrorException;\n+import org.eclipse.hono.kafka.client.CachingKafkaProducerFactory;\n+import org.eclipse.hono.kafka.client.HonoTopic;\n+import org.eclipse.hono.kafka.client.tracing.KafkaTracingHelper;\n+import org.eclipse.hono.tracing.TracingHelper;\n+import org.eclipse.hono.util.Lifecycle;\n+import org.eclipse.hono.util.MessageHelper;\n+import org.eclipse.hono.util.QoS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import io.opentracing.References;\n+import io.opentracing.Span;\n+import io.opentracing.SpanContext;\n+import io.opentracing.Tracer;\n+import io.opentracing.tag.Tags;\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.EncodeException;\n+import io.vertx.core.json.Json;\n+import io.vertx.kafka.client.producer.KafkaHeader;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+import io.vertx.kafka.client.producer.KafkaProducerRecord;\n+import io.vertx.kafka.client.producer.RecordMetadata;\n+import io.vertx.kafka.client.producer.impl.KafkaHeaderImpl;\n+\n+/**\n+ * A client for publishing messages to a Kafka cluster.\n+ */\n+public abstract class AbstractKafkaBasedDownstreamSender implements Lifecycle {\n+\n+    /**\n+     * A logger to be shared with subclasses.\n+     */\n+    protected final Logger log = LoggerFactory.getLogger(getClass());\n+\n+    private final CachingKafkaProducerFactory<String, Buffer> producerFactory;\n+    private final String producerName;\n+    private final Map<String, String> config;\n+    private final Tracer tracer;\n+\n+    /**\n+     * Creates a new Kafka-based telemetry sender.\n+     *\n+     * @param producerFactory The factory to use for creating Kafka producers.\n+     * @param producerName The producer name to use.\n+     * @param config The Kafka producer configuration properties to use.\n+     * @param tracer The OpenTracing tracer.\n+     * @throws NullPointerException if any of the parameters are {@code null}.\n+     */\n+\n+    public AbstractKafkaBasedDownstreamSender(final CachingKafkaProducerFactory<String, Buffer> producerFactory,\n+            final String producerName, final Map<String, String> config, final Tracer tracer) {\n+\n+        Objects.requireNonNull(producerFactory);\n+        Objects.requireNonNull(producerName);\n+        Objects.requireNonNull(config);\n+        Objects.requireNonNull(tracer);\n+\n+        this.config = config;\n+        this.producerName = producerName;\n+        this.tracer = tracer;\n+        this.producerFactory = producerFactory;\n+    }\n+\n+    /**\n+     * Sends a message downstream.\n+     *\n+     * @param topic The topic to send the message to.\n+     * @param tenantId The ID of the tenant that the device belongs to.\n+     * @param deviceId The ID of the device that the data originates from.\n+     * @param qos The delivery semantics to use for sending the data.\n+     * @param contentType The content type of the data.\n+     * @param payload The data to send.\n+     * @param properties Additional meta data that should be included in the downstream message.\n+     * @param context The currently active OpenTracing span (may be {@code null}). An implementation should use this as\n+     *            the parent for any span it creates for tracing the execution of this operation.\n+     * @return A future indicating the outcome of the operation.\n+     *         <p>\n+     *         The future will be succeeded if the message has been sent downstream.\n+     *         <p>\n+     *         The future will be failed with a {@link org.eclipse.hono.client.ServerErrorException} if the data could\n+     *         not be sent. The error code contained in the exception indicates the cause of the failure.\n+     * @throws NullPointerException if topic, tenant ID, device ID, qos or contentType are {@code null}.\n+     */\n+    protected Future<Void> send(final HonoTopic topic, final String tenantId, final String deviceId, final QoS qos,\n+            final String contentType, final Buffer payload, final Map<String, Object> properties,\n+            final SpanContext context) {\n+\n+        Objects.requireNonNull(topic);\n+        Objects.requireNonNull(tenantId);\n+        Objects.requireNonNull(deviceId);\n+        Objects.requireNonNull(qos);\n+        Objects.requireNonNull(contentType);\n+\n+        log.trace(\"sending to Kafka [topic: {}, tenantId: {}, deviceId: {}, qos: {}, contentType: {}, properties: {}]\",\n+                topic, tenantId, deviceId, qos, contentType, properties);\n+        final Span span = startSpan(topic, tenantId, deviceId, qos, contentType, context);\n+\n+        final KafkaProducerRecord<String, Buffer> record = KafkaProducerRecord.create(topic.toString(), deviceId,\n+                payload);\n+        record.addHeaders(createHeaders(properties, deviceId, qos, contentType, span));\n+\n+        KafkaTracingHelper.injectSpanContext(tracer, record, span.context());\n+        logProducerRecord(span, record);\n+\n+        final Promise<RecordMetadata> promise = Promise.promise();\n+        getOrCreateProducer().send(record, promise);\n+\n+        final Future<Void> producerFuture = promise.future()\n+                .recover(t -> {\n+                    logError(span, topic, tenantId, deviceId, qos, t);\n+                    span.finish();\n+                    return Future.failedFuture(new ServerErrorException(getErrorCode(t), t));\n+                })\n+                .map(recordMetadata -> {\n+                    logRecordMetadata(span, deviceId, recordMetadata);\n+                    span.finish();\n+                    return null;\n+                });\n+\n+        return qos.equals(QoS.AT_MOST_ONCE) ? Future.succeededFuture() : producerFuture;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * Starts the producer.\n+     */\n+    @Override\n+    public Future<Void> start() {\n+        getOrCreateProducer();\n+        return Future.succeededFuture();\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * Stops the producer.\n+     */\n+    @Override\n+    public Future<Void> stop() {\n+        return producerFactory.removeProducer(producerName);\n+    }\n+\n+    private KafkaProducer<String, Buffer> getOrCreateProducer() {\n+        return producerFactory.getOrCreateProducer(producerName, config);\n+    }\n+\n+    private List<KafkaHeader> createHeaders(final Map<String, Object> properties, final String deviceId,\n+            final QoS qos, final String contentType, final Span span) {\n+\n+        // ensure that we have a modifiable map\n+        final Map<String, Object> headerProperties = new HashMap<>();\n+        if (properties != null) {\n+            headerProperties.putAll(properties);\n+        }\n+\n+        setStandardProperties(headerProperties, deviceId, qos, contentType);\n+\n+        return encodePropertiesAsKafkaHeaders(headerProperties, span);\n+    }\n+\n+    private void setStandardProperties(final Map<String, Object> headerProperties, final String deviceId,\n+            final QoS qos, final String contentType) {\n+\n+        // ensure that the standard properties are set correctly\n+        headerProperties.put(MessageHelper.SYS_PROPERTY_CONTENT_TYPE, contentType);\n+        headerProperties.put(MessageHelper.APP_PROPERTY_DEVICE_ID, deviceId);\n+        headerProperties.put(MessageHelper.APP_PROPERTY_QOS, qos.ordinal());\n+\n+        if (headerProperties.containsKey(MessageHelper.APP_PROPERTY_DEVICE_TTD)\n+                && !headerProperties.containsKey(MessageHelper.SYS_PROPERTY_CREATION_TIME)) {\n+            // TODO set this as creation time in the KafkaRecord?\n+\n+            // must match http://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-types-v1.0-os.html#type-timestamp\n+            // as defined in https://www.eclipse.org/hono/docs/api/telemetry/#forward-telemetry-data\n+            final long timestamp = Instant.now().toEpochMilli();\n+            headerProperties.put(MessageHelper.SYS_PROPERTY_CREATION_TIME, timestamp);\n+        }\n+    }\n+\n+    private List<KafkaHeader> encodePropertiesAsKafkaHeaders(final Map<String, Object> properties, final Span span) {\n+        final List<KafkaHeader> headers = new ArrayList<>();\n+        properties.forEach((k, v) -> {\n+            try {\n+                final Buffer headerValue = (v instanceof String)\n+                        ? Buffer.buffer((String) v)\n+                        : Buffer.buffer(Json.encode(v));\n+\n+                headers.add(new KafkaHeaderImpl(k, headerValue));\n+            } catch (EncodeException e) {", "originalCommit": "cc1cf9fd77ef2d40d274d0efd10c6367ce299dce", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4ODA5MQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529288091", "bodyText": "AFAIK CachingClientFactory is quite generic and I think it can also accommodate Kafka clients and in this case KafkaProducer? Then we could reuse the code and IMHO having a uniform style throughout, makes the code easier to understand. I am just curious to know if there are any reasons to have a new  CachingKafkaProducerFactory.", "author": "kaniyan", "createdAt": "2020-11-24T08:29:45Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/CachingKafkaProducerFactory.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+\n+import org.apache.kafka.common.errors.AuthorizationException;\n+import org.apache.kafka.common.errors.OutOfOrderSequenceException;\n+import org.apache.kafka.common.errors.ProducerFencedException;\n+import org.apache.kafka.common.errors.UnsupportedForMessageFormatException;\n+import org.apache.kafka.common.errors.UnsupportedVersionException;\n+import org.eclipse.hono.kafka.client.test.FakeProducer;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+import io.vertx.core.Vertx;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+\n+/**\n+ * A factory for creating Kafka producers.\n+ * <p>\n+ * This implementation provides no synchronization and should not be used by multiple threads.\n+ * <p>\n+ * Created producers are being cached.\n+ * <p>\n+ * Producers are closed and removed from the cache if they throw a {@link #isFatalError(Throwable) fatal exception}. A\n+ * following invocation of {@link #getOrCreateProducer(String, Map)} will then return a new instance.\n+ *\n+ * @param <K> The type for the record key serialization.\n+ * @param <V> The type for the record value serialization.\n+ */\n+public class CachingKafkaProducerFactory<K, V> {", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyMjY1NA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r530522654", "bodyText": "CachingClientFactory was not public when I wrote the code.\nFMPOV the CachingKafkaProducerFactory is not comparable to CachingClientFactory but more to the sender factories like org.eclipse.hono.client.impl.DownstreamSenderFactoryImpl. It might be that the naming causes confusion.\nI could have used CachingClientFactory inside of CachingKafkaProducerFactory to hold the producer instances. But it does not fit well because it is designed around managing a connection and synchronizing expensive client creation. Using a shared KafkaProducer all of this is already provided by io.vertx.kafka.client.producer.impl.KafkaProducerImpl, so I think a simple map is sufficient to hold the producer.", "author": "b-abel", "createdAt": "2020-11-25T17:01:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4ODA5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTI4OTc4Nw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529289787", "bodyText": "How about final Exception e?", "author": "kaniyan", "createdAt": "2020-11-24T08:32:24Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/test/FakeProducer.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.test;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import org.apache.kafka.clients.producer.MockProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.kafka.client.common.PartitionInfo;\n+import io.vertx.kafka.client.common.impl.Helper;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+import io.vertx.kafka.client.producer.KafkaProducerRecord;\n+import io.vertx.kafka.client.producer.KafkaWriteStream;\n+import io.vertx.kafka.client.producer.RecordMetadata;\n+\n+/**\n+ * This is a fake Kafka producer. It provides the Vert.x abstraction for the {@link MockProducer} of Kafka's client.\n+ * <p>\n+ * This does not support every Vert.x <em>stream</em> related operation.\n+ * <p>\n+ * <b>Usage Example:</b>\n+ * <pre>\n+ * {@code\n+ *     final FakeProducer<String, String> fakeProducer = new FakeProducer<>();\n+ *\n+ *     final Handler<AsyncResult<RecordMetadata>> resultHandler = asyncResult -> {\n+ *         if (asyncResult.succeeded()) {\n+ *             System.out.println(\"Record produced successfully to topic: \" + asyncResult.result().getTopic());\n+ *         } else {\n+ *             System.out.println(\"Sending record failed: \" + asyncResult.cause().getMessage());\n+ *         }\n+ *     };\n+ *\n+ *     // send two records\n+ *     fakeProducer.send(new KafkaProducerRecordImpl<>(\"my-topic\", \"first message\"), resultHandler);\n+ *     fakeProducer.send(new KafkaProducerRecordImpl<>(\"my-topic\", \"second message\"), resultHandler);\n+ *\n+ *     final MockProducer<String, String> mockProducer = fakeProducer.getMockProducer();\n+ *\n+ *     // completes the result handler of the first record successfully\n+ *     mockProducer.completeNext();\n+ *     // fails the result handler of the second record\n+ *     mockProducer.errorNext(new KafkaException(\"something went wrong\"));\n+ *\n+ *     // inspect the sent records\n+ *     final ProducerRecord<String, String> firstRecord = mockProducer.history().get(0);\n+ *     System.out.println(firstRecord);\n+ *\n+ *     final ProducerRecord<String, String> secondRecord = mockProducer.history().get(1);\n+ *     System.out.println(secondRecord);\n+ *\n+ *     // clean the history...\n+ *     mockProducer.clear();\n+ *     // ... or close it if you are done\n+ *     mockProducer.close();\n+ * }\n+ * </pre>\n+ *\n+ * @param <K> The type for the record key serialization.\n+ * @param <V> The type for the record value serialization.\n+ */\n+public class FakeProducer<K, V> implements KafkaProducer<K, V> {\n+\n+    private final MockProducer<K, V> producer;\n+    private Handler<Throwable> exceptionHandler;\n+\n+    /**\n+     * Creates a fake producer with a new instance of {@link MockProducer#MockProducer()}.\n+     */\n+    public FakeProducer() {\n+        producer = new MockProducer<>();\n+    }\n+\n+    /**\n+     * Creates a fake producer with the given mock producer instance.\n+     *\n+     * @param producer The mock producer to be used.\n+     */\n+    public FakeProducer(final MockProducer<K, V> producer) {\n+        this.producer = producer;\n+    }\n+\n+    /**\n+     * Gets the underlying {@link MockProducer}.\n+     *\n+     * @return the mock producer.\n+     */\n+    public MockProducer<K, V> getMockProducer() {\n+        return producer;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> exceptionHandler(final Handler<Throwable> handler) {\n+        this.exceptionHandler = handler;\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> write(final KafkaProducerRecord<K, V> kafkaProducerRecord) {\n+        write(kafkaProducerRecord, null);\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * This implementation simply returns {@code this}.\n+     */\n+    @Override\n+    public KafkaProducer<K, V> setWriteQueueMaxSize(final int i) {\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * This implementation always returns {@code false}.\n+     */\n+    @Override\n+    public boolean writeQueueFull() {\n+        return false;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     * <p>\n+     * This implementation simply returns {@code this}.\n+     */\n+    @Override\n+    public KafkaProducer<K, V> drainHandler(final Handler<Void> handler) {\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> write(final KafkaProducerRecord<K, V> data, final Handler<AsyncResult<Void>> handler) {\n+        Handler<AsyncResult<RecordMetadata>> mdHandler = null;\n+        if (handler != null) {\n+            mdHandler = ar -> handler.handle(ar.mapEmpty());\n+        }\n+        send(data, mdHandler);\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void end() {\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void end(final Handler<AsyncResult<Void>> handler) {\n+        if (handler != null) {\n+            handler.handle(Future.succeededFuture());\n+        }\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> send(final KafkaProducerRecord<K, V> record) {\n+        send(record, null);\n+        return this;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public KafkaProducer<K, V> send(final KafkaProducerRecord<K, V> record,\n+            final Handler<AsyncResult<RecordMetadata>> handler) {\n+\n+        try {\n+            producer.send(record.record(), (metadata, err) -> {\n+                if (err != null) {\n+                    if (exceptionHandler != null) {\n+                        exceptionHandler.handle(err);\n+                    }\n+                    if (handler != null) {\n+                        handler.handle(Future.failedFuture(err));\n+                    }\n+                } else if (handler != null) {\n+                    handler.handle(Future.succeededFuture(Helper.from(metadata)));\n+                }\n+            });\n+        } catch (Exception e) {", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NDczNw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529384737", "bodyText": "I added #2326. This simplifies this part to the following, by leveraging conditional bean creation:\n// look up client via bean factory in order to take advantage of conditional bean instantiation based\n// on config properties\nadapter.setEventSender(context.getBean(EventSender.class));\nadapter.setTelemetrySender(context.getBean(TelemetrySender.class));\nAdditionally, I can then change the class KafkaProducerConfig to no longer return null.\n@sophokles73 WDYT?", "author": "b-abel", "createdAt": "2020-11-24T10:00:16Z", "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -134,14 +141,24 @@ protected void setCollaborators(\n             adapter.setCommandConsumerFactory(commandConsumerFactory(adapterProperties, samplerFactory, commandRouterClient));\n         }\n \n+        final KafkaProducerConfigProperties kafkaProducerConfig = kafkaProducerConfig();\n+        if (kafkaProducerConfig.getProducerConfig() == null) {\n+            // look up via bean factory is not possible because EventSender and TelemetrySender are implemented by\n+            // ProtonBasedDownstreamSender\n+            adapter.setEventSender(downstreamEventSender(samplerFactory, adapterProperties));\n+            adapter.setTelemetrySender(downstreamTelemetrySender(samplerFactory, adapterProperties));\n+        } else {\n+            final CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory = kafkaProducerFactory();\n+            adapter.setEventSender(downstreamEventKafkaSender(kafkaProducerFactory, kafkaProducerConfig));\n+            adapter.setTelemetrySender(downstreamTelemetryKafkaSender(kafkaProducerFactory, kafkaProducerConfig));\n+        }\n+", "originalCommit": "9fe7b813f22a6f207dfbda02ae89f824ed28f61e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUwNzczMg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529507732", "bodyText": "both the event sender  and the telemetry sender seem to use the same configuration, or am I mistaken? If that is the case, what advantage does it have to create two separate senders? is there a reason why they shouldn't use the same KafkaProducer instance (and the same connection to the Kafka cluster)?", "author": "sophokles73", "createdAt": "2020-11-24T12:28:01Z", "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -297,13 +332,58 @@ public TelemetrySender downstreamTelemetrySender(\n      */\n     @Qualifier(EventConstants.EVENT_ENDPOINT)\n     @Bean\n+    @ConditionalOnAmqpMessaging\n     @Scope(\"prototype\")\n     public EventSender downstreamEventSender(\n             final SendMessageSampler.Factory samplerFactory,\n             final ProtocolAdapterProperties adapterConfig) {\n         return new ProtonBasedDownstreamSender(downstreamConnection(), samplerFactory, adapterConfig);\n     }\n \n+    /**\n+     * Exposes a factory for creating producers for sending downstream messages via the Kafka cluster.\n+     *\n+     * @return The factory.\n+     */\n+    @Bean\n+    @Scope(\"prototype\")\n+    @ConditionalOnKafkaMessaging\n+    public CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory() {\n+        return CachingKafkaProducerFactory.sharedProducerFactory(vertx());\n+    }\n+\n+    /**\n+     * Exposes a client for sending telemetry messages via <em>Kafka</em> as a Spring bean.\n+     *\n+     * @return The client.\n+     * @param kafkaProducerFactory The producer factory to use.\n+     * @param kafkaProducerConfig The producer configuration to use.\n+     */\n+    @Bean\n+    @ConditionalOnKafkaMessaging\n+    @Scope(\"prototype\")\n+    public TelemetrySender downstreamTelemetryKafkaSender(\n+            final CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory,\n+            final KafkaProducerConfigProperties kafkaProducerConfig) {\n+        return new KafkaBasedTelemetrySender(kafkaProducerFactory, kafkaProducerConfig, getTracer());\n+    }\n+\n+    /**\n+     * Exposes a client for sending events via <em>Kafka</em> as a Spring bean.\n+     *\n+     * @return The client.\n+     * @param kafkaProducerFactory The producer factory to use.\n+     * @param kafkaProducerConfig The producer configuration to use.\n+     */\n+    @Bean\n+    @ConditionalOnKafkaMessaging\n+    @Scope(\"prototype\")\n+    public EventSender downstreamEventKafkaSender(\n+            final CachingKafkaProducerFactory<String, Buffer> kafkaProducerFactory,\n+            final KafkaProducerConfigProperties kafkaProducerConfig) {\n+        return new KafkaBasedEventSender(kafkaProducerFactory, kafkaProducerConfig, getTracer());", "originalCommit": "a0dfdbf7c15ef661fb553e1acb2ea4272b417ea5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1NjY0NQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r529756645", "bodyText": "These are very valid questions. I just had no idea where I could explain the reasoning behind it.\nIn general, a Kafka client does not open a single connection but rather connects to the brokers to whose partitions it sends messages, i.e. between 1 and the cluster size. Since the topics for events and telemetry do not have to be on the same brokers, on average there are not many more connections through the separate sender instances.\nI see it as an advantage that the \"rare but important\" events do not have to wait in the same queue as the much more frequent telemetry messages. Since the messages are collected in batches before sending and are sent in sequence with retries and rather generous timeouts (the default timeout for sending is 2 minutes), I expect a lower latency for events under load.\nI would also like us to have the possibility to decide later that both types of messages should be configured differently.", "author": "b-abel", "createdAt": "2020-11-24T17:34:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTUwNzczMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg0NDg4MQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r534844881", "bodyText": "IMHO it would be helpful if the description would explain who needs to invoke this method and why?\nIn particular, it seems that you do not want to let clients invoke the KafkaProducer.close() method.\nDo all the producers need to be closed when shutting down the system? Should this factory take care of that?", "author": "sophokles73", "createdAt": "2020-12-03T07:51:28Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/KafkaProducerFactory.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client;\n+\n+import java.util.Map;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Vertx;\n+import io.vertx.kafka.client.producer.KafkaProducer;\n+\n+/**\n+ * A factory for creating Kafka producers.\n+ *\n+ * @param <K> The type for the record key serialization.\n+ * @param <V> The type for the record value serialization.\n+ */\n+public interface KafkaProducerFactory<K, V> {\n+\n+    /**\n+     * Creates a new factory which produces {@link KafkaProducer#createShared(Vertx, String, Map) shared producers}.\n+     * Shared producers\n+     * can safely be shared between verticle instances.\n+     * <p>\n+     * Config must always be the same for the same key in {@link #getOrCreateProducer(String, Map)}.\n+     *\n+     * @param vertx The Vert.x instance to use.\n+     * @param <K> The type for the record key serialization.\n+     * @param <V> The type for the record value serialization.\n+     * @return An instance of the factory.\n+     */\n+    static <K, V> KafkaProducerFactory<K, V> sharedProducerFactory(final Vertx vertx) {\n+        return new CachingKafkaProducerFactory<>((name, config) -> KafkaProducer.createShared(vertx, name, config));\n+    }\n+\n+    /**\n+     * Gets a producer for sending data to Kafka.\n+     * <p>\n+     * The producer returned may be either newly created or it may be an existing producer for the given producer name.\n+     * The config parameter might be ignored if an existing producer is returned.\n+     *\n+     * @param producerName The name to identify the producer.\n+     * @param config The Kafka configuration with which the producer is to be created.\n+     * @return an existing or new producer.\n+     */\n+    KafkaProducer<K, V> getOrCreateProducer(String producerName, Map<String, String> config);\n+\n+    /**\n+     * Closes the producer with the given producer name if it exists.\n+     *\n+     * @param producerName The name of the producer to remove.\n+     * @return A future that is completed when the close operation completed or a succeeded future if no producer\n+     *         existed with the given name.\n+     */\n+    Future<Void> closeProducer(String producerName);", "originalCommit": "c33956dc6e7dcbb4ceae0313a2726e18fd9b5509", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ5MzM5Mw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r535493393", "bodyText": "I added explanations in my last commit. Are they helpful?", "author": "b-abel", "createdAt": "2020-12-03T18:49:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg0NDg4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg1MDMxMw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r534850313", "bodyText": "this seems to be kind of the Hono standard producer supplier, isn't it? I wonder if every client needs to create this again and again or if we can use this as the default supplier in CachingKafkaProducerFactory instead ...", "author": "sophokles73", "createdAt": "2020-12-03T07:54:33Z", "path": "clients/kafka-common/src/test/java/org/eclipse/hono/kafka/client/CachingKafkaProducerFactoryTest.java", "diffHunk": "@@ -49,7 +59,25 @@\n \n     @BeforeEach\n     void setUp() {\n-        factory = CachingKafkaProducerFactory.testProducerFactory();\n+\n+        final Vertx vertxMock = mock(Vertx.class);\n+        final Context context = VertxMockSupport.mockContext(vertxMock);\n+        when(vertxMock.getOrCreateContext()).thenReturn(context);\n+\n+        doAnswer(invocation -> {\n+            final Promise<RecordMetadata> result = Promise.promise();\n+            final Handler<Future<RecordMetadata>> blockingCode = invocation.getArgument(0);\n+            blockingCode.handle(result.future());\n+            return null;\n+        }).when(context).executeBlocking(VertxMockSupport.anyHandler(), any());\n+\n+        final BiFunction<String, Map<String, String>, KafkaProducer<String, Buffer>> instanceSupplier = (n, c) -> {\n+            final MockProducer<String, Buffer> mockProducer = new MockProducer<>(true, new StringSerializer(),\n+                    new BufferSerializer());\n+            return KafkaProducer.create(vertxMock, mockProducer);\n+        };", "originalCommit": "c33956dc6e7dcbb4ceae0313a2726e18fd9b5509", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ5MjQ0Mw==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r535492443", "bodyText": "This is only the standard producer supplier for unit tests. For productive usage, you would use KafkaProducerFactory.sharedProducerFactory()`. Does this make sense from your POV?", "author": "b-abel", "createdAt": "2020-12-03T18:48:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg1MDMxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg1OTc5NQ==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r534859795", "bodyText": "This should return a KafkaProducerFactory shouldn't it?", "author": "sophokles73", "createdAt": "2020-12-03T07:59:58Z", "path": "clients/adapter-kafka/src/test/java/org/eclipse/hono/adapter/client/telemetry/kafka/TestHelper.java", "diffHunk": "@@ -30,41 +48,65 @@ private TestHelper() {\n     }\n \n     /**\n-     * Gets the {@link MockProducer} for the given producer name from a factory.\n+     * Returns a new {@link org.eclipse.hono.client.impl.CachingClientFactory} for the given native {@link Producer}.\n+     * <p>\n+     * All producers returned by this factory will use the given native producer instance wrapped in a\n+     * {@link KafkaProducer}.\n      *\n-     * @param producerFactory The factory containing the {@link FakeProducer}.\n-     * @param producerName The name under which the fake producer is cached in the factory.\n-     * @param <K> The type for the record key serialization.\n-     * @param <V> The type for the record value serialization.\n-     * @return The mock producer.\n-     *\n-     * @throws NoSuchElementException if the given factory does not contain the expected producer (e.g. when the\n-     *             producer got closed after a fatal error).\n-     * @throws ClassCastException if the provided producer implementation is not an instance of {@link FakeProducer}.\n+     * @param producer The (mock) producer to be wrapped.\n+     * @return The producer factory.\n      */\n-    public static <K, V> MockProducer<K, V> getUnderlyingMockProducer(\n-            final CachingKafkaProducerFactory<K, V> producerFactory, final String producerName) {\n+    public static CachingKafkaProducerFactory<String, Buffer> newProducerFactory(", "originalCommit": "c33956dc6e7dcbb4ceae0313a2726e18fd9b5509", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ5MjUxMg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r535492512", "bodyText": "This method intentionally returns the implementation. The idea is that the factory manages the lifecycle of the producers. In unit tests, I can easily inspect the internal state by invoking CachingKafkaProducerFactory.getProducer(), a method that is not part of the interface.", "author": "b-abel", "createdAt": "2020-12-03T18:48:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDg1OTc5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE5NjA1Ng==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r542196056", "bodyText": "I guess the headers param is mandatory and should therefore be checked for null?", "author": "sophokles73", "createdAt": "2020-12-14T08:30:34Z", "path": "clients/kafka-common/src/main/java/org/eclipse/hono/kafka/client/tracing/KafkaHeaderInjectAdapter.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Copyright (c) 2020 Contributors to the Eclipse Foundation\n+ *\n+ * See the NOTICE file(s) distributed with this work for additional\n+ * information regarding copyright ownership.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Eclipse Public License 2.0 which is available at\n+ * http://www.eclipse.org/legal/epl-2.0\n+ *\n+ * SPDX-License-Identifier: EPL-2.0\n+ */\n+\n+package org.eclipse.hono.kafka.client.tracing;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map.Entry;\n+\n+import io.opentracing.propagation.TextMap;\n+import io.vertx.kafka.client.producer.KafkaHeader;\n+\n+/**\n+ * An adapter for injecting properties as a new {@link KafkaHeader} to a list of Vert.x Kafka producer headers.\n+ *\n+ */\n+public final class KafkaHeaderInjectAdapter implements TextMap {\n+\n+    private final List<KafkaHeader> headers;\n+\n+    /**\n+     * Creates an adapter for a list of {@link KafkaHeader} objects.\n+     *\n+     * @param headers The list of {@link KafkaHeader} objects.", "originalCommit": "1d19342dc5ca057b77116006326a28caeb33d239", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzE0MjcxOA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r543142718", "bodyText": "Right. Good catch, thank you.", "author": "b-abel", "createdAt": "2020-12-15T08:31:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE5NjA1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE5Nzg4Mg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r542197882", "bodyText": "IMHO we should better add a KafkaProducerConfigProperties.isConfigured() method in order to decouple the test from the inner structure of the properties object. WDYT?", "author": "sophokles73", "createdAt": "2020-12-14T08:33:38Z", "path": "service-base/src/main/java/org/eclipse/hono/service/AbstractAdapterConfig.java", "diffHunk": "@@ -134,14 +139,26 @@ protected void setCollaborators(\n             adapter.setCommandConsumerFactory(commandConsumerFactory(adapterProperties, samplerFactory, commandRouterClient));\n         }\n \n+        final KafkaProducerConfigProperties kafkaProducerConfig = kafkaProducerConfig();\n+        if (kafkaProducerConfig.getProducerConfig().isEmpty()) {", "originalCommit": "1d19342dc5ca057b77116006326a28caeb33d239", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzE0Mjc5MA==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r543142790", "bodyText": "This is a good idea. I will do it.", "author": "b-abel", "createdAt": "2020-12-15T08:31:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE5Nzg4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDk1NzA0Mg==", "url": "https://github.com/eclipse/hono/pull/2303#discussion_r544957042", "bodyText": "Missing null check for the adapterConfig.", "author": "kaniyan", "createdAt": "2020-12-17T09:55:59Z", "path": "clients/adapter-kafka/src/main/java/org/eclipse/hono/adapter/client/telemetry/kafka/AbstractKafkaBasedDownstreamSender.java", "diffHunk": "@@ -72,22 +74,25 @@\n      * @param producerFactory The factory to use for creating Kafka producers.\n      * @param producerName The producer name to use.\n      * @param config The Kafka producer configuration properties to use.\n+     * @param adapterConfig The protocol adapter's configuration properties.\n      * @param tracer The OpenTracing tracer.\n      * @throws NullPointerException if any of the parameters are {@code null}.\n      */\n \n     public AbstractKafkaBasedDownstreamSender(final KafkaProducerFactory<String, Buffer> producerFactory,\n-            final String producerName, final Map<String, String> config, final Tracer tracer) {\n+            final String producerName, final Map<String, String> config, final ProtocolAdapterProperties adapterConfig,\n+            final Tracer tracer) {\n \n         Objects.requireNonNull(producerFactory);\n         Objects.requireNonNull(producerName);\n         Objects.requireNonNull(config);\n         Objects.requireNonNull(tracer);\n \n-        this.config = config;\n+        this.producerFactory = producerFactory;\n         this.producerName = producerName;\n+        this.config = config;\n+        this.adapterConfig = adapterConfig;", "originalCommit": "503a37d795895ac01342e95b422341274d6ca79e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "286d04671fc5ced239831cbec32bc1c15d77bf23", "url": "https://github.com/eclipse/hono/commit/286d04671fc5ced239831cbec32bc1c15d77bf23", "message": "[#8] Update Hono version in hono kafka client and release notes.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2020-12-17T14:30:31Z", "type": "forcePushed"}, {"oid": "590952720f42998b5ae9d692230611225404d766", "url": "https://github.com/eclipse/hono/commit/590952720f42998b5ae9d692230611225404d766", "message": "[#8] Add a Kafka based client for downstream messages.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2020-12-17T16:37:18Z", "type": "commit"}, {"oid": "590952720f42998b5ae9d692230611225404d766", "url": "https://github.com/eclipse/hono/commit/590952720f42998b5ae9d692230611225404d766", "message": "[#8] Add a Kafka based client for downstream messages.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2020-12-17T16:37:18Z", "type": "forcePushed"}]}