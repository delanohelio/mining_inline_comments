{"pr_number": 4912, "pr_title": "Decouple geode in sadd,srem,smembers", "pr_createdAt": "2020-04-07T05:09:46Z", "pr_url": "https://github.com/apache/geode/pull/4912", "timeline": [{"oid": "e3fd166511ba93b06b848eec96349d6a26770c9d", "url": "https://github.com/apache/geode/commit/e3fd166511ba93b06b848eec96349d6a26770c9d", "message": "hset hmset hdel hgetall", "committedDate": "2020-04-07T14:11:40Z", "type": "forcePushed"}, {"oid": "bff909db2efc69b71aba497e87399255675cf222", "url": "https://github.com/apache/geode/commit/bff909db2efc69b71aba497e87399255675cf222", "message": "hset hmset hdel hgetall", "committedDate": "2020-04-07T14:15:36Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk0OTgwOQ==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404949809", "bodyText": "Why the change to REPLICATE region type as the default? Should it be PARTITION_REDUNDANT, perhaps?", "author": "upthewaterspout", "createdAt": "2020-04-07T16:33:34Z", "path": "geode-redis/src/main/java/org/apache/geode/redis/GeodeRedisServer.java", "diffHunk": "@@ -306,7 +306,7 @@\n    * @return {@link RegionShortcut}\n    */\n   private static RegionShortcut setRegionType() {\n-    String regionType = System.getProperty(DEFAULT_REGION_SYS_PROP_NAME, \"PARTITION\");\n+    String regionType = System.getProperty(DEFAULT_REGION_SYS_PROP_NAME, \"REPLICATE\");", "originalCommit": "bff909db2efc69b71aba497e87399255675cf222", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk3OTI5MA==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404979290", "bodyText": "i was just messing around...i'll rebase this change out of the PR", "author": "prettyClouds", "createdAt": "2020-04-07T17:17:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk0OTgwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1MTU1OA==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404951558", "bodyText": "Because you set methods are never modifying the old value in place, I think would be safe just to return the result of region.get() here, without the compute or the copying.", "author": "upthewaterspout", "createdAt": "2020-04-07T16:36:13Z", "path": "geode-redis/src/main/java/org/apache/geode/redis/internal/executor/hash/GeodeRedisHashSynchronized.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.redis.internal.executor.hash;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.redis.internal.ByteArrayWrapper;\n+import org.apache.geode.redis.internal.ExecutionHandlerContext;\n+import org.apache.geode.redis.internal.RedisDataType;\n+\n+class GeodeRedisHashSynchronized implements RedisHash {\n+  private final ByteArrayWrapper key;\n+  private final ExecutionHandlerContext context;\n+\n+  public GeodeRedisHashSynchronized(ByteArrayWrapper key, ExecutionHandlerContext context) {\n+    this.key = key;\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public int hset(List<ByteArrayWrapper> fieldsToSet,\n+      boolean NX) {\n+    AtomicInteger fieldsAdded = new AtomicInteger();\n+\n+    Map<ByteArrayWrapper, ByteArrayWrapper> computedHash =\n+        region().compute(key, (_unused_, oldHash) -> {\n+\n+          fieldsAdded.set(0);\n+          HashMap<ByteArrayWrapper, ByteArrayWrapper> newHash;\n+          if (oldHash == null) {\n+            newHash = new HashMap<>();\n+          } else {\n+            newHash = new HashMap<>(oldHash);\n+          }\n+\n+          for (int i = 0; i < fieldsToSet.size(); i += 2) {\n+            ByteArrayWrapper field = fieldsToSet.get(i);\n+            ByteArrayWrapper value = fieldsToSet.get(i + 1);\n+\n+            Object abc;\n+            if (NX) {\n+              abc = newHash.putIfAbsent(field, value);\n+            } else {\n+              abc = newHash.put(field, value);\n+            }\n+\n+            if (abc == null) {\n+              fieldsAdded.getAndIncrement();\n+            }\n+          }\n+\n+          return newHash;\n+        });\n+\n+    if (computedHash != null) {\n+      context.getKeyRegistrar().register(this.key, RedisDataType.REDIS_HASH);\n+    }\n+\n+    return fieldsAdded.get();\n+  }\n+\n+  @Override\n+  public int hdel(List<ByteArrayWrapper> subList) {\n+    AtomicLong numDeleted = new AtomicLong();\n+    region().computeIfPresent(key, (_unused_, oldHash) -> {\n+      HashMap<ByteArrayWrapper, ByteArrayWrapper> newHash = new HashMap<>(oldHash);\n+      for (ByteArrayWrapper fieldToRemove : subList) {\n+        Object oldValue = newHash.remove(fieldToRemove);\n+        if (oldValue != null) {\n+          numDeleted.incrementAndGet();\n+        }\n+      }\n+      return newHash;\n+    });\n+    return numDeleted.intValue();\n+  }\n+\n+  @Override\n+  public Collection<Map.Entry<ByteArrayWrapper, ByteArrayWrapper>> hgetall() {", "originalCommit": "bff909db2efc69b71aba497e87399255675cf222", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk3OTY3Nw==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404979677", "bodyText": "i was concerned about a CME if somebody iterates over the returned value...i think the copy is necessary but let me know.", "author": "prettyClouds", "createdAt": "2020-04-07T17:18:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1MTU1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTExNjYyMQ==", "url": "https://github.com/apache/geode/pull/4912#discussion_r405116621", "bodyText": "Well, the function you pass into computeIfPresent is also technically iterating over the oldHash. And since the function is not necessarily executed under lock if anything changes oldHash the function could also through a CME. The compute* methods don't necessarily lock while executing your function, they could be doing a replace followed by a retry of your function for a concurrent modification exception.", "author": "upthewaterspout", "createdAt": "2020-04-07T21:13:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1MTU1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1NDI1Nw==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404954257", "bodyText": "Might want to comment about why you called fieldsAdded.set(0) (because compute can be called multiple times).\nThe logic you used in the set methods to just call fieldsAdded.set(newHash.size() - oldHash.size()) might be less confusing to someone reading the code.", "author": "upthewaterspout", "createdAt": "2020-04-07T16:40:14Z", "path": "geode-redis/src/main/java/org/apache/geode/redis/internal/executor/hash/GeodeRedisHashSynchronized.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.redis.internal.executor.hash;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.redis.internal.ByteArrayWrapper;\n+import org.apache.geode.redis.internal.ExecutionHandlerContext;\n+import org.apache.geode.redis.internal.RedisDataType;\n+\n+class GeodeRedisHashSynchronized implements RedisHash {\n+  private final ByteArrayWrapper key;\n+  private final ExecutionHandlerContext context;\n+\n+  public GeodeRedisHashSynchronized(ByteArrayWrapper key, ExecutionHandlerContext context) {\n+    this.key = key;\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public int hset(List<ByteArrayWrapper> fieldsToSet,\n+      boolean NX) {\n+    AtomicInteger fieldsAdded = new AtomicInteger();\n+\n+    Map<ByteArrayWrapper, ByteArrayWrapper> computedHash =\n+        region().compute(key, (_unused_, oldHash) -> {\n+\n+          fieldsAdded.set(0);", "originalCommit": "bff909db2efc69b71aba497e87399255675cf222", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk3OTk3Ng==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404979976", "bodyText": "yea...i only caught that because there was luckily a test that was counting the return values. i can add something.", "author": "prettyClouds", "createdAt": "2020-04-07T17:18:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1NDI1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4NTU0Nw==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404985547", "bodyText": "i changed the logic...i was hesitant to run .size(), but it's not a concurrenthashmap, so it should be O(1) and consistent", "author": "prettyClouds", "createdAt": "2020-04-07T17:27:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1NDI1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1NDY5Nw==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404954697", "bodyText": "Need to set numDeleted to 0 at the beginning of the compute block.", "author": "upthewaterspout", "createdAt": "2020-04-07T16:40:55Z", "path": "geode-redis/src/main/java/org/apache/geode/redis/internal/executor/hash/GeodeRedisHashSynchronized.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.redis.internal.executor.hash;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.redis.internal.ByteArrayWrapper;\n+import org.apache.geode.redis.internal.ExecutionHandlerContext;\n+import org.apache.geode.redis.internal.RedisDataType;\n+\n+class GeodeRedisHashSynchronized implements RedisHash {\n+  private final ByteArrayWrapper key;\n+  private final ExecutionHandlerContext context;\n+\n+  public GeodeRedisHashSynchronized(ByteArrayWrapper key, ExecutionHandlerContext context) {\n+    this.key = key;\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public int hset(List<ByteArrayWrapper> fieldsToSet,\n+      boolean NX) {\n+    AtomicInteger fieldsAdded = new AtomicInteger();\n+\n+    Map<ByteArrayWrapper, ByteArrayWrapper> computedHash =\n+        region().compute(key, (_unused_, oldHash) -> {\n+\n+          fieldsAdded.set(0);\n+          HashMap<ByteArrayWrapper, ByteArrayWrapper> newHash;\n+          if (oldHash == null) {\n+            newHash = new HashMap<>();\n+          } else {\n+            newHash = new HashMap<>(oldHash);\n+          }\n+\n+          for (int i = 0; i < fieldsToSet.size(); i += 2) {\n+            ByteArrayWrapper field = fieldsToSet.get(i);\n+            ByteArrayWrapper value = fieldsToSet.get(i + 1);\n+\n+            Object abc;\n+            if (NX) {\n+              abc = newHash.putIfAbsent(field, value);\n+            } else {\n+              abc = newHash.put(field, value);\n+            }\n+\n+            if (abc == null) {\n+              fieldsAdded.getAndIncrement();\n+            }\n+          }\n+\n+          return newHash;\n+        });\n+\n+    if (computedHash != null) {\n+      context.getKeyRegistrar().register(this.key, RedisDataType.REDIS_HASH);\n+    }\n+\n+    return fieldsAdded.get();\n+  }\n+\n+  @Override\n+  public int hdel(List<ByteArrayWrapper> subList) {\n+    AtomicLong numDeleted = new AtomicLong();", "originalCommit": "bff909db2efc69b71aba497e87399255675cf222", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4MDIxMg==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404980212", "bodyText": "good catch...no test for this, so i missed it.  you are a human junit...DanUnit", "author": "prettyClouds", "createdAt": "2020-04-07T17:19:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1NDY5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk4NTk1NQ==", "url": "https://github.com/apache/geode/pull/4912#discussion_r404985955", "bodyText": "fixed...changed the logic to call AtomicLong.set() like you recommended", "author": "prettyClouds", "createdAt": "2020-04-07T17:28:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1NDY5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTE0NjEyNw==", "url": "https://github.com/apache/geode/pull/4912#discussion_r405146127", "bodyText": "I would suggest a refactor to the name here-  this class seems like it's more about operating on sets than being a container for data?", "author": "jhutchison", "createdAt": "2020-04-07T22:17:39Z", "path": "geode-redis/src/main/java/org/apache/geode/redis/internal/executor/set/GeodeRedisSetSynchronized.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.redis.internal.executor.set;\n+\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.redis.internal.ByteArrayWrapper;\n+import org.apache.geode.redis.internal.ExecutionHandlerContext;\n+\n+class GeodeRedisSetSynchronized implements RedisSet {\n+\n+  private ByteArrayWrapper key;\n+  private ExecutionHandlerContext context;\n+\n+  public GeodeRedisSetSynchronized(ByteArrayWrapper key, ExecutionHandlerContext context) {", "originalCommit": "bff909db2efc69b71aba497e87399255675cf222", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8720be195b72bede8cc8be2e3da56a5004424c5b", "url": "https://github.com/apache/geode/commit/8720be195b72bede8cc8be2e3da56a5004424c5b", "message": "fixes", "committedDate": "2020-04-09T19:13:10Z", "type": "forcePushed"}, {"oid": "6c131d5c40a4b488c50d4f19597de4b938922eea", "url": "https://github.com/apache/geode/commit/6c131d5c40a4b488c50d4f19597de4b938922eea", "message": "do not use compute for \"getters\"", "committedDate": "2020-04-09T21:55:56Z", "type": "forcePushed"}, {"oid": "3e3a0788e2633bd4076386738d5ba5665e75e590", "url": "https://github.com/apache/geode/commit/3e3a0788e2633bd4076386738d5ba5665e75e590", "message": "Decouple geode in sadd,srem,smembers\n\nThis commit builds a GeodeRedisSetSynchronized class that brings\ntogether \"set\" methods.  These three are necessary for Spring-Session so\nthey are the only ones included.", "committedDate": "2020-04-09T21:59:21Z", "type": "commit"}, {"oid": "9d41234c52a86840e0b29c2967f03651597a07a5", "url": "https://github.com/apache/geode/commit/9d41234c52a86840e0b29c2967f03651597a07a5", "message": "hset hmset hdel hgetall", "committedDate": "2020-04-09T21:59:21Z", "type": "commit"}, {"oid": "5b099828eba8b4813b221dade071e6fddf91ff73", "url": "https://github.com/apache/geode/commit/5b099828eba8b4813b221dade071e6fddf91ff73", "message": "fixes", "committedDate": "2020-04-09T21:59:21Z", "type": "commit"}, {"oid": "56e793ac549806b6e02682cae9b00beebe5abf8d", "url": "https://github.com/apache/geode/commit/56e793ac549806b6e02682cae9b00beebe5abf8d", "message": "do not use compute for \"getters\"", "committedDate": "2020-04-09T21:59:21Z", "type": "commit"}, {"oid": "56e793ac549806b6e02682cae9b00beebe5abf8d", "url": "https://github.com/apache/geode/commit/56e793ac549806b6e02682cae9b00beebe5abf8d", "message": "do not use compute for \"getters\"", "committedDate": "2020-04-09T21:59:21Z", "type": "forcePushed"}, {"oid": "81c1bdcf8720a25e41399f3e4306bcd636e26d7c", "url": "https://github.com/apache/geode/commit/81c1bdcf8720a25e41399f3e4306bcd636e26d7c", "message": "spA", "committedDate": "2020-04-10T17:13:00Z", "type": "commit"}]}