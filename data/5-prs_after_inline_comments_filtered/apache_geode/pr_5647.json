{"pr_number": 5647, "pr_title": "GEODE-8633: Add concurrency tests for Redis HDEL", "pr_createdAt": "2020-10-21T14:29:18Z", "pr_url": "https://github.com/apache/geode/pull/5647", "timeline": [{"oid": "64d091b7357c95589020b96e9e2f30a9967c538b", "url": "https://github.com/apache/geode/commit/64d091b7357c95589020b96e9e2f30a9967c538b", "message": "GEODE-8633: Add concurrency tests for Redis HDEL\n\n- Also add the ability for ConcurrentLoopingThreads to be run\n  asynchronously.\n\nAuthored-by: Jens Deppe <jdeppe@vmware.com>", "committedDate": "2020-10-21T14:27:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTM5NjI1OA==", "url": "https://github.com/apache/geode/pull/5647#discussion_r509396258", "bodyText": "Since you'll have to re-trigger anyway, the name could be changed to correct some grammatical errors/fit in with the test name below it: testConcurrentHDel_returnsExpectedNumberOfDeletions", "author": "sabbey37", "createdAt": "2020-10-21T15:41:40Z", "path": "geode-redis/src/distributedTest/java/org/apache/geode/redis/internal/executor/hash/HdelDUnitTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.redis.internal.executor.hash;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.REDIS_PORT;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import io.lettuce.core.ClientOptions;\n+import io.lettuce.core.RedisClient;\n+import io.lettuce.core.api.StatefulRedisConnection;\n+import io.lettuce.core.api.sync.RedisCommands;\n+import io.lettuce.core.resource.ClientResources;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import org.apache.geode.internal.AvailablePortHelper;\n+import org.apache.geode.redis.ConcurrentLoopingThreads;\n+import org.apache.geode.redis.session.springRedisTestApplication.config.DUnitSocketAddressResolver;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.dunit.rules.RedisClusterStartupRule;\n+import org.apache.geode.test.junit.rules.ExecutorServiceRule;\n+\n+public class HdelDUnitTest {\n+\n+  @ClassRule\n+  public static RedisClusterStartupRule cluster = new RedisClusterStartupRule();\n+\n+  @ClassRule\n+  public static ExecutorServiceRule executor = new ExecutorServiceRule();\n+\n+  private static final int HASH_SIZE = 50000;\n+  private static MemberVM locator;\n+  private static MemberVM server1;\n+  private static MemberVM server2;\n+  private static int[] redisPorts;\n+  private static RedisCommands<String, String> lettuce;\n+  private static StatefulRedisConnection<String, String> connection;\n+  private static ClientResources resources;\n+\n+  @BeforeClass\n+  public static void classSetup() {\n+    redisPorts = AvailablePortHelper.getRandomAvailableTCPPorts(3);\n+\n+    String redisPort1 = \"\" + redisPorts[0];\n+    String redisPort2 = \"\" + redisPorts[1];\n+\n+    locator = cluster.startLocatorVM(0);\n+\n+    server1 = startRedisVM(1, redisPorts[0]);\n+    server2 = startRedisVM(2, redisPorts[1]);\n+\n+    DUnitSocketAddressResolver dnsResolver =\n+        new DUnitSocketAddressResolver(new String[] {redisPort2, redisPort1});\n+\n+    resources = ClientResources.builder()\n+        .socketAddressResolver(dnsResolver)\n+        .build();\n+\n+    RedisClient redisClient = RedisClient.create(resources, \"redis://localhost\");\n+    redisClient.setOptions(ClientOptions.builder()\n+        .autoReconnect(true)\n+        .build());\n+    connection = redisClient.connect();\n+    lettuce = connection.sync();\n+  }\n+\n+  private static MemberVM startRedisVM(int vmID, int redisPort) {\n+    int locatorPort = locator.getPort();\n+\n+    return cluster.startRedisVM(vmID, x -> x\n+        .withConnectionToLocator(locatorPort)\n+        .withProperty(REDIS_PORT, \"\" + redisPort));\n+  }\n+\n+  @Before\n+  public void testSetup() {\n+    lettuce.flushall();\n+  }\n+\n+  @AfterClass\n+  public static void tearDown() throws Exception {\n+    resources.shutdown().get();\n+    connection.close();\n+    server1.stop();\n+    server2.stop();\n+  }\n+\n+  @Test\n+  public void testConcurrentHDelReturnExceptedNumberOfDeletions() {", "originalCommit": "64d091b7357c95589020b96e9e2f30a9967c538b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTYwODEyNA==", "url": "https://github.com/apache/geode/pull/5647#discussion_r509608124", "bodyText": "Thanks! Done.", "author": "jdeppe-pivotal", "createdAt": "2020-10-21T19:27:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTM5NjI1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTM5NzU4OQ==", "url": "https://github.com/apache/geode/pull/5647#discussion_r509397589", "bodyText": "Since you have to re-trigger anyway, you could change the name to HDel instead of Del and better fit with the test name above: testConcurrentHDel_whenServerCrashesAndRestarts_deletesAllHashFieldsAndValues", "author": "sabbey37", "createdAt": "2020-10-21T15:43:15Z", "path": "geode-redis/src/distributedTest/java/org/apache/geode/redis/internal/executor/hash/HdelDUnitTest.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package org.apache.geode.redis.internal.executor.hash;\n+\n+import static org.apache.geode.distributed.ConfigurationProperties.REDIS_PORT;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import io.lettuce.core.ClientOptions;\n+import io.lettuce.core.RedisClient;\n+import io.lettuce.core.api.StatefulRedisConnection;\n+import io.lettuce.core.api.sync.RedisCommands;\n+import io.lettuce.core.resource.ClientResources;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+\n+import org.apache.geode.internal.AvailablePortHelper;\n+import org.apache.geode.redis.ConcurrentLoopingThreads;\n+import org.apache.geode.redis.session.springRedisTestApplication.config.DUnitSocketAddressResolver;\n+import org.apache.geode.test.dunit.rules.MemberVM;\n+import org.apache.geode.test.dunit.rules.RedisClusterStartupRule;\n+import org.apache.geode.test.junit.rules.ExecutorServiceRule;\n+\n+public class HdelDUnitTest {\n+\n+  @ClassRule\n+  public static RedisClusterStartupRule cluster = new RedisClusterStartupRule();\n+\n+  @ClassRule\n+  public static ExecutorServiceRule executor = new ExecutorServiceRule();\n+\n+  private static final int HASH_SIZE = 50000;\n+  private static MemberVM locator;\n+  private static MemberVM server1;\n+  private static MemberVM server2;\n+  private static int[] redisPorts;\n+  private static RedisCommands<String, String> lettuce;\n+  private static StatefulRedisConnection<String, String> connection;\n+  private static ClientResources resources;\n+\n+  @BeforeClass\n+  public static void classSetup() {\n+    redisPorts = AvailablePortHelper.getRandomAvailableTCPPorts(3);\n+\n+    String redisPort1 = \"\" + redisPorts[0];\n+    String redisPort2 = \"\" + redisPorts[1];\n+\n+    locator = cluster.startLocatorVM(0);\n+\n+    server1 = startRedisVM(1, redisPorts[0]);\n+    server2 = startRedisVM(2, redisPorts[1]);\n+\n+    DUnitSocketAddressResolver dnsResolver =\n+        new DUnitSocketAddressResolver(new String[] {redisPort2, redisPort1});\n+\n+    resources = ClientResources.builder()\n+        .socketAddressResolver(dnsResolver)\n+        .build();\n+\n+    RedisClient redisClient = RedisClient.create(resources, \"redis://localhost\");\n+    redisClient.setOptions(ClientOptions.builder()\n+        .autoReconnect(true)\n+        .build());\n+    connection = redisClient.connect();\n+    lettuce = connection.sync();\n+  }\n+\n+  private static MemberVM startRedisVM(int vmID, int redisPort) {\n+    int locatorPort = locator.getPort();\n+\n+    return cluster.startRedisVM(vmID, x -> x\n+        .withConnectionToLocator(locatorPort)\n+        .withProperty(REDIS_PORT, \"\" + redisPort));\n+  }\n+\n+  @Before\n+  public void testSetup() {\n+    lettuce.flushall();\n+  }\n+\n+  @AfterClass\n+  public static void tearDown() throws Exception {\n+    resources.shutdown().get();\n+    connection.close();\n+    server1.stop();\n+    server2.stop();\n+  }\n+\n+  @Test\n+  public void testConcurrentHDelReturnExceptedNumberOfDeletions() {\n+    AtomicLong client1Deletes = new AtomicLong();\n+    AtomicLong client2Deletes = new AtomicLong();\n+\n+    String key = \"HSET\";\n+\n+    Map<String, String> setUpData =\n+        makeHashMap(HASH_SIZE, \"field\", \"value\");\n+\n+    lettuce.hset(key, setUpData);\n+\n+    new ConcurrentLoopingThreads(HASH_SIZE,\n+        i -> {\n+          long deleted = lettuce.hdel(key, \"field\" + i, \"value\" + i);\n+          client1Deletes.addAndGet(deleted);\n+        },\n+        i -> {\n+          long deleted = lettuce.hdel(key, \"field\" + i, \"value\" + i);\n+          client2Deletes.addAndGet(deleted);\n+        })\n+            .run();\n+\n+    assertThat(client1Deletes.get() + client2Deletes.get()).isEqualTo(HASH_SIZE);\n+  }\n+\n+  @Test\n+  public void testConcurrentDel_whenServerCrashesAndRestarts() {", "originalCommit": "64d091b7357c95589020b96e9e2f30a9967c538b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTYwODIwMQ==", "url": "https://github.com/apache/geode/pull/5647#discussion_r509608201", "bodyText": "Done", "author": "jdeppe-pivotal", "createdAt": "2020-10-21T19:27:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTM5NzU4OQ=="}], "type": "inlineReview"}, {"oid": "71d590572157c2afee7dc299875eaac9f8b54654", "url": "https://github.com/apache/geode/commit/71d590572157c2afee7dc299875eaac9f8b54654", "message": "Review updates", "committedDate": "2020-10-21T19:23:40Z", "type": "commit"}, {"oid": "576df960d4a1a85aa3c5f59a64b2c21d81bfd5d3", "url": "https://github.com/apache/geode/commit/576df960d4a1a85aa3c5f59a64b2c21d81bfd5d3", "message": "Retry command if it received a 'connection reset by peer' error", "committedDate": "2020-10-21T23:35:00Z", "type": "commit"}]}