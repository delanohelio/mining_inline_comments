{"pr_number": 5095, "pr_title": "GEODE-7680: PR.clear must be successful when interacting with rebalance", "pr_createdAt": "2020-05-12T00:28:26Z", "pr_url": "https://github.com/apache/geode/pull/5095", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0NDg2MQ==", "url": "https://github.com/apache/geode/pull/5095#discussion_r423544861", "bodyText": "Good catch!.", "author": "jujoramos", "createdAt": "2020-05-12T08:12:38Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithExpirationDUnitTest.java", "diffHunk": "@@ -323,7 +323,7 @@ public void clearShouldRemoveRegisteredExpirationTasks(TestVM coordinatorVM,\n \n     // Assert Region Buckets are consistent and region is empty,\n     accessor.invoke(this::assertRegionBucketsConsistency);\n-    assertRegionIsEmpty(asList(accessor, server1, server1));\n+    assertRegionIsEmpty(asList(accessor, server1, server2));", "originalCommit": "2717630164a15fc493c06eeafc647ac7c8e238e2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0NDkwOQ==", "url": "https://github.com/apache/geode/pull/5095#discussion_r423544909", "bodyText": "Good catch!.", "author": "jujoramos", "createdAt": "2020-05-12T08:12:43Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithExpirationDUnitTest.java", "diffHunk": "@@ -460,7 +460,7 @@ public void clearShouldSucceedAndRemoveRegisteredExpirationTasksWhenNonCoordinat\n \n     // Assert Region Buckets are consistent and region is empty,\n     accessor.invoke(this::assertRegionBucketsConsistency);\n-    assertRegionIsEmpty(asList(accessor, server1, server1));\n+    assertRegionIsEmpty(asList(accessor, server1, server2));", "originalCommit": "2717630164a15fc493c06eeafc647ac7c8e238e2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDY5OQ==", "url": "https://github.com/apache/geode/pull/5095#discussion_r424694699", "bodyText": "There could be possibility that, by the time the \"wait\" here and \"wait\" in before the clear call (the sleep after first unsuccessful check); and with thread scheduling, the rebalance of buckets may be completed, before the clear start. Very less likely, but may be.", "author": "agingade", "createdAt": "2020-05-13T19:56:30Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithRebalanceDUnitTest.java", "diffHunk": "@@ -0,0 +1,376 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.PartitionAttributesFactory.GLOBAL_MAX_BUCKETS_DEFAULT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT_PERSISTENT;\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.junit.Assert.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.assertj.core.api.Assertions;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedDiskDirRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithRebalanceDUnitTest implements Serializable {\n+  private static final long serialVersionUID = -7183993832801073933L;\n+\n+  private static final Integer BUCKETS = GLOBAL_MAX_BUCKETS_DEFAULT;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  public static final String DISK_STORE_NAME = \"diskStore\";\n+  public static final String BEGIN_CLEAR = \"begin-clear\";\n+  private static final int ENTRIES = 10000;\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  @Rule\n+  public DistributedDiskDirRule distributedDiskDirRule = new DistributedDiskDirRule();\n+\n+  private static transient DUnitBlackboard blackboard;\n+\n+  private VM accessor;\n+  private VM server1;\n+  private VM server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        PARTITION_REDUNDANT,\n+        PARTITION_REDUNDANT_PERSISTENT,\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      // {ClearCoordinatorVM, RebalanceVM, regionShortcut}\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.ACCESSOR, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    getBlackboard().initBlackboard();\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private static DUnitBlackboard getBlackboard() {\n+    if (blackboard == null) {\n+      blackboard = new DUnitBlackboard();\n+    }\n+    return blackboard;\n+  }\n+\n+  private RegionShortcut getRegionAccessorShortcut(RegionShortcut dataStoreRegionShortcut) {\n+    if (dataStoreRegionShortcut.isPersistent()) {\n+      switch (dataStoreRegionShortcut) {\n+        case PARTITION_PERSISTENT:\n+          return PARTITION;\n+        case PARTITION_REDUNDANT_PERSISTENT:\n+          return PARTITION_REDUNDANT;\n+      }\n+    }\n+\n+    return dataStoreRegionShortcut;\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    RegionShortcut accessorShortcut = getRegionAccessorShortcut(regionShortcut);\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .setLocalMaxMemory(0)\n+            .create();\n+\n+    cacheRule.getCache()\n+        .<String, String>createRegionFactory(accessorShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .create();\n+\n+    RegionFactory<String, String> factory = cacheRule.getCache()\n+        .<String, String>createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes);\n+\n+    if (regionShortcut.isPersistent()) {\n+      factory.setDiskStoreName(\n+          cacheRule.getCache().createDiskStoreFactory().create(DISK_STORE_NAME).getName());\n+    }\n+\n+    factory.create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    // Create and populate the region on server1 first, to create an unbalanced distribution of data\n+    server1.invoke(() -> {\n+      initDataStore(regionShortcut);\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, ENTRIES).forEach(i -> region.put(\"key\" + i, \"value\" + i));\n+    });\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private AsyncInvocation<Object> setupAndPrepareClear(TestVM clearCoordinatorVM,\n+      RegionShortcut regionType) {\n+    parametrizedSetup(regionType);\n+\n+    return getVM(clearCoordinatorVM.vmNumber).invokeAsync(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      // Wait for the signal from the blackboard before triggering the clear to start\n+      getBlackboard().waitForGate(BEGIN_CLEAR, GeodeAwaitility.getTimeout().toMillis(),\n+          TimeUnit.MILLISECONDS);\n+      region.clear();\n+    });\n+  }\n+\n+  private RebalanceResults startRebalanceAndGetResults() throws InterruptedException {\n+    // Start a rebalance and wait until bucket creation for redundancy recovery (the first stage of\n+    // a rebalance operation) has started before signalling the blackboard\n+    RebalanceOperation rebalanceOp =\n+        cacheRule.getCache().getResourceManager().createRebalanceFactory().start();\n+    await().untilAsserted(() -> assertThat(cacheRule.getCache().getInternalResourceManager()\n+        .getStats().getRebalanceBucketCreatesCompleted(), greaterThan(0)));", "originalCommit": "2717630164a15fc493c06eeafc647ac7c8e238e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc2Nzg4OQ==", "url": "https://github.com/apache/geode/pull/5095#discussion_r424767889", "bodyText": "There are 10,000 entries in the region, so the rebalance process takes some time. The clear should always start before the rebalance finishes, unless the rebalance manages to finish in only a few milliseconds. Is there a solution to this timing issue other than just making sure the rebalance takes longer? The clear() call will always have some possible delay in starting due to the waitForGate() call.", "author": "DonalEvans", "createdAt": "2020-05-13T22:30:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDY5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcwMTMxNg==", "url": "https://github.com/apache/geode/pull/5095#discussion_r424701316", "bodyText": "Its same as \"startRebalanceAndGetResults()\"; can it be called here as done in previous test.", "author": "agingade", "createdAt": "2020-05-13T20:08:50Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithRebalanceDUnitTest.java", "diffHunk": "@@ -0,0 +1,376 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.PartitionAttributesFactory.GLOBAL_MAX_BUCKETS_DEFAULT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT_PERSISTENT;\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.junit.Assert.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.assertj.core.api.Assertions;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedDiskDirRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithRebalanceDUnitTest implements Serializable {\n+  private static final long serialVersionUID = -7183993832801073933L;\n+\n+  private static final Integer BUCKETS = GLOBAL_MAX_BUCKETS_DEFAULT;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  public static final String DISK_STORE_NAME = \"diskStore\";\n+  public static final String BEGIN_CLEAR = \"begin-clear\";\n+  private static final int ENTRIES = 10000;\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  @Rule\n+  public DistributedDiskDirRule distributedDiskDirRule = new DistributedDiskDirRule();\n+\n+  private static transient DUnitBlackboard blackboard;\n+\n+  private VM accessor;\n+  private VM server1;\n+  private VM server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        PARTITION_REDUNDANT,\n+        PARTITION_REDUNDANT_PERSISTENT,\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      // {ClearCoordinatorVM, RebalanceVM, regionShortcut}\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.ACCESSOR, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    getBlackboard().initBlackboard();\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private static DUnitBlackboard getBlackboard() {\n+    if (blackboard == null) {\n+      blackboard = new DUnitBlackboard();\n+    }\n+    return blackboard;\n+  }\n+\n+  private RegionShortcut getRegionAccessorShortcut(RegionShortcut dataStoreRegionShortcut) {\n+    if (dataStoreRegionShortcut.isPersistent()) {\n+      switch (dataStoreRegionShortcut) {\n+        case PARTITION_PERSISTENT:\n+          return PARTITION;\n+        case PARTITION_REDUNDANT_PERSISTENT:\n+          return PARTITION_REDUNDANT;\n+      }\n+    }\n+\n+    return dataStoreRegionShortcut;\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    RegionShortcut accessorShortcut = getRegionAccessorShortcut(regionShortcut);\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .setLocalMaxMemory(0)\n+            .create();\n+\n+    cacheRule.getCache()\n+        .<String, String>createRegionFactory(accessorShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .create();\n+\n+    RegionFactory<String, String> factory = cacheRule.getCache()\n+        .<String, String>createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes);\n+\n+    if (regionShortcut.isPersistent()) {\n+      factory.setDiskStoreName(\n+          cacheRule.getCache().createDiskStoreFactory().create(DISK_STORE_NAME).getName());\n+    }\n+\n+    factory.create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    // Create and populate the region on server1 first, to create an unbalanced distribution of data\n+    server1.invoke(() -> {\n+      initDataStore(regionShortcut);\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, ENTRIES).forEach(i -> region.put(\"key\" + i, \"value\" + i));\n+    });\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private AsyncInvocation<Object> setupAndPrepareClear(TestVM clearCoordinatorVM,\n+      RegionShortcut regionType) {\n+    parametrizedSetup(regionType);\n+\n+    return getVM(clearCoordinatorVM.vmNumber).invokeAsync(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      // Wait for the signal from the blackboard before triggering the clear to start\n+      getBlackboard().waitForGate(BEGIN_CLEAR, GeodeAwaitility.getTimeout().toMillis(),\n+          TimeUnit.MILLISECONDS);\n+      region.clear();\n+    });\n+  }\n+\n+  private RebalanceResults startRebalanceAndGetResults() throws InterruptedException {\n+    // Start a rebalance and wait until bucket creation for redundancy recovery (the first stage of\n+    // a rebalance operation) has started before signalling the blackboard\n+    RebalanceOperation rebalanceOp =\n+        cacheRule.getCache().getResourceManager().createRebalanceFactory().start();\n+    await().untilAsserted(() -> assertThat(cacheRule.getCache().getInternalResourceManager()\n+        .getStats().getRebalanceBucketCreatesCompleted(), greaterThan(0)));\n+    getBlackboard().signalGate(BEGIN_CLEAR);\n+\n+    return rebalanceOp.getResults();\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      Assertions.assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress())\n+          .isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress())\n+          .isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      Assertions.assertThat(region.getLocalSize()).isEqualTo(0);\n+    }));\n+  }\n+\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalanceClearsRegion(TestVM clearCoordinatorVM,\n+      TestVM rebalanceVM, RegionShortcut regionType) throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      RebalanceResults results = startRebalanceAndGetResults();\n+\n+      // Verify that rebalance did some work\n+      int combinedResults = results.getTotalBucketTransfersCompleted()\n+          + results.getTotalBucketCreatesCompleted() + results.getTotalPrimaryTransfersCompleted();\n+      assertThat(combinedResults, greaterThan(0));\n+\n+      // Verify that no bucket creates failed during the rebalance\n+      assertThat(cacheRule.getCache().getInternalResourceManager().getStats()\n+          .getRebalanceBucketCreatesFailed(), is(0));\n+    });\n+\n+    clearInvocation.await();\n+\n+    // Assert that the region is empty\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalancePrimaryReassignmentClearsRegion(TestVM clearCoordinatorVM,\n+      TestVM rebalanceVM, RegionShortcut regionType) throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      // Start a rebalance and wait until primary reassignment has started before signalling the\n+      // blackboard\n+      RebalanceOperation rebalanceOp =", "originalCommit": "2717630164a15fc493c06eeafc647ac7c8e238e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc2NDUzMw==", "url": "https://github.com/apache/geode/pull/5095#discussion_r424764533", "bodyText": "This case is actually slightly different; it waits for getRebalance**PrimaryTransfers**Completed() to be greater than zero instead of getRebalance**BucketCreates**Completed(). This case is intended to test the behaviour of clear when rebalance is doing the reassigning primaries step specifically.", "author": "DonalEvans", "createdAt": "2020-05-13T22:21:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcwMTMxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcxMDUzNg==", "url": "https://github.com/apache/geode/pull/5095#discussion_r424710536", "bodyText": "Do we need additional check to see cache is closed...When this vm is restarted, it creates the cache again.", "author": "agingade", "createdAt": "2020-05-13T20:26:05Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithRebalanceDUnitTest.java", "diffHunk": "@@ -0,0 +1,376 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.PartitionAttributesFactory.GLOBAL_MAX_BUCKETS_DEFAULT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT_PERSISTENT;\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.junit.Assert.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.assertj.core.api.Assertions;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.CacheWriterException;\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionEvent;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.cache.partition.PartitionRegionHelper;\n+import org.apache.geode.cache.util.CacheWriterAdapter;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.distributed.internal.InternalDistributedSystem;\n+import org.apache.geode.distributed.internal.membership.api.MembershipManagerHelper;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedDiskDirRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithRebalanceDUnitTest implements Serializable {\n+  private static final long serialVersionUID = -7183993832801073933L;\n+\n+  private static final Integer BUCKETS = GLOBAL_MAX_BUCKETS_DEFAULT;\n+  private static final String REGION_NAME = \"PartitionedRegion\";\n+  public static final String DISK_STORE_NAME = \"diskStore\";\n+  public static final String BEGIN_CLEAR = \"begin-clear\";\n+  private static final int ENTRIES = 10000;\n+\n+  @Rule\n+  public DistributedRule distributedRule = new DistributedRule(3);\n+\n+  @Rule\n+  public CacheRule cacheRule = CacheRule.builder().createCacheInAll().build();\n+\n+  @Rule\n+  public DistributedDiskDirRule distributedDiskDirRule = new DistributedDiskDirRule();\n+\n+  private static transient DUnitBlackboard blackboard;\n+\n+  private VM accessor;\n+  private VM server1;\n+  private VM server2;\n+\n+  private enum TestVM {\n+    ACCESSOR(0), SERVER1(1), SERVER2(2);\n+\n+    final int vmNumber;\n+\n+    TestVM(int vmNumber) {\n+      this.vmNumber = vmNumber;\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static RegionShortcut[] regionTypes() {\n+    return new RegionShortcut[] {\n+        PARTITION_REDUNDANT,\n+        PARTITION_REDUNDANT_PERSISTENT,\n+    };\n+  }\n+\n+  @SuppressWarnings(\"unused\")\n+  static Object[] vmsAndRegionTypes() {\n+    ArrayList<Object[]> parameters = new ArrayList<>();\n+    RegionShortcut[] regionShortcuts = regionTypes();\n+\n+    Arrays.stream(regionShortcuts).forEach(regionShortcut -> {\n+      // {ClearCoordinatorVM, RebalanceVM, regionShortcut}\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.SERVER1, TestVM.ACCESSOR, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.SERVER1, regionShortcut});\n+      parameters.add(new Object[] {TestVM.ACCESSOR, TestVM.ACCESSOR, regionShortcut});\n+    });\n+\n+    return parameters.toArray();\n+  }\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    getBlackboard().initBlackboard();\n+    server1 = getVM(TestVM.SERVER1.vmNumber);\n+    server2 = getVM(TestVM.SERVER2.vmNumber);\n+    accessor = getVM(TestVM.ACCESSOR.vmNumber);\n+  }\n+\n+  private static DUnitBlackboard getBlackboard() {\n+    if (blackboard == null) {\n+      blackboard = new DUnitBlackboard();\n+    }\n+    return blackboard;\n+  }\n+\n+  private RegionShortcut getRegionAccessorShortcut(RegionShortcut dataStoreRegionShortcut) {\n+    if (dataStoreRegionShortcut.isPersistent()) {\n+      switch (dataStoreRegionShortcut) {\n+        case PARTITION_PERSISTENT:\n+          return PARTITION;\n+        case PARTITION_REDUNDANT_PERSISTENT:\n+          return PARTITION_REDUNDANT;\n+      }\n+    }\n+\n+    return dataStoreRegionShortcut;\n+  }\n+\n+  private void initAccessor(RegionShortcut regionShortcut) {\n+    RegionShortcut accessorShortcut = getRegionAccessorShortcut(regionShortcut);\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .setLocalMaxMemory(0)\n+            .create();\n+\n+    cacheRule.getCache()\n+        .<String, String>createRegionFactory(accessorShortcut)\n+        .setPartitionAttributes(attributes)\n+        .create(REGION_NAME);\n+  }\n+\n+  private void initDataStore(RegionShortcut regionShortcut) {\n+    // StartupRecoveryDelay is set to infinite to prevent automatic rebalancing when creating the\n+    // region on other members\n+    PartitionAttributes<String, String> attributes =\n+        new PartitionAttributesFactory<String, String>()\n+            .setTotalNumBuckets(BUCKETS)\n+            .setStartupRecoveryDelay(-1)\n+            .create();\n+\n+    RegionFactory<String, String> factory = cacheRule.getCache()\n+        .<String, String>createRegionFactory(regionShortcut)\n+        .setPartitionAttributes(attributes);\n+\n+    if (regionShortcut.isPersistent()) {\n+      factory.setDiskStoreName(\n+          cacheRule.getCache().createDiskStoreFactory().create(DISK_STORE_NAME).getName());\n+    }\n+\n+    factory.create(REGION_NAME);\n+  }\n+\n+  private void parametrizedSetup(RegionShortcut regionShortcut) {\n+    // Create and populate the region on server1 first, to create an unbalanced distribution of data\n+    server1.invoke(() -> {\n+      initDataStore(regionShortcut);\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      IntStream.range(0, ENTRIES).forEach(i -> region.put(\"key\" + i, \"value\" + i));\n+    });\n+    server2.invoke(() -> initDataStore(regionShortcut));\n+    accessor.invoke(() -> initAccessor(regionShortcut));\n+  }\n+\n+  private AsyncInvocation<Object> setupAndPrepareClear(TestVM clearCoordinatorVM,\n+      RegionShortcut regionType) {\n+    parametrizedSetup(regionType);\n+\n+    return getVM(clearCoordinatorVM.vmNumber).invokeAsync(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      // Wait for the signal from the blackboard before triggering the clear to start\n+      getBlackboard().waitForGate(BEGIN_CLEAR, GeodeAwaitility.getTimeout().toMillis(),\n+          TimeUnit.MILLISECONDS);\n+      region.clear();\n+    });\n+  }\n+\n+  private RebalanceResults startRebalanceAndGetResults() throws InterruptedException {\n+    // Start a rebalance and wait until bucket creation for redundancy recovery (the first stage of\n+    // a rebalance operation) has started before signalling the blackboard\n+    RebalanceOperation rebalanceOp =\n+        cacheRule.getCache().getResourceManager().createRebalanceFactory().start();\n+    await().untilAsserted(() -> assertThat(cacheRule.getCache().getInternalResourceManager()\n+        .getStats().getRebalanceBucketCreatesCompleted(), greaterThan(0)));\n+    getBlackboard().signalGate(BEGIN_CLEAR);\n+\n+    return rebalanceOp.getResults();\n+  }\n+\n+  private void waitForSilence() {\n+    DMStats dmStats = cacheRule.getSystem().getDistributionManager().getStats();\n+    PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+    PartitionedRegionStats partitionedRegionStats = region.getPrStats();\n+\n+    await().untilAsserted(() -> {\n+      Assertions.assertThat(dmStats.getReplyWaitsInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getVolunteeringInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getBucketCreatesInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getPrimaryTransfersInProgress()).isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getRebalanceBucketCreatesInProgress())\n+          .isEqualTo(0);\n+      Assertions.assertThat(partitionedRegionStats.getRebalancePrimaryTransfersInProgress())\n+          .isEqualTo(0);\n+    });\n+  }\n+\n+  private void assertRegionIsEmpty(List<VM> vms) {\n+    vms.forEach(vm -> vm.invoke(() -> {\n+      waitForSilence();\n+      PartitionedRegion region = (PartitionedRegion) cacheRule.getCache().getRegion(REGION_NAME);\n+\n+      Assertions.assertThat(region.getLocalSize()).isEqualTo(0);\n+    }));\n+  }\n+\n+  private void registerVMKillerAsCacheWriter(List<VM> vmsToBounce) {\n+    vmsToBounce.forEach(vm -> vm.invoke(() -> {\n+      Region<String, String> region = cacheRule.getCache().getRegion(REGION_NAME);\n+      region.getAttributesMutator().setCacheWriter(new MemberKiller());\n+    }));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalanceClearsRegion(TestVM clearCoordinatorVM,\n+      TestVM rebalanceVM, RegionShortcut regionType) throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      RebalanceResults results = startRebalanceAndGetResults();\n+\n+      // Verify that rebalance did some work\n+      int combinedResults = results.getTotalBucketTransfersCompleted()\n+          + results.getTotalBucketCreatesCompleted() + results.getTotalPrimaryTransfersCompleted();\n+      assertThat(combinedResults, greaterThan(0));\n+\n+      // Verify that no bucket creates failed during the rebalance\n+      assertThat(cacheRule.getCache().getInternalResourceManager().getStats()\n+          .getRebalanceBucketCreatesFailed(), is(0));\n+    });\n+\n+    clearInvocation.await();\n+\n+    // Assert that the region is empty\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalancePrimaryReassignmentClearsRegion(TestVM clearCoordinatorVM,\n+      TestVM rebalanceVM, RegionShortcut regionType) throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      // Start a rebalance and wait until primary reassignment has started before signalling the\n+      // blackboard\n+      RebalanceOperation rebalanceOp =\n+          cacheRule.getCache().getResourceManager().createRebalanceFactory().start();\n+      await().untilAsserted(() -> assertThat(cacheRule.getCache().getInternalResourceManager()\n+          .getStats().getRebalancePrimaryTransfersCompleted(), greaterThan(0)));\n+      getBlackboard().signalGate(BEGIN_CLEAR);\n+\n+      // Verify that rebalance did some work\n+      RebalanceResults results = rebalanceOp.getResults();\n+      int combinedResults = results.getTotalBucketTransfersCompleted()\n+          + results.getTotalBucketCreatesCompleted() + results.getTotalPrimaryTransfersCompleted();\n+      assertThat(combinedResults, greaterThan(0));\n+\n+      // Verify that no primary transfers failed during the rebalance\n+      assertThat(cacheRule.getCache().getInternalResourceManager().getStats()\n+          .getRebalancePrimaryTransfersFailed(), is(0));\n+    });\n+\n+    clearInvocation.await();\n+\n+    // Assert that the region is empty\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  @Test\n+  @Parameters(method = \"vmsAndRegionTypes\")\n+  @TestCaseName(\"[{index}] {method}(ClearCoordinator:{0}, RebalanceCoordinator:{1}, RegionType:{2})\")\n+  public void clearRegionDuringRebalanceClearsRegionWhenNonCoordinatorIsBounced(\n+      TestVM clearCoordinatorVM, TestVM rebalanceVM, RegionShortcut regionType)\n+      throws InterruptedException {\n+    AsyncInvocation<?> clearInvocation = setupAndPrepareClear(clearCoordinatorVM, regionType);\n+\n+    // Server 2 is never the clear coordinator\n+    registerVMKillerAsCacheWriter(Collections.singletonList(server2));\n+\n+    getVM(rebalanceVM.vmNumber).invoke(() -> {\n+      // Start a rebalance and wait until bucket creation for redundancy recovery has started before\n+      // signalling the blackboard\n+      RebalanceResults results = startRebalanceAndGetResults();\n+\n+      // Verify that rebalance did some work\n+      int combinedResults = results.getTotalBucketTransfersCompleted()\n+          + results.getTotalBucketCreatesCompleted() + results.getTotalPrimaryTransfersCompleted();\n+      assertThat(combinedResults, greaterThan(0));\n+    });\n+\n+    clearInvocation.await();\n+\n+    // Bring server 2 back online and assign buckets\n+    server2.invoke(() -> {\n+      cacheRule.createCache();\n+      initDataStore(regionType);\n+      await().untilAsserted(\n+          () -> Assertions.assertThat(InternalDistributedSystem.getConnectedInstance())\n+              .isNotNull());\n+      PartitionRegionHelper.assignBucketsToPartitions(cacheRule.getCache().getRegion(REGION_NAME));\n+    });\n+\n+    // Assert that the region is empty\n+    assertRegionIsEmpty(asList(accessor, server1, server2));\n+  }\n+\n+  /**\n+   * Shutdowns a member while the clear operation is in progress.\n+   * The writer is only installed on the member the test wants to shutdown, doesn't matter whether\n+   * it's the clear coordinator or another member holding primary buckets.\n+   */\n+  public static class MemberKiller extends CacheWriterAdapter<String, String> {\n+\n+    @Override\n+    public synchronized void beforeRegionClear(RegionEvent<String, String> event)\n+        throws CacheWriterException {\n+      InternalDistributedSystem.getConnectedInstance().stopReconnectingNoDisconnect();\n+      MembershipManagerHelper.crashDistributedSystem(\n+          InternalDistributedSystem.getConnectedInstance());\n+      await().untilAsserted(\n+          () -> Assertions.assertThat(InternalDistributedSystem.getConnectedInstance()).isNull());", "originalCommit": "2717630164a15fc493c06eeafc647ac7c8e238e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc3NTcwOQ==", "url": "https://github.com/apache/geode/pull/5095#discussion_r424775709", "bodyText": "I can add a check.", "author": "DonalEvans", "createdAt": "2020-05-13T22:52:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcxMDUzNg=="}], "type": "inlineReview"}, {"oid": "471174e0428631bf9382e293c04ce2da8de78a06", "url": "https://github.com/apache/geode/commit/471174e0428631bf9382e293c04ce2da8de78a06", "message": "Rebased on feature branch, added tests for colocated regions\n\n- Call assignBucketsToPartitions() on leader colocated region during clear\ninstead of target region\n- Remove HA test, since clear always throws PartialClearException when\nmember departs and rebalance behaviour when member departs is already\ncovered\n\nAuthored-by: Donal Evans <doevans@pivotal.io>", "committedDate": "2020-05-26T19:33:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMzI5MA==", "url": "https://github.com/apache/geode/pull/5095#discussion_r430713290", "bodyText": "Looks good. If it is fine with you, can you add one more scenario, where there are 3 data nodes/servers and one of the server is brought down (case 1) and brought up (case 2); during clear, rebalance in progress....", "author": "agingade", "createdAt": "2020-05-26T21:17:52Z", "path": "geode-core/src/distributedTest/java/org/apache/geode/internal/cache/PartitionedRegionClearWithRebalanceDUnitTest.java", "diffHunk": "@@ -0,0 +1,386 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more contributor license\n+ * agreements. See the NOTICE file distributed with this work for additional information regarding\n+ * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License. You may obtain a\n+ * copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License\n+ * is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n+ * or implied. See the License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+package org.apache.geode.internal.cache;\n+\n+import static org.apache.geode.cache.PartitionAttributesFactory.GLOBAL_MAX_BUCKETS_DEFAULT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT;\n+import static org.apache.geode.cache.RegionShortcut.PARTITION_REDUNDANT_PERSISTENT;\n+import static org.apache.geode.internal.util.ArrayUtils.asList;\n+import static org.apache.geode.test.awaitility.GeodeAwaitility.await;\n+import static org.apache.geode.test.dunit.VM.getVM;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.junit.Assert.assertThat;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.IntStream;\n+\n+import junitparams.JUnitParamsRunner;\n+import junitparams.Parameters;\n+import junitparams.naming.TestCaseName;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import org.apache.geode.cache.PartitionAttributes;\n+import org.apache.geode.cache.PartitionAttributesFactory;\n+import org.apache.geode.cache.Region;\n+import org.apache.geode.cache.RegionFactory;\n+import org.apache.geode.cache.RegionShortcut;\n+import org.apache.geode.cache.control.RebalanceOperation;\n+import org.apache.geode.cache.control.RebalanceResults;\n+import org.apache.geode.distributed.internal.DMStats;\n+import org.apache.geode.test.awaitility.GeodeAwaitility;\n+import org.apache.geode.test.dunit.AsyncInvocation;\n+import org.apache.geode.test.dunit.DUnitBlackboard;\n+import org.apache.geode.test.dunit.SerializableRunnableIF;\n+import org.apache.geode.test.dunit.VM;\n+import org.apache.geode.test.dunit.rules.CacheRule;\n+import org.apache.geode.test.dunit.rules.DistributedDiskDirRule;\n+import org.apache.geode.test.dunit.rules.DistributedRule;\n+\n+@RunWith(JUnitParamsRunner.class)\n+public class PartitionedRegionClearWithRebalanceDUnitTest implements Serializable {", "originalCommit": "471174e0428631bf9382e293c04ce2da8de78a06", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxNjI1Mw==", "url": "https://github.com/apache/geode/pull/5095#discussion_r430716253", "bodyText": "In the first scenario, would we expect clear to succeed? If a member departs during clear, we get PartitionedRegionPartialClearException, right? I can definitely add the second scenario though.", "author": "DonalEvans", "createdAt": "2020-05-26T21:24:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMzI5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc0MTIxOQ==", "url": "https://github.com/apache/geode/pull/5095#discussion_r430741219", "bodyText": "Based on the redundant copies available; the clear should finish successfully, even with server down. The clear operation waits certain time for secondary to become primary, if it is unable to find the primary in given time, then it will throw Partial Clear exception.", "author": "agingade", "createdAt": "2020-05-26T22:25:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMzI5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjAwMDY0Mg==", "url": "https://github.com/apache/geode/pull/5095#discussion_r432000642", "bodyText": "Using three servers, with a PartitionedRegion with one redundant copy, and killing the non-coordinator server when the clear operation starts, I am still seeing a PartialClearException some of the time. It seems to be flaky whether the clear operation has enough time to find the new primary in the case that a server goes down. This happens even if there is no rebalance happening at the time; as long as some data is hosted on the member that is killed, there is a chance of a PartialClearException, it seems. I don't know if it will be possible to write a useful test in this scenario, since we have to either assert that the clear succeeds, or that it fails, but it doesn't do either reliably.", "author": "DonalEvans", "createdAt": "2020-05-28T17:22:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMzI5MA=="}], "type": "inlineReview"}, {"oid": "929aee49153e7c1b1eece5ae7349883916ccce71", "url": "https://github.com/apache/geode/commit/929aee49153e7c1b1eece5ae7349883916ccce71", "message": "Add HA test cases\n\n- Test when member departs during clear/rebalance\n- Test when member joins during clear/rebalance\n- Add retry to clear if PartialClearException is thrown\n\nAuthored-by: Donal Evans <doevans@vmware.com>", "committedDate": "2020-07-10T01:03:44Z", "type": "forcePushed"}, {"oid": "84b7f96cb6934816ba34228ba1317836f6343c73", "url": "https://github.com/apache/geode/commit/84b7f96cb6934816ba34228ba1317836f6343c73", "message": "Refactor DUnit tests, remove redundant test cases\n\nAuthored-by: Donal Evans <doevans@vmware.com>", "committedDate": "2020-07-15T20:38:08Z", "type": "forcePushed"}, {"oid": "94deeb83f26761b935c7e98657f379f3a1e1fc7b", "url": "https://github.com/apache/geode/commit/94deeb83f26761b935c7e98657f379f3a1e1fc7b", "message": "Refactor DUnit test and remove test case\n\n- Rebalance > clear > kill member during clear test was\nnondeterministic. If primary buckets could be recovered, no exception\nwas thrown, but if primary revocery timed out,\nPartitionedRegionPartialClearException was thrown.\n\nAuthored-by: Donal Evans <doevans@vmware.com>", "committedDate": "2020-07-17T19:59:56Z", "type": "forcePushed"}, {"oid": "e40815146e960c5957db1b479b2733caaba0178b", "url": "https://github.com/apache/geode/commit/e40815146e960c5957db1b479b2733caaba0178b", "message": "GEODE-7680: PR.clear must be successful when interacting with rebalance\n\n- Added DUnit tests to confirm that clear does not interfere with\nrebalance or vice versa\n- Fixed typo in PartitionedRegionClearWithExpirationDUnitTest\n- Fixed typo in PartitionedRegion\n\nAuthored-by: Donal Evans <doevans@pivotal.io>", "committedDate": "2020-07-17T20:04:44Z", "type": "commit"}, {"oid": "858dc74fc3d092abcf48b0d7c34a19bba1212edf", "url": "https://github.com/apache/geode/commit/858dc74fc3d092abcf48b0d7c34a19bba1212edf", "message": "Rebased on feature branch, added tests for colocated regions\n\n- Call assignBucketsToPartitions() on leader colocated region during clear\ninstead of target region\n- Remove HA test, since clear always throws PartialClearException when\nmember departs and rebalance behaviour when member departs is already\ncovered\n\nAuthored-by: Donal Evans <doevans@pivotal.io>", "committedDate": "2020-07-17T20:04:45Z", "type": "commit"}, {"oid": "46192dea9398fea92951eeb853a5ced997f9946e", "url": "https://github.com/apache/geode/commit/46192dea9398fea92951eeb853a5ced997f9946e", "message": "Add HA test cases\n\n- Test when member departs during clear/rebalance\n- Test when member joins during clear/rebalance\n- Add retry to clear if PartialClearException is thrown\n\nAuthored-by: Donal Evans <doevans@vmware.com>", "committedDate": "2020-07-17T20:04:45Z", "type": "commit"}, {"oid": "f9d910e2bf2ea99667c77ad17b8f1ef3377dabea", "url": "https://github.com/apache/geode/commit/f9d910e2bf2ea99667c77ad17b8f1ef3377dabea", "message": "Fix failing unit tests\n\nAuthored-by: Donal Evans <doevans@vmware.com>", "committedDate": "2020-07-17T20:04:45Z", "type": "commit"}, {"oid": "4cadadaad343badd1b3a30153f449e6c68a10844", "url": "https://github.com/apache/geode/commit/4cadadaad343badd1b3a30153f449e6c68a10844", "message": "Refactor DUnit tests, remove redundant test cases\n\nAuthored-by: Donal Evans <doevans@vmware.com>", "committedDate": "2020-07-17T20:04:45Z", "type": "commit"}, {"oid": "8e03b1e796669f05c8debc07c256b7d99d94ce18", "url": "https://github.com/apache/geode/commit/8e03b1e796669f05c8debc07c256b7d99d94ce18", "message": "Refactor DUnit test and remove test case\n\n- Rebalance > clear > kill member during clear test was\nnondeterministic. If primary buckets could be recovered, no exception\nwas thrown, but if primary revocery timed out,\nPartitionedRegionPartialClearException was thrown.\n\nAuthored-by: Donal Evans <doevans@vmware.com>", "committedDate": "2020-07-17T20:04:45Z", "type": "commit"}, {"oid": "8e03b1e796669f05c8debc07c256b7d99d94ce18", "url": "https://github.com/apache/geode/commit/8e03b1e796669f05c8debc07c256b7d99d94ce18", "message": "Refactor DUnit test and remove test case\n\n- Rebalance > clear > kill member during clear test was\nnondeterministic. If primary buckets could be recovered, no exception\nwas thrown, but if primary revocery timed out,\nPartitionedRegionPartialClearException was thrown.\n\nAuthored-by: Donal Evans <doevans@vmware.com>", "committedDate": "2020-07-17T20:04:45Z", "type": "forcePushed"}]}