{"pr_number": 6225, "pr_title": "Perf optimization for SQL GROUP BY ORDER BY", "pr_createdAt": "2020-11-03T18:10:33Z", "pr_url": "https://github.com/apache/pinot/pull/6225", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4NjU3OQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r516886579", "bodyText": "(Critical) This will break Having clause", "author": "Jackie-Jiang", "createdAt": "2020-11-03T18:53:58Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/GroupByDataTableReducer.java", "diffHunk": "@@ -265,7 +265,7 @@ private IndexedTable getIndexedTable(DataSchema dataSchema, Collection<DataTable\n     int numReduceThreadsToUse = getNumReduceThreadsToUse(numDataTables, reducerContext.getMaxReduceThreadsPerQuery());\n \n     // In case of single reduce thread, fall back to SimpleIndexedTable to avoid redundant locking/unlocking calls.\n-    int capacity = GroupByUtils.getTableCapacity(_queryContext);\n+    int capacity = _queryContext.getLimit();", "originalCommit": "beb196d39c79012efaa4fdbe927e887a48624e7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2NjU4Ng==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525566586", "bodyText": "This is no longer needed. I removed the change", "author": "siddharthteotia", "createdAt": "2020-11-17T22:27:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4NjU3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4OTE5OA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r516889198", "bodyText": "I don't think we should embed Key inside Record, especially when the key is extracted from the Record, and then set back into Record using a setter.\nIt's okay to merge Key class into the Record class so that we have a central place for all the record information. The constructor should initialize both keys and values, and they should be final.", "author": "Jackie-Jiang", "createdAt": "2020-11-03T18:58:53Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/Record.java", "diffHunk": "@@ -45,6 +45,7 @@\n public class Record {\n   private final Object[] _values;\n \n+  private Key _key;", "originalCommit": "beb196d39c79012efaa4fdbe927e887a48624e7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDg0ODg2Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r524848862", "bodyText": "Removed this. No longer needed", "author": "siddharthteotia", "createdAt": "2020-11-17T02:43:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4OTE5OA=="}], "type": "inlineReview"}, {"oid": "ea600cf017fe973115a223d68ac33adabf3c1495", "url": "https://github.com/apache/pinot/commit/ea600cf017fe973115a223d68ac33adabf3c1495", "message": "SQL group by order by perf optimization", "committedDate": "2020-11-17T02:30:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDg1MDE1OQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r524850159", "bodyText": "Forgot to undo info. Will revert to debug", "author": "siddharthteotia", "createdAt": "2020-11-17T02:47:55Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/SimpleIndexedTable.java", "diffHunk": "@@ -136,20 +125,16 @@ public int size() {\n \n   @Override\n   public void finish(boolean sort) {\n-\n     if (_hasOrderBy) {\n-\n       if (sort) {\n-        List<Record> sortedRecords = resizeAndSort(_capacity);\n+        List<Record> sortedRecords = resizeAndSort(_trimSize);\n         _iterator = sortedRecords.iterator();\n       } else {\n-        resize(_capacity);\n+        resize(_trimSize);\n       }\n-      LOGGER\n-          .debug(\"Num resizes : {}, Total time spent in resizing : {}, Avg resize time : {}\", _numResizes, _resizeTime,\n-              _numResizes == 0 ? 0 : _resizeTime / _numResizes);\n+      LOGGER.info(\"Num resizes : {}, Total time spent in resizing : {}, Avg resize time : {}, trimSize: {}, trimThresholdForUpsert: {},  trimThresholdForFinish: {}\",", "originalCommit": "de485c52302eba27197b98bb084e68973166e779", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MzU1Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525373552", "bodyText": "Can we reuse existing PQL configs?", "author": "mayankshriv", "createdAt": "2020-11-17T18:02:04Z", "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/CommonConstants.java", "diffHunk": "@@ -173,6 +173,10 @@\n     public static final int DEFAULT_MAX_REDUCE_THREADS_PER_QUERY =\n         Math.max(1, Math.min(10, Runtime.getRuntime().availableProcessors() / 2)); // Same logic as CombineOperatorUtils\n \n+    // used for SQL GROUP BY ORDER BY\n+    public static final String CONFIG_OF_BROKER_SQL_GROUPBY_TRIM_THRESHOLD = \"pinot.broker.sql.groupby.trim.threshold\";", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2Njk4OQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525566989", "bodyText": "@mayankshriv\nBroker reduce also needs to be optimized the same way as server combine since both use indexed table. The PQL config which this PR is reusing on the server for SQL GROUP BY is in ServerConf and there is no way for it to be available to Broker. Secondly, PQL never had a broker config for GROUP BY. Hence, I introduced a new config.", "author": "siddharthteotia", "createdAt": "2020-11-17T22:28:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MzU1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ4ODk1NA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526488954", "bodyText": "(optional) Suggest removing the sql (rename to pinot.broker.groupby.trim.threshold) because we are going to deprecate pql and sql will be the standard", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:23:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MzU1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NTI0Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525375242", "bodyText": "Please add javadoc for the class and public methods.", "author": "mayankshriv", "createdAt": "2020-11-17T18:04:47Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTableOptimizedForLargeGroups.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.table;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.common.utils.DataSchema;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+\n+\n+public class ConcurrentIndexedTableOptimizedForLargeGroups extends ConcurrentIndexedTable {", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxMzQ1OQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525513459", "bodyText": "Rename this class to better reflect the purpose? Maybe UnboundedConcurrentIndexedTable?", "author": "Jackie-Jiang", "createdAt": "2020-11-17T20:46:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NTI0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU3NzMxNg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525577316", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-17T22:49:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NTI0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NTcwMA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525375700", "bodyText": "Could be skipped for perf?", "author": "mayankshriv", "createdAt": "2020-11-17T18:05:24Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTableOptimizedForLargeGroups.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.table;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.common.utils.DataSchema;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+\n+\n+public class ConcurrentIndexedTableOptimizedForLargeGroups extends ConcurrentIndexedTable {\n+\n+  public ConcurrentIndexedTableOptimizedForLargeGroups(DataSchema dataSchema,\n+      QueryContext queryContext, int trimSize, int trimThreshold) {\n+    super(dataSchema, queryContext, trimSize, trimThreshold);\n+  }\n+\n+  @Override\n+  public boolean upsert(Key key, Record newRecord) {\n+    Preconditions.checkNotNull(key, \"Cannot upsert record with null keys\");", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU3NzY3Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525577672", "bodyText": "I actually didn't try it to see the improvement. May be we can remove it.", "author": "siddharthteotia", "createdAt": "2020-11-17T22:50:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NTcwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTgwMg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525379802", "bodyText": "Use >= instead of ==?", "author": "mayankshriv", "createdAt": "2020-11-17T18:11:42Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/GroupByDataTableReducer.java", "diffHunk": "@@ -262,13 +264,24 @@ private IndexedTable getIndexedTable(DataSchema dataSchema, Collection<DataTable\n     int numDataTables = dataTablesToReduce.size();\n \n     // Get the number of threads to use for reducing.\n-    int numReduceThreadsToUse = getNumReduceThreadsToUse(numDataTables, reducerContext.getMaxReduceThreadsPerQuery());\n-\n     // In case of single reduce thread, fall back to SimpleIndexedTable to avoid redundant locking/unlocking calls.\n-    int capacity = GroupByUtils.getTableCapacity(_queryContext);\n-    IndexedTable indexedTable =\n-        (numReduceThreadsToUse > 1) ? new ConcurrentIndexedTable(dataSchema, _queryContext, capacity)\n-            : new SimpleIndexedTable(dataSchema, _queryContext, capacity);\n+    int numReduceThreadsToUse = getNumReduceThreadsToUse(numDataTables, reducerContext.getMaxReduceThreadsPerQuery());\n+    int trimSize = GroupByUtils.getTableCapacity(_queryContext);\n+    int trimThreshold = reducerContext.getSqlGroupByTrimThreshold();\n+    IndexedTable indexedTable;\n+    if (numReduceThreadsToUse <= 1) {\n+      indexedTable = new SimpleIndexedTable(dataSchema, _queryContext, trimSize, trimThreshold);\n+    } else {\n+      if (trimThreshold == GroupByOrderByCombineOperator.INFINITE_INTER_SEGMENT_GROUPS_LIMIT) {", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMzA4NQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525523085", "bodyText": "+1", "author": "Jackie-Jiang", "createdAt": "2020-11-17T21:03:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTgwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0ODU2Mw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525548563", "bodyText": "Right. I did the same in server combine. Missed it here. Fixed now", "author": "siddharthteotia", "createdAt": "2020-11-17T21:51:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTgwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ5MzY2Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525493662", "bodyText": "Why do we need a trim threshold for finish? We should always trim it to the _trimSize right?", "author": "Jackie-Jiang", "createdAt": "2020-11-17T20:23:45Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -37,39 +37,48 @@\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThresholdForUpsert;\n+  protected final int _trimThresholdForFinish;", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyODE5Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525528192", "bodyText": "@Jackie-Jiang , For Parity with PQL, finish(false) called from server combine should trim to trimSize only if map size > trimThreshold. This behavior is same as PQL (see AggregationGroupByTrimmingService)", "author": "siddharthteotia", "createdAt": "2020-11-17T21:13:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ5MzY2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMTIyMA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525601220", "bodyText": "This is incorrect. We should always trim the result in finish to reduce the records sent from broker to server. We should also change the code in PQL path", "author": "Jackie-Jiang", "createdAt": "2020-11-17T23:49:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ5MzY2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUwODk3Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525508972", "bodyText": "We should reuse the map to prevent growing the map again and again", "author": "Jackie-Jiang", "createdAt": "2020-11-17T20:38:28Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTable.java", "diffHunk": "@@ -125,50 +124,44 @@ public int size() {\n   }\n \n   private void resize(int trimToSize) {\n-\n     long startTime = System.currentTimeMillis();\n-\n-    _tableResizer.resizeRecordsMap(_lookupMap, trimToSize);\n-\n+    // when the resizer trims using a PQ, it will return a new trimmed map.\n+    // the reference held by the indexed table needs to be updated. this is also\n+    // the reason why it is volatile since the thread doing the resize will result in\n+    // a new reference\n+    _lookupMap = (ConcurrentMap)_tableResizer.resizeRecordsMap(_lookupMap, trimToSize);", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyODE4Mw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525528183", "bodyText": "This is a perf enhancement. Reusing the map requires the TableResizer to invoke retainAll() on the existing map which was taking considerable period of time. PQL also builds a new map.", "author": "siddharthteotia", "createdAt": "2020-11-17T21:13:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUwODk3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5OTIyNw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525599227", "bodyText": "PQL builds a new map because the new map is final and won't grow again. We cannot use retainAll() because looking up values in PQ is expensive, but we should try to use the existing map to avoid the overhead of growing the map.\nI'm okay keeping it this way for now, but please add a TODO", "author": "Jackie-Jiang", "createdAt": "2020-11-17T23:43:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUwODk3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxNzE1Mw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525517153", "bodyText": "Prevent int overflow\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                _trimThreshold = Math.min(segmentLevelNumGroupsLimit * 2, Integer.MAX_VALUE);\n          \n          \n            \n                _trimThreshold = (int) Math.min((long) segmentLevelNumGroupsLimit * 2, Integer.MAX_VALUE);", "author": "Jackie-Jiang", "createdAt": "2020-11-17T20:52:54Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,28 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_INTER_SEGMENT_GROUPS_LIMIT = 2 * 1_000_000_000;\n \n   private final List<Operator> _operators;\n   private final QueryContext _queryContext;\n   private final ExecutorService _executorService;\n   private final long _endTimeMs;\n-  private final int _indexedTableCapacity;\n+  private final int _trimSize;\n   private final Lock _initLock;\n   private DataSchema _dataSchema;\n   private ConcurrentIndexedTable _indexedTable;\n+  private final int _trimThreshold;\n+\n \n   public GroupByOrderByCombineOperator(List<Operator> operators, QueryContext queryContext,\n-      ExecutorService executorService, long endTimeMs) {\n+      ExecutorService executorService, long endTimeMs, int segmentLevelNumGroupsLimit) {\n     _operators = operators;\n     _queryContext = queryContext;\n     _executorService = executorService;\n     _endTimeMs = endTimeMs;\n     _initLock = new ReentrantLock();\n-    _indexedTableCapacity = GroupByUtils.getTableCapacity(_queryContext);\n+    _trimSize = GroupByUtils.getTableCapacity(_queryContext);\n+    _trimThreshold = Math.min(segmentLevelNumGroupsLimit * 2, Integer.MAX_VALUE);", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0OTg1MA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525549850", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-17T21:54:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxNzE1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxNzY3Nw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525517677", "bodyText": "(nit) move to line 73", "author": "Jackie-Jiang", "createdAt": "2020-11-17T20:53:56Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,28 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_INTER_SEGMENT_GROUPS_LIMIT = 2 * 1_000_000_000;\n \n   private final List<Operator> _operators;\n   private final QueryContext _queryContext;\n   private final ExecutorService _executorService;\n   private final long _endTimeMs;\n-  private final int _indexedTableCapacity;\n+  private final int _trimSize;\n   private final Lock _initLock;\n   private DataSchema _dataSchema;\n   private ConcurrentIndexedTable _indexedTable;\n+  private final int _trimThreshold;", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0ODYyMQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525548621", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-17T21:51:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxNzY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMDcxNQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525520715", "bodyText": "Please rename this method accordingly as it no longer resizes the map", "author": "Jackie-Jiang", "createdAt": "2020-11-17T20:59:32Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/TableResizer.java", "diffHunk": "@@ -183,62 +192,26 @@ public void resizeRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {\n     return priorityQueue;\n   }\n \n-  private List<Record> sortRecordsMap(Map<Key, Record> recordsMap) {\n-    int numRecords = recordsMap.size();\n-    List<Record> sortedRecords = new ArrayList<>(numRecords);\n-    List<IntermediateRecord> intermediateRecords = new ArrayList<>(numRecords);\n-    for (Map.Entry<Key, Record> entry : recordsMap.entrySet()) {\n-      intermediateRecords.add(getIntermediateRecord(entry.getKey(), entry.getValue()));\n-    }\n-    intermediateRecords.sort(_intermediateRecordComparator);\n-    for (IntermediateRecord intermediateRecord : intermediateRecords) {\n-      sortedRecords.add(recordsMap.get(intermediateRecord._key));\n-    }\n-    return sortedRecords;\n-  }\n-\n   /**\n    * Resizes the recordsMap and returns a sorted list of records.\n    * This method is to be called from IndexedTable::finish, if both resize and sort is needed\n-   *\n-   * If numRecordsToEvict > numRecordsToRetain, resize with PQ of records to evict, and then sort\n-   * Else, resize with PQ of record to retain, then use the PQ to create sorted list\n+   * Resize with PQ of record to retain, then use the PQ to create sorted list\n    */\n   public List<Record> resizeAndSortRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU3Njc1NQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525576755", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-17T22:48:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMDcxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMTQ5Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525521492", "bodyText": "Try to not create a new map as growing the map again is very expensive", "author": "Jackie-Jiang", "createdAt": "2020-11-17T21:00:55Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/TableResizer.java", "diffHunk": "@@ -136,39 +138,46 @@ private IntermediateRecord getIntermediateRecord(Key key, Record record) {\n    * Resize only if number of records is greater than trimToSize\n    * The resizer smartly chooses to create PQ of records to evict or records to retain, based on the number of records and the number of records to evict\n    */\n-  public void resizeRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {\n+  public Map<Key, Record> resizeRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {\n     int numRecordsToEvict = recordsMap.size() - trimToSize;\n-\n     if (numRecordsToEvict > 0) {\n       // TODO: compare the performance of converting to IntermediateRecord vs keeping Record, in cases where we do not need to extract final results\n-\n-      if (numRecordsToEvict < trimToSize) { // num records to evict is smaller than num records to retain\n+      if (numRecordsToEvict < trimToSize) {\n+        // num records to evict is smaller than num records to retain\n         // make PQ of records to evict\n         PriorityQueue<IntermediateRecord> priorityQueue =\n             convertToIntermediateRecordsPQ(recordsMap, numRecordsToEvict, _intermediateRecordComparator);\n         for (IntermediateRecord evictRecord : priorityQueue) {\n           recordsMap.remove(evictRecord._key);\n         }\n-      } else { // num records to retain is smaller than num records to evict\n+        return recordsMap;\n+      } else {\n+        // num records to retain is smaller than num records to evict\n         // make PQ of records to retain\n+        Map<Key, Record> trimmedRecordsMap;", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyODk1OQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525528959", "bodyText": "@Jackie-Jiang , I noticed that retainAll() is very expensive so creating a result map (same as what is done by AggregationGroupByTrimmingService in PQL) is preferrable and it resulted in significant improvement. retainAll() was taking > 1sec in some cases", "author": "siddharthteotia", "createdAt": "2020-11-17T21:15:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMTQ5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMTYwOQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525601609", "bodyText": "We need to avoid retainAll() on PQ for sure, but we should also try to reuse the existing map", "author": "Jackie-Jiang", "createdAt": "2020-11-17T23:50:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMTQ5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMTc5Nw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525521797", "bodyText": "Not used?", "author": "Jackie-Jiang", "createdAt": "2020-11-17T21:01:25Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/blocks/IntermediateResultsBlock.java", "diffHunk": "@@ -40,16 +40,20 @@\n import org.apache.pinot.core.common.datatable.DataTableImplV2;\n import org.apache.pinot.core.data.table.Record;\n import org.apache.pinot.core.data.table.Table;\n+import org.apache.pinot.core.operator.combine.GroupByCombineOperator;\n import org.apache.pinot.core.query.aggregation.function.AggregationFunction;\n import org.apache.pinot.core.query.aggregation.groupby.AggregationGroupByResult;\n import org.apache.pinot.core.query.selection.SelectionOperatorUtils;\n import org.apache.pinot.spi.utils.ByteArray;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n \n /**\n  * The <code>IntermediateResultsBlock</code> class is the holder of the server side inter-segment results.\n  */\n public class IntermediateResultsBlock implements Block {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(IntermediateResultsBlock.class);", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0NTExMw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525545113", "bodyText": "Yes. Was using it for debugging. Removed now.", "author": "siddharthteotia", "createdAt": "2020-11-17T21:45:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMTc5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMjQ2Mw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525522463", "bodyText": "(nit) Don't remove these empty lines for better readability", "author": "Jackie-Jiang", "createdAt": "2020-11-17T21:02:38Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/blocks/IntermediateResultsBlock.java", "diffHunk": "@@ -388,7 +391,6 @@ private DataTable getAggregationGroupByResultDataTable()\n       throws Exception {\n     String[] columnNames = new String[]{\"functionName\", \"GroupByResultMap\"};\n     ColumnDataType[] columnDataTypes = new ColumnDataType[]{ColumnDataType.STRING, ColumnDataType.OBJECT};\n-", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0OTI5OA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525549298", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-17T21:53:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMjQ2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNDg5OA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525524898", "bodyText": "We should not have this max because the trimThreshold is already the higher bound allowed", "author": "Jackie-Jiang", "createdAt": "2020-11-17T21:07:15Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -37,39 +37,48 @@\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThresholdForUpsert;\n+  protected final int _trimThresholdForFinish;\n \n-  protected IndexedTable(DataSchema dataSchema, QueryContext queryContext, int capacity) {\n-    super(dataSchema);\n+  protected List<Record> _sortedRecords;\n \n+  public IndexedTable(DataSchema dataSchema, QueryContext queryContext, int trimSize, int trimThreshold) {\n+    super(dataSchema);\n     List<ExpressionContext> groupByExpressions = queryContext.getGroupByExpressions();\n     assert groupByExpressions != null;\n     _numKeyColumns = groupByExpressions.size();\n-\n     _aggregationFunctions = queryContext.getAggregationFunctions();\n-\n     List<OrderByExpressionContext> orderByExpressions = queryContext.getOrderByExpressions();\n     if (orderByExpressions != null) {\n+      // SQL GROUP BY with ORDER BY\n+      // trimSize = max (limit N * 5, 5000) (see GroupByUtils.getTableCapacity)\n+      // to keep parity with PQL for some use cases with infinitely large group by,\n+      // we have different trim thresholds for upsert and finish.\n+      // for such cases, trimThresholdForUpsert will be 1_000_000_000 * 2\n+      // (exactly same as PQL). this essentially implies there will be no\n+      // resizing/trimming during upsert. during finish (called after server combine is over),\n+      // we still want to trim the results and trimThreshold is computed in the\n+      // same manner as PQL (trimSize * 4)\n       _hasOrderBy = true;\n       _tableResizer = new TableResizer(dataSchema, queryContext);\n-      _capacity = capacity;\n-\n-      // TODO: tune these numbers and come up with a better formula (github ISSUE-4801)\n-      // Based on the capacity and maxCapacity, the resizer will smartly choose to evict/retain recors from the PQ\n-      if (capacity\n-          <= 100_000) { // Capacity is small, make a very large buffer. Make PQ of records to retain, during resize\n-        _maxCapacity = 1_000_000;\n-      } else { // Capacity is large, make buffer only slightly bigger. Make PQ of records to evict, during resize\n-        _maxCapacity = (int) (capacity * 1.2);\n-      }\n+      _trimSize = trimSize;\n+      _trimThresholdForUpsert = Math.max(trimSize * 4, trimThreshold);", "originalCommit": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5NjQ1MQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525596451", "bodyText": "yes, not needed. Removed", "author": "siddharthteotia", "createdAt": "2020-11-17T23:35:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNDg5OA=="}], "type": "inlineReview"}, {"oid": "b3eb38e348892144267aaa568d85e3208417a637", "url": "https://github.com/apache/pinot/commit/b3eb38e348892144267aaa568d85e3208417a637", "message": "SQL group by order by perf optimization", "committedDate": "2020-11-17T23:35:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMjYxNw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525602617", "bodyText": "(nit) reformat", "author": "Jackie-Jiang", "createdAt": "2020-11-17T23:53:02Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,27 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_INTER_SEGMENT_GROUPS_LIMIT = 2 * 1_000_000_000;\n \n   private final List<Operator> _operators;\n   private final QueryContext _queryContext;\n   private final ExecutorService _executorService;\n   private final long _endTimeMs;\n-  private final int _indexedTableCapacity;\n+  private final int _trimSize;\n+  private final int _trimThreshold;\n   private final Lock _initLock;\n   private DataSchema _dataSchema;\n   private ConcurrentIndexedTable _indexedTable;\n \n   public GroupByOrderByCombineOperator(List<Operator> operators, QueryContext queryContext,\n-      ExecutorService executorService, long endTimeMs) {\n+      ExecutorService executorService, long endTimeMs, int segmentLevelNumGroupsLimit) {\n     _operators = operators;\n     _queryContext = queryContext;\n     _executorService = executorService;\n     _endTimeMs = endTimeMs;\n     _initLock = new ReentrantLock();\n-    _indexedTableCapacity = GroupByUtils.getTableCapacity(_queryContext);\n+    _trimSize = GroupByUtils.getTableCapacity(_queryContext);\n+    _trimThreshold = (int)Math.min((long)segmentLevelNumGroupsLimit * 2, Integer.MAX_VALUE);", "originalCommit": "b3eb38e348892144267aaa568d85e3208417a637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ2NTgwNA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526465804", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-18T22:28:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMjYxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzY0OQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525603649", "bodyText": "(Critical) This is incorrect. Indexed table size can be the same as trim size in regular cases.", "author": "Jackie-Jiang", "createdAt": "2020-11-17T23:55:43Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -242,7 +255,7 @@ public void runJob() {\n       // Set the execution statistics.\n       CombineOperatorUtils.setExecutionStatistics(mergedBlock, _operators);\n \n-      if (_indexedTable.size() >= _indexedTableCapacity) {\n+      if (_indexedTable.size() >= _trimSize) {", "originalCommit": "b3eb38e348892144267aaa568d85e3208417a637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ3MzgyNg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526473826", "bodyText": "this has always been incorrect (inaccurate actually) for both SQL and PQL. Will fix in a follow-up. Added a TODO.", "author": "siddharthteotia", "createdAt": "2020-11-18T22:45:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzY0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5NDQ2Mw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526494463", "bodyText": "It is correctly set for PQL. Please remove this if block, and maybe add a TODO to properly set this flag", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:38:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzY0OQ=="}], "type": "inlineReview"}, {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f", "url": "https://github.com/apache/pinot/commit/67410cd450aff9f6699470ebfd379f3403c1a96f", "message": "SQL group by order by perf optimization", "committedDate": "2020-11-18T20:38:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MDE4OA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526490188", "bodyText": "(nit) remove", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:26:47Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTable.java", "diffHunk": "@@ -125,52 +120,47 @@ public int size() {\n   }\n \n   private void resize(int trimToSize) {\n-\n     long startTime = System.currentTimeMillis();\n-\n-    _tableResizer.resizeRecordsMap(_lookupMap, trimToSize);\n-\n+    // when the resizer trims using a PQ, it will return a new trimmed map.\n+    // the reference held by the indexed table needs to be updated. this is also\n+    // the reason why it is volatile since the thread doing the resize will result in\n+    // a new reference\n+    _lookupMap = (ConcurrentMap)_tableResizer.resizeRecordsMap(_lookupMap, trimToSize);\n     long endTime = System.currentTimeMillis();\n     long timeElapsed = endTime - startTime;\n-\n     _numResizes.incrementAndGet();\n     _resizeTime.addAndGet(timeElapsed);\n   }\n \n   private List<Record> resizeAndSort(int trimToSize) {\n-\n     long startTime = System.currentTimeMillis();\n-\n-    List<Record> sortedRecords = _tableResizer.resizeAndSortRecordsMap(_lookupMap, trimToSize);\n-\n+    List<Record> sortedRecords = _tableResizer.sortRecordsMap(_lookupMap, trimToSize);\n     long endTime = System.currentTimeMillis();\n     long timeElapsed = endTime - startTime;\n-\n     _numResizes.incrementAndGet();\n     _resizeTime.addAndGet(timeElapsed);\n-\n     return sortedRecords;\n   }\n \n   @Override\n   public void finish(boolean sort) {\n-\n     if (_hasOrderBy) {\n-\n       if (sort) {\n-        List<Record> sortedRecords = resizeAndSort(_capacity);\n-        _iterator = sortedRecords.iterator();\n+        _sortedRecords = resizeAndSort(_trimSize);\n+        _iterator = _sortedRecords.iterator();\n       } else {\n-        resize(_capacity);\n+        resize(_trimSize);\n       }\n       int numResizes = _numResizes.get();\n       long resizeTime = _resizeTime.get();\n-      LOGGER.debug(\"Num resizes : {}, Total time spent in resizing : {}, Avg resize time : {}\", numResizes, resizeTime,\n-          numResizes == 0 ? 0 : resizeTime / numResizes);\n+      LOGGER.debug(\n+          \"Num resizes : {}, Total time spent in resizing : {}, Avg resize time : {}, trimSize: {}, trimThreshold: {}\",\n+          numResizes, resizeTime, numResizes == 0 ? 0 : resizeTime / numResizes, _trimSize, _trimThreshold);\n     }\n-\n     if (_iterator == null) {\n       _iterator = _lookupMap.values().iterator();\n     }\n   }\n+", "originalCommit": "67410cd450aff9f6699470ebfd379f3403c1a96f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcwMTc1OA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526701758", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-19T09:11:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MDE4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTI0MQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526491241", "bodyText": "(nit) _resizeTimeMs", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:30:00Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -36,40 +38,46 @@\n   protected final AggregationFunction[] _aggregationFunctions;\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n+  protected final AtomicInteger _numResizes = new AtomicInteger();\n+  protected final AtomicLong _resizeTime = new AtomicLong();", "originalCommit": "67410cd450aff9f6699470ebfd379f3403c1a96f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcwMTc0Mw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526701743", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-19T09:11:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTI0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTM0Mw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526491343", "bodyText": "(nit) reformat", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:30:13Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -36,40 +38,46 @@\n   protected final AggregationFunction[] _aggregationFunctions;\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n+  protected final AtomicInteger _numResizes = new AtomicInteger();\n+  protected final AtomicLong _resizeTime = new AtomicLong();\n+  protected List<Record> _sortedRecords;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThreshold;\n \n-  protected IndexedTable(DataSchema dataSchema, QueryContext queryContext, int capacity) {\n+  public IndexedTable(DataSchema dataSchema, QueryContext queryContext, int trimSize, int trimThreshold) {\n     super(dataSchema);\n-\n     List<ExpressionContext> groupByExpressions = queryContext.getGroupByExpressions();\n     assert groupByExpressions != null;\n     _numKeyColumns = groupByExpressions.size();\n-\n     _aggregationFunctions = queryContext.getAggregationFunctions();\n-\n     List<OrderByExpressionContext> orderByExpressions = queryContext.getOrderByExpressions();\n     if (orderByExpressions != null) {\n+      // SQL GROUP BY with ORDER BY\n+      // trimSize = max (limit N * 5, 5000) (see GroupByUtils.getTableCapacity).\n+      // trimSize is also bound by trimThreshold/2 to protect the server in case\n+      // when user specifies a very high value of LIMIT N.\n+      // trimThreshold is configurable. to keep parity with PQL for some use\n+      // cases with infinitely large group by, trimThreshold will be >= 1B\n+      // (exactly same as PQL). This essentially implies there will be no\n+      // resizing/trimming during upsert and exactly one trim during finish.\n       _hasOrderBy = true;\n       _tableResizer = new TableResizer(dataSchema, queryContext);\n-      _capacity = capacity;\n-\n-      // TODO: tune these numbers and come up with a better formula (github ISSUE-4801)\n-      // Based on the capacity and maxCapacity, the resizer will smartly choose to evict/retain recors from the PQ\n-      if (capacity\n-          <= 100_000) { // Capacity is small, make a very large buffer. Make PQ of records to retain, during resize\n-        _maxCapacity = 1_000_000;\n-      } else { // Capacity is large, make buffer only slightly bigger. Make PQ of records to evict, during resize\n-        _maxCapacity = (int) (capacity * 1.2);\n-      }\n+      _trimSize = Math.min(trimSize, trimThreshold/2);", "originalCommit": "67410cd450aff9f6699470ebfd379f3403c1a96f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcwMTcyMQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526701721", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-19T09:11:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTM0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTQ1MQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526491451", "bodyText": "Should still be protected?", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:30:31Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -36,40 +38,46 @@\n   protected final AggregationFunction[] _aggregationFunctions;\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n+  protected final AtomicInteger _numResizes = new AtomicInteger();\n+  protected final AtomicLong _resizeTime = new AtomicLong();\n+  protected List<Record> _sortedRecords;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThreshold;\n \n-  protected IndexedTable(DataSchema dataSchema, QueryContext queryContext, int capacity) {\n+  public IndexedTable(DataSchema dataSchema, QueryContext queryContext, int trimSize, int trimThreshold) {", "originalCommit": "67410cd450aff9f6699470ebfd379f3403c1a96f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcwMTY5MA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526701690", "bodyText": "removed", "author": "siddharthteotia", "createdAt": "2020-11-19T09:11:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTQ1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MjIxMA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526492210", "bodyText": "(nit)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public void setResizeTimeMs(long resizeTime) {\n          \n          \n            \n              public void setResizeTimeMs(long resizeTimeMs) {", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:32:40Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/blocks/IntermediateResultsBlock.java", "diffHunk": "@@ -218,6 +223,14 @@ public void setNumGroupsLimitReached(boolean numGroupsLimitReached) {\n     _numGroupsLimitReached = numGroupsLimitReached;\n   }\n \n+  public void setNumResizes(int numResizes) {\n+    _numResizes = numResizes;\n+  }\n+\n+  public void setResizeTimeMs(long resizeTime) {", "originalCommit": "67410cd450aff9f6699470ebfd379f3403c1a96f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcwMTYzNQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526701635", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-19T09:11:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MjIxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MzE5Mg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526493192", "bodyText": "Move it into InstancePlanMakerImplV2 along with the num.groups.limit. Also suggest removing the sql", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:35:07Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,29 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_TRIM_THRESHOLD = 1_000_000_000;\n+  public static final String SQL_GROUPBY_TRIM_THRESHOLD = \"sql.groupby.trim.threshold\";", "originalCommit": "67410cd450aff9f6699470ebfd379f3403c1a96f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcwMTYwNQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526701605", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-19T09:11:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MzE5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MzQxNA==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526493414", "bodyText": "(nit)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  ExecutorService executorService, long endTimeMs, int sqlGroupByTrimThreshold) {\n          \n          \n            \n                  ExecutorService executorService, long endTimeMs, int trimThreshold) {", "author": "Jackie-Jiang", "createdAt": "2020-11-18T23:35:41Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,29 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_TRIM_THRESHOLD = 1_000_000_000;\n+  public static final String SQL_GROUPBY_TRIM_THRESHOLD = \"sql.groupby.trim.threshold\";\n+  public static final int DEFAULT_SQL_GROUPBY_TRIM_THRESHOLD = 1_000_000;\n \n   private final List<Operator> _operators;\n   private final QueryContext _queryContext;\n   private final ExecutorService _executorService;\n   private final long _endTimeMs;\n-  private final int _indexedTableCapacity;\n+  private final int _trimSize;\n+  private final int _trimThreshold;\n   private final Lock _initLock;\n   private DataSchema _dataSchema;\n   private ConcurrentIndexedTable _indexedTable;\n \n   public GroupByOrderByCombineOperator(List<Operator> operators, QueryContext queryContext,\n-      ExecutorService executorService, long endTimeMs) {\n+      ExecutorService executorService, long endTimeMs, int sqlGroupByTrimThreshold) {", "originalCommit": "67410cd450aff9f6699470ebfd379f3403c1a96f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcwMTUxMg==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526701512", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-19T09:11:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MzQxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyMjA5OQ==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526522099", "bodyText": "Maybe better to use MAX_TRIM_THRESHOLD?", "author": "snleee", "createdAt": "2020-11-19T00:57:26Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,29 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_TRIM_THRESHOLD = 1_000_000_000;", "originalCommit": "67410cd450aff9f6699470ebfd379f3403c1a96f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcwMjkxMw==", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526702913", "bodyText": "done", "author": "siddharthteotia", "createdAt": "2020-11-19T09:13:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyMjA5OQ=="}], "type": "inlineReview"}, {"oid": "d6eef58ea01f6acc801b10e0ffb4e8c91e2b900f", "url": "https://github.com/apache/pinot/commit/d6eef58ea01f6acc801b10e0ffb4e8c91e2b900f", "message": "SQL group by order by perf optimization", "committedDate": "2020-11-19T09:12:46Z", "type": "commit"}, {"oid": "d6eef58ea01f6acc801b10e0ffb4e8c91e2b900f", "url": "https://github.com/apache/pinot/commit/d6eef58ea01f6acc801b10e0ffb4e8c91e2b900f", "message": "SQL group by order by perf optimization", "committedDate": "2020-11-19T09:12:46Z", "type": "forcePushed"}, {"oid": "e8bcb80f300c6c61189540597fc3b012c27bb081", "url": "https://github.com/apache/pinot/commit/e8bcb80f300c6c61189540597fc3b012c27bb081", "message": "cleanup", "committedDate": "2020-11-19T09:31:25Z", "type": "commit"}]}