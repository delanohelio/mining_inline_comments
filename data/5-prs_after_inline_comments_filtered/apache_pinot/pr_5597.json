{"pr_number": 5597, "pr_title": "Filtering during ingestion", "pr_createdAt": "2020-06-20T01:13:39Z", "pr_url": "https://github.com/apache/pinot/pull/5597", "timeline": [{"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "url": "https://github.com/apache/pinot/commit/fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "message": "Filtering during ingestion", "committedDate": "2020-06-20T01:04:21Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MDY4OA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443150688", "bodyText": "High level comment, recording it here so that I dont forget. Intuitively, rows ingested should be indicated by the schema, not by whether the row is filtered or not.  So, I am not sure what this change implies.", "author": "mcvsubbu", "createdAt": "2020-06-20T18:33:00Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/HLRealtimeSegmentDataManager.java", "diffHunk": "@@ -169,9 +169,9 @@ public HLRealtimeSegmentDataManager(final RealtimeSegmentZKMetadata realtimeSegm\n     // create and init stream level consumer\n     StreamConsumerFactory streamConsumerFactory = StreamConsumerFactoryProvider.create(_streamConfig);\n     String clientId = HLRealtimeSegmentDataManager.class.getSimpleName() + \"-\" + _streamConfig.getTopicName();\n-    _streamLevelConsumer = streamConsumerFactory\n-        .createStreamLevelConsumer(clientId, _tableNameWithType, SchemaUtils.extractSourceFields(schema),\n-            instanceMetadata.getGroupId(_tableNameWithType));\n+    _streamLevelConsumer = streamConsumerFactory.createStreamLevelConsumer(clientId, _tableNameWithType,\n+        IngestionUtils.getFieldsForRecordExtractor(tableConfig, schema),", "originalCommit": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MjYyOQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443152629", "bodyText": "I think I have the answer for my question. I think this is because we may have filter expressions on columns that are not present in the schema.\nIf this explanation is right, can you please document it some place? (Perhaps in IngestionUtils class?) Also, it may be worthwhile to make two separate calls, and let the caller decide whether to union the fields or otherwise use them independently. Not sure if there is a use case, but think about it. It certainly makes the code more readable. getFieldsToExtractFromStream(), and getFieldsToFilterOn().\nLastly, is it enough to pass in the IngestionConfig (or, maybe even just the FilterConfig) rather than entire TableConfig? This will keep the discipline of adding any ingestion related item to IngestionConfig than looking some place else in the TableConfig", "author": "mcvsubbu", "createdAt": "2020-06-20T19:02:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MDY4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNDY3Ng==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443704676", "bodyText": "Yes the explanation is right. Updated javadoc on IngestionUtils#getFieldsForRecordExtractor method.\n\n\nIndividual calls should never have to be made, I feel it is better if provide only the method which will extract all the necessary fields, so that we avoid errors in the following phases of ingestion.\n\n\nI like the suggestion of passing just IngestionConfig to set the discipline. Changed the method to take IngestionConfig.", "author": "npawar", "createdAt": "2020-06-22T17:06:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MDY4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MTI0OQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443151249", "bodyText": "On this note, can you add some comments on GenericRow as to how MULTIPLE_RECORDS_KEY is used for (in GenericRow class) and also document it in the decoders description in the documentation? It seems to be used only in test files now, and there is no doc on what it means. Thanks.\nIt looks like the MULTIPLE stuff is a decoder feature. So, when you add a FIXME like this, does this mean that the decoders using multiple recorsd key will break? Or, will they simply not be able to use filters? When is this planned to be fixed? Is this just an interim state from which we should take care not to cut a release? Is this work in progress?", "author": "mcvsubbu", "createdAt": "2020-06-20T18:41:35Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/HLRealtimeSegmentDataManager.java", "diffHunk": "@@ -245,7 +245,8 @@ public void run() {\n             if (consumedRow != null) {\n               try {\n                 GenericRow transformedRow = _recordTransformer.transform(consumedRow);\n-                if (transformedRow != null) {\n+                // FIXME: MULTIPLE_RECORDS_KEY is not handled here", "originalCommit": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNTQwNw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443705407", "bodyText": "Added javadoc in GenericRow.\nAlso added documentation here for the whole IngestionConfig: https://docs.pinot.apache.org/developers/advanced/ingestion-level-transformations", "author": "npawar", "createdAt": "2020-06-22T17:07:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MTI0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MTUwNw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443151507", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                          if (transformedRow != null && IngestionUtils.passedFilter(transformedRow)) {\n          \n          \n            \n                          if (transformedRow != null && IngestionUtils.isRowPruned(transformedRow)) {\n          \n      \n    \n    \n  \n\nOr, IngestionUtils.shouldIngestRow()?\nJust a suggestion, you decide", "author": "mcvsubbu", "createdAt": "2020-06-20T18:45:00Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManager.java", "diffHunk": "@@ -471,7 +471,7 @@ private void processStreamEvents(MessageBatch messagesAndOffsets, long idlePipeS\n           if (decodedRow.getValue(GenericRow.MULTIPLE_RECORDS_KEY) != null) {\n             for (Object singleRow : (Collection) decodedRow.getValue(GenericRow.MULTIPLE_RECORDS_KEY)) {\n               GenericRow transformedRow = _recordTransformer.transform((GenericRow) singleRow);\n-              if (transformedRow != null) {\n+              if (transformedRow != null && IngestionUtils.passedFilter(transformedRow)) {", "originalCommit": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNTUxNA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443705514", "bodyText": "Changed it to shouldIngestRow", "author": "npawar", "createdAt": "2020-06-22T17:07:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MTUwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MTYxNA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443151614", "bodyText": "Same comment as before", "author": "mcvsubbu", "createdAt": "2020-06-20T18:46:36Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManager.java", "diffHunk": "@@ -1185,12 +1185,12 @@ public LLRealtimeSegmentDataManager(RealtimeSegmentZKMetadata segmentZKMetadata,\n             .setConsumerDir(consumerDir);\n \n     // Create message decoder\n-    _messageDecoder =\n-        StreamDecoderProvider.create(_partitionLevelStreamConfig, SchemaUtils.extractSourceFields(_schema));\n+    _messageDecoder = StreamDecoderProvider\n+        .create(_partitionLevelStreamConfig, IngestionUtils.getFieldsForRecordExtractor(_tableConfig, _schema));", "originalCommit": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MjY5MA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443152690", "bodyText": "Consider making two methods below public, for readability.\ngetFieldsToFilterOn()\ngetFieldsToExtract()\nOr, keep one in the schema and the other here, but that may lead callers to ignore this one.", "author": "mcvsubbu", "createdAt": "2020-06-20T19:03:24Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import com.google.common.collect.Sets;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Utility methods for extracting source and destination fields from ingestion configs\n+ */\n+public class IngestionUtils {\n+\n+  /**\n+   * Extracts all fields required by the {@link org.apache.pinot.spi.data.readers.RecordExtractor} from the given TableConfig and Schema\n+   */\n+  public static Set<String> getFieldsForRecordExtractor(TableConfig tableConfig, Schema schema) {", "originalCommit": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNTk0Mw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443705943", "bodyText": "Renamed them. Also separated out the call to collect source fields on a differnet line, for readability.", "author": "npawar", "createdAt": "2020-06-22T17:08:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MjY5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MjczNQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443152735", "bodyText": "Spark/Hadoop jobs that depend on this method may break. Consider deprecating it in stead of removing it. Or, atleast add a backward incompat", "author": "mcvsubbu", "createdAt": "2020-06-20T19:04:10Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/SchemaUtils.java", "diffHunk": "@@ -41,28 +39,6 @@\n \n   private static final Logger LOGGER = LoggerFactory.getLogger(SchemaUtils.class);\n \n-  /**\n-   * Extracts the source fields and destination fields from the schema\n-   * For field specs with a transform expression defined, use the arguments provided to the function\n-   * By default, add the field spec name\n-   *\n-   * TODO: for now, we assume that arguments to transform function are in the source i.e. there's no columns which are derived from transformed columns\n-   */\n-  public static Set<String> extractSourceFields(Schema schema) {", "originalCommit": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNjE0MA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443706140", "bodyText": "Added backward incompat label, and added to release notes section", "author": "npawar", "createdAt": "2020-06-22T17:08:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MjczNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MzU1NA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443153554", "bodyText": "Shouldn't this be a list of filter functions applied in sequence specified? How do we indicate filter like:\n\nSample x% of the records\nfilter out those with age > 40\n\nOr,\n\nFilter out those with age > 40\nSample x% of these records.", "author": "mcvsubbu", "createdAt": "2020-06-20T19:16:53Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/config/table/ingestion/FilterConfig.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.config.table.ingestion;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonPropertyDescription;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.config.BaseJsonConfig;\n+\n+\n+/**\n+ * Configs related to filtering records during ingestion\n+ */\n+public class FilterConfig extends BaseJsonConfig {\n+\n+  @JsonPropertyDescription(\"Filter function string. Filter out records during ingestion, if this evaluates to true\")\n+  private final String _filterFunction;", "originalCommit": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwNjYxMQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443706611", "bodyText": "For now, the sampling is not supported. We could add a \"samplePercent\" into the FilterConfigs to go along with \"filterFunction\". I'm not sure if sampling should be put into the filterFunction. A separate config would be better", "author": "npawar", "createdAt": "2020-06-22T17:09:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MzU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgyNzg3Nw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443827877", "bodyText": "Can the sample percent be a function?\n\"filterFunction\": \"samplePercent() < 40\"\nBasically an inbuilt function with no arguments.", "author": "mcvsubbu", "createdAt": "2020-06-22T21:09:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MzU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQyODkyMw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444428923", "bodyText": "If our transform function evaluator supported this expression, we could support this. But it only allows function calls. To support this, I believe we would need something like\nfilterFunction: \"samplePercent(40)\"", "author": "npawar", "createdAt": "2020-06-23T18:37:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MzU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0NzkwOQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444547909", "bodyText": "we can add it later, just wanted to know what the interface would look like if we added a function. So, in this case, the samplePercent(n) should return a boolean?", "author": "mcvsubbu", "createdAt": "2020-06-23T22:42:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MzU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1MTk5OA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444551998", "bodyText": "that's right. final return value should be a boolean.\ncould also be isLessThan(samplePercent(), 40) which maps closer to your example. We probably would be adding a lot of such basic inbuilt functions soon anyway.", "author": "npawar", "createdAt": "2020-06-23T22:54:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MzU1NA=="}], "type": "inlineReview"}, {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc", "url": "https://github.com/apache/pinot/commit/4270fc669e0134d0bd1610304849e86cbf779dfc", "message": "Review comments", "committedDate": "2020-06-22T16:57:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgzMTc4Ng==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443831786", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              @JsonPropertyDescription(value = \"Config related to table ingestion\")\n          \n          \n            \n              @JsonPropertyDescription(value = \"Config related to ingesting data into the table\")\n          \n      \n    \n    \n  \n\nShould we consider moving append frequency into this?", "author": "mcvsubbu", "createdAt": "2020-06-22T21:17:44Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/config/table/TableConfig.java", "diffHunk": "@@ -79,6 +80,9 @@\n   @JsonPropertyDescription(value = \"upsert related config\")\n   private UpsertConfig _upsertConfig;\n \n+  @JsonPropertyDescription(value = \"Config related to table ingestion\")", "originalCommit": "4270fc669e0134d0bd1610304849e86cbf779dfc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQyOTQ5MQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444429491", "bodyText": "Yes that's a good one to go into this config", "author": "npawar", "createdAt": "2020-06-23T18:38:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgzMTc4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0MzYzMQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444543631", "bodyText": "Noted in the design doc extensions section, where more such are listed", "author": "npawar", "createdAt": "2020-06-23T22:29:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgzMTc4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgzMzQ3Ng==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443833476", "bodyText": "I would suggest renaming these as \"$PINOT_INTERNAL_MULTIPLE_RECORDS_KEY$\" and \"$PINOT_INTERNAL_SHOULD_INGEST_ROW$\". Of course, this will mean that the decoders that put in the existing MULTIPLE_RECORDS_KEY should be handled right (if we released this in 0.4.0 without documentation). I don't see any documentation for it in our docs. Let me know if I am not looking at the right place.", "author": "mcvsubbu", "createdAt": "2020-06-22T21:21:25Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/GenericRow.java", "diffHunk": "@@ -49,7 +49,17 @@\n  */\n public class GenericRow {\n \n+  /**\n+   * This key is used by a Decoder/RecordReader to handle 1 record to many records flattening.\n+   * If a Decoder/RecordReader produces multiple GenericRows from the given record, they must be put into the destination GenericRow as a List<GenericRow> with this key\n+   * The segment generation drivers handle this key as a special case and process the multiple records\n+   */\n   public static final String MULTIPLE_RECORDS_KEY = \"$MULTIPLE_RECORDS_KEY$\";\n+  /**\n+   * This key is used by the FilterTransformer to handle filtering out of records during ingestion\n+   * The FilterTransformer puts this key into the GenericRow with value true, if the record matches the filtering out criteria, based on FilterConfig\n+   */\n+  public static final String FILTER_RECORD_KEY = \"$FILTER_RECORD_KEY$\";", "originalCommit": "4270fc669e0134d0bd1610304849e86cbf779dfc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0NDQ3OQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444544479", "bodyText": "Multiple records key feature didn't go into the release. It has been documented here: https://docs.pinot.apache.org/developers/advanced/ingestion-level-transformations#one-record-into-many\nRenamed to $SKIP_RECORDS_KEY$. Also based on Jackie's comment, will avoid making it long, so multiple key remains $MULTIPLE_RECORDS_KEY$", "author": "npawar", "createdAt": "2020-06-23T22:31:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgzMzQ3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0Mzg1OA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444443858", "bodyText": "(nit) Make it final", "author": "Jackie-Jiang", "createdAt": "2020-06-23T19:04:00Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/FilterTransformer.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.recordtransformer;\n+\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Based on filter config, decide whether to skip or allow this record.\n+ * If record should be skipped, puts a special key in the record.\n+ */\n+public class FilterTransformer implements RecordTransformer {\n+\n+  private FunctionEvaluator _evaluator = null;", "originalCommit": "4270fc669e0134d0bd1610304849e86cbf779dfc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NTczNw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444445737", "bodyText": "(nit) Can we put table config in front of schema for consistency?", "author": "Jackie-Jiang", "createdAt": "2020-06-23T19:07:10Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/StatsCollectorConfig.java", "diffHunk": "@@ -35,16 +36,19 @@\n public class StatsCollectorConfig {\n \n   private final Schema _schema;\n+  private final TableConfig _tableConfig;\n   private final SegmentPartitionConfig _segmentPartitionConfig;\n \n   /**\n    * Constructor for the class.\n    * @param schema Data schema\n    * @param segmentPartitionConfig Segment partitioning config\n    */\n-  public StatsCollectorConfig(@Nonnull Schema schema, SegmentPartitionConfig segmentPartitionConfig) {\n+  public StatsCollectorConfig(Schema schema, TableConfig tableConfig, @Nullable SegmentPartitionConfig segmentPartitionConfig) {", "originalCommit": "4270fc669e0134d0bd1610304849e86cbf779dfc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0MTY1Nw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444541657", "bodyText": "sure , done", "author": "npawar", "createdAt": "2020-06-23T22:23:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NTczNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NjU3Nw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444446577", "bodyText": "(nit) annotate ingestionConfig as nullable", "author": "Jackie-Jiang", "createdAt": "2020-06-23T19:08:42Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import com.google.common.collect.Sets;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Utility methods for extracting source and destination fields from ingestion configs\n+ */\n+public class IngestionUtils {\n+\n+  /**\n+   * Extracts all fields required by the {@link org.apache.pinot.spi.data.readers.RecordExtractor} from the given TableConfig and Schema\n+   * Fields for ingestion come from 2 places:\n+   * 1. The schema\n+   * 2. The ingestion config in the table config. The ingestion config (e.g. filter) can have fields which are not in the schema.\n+   */\n+  public static Set<String> getFieldsForRecordExtractor(IngestionConfig ingestionConfig, Schema schema) {", "originalCommit": "4270fc669e0134d0bd1610304849e86cbf779dfc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NzgwOQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444447809", "bodyText": "Recommend passing the set into the helper method to prevent creating multiple sets.", "author": "Jackie-Jiang", "createdAt": "2020-06-23T19:11:01Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import com.google.common.collect.Sets;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Utility methods for extracting source and destination fields from ingestion configs\n+ */\n+public class IngestionUtils {\n+\n+  /**\n+   * Extracts all fields required by the {@link org.apache.pinot.spi.data.readers.RecordExtractor} from the given TableConfig and Schema\n+   * Fields for ingestion come from 2 places:\n+   * 1. The schema\n+   * 2. The ingestion config in the table config. The ingestion config (e.g. filter) can have fields which are not in the schema.\n+   */\n+  public static Set<String> getFieldsForRecordExtractor(IngestionConfig ingestionConfig, Schema schema) {\n+    Set<String> fieldsForRecordExtractor = new HashSet<>();\n+    fieldsForRecordExtractor.addAll(getFieldsFromIngestionConfig(ingestionConfig));", "originalCommit": "4270fc669e0134d0bd1610304849e86cbf779dfc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0MTczNw==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444541737", "bodyText": "done", "author": "npawar", "createdAt": "2020-06-23T22:23:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NzgwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0OTE5MA==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444449190", "bodyText": "Please rename this class to *Test or the framework cannot auto-detect this as a test", "author": "Jackie-Jiang", "createdAt": "2020-06-23T19:13:32Z", "path": "pinot-core/src/test/java/org/apache/pinot/core/segment/index/creator/SegmentGenerationWithFilterRecordsKey.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.segment.index.creator;\n+\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.core.data.readers.GenericRowRecordReader;\n+import org.apache.pinot.core.data.readers.PinotSegmentRecordReader;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.core.segment.creator.impl.SegmentIndexCreationDriverImpl;\n+import org.apache.pinot.core.segment.index.metadata.SegmentMetadataImpl;\n+import org.apache.pinot.core.segment.store.SegmentDirectory;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.utils.builder.TableConfigBuilder;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Test;\n+\n+\n+public class SegmentGenerationWithFilterRecordsKey {", "originalCommit": "4270fc669e0134d0bd1610304849e86cbf779dfc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0MTk2NQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444541965", "bodyText": "I did not know that! renamed", "author": "npawar", "createdAt": "2020-06-23T22:24:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0OTE5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MTgxOQ==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444451819", "bodyText": "Rename it to SKIP_RECORD_KEY for clarity?\n@mcvsubbu The $ already denotes the field to be internal. I wouldn't recommend making the key too long because it will add cost for the hash lookup.", "author": "Jackie-Jiang", "createdAt": "2020-06-23T19:18:39Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/GenericRow.java", "diffHunk": "@@ -49,7 +49,17 @@\n  */\n public class GenericRow {\n \n+  /**\n+   * This key is used by a Decoder/RecordReader to handle 1 record to many records flattening.\n+   * If a Decoder/RecordReader produces multiple GenericRows from the given record, they must be put into the destination GenericRow as a List<GenericRow> with this key\n+   * The segment generation drivers handle this key as a special case and process the multiple records\n+   */\n   public static final String MULTIPLE_RECORDS_KEY = \"$MULTIPLE_RECORDS_KEY$\";\n+  /**\n+   * This key is used by the FilterTransformer to handle filtering out of records during ingestion\n+   * The FilterTransformer puts this key into the GenericRow with value true, if the record matches the filtering out criteria, based on FilterConfig\n+   */\n+  public static final String FILTER_RECORD_KEY = \"$FILTER_RECORD_KEY$\";", "originalCommit": "4270fc669e0134d0bd1610304849e86cbf779dfc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0MjE4Ng==", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444542186", "bodyText": "yes SKIP_RECORD_KEY sounds better than FILTER. Renamed.", "author": "npawar", "createdAt": "2020-06-23T22:25:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MTgxOQ=="}], "type": "inlineReview"}, {"oid": "c869999cc11885e977af15a3b30991c3a0e2d518", "url": "https://github.com/apache/pinot/commit/c869999cc11885e977af15a3b30991c3a0e2d518", "message": "Review comments", "committedDate": "2020-06-23T22:22:43Z", "type": "commit"}, {"oid": "1e35d28c8d792b8515b4aa0dba444d7a5a736763", "url": "https://github.com/apache/pinot/commit/1e35d28c8d792b8515b4aa0dba444d7a5a736763", "message": "Change StatsCollectorConfig constructor params order", "committedDate": "2020-06-23T22:28:10Z", "type": "commit"}]}