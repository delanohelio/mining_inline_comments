{"pr_number": 5681, "pr_title": "TransformConfig in IngestionConfig for ingestion transformations", "pr_createdAt": "2020-07-10T08:34:57Z", "pr_url": "https://github.com/apache/pinot/pull/5681", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0MTYwMg==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453841602", "bodyText": "(nit) Let's put tableConfig in front of schema", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:19:22Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "diffHunk": "@@ -36,12 +38,19 @@\n \n   private final Map<String, FunctionEvaluator> _expressionEvaluators = new HashMap<>();\n \n-  public ExpressionTransformer(Schema schema) {\n+  public ExpressionTransformer(Schema schema, TableConfig tableConfig) {", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NDY2OQ==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453844669", "bodyText": "This will have conflict with #5667. Let's figure out the sequence of merging these 2 PRs", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:24:46Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAwOTE3Mg==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r454009172", "bodyText": "I am yet to address a few comments on mine. Will do by EOD. This one can go first and I will rebase.", "author": "siddharthteotia", "createdAt": "2020-07-13T23:38:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NDY2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NTI3Mw==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453845273", "bodyText": "Please comment on why we extract both input and output column", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:25:44Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -67,12 +70,24 @@ private static void extractFieldsFromSchema(Schema schema, Set<String> fields) {\n    * Extracts the fields needed by a RecordExtractor from given {@link IngestionConfig}\n    */\n   private static void extractFieldsFromIngestionConfig(@Nullable IngestionConfig ingestionConfig, Set<String> fields) {\n-    if (ingestionConfig != null && ingestionConfig.getFilterConfig() != null) {\n-      String filterFunction = ingestionConfig.getFilterConfig().getFilterFunction();\n-      if (filterFunction != null) {\n-        FunctionEvaluator functionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n-        if (functionEvaluator != null) {\n-          fields.addAll(functionEvaluator.getArguments());\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          FunctionEvaluator functionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          if (functionEvaluator != null) {\n+            fields.addAll(functionEvaluator.getArguments());\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          FunctionEvaluator expressionEvaluator =\n+              FunctionEvaluatorFactory.getExpressionEvaluator(transformConfig.getTransformFunction());\n+          fields.addAll(expressionEvaluator.getArguments());\n+          fields.add(transformConfig.getColumnName());", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3OTQzNQ==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453979435", "bodyText": "if transformation is already done at source, this ensures we avoid doing it again. This behavior is being carried over from previous behavior when it used to be in schema.\nAdded a comment too", "author": "npawar", "createdAt": "2020-07-13T22:26:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NTI3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NjgwMw==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453846803", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      if (transformColumns.contains(columnName)) {\n          \n          \n            \n                        throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n          \n          \n            \n                      }\n          \n          \n            \n                      transformColumns.add(columnName);\n          \n          \n            \n                      if (!transformColumns.add(columnName)) {\n          \n          \n            \n                        throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n          \n          \n            \n                      }", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:28:13Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {\n+\n+  private TableConfigUtils() {\n+\n+  }\n+\n+  /**\n+   * Validates the table config with the following rules:\n+   * <ul>\n+   *   <li>Text index column must be raw</li>\n+   *   <li>peerSegmentDownloadScheme in ValidationConfig must be http or https</li>\n+   * </ul>\n+   */\n+  public static void validate(TableConfig tableConfig) {\n+    validateFieldConfigList(tableConfig);\n+    validateValidationConfig(tableConfig);\n+    validateIngestionConfig(tableConfig.getIngestionConfig());\n+  }\n+\n+  private static void validateFieldConfigList(TableConfig tableConfig) {\n+    List<FieldConfig> fieldConfigList = tableConfig.getFieldConfigList();\n+    if (fieldConfigList != null) {\n+      List<String> noDictionaryColumns = tableConfig.getIndexingConfig().getNoDictionaryColumns();\n+      for (FieldConfig fieldConfig : fieldConfigList) {\n+        if (fieldConfig.getIndexType() == FieldConfig.IndexType.TEXT) {\n+          // For Text index column, it must be raw (no-dictionary)\n+          // NOTE: Check both encodingType and noDictionaryColumns before migrating indexing configs into field configs\n+          String column = fieldConfig.getName();\n+          if (fieldConfig.getEncodingType() != FieldConfig.EncodingType.RAW || noDictionaryColumns == null\n+              || !noDictionaryColumns.contains(column)) {\n+            throw new IllegalStateException(\n+                \"Text index column: \" + column + \" must be raw (no-dictionary) in both FieldConfig and IndexingConfig\");\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private static void validateValidationConfig(TableConfig tableConfig) {\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig != null) {\n+      if (tableConfig.getTableType() == TableType.REALTIME && validationConfig.getTimeColumnName() == null) {\n+        throw new IllegalStateException(\"Must provide time column in real-time table config\");\n+      }\n+      String peerSegmentDownloadScheme = validationConfig.getPeerSegmentDownloadScheme();\n+      if (peerSegmentDownloadScheme != null) {\n+        if (!CommonConstants.HTTP_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme) && !CommonConstants.HTTPS_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme)) {\n+          throw new IllegalStateException(\"Invalid value '\" + peerSegmentDownloadScheme + \"' for peerSegmentDownloadScheme. Must be one of http nor https\" );\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates the following:\n+   * 1. validity of filter function\n+   * 2. checks for duplicate transform configs\n+   * 3. checks for null column name or transform function in transform config\n+   * 4. validity of transform function string\n+   * 5. checks for source fields used in destination columns\n+   */\n+  private static void validateIngestionConfig(@Nullable IngestionConfig ingestionConfig) {\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          try {\n+            FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\"Invalid filter function \" + filterFunction, e);\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        Set<String> transformColumns = new HashSet<>();\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          String columnName = transformConfig.getColumnName();\n+          if (transformColumns.contains(columnName)) {\n+            throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n+          }\n+          transformColumns.add(columnName);", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NzU5Mw==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453847593", "bodyText": "Perform null check before the set check", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:29:22Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {\n+\n+  private TableConfigUtils() {\n+\n+  }\n+\n+  /**\n+   * Validates the table config with the following rules:\n+   * <ul>\n+   *   <li>Text index column must be raw</li>\n+   *   <li>peerSegmentDownloadScheme in ValidationConfig must be http or https</li>\n+   * </ul>\n+   */\n+  public static void validate(TableConfig tableConfig) {\n+    validateFieldConfigList(tableConfig);\n+    validateValidationConfig(tableConfig);\n+    validateIngestionConfig(tableConfig.getIngestionConfig());\n+  }\n+\n+  private static void validateFieldConfigList(TableConfig tableConfig) {\n+    List<FieldConfig> fieldConfigList = tableConfig.getFieldConfigList();\n+    if (fieldConfigList != null) {\n+      List<String> noDictionaryColumns = tableConfig.getIndexingConfig().getNoDictionaryColumns();\n+      for (FieldConfig fieldConfig : fieldConfigList) {\n+        if (fieldConfig.getIndexType() == FieldConfig.IndexType.TEXT) {\n+          // For Text index column, it must be raw (no-dictionary)\n+          // NOTE: Check both encodingType and noDictionaryColumns before migrating indexing configs into field configs\n+          String column = fieldConfig.getName();\n+          if (fieldConfig.getEncodingType() != FieldConfig.EncodingType.RAW || noDictionaryColumns == null\n+              || !noDictionaryColumns.contains(column)) {\n+            throw new IllegalStateException(\n+                \"Text index column: \" + column + \" must be raw (no-dictionary) in both FieldConfig and IndexingConfig\");\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private static void validateValidationConfig(TableConfig tableConfig) {\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig != null) {\n+      if (tableConfig.getTableType() == TableType.REALTIME && validationConfig.getTimeColumnName() == null) {\n+        throw new IllegalStateException(\"Must provide time column in real-time table config\");\n+      }\n+      String peerSegmentDownloadScheme = validationConfig.getPeerSegmentDownloadScheme();\n+      if (peerSegmentDownloadScheme != null) {\n+        if (!CommonConstants.HTTP_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme) && !CommonConstants.HTTPS_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme)) {\n+          throw new IllegalStateException(\"Invalid value '\" + peerSegmentDownloadScheme + \"' for peerSegmentDownloadScheme. Must be one of http nor https\" );\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates the following:\n+   * 1. validity of filter function\n+   * 2. checks for duplicate transform configs\n+   * 3. checks for null column name or transform function in transform config\n+   * 4. validity of transform function string\n+   * 5. checks for source fields used in destination columns\n+   */\n+  private static void validateIngestionConfig(@Nullable IngestionConfig ingestionConfig) {\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          try {\n+            FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\"Invalid filter function \" + filterFunction, e);\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        Set<String> transformColumns = new HashSet<>();\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          String columnName = transformConfig.getColumnName();\n+          if (transformColumns.contains(columnName)) {\n+            throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n+          }\n+          transformColumns.add(columnName);\n+          String transformFunction = transformConfig.getTransformFunction();\n+          if (columnName == null || transformFunction == null) {", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0ODkzMQ==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453848931", "bodyText": "Should we check that arguments are not contained in the transformColumns? We do not support chained transforms currently", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:31:32Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {\n+\n+  private TableConfigUtils() {\n+\n+  }\n+\n+  /**\n+   * Validates the table config with the following rules:\n+   * <ul>\n+   *   <li>Text index column must be raw</li>\n+   *   <li>peerSegmentDownloadScheme in ValidationConfig must be http or https</li>\n+   * </ul>\n+   */\n+  public static void validate(TableConfig tableConfig) {\n+    validateFieldConfigList(tableConfig);\n+    validateValidationConfig(tableConfig);\n+    validateIngestionConfig(tableConfig.getIngestionConfig());\n+  }\n+\n+  private static void validateFieldConfigList(TableConfig tableConfig) {\n+    List<FieldConfig> fieldConfigList = tableConfig.getFieldConfigList();\n+    if (fieldConfigList != null) {\n+      List<String> noDictionaryColumns = tableConfig.getIndexingConfig().getNoDictionaryColumns();\n+      for (FieldConfig fieldConfig : fieldConfigList) {\n+        if (fieldConfig.getIndexType() == FieldConfig.IndexType.TEXT) {\n+          // For Text index column, it must be raw (no-dictionary)\n+          // NOTE: Check both encodingType and noDictionaryColumns before migrating indexing configs into field configs\n+          String column = fieldConfig.getName();\n+          if (fieldConfig.getEncodingType() != FieldConfig.EncodingType.RAW || noDictionaryColumns == null\n+              || !noDictionaryColumns.contains(column)) {\n+            throw new IllegalStateException(\n+                \"Text index column: \" + column + \" must be raw (no-dictionary) in both FieldConfig and IndexingConfig\");\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private static void validateValidationConfig(TableConfig tableConfig) {\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig != null) {\n+      if (tableConfig.getTableType() == TableType.REALTIME && validationConfig.getTimeColumnName() == null) {\n+        throw new IllegalStateException(\"Must provide time column in real-time table config\");\n+      }\n+      String peerSegmentDownloadScheme = validationConfig.getPeerSegmentDownloadScheme();\n+      if (peerSegmentDownloadScheme != null) {\n+        if (!CommonConstants.HTTP_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme) && !CommonConstants.HTTPS_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme)) {\n+          throw new IllegalStateException(\"Invalid value '\" + peerSegmentDownloadScheme + \"' for peerSegmentDownloadScheme. Must be one of http nor https\" );\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates the following:\n+   * 1. validity of filter function\n+   * 2. checks for duplicate transform configs\n+   * 3. checks for null column name or transform function in transform config\n+   * 4. validity of transform function string\n+   * 5. checks for source fields used in destination columns\n+   */\n+  private static void validateIngestionConfig(@Nullable IngestionConfig ingestionConfig) {\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          try {\n+            FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\"Invalid filter function \" + filterFunction, e);\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        Set<String> transformColumns = new HashSet<>();\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          String columnName = transformConfig.getColumnName();\n+          if (transformColumns.contains(columnName)) {\n+            throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n+          }\n+          transformColumns.add(columnName);\n+          String transformFunction = transformConfig.getTransformFunction();\n+          if (columnName == null || transformFunction == null) {\n+            throw new IllegalStateException(\"columnName/transformFunction cannot be null in TransformConfig \" + transformConfig);\n+          }\n+          FunctionEvaluator expressionEvaluator;\n+          try {\n+            expressionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(transformFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\n+                \"Invalid transform function '\" + transformFunction + \"' for column '\" + columnName + \"'\");\n+          }\n+          List<String> arguments = expressionEvaluator.getArguments();", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3OTg5Ng==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453979896", "bodyText": "yes sounds good. added", "author": "npawar", "createdAt": "2020-07-13T22:27:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0ODkzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1MjQxOA==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453852418", "bodyText": "Remove this class", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:37:24Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/Temp.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+\n+/**\n+ * Hybrid cluster integration test that uses one of the DateTimeFieldSpec as primary time column\n+ */\n+public class Temp extends BaseClusterIntegrationTest {", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDU2OQ==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453854569", "bodyText": "Should we keep a test for transform in schema to ensure this change is backward-compatible? We can remove the test when we remove the schema transform support.", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:41:09Z", "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "diffHunk": "@@ -43,14 +43,28 @@\n public class ExpressionTransformerTest {\n \n   @Test\n-  public void testGroovyExpressionTransformer()\n-      throws IOException {\n-    URL resource = AbstractRecordExtractorTest.class.getClassLoader()", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MTE1Mg==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453981152", "bodyText": "i've split this test into 2 - testTransformFunctionsInSchema testTransformFunctionsInTable. They are both in the same file", "author": "npawar", "createdAt": "2020-07-13T22:29:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDU2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NjMxMQ==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453856311", "bodyText": "(nit) remove empty line", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:44:20Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }\n+\n+  @Override\n+  protected String getTimeColumnName() {\n+    return TIME_COLUMN_NAME;\n+  }\n+\n+  @Override\n+  protected long getCountStarResult() {\n+    return 22300;\n+  }\n+\n+  @Override\n+  protected boolean useLlc() {\n+    return true;\n+  }\n+\n+  @Override\n+  protected IngestionConfig getIngestionConfig() {\n+    FilterConfig filterConfig = new FilterConfig(\"Groovy({AirlineID == 19393 || ArrDelayMinutes <= 5 }, AirlineID, ArrDelayMinutes)\");\n+    List<TransformConfig> transformConfigs = new ArrayList<>();\n+    transformConfigs.add(new TransformConfig(\"AmPm\", \"Groovy({DepTime < 1200 ? \\\"AM\\\": \\\"PM\\\"}, DepTime)\"));\n+    transformConfigs.add(new TransformConfig(\"millisSinceEpoch\", \"fromEpochDays(DaysSinceEpoch)\"));\n+    transformConfigs.add(new TransformConfig(\"lowerCaseDestCityName\", \"lower(DestCityName)\"));\n+    return new IngestionConfig(filterConfig, transformConfigs);\n+  }\n+\n+  @BeforeClass\n+  public void setUp()\n+      throws Exception {\n+    TestUtils.ensureDirectoriesExistAndEmpty(_tempDir, _segmentDir, _tarDir);\n+\n+    // Start the Pinot cluster\n+    startZk();\n+    startController();\n+    startBroker();\n+    startServer();\n+    startKafka();\n+\n+    // Create and upload the schema and table config\n+    Schema schema = createSchema();\n+    addSchema(schema);\n+    TableConfig tableConfig = createOfflineTableConfig();\n+    addTableConfig(tableConfig);\n+\n+    // Unpack the Avro files\n+    List<File> avroFiles = unpackAvroData(_tempDir);\n+\n+    // Create and upload segments\n+    ClusterIntegrationTestUtils.buildSegmentsFromAvro(avroFiles.subList(0, avroFiles.size() -1), tableConfig, schema, 0, _segmentDir, _tarDir);\n+    uploadSegments(getTableName(), _tarDir);\n+\n+    List<File> realtimeAvroFile = Lists.newArrayList(avroFiles.get(avroFiles.size() - 1));\n+    addTableConfig(createRealtimeTableConfig(realtimeAvroFile.get(0)));\n+    pushAvroIntoKafka(realtimeAvroFile);\n+\n+    // Wait for all documents loaded\n+    waitForAllDocsLoaded(600_000L);\n+  }\n+\n+  @Test\n+  public void testQueries()\n+      throws Exception {\n+    // Select column created with transform function\n+    String sqlQuery = \"Select millisSinceEpoch from \" + DEFAULT_TABLE_NAME;\n+    JsonNode response = postSqlQuery(sqlQuery);\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(0).asText(), \"millisSinceEpoch\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(0).asText(), \"LONG\");\n+\n+    // Select column created with transform function\n+    sqlQuery = \"Select AmPm, DepTime from \" + DEFAULT_TABLE_NAME;\n+    response = postSqlQuery(sqlQuery);\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(0).asText(), \"AmPm\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(1).asText(), \"DepTime\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(0).asText(), \"STRING\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(1).asText(), \"INT\");\n+    for (int i = 0; i < response.get(\"resultTable\").get(\"rows\").size(); i++) {\n+      String amPm = response.get(\"resultTable\").get(\"rows\").get(i).get(0).asText();\n+      int depTime = response.get(\"resultTable\").get(\"rows\").get(i).get(1).asInt();\n+      Assert.assertEquals(amPm, (depTime < 1200) ? \"AM\" : \"PM\");\n+    }\n+\n+    // Select column created with transform function - offline table\n+    sqlQuery = \"Select AmPm, DepTime from \" + DEFAULT_TABLE_NAME + \"_OFFLINE\";\n+    response = postSqlQuery(sqlQuery);\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(0).asText(), \"AmPm\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(1).asText(), \"DepTime\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(0).asText(), \"STRING\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(1).asText(), \"INT\");\n+    for (int i = 0; i < response.get(\"resultTable\").get(\"rows\").size(); i++) {\n+      String amPm = response.get(\"resultTable\").get(\"rows\").get(i).get(0).asText();\n+      int depTime = response.get(\"resultTable\").get(\"rows\").get(i).get(1).asInt();\n+      Assert.assertEquals(amPm, (depTime < 1200) ? \"AM\" : \"PM\");\n+    }\n+\n+    // Select column created with transform - realtime table\n+    sqlQuery = \"Select AmPm, DepTime from \" + DEFAULT_TABLE_NAME + \"_REALTIME\";\n+    response = postSqlQuery(sqlQuery);\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(0).asText(), \"AmPm\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(1).asText(), \"DepTime\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(0).asText(), \"STRING\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(1).asText(), \"INT\");\n+    for (int i = 0; i < response.get(\"resultTable\").get(\"rows\").size(); i++) {\n+      String amPm = response.get(\"resultTable\").get(\"rows\").get(i).get(0).asText();\n+      int depTime = response.get(\"resultTable\").get(\"rows\").get(i).get(1).asInt();\n+      Assert.assertEquals(amPm, (depTime < 1200) ? \"AM\" : \"PM\");\n+    }\n+\n+    // Check there's no values that should've been filtered\n+    sqlQuery = \"Select * from \" + DEFAULT_TABLE_NAME\n+        + \"  where AirlineID = 19393 or ArrDelayMinutes <= 5\";\n+    response = postSqlQuery(sqlQuery);\n+    Assert.assertEquals(response.get(\"resultTable\").get(\"rows\").size(), 0);\n+\n+    // Check there's no values that should've been filtered - realtime table\n+    sqlQuery = \"Select * from \" + DEFAULT_TABLE_NAME + \"_REALTIME\"\n+        + \"  where AirlineID = 19393 or ArrDelayMinutes <= 5\";\n+    response = postSqlQuery(sqlQuery);\n+    Assert.assertEquals(response.get(\"resultTable\").get(\"rows\").size(), 0);\n+\n+    // Check there's no values that should've been filtered - offline table\n+    sqlQuery = \"Select * from \" + DEFAULT_TABLE_NAME + \"_OFFLINE\"\n+        + \"  where AirlineID = 19393 or ArrDelayMinutes <= 5\";\n+    response = postSqlQuery(sqlQuery);\n+    Assert.assertEquals(response.get(\"resultTable\").get(\"rows\").size(), 0);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+      throws Exception {\n+", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1OTQ2MA==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453859460", "bodyText": "extend BaseClusterIntegrationTest instead of BaseClusterIntegrationTestSet", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:49:37Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2MDMwOQ==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453860309", "bodyText": "Make a simplified schema (only contains the columns needed for the test).\nYou can directly override createSchema()", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:51:08Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2MTI2OQ==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453861269", "bodyText": "No overlapping segments? The result won't be correct. Please use the set up  logic as in the HybridClusterIntegrationTest", "author": "Jackie-Jiang", "createdAt": "2020-07-13T18:52:48Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }\n+\n+  @Override\n+  protected String getTimeColumnName() {\n+    return TIME_COLUMN_NAME;\n+  }\n+\n+  @Override\n+  protected long getCountStarResult() {\n+    return 22300;\n+  }\n+\n+  @Override\n+  protected boolean useLlc() {\n+    return true;\n+  }\n+\n+  @Override\n+  protected IngestionConfig getIngestionConfig() {\n+    FilterConfig filterConfig = new FilterConfig(\"Groovy({AirlineID == 19393 || ArrDelayMinutes <= 5 }, AirlineID, ArrDelayMinutes)\");\n+    List<TransformConfig> transformConfigs = new ArrayList<>();\n+    transformConfigs.add(new TransformConfig(\"AmPm\", \"Groovy({DepTime < 1200 ? \\\"AM\\\": \\\"PM\\\"}, DepTime)\"));\n+    transformConfigs.add(new TransformConfig(\"millisSinceEpoch\", \"fromEpochDays(DaysSinceEpoch)\"));\n+    transformConfigs.add(new TransformConfig(\"lowerCaseDestCityName\", \"lower(DestCityName)\"));\n+    return new IngestionConfig(filterConfig, transformConfigs);\n+  }\n+\n+  @BeforeClass\n+  public void setUp()\n+      throws Exception {\n+    TestUtils.ensureDirectoriesExistAndEmpty(_tempDir, _segmentDir, _tarDir);\n+\n+    // Start the Pinot cluster\n+    startZk();\n+    startController();\n+    startBroker();\n+    startServer();\n+    startKafka();\n+\n+    // Create and upload the schema and table config\n+    Schema schema = createSchema();\n+    addSchema(schema);\n+    TableConfig tableConfig = createOfflineTableConfig();\n+    addTableConfig(tableConfig);\n+\n+    // Unpack the Avro files\n+    List<File> avroFiles = unpackAvroData(_tempDir);\n+\n+    // Create and upload segments\n+    ClusterIntegrationTestUtils.buildSegmentsFromAvro(avroFiles.subList(0, avroFiles.size() -1), tableConfig, schema, 0, _segmentDir, _tarDir);\n+    uploadSegments(getTableName(), _tarDir);\n+\n+    List<File> realtimeAvroFile = Lists.newArrayList(avroFiles.get(avroFiles.size() - 1));", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2NTcyMw==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453865723", "bodyText": "This result should be the same as select count(*) from mytable where AirlineID != 19393 AND ArrDelayMinutes > 5 within other integration test, where I got 24047.\nPlease document how this number is calculated. When we add a test, we should not run the test and directly put the result as the expected value because that won't catch the bug of the code or the test logic", "author": "Jackie-Jiang", "createdAt": "2020-07-13T19:00:37Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }\n+\n+  @Override\n+  protected String getTimeColumnName() {\n+    return TIME_COLUMN_NAME;\n+  }\n+\n+  @Override\n+  protected long getCountStarResult() {\n+    return 22300;", "originalCommit": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MjExMA==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453982110", "bodyText": "it was an effect of using different number of files as compared to Hybrid test. Changed it to be exactly like Hybrid test. Now number is 24047", "author": "npawar", "createdAt": "2020-07-13T22:30:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2NTcyMw=="}], "type": "inlineReview"}, {"oid": "9b8fb534c8a02bf23c4ff6c3aad05fd4862b0f91", "url": "https://github.com/apache/pinot/commit/9b8fb534c8a02bf23c4ff6c3aad05fd4862b0f91", "message": "TransformConfig in IngestionConfig for ingestion transformations", "committedDate": "2020-07-13T22:36:52Z", "type": "commit"}, {"oid": "951fc7065cd3486a93bcd8f8f28f53de065cf1b7", "url": "https://github.com/apache/pinot/commit/951fc7065cd3486a93bcd8f8f28f53de065cf1b7", "message": "Review comments", "committedDate": "2020-07-13T22:36:52Z", "type": "commit"}, {"oid": "f3ef701d78488ae3c9363ec4d134a0446bf15766", "url": "https://github.com/apache/pinot/commit/f3ef701d78488ae3c9363ec4d134a0446bf15766", "message": "Comment", "committedDate": "2020-07-13T22:37:22Z", "type": "commit"}, {"oid": "f3ef701d78488ae3c9363ec4d134a0446bf15766", "url": "https://github.com/apache/pinot/commit/f3ef701d78488ae3c9363ec4d134a0446bf15766", "message": "Comment", "committedDate": "2020-07-13T22:37:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjEyNA==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453992124", "bodyText": "Remove this line", "author": "Jackie-Jiang", "createdAt": "2020-07-13T22:52:42Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Tests ingestion configs on a hybrid table\n+ */\n+public class IngestionConfigHybridIntegrationTest extends BaseClusterIntegrationTest {\n+  private static final int NUM_OFFLINE_SEGMENTS = 8;\n+  private static final int NUM_REALTIME_SEGMENTS = 6;\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";", "originalCommit": "f3ef701d78488ae3c9363ec4d134a0446bf15766", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjE3OA==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453992178", "bodyText": "Remove", "author": "Jackie-Jiang", "createdAt": "2020-07-13T22:52:52Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Tests ingestion configs on a hybrid table\n+ */\n+public class IngestionConfigHybridIntegrationTest extends BaseClusterIntegrationTest {\n+  private static final int NUM_OFFLINE_SEGMENTS = 8;\n+  private static final int NUM_REALTIME_SEGMENTS = 6;\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+  private static final long FILTERED_COUNT_STAR_RESULT = 24047L;\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }", "originalCommit": "f3ef701d78488ae3c9363ec4d134a0446bf15766", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5Mjc4Ng==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453992786", "bodyText": "Let's document how this value is calculated (query result of SELECT COUNT(*) FROM mytable WHERE AirlineID != 19393 AND ArrDelayMinutes > 5 on unfiltered data)", "author": "Jackie-Jiang", "createdAt": "2020-07-13T22:54:37Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Tests ingestion configs on a hybrid table\n+ */\n+public class IngestionConfigHybridIntegrationTest extends BaseClusterIntegrationTest {\n+  private static final int NUM_OFFLINE_SEGMENTS = 8;\n+  private static final int NUM_REALTIME_SEGMENTS = 6;\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+  private static final long FILTERED_COUNT_STAR_RESULT = 24047L;", "originalCommit": "f3ef701d78488ae3c9363ec4d134a0446bf15766", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NDI0Mg==", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453994242", "bodyText": "(nit)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public void testTransformConfigsFromTable() {\n          \n          \n            \n              public void testTransformConfigsFromTableConfig() {", "author": "Jackie-Jiang", "createdAt": "2020-07-13T22:58:52Z", "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "diffHunk": "@@ -43,14 +43,28 @@\n public class ExpressionTransformerTest {\n \n   @Test\n-  public void testGroovyExpressionTransformer()\n-      throws IOException {\n-    URL resource = AbstractRecordExtractorTest.class.getClassLoader()\n-        .getResource(\"data/expression_transformer/groovy_expression_transformer.json\");\n-    File schemaFile = new File(resource.getFile());\n-    Schema pinotSchema = Schema.fromFile(schemaFile);\n-\n-    ExpressionTransformer expressionTransformer = new ExpressionTransformer(pinotSchema);\n+  public void testTransformConfigsFromTable() {", "originalCommit": "f3ef701d78488ae3c9363ec4d134a0446bf15766", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "78c219dbaad76dbd23af98d575def265dababad1", "url": "https://github.com/apache/pinot/commit/78c219dbaad76dbd23af98d575def265dababad1", "message": "Review comments", "committedDate": "2020-07-13T23:18:12Z", "type": "commit"}]}