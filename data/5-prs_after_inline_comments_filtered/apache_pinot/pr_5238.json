{"pr_number": 5238, "pr_title": "Evaluate schema transform expressions during ingestion", "pr_createdAt": "2020-04-10T20:32:51Z", "pr_url": "https://github.com/apache/pinot/pull/5238", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjk3MDkxOA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r406970918", "bodyText": "include column name in the log", "author": "mcvsubbu", "createdAt": "2020-04-10T22:37:49Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    if (!fieldSpec.isVirtualColumn()) {\n+\n+      String columnName = fieldSpec.getName();\n+      String transformExpression = fieldSpec.getTransformFunction();\n+      if (transformExpression != null) {\n+\n+        // if transform function expression present, use it to generate function evaluator\n+        try {\n+          expressionEvaluator = getExpressionEvaluator(transformExpression);\n+        } catch (Exception e) {\n+          LOGGER.error(\"Caught exception while constructing expression evaluator for: {}, skipping\", transformExpression, e);", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2MzM3MQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407663371", "bodyText": "done", "author": "npawar", "createdAt": "2020-04-13T19:16:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjk3MDkxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNTYwNQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407235605", "bodyText": "userId --> user_id we might make columns case insensitive at some point and this test case should still be valid.", "author": "kishoreg", "createdAt": "2020-04-12T18:29:06Z", "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.recordtransformer;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.AbstractRecordExtractorTest;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+\n+/**\n+ * Tests the evaluation of transform expressions by the ExpressionTransformer\n+ */\n+public class ExpressionTransformerTest {\n+\n+  private Schema _pinotSchema;\n+\n+  @BeforeClass\n+  public void setup()\n+      throws IOException {\n+    URL resource =\n+        AbstractRecordExtractorTest.class.getClassLoader().getResource(\"data/expression_transformer/groovy_expression_transformer.json\");\n+    File schemaFile = new File(resource.getFile());\n+    _pinotSchema = Schema.fromFile(schemaFile);\n+  }\n+\n+  @Test\n+  public void testGroovyExpressionTransformer() {\n+    ExpressionTransformer expressionTransformer = new ExpressionTransformer(_pinotSchema);\n+    DataTypeTransformer dataTypeTransformer = new DataTypeTransformer(_pinotSchema);\n+\n+    // test functions from schema\n+    GenericRow genericRow = new GenericRow();\n+    genericRow.putValue(\"userID\", 1L);\n+    genericRow.putValue(\"firstName\", \"John\");\n+    genericRow.putValue(\"lastName\", \"Denver\");\n+    genericRow.putValue(\"bids\", Arrays.asList(10, 20));\n+    HashMap<String, String> map1 = new HashMap<>(); // keys in Map from avro are always in STRING\n+    map1.put(\"30\", \"foo\");\n+    map1.put(\"200\", \"bar\");\n+    genericRow.putValue(\"map1\", map1);\n+    HashMap<String, Integer> map2 = new HashMap<>();\n+    map2.put(\"k1\", 10);\n+    map2.put(\"k2\", 20);\n+    genericRow.putValue(\"map2\", map2);\n+    genericRow.putValue(\"cost\", 1000.0);\n+    genericRow.putValue(\"timestamp\", 1574000000000L);\n+\n+    // expression transformer\n+    expressionTransformer.transform(genericRow);\n+\n+    // extract userId\n+    Assert.assertEquals(genericRow.getValue(\"userId\"), 1L);", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjAyOQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407236029", "bodyText": "should this be part of SchemaUtils?", "author": "kishoreg", "createdAt": "2020-04-12T18:33:00Z", "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroRecordReader.java", "diffHunk": "@@ -24,12 +24,11 @@\n import javax.annotation.Nullable;\n import org.apache.avro.file.DataFileStream;\n import org.apache.avro.generic.GenericRecord;\n-import org.apache.pinot.spi.data.FieldSpec;\n import org.apache.pinot.spi.data.Schema;\n import org.apache.pinot.spi.data.readers.GenericRow;\n import org.apache.pinot.spi.data.readers.RecordReader;\n import org.apache.pinot.spi.data.readers.RecordReaderConfig;\n-import org.apache.pinot.spi.data.readers.RecordReaderUtils;\n+import org.apache.pinot.spi.data.function.evaluators.SourceFieldNameExtractor;", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY0NzMzNQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407647335", "bodyText": "SchemaUtils is in pinot-common, which is not accessible to most of the places this is needed", "author": "npawar", "createdAt": "2020-04-13T18:46:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjAyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMDAzOQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407800039", "bodyText": "You may have another SchemaUtils in pinot-spi. I don't have preference for the exact name, but recommend making it ***Utils as it is a util class.", "author": "Jackie-Jiang", "createdAt": "2020-04-14T00:44:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjAyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgzNDg4OA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407834888", "bodyText": "Done. Created SchemaFieldExtractorUtils in pinot-spi under utils", "author": "npawar", "createdAt": "2020-04-14T02:51:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjAyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjI1Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407236253", "bodyText": "is this specific to Avro?", "author": "kishoreg", "createdAt": "2020-04-12T18:34:44Z", "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroUtils.java", "diffHunk": "@@ -368,6 +341,21 @@ public static Object handleMultiValue(@Nullable Collection values) {\n     for (Object value : values) {\n       list.add(handleSingleValue(value));\n     }\n-    return list;\n+    return RecordReaderUtils.convertMultiValue(list);\n+  }\n+\n+  /**\n+   * Converts the values withing the map to single-valued values\n+   */\n+  public static Object handleMap(@Nullable Map map) {", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY0Nzg2OA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407647868", "bodyText": "Right now, yes. It is designed based off what was done in AvroUtils to handle the map", "author": "npawar", "createdAt": "2020-04-13T18:47:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjI1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjg5Ng==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407236896", "bodyText": "will be nice to get perf on this and possibly optimize it by caching the compiled script. see this https://www.tothenew.com/blog/compile-groovyscript-at-runtime-allow-caching-of-compiled-source-to-avoid-recompilation-at-runtime-using-groovyclassloader/.\nWe can do this in another PR", "author": "kishoreg", "createdAt": "2020-04-12T18:41:03Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN = Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);\n+      } else {\n+        _arguments = Collections.emptyList();\n+      }\n+    }\n+  }\n+\n+  public static String getGroovyExpressionPrefix() {\n+    return GROOVY_EXPRESSION_PREFIX;\n+  }\n+\n+  @Override\n+  public List<String> getArguments() {\n+    return _arguments;\n+  }\n+\n+  @Override\n+  public Object evaluate(GenericRow genericRow) {\n+    Map<String, Object> params = new HashMap<>();\n+    for (String argument : _arguments) {\n+      params.put(argument, genericRow.getValue(argument));\n+    }\n+    if (params.containsValue(null)) { // TODO: disallow evaluation of any of the params is null? Or give complete control to function?\n+      return null;\n+    } else {\n+      Binding binding = new Binding();\n+      for (String argument : _arguments) {\n+        binding.setVariable(argument, params.get(argument));\n+      }\n+      GroovyShell shell = new GroovyShell(binding);", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NTcwMA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407685700", "bodyText": "+1", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:58:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjg5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgzNTAxNQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407835015", "bodyText": "Will do this in the immediate next step", "author": "npawar", "createdAt": "2020-04-14T02:51:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjg5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjkzNg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407236936", "bodyText": "we can merge this into Schema utils?", "author": "kishoreg", "createdAt": "2020-04-12T18:41:34Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/SourceFieldNameExtractor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.collect.Lists;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SourceFieldNameExtractor {", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzAwMg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407237002", "bodyText": "is there a better place for this constant?", "author": "kishoreg", "createdAt": "2020-04-12T18:42:14Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/SourceFieldNameExtractor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.collect.Lists;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SourceFieldNameExtractor {\n+  public static final String MAP_KEY_COLUMN_SUFFIX = \"__KEYS\";", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzcyOTU3MA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407729570", "bodyText": "I felt this was the best place, as this is information needed to deduce the source column names", "author": "npawar", "createdAt": "2020-04-13T21:22:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzExOA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407237118", "bodyText": "Nice to extractor interface decoupled from Schema", "author": "kishoreg", "createdAt": "2020-04-12T18:43:22Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordExtractor.java", "diffHunk": "@@ -18,16 +18,28 @@\n  */\n package org.apache.pinot.spi.data.readers;\n \n-import org.apache.pinot.spi.data.Schema;\n+import java.util.List;\n \n+\n+/**\n+ * Extracts fields from input records\n+ * @param <T> The format of the input record\n+ */\n public interface RecordExtractor<T> {\n+\n+  /**\n+   * Initialize the record extractor with its config\n+   */\n+  default void init(RecordExtractorConfig recordExtractorConfig) {\n+  }\n+\n   /**\n-   * TODO Add text to this javadoc\n+   * Extracts fields as listed in the sourceFieldNames from the given input record and sets them into the GenericRow\n    *\n-   * @param schema\n-   * @param from\n-   * @param to\n-   * @return\n+   * @param sourceFieldNames List of field names to extract from the provided input record\n+   * @param from The input record\n+   * @param to The output GenericRow\n+   * @return The output GenericRow\n    */\n-  GenericRow extract(Schema schema, T from, GenericRow to);\n+  GenericRow extract(List<String> sourceFieldNames, T from, GenericRow to);", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3ODA5MA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407678090", "bodyText": "I would recommend putting source fields into the init and rename it to fields for simplicity:\n  void init(List<String> fields, @Nullable RecordExtractorConfig recordExtractorConfig);", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:44:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzExOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwNjAzOA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407806038", "bodyText": "This comment is not addressed", "author": "Jackie-Jiang", "createdAt": "2020-04-14T01:05:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzExOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgzNTEwNQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407835105", "bodyText": "Done", "author": "npawar", "createdAt": "2020-04-14T02:52:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzExOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY1ODA1NA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407658054", "bodyText": "(nit) revert?", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:06:11Z", "path": "pinot-common/src/test/java/org/apache/pinot/common/utils/time/TimeConverterTest.java", "diffHunk": "@@ -21,6 +21,7 @@\n import java.util.concurrent.TimeUnit;\n import org.apache.pinot.spi.data.FieldSpec;\n import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.TimeConverter;", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2MjY0Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407662643", "bodyText": "Should be okay as we only extract the needed columns, then we can reuse the record", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:14:56Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/CompositeTransformer.java", "diffHunk": "@@ -48,9 +47,11 @@\n    * </ul>\n    */\n   public static CompositeTransformer getDefaultTransformer(Schema schema) {\n+    // TODO: ExpressionTransformer contains record with source columns, and after transformation, the record has source + destination columns.", "originalCommit": "865922d017e139b54ab245b84e33d1a495f6f978", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzcyODQ5NA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407728494", "bodyText": "Thanks, removed the comment", "author": "npawar", "createdAt": "2020-04-13T21:20:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2MjY0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2NDc5Nw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407664797", "bodyText": "Annotate as nullable for the return value", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:18:59Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2NjMyNA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407666324", "bodyText": "(nit) private?", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:21:45Z", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/ClusterTest.java", "diffHunk": "@@ -346,8 +347,8 @@ protected void dropOfflineTable(String tableName)\n     private static final Logger LOGGER = LoggerFactory.getLogger(AvroFileSchemaKafkaAvroMessageDecoder.class);\n     public static File avroFile;\n     private org.apache.avro.Schema _avroSchema;\n-    private Schema _pinotSchema;\n-    private RecordExtractor<GenericData.Record> _recordExtractor;\n+    List<String> _sourceFieldNames;", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2OTcyMw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407669723", "bodyText": "(nit) revert?", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:28:15Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordReaderUtils.java", "diffHunk": "@@ -105,6 +136,8 @@ public static Object convert(FieldSpec fieldSpec, @Nullable Object value) {\n     }\n   }\n \n+", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3MDIyNA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407670224", "bodyText": "Annotate both value and return as nullable, same for other methods", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:29:15Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordReaderUtils.java", "diffHunk": "@@ -67,31 +63,66 @@ public static InputStream getInputStream(File dataFile)\n   }\n \n   /**\n-   * Extracts all field specs from the given schema.\n-   * <p>For time field spec:\n-   * <ul>\n-   *   <li>If incoming and outgoing time column name are the same, use incoming time field spec</li>\n-   *   <li>If incoming and outgoing time column name are different, put both of them as time field spec</li>\n-   *   <li>\n-   *     We keep both incoming and outgoing time column to handle cases where the input file contains time values that\n-   *     are already converted\n-   *   </li>\n-   * </ul>\n+   * Converts the value to a multi-values value or a single values value\n    */\n-  public static List<FieldSpec> extractFieldSpecs(Schema schema) {\n-    List<FieldSpec> fieldSpecs = new ArrayList<>();\n-    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (fieldSpec.getFieldType() == FieldSpec.FieldType.TIME) {\n-        TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n-        fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getIncomingGranularitySpec()));\n-        if (!timeFieldSpec.getOutgoingTimeColumnName().equals(timeFieldSpec.getIncomingTimeColumnName())) {\n-          fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getOutgoingGranularitySpec()));\n-        }\n-      } else {\n-        fieldSpecs.add(fieldSpec);\n+  public static Object convert(Object value) {", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3MjA3OQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407672079", "bodyText": "(nit) Several new files are lacking the empty line", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:32:42Z", "path": "pinot-spi/src/test/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluatorTest.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.testng.Assert;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+import org.testng.collections.Lists;\n+\n+\n+/**\n+ * Tests Groovy functions for transforming schema columns\n+ */\n+public class GroovyExpressionEvaluatorTest {\n+\n+  @Test(dataProvider = \"groovyFunctionEvaluationDataProvider\")\n+  public void testGroovyFunctionEvaluation(String transformFunction, List<String> arguments, GenericRow genericRow, Object expectedResult) {\n+\n+    GroovyExpressionEvaluator groovyExpressionEvaluator = new GroovyExpressionEvaluator(transformFunction);\n+    Assert.assertEquals(groovyExpressionEvaluator.getArguments(), arguments);\n+\n+    Object result = groovyExpressionEvaluator.evaluate(genericRow);\n+    Assert.assertEquals(result, expectedResult);\n+  }\n+\n+  @DataProvider(name = \"groovyFunctionEvaluationDataProvider\")\n+  public Object[][] groovyFunctionEvaluationDataProvider() {\n+\n+    List<Object[]> entries = new ArrayList<>();\n+\n+    GenericRow genericRow1 = new GenericRow();\n+    genericRow1.putValue(\"userID\", 101);\n+    entries.add(new Object[]{\"Groovy({userID}, userID)\", Lists.newArrayList(\"userID\"), genericRow1, 101});\n+\n+    GenericRow genericRow2 = new GenericRow();\n+    Map<String, Integer> map1 = new HashMap<>();\n+    map1.put(\"def\", 10);\n+    map1.put(\"xyz\", 30);\n+    map1.put(\"abc\", 40);\n+    genericRow2.putValue(\"map1\", map1);\n+    entries.add(new Object[]{\"Groovy({map1.sort()*.value}, map1)\", Lists.newArrayList(\"map1\"), genericRow2, Lists.newArrayList(40, 10, 30)});\n+\n+    GenericRow genericRow3 = new GenericRow();\n+    genericRow3.putValue(\"campaigns\", new Object[]{3, 2});\n+    entries.add(new Object[]{\"Groovy({campaigns.max{ it.toBigDecimal() }}, campaigns)\", Lists.newArrayList(\"campaigns\"), genericRow3, 3});\n+\n+    GenericRow genericRow4 = new GenericRow();\n+    genericRow4.putValue(\"millis\", \"1584040201500\");\n+    entries.add(new Object[]{\"Groovy({(long)(Long.parseLong(millis)/(1000*60*60))}, millis)\", Lists.newArrayList(\"millis\"), genericRow4, 440011L});\n+\n+    GenericRow genericRow5 = new GenericRow();\n+    genericRow5.putValue(\"firstName\", \"John\");\n+    genericRow5.putValue(\"lastName\", \"Doe\");\n+    entries.add(new Object[]{\"Groovy({firstName + ' ' + lastName}, firstName, lastName)\", Lists.newArrayList(\"firstName\", \"lastName\"), genericRow5, \"John Doe\"});\n+\n+    GenericRow genericRow6 = new GenericRow();\n+    genericRow6.putValue(\"eventType\", \"IMPRESSION\");\n+    entries.add(new Object[]{\"Groovy({eventType == 'IMPRESSION' ? 1: 0}, eventType)\", Lists.newArrayList(\"eventType\"), genericRow6, 1});\n+\n+    GenericRow genericRow7 = new GenericRow();\n+    genericRow7.putValue(\"eventType\", \"CLICK\");\n+    entries.add(new Object[]{\"Groovy({eventType == 'IMPRESSION' ? 1: 0}, eventType)\", Lists.newArrayList(\"eventType\"), genericRow7, 0});\n+\n+    return entries.toArray(new Object[entries.size()][]);\n+  }\n+\n+}", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzcyODc3NA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407728774", "bodyText": "fixed all", "author": "npawar", "createdAt": "2020-04-13T21:21:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3MjA3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3ODk5NA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407678994", "bodyText": "I don't think this logic can be shared among all the record readers. For different input format, we might need different utils for them", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:46:22Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordReaderUtils.java", "diffHunk": "@@ -67,31 +63,66 @@ public static InputStream getInputStream(File dataFile)\n   }\n \n   /**\n-   * Extracts all field specs from the given schema.\n-   * <p>For time field spec:\n-   * <ul>\n-   *   <li>If incoming and outgoing time column name are the same, use incoming time field spec</li>\n-   *   <li>If incoming and outgoing time column name are different, put both of them as time field spec</li>\n-   *   <li>\n-   *     We keep both incoming and outgoing time column to handle cases where the input file contains time values that\n-   *     are already converted\n-   *   </li>\n-   * </ul>\n+   * Converts the value to a multi-values value or a single values value\n    */\n-  public static List<FieldSpec> extractFieldSpecs(Schema schema) {\n-    List<FieldSpec> fieldSpecs = new ArrayList<>();\n-    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (fieldSpec.getFieldType() == FieldSpec.FieldType.TIME) {\n-        TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n-        fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getIncomingGranularitySpec()));\n-        if (!timeFieldSpec.getOutgoingTimeColumnName().equals(timeFieldSpec.getIncomingTimeColumnName())) {\n-          fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getOutgoingGranularitySpec()));\n-        }\n-      } else {\n-        fieldSpecs.add(fieldSpec);\n+  public static Object convert(Object value) {", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0MDQ2Mg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407740462", "bodyText": "RecordReaderUtils contained method convert(FieldSpec fieldSpec, Object value) which was shared amongst many of the record readers. This method is a replacement to that one, w/o the fieldSpec. It is only used by those who need this exact logic.\nIs there any part in particular you think cannot be shared?", "author": "npawar", "createdAt": "2020-04-13T21:46:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3ODk5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc1MTk1Mg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407751952", "bodyText": "For different source format, the input value can only be some certain types. Current approach is to add all the possible types for all source formant into this methods, which IMO is not efficient and not easy to manage. For example, for Json, ByteBuffer is not possible; For Avro, List is not possible etc.", "author": "Jackie-Jiang", "createdAt": "2020-04-13T22:15:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3ODk5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc3NDg0NQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407774845", "bodyText": "Separated it for JSONRecordExtractor. Now only Avro, Parquet and Thrift use this, and I think it applies to all 3 of them.", "author": "npawar", "createdAt": "2020-04-13T23:21:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3ODk5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4MTI3Nw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407681277", "bodyText": "(Critical) You should skip the virtual columns here instead of inside the ExpressionEvaluatorFactory. You don't want to put virtual column into the sourceFieldNames", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:50:40Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/SourceFieldNameExtractor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.collect.Lists;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SourceFieldNameExtractor {\n+  public static final String MAP_KEY_COLUMN_SUFFIX = \"__KEYS\";\n+  public static final String MAP_VALUE_COLUMN_SUFFIX = \"__VALUES\";\n+\n+  /**\n+   * Extracts the source fields from the schema\n+   * For field specs with a transform expression defined, use the arguments provided to the function\n+   * Otherwise, use the column name as is\n+   * TODO: for now, we assume that arguments to transform function are in the source i.e. there's no columns which are derived from transformed columns\n+   */\n+  public static List<String> extract(Schema schema) {\n+    Set<String> sourceFieldNames = new HashSet<>();\n+    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n+      String columnName = fieldSpec.getName();", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzcyODkzMw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407728933", "bodyText": "Thanks for catching that. Fixed", "author": "npawar", "createdAt": "2020-04-13T21:21:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4MTI3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4MTU1OA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407681558", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                return Lists.newArrayList(sourceFieldNames);\n          \n          \n            \n                return new ArrayList<>(sourceFieldNames);", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:51:11Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/SourceFieldNameExtractor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.collect.Lists;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SourceFieldNameExtractor {\n+  public static final String MAP_KEY_COLUMN_SUFFIX = \"__KEYS\";\n+  public static final String MAP_VALUE_COLUMN_SUFFIX = \"__VALUES\";\n+\n+  /**\n+   * Extracts the source fields from the schema\n+   * For field specs with a transform expression defined, use the arguments provided to the function\n+   * Otherwise, use the column name as is\n+   * TODO: for now, we assume that arguments to transform function are in the source i.e. there's no columns which are derived from transformed columns\n+   */\n+  public static List<String> extract(Schema schema) {\n+    Set<String> sourceFieldNames = new HashSet<>();\n+    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n+      String columnName = fieldSpec.getName();\n+      ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+\n+      if (expressionEvaluator != null) {\n+        sourceFieldNames.addAll(expressionEvaluator.getArguments());\n+      } else {\n+        sourceFieldNames.add(columnName);\n+      }\n+    }\n+    return Lists.newArrayList(sourceFieldNames);", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4MzI5Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407683293", "bodyText": "Handling the virtual column before calling this method?\nAllow calling this for virtual column and handle it inside can cause confusion. You cannot differentiate virtual column or column without transform.", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:54:26Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    if (!fieldSpec.isVirtualColumn()) {", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NTI0Ng==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407685246", "bodyText": "For better performance, check it at line 86", "author": "Jackie-Jiang", "createdAt": "2020-04-13T19:58:00Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN = Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);\n+      } else {\n+        _arguments = Collections.emptyList();\n+      }\n+    }\n+  }\n+\n+  public static String getGroovyExpressionPrefix() {\n+    return GROOVY_EXPRESSION_PREFIX;\n+  }\n+\n+  @Override\n+  public List<String> getArguments() {\n+    return _arguments;\n+  }\n+\n+  @Override\n+  public Object evaluate(GenericRow genericRow) {\n+    Map<String, Object> params = new HashMap<>();\n+    for (String argument : _arguments) {\n+      params.put(argument, genericRow.getValue(argument));\n+    }\n+    if (params.containsValue(null)) { // TODO: disallow evaluation of any of the params is null? Or give complete control to function?", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NzA1Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407687053", "bodyText": "We should standardize what data types are allowed in the GenericRow so that RecordReader and RecordExtractor can always extract the row into the supported data types, and ExpressionEvaluator can only evaluate values into these types", "author": "Jackie-Jiang", "createdAt": "2020-04-13T20:01:16Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.List;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Interface for evaluators of transform function expressions of schema field specs\n+ * They transformFunction follows the convention:\n+ *  \"transformFunction\": \"FunctionType({function}, argument1, argument2,...argumentN)\"\n+ *  For example,\n+ *  \"transformFunction\" : \"Groovy({firstName + ' ' + lastName}, firstName, lastName)\"\n+ */\n+public interface ExpressionEvaluator {\n+\n+  /**\n+   * Get the arguments of the function\n+   */\n+  List<String> getArguments();\n+\n+  /**\n+   * Evaluate the function on the generic row and return the result\n+   */\n+  Object evaluate(GenericRow genericRow);", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0MTUxMQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407741511", "bodyText": "Yes that sounds good. Do you think any of that is actionable in this PR?", "author": "npawar", "createdAt": "2020-04-13T21:49:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NzA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc1MDg1OA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407750858", "bodyText": "Adding some javadoc should be good (may be add them inside the GenericRow.class).\nInside generic row, I think we should standardize the data types as followings:\nInteger, Long, Float, Double, String, byte[], Object[] of the single-value types", "author": "Jackie-Jiang", "createdAt": "2020-04-13T22:12:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NzA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc2OTAxNw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407769017", "bodyText": "Added", "author": "npawar", "createdAt": "2020-04-13T23:03:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NzA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwNDIxMw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407804213", "bodyText": "Just checked the code (DataTypeTransformer). Based on the current behavior, we support the following data types:\nSV: Boolean, Byte, Character, Short, Integer, Long, Float, Double, String, byte[]\nMV: Object[] or List of Byte, Character, Short, Integer, Long, Float, Double, String\nI vote for not using Boolean, Byte, Character and Short to keep it simple, but it is not done inside each RecordExtractor. We might want to track this issue somewhere.", "author": "Jackie-Jiang", "createdAt": "2020-04-14T00:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NzA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA3NjgwMg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r409076802", "bodyText": "Added more details on these lines to the comment", "author": "npawar", "createdAt": "2020-04-15T19:18:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NzA1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzcyOTQxMA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407729410", "bodyText": "Shall we consider make this evaluators to be ordered? So we can derived a field based on another derived field?", "author": "xiangfu0", "createdAt": "2020-04-13T21:22:39Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "diffHunk": "@@ -34,33 +33,31 @@\n  * regular column for other record transformers.\n  */\n public class ExpressionTransformer implements RecordTransformer {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionTransformer.class);\n \n-  private final Map<String, FunctionExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+  private final Map<String, ExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+\n+  private final String _timeColumn;\n \n   public ExpressionTransformer(Schema schema) {\n+    _timeColumn = schema.getTimeColumnName();\n     for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (!fieldSpec.isVirtualColumn()) {\n-        String expression = fieldSpec.getTransformFunction();\n-        if (expression != null) {\n-          try {\n-            _expressionEvaluators.put(fieldSpec.getName(), new FunctionExpressionEvaluator(expression));\n-          } catch (Exception e) {\n-            LOGGER.error(\"Caught exception while constructing expression evaluator for: {}, skipping\", expression, e);\n-          }\n-        }\n+      ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+      if (expressionEvaluator != null) {\n+        _expressionEvaluators.put(fieldSpec.getName(), expressionEvaluator);\n       }\n     }\n   }\n \n   @Override\n   public GenericRow transform(GenericRow record) {\n-    for (Map.Entry<String, FunctionExpressionEvaluator> entry : _expressionEvaluators.entrySet()) {\n+    for (Map.Entry<String, ExpressionEvaluator> entry : _expressionEvaluators.entrySet()) {", "originalCommit": "276fba0688677fc04893d25d3fc237fd3cf6ea68", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0MzM4Mg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407743382", "bodyText": "In this iteration, I haven't considered derived fields. It's part of my next steps. Yes, can make this map ordered then. Will also have to include logic in the ExpressionTransformer constructor to come up with the ordering.\nThe next steps are:\n\nDerived fields\nCustom functions\nSome default time related functions\nUse all of the above to migrate to dateTimeFieldSpec\nAdvanced transformations - filter, flatten\nPluggable RecordTransformer", "author": "npawar", "createdAt": "2020-04-13T21:53:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzcyOTQxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0MDIxMQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407740211", "bodyText": "nit: move the package below license", "author": "xiangfu0", "createdAt": "2020-04-13T21:46:03Z", "path": "pinot-spi/src/test/java/org/apache/pinot/spi/utils/TimeConverterTest.java", "diffHunk": "@@ -1,3 +1,5 @@\n+package org.apache.pinot.spi.utils;", "originalCommit": "aa9584c853cdb1294e7f54bc629189618b69ad96", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0Mzc2MQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407743761", "bodyText": "Where we will do the conversion for dataType=bytes, and value is string.", "author": "xiangfu0", "createdAt": "2020-04-13T21:54:13Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordReaderUtils.java", "diffHunk": "@@ -67,167 +59,65 @@ public static InputStream getInputStream(File dataFile)\n   }\n \n   /**\n-   * Extracts all field specs from the given schema.\n-   * <p>For time field spec:\n-   * <ul>\n-   *   <li>If incoming and outgoing time column name are the same, use incoming time field spec</li>\n-   *   <li>If incoming and outgoing time column name are different, put both of them as time field spec</li>\n-   *   <li>\n-   *     We keep both incoming and outgoing time column to handle cases where the input file contains time values that\n-   *     are already converted\n-   *   </li>\n-   * </ul>\n+   * Converts the value to a multi-values value or a single values value\n    */\n-  public static List<FieldSpec> extractFieldSpecs(Schema schema) {\n-    List<FieldSpec> fieldSpecs = new ArrayList<>();\n-    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (fieldSpec.getFieldType() == FieldSpec.FieldType.TIME) {\n-        TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n-        fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getIncomingGranularitySpec()));\n-        if (!timeFieldSpec.getOutgoingTimeColumnName().equals(timeFieldSpec.getIncomingTimeColumnName())) {\n-          fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getOutgoingGranularitySpec()));\n-        }\n-      } else {\n-        fieldSpecs.add(fieldSpec);\n-      }\n-    }\n-    return fieldSpecs;\n-  }\n+  public static @Nullable Object convert(@Nullable Object value) {\n \n-  /**\n-   * Converts the value based on the given field spec.\n-   */\n-  public static Object convert(FieldSpec fieldSpec, @Nullable Object value) {\n-    if (fieldSpec.isSingleValueField()) {\n-      return convertSingleValue(fieldSpec, value);\n+    if (value == null) {\n+      return null;\n+    }\n+    if (value instanceof Collection) {\n+      return convertMultiValue((Collection) value);\n     } else {\n-      return convertMultiValue(fieldSpec, (Collection) value);\n+      return convertSingleValue(value);\n     }\n   }\n \n   /**\n-   * Converts the value to a single-valued value based on the given field spec.\n+   * Converts the value to a single-valued value\n    */\n-  public static Object convertSingleValue(FieldSpec fieldSpec, @Nullable Object value) {\n+  public static @Nullable Object convertSingleValue(@Nullable Object value) {\n     if (value == null) {\n       return null;\n     }\n-    DataType dataType = fieldSpec.getDataType();\n-    if (dataType == FieldSpec.DataType.BYTES) {\n-      // Avro ByteBuffer maps to byte[]\n-      if (value instanceof ByteBuffer) {\n-        ByteBuffer byteBufferValue = (ByteBuffer) value;\n \n-        // Use byteBufferValue.remaining() instead of byteBufferValue.capacity() so that it still works when buffer is\n-        // over-sized\n-        byte[] bytesValue = new byte[byteBufferValue.remaining()];\n-        byteBufferValue.get(bytesValue);\n-        return bytesValue;\n-      } else {\n-        Preconditions\n-            .checkState(value instanceof byte[], \"For BYTES data type, value must be either ByteBuffer or byte[]\");\n-        return value;\n-      }\n-    }\n-    if (value instanceof Number) {\n-      Number numberValue = (Number) value;\n-      switch (dataType) {\n-        case INT:\n-          return numberValue.intValue();\n-        case LONG:\n-          return numberValue.longValue();\n-        case FLOAT:\n-          return numberValue.floatValue();\n-        case DOUBLE:\n-          return numberValue.doubleValue();\n-        case STRING:\n-          return numberValue.toString();\n-        default:\n-          throw new IllegalStateException(\"Illegal data type: \" + dataType);\n-      }\n-    }\n-    return convertSingleValue(fieldSpec, value.toString());\n-  }\n+    if (value instanceof ByteBuffer) {\n+      ByteBuffer byteBufferValue = (ByteBuffer) value;\n \n-  /**\n-   * Converts the string value to a single-valued value based on the given field spec.\n-   */\n-  public static Object convertSingleValue(FieldSpec fieldSpec, @Nullable String stringValue) {\n-    if (stringValue == null) {\n-      return null;\n-    }\n-    DataType dataType = fieldSpec.getDataType();\n-    // Treat empty string as null for data types other than STRING\n-    if (stringValue.isEmpty() && dataType != DataType.STRING) {\n-      return null;\n+      // Use byteBufferValue.remaining() instead of byteBufferValue.capacity() so that it still works when buffer is\n+      // over-sized\n+      byte[] bytesValue = new byte[byteBufferValue.remaining()];\n+      byteBufferValue.get(bytesValue);\n+      return bytesValue;\n     }\n-    switch (dataType) {\n-      case INT:\n-        return Integer.parseInt(stringValue);\n-      case LONG:\n-        return Long.parseLong(stringValue);\n-      case FLOAT:\n-        return Float.parseFloat(stringValue);\n-      case DOUBLE:\n-        return Double.parseDouble(stringValue);\n-      case STRING:\n-        return stringValue;\n-      case BYTES:\n-        return BytesUtils.toBytes(stringValue);\n-      default:\n-        throw new IllegalStateException(\"Illegal data type: \" + dataType);\n+    if (value instanceof Number) {\n+      return value;\n     }\n+    return value.toString();", "originalCommit": "aa9584c853cdb1294e7f54bc629189618b69ad96", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc2ODgyOQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407768829", "bodyText": "I checked that this will be handled within DataTypeTransformer. There are tests for this in the PinotDataTypeTest", "author": "npawar", "createdAt": "2020-04-13T23:03:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0Mzc2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc5NzY2MA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407797660", "bodyText": "Skip virtual columns here", "author": "Jackie-Jiang", "createdAt": "2020-04-14T00:35:37Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "diffHunk": "@@ -34,33 +33,31 @@\n  * regular column for other record transformers.\n  */\n public class ExpressionTransformer implements RecordTransformer {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionTransformer.class);\n \n-  private final Map<String, FunctionExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+  private final Map<String, ExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+\n+  private final String _timeColumn;\n \n   public ExpressionTransformer(Schema schema) {\n+    _timeColumn = schema.getTimeColumnName();\n     for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (!fieldSpec.isVirtualColumn()) {\n-        String expression = fieldSpec.getTransformFunction();\n-        if (expression != null) {\n-          try {\n-            _expressionEvaluators.put(fieldSpec.getName(), new FunctionExpressionEvaluator(expression));\n-          } catch (Exception e) {\n-            LOGGER.error(\"Caught exception while constructing expression evaluator for: {}, skipping\", expression, e);\n-          }\n-        }\n+      ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);", "originalCommit": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc5Nzk2Ng==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407797966", "bodyText": "(convention) Put nullable in front of public static as a separate line", "author": "Jackie-Jiang", "createdAt": "2020-04-14T00:36:49Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  public static @Nullable", "originalCommit": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc5OTI2Nw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407799267", "bodyText": "Don't specialize time column here. When the dest column already exists, we should not evaluate the expression again.\nThe reason for this is that: for hybrid table, both realtime and offline side share the same schema, and usually the batch ingestion already pre-processed the data and finished all the expression evaluation.\nHere comes a limitation of maintaining this behavior: the source column name must be different from the dest column name, but I think this should be fine. We can also add a validation for that in the SourceFieldNameExtractor", "author": "Jackie-Jiang", "createdAt": "2020-04-14T00:41:23Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "diffHunk": "@@ -34,33 +33,31 @@\n  * regular column for other record transformers.\n  */\n public class ExpressionTransformer implements RecordTransformer {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionTransformer.class);\n \n-  private final Map<String, FunctionExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+  private final Map<String, ExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+\n+  private final String _timeColumn;\n \n   public ExpressionTransformer(Schema schema) {\n+    _timeColumn = schema.getTimeColumnName();\n     for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (!fieldSpec.isVirtualColumn()) {\n-        String expression = fieldSpec.getTransformFunction();\n-        if (expression != null) {\n-          try {\n-            _expressionEvaluators.put(fieldSpec.getName(), new FunctionExpressionEvaluator(expression));\n-          } catch (Exception e) {\n-            LOGGER.error(\"Caught exception while constructing expression evaluator for: {}, skipping\", expression, e);\n-          }\n-        }\n+      ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+      if (expressionEvaluator != null) {\n+        _expressionEvaluators.put(fieldSpec.getName(), expressionEvaluator);\n       }\n     }\n   }\n \n   @Override\n   public GenericRow transform(GenericRow record) {\n-    for (Map.Entry<String, FunctionExpressionEvaluator> entry : _expressionEvaluators.entrySet()) {\n+    for (Map.Entry<String, ExpressionEvaluator> entry : _expressionEvaluators.entrySet()) {\n       String column = entry.getKey();\n-      // Skip transformation if column value already exist\n+      ExpressionEvaluator transformExpressionEvaluator = entry.getValue();\n+      // Skip transformation if column value already exist. Value can exist for time transformation (incoming name = outgoing name)\n       // NOTE: column value might already exist for OFFLINE data\n-      if (record.getValue(column) == null) {\n-        record.putValue(column, entry.getValue().evaluate(record));\n+      if (record.getValue(column) == null || column.equals(_timeColumn)) {", "originalCommit": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgyNjY2Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407826663", "bodyText": "I added that precisely to handle the case you mentioned - incoming and outgoing spec are different, but have the same name. If you're saying that we don't need to handle that case, then I can remove this", "author": "npawar", "createdAt": "2020-04-14T02:20:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc5OTI2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgzODc4Nw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407838787", "bodyText": "What I'm suggesting is to not force transformation for time column because of the scenario I described.", "author": "Jackie-Jiang", "createdAt": "2020-04-14T03:05:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc5OTI2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMTA0Nw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407801047", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    requireNonNull(indexingSchema, \"indexingSchema is null\");\n          \n          \n            \n                    Preconditions.checkState(indexingSchema != null, \"Schema must be provided\");\n          \n      \n    \n    \n  \n\nAlso remove the static import", "author": "Jackie-Jiang", "createdAt": "2020-04-14T00:47:43Z", "path": "pinot-plugins/pinot-input-format/pinot-confluent-avro/src/main/java/org/apache/pinot/plugin/inputformat/avro/confluent/KafkaConfluentSchemaRegistryAvroMessageDecoder.java", "diffHunk": "@@ -44,13 +46,14 @@\n     private KafkaAvroDeserializer deserializer;\n     private RecordExtractor<Record> avroRecordConverter;\n     private String topicName;\n-    private Schema pinotSchema;\n+    private List<String> _sourceFieldNames;\n \n     @Override\n     public void init(Map<String, String> props, Schema indexingSchema, String topicName) throws Exception {\n         checkState(props.containsKey(SCHEMA_REGISTRY_REST_URL), \"Missing required property '%s'\", SCHEMA_REGISTRY_REST_URL);\n         String schemaRegistryUrl = props.get(SCHEMA_REGISTRY_REST_URL);\n-        pinotSchema = requireNonNull(indexingSchema, \"indexingSchema is null\");\n+        requireNonNull(indexingSchema, \"indexingSchema is null\");", "originalCommit": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMjg4NA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407802884", "bodyText": "(Critical) ORC might not work with the extractor model because it is not read row-by-row but batch-by-batch.\nI would recommend reverting the change on ORCRecordReader and leave it as is. I'm working on re-do this record reader.", "author": "Jackie-Jiang", "createdAt": "2020-04-14T00:54:22Z", "path": "pinot-plugins/pinot-input-format/pinot-orc/src/main/java/org/apache/pinot/plugin/inputformat/orc/ORCRecordExtractor.java", "diffHunk": "@@ -0,0 +1,144 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.inputformat.orc;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.io.BooleanWritable;\n+import org.apache.hadoop.io.ByteWritable;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.FloatWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.io.ShortWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.WritableComparable;\n+import org.apache.orc.TypeDescription;\n+import org.apache.orc.mapred.OrcList;\n+import org.apache.orc.mapred.OrcMapredRecordReader;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.data.readers.RecordExtractor;\n+import org.apache.pinot.spi.data.readers.RecordExtractorConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Extractor for ORC records\n+ */\n+public class ORCRecordExtractor implements RecordExtractor<VectorizedRowBatch> {", "originalCommit": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwOTA0NA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407809044", "bodyText": "Wait... Seems we are always creating batch of one row... So it might work but just inefficient...\nStill, I think this model does not apply to ORC record reader", "author": "Jackie-Jiang", "createdAt": "2020-04-14T01:17:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgyNDQ3Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407824473", "bodyText": "It works i think because of this\n_reusableVectorizedRowBatch = _orcSchema.createRowBatch(1);\nThe row batch size is 1.\nORCRecordReader tests also pass. The tests I added have 4 records.\nI prefer to keep this change. When you refactor, you can change it as needed", "author": "npawar", "createdAt": "2020-04-14T02:12:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMjg4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMzI1MA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407803250", "bodyText": "I think this test will fail if you create a file with more than 1 records.", "author": "Jackie-Jiang", "createdAt": "2020-04-14T00:55:40Z", "path": "pinot-plugins/pinot-input-format/pinot-orc/src/test/java/org/apache/pinot/plugin/inputformat/orc/ORCRecordExtractorTest.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.inputformat.orc;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.orc.OrcFile;\n+import org.apache.orc.TypeDescription;\n+import org.apache.orc.Writer;\n+import org.apache.orc.mapred.OrcList;\n+import org.apache.orc.mapred.OrcMapredRecordWriter;\n+import org.apache.orc.mapred.OrcStruct;\n+import org.apache.pinot.spi.data.readers.AbstractRecordExtractorTest;\n+import org.apache.pinot.spi.data.readers.RecordReader;\n+\n+\n+/**\n+ * Tests the {@link ORCRecordExtractor} using a schema containing groovy transform functions\n+ */\n+public class ORCRecordExtractorTest extends AbstractRecordExtractorTest {", "originalCommit": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwODU4Mg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407808582", "bodyText": "The test uses 4 records. Which test are you referring to that uses just 1?", "author": "npawar", "createdAt": "2020-04-14T01:15:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMzI1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgxMDE3Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407810173", "bodyText": "Sorry didn't notice the records are from the parent class, never mind.", "author": "Jackie-Jiang", "createdAt": "2020-04-14T01:21:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMzI1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwOTU4MQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407809581", "bodyText": "Wrong format", "author": "Jackie-Jiang", "createdAt": "2020-04-14T01:19:01Z", "path": "pinot-plugins/pinot-input-format/pinot-orc/src/test/java/org/apache/pinot/plugin/inputformat/orc/ORCRecordExtractorTest.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.inputformat.orc;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.orc.OrcFile;\n+import org.apache.orc.TypeDescription;\n+import org.apache.orc.Writer;\n+import org.apache.orc.mapred.OrcList;\n+import org.apache.orc.mapred.OrcMapredRecordWriter;\n+import org.apache.orc.mapred.OrcStruct;\n+import org.apache.pinot.spi.data.readers.AbstractRecordExtractorTest;\n+import org.apache.pinot.spi.data.readers.RecordReader;\n+\n+\n+/**\n+ * Tests the {@link ORCRecordExtractor} using a schema containing groovy transform functions\n+ */\n+public class ORCRecordExtractorTest extends AbstractRecordExtractorTest {\n+\n+  private final File _dataFile = new File(_tempDir, \"events.orc\");\n+\n+  /**\n+   * Create an ORCRecordReader\n+   */\n+  @Override\n+  protected RecordReader createRecordReader()\n+      throws IOException {\n+    ORCRecordReader orcRecordReader = new ORCRecordReader();\n+    orcRecordReader.init(_dataFile, _pinotSchema, null);\n+    return orcRecordReader;\n+  }\n+\n+  /**\n+   * Create an ORC input file using the input records\n+   */\n+  @Override\n+  protected void createInputFile()\n+      throws IOException {\n+    TypeDescription schema = TypeDescription.createStruct();\n+    schema.addField(\"userID\", TypeDescription.createInt());\n+    schema.addField(\"firstName\", TypeDescription.createString());\n+    schema.addField(\"lastName\", TypeDescription.createString());\n+    TypeDescription typeBids = TypeDescription.createList(TypeDescription.createInt());\n+    schema.addField(\"bids\", typeBids);\n+    schema.addField(\"campaignInfo\", TypeDescription.createString());\n+    schema.addField(\"cost\", TypeDescription.createDouble());\n+    schema.addField(\"timestamp\", TypeDescription.createLong());\n+\n+    Writer writer = OrcFile.createWriter(new Path(_dataFile.getAbsolutePath()),\n+        OrcFile.writerOptions(new Configuration()).setSchema(schema));\n+    OrcMapredRecordWriter mrRecordWriter = new OrcMapredRecordWriter(writer);\n+    for (Map<String, Object> inputRecord : _inputRecords) {\n+      OrcStruct struct = new OrcStruct(schema);\n+      Integer userID = (Integer) inputRecord.get(\"userID\");\n+      struct.setFieldValue(\"userID\", userID == null ? null : new IntWritable(userID));\n+      String firstName = (String) inputRecord.get(\"firstName\");\n+      struct.setFieldValue(\"firstName\", firstName == null ? null : new Text(firstName));\n+      struct.setFieldValue(\"lastName\", new Text((String) inputRecord.get(\"lastName\")));\n+      List<Integer> bids = (List<Integer>) inputRecord.get(\"bids\");\n+      if (bids != null) {\n+        OrcList<IntWritable> bidsList = new OrcList<>(typeBids);\n+        for (Integer bid : bids) {\n+          bidsList.add(new IntWritable(bid));\n+        }\n+        struct.setFieldValue(\"bids\", bidsList);\n+      } else {\n+        struct.setFieldValue(\"bids\", null);\n+      }\n+      struct.setFieldValue(\"campaignInfo\", new Text((String) inputRecord.get(\"campaignInfo\")));\n+      struct.setFieldValue(\"cost\", new DoubleWritable((Double) inputRecord.get(\"cost\")));\n+      struct.setFieldValue(\"timestamp\", new LongWritable((Long) inputRecord.get(\"timestamp\")));\n+      mrRecordWriter.write(null, struct);\n+    } mrRecordWriter.close(null);", "originalCommit": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgxMzgwOA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407813808", "bodyText": "Please remove this log message, it will show up in every input message.  We don't seem to be logging this in other extractors either", "author": "mcvsubbu", "createdAt": "2020-04-14T01:34:13Z", "path": "pinot-plugins/pinot-input-format/pinot-orc/src/main/java/org/apache/pinot/plugin/inputformat/orc/ORCRecordExtractor.java", "diffHunk": "@@ -0,0 +1,144 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.inputformat.orc;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.io.BooleanWritable;\n+import org.apache.hadoop.io.ByteWritable;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.FloatWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.io.ShortWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.WritableComparable;\n+import org.apache.orc.TypeDescription;\n+import org.apache.orc.mapred.OrcList;\n+import org.apache.orc.mapred.OrcMapredRecordReader;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.data.readers.RecordExtractor;\n+import org.apache.pinot.spi.data.readers.RecordExtractorConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Extractor for ORC records\n+ */\n+public class ORCRecordExtractor implements RecordExtractor<VectorizedRowBatch> {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ORCRecordExtractor.class);\n+\n+  private TypeDescription _orcSchema;\n+\n+  @Override\n+  public void init(RecordExtractorConfig recordExtractorConfig) {\n+    _orcSchema = ((ORCRecordExtractorConfig) recordExtractorConfig).getOrcSchema();\n+  }\n+\n+  @Override\n+  public GenericRow extract(List<String> sourceFieldNames, VectorizedRowBatch from, GenericRow to) {\n+    // TODO: use Pinot schema to fill the values to handle missing column and default values properly\n+\n+    // ORC's TypeDescription is the equivalent of a schema. The way we will support ORC in Pinot\n+    // will be to get the top level struct that contains all our fields and look through its\n+    // children to determine the fields in our schemas.\n+    if (_orcSchema.getCategory().equals(TypeDescription.Category.STRUCT)) {\n+      List<TypeDescription> orcSchemaChildren = _orcSchema.getChildren();\n+      for (int i = 0; i < orcSchemaChildren.size(); i++) {\n+        // Get current column in schema\n+        String currColumnName = _orcSchema.getFieldNames().get(i);\n+        if (!sourceFieldNames.contains(currColumnName)) {\n+          LOGGER.warn(\"Skipping column {} because it is not in source columns\", currColumnName);", "originalCommit": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7740e915ae6f773b6be7468ffda9b5065aadfb5d", "url": "https://github.com/apache/pinot/commit/7740e915ae6f773b6be7468ffda9b5065aadfb5d", "message": "First pass of transform functions using Groovy", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "6ac6ff18edc3d7934f0bc350526527dac04e72c5", "url": "https://github.com/apache/pinot/commit/6ac6ff18edc3d7934f0bc350526527dac04e72c5", "message": "Tests for RecordExtractors, Evaluators, SourceFieldName utility, ExpressionTransformer, Map type, TimeSpec conversion and more", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "2926598fefb24f28c685af92a196c0ed68b80d1d", "url": "https://github.com/apache/pinot/commit/2926598fefb24f28c685af92a196c0ed68b80d1d", "message": "More Groovy test", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "93a80d575d31ef78489dbcf74d70357a471c1dc6", "url": "https://github.com/apache/pinot/commit/93a80d575d31ef78489dbcf74d70357a471c1dc6", "message": "Javadocs", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "c6b3718e0223c15f53ca06064896f8d3d0d31a51", "url": "https://github.com/apache/pinot/commit/c6b3718e0223c15f53ca06064896f8d3d0d31a51", "message": "Corner cases in Time", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "398af9b4d30433e614a7439da658391a6bfdae99", "url": "https://github.com/apache/pinot/commit/398af9b4d30433e614a7439da658391a6bfdae99", "message": "Review comments - Nullable, newline, blank lines, some refactoring", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "e0b3619d9d644e73aacac676c0063eea393dc0c3", "url": "https://github.com/apache/pinot/commit/e0b3619d9d644e73aacac676c0063eea393dc0c3", "message": "Remove unused code form RecordReaderUtils", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "f8474d4f05455712f490732b3065d169a93b79d6", "url": "https://github.com/apache/pinot/commit/f8474d4f05455712f490732b3065d169a93b79d6", "message": "Addressing some review comments", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "9fec7577082fcf10f6f3bdc1d2cf8a0ab4b9f1c4", "url": "https://github.com/apache/pinot/commit/9fec7577082fcf10f6f3bdc1d2cf8a0ab4b9f1c4", "message": "Make JsonRecordExtractor not use the generic RecordReaderUtils for conversion", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "ec6f299710c1e1e9a45e3965986fb34eb23f3ea7", "url": "https://github.com/apache/pinot/commit/ec6f299710c1e1e9a45e3965986fb34eb23f3ea7", "message": "Fix AvroRecordToPinotRowGeneratortest", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"oid": "55c789aad03deedc729a097cc86f4b353b7c4a58", "url": "https://github.com/apache/pinot/commit/55c789aad03deedc729a097cc86f4b353b7c4a58", "message": "Addressed review comments", "committedDate": "2020-04-14T03:22:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwOTk3Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408209973", "bodyText": "Can value be an instance of primitive array?", "author": "mayankshriv", "createdAt": "2020-04-14T15:04:23Z", "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroUtils.java", "diffHunk": "@@ -305,46 +301,23 @@ public static boolean isSingleValueField(Field field) {\n     }\n   }\n \n-  @SuppressWarnings(\"unchecked\")\n-  public static void extractField(FieldSpec fieldSpec, GenericRecord from, GenericRow to) {\n-    String fieldName = fieldSpec.getName();\n-\n-    // Handle the Map type\n-    if (fieldName.endsWith(MAP_KEY_COLUMN_SUFFIX)) {\n-      String avroFieldName = fieldName.substring(0, fieldName.length() - MAP_KEY_COLUMN_SUFFIX.length());\n-      Map map = (Map) from.get(avroFieldName);\n-      if (map != null) {\n-        // Sort the keys so that the order is deterministic\n-        TreeSet sortedKeys = new TreeSet(map.keySet());\n-        to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, sortedKeys));\n-        return;\n-      }\n-    } else if (fieldName.endsWith(MAP_VALUE_COLUMN_SUFFIX)) {\n-      String avroFieldName = fieldName.substring(0, fieldName.length() - MAP_VALUE_COLUMN_SUFFIX.length());\n-      Map map = (Map) from.get(avroFieldName);\n-      if (map != null) {\n-        // Sort the keys so that the order is deterministic\n-        TreeMap sortedMap = new TreeMap<>(map);\n-        to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, sortedMap.values()));\n-        return;\n-      }\n-    }\n-    to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, convert(fieldSpec, from.get(fieldName))));\n-  }\n-\n   /**\n-   * Converts the value based on the given field spec.\n+   * Converts the value to a single-valued value or a multi-valued value\n    */\n-  public static Object convert(FieldSpec fieldSpec, @Nullable Object value) {\n-    if (fieldSpec.isSingleValueField()) {\n-      return handleSingleValue(value);\n+  public static Object convert(Object value) {\n+    Object convertedValue;\n+    if (value instanceof Collection) {", "originalCommit": "e12c035a961305656393a4802bffc2c809155525", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODMwNjg1NQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408306855", "bodyText": "In avro, it cannot be", "author": "npawar", "createdAt": "2020-04-14T17:22:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwOTk3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIxMDc0OA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408210748", "bodyText": "So we no longer need source schema?", "author": "mayankshriv", "createdAt": "2020-04-14T15:05:24Z", "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroRecordExtractor.java", "diffHunk": "@@ -18,18 +18,31 @@\n  */\n package org.apache.pinot.plugin.inputformat.avro;\n \n-import org.apache.avro.generic.GenericData;\n-import org.apache.pinot.spi.data.FieldSpec;\n-import org.apache.pinot.spi.data.Schema;\n-import org.apache.pinot.spi.data.readers.AbstractBaseRecordExtractor;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.avro.generic.GenericRecord;\n import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.data.readers.RecordExtractor;\n+import org.apache.pinot.spi.data.readers.RecordExtractorConfig;\n+\n+\n+/**\n+ * Extractor for Avro Records\n+ */\n+public class AvroRecordExtractor implements RecordExtractor<GenericRecord> {\n+  private List<String> _fields;\n+\n+  @Override\n+  public void init(List<String> fields, @Nullable RecordExtractorConfig recordExtractorConfig) {\n+    _fields = fields;\n+  }\n \n-public class AvroRecordExtractor extends AbstractBaseRecordExtractor<GenericData.Record> {\n   @Override\n-  public GenericRow extract(Schema schema, GenericData.Record from, GenericRow to) {\n-    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      FieldSpec incomingFieldSpec = getFieldSpecToUse(schema, fieldSpec);\n-      AvroUtils.extractField(incomingFieldSpec, from, to);\n+  public GenericRow extract(GenericRecord from, GenericRow to) {", "originalCommit": "e12c035a961305656393a4802bffc2c809155525", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI5MzMxMA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408293310", "bodyText": "That's right. The pinot schema represents the destination columns. We don't have schema for source anymore", "author": "npawar", "createdAt": "2020-04-14T17:00:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIxMDc0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIxMzA4OQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408213089", "bodyText": "Probably a bit more description would help.", "author": "mayankshriv", "createdAt": "2020-04-14T15:08:20Z", "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroUtils.java", "diffHunk": "@@ -305,46 +301,23 @@ public static boolean isSingleValueField(Field field) {\n     }\n   }\n \n-  @SuppressWarnings(\"unchecked\")\n-  public static void extractField(FieldSpec fieldSpec, GenericRecord from, GenericRow to) {\n-    String fieldName = fieldSpec.getName();\n-\n-    // Handle the Map type\n-    if (fieldName.endsWith(MAP_KEY_COLUMN_SUFFIX)) {\n-      String avroFieldName = fieldName.substring(0, fieldName.length() - MAP_KEY_COLUMN_SUFFIX.length());\n-      Map map = (Map) from.get(avroFieldName);\n-      if (map != null) {\n-        // Sort the keys so that the order is deterministic\n-        TreeSet sortedKeys = new TreeSet(map.keySet());\n-        to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, sortedKeys));\n-        return;\n-      }\n-    } else if (fieldName.endsWith(MAP_VALUE_COLUMN_SUFFIX)) {\n-      String avroFieldName = fieldName.substring(0, fieldName.length() - MAP_VALUE_COLUMN_SUFFIX.length());\n-      Map map = (Map) from.get(avroFieldName);\n-      if (map != null) {\n-        // Sort the keys so that the order is deterministic\n-        TreeMap sortedMap = new TreeMap<>(map);\n-        to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, sortedMap.values()));\n-        return;\n-      }\n-    }\n-    to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, convert(fieldSpec, from.get(fieldName))));\n-  }\n-\n   /**\n-   * Converts the value based on the given field spec.\n+   * Converts the value to a single-valued value or a multi-valued value\n    */\n-  public static Object convert(FieldSpec fieldSpec, @Nullable Object value) {\n-    if (fieldSpec.isSingleValueField()) {\n-      return handleSingleValue(value);\n+  public static Object convert(Object value) {\n+    Object convertedValue;\n+    if (value instanceof Collection) {\n+      convertedValue = handleMultiValue((Collection) value);\n+    } else if (value instanceof Map) {\n+      convertedValue = handleMap((Map) value);\n     } else {\n-      return handleMultiValue((Collection) value);\n+      convertedValue = handleSingleValue(value);\n     }\n+    return convertedValue;\n   }\n \n   /**\n-   * Converts the value based on the given field spec.\n+   * Converts the value to a single-valued value", "originalCommit": "e12c035a961305656393a4802bffc2c809155525", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIxMzQ2MA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408213460", "bodyText": "s/withing/within", "author": "mayankshriv", "createdAt": "2020-04-14T15:08:47Z", "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroUtils.java", "diffHunk": "@@ -368,6 +341,21 @@ public static Object handleMultiValue(@Nullable Collection values) {\n     for (Object value : values) {\n       list.add(handleSingleValue(value));\n     }\n-    return list;\n+    return RecordReaderUtils.convertMultiValue(list);\n+  }\n+\n+  /**\n+   * Converts the values withing the map to single-valued values", "originalCommit": "e12c035a961305656393a4802bffc2c809155525", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0MTA1MA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408241050", "bodyText": "Is genericRecord the right argument for this api, to make it more general purpose evaluator?", "author": "mayankshriv", "createdAt": "2020-04-14T15:45:12Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.List;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Interface for evaluators of transform function expressions of schema field specs\n+ * They transformFunction follows the convention:\n+ *  \"transformFunction\": \"FunctionType({function}, argument1, argument2,...argumentN)\"\n+ *  For example,\n+ *  \"transformFunction\" : \"Groovy({firstName + ' ' + lastName}, firstName, lastName)\"\n+ */\n+public interface ExpressionEvaluator {\n+\n+  /**\n+   * Get the arguments of the function\n+   */\n+  List<String> getArguments();\n+\n+  /**\n+   * Evaluate the function on the generic row and return the result\n+   */\n+  Object evaluate(GenericRow genericRow);", "originalCommit": "e12c035a961305656393a4802bffc2c809155525", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NzMxNA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408477314", "bodyText": "This is only invoked within ExpressionTransformers, which operates on GenericRow. We could change this to a Map with just the needed fields. But I thought better to avoid creating additional Map for every transformation of every row, and let the evaluator pull out whatever is needed", "author": "npawar", "createdAt": "2020-04-14T22:39:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0MTA1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NDI0Mg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408244242", "bodyText": "Is this really expression evaluator, or more of a function evaluator? For example, the function could be a complex groovy script?  Also, how about nested functions?", "author": "mayankshriv", "createdAt": "2020-04-14T15:49:19Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.List;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Interface for evaluators of transform function expressions of schema field specs\n+ * They transformFunction follows the convention:\n+ *  \"transformFunction\": \"FunctionType({function}, argument1, argument2,...argumentN)\"\n+ *  For example,\n+ *  \"transformFunction\" : \"Groovy({firstName + ' ' + lastName}, firstName, lastName)\"\n+ */\n+public interface ExpressionEvaluator {", "originalCommit": "e12c035a961305656393a4802bffc2c809155525", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NjE0Nw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408476147", "bodyText": "Yes it can be several expressions, functions, nested functions.\nFunction was already quite overloaded. I didn't want this to be confused as an evaluator for TransformFunction. And we also have a FunctionExpressionEvaluator (which should go away).\nBesides, this is only invoked inside the ExpressionTransformer, hence thought ExpressionEvaluator makes sense.\nI don't have a strong preference. But just thought this was less confusing", "author": "npawar", "createdAt": "2020-04-14T22:36:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NDI0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NjA1MA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408246050", "bodyText": "Is this the only syntax available for a groovy script?", "author": "mayankshriv", "createdAt": "2020-04-14T15:51:45Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";", "originalCommit": "e12c035a961305656393a4802bffc2c809155525", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI4ODE3Mg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408288172", "bodyText": "This is the convention we will follow\nFunctionType({script}, argument1, argument2...)\nFor Groovy that becomes\nGroovy({groovy script}, argument1, argument2)\nThis can be easily extended to other function types. I've put some more details in the PR description, and also in the design doc linked in the PR description", "author": "npawar", "createdAt": "2020-04-14T16:52:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NjA1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NzA5OA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408247098", "bodyText": "Checkout Groovy Binding for argument biniding.", "author": "mayankshriv", "createdAt": "2020-04-14T15:53:13Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN =\n+      Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);", "originalCommit": "e12c035a961305656393a4802bffc2c809155525", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI4ODkwMQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408288901", "bodyText": "That's exactly what we are using. Check in the evaluate method in GroovyExpressionEvaluator", "author": "npawar", "createdAt": "2020-04-14T16:53:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NzA5OA=="}], "type": "inlineReview"}, {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74", "url": "https://github.com/apache/pinot/commit/2570bf792aa94dca41909cdd3c9a09b223285b74", "message": "Simplify time conversion logic", "committedDate": "2020-04-14T22:14:13Z", "type": "commit"}, {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74", "url": "https://github.com/apache/pinot/commit/2570bf792aa94dca41909cdd3c9a09b223285b74", "message": "Simplify time conversion logic", "committedDate": "2020-04-14T22:14:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3MzQzNQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408473435", "bodyText": "Argument should only contain _incomingTimeColumn?", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:29:07Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/DefaultTimeSpecEvaluator.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.utils.TimeConverter;\n+import org.apache.pinot.spi.utils.TimeUtils;\n+\n+\n+/**\n+ * The {@code DefaultTimeSpecEvaluator} class will convert the time value based on the {@link TimeFieldSpec}.\n+ */\n+public class DefaultTimeSpecEvaluator implements ExpressionEvaluator {\n+  private String _incomingTimeColumn;\n+  private String _outgoingTimeColumn;\n+  private TimeConverter _incomingTimeConverter;\n+  private TimeConverter _outgoingTimeConverter;\n+  private boolean _isValidated = false;\n+\n+  public DefaultTimeSpecEvaluator(TimeGranularitySpec incomingGranularitySpec,\n+      TimeGranularitySpec outgoingGranularitySpec) {\n+    Preconditions.checkState(!incomingGranularitySpec.equals(outgoingGranularitySpec));\n+    _incomingTimeColumn = incomingGranularitySpec.getName();\n+    _outgoingTimeColumn = outgoingGranularitySpec.getName();\n+    Preconditions.checkState(!_incomingTimeColumn.equals(_outgoingTimeColumn));\n+    _incomingTimeConverter = new TimeConverter(incomingGranularitySpec);\n+    _outgoingTimeConverter = new TimeConverter(outgoingGranularitySpec);\n+  }\n+\n+  @Override\n+  public List<String> getArguments() {\n+    return Lists.newArrayList(_incomingTimeColumn, _outgoingTimeColumn);", "originalCommit": "2570bf792aa94dca41909cdd3c9a09b223285b74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3OTU3OQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408479579", "bodyText": "No. If it contains only incoming, we will never read the outgoing in the record extractor. The ExpressionTransformer will not know about outgoing time value. This is necessary to handle the case where outgoing is already computed by user.", "author": "npawar", "createdAt": "2020-04-14T22:46:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3MzQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4NDM0Mg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408484342", "bodyText": "I don't follow. Arguments should only contain the input columns. For time conversion, the input should always be the incoming time column, it should never be the outgoing time column.\nThe fields passed to the record extractor should be the outgoing column name, and the arguments for the evaluator should be the incoming column name right?", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:59:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3MzQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUxNjE5OA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408516198", "bodyText": "Based on offline discussion, added support for case where transformed destination field already exists in the data.\nDefaultTimeSpecEvaluator looks right now i.e. only incoming in getArguments.", "author": "npawar", "createdAt": "2020-04-15T00:43:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3MzQzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NDExNQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408474115", "bodyText": "The first 4 variables can be final", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:31:01Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/DefaultTimeSpecEvaluator.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.utils.TimeConverter;\n+import org.apache.pinot.spi.utils.TimeUtils;\n+\n+\n+/**\n+ * The {@code DefaultTimeSpecEvaluator} class will convert the time value based on the {@link TimeFieldSpec}.\n+ */\n+public class DefaultTimeSpecEvaluator implements ExpressionEvaluator {\n+  private String _incomingTimeColumn;", "originalCommit": "2570bf792aa94dca41909cdd3c9a09b223285b74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NTAxNg==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408475016", "bodyText": "Directly throw the exception out to prevent unexpected data ingested", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:33:30Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.SchemaFieldExtractorUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, if conversion is needed, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  @Nullable\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    String columnName = fieldSpec.getName();\n+    String transformExpression = fieldSpec.getTransformFunction();\n+    if (transformExpression != null) {\n+\n+      // if transform function expression present, use it to generate function evaluator\n+      try {\n+        expressionEvaluator = getExpressionEvaluator(transformExpression);\n+      } catch (Exception e) {\n+        LOGGER.error(", "originalCommit": "2570bf792aa94dca41909cdd3c9a09b223285b74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NTIwOQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408475209", "bodyText": "Better to throw IllegalStateException when incoming and outgoing name are the same", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:34:01Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.SchemaFieldExtractorUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, if conversion is needed, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  @Nullable\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    String columnName = fieldSpec.getName();\n+    String transformExpression = fieldSpec.getTransformFunction();\n+    if (transformExpression != null) {\n+\n+      // if transform function expression present, use it to generate function evaluator\n+      try {\n+        expressionEvaluator = getExpressionEvaluator(transformExpression);\n+      } catch (Exception e) {\n+        LOGGER.error(\n+            \"Caught exception while constructing expression evaluator for transform expression: {}, of column: {}, skipping\",\n+            transformExpression, columnName, e);\n+      }\n+    } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n+\n+      // for backward compatible handling of TIME field conversion\n+      TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n+      TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n+      TimeGranularitySpec outgoingGranularitySpec = timeFieldSpec.getOutgoingGranularitySpec();\n+      if (outgoingGranularitySpec != null && !incomingGranularitySpec.equals(outgoingGranularitySpec)\n+          && !incomingGranularitySpec.getName().equals(outgoingGranularitySpec.getName())) {", "originalCommit": "2570bf792aa94dca41909cdd3c9a09b223285b74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzMTk3OA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408531978", "bodyText": "Done, in both places", "author": "npawar", "createdAt": "2020-04-15T01:42:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NTIwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NTY0Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408475643", "bodyText": "(nit) transformExpression can never be null. Suggest moving this check to the caller", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:35:13Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.SchemaFieldExtractorUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, if conversion is needed, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  @Nullable\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    String columnName = fieldSpec.getName();\n+    String transformExpression = fieldSpec.getTransformFunction();\n+    if (transformExpression != null) {\n+\n+      // if transform function expression present, use it to generate function evaluator\n+      try {\n+        expressionEvaluator = getExpressionEvaluator(transformExpression);\n+      } catch (Exception e) {\n+        LOGGER.error(\n+            \"Caught exception while constructing expression evaluator for transform expression: {}, of column: {}, skipping\",\n+            transformExpression, columnName, e);\n+      }\n+    } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n+\n+      // for backward compatible handling of TIME field conversion\n+      TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n+      TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n+      TimeGranularitySpec outgoingGranularitySpec = timeFieldSpec.getOutgoingGranularitySpec();\n+      if (outgoingGranularitySpec != null && !incomingGranularitySpec.equals(outgoingGranularitySpec)\n+          && !incomingGranularitySpec.getName().equals(outgoingGranularitySpec.getName())) {\n+        expressionEvaluator = new DefaultTimeSpecEvaluator(incomingGranularitySpec, outgoingGranularitySpec);\n+      }\n+    } else if (columnName.endsWith(SchemaFieldExtractorUtils.MAP_KEY_COLUMN_SUFFIX)) {\n+\n+      // for backward compatible handling of Map type (currently only in Avro)\n+      String sourceMapName =\n+          columnName.substring(0, columnName.length() - SchemaFieldExtractorUtils.MAP_KEY_COLUMN_SUFFIX.length());\n+      String defaultMapKeysTransformExpression = getDefaultMapKeysTransformExpression(sourceMapName);\n+      expressionEvaluator = getExpressionEvaluator(defaultMapKeysTransformExpression);\n+    } else if (columnName.endsWith(SchemaFieldExtractorUtils.MAP_VALUE_COLUMN_SUFFIX)) {\n+\n+      // for backward compatible handling of Map type in avro (currently only in Avro)\n+      String sourceMapName =\n+          columnName.substring(0, columnName.length() - SchemaFieldExtractorUtils.MAP_VALUE_COLUMN_SUFFIX.length());\n+      String defaultMapValuesTransformExpression = getDefaultMapValuesTransformExpression(sourceMapName);\n+      expressionEvaluator = getExpressionEvaluator(defaultMapValuesTransformExpression);\n+    }\n+\n+    return expressionEvaluator;\n+  }\n+\n+  private static ExpressionEvaluator getExpressionEvaluator(String transformExpression) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+    if (transformExpression != null && !transformExpression.isEmpty()) {", "originalCommit": "2570bf792aa94dca41909cdd3c9a09b223285b74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NjE1OQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408476159", "bodyText": "Is this possible? Should we throw exception here?", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:36:41Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN =\n+      Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);\n+      } else {\n+        _arguments = Collections.emptyList();", "originalCommit": "2570bf792aa94dca41909cdd3c9a09b223285b74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4MTExMQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408481111", "bodyText": "I think it is possible. We could have a function that simply computes a value, like a default. Can be based on say current time.", "author": "npawar", "createdAt": "2020-04-14T22:50:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NjE1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NzI4OQ==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408477289", "bodyText": "(nit) outgoingGranularitySpec will never be null because it will return incoming spec if outgoing is not set", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:39:40Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/utils/SchemaFieldExtractorUtils.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.utils;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.data.function.evaluators.ExpressionEvaluator;\n+import org.apache.pinot.spi.data.function.evaluators.ExpressionEvaluatorFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SchemaFieldExtractorUtils {\n+  public static final String MAP_KEY_COLUMN_SUFFIX = \"__KEYS\";\n+  public static final String MAP_VALUE_COLUMN_SUFFIX = \"__VALUES\";\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SchemaFieldExtractorUtils.class);\n+\n+  /**\n+   * Extracts the source fields from the schema\n+   * For field specs with a transform expression defined, use the arguments provided to the function\n+   * Otherwise, use the column name as is\n+   * TODO: for now, we assume that arguments to transform function are in the source i.e. there's no columns which are derived from transformed columns\n+   */\n+  public static List<String> extract(Schema schema) {\n+    Set<String> sourceFieldNames = new HashSet<>();\n+    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n+      if (!fieldSpec.isVirtualColumn()) {\n+        ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+\n+        if (expressionEvaluator != null) {\n+          sourceFieldNames.addAll(expressionEvaluator.getArguments());\n+        } else {\n+          sourceFieldNames.add(fieldSpec.getName());\n+        }\n+      }\n+    }\n+    return new ArrayList<>(sourceFieldNames);\n+  }\n+\n+  /**\n+   * Validates that for a field spec with transform function, the source column name and destination column name are exclusive\n+   * i.e. do not allow using source column name for destination column\n+   * 1. Transform function of a field spec should not use the destination column\n+   * 2. TimeFieldSpec - cannot have same name for incoming and outgoing field spec, if the specs are different\n+   */\n+  public static boolean validate(Schema schema) {\n+    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n+      if (!fieldSpec.isVirtualColumn()) {\n+        String column = fieldSpec.getName();\n+        String transformFunction = fieldSpec.getTransformFunction();\n+        if (transformFunction != null) {\n+          ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+          if (expressionEvaluator != null) {\n+            List<String> arguments = expressionEvaluator.getArguments();\n+            // output column used as input\n+            if (arguments.contains(column)) {\n+              LOGGER.error(\"The arguments of transform function: {}, should not contain the destination column: {}\",\n+                  transformFunction, column);\n+              return false;\n+            }\n+          }\n+        } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n+          TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n+          TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n+          TimeGranularitySpec outgoingGranularitySpec = timeFieldSpec.getOutgoingGranularitySpec();\n+          // different incoming and outgoing spec, but same name\n+          if (outgoingGranularitySpec != null && !incomingGranularitySpec.equals(outgoingGranularitySpec)", "originalCommit": "2570bf792aa94dca41909cdd3c9a09b223285b74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NzU3Mw==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408477573", "bodyText": "(nit) outgoingGranularitySpec will never be null because it will return incoming spec if outgoing is not set", "author": "Jackie-Jiang", "createdAt": "2020-04-14T22:40:26Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.SchemaFieldExtractorUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, if conversion is needed, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  @Nullable\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    String columnName = fieldSpec.getName();\n+    String transformExpression = fieldSpec.getTransformFunction();\n+    if (transformExpression != null) {\n+\n+      // if transform function expression present, use it to generate function evaluator\n+      try {\n+        expressionEvaluator = getExpressionEvaluator(transformExpression);\n+      } catch (Exception e) {\n+        LOGGER.error(\n+            \"Caught exception while constructing expression evaluator for transform expression: {}, of column: {}, skipping\",\n+            transformExpression, columnName, e);\n+      }\n+    } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n+\n+      // for backward compatible handling of TIME field conversion\n+      TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n+      TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n+      TimeGranularitySpec outgoingGranularitySpec = timeFieldSpec.getOutgoingGranularitySpec();\n+      if (outgoingGranularitySpec != null && !incomingGranularitySpec.equals(outgoingGranularitySpec)", "originalCommit": "2570bf792aa94dca41909cdd3c9a09b223285b74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "aa723c8b4ef6113594a06b4c94bce7ddb91c43e4", "url": "https://github.com/apache/pinot/commit/aa723c8b4ef6113594a06b4c94bce7ddb91c43e4", "message": "Handle case where transformed destination value already exists in the record", "committedDate": "2020-04-15T00:40:28Z", "type": "commit"}, {"oid": "8cb07c0fd9baab32ee4977c34ee8a319d4b3a925", "url": "https://github.com/apache/pinot/commit/8cb07c0fd9baab32ee4977c34ee8a319d4b3a925", "message": "Make extract return Set. Exceptions from ExpressionEvaluatorFactory", "committedDate": "2020-04-15T01:37:25Z", "type": "commit"}, {"oid": "e3b81b7e5fc49833f5175bb07d2746589917737d", "url": "https://github.com/apache/pinot/commit/e3b81b7e5fc49833f5175bb07d2746589917737d", "message": "Fix brokern test", "committedDate": "2020-04-15T01:42:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzMzUwNA==", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408533504", "bodyText": "This should also take a set", "author": "Jackie-Jiang", "createdAt": "2020-04-15T01:48:24Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordExtractor.java", "diffHunk": "@@ -18,16 +18,29 @@\n  */\n package org.apache.pinot.spi.data.readers;\n \n-import org.apache.pinot.spi.data.Schema;\n+import java.util.List;\n \n+\n+/**\n+ * Extracts fields from input records\n+ * @param <T> The format of the input record\n+ */\n public interface RecordExtractor<T> {\n+\n+  /**\n+   * Initialize the record extractor with its config\n+   *\n+   * @param fields List of field names to extract from the provided input record\n+   * @param recordExtractorConfig The record extractor config\n+   */\n+  void init(List<String> fields, RecordExtractorConfig recordExtractorConfig);", "originalCommit": "e3b81b7e5fc49833f5175bb07d2746589917737d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "55a1cf9ea867a47fc086367aa4b5909fd04ce4f6", "url": "https://github.com/apache/pinot/commit/55a1cf9ea867a47fc086367aa4b5909fd04ce4f6", "message": "Make fields a set in the interface, fix tests, fix quickstart", "committedDate": "2020-04-15T17:50:57Z", "type": "commit"}, {"oid": "de3031d5fb29b3c5f193879ce24927d433dfd2c8", "url": "https://github.com/apache/pinot/commit/de3031d5fb29b3c5f193879ce24927d433dfd2c8", "message": "Comment about supported datatypes in GenericRow", "committedDate": "2020-04-15T19:07:47Z", "type": "commit"}]}