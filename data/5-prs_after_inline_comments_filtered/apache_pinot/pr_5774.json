{"pr_number": 5774, "pr_title": "Config recommendation engine", "pr_createdAt": "2020-07-30T18:42:04Z", "pr_url": "https://github.com/apache/pinot/pull/5774", "timeline": [{"oid": "94edd3c8127a90cbb23e9ec260043bc263ecd2fd", "url": "https://github.com/apache/pinot/commit/94edd3c8127a90cbb23e9ec260043bc263ecd2fd", "message": "Rebase config recommender on master", "committedDate": "2020-08-04T21:16:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5MzY1NQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465793655", "bodyText": "We should also use @consumes annotation right?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:02:36Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotTableRestletResource.java", "diffHunk": "@@ -141,6 +142,18 @@ public SuccessResponse addTable(String tableConfigStr) {\n     }\n   }\n \n+  @PUT\n+  @Produces(MediaType.APPLICATION_JSON)", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MDAwNg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465940006", "bodyText": "got it", "author": "jasperjiaguo", "createdAt": "2020-08-05T19:02:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5MzY1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMwMDI2Mg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r467300262", "bodyText": "I stayed with only @Produces(MediaType.APPLICATION_JSON) to follow the pattern of other APIs", "author": "jasperjiaguo", "createdAt": "2020-08-07T21:56:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5MzY1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5MzczOA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465793738", "bodyText": "A concise javadoc would be helpful explaining the purpose of each class. No need to explain the algorithm, but bullet-list items explaining the responsibility of the class", "author": "siddharthteotia", "createdAt": "2020-08-05T15:02:42Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/RecommenderDriver.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n+import java.io.IOException;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.exceptions.InvalidInputException;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.RulesToExecute;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+\n+public class RecommenderDriver {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMwMDM0Nw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r467300347", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-07T21:56:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5MzczOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5MzgxNw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465793817", "bodyText": "IIUC, this is the output side right?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:02:49Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/ConfigManager.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io;\n+\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import org.apache.pinot.controller.recommender.rules.io.FlaggedQueries;\n+import org.apache.pinot.controller.recommender.rules.io.configs.IndexConfig;\n+import org.apache.pinot.controller.recommender.rules.io.configs.PartitionConfig;\n+\n+\n+public class ConfigManager {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTkyMTQ0NA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465921444", "bodyText": "Yes I will add java docs...", "author": "jasperjiaguo", "createdAt": "2020-08-05T18:28:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5MzgxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5Mzg3Ng==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465793876", "bodyText": "javadoc please", "author": "siddharthteotia", "createdAt": "2020-08-05T15:02:53Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/InputManager.java", "diffHunk": "@@ -0,0 +1,519 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io;\n+\n+import com.fasterxml.jackson.annotation.JsonAutoDetect;\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.pinot.controller.recommender.io.exceptions.InvalidInputException;\n+import org.apache.pinot.controller.recommender.io.metadata.ColumnMetaData;\n+import org.apache.pinot.controller.recommender.io.metadata.SchemaWithMetaData;\n+import org.apache.pinot.controller.recommender.rules.RulesToExecute;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.FlagQueryRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.InvertedSortedIndexJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.spi.data.DimensionFieldSpec;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.MetricFieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.NONE)\n+public class InputManager {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzODYxMg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466638612", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-06T19:30:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5Mzg3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5Mzk2OQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465793969", "bodyText": "consider naming it numMessagesPerSecInKafKaTopic and add a comment stating this is applicable to realtime/hybrid table", "author": "siddharthteotia", "createdAt": "2020-08-05T15:02:59Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/InputManager.java", "diffHunk": "@@ -0,0 +1,519 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io;\n+\n+import com.fasterxml.jackson.annotation.JsonAutoDetect;\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.pinot.controller.recommender.io.exceptions.InvalidInputException;\n+import org.apache.pinot.controller.recommender.io.metadata.ColumnMetaData;\n+import org.apache.pinot.controller.recommender.io.metadata.SchemaWithMetaData;\n+import org.apache.pinot.controller.recommender.rules.RulesToExecute;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.FlagQueryRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.InvertedSortedIndexJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.spi.data.DimensionFieldSpec;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.MetricFieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.NONE)\n+public class InputManager {\n+  private final Logger LOGGER = LoggerFactory.getLogger(InputManager.class);\n+\n+  /******************************Deserialized from input json*********************************/\n+  // Basic input fields\n+  public RulesToExecute _rulesToExecute = new RulesToExecute(); // dictates which rules to execute\n+  public Schema _schema = new Schema();\n+  public SchemaWithMetaData _schemaWithMetaData = new SchemaWithMetaData();\n+\n+  public String _queryType = SQL; // SQL or PQL\n+  public long _qps = DEFAULT_QPS;\n+  public Map<String, Double> _queryWeightMap = new HashMap<>(); // {\"queryString\":\"queryWeight\"}\n+  public String _tableType = OFFLINE;\n+  public long _numMessagesPerSec = DEFAULT_NUM_MSG_PER_SEC; // messages per sec for kafka to consume", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MDMyMw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465940323", "bodyText": "got it", "author": "jasperjiaguo", "createdAt": "2020-08-05T19:03:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5Mzk2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDAxNQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794015", "bodyText": "I think we need to make the purpose of overwrittenConfigs more clear. IIUC, this works as follows:\nI as a user/dev wants to use the rule engine to recommend configs. However, based on my experience or due to a special optimization for a use case, I know that it will help to have inverted index on a particular column. But I still want to run the engine to recommend inverted indexes on other columns (if applicable) and recommend other configs (sorted, bloom etc). The engine will do it's job of recommending by taking into account the overwritten config and honoring it. In other words, the recommended config is going to be a super-set of the overwritten config. Is this understanding correct?\nWe should highlight the purpose clearly in comments", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:04Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/InputManager.java", "diffHunk": "@@ -0,0 +1,519 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io;\n+\n+import com.fasterxml.jackson.annotation.JsonAutoDetect;\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.pinot.controller.recommender.io.exceptions.InvalidInputException;\n+import org.apache.pinot.controller.recommender.io.metadata.ColumnMetaData;\n+import org.apache.pinot.controller.recommender.io.metadata.SchemaWithMetaData;\n+import org.apache.pinot.controller.recommender.rules.RulesToExecute;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.FlagQueryRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.InvertedSortedIndexJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.spi.data.DimensionFieldSpec;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.MetricFieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.NONE)\n+public class InputManager {\n+  private final Logger LOGGER = LoggerFactory.getLogger(InputManager.class);\n+\n+  /******************************Deserialized from input json*********************************/\n+  // Basic input fields\n+  public RulesToExecute _rulesToExecute = new RulesToExecute(); // dictates which rules to execute\n+  public Schema _schema = new Schema();\n+  public SchemaWithMetaData _schemaWithMetaData = new SchemaWithMetaData();\n+\n+  public String _queryType = SQL; // SQL or PQL\n+  public long _qps = DEFAULT_QPS;\n+  public Map<String, Double> _queryWeightMap = new HashMap<>(); // {\"queryString\":\"queryWeight\"}\n+  public String _tableType = OFFLINE;\n+  public long _numMessagesPerSec = DEFAULT_NUM_MSG_PER_SEC; // messages per sec for kafka to consume\n+  public long _numRecordsPerPush = DEFAULT_NUM_RECORDS_PER_PUSH; // records per push for offline part of a table\n+  public long _latencySLA = DEFAULT_LATENCY_SLA; // latency sla in ms\n+  public int _numKafkaPartitions = DEFAULT_NUM_KAFKA_PARTITIONS;\n+\n+  // The parameters of rules\n+  public PartitionRuleParams _partitionRuleParams = new PartitionRuleParams();\n+  public InvertedSortedIndexJointRuleParams _invertedSortedIndexJointRuleParams =\n+      new InvertedSortedIndexJointRuleParams();\n+  public BloomFilterRuleParams _bloomFilterRuleParams = new BloomFilterRuleParams();\n+  public NoDictionaryOnHeapDictionaryJointRuleParams _noDictionaryOnHeapDictionaryJointRuleParams =\n+      new NoDictionaryOnHeapDictionaryJointRuleParams();\n+  public FlagQueryRuleParams _flagQueryRuleParams = new FlagQueryRuleParams();\n+\n+  // For forward compatibility: 1. dev/sre to overwrite field(s) 2. incremental recommendation on existing/staging tables\n+  public ConfigManager _overWrittenConfigs = new ConfigManager();", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA5NjQyNA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466096424", "bodyText": "added comments", "author": "jasperjiaguo", "createdAt": "2020-08-06T01:42:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDAxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzODU0MA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466638540", "bodyText": "Added code comments", "author": "jasperjiaguo", "createdAt": "2020-08-06T19:30:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDAxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDA1OA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794058", "bodyText": "I don't think I fully understand why this should be ignored by the deserializer", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:07Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/InputManager.java", "diffHunk": "@@ -0,0 +1,519 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io;\n+\n+import com.fasterxml.jackson.annotation.JsonAutoDetect;\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.pinot.controller.recommender.io.exceptions.InvalidInputException;\n+import org.apache.pinot.controller.recommender.io.metadata.ColumnMetaData;\n+import org.apache.pinot.controller.recommender.io.metadata.SchemaWithMetaData;\n+import org.apache.pinot.controller.recommender.rules.RulesToExecute;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.FlagQueryRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.InvertedSortedIndexJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.spi.data.DimensionFieldSpec;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.MetricFieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.NONE)\n+public class InputManager {\n+  private final Logger LOGGER = LoggerFactory.getLogger(InputManager.class);\n+\n+  /******************************Deserialized from input json*********************************/\n+  // Basic input fields\n+  public RulesToExecute _rulesToExecute = new RulesToExecute(); // dictates which rules to execute\n+  public Schema _schema = new Schema();\n+  public SchemaWithMetaData _schemaWithMetaData = new SchemaWithMetaData();\n+\n+  public String _queryType = SQL; // SQL or PQL\n+  public long _qps = DEFAULT_QPS;\n+  public Map<String, Double> _queryWeightMap = new HashMap<>(); // {\"queryString\":\"queryWeight\"}\n+  public String _tableType = OFFLINE;\n+  public long _numMessagesPerSec = DEFAULT_NUM_MSG_PER_SEC; // messages per sec for kafka to consume\n+  public long _numRecordsPerPush = DEFAULT_NUM_RECORDS_PER_PUSH; // records per push for offline part of a table\n+  public long _latencySLA = DEFAULT_LATENCY_SLA; // latency sla in ms\n+  public int _numKafkaPartitions = DEFAULT_NUM_KAFKA_PARTITIONS;\n+\n+  // The parameters of rules\n+  public PartitionRuleParams _partitionRuleParams = new PartitionRuleParams();\n+  public InvertedSortedIndexJointRuleParams _invertedSortedIndexJointRuleParams =\n+      new InvertedSortedIndexJointRuleParams();\n+  public BloomFilterRuleParams _bloomFilterRuleParams = new BloomFilterRuleParams();\n+  public NoDictionaryOnHeapDictionaryJointRuleParams _noDictionaryOnHeapDictionaryJointRuleParams =\n+      new NoDictionaryOnHeapDictionaryJointRuleParams();\n+  public FlagQueryRuleParams _flagQueryRuleParams = new FlagQueryRuleParams();\n+\n+  // For forward compatibility: 1. dev/sre to overwrite field(s) 2. incremental recommendation on existing/staging tables\n+  public ConfigManager _overWrittenConfigs = new ConfigManager();\n+\n+  /******************************Ignored by deserializer****************************************/", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTkyNjc2Ng==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465926766", "bodyText": "The fields following this line are pre-processed from the input and used as algorithm input only, so no need to serialize/deserialize them using jackson.", "author": "jasperjiaguo", "createdAt": "2020-08-05T18:38:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MTQ2OA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465941468", "bodyText": "Got it. Thanks.", "author": "siddharthteotia", "createdAt": "2020-08-05T19:05:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDA1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDEwNQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794105", "bodyText": "Please see my comment above w.r.t explaining the purpose and usage of overwritten configs.", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:10Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/InputManager.java", "diffHunk": "@@ -0,0 +1,519 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io;\n+\n+import com.fasterxml.jackson.annotation.JsonAutoDetect;\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.pinot.controller.recommender.io.exceptions.InvalidInputException;\n+import org.apache.pinot.controller.recommender.io.metadata.ColumnMetaData;\n+import org.apache.pinot.controller.recommender.io.metadata.SchemaWithMetaData;\n+import org.apache.pinot.controller.recommender.rules.RulesToExecute;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.FlagQueryRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.InvertedSortedIndexJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.spi.data.DimensionFieldSpec;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.MetricFieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.NONE)\n+public class InputManager {\n+  private final Logger LOGGER = LoggerFactory.getLogger(InputManager.class);\n+\n+  /******************************Deserialized from input json*********************************/\n+  // Basic input fields\n+  public RulesToExecute _rulesToExecute = new RulesToExecute(); // dictates which rules to execute\n+  public Schema _schema = new Schema();\n+  public SchemaWithMetaData _schemaWithMetaData = new SchemaWithMetaData();\n+\n+  public String _queryType = SQL; // SQL or PQL\n+  public long _qps = DEFAULT_QPS;\n+  public Map<String, Double> _queryWeightMap = new HashMap<>(); // {\"queryString\":\"queryWeight\"}\n+  public String _tableType = OFFLINE;\n+  public long _numMessagesPerSec = DEFAULT_NUM_MSG_PER_SEC; // messages per sec for kafka to consume\n+  public long _numRecordsPerPush = DEFAULT_NUM_RECORDS_PER_PUSH; // records per push for offline part of a table\n+  public long _latencySLA = DEFAULT_LATENCY_SLA; // latency sla in ms\n+  public int _numKafkaPartitions = DEFAULT_NUM_KAFKA_PARTITIONS;\n+\n+  // The parameters of rules\n+  public PartitionRuleParams _partitionRuleParams = new PartitionRuleParams();\n+  public InvertedSortedIndexJointRuleParams _invertedSortedIndexJointRuleParams =\n+      new InvertedSortedIndexJointRuleParams();\n+  public BloomFilterRuleParams _bloomFilterRuleParams = new BloomFilterRuleParams();\n+  public NoDictionaryOnHeapDictionaryJointRuleParams _noDictionaryOnHeapDictionaryJointRuleParams =\n+      new NoDictionaryOnHeapDictionaryJointRuleParams();\n+  public FlagQueryRuleParams _flagQueryRuleParams = new FlagQueryRuleParams();\n+\n+  // For forward compatibility: 1. dev/sre to overwrite field(s) 2. incremental recommendation on existing/staging tables\n+  public ConfigManager _overWrittenConfigs = new ConfigManager();\n+\n+  /******************************Ignored by deserializer****************************************/\n+  public Map<String, ColumnMetaData> _metaDataMap = new HashMap<>(); // meta data per column, complement to schema\n+  long _sizePerRecord = 0;\n+  Map<String, FieldSpec.DataType> _colnameFieldTypeMap = new HashMap<>();\n+  Set<String> _dimNames = null;\n+  Set<String> _metricNames = null;\n+  Set<String> _dateTimeNames = null;\n+  Set<String> _dimNamesInveredSortedIndexApplicable = null;\n+  Map<String, Integer> _colNameToIntMap = null;\n+  String[] _intToColNameMap = null;\n+  Map<FieldSpec.DataType, Integer> _dataTypeSizeMap = new HashMap<FieldSpec.DataType, Integer>() {{\n+    put(FieldSpec.DataType.INT, DEFAULT_INT_SIZE);\n+    put(FieldSpec.DataType.LONG, DEFAULT_LONG_SIZE);\n+    put(FieldSpec.DataType.FLOAT, DEFAULT_FLOAT_SIZE);\n+    put(FieldSpec.DataType.DOUBLE, DEFAULT_DOUBLE_SIZE);\n+    put(FieldSpec.DataType.BYTES, DEFAULT_BYTE_SIZE);\n+    put(FieldSpec.DataType.STRING, DEFAULT_CHAR_SIZE);\n+    put(null, DEFAULT_NULL_SIZE);\n+  }};\n+\n+  /**\n+   * Process the dependencies incurred by overwritten configs.", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDE4OA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794188", "bodyText": "Why did we move this class to the recommender? Is it not being used elsewhere?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:18Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/exceptions/InvalidInputException.java", "diffHunk": "@@ -16,14 +16,12 @@\n  * specific language governing permissions and limitations\n  * under the License.\n  */\n-package org.apache.pinot.tools.tuner.query.src.stats.wrapper;\n+package org.apache.pinot.controller.recommender.io.exceptions;", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTkzMDAzMw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465930033", "bodyText": "The tuner package was the old code for index recommender. I did reuse some of the old code, so github shows I'm moving some files from the old package. But I'm not sure why this happens in InvalidInputException class as it is completely new. The old  index recommender is not used anywhere right now so I removed  the sources completely.", "author": "jasperjiaguo", "createdAt": "2020-08-05T18:44:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDE4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MTU5Ng==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465941596", "bodyText": "Got it. Thanks", "author": "siddharthteotia", "createdAt": "2020-08-05T19:05:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDE4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDI0MA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794240", "bodyText": "We have an existing class ColumnMetadata in pinot-core. Although, this is in a different package so there shouldn't be any conflict. But, just to avoid any confusion (intellij will display both files as the user starts typing the name in file search), please consider renaming it.", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:23Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/metadata/ColumnMetaData.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io.metadata;\n+\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import org.apache.pinot.spi.data.FieldSpec;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.DEFAULT_AVERAGE_NUM_VALUES_PER_ENTRY;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.DEFAULT_CARDINALITY;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.DEFAULT_DATA_LENGTH;\n+\n+\n+/**\n+ * The metadata of a column\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class ColumnMetaData extends FieldSpec {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MTg2OQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465941869", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-05T19:06:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDI0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDMwNQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794305", "bodyText": "This should be a new class/interface for the recommender right? Why are we moving an existing class? or is this a github issue?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:28Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/AbstractRule.java", "diffHunk": "@@ -16,22 +16,19 @@\n  * specific language governing permissions and limitations\n  * under the License.\n  */\n-package org.apache.pinot.tools.tuner.query.src.parser;\n+package org.apache.pinot.controller.recommender.rules;\n \n-import javax.annotation.Nullable;\n-import org.apache.pinot.tools.tuner.query.src.stats.wrapper.AbstractQueryStats;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n \n \n-/**\n- * Parser interface for a query line\n- */\n-public interface QueryParser {\n-  /**\n-   * parse the the complete log line to a parsed obj\n-   * @param line the complete log line to be parsed, InputIterator should put broken lines together\n-   * @return the parsed log line obj\n-   */\n-  @Nullable\n-  AbstractQueryStats parse(String line);\n-}\n+public abstract class AbstractRule {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTkzMjAzMQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465932031", "bodyText": "Please see the above conversation.", "author": "jasperjiaguo", "createdAt": "2020-08-05T18:48:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDMwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MTk2Nw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465941967", "bodyText": "Got it. They came from tuner", "author": "siddharthteotia", "createdAt": "2020-08-05T19:06:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDMwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDM3OQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794379", "bodyText": "Javadoc would be nice", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:33Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/RulesToExecute.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules;\n+\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.impl.BloomFilterRule;\n+import org.apache.pinot.controller.recommender.rules.impl.FlagQueryRule;\n+import org.apache.pinot.controller.recommender.rules.impl.InvertedSortedIndexJointRule;\n+import org.apache.pinot.controller.recommender.rules.impl.KafkaPartitionRule;\n+import org.apache.pinot.controller.recommender.rules.impl.NoDictionaryOnHeapDictionaryJointRule;\n+import org.apache.pinot.controller.recommender.rules.impl.PinotTablePartitionRule;\n+import org.apache.pinot.controller.recommender.rules.impl.VariedLengthDictionaryRule;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.RulesToExecute.*;\n+\n+\n+public class RulesToExecute {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAyNDkyNg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466024926", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:51:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDM3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDQ5NA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794494", "bodyText": "The enum name shouldn't really have \"plural\". The enum although defines multiple constants, it represents only 1 of them at a give time. So, we should simply call it Rule?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:43Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/RulesToExecute.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules;\n+\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.impl.BloomFilterRule;\n+import org.apache.pinot.controller.recommender.rules.impl.FlagQueryRule;\n+import org.apache.pinot.controller.recommender.rules.impl.InvertedSortedIndexJointRule;\n+import org.apache.pinot.controller.recommender.rules.impl.KafkaPartitionRule;\n+import org.apache.pinot.controller.recommender.rules.impl.NoDictionaryOnHeapDictionaryJointRule;\n+import org.apache.pinot.controller.recommender.rules.impl.PinotTablePartitionRule;\n+import org.apache.pinot.controller.recommender.rules.impl.VariedLengthDictionaryRule;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.RulesToExecute.*;\n+\n+\n+public class RulesToExecute {\n+  public static class RuleFactory {\n+    public static AbstractRule getRule(Rules rule, InputManager inputManager, ConfigManager outputManager) {\n+      switch (rule) {\n+        case FlagQueryRule:\n+          return new FlagQueryRule(inputManager, outputManager);\n+        case InvertedSortedIndexJointRule:\n+          return new InvertedSortedIndexJointRule(inputManager, outputManager);\n+        case KafkaPartitionRule:\n+          return new KafkaPartitionRule(inputManager, outputManager);\n+        case PinotTablePartitionRule:\n+          return new PinotTablePartitionRule(inputManager, outputManager);\n+        case BloomFilterRule:\n+          return new BloomFilterRule(inputManager, outputManager);\n+        case NoDictionaryOnHeapDictionaryJointRule:\n+          return new NoDictionaryOnHeapDictionaryJointRule(inputManager, outputManager);\n+        case VariedLengthDictionaryRule:\n+          return new VariedLengthDictionaryRule(inputManager, outputManager);\n+        default:\n+          return null;\n+      }\n+    }\n+  }\n+  // All rules will execute by default unless explicitly specifying \"recommendInvertedSortedIndexJoint\" = \"false\"\n+  boolean _recommendKafkaPartition = DEFAULT_RECOMMEND_KAFKA_PARTITION;\n+  boolean _recommendPinotTablePartition = DEFAULT_RECOMMEND_PINOT_TABLE_PARTITION;\n+  boolean _recommendInvertedSortedIndexJoint = DEFAULT_RECOMMEND_INVERTED_SORTED_INDEX_JOINT;\n+  boolean _recommendBloomFilter = DEFAULT_RECOMMEND_BLOOM_FILTER;\n+  boolean _recommendNoDictionaryOnHeapDictionaryJoint = DEFAULT_RECOMMEND_NO_DICTIONARY_ONHEAP_DICTIONARY_JOINT;\n+  boolean _recommendVariedLengthDictionary = DEFAULT_RECOMMEND_VARIED_LENGTH_DICTIONARY;\n+  boolean _recommendFlagQuery = DEFAULT_RECOMMEND_FLAG_QUERY;\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRecommendVariedLengthDictionary(boolean recommendVariedLengthDictionary) {\n+    _recommendVariedLengthDictionary = recommendVariedLengthDictionary;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRecommendFlagQuery(boolean recommendFlagQuery) {\n+    _recommendFlagQuery = recommendFlagQuery;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRecommendNoDictionaryOnHeapDictionaryJoint(boolean recommendNoDictionaryOnHeapDictionaryJoint) {\n+    _recommendNoDictionaryOnHeapDictionaryJoint = recommendNoDictionaryOnHeapDictionaryJoint;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRecommendKafkaPartition(boolean recommendKafkaPartition) {\n+    _recommendKafkaPartition = recommendKafkaPartition;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRecommendInvertedSortedIndexJoint(boolean recommendInvertedSortedIndexJoint) {\n+    _recommendInvertedSortedIndexJoint = recommendInvertedSortedIndexJoint;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRecommendPinotTablePartition(boolean recommendPinotTablePartition) {\n+    _recommendPinotTablePartition = recommendPinotTablePartition;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRecommendBloomFilter(boolean recommendBloomFilter) {\n+    _recommendBloomFilter = recommendBloomFilter;\n+  }\n+\n+  public boolean isRecommendVariedLengthDictionary() {\n+    return _recommendVariedLengthDictionary;\n+  }\n+\n+  public boolean isRecommendFlagQuery() {\n+    return _recommendFlagQuery;\n+  }\n+\n+  public boolean isRecommendNoDictionaryOnHeapDictionaryJoint() {\n+    return _recommendNoDictionaryOnHeapDictionaryJoint;\n+  }\n+\n+  public boolean isRecommendKafkaPartition() {\n+    return _recommendKafkaPartition;\n+  }\n+\n+  public boolean isRecommendInvertedSortedIndexJoint() {\n+    return _recommendInvertedSortedIndexJoint;\n+  }\n+\n+  public boolean isRecommendPinotTablePartition() {\n+    return _recommendPinotTablePartition;\n+  }\n+\n+  public boolean isRecommendBloomFilter() {\n+    return _recommendBloomFilter;\n+  }\n+\n+  public enum Rules {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAyNDg4NQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466024885", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:51:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDQ5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDUzOA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794538", "bodyText": "Please add javadoc and brief explanation of the rule's algorithm. We already have that in the design, so just englishize it here :)", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:47Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/BloomFilterRule.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import com.google.common.util.concurrent.AtomicDouble;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class  BloomFilterRule extends AbstractRule {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA5OTcwNA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466099704", "bodyText": "Done", "author": "jasperjiaguo", "createdAt": "2020-08-06T01:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDUzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzODI1NA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466638254", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-06T19:29:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDUzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDYwMA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794600", "bodyText": "Mark this is as a TODO since it can be easily spotted in the code if someone stumbles upon it in the future.\nTODO: once Pinot starts supporting bloom filter based pruning for IN, !=, NOT IN, we should enhance the algorithm of this rule.", "author": "siddharthteotia", "createdAt": "2020-08-05T15:03:53Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/BloomFilterRule.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import com.google.common.util.concurrent.AtomicDouble;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+public class  BloomFilterRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(BloomFilterRule.class);\n+  private final BloomFilterRuleParams _params;\n+  protected final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+\n+  public BloomFilterRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    _params = inputManager.getBloomFilterRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    int numDims = _inputManager.getNumDims();\n+    double[] weights = new double[numDims];\n+    AtomicDouble totalWeight = new AtomicDouble(0);\n+\n+    // For each query, find out the dimensions used in 'EQ'\n+    // and accumulate the (weighted) frequencies\n+    _inputManager.getQueryWeightMap().forEach((query,weight) -> {\n+      totalWeight.addAndGet(weight);\n+      FixedLenBitset fixedLenBitset = parseQuery(query);\n+      LOGGER.debug(\"fixedLenBitset {}\", fixedLenBitset);\n+      for (Integer i : fixedLenBitset.getOffsets()) {\n+        weights[i] += weight;\n+      }\n+    });\n+    LOGGER.debug(\"Weight: {}, Total {}\", weights, totalWeight);\n+\n+    for (int i = 0; i < numDims; i++) {\n+      String dimName = _inputManager.intToColName(i);\n+      if (((weights[i] / totalWeight.get()) > _params.THRESHOLD_MIN_PERCENT_EQ_BLOOMFILTER)\n+          //The partitioned dimension should be frequently > P used\n+          && (_inputManager.getCardinality(dimName)\n+          < _params.THRESHOLD_MAX_CARDINALITY_BLOOMFILTER)) { //The Cardinality < C (1 million for 1MB size)\n+        _outputManager.getIndexConfig().getBloomFilterColumns().add(dimName);\n+      }\n+    }\n+  }\n+\n+  public FixedLenBitset parseQuery(String queryString) {\n+    LOGGER.debug(\"Parsing query: {}\", queryString);\n+    if (queryString == null) {\n+      return FixedLenBitset.IMMUTABLE_EMPTY_SET;\n+    }\n+\n+    BrokerRequest brokerRequest;\n+    AbstractCompiler parser = PinotQueryParserFactory.get(_inputManager.getQueryType());\n+    try {\n+      brokerRequest = parser.compileToBrokerRequest(queryString);\n+    } catch (SqlCompilationException e) {\n+      LOGGER.error(\"Error parsing query: {}, {}\", queryString, e.getMessage());\n+      return FixedLenBitset.IMMUTABLE_EMPTY_SET;\n+    }\n+    BrokerRequest optimizedRequest = _brokerRequestOptimizer.optimize(brokerRequest, _inputManager.getTimeCol());\n+    QueryContext queryContext = BrokerRequestToQueryContextConverter.convert(optimizedRequest);\n+\n+    if (queryContext.getFilter() == null) {\n+      return FixedLenBitset.IMMUTABLE_EMPTY_SET;\n+    }\n+\n+    LOGGER.trace(\"Parsing Where Clause: {}\", queryContext.getFilter().toString());\n+    return parsePredicateList(queryContext.getFilter());\n+  }\n+\n+  /**\n+   * The partitioned dimension should used in the \u201c=\u201d \uff08IN, NOT IN, != are not using bloom filter in Pinot for now) filter.\n+   * @param filterContext filterContext", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3OTA3Mg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466079072", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-06T00:37:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDYwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDkwMQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794901", "bodyText": "Please add javadoc and brief explanation of the algorithm (please do this for all rules)", "author": "siddharthteotia", "createdAt": "2020-08-05T15:04:19Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/NoDictionaryOnHeapDictionaryJointRule.java", "diffHunk": "@@ -0,0 +1,245 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import com.google.common.util.concurrent.AtomicDouble;\n+import java.util.HashSet;\n+import java.util.Set;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static java.lang.Math.min;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.NoDictionaryOnHeapDictionaryJointRule.*;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.REALTIME;\n+\n+\n+public class NoDictionaryOnHeapDictionaryJointRule extends AbstractRule {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzODMyNw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466638327", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-06T19:30:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDkwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDk1MQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465794951", "bodyText": "Not sure if I follow this. If the column is in filter and group by, why do we have to consider the frequency?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:04:23Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/NoDictionaryOnHeapDictionaryJointRule.java", "diffHunk": "@@ -0,0 +1,245 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import com.google.common.util.concurrent.AtomicDouble;\n+import java.util.HashSet;\n+import java.util.Set;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static java.lang.Math.min;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.NoDictionaryOnHeapDictionaryJointRule.*;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.REALTIME;\n+\n+\n+public class NoDictionaryOnHeapDictionaryJointRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(NoDictionaryOnHeapDictionaryJointRule.class);\n+  private final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+  private final NoDictionaryOnHeapDictionaryJointRuleParams _params;\n+\n+  public NoDictionaryOnHeapDictionaryJointRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    _params = inputManager.getNoDictionaryOnHeapDictionaryJointRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    LOGGER.info(\"Recommending no dictionary and on-heap dictionaries\");\n+\n+    int numCols = _inputManager.getNumCols();\n+    double[] filterGroupByWeights = new double[numCols];\n+    double[] selectionWeights = new double[numCols];\n+    AtomicDouble totalWeight = new AtomicDouble(0);\n+\n+    //**********No dictionary recommendation*******/\n+    Set<String> noDictCols = new HashSet<>(_inputManager.getColNameToIntMap().keySet());\n+\n+    //Exclude cols with index\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getInvertedIndexColumns());\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getSortedColumn());\n+    // TODO: Remove this after range index is implemented for no-dictionary\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getRangeIndexColumns());\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+    //Find out columns used in filter&groupby and selection and corresponding frequencies\n+    _inputManager.getQueryWeightMap().forEach((query, weight) -> {\n+      parseQuery(query, weight, filterGroupByWeights, selectionWeights);\n+      totalWeight.addAndGet(weight);\n+    });\n+\n+    //Add dictionary on columns used in filter&groupby , with frequency > threshold\n+    for (int i = 0; i < numCols; i++) {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MzYxNg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465943616", "bodyText": "Add a comment explaining the rationale", "author": "siddharthteotia", "createdAt": "2020-08-05T19:09:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDk1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3ODM5MA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466078390", "bodyText": "resolved", "author": "jasperjiaguo", "createdAt": "2020-08-06T00:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NDk1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NjYzMQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465796631", "bodyText": "Might want to add comment about the experiment done during the design phase -- for a column heavily used in selection only (not part of filter or group by), making it no dictionary reduces the latency by 20% (I guess) since we avoid the 2 lookups.", "author": "siddharthteotia", "createdAt": "2020-08-05T15:06:49Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/NoDictionaryOnHeapDictionaryJointRule.java", "diffHunk": "@@ -0,0 +1,245 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import com.google.common.util.concurrent.AtomicDouble;\n+import java.util.HashSet;\n+import java.util.Set;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static java.lang.Math.min;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.NoDictionaryOnHeapDictionaryJointRule.*;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.REALTIME;\n+\n+\n+public class NoDictionaryOnHeapDictionaryJointRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(NoDictionaryOnHeapDictionaryJointRule.class);\n+  private final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+  private final NoDictionaryOnHeapDictionaryJointRuleParams _params;\n+\n+  public NoDictionaryOnHeapDictionaryJointRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    _params = inputManager.getNoDictionaryOnHeapDictionaryJointRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    LOGGER.info(\"Recommending no dictionary and on-heap dictionaries\");\n+\n+    int numCols = _inputManager.getNumCols();\n+    double[] filterGroupByWeights = new double[numCols];\n+    double[] selectionWeights = new double[numCols];\n+    AtomicDouble totalWeight = new AtomicDouble(0);\n+\n+    //**********No dictionary recommendation*******/\n+    Set<String> noDictCols = new HashSet<>(_inputManager.getColNameToIntMap().keySet());\n+\n+    //Exclude cols with index\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getInvertedIndexColumns());\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getSortedColumn());\n+    // TODO: Remove this after range index is implemented for no-dictionary\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getRangeIndexColumns());\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+    //Find out columns used in filter&groupby and selection and corresponding frequencies\n+    _inputManager.getQueryWeightMap().forEach((query, weight) -> {\n+      parseQuery(query, weight, filterGroupByWeights, selectionWeights);\n+      totalWeight.addAndGet(weight);\n+    });\n+\n+    //Add dictionary on columns used in filter&groupby , with frequency > threshold\n+    for (int i = 0; i < numCols; i++) {\n+      double filterGroupByFreq = filterGroupByWeights[i] / totalWeight.get();\n+      if (filterGroupByFreq > _params.THRESHOLD_MIN_FILTER_FREQ_DICTIONARY) {\n+        noDictCols.remove(_inputManager.intToColName(i));\n+      }\n+    }\n+\n+    LOGGER.debug(\"filterGroupByWeights {}, selectionWeights{}, totalWeight{} \", filterGroupByWeights, selectionWeights,\n+        totalWeight);\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+\n+    for (int i = 0; i < numCols; i++) {\n+      // No dictionary on columns frequently used in selection", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0NzYyNA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465947624", "bodyText": "It looks like we can improve the performance of this loop starting at line 94 by going over the remaining columns", "author": "siddharthteotia", "createdAt": "2020-08-05T19:17:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NjYzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3ODMyMg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466078322", "bodyText": "added", "author": "jasperjiaguo", "createdAt": "2020-08-06T00:34:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5NjYzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5ODI3MQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465798271", "bodyText": "General question - Would it be possible to parse the query exactly once before the execution of first rule begins? Right now, it seems like as the rules are fired in order, each rule will parse the input query set? Even though the algorithm of each rule is different, is it possible to parse once and extract all the common info needed by all the rules?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:09:12Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/NoDictionaryOnHeapDictionaryJointRule.java", "diffHunk": "@@ -0,0 +1,245 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import com.google.common.util.concurrent.AtomicDouble;\n+import java.util.HashSet;\n+import java.util.Set;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static java.lang.Math.min;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.NoDictionaryOnHeapDictionaryJointRule.*;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.REALTIME;\n+\n+\n+public class NoDictionaryOnHeapDictionaryJointRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(NoDictionaryOnHeapDictionaryJointRule.class);\n+  private final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+  private final NoDictionaryOnHeapDictionaryJointRuleParams _params;\n+\n+  public NoDictionaryOnHeapDictionaryJointRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    _params = inputManager.getNoDictionaryOnHeapDictionaryJointRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    LOGGER.info(\"Recommending no dictionary and on-heap dictionaries\");\n+\n+    int numCols = _inputManager.getNumCols();\n+    double[] filterGroupByWeights = new double[numCols];\n+    double[] selectionWeights = new double[numCols];\n+    AtomicDouble totalWeight = new AtomicDouble(0);\n+\n+    //**********No dictionary recommendation*******/\n+    Set<String> noDictCols = new HashSet<>(_inputManager.getColNameToIntMap().keySet());\n+\n+    //Exclude cols with index\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getInvertedIndexColumns());\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getSortedColumn());\n+    // TODO: Remove this after range index is implemented for no-dictionary\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getRangeIndexColumns());\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+    //Find out columns used in filter&groupby and selection and corresponding frequencies\n+    _inputManager.getQueryWeightMap().forEach((query, weight) -> {\n+      parseQuery(query, weight, filterGroupByWeights, selectionWeights);\n+      totalWeight.addAndGet(weight);\n+    });\n+\n+    //Add dictionary on columns used in filter&groupby , with frequency > threshold\n+    for (int i = 0; i < numCols; i++) {\n+      double filterGroupByFreq = filterGroupByWeights[i] / totalWeight.get();\n+      if (filterGroupByFreq > _params.THRESHOLD_MIN_FILTER_FREQ_DICTIONARY) {\n+        noDictCols.remove(_inputManager.intToColName(i));\n+      }\n+    }\n+\n+    LOGGER.debug(\"filterGroupByWeights {}, selectionWeights{}, totalWeight{} \", filterGroupByWeights, selectionWeights,\n+        totalWeight);\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+\n+    for (int i = 0; i < numCols; i++) {\n+      // No dictionary on columns frequently used in selection\n+      double selectionFreq = selectionWeights[i] / totalWeight.get();\n+      if (selectionFreq > _params.THRESHOLD_MAX_SELECTION_FREQ_DICTIONARY) {\n+        continue;\n+      }\n+\n+      // Add dictionary on columns NOT frequently used in selection\n+      // AND can save storage > threshold\n+      String colName = _inputManager.intToColName(i);\n+      double noDictSize;\n+      double withDictSize;\n+      long colDataSizeWithoutDictionary = _inputManager.getColDataSizeWithoutDictionary(colName);\n+      double numValuesPerEntry = _inputManager.getNumValuesPerEntry(colName);\n+      int bitCompressedDataSize = _inputManager.getBitCompressedDataSize(colName);\n+      long dictionarySize = _inputManager.getDictionarySize(colName);\n+      double cardinality = _inputManager.getCardinality(colName);\n+      long numRecordsPerPush = _inputManager.getNumRecordsPerPush();\n+      LOGGER.debug(\"colDataSizeWithoutDictionary {}\", colDataSizeWithoutDictionary);\n+      LOGGER.debug(\"bitCompressedDataSize {}\", bitCompressedDataSize);\n+      LOGGER.debug(\"dictionarySize {}\", dictionarySize);\n+      LOGGER.debug(\"numValuesPerEntry {}\", numValuesPerEntry);\n+\n+      if (_inputManager.getTableType().equalsIgnoreCase(REALTIME)) {\n+        //TODO: improve this estimation\n+        noDictSize = // size of one segment flushed ith no dictionary\n+            colDataSizeWithoutDictionary * numValuesPerEntry * _params.SEGMENT_FLUSH_TIME;\n+        withDictSize = // size of one flushed segment with dictionary\n+            dictionarySize + bitCompressedDataSize * numValuesPerEntry * _params.SEGMENT_FLUSH_TIME;\n+      } else { // For hybrid or offline table, nodictionary follows the offline side\n+        noDictSize = // size of all segments in one push  with no dictionary\n+            colDataSizeWithoutDictionary * numValuesPerEntry * numRecordsPerPush;\n+        withDictSize = // size of all segments in one push with dictionary\n+            dictionarySize * dictionaryCoefficient(cardinality, numRecordsPerPush) * DEFAUlT_NUM_PARTITIONS\n+                + bitCompressedDataSize * numValuesPerEntry * numRecordsPerPush;\n+      }\n+\n+      double storageSaved = (double) (noDictSize - withDictSize) / noDictSize;\n+      LOGGER.debug(\"colName {}, noDictSize {}, withDictSize{}, storageSaved{}\", colName, noDictSize, withDictSize,\n+          storageSaved);\n+\n+      if (storageSaved > _params.THRESHOLD_MIN_PERCENT_DICTIONARY_STORAGE_SVAE) {\n+        noDictCols.remove(colName);\n+      }\n+    }\n+\n+    // Add the no dictionary cols to config\n+    _outputManager.getIndexConfig().getNoDictionaryColumns().addAll(noDictCols);\n+\n+    //**********On heap dictionary recommendation*******/\n+    if (_inputManager.getQps() > _params.THRESHOLD_MIN_QPS_ON_HEAP) { // QPS > THRESHOLD_MIN_QPS_ON_HEAP\n+      for (String colName : _inputManager.getColNameToIntMap().keySet()) {\n+        if (!_outputManager.getIndexConfig().getNoDictionaryColumns().contains(colName)) //exclude no dictionary column\n+        {\n+          long dictionarySize = _inputManager.getDictionarySize(colName);\n+          int colId = _inputManager.colNameToInt(colName);\n+          double filterGroupByFreq = filterGroupByWeights[colId] / totalWeight.get();\n+          if (filterGroupByFreq > _params.THRESHOLD_MIN_FILTER_FREQ_ON_HEAP  //frequently used in filter/group by\n+              && dictionarySize < _params.THRESHOLD_MAX_DICTIONARY_SIZE_ON_HEAP) { // memory foot print < threshold\n+            _outputManager.getIndexConfig().getOnHeapDictionaryColumns().add(colName);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private double dictionaryCoefficient(double cardinality, long numRecordsPerPush) {\n+    return 1 - min(max(DEFAULT_DICT_COEFF_A * Math.log(DEFAULT_DICT_COEFF_B * cardinality / numRecordsPerPush),\n+        DEFAULT_DICT_LOWER), DEFAULT_DICT_UPPER);\n+  }\n+\n+  public void parseQuery(String queryString, double weight, double[] filterGroupByWeights, double[] selectionWeights) {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzODExNg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466638116", "bodyText": "resolved - the code will parse only once", "author": "jasperjiaguo", "createdAt": "2020-08-06T19:29:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTc5ODI3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwMDI3OA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465800278", "bodyText": "We can simplify this by not bringing numValuesPerEntry into the equation. numValuesPerEntry is applicable to MV columns right? Pinot currently doesn't support raw MV columns so they are always dictionary encoded", "author": "siddharthteotia", "createdAt": "2020-08-05T15:11:58Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/NoDictionaryOnHeapDictionaryJointRule.java", "diffHunk": "@@ -0,0 +1,245 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import com.google.common.util.concurrent.AtomicDouble;\n+import java.util.HashSet;\n+import java.util.Set;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static java.lang.Math.min;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.NoDictionaryOnHeapDictionaryJointRule.*;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.REALTIME;\n+\n+\n+public class NoDictionaryOnHeapDictionaryJointRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(NoDictionaryOnHeapDictionaryJointRule.class);\n+  private final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+  private final NoDictionaryOnHeapDictionaryJointRuleParams _params;\n+\n+  public NoDictionaryOnHeapDictionaryJointRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    _params = inputManager.getNoDictionaryOnHeapDictionaryJointRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    LOGGER.info(\"Recommending no dictionary and on-heap dictionaries\");\n+\n+    int numCols = _inputManager.getNumCols();\n+    double[] filterGroupByWeights = new double[numCols];\n+    double[] selectionWeights = new double[numCols];\n+    AtomicDouble totalWeight = new AtomicDouble(0);\n+\n+    //**********No dictionary recommendation*******/\n+    Set<String> noDictCols = new HashSet<>(_inputManager.getColNameToIntMap().keySet());\n+\n+    //Exclude cols with index\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getInvertedIndexColumns());\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getSortedColumn());\n+    // TODO: Remove this after range index is implemented for no-dictionary\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getRangeIndexColumns());\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+    //Find out columns used in filter&groupby and selection and corresponding frequencies\n+    _inputManager.getQueryWeightMap().forEach((query, weight) -> {\n+      parseQuery(query, weight, filterGroupByWeights, selectionWeights);\n+      totalWeight.addAndGet(weight);\n+    });\n+\n+    //Add dictionary on columns used in filter&groupby , with frequency > threshold\n+    for (int i = 0; i < numCols; i++) {\n+      double filterGroupByFreq = filterGroupByWeights[i] / totalWeight.get();\n+      if (filterGroupByFreq > _params.THRESHOLD_MIN_FILTER_FREQ_DICTIONARY) {\n+        noDictCols.remove(_inputManager.intToColName(i));\n+      }\n+    }\n+\n+    LOGGER.debug(\"filterGroupByWeights {}, selectionWeights{}, totalWeight{} \", filterGroupByWeights, selectionWeights,\n+        totalWeight);\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+\n+    for (int i = 0; i < numCols; i++) {\n+      // No dictionary on columns frequently used in selection\n+      double selectionFreq = selectionWeights[i] / totalWeight.get();\n+      if (selectionFreq > _params.THRESHOLD_MAX_SELECTION_FREQ_DICTIONARY) {\n+        continue;\n+      }\n+\n+      // Add dictionary on columns NOT frequently used in selection\n+      // AND can save storage > threshold\n+      String colName = _inputManager.intToColName(i);\n+      double noDictSize;\n+      double withDictSize;\n+      long colDataSizeWithoutDictionary = _inputManager.getColDataSizeWithoutDictionary(colName);\n+      double numValuesPerEntry = _inputManager.getNumValuesPerEntry(colName);\n+      int bitCompressedDataSize = _inputManager.getBitCompressedDataSize(colName);\n+      long dictionarySize = _inputManager.getDictionarySize(colName);\n+      double cardinality = _inputManager.getCardinality(colName);\n+      long numRecordsPerPush = _inputManager.getNumRecordsPerPush();\n+      LOGGER.debug(\"colDataSizeWithoutDictionary {}\", colDataSizeWithoutDictionary);\n+      LOGGER.debug(\"bitCompressedDataSize {}\", bitCompressedDataSize);\n+      LOGGER.debug(\"dictionarySize {}\", dictionarySize);\n+      LOGGER.debug(\"numValuesPerEntry {}\", numValuesPerEntry);\n+\n+      if (_inputManager.getTableType().equalsIgnoreCase(REALTIME)) {\n+        //TODO: improve this estimation\n+        noDictSize = // size of one segment flushed ith no dictionary\n+            colDataSizeWithoutDictionary * numValuesPerEntry * _params.SEGMENT_FLUSH_TIME;", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwMDkxNQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465800915", "bodyText": "We should add a TODO though -- stating to enhance this to consider MV columns as noDictionary in the future when Pinot supports that", "author": "siddharthteotia", "createdAt": "2020-08-05T15:12:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwMDI3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA1ODI3MQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466058271", "bodyText": "Done. Thanks for bring out this!", "author": "jasperjiaguo", "createdAt": "2020-08-05T23:25:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwMDI3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwNjI0Mw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465806243", "bodyText": "Why is DEFAULT_NUM_PARTITIONS used here?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:20:02Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/NoDictionaryOnHeapDictionaryJointRule.java", "diffHunk": "@@ -0,0 +1,245 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import com.google.common.util.concurrent.AtomicDouble;\n+import java.util.HashSet;\n+import java.util.Set;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static java.lang.Math.min;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.NoDictionaryOnHeapDictionaryJointRule.*;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.REALTIME;\n+\n+\n+public class NoDictionaryOnHeapDictionaryJointRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(NoDictionaryOnHeapDictionaryJointRule.class);\n+  private final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+  private final NoDictionaryOnHeapDictionaryJointRuleParams _params;\n+\n+  public NoDictionaryOnHeapDictionaryJointRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    _params = inputManager.getNoDictionaryOnHeapDictionaryJointRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    LOGGER.info(\"Recommending no dictionary and on-heap dictionaries\");\n+\n+    int numCols = _inputManager.getNumCols();\n+    double[] filterGroupByWeights = new double[numCols];\n+    double[] selectionWeights = new double[numCols];\n+    AtomicDouble totalWeight = new AtomicDouble(0);\n+\n+    //**********No dictionary recommendation*******/\n+    Set<String> noDictCols = new HashSet<>(_inputManager.getColNameToIntMap().keySet());\n+\n+    //Exclude cols with index\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getInvertedIndexColumns());\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getSortedColumn());\n+    // TODO: Remove this after range index is implemented for no-dictionary\n+    noDictCols.removeAll(_outputManager.getIndexConfig().getRangeIndexColumns());\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+    //Find out columns used in filter&groupby and selection and corresponding frequencies\n+    _inputManager.getQueryWeightMap().forEach((query, weight) -> {\n+      parseQuery(query, weight, filterGroupByWeights, selectionWeights);\n+      totalWeight.addAndGet(weight);\n+    });\n+\n+    //Add dictionary on columns used in filter&groupby , with frequency > threshold\n+    for (int i = 0; i < numCols; i++) {\n+      double filterGroupByFreq = filterGroupByWeights[i] / totalWeight.get();\n+      if (filterGroupByFreq > _params.THRESHOLD_MIN_FILTER_FREQ_DICTIONARY) {\n+        noDictCols.remove(_inputManager.intToColName(i));\n+      }\n+    }\n+\n+    LOGGER.debug(\"filterGroupByWeights {}, selectionWeights{}, totalWeight{} \", filterGroupByWeights, selectionWeights,\n+        totalWeight);\n+    LOGGER.debug(\"noDictCols {}\", noDictCols);\n+\n+    for (int i = 0; i < numCols; i++) {\n+      // No dictionary on columns frequently used in selection\n+      double selectionFreq = selectionWeights[i] / totalWeight.get();\n+      if (selectionFreq > _params.THRESHOLD_MAX_SELECTION_FREQ_DICTIONARY) {\n+        continue;\n+      }\n+\n+      // Add dictionary on columns NOT frequently used in selection\n+      // AND can save storage > threshold\n+      String colName = _inputManager.intToColName(i);\n+      double noDictSize;\n+      double withDictSize;\n+      long colDataSizeWithoutDictionary = _inputManager.getColDataSizeWithoutDictionary(colName);\n+      double numValuesPerEntry = _inputManager.getNumValuesPerEntry(colName);\n+      int bitCompressedDataSize = _inputManager.getBitCompressedDataSize(colName);\n+      long dictionarySize = _inputManager.getDictionarySize(colName);\n+      double cardinality = _inputManager.getCardinality(colName);\n+      long numRecordsPerPush = _inputManager.getNumRecordsPerPush();\n+      LOGGER.debug(\"colDataSizeWithoutDictionary {}\", colDataSizeWithoutDictionary);\n+      LOGGER.debug(\"bitCompressedDataSize {}\", bitCompressedDataSize);\n+      LOGGER.debug(\"dictionarySize {}\", dictionarySize);\n+      LOGGER.debug(\"numValuesPerEntry {}\", numValuesPerEntry);\n+\n+      if (_inputManager.getTableType().equalsIgnoreCase(REALTIME)) {\n+        //TODO: improve this estimation\n+        noDictSize = // size of one segment flushed ith no dictionary\n+            colDataSizeWithoutDictionary * numValuesPerEntry * _params.SEGMENT_FLUSH_TIME;\n+        withDictSize = // size of one flushed segment with dictionary\n+            dictionarySize + bitCompressedDataSize * numValuesPerEntry * _params.SEGMENT_FLUSH_TIME;\n+      } else { // For hybrid or offline table, nodictionary follows the offline side\n+        noDictSize = // size of all segments in one push  with no dictionary\n+            colDataSizeWithoutDictionary * numValuesPerEntry * numRecordsPerPush;\n+        withDictSize = // size of all segments in one push with dictionary\n+            dictionarySize * dictionaryCoefficient(cardinality, numRecordsPerPush) * DEFAUlT_NUM_PARTITIONS", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwNzQxMw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465807413", "bodyText": "you can probably remove the \"*\". It just adds minor overhead to the logger", "author": "siddharthteotia", "createdAt": "2020-08-05T15:21:39Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/PinotTablePartitionRule.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.InPredicate;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+public class PinotTablePartitionRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(PinotTablePartitionRule.class);\n+  PartitionRuleParams _params;\n+\n+  protected final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+\n+  public PinotTablePartitionRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    this._params = inputManager.getPartitionRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    //**********Calculate size per record***************/\n+    _inputManager.estimateSizePerRecord();\n+    //**************************************************/\n+\n+    LOGGER.info(\"Recommending partition configurations\");\n+\n+    if (_inputManager.getQps()\n+        < _params.THRESHOLD_MIN_QPS_PARTITION) { //For a table whose QPS < Q (say 200 or 300) NO partitioning is needed.\n+      LOGGER.info(\"*Input QPS {} < threshold {}, no partition needed\", _inputManager.getQps(),\n+          _params.THRESHOLD_MIN_QPS_PARTITION);\n+      return;\n+    }\n+    if (_inputManager.getLatencySLA()\n+        > _params.THRESHOLD_MAX_SLA_PARTITION) { //For a table whose latency SLA > L (say 1000ms) NO partitioning is needed.\n+      LOGGER.info(\"*Input SLA {} > threshold {}, no partition needed\", _inputManager.getLatencySLA(),\n+          _params.THRESHOLD_MAX_SLA_PARTITION);\n+      return;\n+    }\n+\n+    LOGGER.info(\"*Recommending partition number\");", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwOTk1Ng==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465809956", "bodyText": "(nit): suggest changing it to \"Recommending number of partitions\"", "author": "siddharthteotia", "createdAt": "2020-08-05T15:25:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwNzQxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwOTE5NQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465809195", "bodyText": "We can actually simplify the code here. Currently we are writing the code for offline and realtime.\nWe can compute once for offline (if type is OFFLINE or HYBRID)\nWe can compute once for realtime (if type if REALTIME or HYBRID)\nThis will clenup the if-else block here", "author": "siddharthteotia", "createdAt": "2020-08-05T15:24:11Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/PinotTablePartitionRule.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.InPredicate;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+public class PinotTablePartitionRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(PinotTablePartitionRule.class);\n+  PartitionRuleParams _params;\n+\n+  protected final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+\n+  public PinotTablePartitionRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    this._params = inputManager.getPartitionRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    //**********Calculate size per record***************/\n+    _inputManager.estimateSizePerRecord();\n+    //**************************************************/\n+\n+    LOGGER.info(\"Recommending partition configurations\");\n+\n+    if (_inputManager.getQps()\n+        < _params.THRESHOLD_MIN_QPS_PARTITION) { //For a table whose QPS < Q (say 200 or 300) NO partitioning is needed.\n+      LOGGER.info(\"*Input QPS {} < threshold {}, no partition needed\", _inputManager.getQps(),\n+          _params.THRESHOLD_MIN_QPS_PARTITION);\n+      return;\n+    }\n+    if (_inputManager.getLatencySLA()\n+        > _params.THRESHOLD_MAX_SLA_PARTITION) { //For a table whose latency SLA > L (say 1000ms) NO partitioning is needed.\n+      LOGGER.info(\"*Input SLA {} > threshold {}, no partition needed\", _inputManager.getLatencySLA(),\n+          _params.THRESHOLD_MAX_SLA_PARTITION);\n+      return;\n+    }\n+\n+    LOGGER.info(\"*Recommending partition number\");\n+    if (_inputManager.getTableType().equalsIgnoreCase(\n+        REALTIME)) { //real time partition num should be the same value as the number of kafka partitions", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA3NjA3MQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466076071", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-06T00:26:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgwOTE5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMTEwOQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465811109", "bodyText": "I think our check-style will complain for using * import. We should import specifically", "author": "siddharthteotia", "createdAt": "2020-08-05T15:26:54Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/PartitionRuleParams.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.PartitionRule.*;", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjczMDkzMQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466730931", "bodyText": "mvn checkstyle:check success so we should be fine", "author": "jasperjiaguo", "createdAt": "2020-08-06T23:03:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMTEwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMTgyOQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465811829", "bodyText": "Please add javadoc and a short one-line comment explaining the purpose of each configuration. Please try to do this for all param classes.", "author": "siddharthteotia", "createdAt": "2020-08-05T15:27:58Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/PartitionRuleParams.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.PartitionRule.*;\n+\n+\n+public class PartitionRuleParams {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzNzgyMA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466637820", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-06T19:29:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMTgyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMTkwOQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465811909", "bodyText": "Please add javadoc", "author": "siddharthteotia", "createdAt": "2020-08-05T15:28:06Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/RecommenderConstants.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+public class RecommenderConstants {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzNzc1OQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466637759", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-06T19:29:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMTkwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMTk0NQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465811945", "bodyText": "a very short one line comment above each configuration (at least for the ones that are not self explanatory and intuitive from the name)", "author": "siddharthteotia", "createdAt": "2020-08-05T15:28:09Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/RecommenderConstants.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+public class RecommenderConstants {\n+  public static class InvertedSortedIndexJointRule {\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_FUNCTION = 0.5d;", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxODU0Nw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466018547", "bodyText": "Will add the comments in the *Params class for parameters", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:37:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMTk0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxNzYwNA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465817604", "bodyText": "typo in name?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:36:31Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/NoDictionaryOnHeapDictionaryJointRuleParams.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.NoDictionaryOnHeapDictionaryJointRule.*;\n+\n+\n+public class NoDictionaryOnHeapDictionaryJointRuleParams {\n+  public Double THRESHOLD_MIN_PERCENT_DICTIONARY_STORAGE_SVAE = DEFAULT_THRESHOLD_MIN_PERCENT_DICTIONARY_STORAGE_SVAE;", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxNzQ3NQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466017475", "bodyText": "fixed", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:34:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxNzYwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxODYzMw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465818633", "bodyText": "include latency in the name", "author": "siddharthteotia", "createdAt": "2020-08-05T15:37:59Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/RecommenderConstants.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+public class RecommenderConstants {\n+  public static class InvertedSortedIndexJointRule {\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_FUNCTION = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_TEXT_MATCH = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_RANGE = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_REGEX = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_ISNULL = 0.5d;\n+    public static final double DEFAULT_THRESHOLD_MIN_AND_PREDICATE_INCREMENTAL_VOTE = 0.6d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_AND_PREDICATE_TOP_CANDIDATES = 0.8d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_GAIN_DIFF_BETWEEN_ITERATION = 0.05d;\n+    public static final int DEFAULT_MAX_NUM_ITERATION_WITHOUT_GAIN = 3;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_NESI_FOR_TOP_CANDIDATES = 0.7d;\n+  }\n+\n+  public static class RulesToExecute {\n+    public static final boolean DEFAULT_RECOMMEND_FLAG_QUERY = true;\n+    public static final boolean DEFAULT_RECOMMEND_VARIED_LENGTH_DICTIONARY = true;\n+    public static final boolean DEFAULT_RECOMMEND_KAFKA_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_PINOT_TABLE_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_INVERTED_SORTED_INDEX_JOINT = true;\n+    public static final boolean DEFAULT_RECOMMEND_BLOOM_FILTER = true;\n+    public static final boolean DEFAULT_RECOMMEND_NO_DICTIONARY_ONHEAP_DICTIONARY_JOINT = true;\n+  }\n+\n+  public static class PartitionRule {\n+    public static final int DEFAULT_NUM_PARTITIONS = 0;\n+\n+    public static final long DEFAULT_THRESHOLD_MAX_SLA_PARTITION = 1000;", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxNzE3OQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466017179", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:34:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxODYzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgyMDU1Mg==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465820552", "bodyText": "I don't think we should accept input if QPS, latency, num messages per second in kafka topic and number of records pushed per day are not specified. It is something user (or whoever is getting the recommendation) needs to know. So, we should not have any defaults for these 4.", "author": "siddharthteotia", "createdAt": "2020-08-05T15:40:45Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/RecommenderConstants.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+public class RecommenderConstants {\n+  public static class InvertedSortedIndexJointRule {\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_FUNCTION = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_TEXT_MATCH = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_RANGE = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_REGEX = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_ISNULL = 0.5d;\n+    public static final double DEFAULT_THRESHOLD_MIN_AND_PREDICATE_INCREMENTAL_VOTE = 0.6d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_AND_PREDICATE_TOP_CANDIDATES = 0.8d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_GAIN_DIFF_BETWEEN_ITERATION = 0.05d;\n+    public static final int DEFAULT_MAX_NUM_ITERATION_WITHOUT_GAIN = 3;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_NESI_FOR_TOP_CANDIDATES = 0.7d;\n+  }\n+\n+  public static class RulesToExecute {\n+    public static final boolean DEFAULT_RECOMMEND_FLAG_QUERY = true;\n+    public static final boolean DEFAULT_RECOMMEND_VARIED_LENGTH_DICTIONARY = true;\n+    public static final boolean DEFAULT_RECOMMEND_KAFKA_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_PINOT_TABLE_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_INVERTED_SORTED_INDEX_JOINT = true;\n+    public static final boolean DEFAULT_RECOMMEND_BLOOM_FILTER = true;\n+    public static final boolean DEFAULT_RECOMMEND_NO_DICTIONARY_ONHEAP_DICTIONARY_JOINT = true;\n+  }\n+\n+  public static class PartitionRule {\n+    public static final int DEFAULT_NUM_PARTITIONS = 0;\n+\n+    public static final long DEFAULT_THRESHOLD_MAX_SLA_PARTITION = 1000;\n+    public static final long DEFAULT_THRESHOLD_MIN_QPS_PARTITION = 200;\n+    public static final long DEFAULT_OPTIMAL_SIZE_PER_SEGMENT = 2000_000_000; //2GB\n+    public static final long DEFAULT_KAFKA_NUM_MESSAGES_PER_SEC_PER_PARTITION = 250;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_DIMENSION_PARTITION_TOP_CANDIDATES = 0.8d;\n+    public static final int DEFAULT_THRESHOLD_MAX_IN_LENGTH = 4;\n+  }\n+\n+  public static class BloomFilterRule {\n+    public static final long DEFAULT_THRESHOLD_MAX_CARDINALITY_BLOOMFILTER = 1000_000;\n+    public static final double DEFAULT_THRESHOLD_MIN_PERCENT_EQ_BLOOMFILTER = 0.5d;\n+  }\n+\n+  public static class NoDictionaryOnHeapDictionaryJointRule {\n+    public static final double DEFAULT_THRESHOLD_MIN_FILTER_FREQ_DICTIONARY = 0d;\n+    public static final double DEFAULT_THRESHOLD_MAX_SELECTION_FREQ_DICTIONARY = 0.3d;\n+    public static final long DEFAULT_THRESHOLD_MIN_QPS_ON_HEAP = 10_000;\n+    public static final long DEFAULT_THRESHOLD_MAX_DICTIONARY_SIZE_ON_HEAP = 1000_000L;\n+    public static final double DEFAULT_THRESHOLD_MIN_FILTER_FREQ_ON_HEAP = 0.3d;\n+    public static final double DEFAULT_THRESHOLD_MIN_PERCENT_DICTIONARY_STORAGE_SVAE = 0.95;\n+\n+    public static final double DEFAULT_DICT_COEFF_A = 0.217769;\n+    public static final double DEFAULT_DICT_COEFF_B = 89.0975;\n+    public static final double DEFAULT_DICT_LOWER = 0;\n+    public static final double DEFAULT_DICT_UPPER = 0;\n+    public static final int DEFAUlT_NUM_PARTITIONS = 16;\n+\n+    public static final int DEFAULT_SEGMENT_FLUSH_TIME = 86400;\n+  }\n+\n+  public static class FlagQueryRuleParams{\n+    public static final long DEFAULT_THRESHOLD_MAX_LIMIT_SIZE = 100000;\n+    public static final String WARNING_NO_FILTERING = \"Warning: No filtering in ths query\";\n+    public static final String WARNING_NO_TIME_COL = \"Warning: No time column used in ths query\";\n+    public static final String WARNING_TOO_LONG_LIMIT = \"Warning: The size of LIMIT is longer than \" + DEFAULT_THRESHOLD_MAX_LIMIT_SIZE;\n+    public static final String ERROR_INVALID_QUERY = \"Error: query not able to parse, skipped\";\n+  }\n+\n+  public static final String PQL = \"pql\";\n+  public static final String SQL = \"sql\";\n+  public static final String OFFLINE = \"offline\";\n+  public static final String REALTIME = \"realtime\";\n+  public static final String HYBRID = \"hybrid\";\n+  public static final int NO_SUCH_COL = -1;\n+  public static final double DEFAULT_CARDINALITY = 1;\n+  public static final double MIN_CARDINALITY = 1;\n+  public static final double DEFAULT_AVERAGE_NUM_VALUES_PER_ENTRY = 1d;", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAzMDA5OA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466030098", "bodyText": "done, I think on Dino side he can probably make these fields \"required\"", "author": "jasperjiaguo", "createdAt": "2020-08-05T22:03:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgyMDU1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgyMjA5Mw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465822093", "bodyText": "I don't think you need to have DEFAULT_FLOAT/INT/LONG etc size. These are fixed width columns and will always be same as specified in their respective classes. -- Float.BYTES, Long.BYTES etc", "author": "siddharthteotia", "createdAt": "2020-08-05T15:42:55Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/RecommenderConstants.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+public class RecommenderConstants {\n+  public static class InvertedSortedIndexJointRule {\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_FUNCTION = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_TEXT_MATCH = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_RANGE = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_REGEX = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_ISNULL = 0.5d;\n+    public static final double DEFAULT_THRESHOLD_MIN_AND_PREDICATE_INCREMENTAL_VOTE = 0.6d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_AND_PREDICATE_TOP_CANDIDATES = 0.8d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_GAIN_DIFF_BETWEEN_ITERATION = 0.05d;\n+    public static final int DEFAULT_MAX_NUM_ITERATION_WITHOUT_GAIN = 3;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_NESI_FOR_TOP_CANDIDATES = 0.7d;\n+  }\n+\n+  public static class RulesToExecute {\n+    public static final boolean DEFAULT_RECOMMEND_FLAG_QUERY = true;\n+    public static final boolean DEFAULT_RECOMMEND_VARIED_LENGTH_DICTIONARY = true;\n+    public static final boolean DEFAULT_RECOMMEND_KAFKA_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_PINOT_TABLE_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_INVERTED_SORTED_INDEX_JOINT = true;\n+    public static final boolean DEFAULT_RECOMMEND_BLOOM_FILTER = true;\n+    public static final boolean DEFAULT_RECOMMEND_NO_DICTIONARY_ONHEAP_DICTIONARY_JOINT = true;\n+  }\n+\n+  public static class PartitionRule {\n+    public static final int DEFAULT_NUM_PARTITIONS = 0;\n+\n+    public static final long DEFAULT_THRESHOLD_MAX_SLA_PARTITION = 1000;\n+    public static final long DEFAULT_THRESHOLD_MIN_QPS_PARTITION = 200;\n+    public static final long DEFAULT_OPTIMAL_SIZE_PER_SEGMENT = 2000_000_000; //2GB\n+    public static final long DEFAULT_KAFKA_NUM_MESSAGES_PER_SEC_PER_PARTITION = 250;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_DIMENSION_PARTITION_TOP_CANDIDATES = 0.8d;\n+    public static final int DEFAULT_THRESHOLD_MAX_IN_LENGTH = 4;\n+  }\n+\n+  public static class BloomFilterRule {\n+    public static final long DEFAULT_THRESHOLD_MAX_CARDINALITY_BLOOMFILTER = 1000_000;\n+    public static final double DEFAULT_THRESHOLD_MIN_PERCENT_EQ_BLOOMFILTER = 0.5d;\n+  }\n+\n+  public static class NoDictionaryOnHeapDictionaryJointRule {\n+    public static final double DEFAULT_THRESHOLD_MIN_FILTER_FREQ_DICTIONARY = 0d;\n+    public static final double DEFAULT_THRESHOLD_MAX_SELECTION_FREQ_DICTIONARY = 0.3d;\n+    public static final long DEFAULT_THRESHOLD_MIN_QPS_ON_HEAP = 10_000;\n+    public static final long DEFAULT_THRESHOLD_MAX_DICTIONARY_SIZE_ON_HEAP = 1000_000L;\n+    public static final double DEFAULT_THRESHOLD_MIN_FILTER_FREQ_ON_HEAP = 0.3d;\n+    public static final double DEFAULT_THRESHOLD_MIN_PERCENT_DICTIONARY_STORAGE_SVAE = 0.95;\n+\n+    public static final double DEFAULT_DICT_COEFF_A = 0.217769;\n+    public static final double DEFAULT_DICT_COEFF_B = 89.0975;\n+    public static final double DEFAULT_DICT_LOWER = 0;\n+    public static final double DEFAULT_DICT_UPPER = 0;\n+    public static final int DEFAUlT_NUM_PARTITIONS = 16;\n+\n+    public static final int DEFAULT_SEGMENT_FLUSH_TIME = 86400;\n+  }\n+\n+  public static class FlagQueryRuleParams{\n+    public static final long DEFAULT_THRESHOLD_MAX_LIMIT_SIZE = 100000;\n+    public static final String WARNING_NO_FILTERING = \"Warning: No filtering in ths query\";\n+    public static final String WARNING_NO_TIME_COL = \"Warning: No time column used in ths query\";\n+    public static final String WARNING_TOO_LONG_LIMIT = \"Warning: The size of LIMIT is longer than \" + DEFAULT_THRESHOLD_MAX_LIMIT_SIZE;\n+    public static final String ERROR_INVALID_QUERY = \"Error: query not able to parse, skipped\";\n+  }\n+\n+  public static final String PQL = \"pql\";\n+  public static final String SQL = \"sql\";\n+  public static final String OFFLINE = \"offline\";\n+  public static final String REALTIME = \"realtime\";\n+  public static final String HYBRID = \"hybrid\";\n+  public static final int NO_SUCH_COL = -1;\n+  public static final double DEFAULT_CARDINALITY = 1;\n+  public static final double MIN_CARDINALITY = 1;\n+  public static final double DEFAULT_AVERAGE_NUM_VALUES_PER_ENTRY = 1d;\n+  public static final int DEFAULT_QPS = 100;\n+  public static final int DEFAULT_LATENCY_SLA = 1000;\n+  public static final int DEFAULT_NUM_MSG_PER_SEC = 250;\n+  public static final int DEFAULT_NUM_RECORDS_PER_PUSH = 10000;\n+  public static final int DEFAULT_INT_SIZE = Integer.BYTES;\n+  public static final int DEFAULT_NULL_SIZE = 0;", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxNTc4NQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466015785", "bodyText": "Done", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:30:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgyMjA5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgyMzE3MQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465823171", "bodyText": "How are these coefficients used?", "author": "siddharthteotia", "createdAt": "2020-08-05T15:44:36Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/RecommenderConstants.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+public class RecommenderConstants {\n+  public static class InvertedSortedIndexJointRule {\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_FUNCTION = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_TEXT_MATCH = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_RANGE = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_REGEX = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_ISNULL = 0.5d;\n+    public static final double DEFAULT_THRESHOLD_MIN_AND_PREDICATE_INCREMENTAL_VOTE = 0.6d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_AND_PREDICATE_TOP_CANDIDATES = 0.8d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_GAIN_DIFF_BETWEEN_ITERATION = 0.05d;\n+    public static final int DEFAULT_MAX_NUM_ITERATION_WITHOUT_GAIN = 3;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_NESI_FOR_TOP_CANDIDATES = 0.7d;\n+  }\n+\n+  public static class RulesToExecute {\n+    public static final boolean DEFAULT_RECOMMEND_FLAG_QUERY = true;\n+    public static final boolean DEFAULT_RECOMMEND_VARIED_LENGTH_DICTIONARY = true;\n+    public static final boolean DEFAULT_RECOMMEND_KAFKA_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_PINOT_TABLE_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_INVERTED_SORTED_INDEX_JOINT = true;\n+    public static final boolean DEFAULT_RECOMMEND_BLOOM_FILTER = true;\n+    public static final boolean DEFAULT_RECOMMEND_NO_DICTIONARY_ONHEAP_DICTIONARY_JOINT = true;\n+  }\n+\n+  public static class PartitionRule {\n+    public static final int DEFAULT_NUM_PARTITIONS = 0;\n+\n+    public static final long DEFAULT_THRESHOLD_MAX_SLA_PARTITION = 1000;\n+    public static final long DEFAULT_THRESHOLD_MIN_QPS_PARTITION = 200;\n+    public static final long DEFAULT_OPTIMAL_SIZE_PER_SEGMENT = 2000_000_000; //2GB\n+    public static final long DEFAULT_KAFKA_NUM_MESSAGES_PER_SEC_PER_PARTITION = 250;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_DIMENSION_PARTITION_TOP_CANDIDATES = 0.8d;\n+    public static final int DEFAULT_THRESHOLD_MAX_IN_LENGTH = 4;\n+  }\n+\n+  public static class BloomFilterRule {\n+    public static final long DEFAULT_THRESHOLD_MAX_CARDINALITY_BLOOMFILTER = 1000_000;\n+    public static final double DEFAULT_THRESHOLD_MIN_PERCENT_EQ_BLOOMFILTER = 0.5d;\n+  }\n+\n+  public static class NoDictionaryOnHeapDictionaryJointRule {\n+    public static final double DEFAULT_THRESHOLD_MIN_FILTER_FREQ_DICTIONARY = 0d;\n+    public static final double DEFAULT_THRESHOLD_MAX_SELECTION_FREQ_DICTIONARY = 0.3d;\n+    public static final long DEFAULT_THRESHOLD_MIN_QPS_ON_HEAP = 10_000;\n+    public static final long DEFAULT_THRESHOLD_MAX_DICTIONARY_SIZE_ON_HEAP = 1000_000L;\n+    public static final double DEFAULT_THRESHOLD_MIN_FILTER_FREQ_ON_HEAP = 0.3d;\n+    public static final double DEFAULT_THRESHOLD_MIN_PERCENT_DICTIONARY_STORAGE_SVAE = 0.95;\n+", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMjc4Mw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466012783", "bodyText": "Will revisit this later today", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:24:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgyMzE3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgzNDk1MQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465834951", "bodyText": "It will also be very useful for reference to quote the study and analysis we had done for use case at Li. Please don't quote the table names. However, we should include the following general comments:\n\nFor realtime/hybrid, the number of partitions on realtime Pinot table side is same as number of kafka partitions. This is generally the case unless there is a reason for them to be different. We saw one outlier\nFor offline, the number of partitions on offline Pinot table side is dependent on the amount of data. For hybrid table, we have seen cases where this value = number of kafka partitions  = number of realtime table partitions. For hybrid table, we have also seen cases, where the value for offline is lower than realtime since the data generated on a given day is low volume and using a high count of number of partitions would lead to too many small sized segments since we typically have data from one partition in a segment.", "author": "siddharthteotia", "createdAt": "2020-08-05T16:01:52Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/impl/PinotTablePartitionRule.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.impl;\n+\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.core.query.request.context.ExpressionContext;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+import org.apache.pinot.core.query.request.context.predicate.InPredicate;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.core.query.request.context.utils.BrokerRequestToQueryContextConverter;\n+import org.apache.pinot.core.requesthandler.BrokerRequestOptimizer;\n+import org.apache.pinot.core.requesthandler.PinotQueryParserFactory;\n+import org.apache.pinot.parsers.AbstractCompiler;\n+import org.apache.pinot.sql.parsers.SqlCompilationException;\n+import org.apache.pinot.controller.recommender.io.ConfigManager;\n+import org.apache.pinot.controller.recommender.io.InputManager;\n+import org.apache.pinot.controller.recommender.rules.AbstractRule;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+public class PinotTablePartitionRule extends AbstractRule {\n+  private final Logger LOGGER = LoggerFactory.getLogger(PinotTablePartitionRule.class);\n+  PartitionRuleParams _params;\n+\n+  protected final BrokerRequestOptimizer _brokerRequestOptimizer = new BrokerRequestOptimizer();\n+\n+  public PinotTablePartitionRule(InputManager inputManager, ConfigManager outputManager) {\n+    super(inputManager, outputManager);\n+    this._params = inputManager.getPartitionRuleParams();\n+  }\n+\n+  @Override\n+  public void run() {\n+    //**********Calculate size per record***************/\n+    _inputManager.estimateSizePerRecord();\n+    //**************************************************/\n+\n+    LOGGER.info(\"Recommending partition configurations\");\n+\n+    if (_inputManager.getQps()\n+        < _params.THRESHOLD_MIN_QPS_PARTITION) { //For a table whose QPS < Q (say 200 or 300) NO partitioning is needed.\n+      LOGGER.info(\"*Input QPS {} < threshold {}, no partition needed\", _inputManager.getQps(),\n+          _params.THRESHOLD_MIN_QPS_PARTITION);\n+      return;\n+    }\n+    if (_inputManager.getLatencySLA()\n+        > _params.THRESHOLD_MAX_SLA_PARTITION) { //For a table whose latency SLA > L (say 1000ms) NO partitioning is needed.\n+      LOGGER.info(\"*Input SLA {} > threshold {}, no partition needed\", _inputManager.getLatencySLA(),\n+          _params.THRESHOLD_MAX_SLA_PARTITION);\n+      return;\n+    }\n+\n+    LOGGER.info(\"*Recommending partition number\");\n+    if (_inputManager.getTableType().equalsIgnoreCase(\n+        REALTIME)) { //real time partition num should be the same value as the number of kafka partitions\n+      _outputManager.getPartitionConfig()\n+          .setNumPartitionsRealtime(_outputManager.getPartitionConfig().getNumKafkaPartitions());\n+    } else if (_inputManager.getTableType().equalsIgnoreCase(OFFLINE)) {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMjMxMQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466012311", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:23:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgzNDk1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgzNTg0OA==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465835848", "bodyText": "I think 2GB is on the high end. Let's just start with 1GB probably", "author": "siddharthteotia", "createdAt": "2020-08-05T16:03:20Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/rules/io/params/RecommenderConstants.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.rules.io.params;\n+\n+public class RecommenderConstants {\n+  public static class InvertedSortedIndexJointRule {\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_FUNCTION = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_TEXT_MATCH = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_RANGE = 0.5d;\n+    public static final double DEAFULT_PERCENT_SELECT_FOR_REGEX = 0.5d;\n+    public static final double DEFAULT_PERCENT_SELECT_FOR_ISNULL = 0.5d;\n+    public static final double DEFAULT_THRESHOLD_MIN_AND_PREDICATE_INCREMENTAL_VOTE = 0.6d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_AND_PREDICATE_TOP_CANDIDATES = 0.8d;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_GAIN_DIFF_BETWEEN_ITERATION = 0.05d;\n+    public static final int DEFAULT_MAX_NUM_ITERATION_WITHOUT_GAIN = 3;\n+    public static final double DEFAULT_THRESHOLD_RATIO_MIN_NESI_FOR_TOP_CANDIDATES = 0.7d;\n+  }\n+\n+  public static class RulesToExecute {\n+    public static final boolean DEFAULT_RECOMMEND_FLAG_QUERY = true;\n+    public static final boolean DEFAULT_RECOMMEND_VARIED_LENGTH_DICTIONARY = true;\n+    public static final boolean DEFAULT_RECOMMEND_KAFKA_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_PINOT_TABLE_PARTITION = true;\n+    public static final boolean DEFAULT_RECOMMEND_INVERTED_SORTED_INDEX_JOINT = true;\n+    public static final boolean DEFAULT_RECOMMEND_BLOOM_FILTER = true;\n+    public static final boolean DEFAULT_RECOMMEND_NO_DICTIONARY_ONHEAP_DICTIONARY_JOINT = true;\n+  }\n+\n+  public static class PartitionRule {\n+    public static final int DEFAULT_NUM_PARTITIONS = 0;\n+\n+    public static final long DEFAULT_THRESHOLD_MAX_SLA_PARTITION = 1000;\n+    public static final long DEFAULT_THRESHOLD_MIN_QPS_PARTITION = 200;\n+    public static final long DEFAULT_OPTIMAL_SIZE_PER_SEGMENT = 2000_000_000; //2GB", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwNzYwMQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466007601", "bodyText": "changed to 1 GB", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:13:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgzNTg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NDQyOQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465954429", "bodyText": "This function is only computing the size of dictionary right? We should not include the size of bit compressed forward index", "author": "siddharthteotia", "createdAt": "2020-08-05T19:30:17Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/InputManager.java", "diffHunk": "@@ -0,0 +1,519 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io;\n+\n+import com.fasterxml.jackson.annotation.JsonAutoDetect;\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.pinot.controller.recommender.io.exceptions.InvalidInputException;\n+import org.apache.pinot.controller.recommender.io.metadata.ColumnMetaData;\n+import org.apache.pinot.controller.recommender.io.metadata.SchemaWithMetaData;\n+import org.apache.pinot.controller.recommender.rules.RulesToExecute;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.FlagQueryRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.InvertedSortedIndexJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.spi.data.DimensionFieldSpec;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.MetricFieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.NONE)\n+public class InputManager {\n+  private final Logger LOGGER = LoggerFactory.getLogger(InputManager.class);\n+\n+  /******************************Deserialized from input json*********************************/\n+  // Basic input fields\n+  public RulesToExecute _rulesToExecute = new RulesToExecute(); // dictates which rules to execute\n+  public Schema _schema = new Schema();\n+  public SchemaWithMetaData _schemaWithMetaData = new SchemaWithMetaData();\n+\n+  public String _queryType = SQL; // SQL or PQL\n+  public long _qps = DEFAULT_QPS;\n+  public Map<String, Double> _queryWeightMap = new HashMap<>(); // {\"queryString\":\"queryWeight\"}\n+  public String _tableType = OFFLINE;\n+  public long _numMessagesPerSec = DEFAULT_NUM_MSG_PER_SEC; // messages per sec for kafka to consume\n+  public long _numRecordsPerPush = DEFAULT_NUM_RECORDS_PER_PUSH; // records per push for offline part of a table\n+  public long _latencySLA = DEFAULT_LATENCY_SLA; // latency sla in ms\n+  public int _numKafkaPartitions = DEFAULT_NUM_KAFKA_PARTITIONS;\n+\n+  // The parameters of rules\n+  public PartitionRuleParams _partitionRuleParams = new PartitionRuleParams();\n+  public InvertedSortedIndexJointRuleParams _invertedSortedIndexJointRuleParams =\n+      new InvertedSortedIndexJointRuleParams();\n+  public BloomFilterRuleParams _bloomFilterRuleParams = new BloomFilterRuleParams();\n+  public NoDictionaryOnHeapDictionaryJointRuleParams _noDictionaryOnHeapDictionaryJointRuleParams =\n+      new NoDictionaryOnHeapDictionaryJointRuleParams();\n+  public FlagQueryRuleParams _flagQueryRuleParams = new FlagQueryRuleParams();\n+\n+  // For forward compatibility: 1. dev/sre to overwrite field(s) 2. incremental recommendation on existing/staging tables\n+  public ConfigManager _overWrittenConfigs = new ConfigManager();\n+\n+  /******************************Ignored by deserializer****************************************/\n+  public Map<String, ColumnMetaData> _metaDataMap = new HashMap<>(); // meta data per column, complement to schema\n+  long _sizePerRecord = 0;\n+  Map<String, FieldSpec.DataType> _colnameFieldTypeMap = new HashMap<>();\n+  Set<String> _dimNames = null;\n+  Set<String> _metricNames = null;\n+  Set<String> _dateTimeNames = null;\n+  Set<String> _dimNamesInveredSortedIndexApplicable = null;\n+  Map<String, Integer> _colNameToIntMap = null;\n+  String[] _intToColNameMap = null;\n+  Map<FieldSpec.DataType, Integer> _dataTypeSizeMap = new HashMap<FieldSpec.DataType, Integer>() {{\n+    put(FieldSpec.DataType.INT, DEFAULT_INT_SIZE);\n+    put(FieldSpec.DataType.LONG, DEFAULT_LONG_SIZE);\n+    put(FieldSpec.DataType.FLOAT, DEFAULT_FLOAT_SIZE);\n+    put(FieldSpec.DataType.DOUBLE, DEFAULT_DOUBLE_SIZE);\n+    put(FieldSpec.DataType.BYTES, DEFAULT_BYTE_SIZE);\n+    put(FieldSpec.DataType.STRING, DEFAULT_CHAR_SIZE);\n+    put(null, DEFAULT_NULL_SIZE);\n+  }};\n+\n+  /**\n+   * Process the dependencies incurred by overwritten configs.\n+   * E.g. we will subtract the dimensions with overwritten indices from _dimNames to get _dimNamesIndexApplicable\n+   * This ensures we do not recommend indices on those dimensions\n+   */\n+  public void init()\n+      throws InvalidInputException {\n+    LOGGER.info(\"Preprocessing Input:\");\n+    reorderDimsAndBuildMap();\n+    registerColnameFieldType();\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setFlagQueryRuleParams(FlagQueryRuleParams flagQueryRuleParams) {\n+    _flagQueryRuleParams = flagQueryRuleParams;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setNumKafkaPartitions(int numKafkaPartitions) {\n+    _numKafkaPartitions = numKafkaPartitions;\n+  }\n+\n+  @JsonSetter(value = \"queriesWithWeights\", nulls = Nulls.SKIP)\n+  public void setQueryWeightMap(Map<String, Double> queryWeightMap) {\n+    _queryWeightMap = queryWeightMap;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setNoDictionaryOnHeapDictionaryJointRuleParams(\n+      NoDictionaryOnHeapDictionaryJointRuleParams noDictionaryOnHeapDictionaryJointRuleParams) {\n+    _noDictionaryOnHeapDictionaryJointRuleParams = noDictionaryOnHeapDictionaryJointRuleParams;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setLatencySLA(int latencySLA) {\n+    _latencySLA = latencySLA;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setQps(long qps) {\n+    _qps = qps;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setBloomFilterRuleParams(BloomFilterRuleParams bloomFilterRuleParams) {\n+    _bloomFilterRuleParams = bloomFilterRuleParams;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setPartitionRuleParams(PartitionRuleParams partitionRuleParams) {\n+    _partitionRuleParams = partitionRuleParams;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setTableType(String tableType) {\n+    _tableType = tableType;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setNumMessagesPerSec(long numMessagesPerSec) {\n+    _numMessagesPerSec = numMessagesPerSec;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setNumRecordsPerPush(long numRecordsPerPush) {\n+    _numRecordsPerPush = numRecordsPerPush;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRulesToExecute(RulesToExecute rulesToExecute) {\n+    _rulesToExecute = rulesToExecute;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setSchema(JsonNode jsonNode)\n+      throws IOException {\n+    ObjectReader reader = new ObjectMapper().readerFor(Schema.class);\n+    this._schema=reader.readValue(jsonNode);\n+    reader = new ObjectMapper().readerFor(SchemaWithMetaData.class);\n+    this._schemaWithMetaData=reader.readValue(jsonNode);\n+    _schemaWithMetaData.getDimensionFieldSpecs()\n+        .forEach(columnMetaData -> {_metaDataMap.put(columnMetaData.getName(),columnMetaData);});\n+    _schemaWithMetaData.getMetricFieldSpecs()\n+        .forEach(columnMetaData -> {_metaDataMap.put(columnMetaData.getName(),columnMetaData);});\n+    _schemaWithMetaData.getDateTimeFieldSpecs()\n+        .forEach(columnMetaData -> {_metaDataMap.put(columnMetaData.getName(),columnMetaData);});\n+    _metaDataMap.put(_schemaWithMetaData.getTimeFieldSpec().getName(), _schemaWithMetaData.getTimeFieldSpec());\n+  }\n+\n+  @JsonIgnore\n+  public void setMetaDataMap(Map<String, ColumnMetaData> metaDataMap) {\n+    _metaDataMap = metaDataMap;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setQueryType(String queryType) {\n+    _queryType = queryType;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setInvertedSortedIndexJointRuleParams(\n+      InvertedSortedIndexJointRuleParams invertedSortedIndexJointRuleParams) {\n+    _invertedSortedIndexJointRuleParams = invertedSortedIndexJointRuleParams;\n+  }\n+\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setOverWrittenConfigs(ConfigManager overWrittenConfigs) {\n+    _overWrittenConfigs = overWrittenConfigs;\n+  }\n+\n+\n+  public FlagQueryRuleParams getFlagQueryRuleParams() {\n+    return _flagQueryRuleParams;\n+  }\n+\n+\n+  public FieldSpec.DataType getFieldType(String colName){\n+    return _colnameFieldTypeMap.getOrDefault(colName, null);\n+  }\n+\n+  public Map<String, Integer> getColNameToIntMap() {\n+    return _colNameToIntMap;\n+  }\n+\n+  /**\n+   * Get the number of dimensions we can apply indices on.\n+   * @return total number of dimensions minus number of dimensions with overwritten indices\n+   */\n+  public int getNumDimsInvertedSortedApplicable() {\n+    return _dimNamesInveredSortedIndexApplicable.size();\n+  }\n+\n+  public NoDictionaryOnHeapDictionaryJointRuleParams getNoDictionaryOnHeapDictionaryJointRuleParams() {\n+    return _noDictionaryOnHeapDictionaryJointRuleParams;\n+  }\n+\n+  public int getNumDims() {\n+    return _dimNames.size();\n+  }\n+\n+  public int getNumCols() {\n+    return _colNameToIntMap.size();\n+  }\n+\n+  //TODO: Currently Pinot is using only ONE time column specified by TimeFieldSpec\n+  //TODO: Change the implementation after the new schema with multiple _dateTimeNames is in use\n+  public String getTimeCol() {\n+    return _schema.getTimeFieldSpec().getName();\n+  }\n+\n+  public Set<String> getColNamesNoDictionary() {\n+    return _overWrittenConfigs.getIndexConfig().getNoDictionaryColumns();\n+  }\n+\n+  public long getLatencySLA() {\n+    return _latencySLA;\n+  }\n+\n+  public long getQps() {\n+    return _qps;\n+  }\n+\n+  public BloomFilterRuleParams getBloomFilterRuleParams() {\n+    return _bloomFilterRuleParams;\n+  }\n+\n+  public PartitionRuleParams getPartitionRuleParams() {\n+    return _partitionRuleParams;\n+  }\n+\n+  public String getTableType() {\n+    return _tableType;\n+  }\n+\n+  public Map<String, Double> getQueryWeightMap() {\n+    return _queryWeightMap;\n+  }\n+\n+  public long getNumMessagesPerSec() {\n+    return _numMessagesPerSec;\n+  }\n+\n+  public long getNumRecordsPerPush() {\n+    return _numRecordsPerPush;\n+  }\n+\n+  public RulesToExecute getRulesToExecute() {\n+    return _rulesToExecute;\n+  }\n+\n+  public Schema getSchema() {\n+    return _schema;\n+  }\n+\n+  @JsonIgnore\n+  public Map<String, ColumnMetaData> getMetaDataMap() {\n+    return _metaDataMap;\n+  }\n+\n+  public String getQueryType() {\n+    return _queryType;\n+  }\n+\n+  public InvertedSortedIndexJointRuleParams getInvertedSortedIndexJointRuleParams() {\n+    return _invertedSortedIndexJointRuleParams;\n+  }\n+\n+  public ConfigManager getOverWrittenConfigs() {\n+    return _overWrittenConfigs;\n+  }\n+\n+  public long getSizePerRecord() {\n+    return _sizePerRecord;\n+  }\n+\n+  public double getCardinality(String columnName) {\n+    return max(_metaDataMap.getOrDefault(columnName, new ColumnMetaData()).getCardinality(), MIN_CARDINALITY);\n+  }\n+\n+  public double getNumValuesPerEntry(String columnName) {\n+    return _metaDataMap.getOrDefault(columnName, new ColumnMetaData()).getNumValuesPerEntry();\n+  }\n+\n+  public int getAverageDataLen(String columnName) {\n+    return _metaDataMap.getOrDefault(columnName, new ColumnMetaData()).getAverageLength();\n+  }\n+\n+  public int getNumKafkaPartitions() {\n+    return _numKafkaPartitions;\n+  }\n+\n+  public boolean isIndexableDim(String colName) {\n+    return _dimNamesInveredSortedIndexApplicable.contains(colName);\n+  }\n+\n+  public boolean isSingleValueColumn(String colName){\n+    ColumnMetaData columnMetaData = _metaDataMap.getOrDefault(colName, new ColumnMetaData());\n+    return columnMetaData.isSingleValueField() && (columnMetaData.getNumValuesPerEntry() < DEFAULT_AVERAGE_NUM_VALUES_PER_ENTRY + EPSILON);\n+  }\n+\n+  /**\n+   * Map a index-applicable dimension name to an 0<=integer<getNumDimsInvertedSortedApplicable,\n+   * to be used with {@link FixedLenBitset}\n+   * @param colName a dimension with no overwritten index\n+   * @return a unique integer id\n+   */\n+  public int colNameToInt(String colName) {\n+    return _colNameToIntMap.getOrDefault(colName, NO_SUCH_COL);\n+  }\n+\n+  /**\n+   * A reverse process of colNameToInt\n+   * @param colID a unique integer id\n+   * @return column name\n+   */\n+  public String intToColName(int colID) {\n+    return _intToColNameMap[colID];\n+  }\n+\n+  /**\n+   * Test if colName is a valid dimension name\n+   */\n+  public boolean isDim(String colName) {\n+    return _dimNames.contains(colName);\n+  }\n+\n+  public boolean isDateTime(String colName) {\n+    return _schema.getTimeFieldSpec().getName().equals(colName);\n+  }\n+\n+  public void registerColnameFieldType() { // create a map from colname to data type\n+    for (DimensionFieldSpec dimensionFieldSpec : _schema.getDimensionFieldSpecs()) {\n+      _colnameFieldTypeMap.put(dimensionFieldSpec.getName(), dimensionFieldSpec.getDataType());\n+    }\n+    for (MetricFieldSpec metricFieldSpec : _schema.getMetricFieldSpecs()) {\n+      _colnameFieldTypeMap.put(metricFieldSpec.getName(), metricFieldSpec.getDataType());\n+    }\n+    //TODO: add support for multiple getDateTimeFieldSpecs\n+    _colnameFieldTypeMap.put(_schema.getTimeFieldSpec().getName(), _schema.getTimeFieldSpec().getDataType());\n+  }\n+\n+  public void estimateSizePerRecord() {\n+    for (String colName : _colnameFieldTypeMap.keySet()) {\n+      _sizePerRecord += getColDataSizeWithDictionary(colName);\n+      LOGGER.debug(\"{} {}\",colName, getColDataSizeWithDictionary(colName));\n+    }\n+    LOGGER.info(\"*Estimated size per record {} bytes\", _sizePerRecord);\n+  }\n+\n+  public long getColDataSizeWithoutDictionary(String colName) {\n+    //TODO: implement this after the complex is supported\n+    FieldSpec.DataType dataType = getFieldType(colName);\n+    if (dataType == FieldSpec.DataType.STRUCT || dataType == FieldSpec.DataType.MAP\n+        || dataType == FieldSpec.DataType.LIST) {\n+      return 0;\n+    } else {\n+      if (dataType == FieldSpec.DataType.BYTES || dataType == FieldSpec.DataType.STRING) {\n+        return _dataTypeSizeMap.get(dataType) * getAverageDataLen(colName);\n+      } else {\n+        return _dataTypeSizeMap.get(dataType);\n+      }\n+    }\n+  }\n+\n+  public long getColDataSizeWithDictionary(String colName) {\n+    //TODO: implement this after the complex is supported\n+    FieldSpec.DataType dataType = getFieldType(colName);\n+    int numValuesPerEntry = (int) Math.ceil(getNumValuesPerEntry(colName));\n+    LOGGER.trace(\"{} {}\", colName, numValuesPerEntry);\n+    if (dataType == FieldSpec.DataType.STRUCT || dataType == FieldSpec.DataType.MAP\n+        || dataType == FieldSpec.DataType.LIST) {\n+      return 0;\n+    } else if (!_overWrittenConfigs.getIndexConfig().getNoDictionaryColumns().contains(colName)) { // has dictionary\n+      return getBitCompressedDataSize(colName) * numValuesPerEntry;\n+    } else { // no dictionary\n+      if (dataType == FieldSpec.DataType.BYTES || dataType == FieldSpec.DataType.STRING) {\n+        return _dataTypeSizeMap.get(dataType) * numValuesPerEntry * getAverageDataLen(colName);\n+      } else {\n+        return _dataTypeSizeMap.get(dataType) * numValuesPerEntry;\n+      }\n+    }\n+  }\n+\n+  public int getBitCompressedDataSize(String colName) {\n+    return max((int) Math.ceil(Math.log(getCardinality(colName)) / (8 * Math.log(2))), 1);\n+  }\n+\n+  //\n+  public long getDictionarySize(String colName) {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwNzIwNQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r466007205", "bodyText": "Done! Thanks for pointing out this bug.", "author": "jasperjiaguo", "createdAt": "2020-08-05T21:12:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NDQyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NTkzNw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465955937", "bodyText": "You might want to rename it to getDictionaryEncodedForwardIndexSize", "author": "siddharthteotia", "createdAt": "2020-08-05T19:33:22Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/recommender/io/InputManager.java", "diffHunk": "@@ -0,0 +1,519 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.recommender.io;\n+\n+import com.fasterxml.jackson.annotation.JsonAutoDetect;\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.fasterxml.jackson.annotation.JsonSetter;\n+import com.fasterxml.jackson.annotation.Nulls;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.pinot.controller.recommender.io.exceptions.InvalidInputException;\n+import org.apache.pinot.controller.recommender.io.metadata.ColumnMetaData;\n+import org.apache.pinot.controller.recommender.io.metadata.SchemaWithMetaData;\n+import org.apache.pinot.controller.recommender.rules.RulesToExecute;\n+import org.apache.pinot.controller.recommender.rules.io.params.BloomFilterRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.FlagQueryRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.InvertedSortedIndexJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.NoDictionaryOnHeapDictionaryJointRuleParams;\n+import org.apache.pinot.controller.recommender.rules.io.params.PartitionRuleParams;\n+import org.apache.pinot.controller.recommender.rules.utils.FixedLenBitset;\n+import org.apache.pinot.spi.data.DimensionFieldSpec;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.MetricFieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static java.lang.Math.max;\n+import static org.apache.pinot.controller.recommender.rules.io.params.RecommenderConstants.*;\n+\n+\n+@JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.NONE)\n+public class InputManager {\n+  private final Logger LOGGER = LoggerFactory.getLogger(InputManager.class);\n+\n+  /******************************Deserialized from input json*********************************/\n+  // Basic input fields\n+  public RulesToExecute _rulesToExecute = new RulesToExecute(); // dictates which rules to execute\n+  public Schema _schema = new Schema();\n+  public SchemaWithMetaData _schemaWithMetaData = new SchemaWithMetaData();\n+\n+  public String _queryType = SQL; // SQL or PQL\n+  public long _qps = DEFAULT_QPS;\n+  public Map<String, Double> _queryWeightMap = new HashMap<>(); // {\"queryString\":\"queryWeight\"}\n+  public String _tableType = OFFLINE;\n+  public long _numMessagesPerSec = DEFAULT_NUM_MSG_PER_SEC; // messages per sec for kafka to consume\n+  public long _numRecordsPerPush = DEFAULT_NUM_RECORDS_PER_PUSH; // records per push for offline part of a table\n+  public long _latencySLA = DEFAULT_LATENCY_SLA; // latency sla in ms\n+  public int _numKafkaPartitions = DEFAULT_NUM_KAFKA_PARTITIONS;\n+\n+  // The parameters of rules\n+  public PartitionRuleParams _partitionRuleParams = new PartitionRuleParams();\n+  public InvertedSortedIndexJointRuleParams _invertedSortedIndexJointRuleParams =\n+      new InvertedSortedIndexJointRuleParams();\n+  public BloomFilterRuleParams _bloomFilterRuleParams = new BloomFilterRuleParams();\n+  public NoDictionaryOnHeapDictionaryJointRuleParams _noDictionaryOnHeapDictionaryJointRuleParams =\n+      new NoDictionaryOnHeapDictionaryJointRuleParams();\n+  public FlagQueryRuleParams _flagQueryRuleParams = new FlagQueryRuleParams();\n+\n+  // For forward compatibility: 1. dev/sre to overwrite field(s) 2. incremental recommendation on existing/staging tables\n+  public ConfigManager _overWrittenConfigs = new ConfigManager();\n+\n+  /******************************Ignored by deserializer****************************************/\n+  public Map<String, ColumnMetaData> _metaDataMap = new HashMap<>(); // meta data per column, complement to schema\n+  long _sizePerRecord = 0;\n+  Map<String, FieldSpec.DataType> _colnameFieldTypeMap = new HashMap<>();\n+  Set<String> _dimNames = null;\n+  Set<String> _metricNames = null;\n+  Set<String> _dateTimeNames = null;\n+  Set<String> _dimNamesInveredSortedIndexApplicable = null;\n+  Map<String, Integer> _colNameToIntMap = null;\n+  String[] _intToColNameMap = null;\n+  Map<FieldSpec.DataType, Integer> _dataTypeSizeMap = new HashMap<FieldSpec.DataType, Integer>() {{\n+    put(FieldSpec.DataType.INT, DEFAULT_INT_SIZE);\n+    put(FieldSpec.DataType.LONG, DEFAULT_LONG_SIZE);\n+    put(FieldSpec.DataType.FLOAT, DEFAULT_FLOAT_SIZE);\n+    put(FieldSpec.DataType.DOUBLE, DEFAULT_DOUBLE_SIZE);\n+    put(FieldSpec.DataType.BYTES, DEFAULT_BYTE_SIZE);\n+    put(FieldSpec.DataType.STRING, DEFAULT_CHAR_SIZE);\n+    put(null, DEFAULT_NULL_SIZE);\n+  }};\n+\n+  /**\n+   * Process the dependencies incurred by overwritten configs.\n+   * E.g. we will subtract the dimensions with overwritten indices from _dimNames to get _dimNamesIndexApplicable\n+   * This ensures we do not recommend indices on those dimensions\n+   */\n+  public void init()\n+      throws InvalidInputException {\n+    LOGGER.info(\"Preprocessing Input:\");\n+    reorderDimsAndBuildMap();\n+    registerColnameFieldType();\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setFlagQueryRuleParams(FlagQueryRuleParams flagQueryRuleParams) {\n+    _flagQueryRuleParams = flagQueryRuleParams;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setNumKafkaPartitions(int numKafkaPartitions) {\n+    _numKafkaPartitions = numKafkaPartitions;\n+  }\n+\n+  @JsonSetter(value = \"queriesWithWeights\", nulls = Nulls.SKIP)\n+  public void setQueryWeightMap(Map<String, Double> queryWeightMap) {\n+    _queryWeightMap = queryWeightMap;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setNoDictionaryOnHeapDictionaryJointRuleParams(\n+      NoDictionaryOnHeapDictionaryJointRuleParams noDictionaryOnHeapDictionaryJointRuleParams) {\n+    _noDictionaryOnHeapDictionaryJointRuleParams = noDictionaryOnHeapDictionaryJointRuleParams;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setLatencySLA(int latencySLA) {\n+    _latencySLA = latencySLA;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setQps(long qps) {\n+    _qps = qps;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setBloomFilterRuleParams(BloomFilterRuleParams bloomFilterRuleParams) {\n+    _bloomFilterRuleParams = bloomFilterRuleParams;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setPartitionRuleParams(PartitionRuleParams partitionRuleParams) {\n+    _partitionRuleParams = partitionRuleParams;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setTableType(String tableType) {\n+    _tableType = tableType;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setNumMessagesPerSec(long numMessagesPerSec) {\n+    _numMessagesPerSec = numMessagesPerSec;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setNumRecordsPerPush(long numRecordsPerPush) {\n+    _numRecordsPerPush = numRecordsPerPush;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setRulesToExecute(RulesToExecute rulesToExecute) {\n+    _rulesToExecute = rulesToExecute;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setSchema(JsonNode jsonNode)\n+      throws IOException {\n+    ObjectReader reader = new ObjectMapper().readerFor(Schema.class);\n+    this._schema=reader.readValue(jsonNode);\n+    reader = new ObjectMapper().readerFor(SchemaWithMetaData.class);\n+    this._schemaWithMetaData=reader.readValue(jsonNode);\n+    _schemaWithMetaData.getDimensionFieldSpecs()\n+        .forEach(columnMetaData -> {_metaDataMap.put(columnMetaData.getName(),columnMetaData);});\n+    _schemaWithMetaData.getMetricFieldSpecs()\n+        .forEach(columnMetaData -> {_metaDataMap.put(columnMetaData.getName(),columnMetaData);});\n+    _schemaWithMetaData.getDateTimeFieldSpecs()\n+        .forEach(columnMetaData -> {_metaDataMap.put(columnMetaData.getName(),columnMetaData);});\n+    _metaDataMap.put(_schemaWithMetaData.getTimeFieldSpec().getName(), _schemaWithMetaData.getTimeFieldSpec());\n+  }\n+\n+  @JsonIgnore\n+  public void setMetaDataMap(Map<String, ColumnMetaData> metaDataMap) {\n+    _metaDataMap = metaDataMap;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setQueryType(String queryType) {\n+    _queryType = queryType;\n+  }\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setInvertedSortedIndexJointRuleParams(\n+      InvertedSortedIndexJointRuleParams invertedSortedIndexJointRuleParams) {\n+    _invertedSortedIndexJointRuleParams = invertedSortedIndexJointRuleParams;\n+  }\n+\n+\n+  @JsonSetter(nulls = Nulls.SKIP)\n+  public void setOverWrittenConfigs(ConfigManager overWrittenConfigs) {\n+    _overWrittenConfigs = overWrittenConfigs;\n+  }\n+\n+\n+  public FlagQueryRuleParams getFlagQueryRuleParams() {\n+    return _flagQueryRuleParams;\n+  }\n+\n+\n+  public FieldSpec.DataType getFieldType(String colName){\n+    return _colnameFieldTypeMap.getOrDefault(colName, null);\n+  }\n+\n+  public Map<String, Integer> getColNameToIntMap() {\n+    return _colNameToIntMap;\n+  }\n+\n+  /**\n+   * Get the number of dimensions we can apply indices on.\n+   * @return total number of dimensions minus number of dimensions with overwritten indices\n+   */\n+  public int getNumDimsInvertedSortedApplicable() {\n+    return _dimNamesInveredSortedIndexApplicable.size();\n+  }\n+\n+  public NoDictionaryOnHeapDictionaryJointRuleParams getNoDictionaryOnHeapDictionaryJointRuleParams() {\n+    return _noDictionaryOnHeapDictionaryJointRuleParams;\n+  }\n+\n+  public int getNumDims() {\n+    return _dimNames.size();\n+  }\n+\n+  public int getNumCols() {\n+    return _colNameToIntMap.size();\n+  }\n+\n+  //TODO: Currently Pinot is using only ONE time column specified by TimeFieldSpec\n+  //TODO: Change the implementation after the new schema with multiple _dateTimeNames is in use\n+  public String getTimeCol() {\n+    return _schema.getTimeFieldSpec().getName();\n+  }\n+\n+  public Set<String> getColNamesNoDictionary() {\n+    return _overWrittenConfigs.getIndexConfig().getNoDictionaryColumns();\n+  }\n+\n+  public long getLatencySLA() {\n+    return _latencySLA;\n+  }\n+\n+  public long getQps() {\n+    return _qps;\n+  }\n+\n+  public BloomFilterRuleParams getBloomFilterRuleParams() {\n+    return _bloomFilterRuleParams;\n+  }\n+\n+  public PartitionRuleParams getPartitionRuleParams() {\n+    return _partitionRuleParams;\n+  }\n+\n+  public String getTableType() {\n+    return _tableType;\n+  }\n+\n+  public Map<String, Double> getQueryWeightMap() {\n+    return _queryWeightMap;\n+  }\n+\n+  public long getNumMessagesPerSec() {\n+    return _numMessagesPerSec;\n+  }\n+\n+  public long getNumRecordsPerPush() {\n+    return _numRecordsPerPush;\n+  }\n+\n+  public RulesToExecute getRulesToExecute() {\n+    return _rulesToExecute;\n+  }\n+\n+  public Schema getSchema() {\n+    return _schema;\n+  }\n+\n+  @JsonIgnore\n+  public Map<String, ColumnMetaData> getMetaDataMap() {\n+    return _metaDataMap;\n+  }\n+\n+  public String getQueryType() {\n+    return _queryType;\n+  }\n+\n+  public InvertedSortedIndexJointRuleParams getInvertedSortedIndexJointRuleParams() {\n+    return _invertedSortedIndexJointRuleParams;\n+  }\n+\n+  public ConfigManager getOverWrittenConfigs() {\n+    return _overWrittenConfigs;\n+  }\n+\n+  public long getSizePerRecord() {\n+    return _sizePerRecord;\n+  }\n+\n+  public double getCardinality(String columnName) {\n+    return max(_metaDataMap.getOrDefault(columnName, new ColumnMetaData()).getCardinality(), MIN_CARDINALITY);\n+  }\n+\n+  public double getNumValuesPerEntry(String columnName) {\n+    return _metaDataMap.getOrDefault(columnName, new ColumnMetaData()).getNumValuesPerEntry();\n+  }\n+\n+  public int getAverageDataLen(String columnName) {\n+    return _metaDataMap.getOrDefault(columnName, new ColumnMetaData()).getAverageLength();\n+  }\n+\n+  public int getNumKafkaPartitions() {\n+    return _numKafkaPartitions;\n+  }\n+\n+  public boolean isIndexableDim(String colName) {\n+    return _dimNamesInveredSortedIndexApplicable.contains(colName);\n+  }\n+\n+  public boolean isSingleValueColumn(String colName){\n+    ColumnMetaData columnMetaData = _metaDataMap.getOrDefault(colName, new ColumnMetaData());\n+    return columnMetaData.isSingleValueField() && (columnMetaData.getNumValuesPerEntry() < DEFAULT_AVERAGE_NUM_VALUES_PER_ENTRY + EPSILON);\n+  }\n+\n+  /**\n+   * Map a index-applicable dimension name to an 0<=integer<getNumDimsInvertedSortedApplicable,\n+   * to be used with {@link FixedLenBitset}\n+   * @param colName a dimension with no overwritten index\n+   * @return a unique integer id\n+   */\n+  public int colNameToInt(String colName) {\n+    return _colNameToIntMap.getOrDefault(colName, NO_SUCH_COL);\n+  }\n+\n+  /**\n+   * A reverse process of colNameToInt\n+   * @param colID a unique integer id\n+   * @return column name\n+   */\n+  public String intToColName(int colID) {\n+    return _intToColNameMap[colID];\n+  }\n+\n+  /**\n+   * Test if colName is a valid dimension name\n+   */\n+  public boolean isDim(String colName) {\n+    return _dimNames.contains(colName);\n+  }\n+\n+  public boolean isDateTime(String colName) {\n+    return _schema.getTimeFieldSpec().getName().equals(colName);\n+  }\n+\n+  public void registerColnameFieldType() { // create a map from colname to data type\n+    for (DimensionFieldSpec dimensionFieldSpec : _schema.getDimensionFieldSpecs()) {\n+      _colnameFieldTypeMap.put(dimensionFieldSpec.getName(), dimensionFieldSpec.getDataType());\n+    }\n+    for (MetricFieldSpec metricFieldSpec : _schema.getMetricFieldSpecs()) {\n+      _colnameFieldTypeMap.put(metricFieldSpec.getName(), metricFieldSpec.getDataType());\n+    }\n+    //TODO: add support for multiple getDateTimeFieldSpecs\n+    _colnameFieldTypeMap.put(_schema.getTimeFieldSpec().getName(), _schema.getTimeFieldSpec().getDataType());\n+  }\n+\n+  public void estimateSizePerRecord() {\n+    for (String colName : _colnameFieldTypeMap.keySet()) {\n+      _sizePerRecord += getColDataSizeWithDictionary(colName);\n+      LOGGER.debug(\"{} {}\",colName, getColDataSizeWithDictionary(colName));\n+    }\n+    LOGGER.info(\"*Estimated size per record {} bytes\", _sizePerRecord);\n+  }\n+\n+  public long getColDataSizeWithoutDictionary(String colName) {\n+    //TODO: implement this after the complex is supported\n+    FieldSpec.DataType dataType = getFieldType(colName);\n+    if (dataType == FieldSpec.DataType.STRUCT || dataType == FieldSpec.DataType.MAP\n+        || dataType == FieldSpec.DataType.LIST) {\n+      return 0;\n+    } else {\n+      if (dataType == FieldSpec.DataType.BYTES || dataType == FieldSpec.DataType.STRING) {\n+        return _dataTypeSizeMap.get(dataType) * getAverageDataLen(colName);\n+      } else {\n+        return _dataTypeSizeMap.get(dataType);\n+      }\n+    }\n+  }\n+\n+  public long getColDataSizeWithDictionary(String colName) {\n+    //TODO: implement this after the complex is supported\n+    FieldSpec.DataType dataType = getFieldType(colName);\n+    int numValuesPerEntry = (int) Math.ceil(getNumValuesPerEntry(colName));\n+    LOGGER.trace(\"{} {}\", colName, numValuesPerEntry);\n+    if (dataType == FieldSpec.DataType.STRUCT || dataType == FieldSpec.DataType.MAP\n+        || dataType == FieldSpec.DataType.LIST) {\n+      return 0;\n+    } else if (!_overWrittenConfigs.getIndexConfig().getNoDictionaryColumns().contains(colName)) { // has dictionary\n+      return getBitCompressedDataSize(colName) * numValuesPerEntry;\n+    } else { // no dictionary\n+      if (dataType == FieldSpec.DataType.BYTES || dataType == FieldSpec.DataType.STRING) {\n+        return _dataTypeSizeMap.get(dataType) * numValuesPerEntry * getAverageDataLen(colName);\n+      } else {\n+        return _dataTypeSizeMap.get(dataType) * numValuesPerEntry;\n+      }\n+    }\n+  }\n+\n+  public int getBitCompressedDataSize(String colName) {", "originalCommit": "c3c722c824480ab95851c0df2cef36adb7f29e65", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk2MDc4OQ==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465960789", "bodyText": "This function doesn't actually return the total bit compressed size.\nWhat we need is the following:\n\nget the number of bits per value\nnumber of records\n\nmultiply both\nnumber of bits per value  can be calculated by a function PinotDataBitSet", "author": "siddharthteotia", "createdAt": "2020-08-05T19:42:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NTkzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5ODUwMw==", "url": "https://github.com/apache/pinot/pull/5774#discussion_r465998503", "bodyText": "done", "author": "jasperjiaguo", "createdAt": "2020-08-05T20:55:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NTkzNw=="}], "type": "inlineReview"}, {"oid": "1886536a82a50ad3721c3576b1264791218fe4f6", "url": "https://github.com/apache/pinot/commit/1886536a82a50ad3721c3576b1264791218fe4f6", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase\n\nremove log printing\n\nfixed a bug in InputManager, added test cases for FlagQuery and VariedLengthDictionary\n\nrefactored code\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs", "committedDate": "2020-08-07T03:40:11Z", "type": "forcePushed"}, {"oid": "8fe31b734898b939edd39e8ef6113454ae7ce750", "url": "https://github.com/apache/pinot/commit/8fe31b734898b939edd39e8ef6113454ae7ce750", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase\n\nremove log printing\n\nfixed a bug in InputManager, added test cases for FlagQuery and VariedLengthDictionary\n\nrefactored code\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nAddressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfixed testcases", "committedDate": "2020-08-07T03:43:57Z", "type": "forcePushed"}, {"oid": "76184a54001d770efbfb576ed3ff274dae86a666", "url": "https://github.com/apache/pinot/commit/76184a54001d770efbfb576ed3ff274dae86a666", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase", "committedDate": "2020-08-07T04:19:32Z", "type": "forcePushed"}, {"oid": "85628c8c8e4ad62766cfa88b391250b737689c4e", "url": "https://github.com/apache/pinot/commit/85628c8c8e4ad62766cfa88b391250b737689c4e", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase\n\nadded license", "committedDate": "2020-08-07T04:51:37Z", "type": "forcePushed"}, {"oid": "0879d3ad9cfa6cac163ca77a0b44963279671803", "url": "https://github.com/apache/pinot/commit/0879d3ad9cfa6cac163ca77a0b44963279671803", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase\n\nadded license\n\nadded cardinality regulator", "committedDate": "2020-08-07T09:48:01Z", "type": "forcePushed"}, {"oid": "3873a1b35c0202a60965f1869b47c783b962d97d", "url": "https://github.com/apache/pinot/commit/3873a1b35c0202a60965f1869b47c783b962d97d", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase\n\nadded license\n\nadded cardinality regulator\n\nrestart test\n\nrestart test\n\nresolve comments", "committedDate": "2020-08-07T21:44:30Z", "type": "forcePushed"}, {"oid": "b9540c67efd462fa57c776113cddf3340636430e", "url": "https://github.com/apache/pinot/commit/b9540c67efd462fa57c776113cddf3340636430e", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase\n\nadded license\n\nadded cardinality regulator\n\nrestart test\n\nrestart test\n\nresolve comments\n\nremoved logging", "committedDate": "2020-08-07T22:06:39Z", "type": "forcePushed"}, {"oid": "e518a71fdab60b4e5fdea13f79769d3cd7eef116", "url": "https://github.com/apache/pinot/commit/e518a71fdab60b4e5fdea13f79769d3cd7eef116", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase\n\nadded license\n\nadded cardinality regulator\n\nrestart test\n\nrestart test\n\nresolve comments\n\nremoved logging\n\ntest", "committedDate": "2020-08-10T17:31:10Z", "type": "commit"}, {"oid": "e518a71fdab60b4e5fdea13f79769d3cd7eef116", "url": "https://github.com/apache/pinot/commit/e518a71fdab60b4e5fdea13f79769d3cd7eef116", "message": "Addressed issues in code review:\n1. for MV use dictionary encoding only\n2. renamed code\n3. cleaned up some conditions\n4. added a few java docs\n\nfix testcase\n\nadded license\n\nadded cardinality regulator\n\nrestart test\n\nrestart test\n\nresolve comments\n\nremoved logging\n\ntest", "committedDate": "2020-08-10T17:31:10Z", "type": "forcePushed"}]}