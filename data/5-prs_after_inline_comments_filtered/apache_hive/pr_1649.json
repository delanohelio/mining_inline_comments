{"pr_number": 1649, "pr_title": "HIVE-24245: Vectorized PTF with count and distinct over partition producing incorrect results.", "pr_createdAt": "2020-11-03T15:14:52Z", "pr_url": "https://github.com/apache/hive/pull/1649", "timeline": [{"oid": "e7b9863ada6f012ff6b2ebd6078640217e67e131", "url": "https://github.com/apache/hive/commit/e7b9863ada6f012ff6b2ebd6078640217e67e131", "message": "HIVE-24245: Vectorized PTF with count and distinct over partition producing incorrect results.", "committedDate": "2020-11-03T15:30:29Z", "type": "forcePushed"}, {"oid": "bf24ff6f3924c7fe60ab06620f51740839acdd7e", "url": "https://github.com/apache/hive/commit/bf24ff6f3924c7fe60ab06620f51740839acdd7e", "message": "HIVE-24245: Vectorized PTF with count and distinct over partition producing incorrect results.", "committedDate": "2020-11-03T15:42:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc5Nzk5MQ==", "url": "https://github.com/apache/hive/pull/1649#discussion_r528797991", "bodyText": "We do check if the element is present twice here -- add method already checks if the element is part of the Set so we dont need to call contains. I would just add a comment here instead.", "author": "pgaref", "createdAt": "2020-11-23T15:43:24Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+import com.google.common.base.Preconditions;\n+\n+/**\n+ * This class evaluates count(column) for a PTF group where a distinct keyword is applied to the\n+ * partitioning column itself, e.g.:\n+ * \n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt1) over(partition by txt1) as n,\n+ *   count(distinct txt2) over(partition by txt2) as m\n+ * FROM example;\n+ *\n+ * In this case, the framework is still supposed to ensure sorting\n+ * on the key (let's say txt1 for the first Reducer stage), but the original\n+ * VectorPTFEvaluatorCount is not aware that a distinct keyword was applied\n+ * to the key column. This case would be simple, because such function should\n+ * return 1 every time. However, that's just a corner-case, a real scenario is\n+ * when the partitioning column is not the same. In such cases, a real count\n+ * distinct implementation is needed:\n+ *\n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt2) over(partition by txt1) as n,\n+ *   count(distinct txt1) over(partition by txt2) as m\n+ * FROM example;\n+ */\n+public abstract class VectorPTFEvaluatorCountDistinct extends VectorPTFEvaluatorCount {\n+\n+  protected Set<Object> uniqueObjects;\n+\n+  public VectorPTFEvaluatorCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  @Override\n+  public void evaluateGroupBatch(VectorizedRowBatch batch) throws HiveException {\n+\n+    evaluateInputExpr(batch);\n+\n+    // We do not filter when PTF is in reducer.\n+    Preconditions.checkState(!batch.selectedInUse);\n+\n+    final int size = batch.size;\n+    if (size == 0) {\n+      return;\n+    }\n+    ColumnVector colVector = batch.cols[inputColumnNum];\n+    if (colVector.isRepeating) {\n+      if (colVector.noNulls || !colVector.isNull[0]) {\n+        countValue(colVector, 0);\n+      }\n+    } else {\n+      boolean[] batchIsNull = colVector.isNull;\n+      for (int i = 0; i < size; i++) {\n+        if (!batchIsNull[i]) {\n+          countValue(colVector, i);\n+        }\n+      }\n+    }\n+  }\n+\n+  protected void countValue(ColumnVector colVector, int i) {\n+    Object value = getValue(colVector, i);\n+    if (!uniqueObjects.contains(value)) {\n+      uniqueObjects.add(value);", "originalCommit": "bf24ff6f3924c7fe60ab06620f51740839acdd7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE3ODYwNA==", "url": "https://github.com/apache/hive/pull/1649#discussion_r530178604", "bodyText": "yeah, thanks, forgot that Set takes care of uniqueness :)", "author": "abstractdog", "createdAt": "2020-11-25T08:14:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc5Nzk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE4NTU0Ng==", "url": "https://github.com/apache/hive/pull/1649#discussion_r530185546", "bodyText": "btw, I copied this wrong approach from GenericUDAFCount, I'm fixing it there also", "author": "abstractdog", "createdAt": "2020-11-25T08:26:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc5Nzk5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgwMDQxMQ==", "url": "https://github.com/apache/hive/pull/1649#discussion_r528800411", "bodyText": "Instead of updating the inherited count variable we could override getLongGroupResult() with uniqueObjects.size", "author": "pgaref", "createdAt": "2020-11-23T15:46:30Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorCountDistinct.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.metadata.HiveException;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+import com.google.common.base.Preconditions;\n+\n+/**\n+ * This class evaluates count(column) for a PTF group where a distinct keyword is applied to the\n+ * partitioning column itself, e.g.:\n+ * \n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt1) over(partition by txt1) as n,\n+ *   count(distinct txt2) over(partition by txt2) as m\n+ * FROM example;\n+ *\n+ * In this case, the framework is still supposed to ensure sorting\n+ * on the key (let's say txt1 for the first Reducer stage), but the original\n+ * VectorPTFEvaluatorCount is not aware that a distinct keyword was applied\n+ * to the key column. This case would be simple, because such function should\n+ * return 1 every time. However, that's just a corner-case, a real scenario is\n+ * when the partitioning column is not the same. In such cases, a real count\n+ * distinct implementation is needed:\n+ *\n+ * SELECT\n+ *   txt1,\n+ *   txt2,\n+ *   count(distinct txt2) over(partition by txt1) as n,\n+ *   count(distinct txt1) over(partition by txt2) as m\n+ * FROM example;\n+ */\n+public abstract class VectorPTFEvaluatorCountDistinct extends VectorPTFEvaluatorCount {\n+\n+  protected Set<Object> uniqueObjects;\n+\n+  public VectorPTFEvaluatorCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  @Override\n+  public void evaluateGroupBatch(VectorizedRowBatch batch) throws HiveException {\n+\n+    evaluateInputExpr(batch);\n+\n+    // We do not filter when PTF is in reducer.\n+    Preconditions.checkState(!batch.selectedInUse);\n+\n+    final int size = batch.size;\n+    if (size == 0) {\n+      return;\n+    }\n+    ColumnVector colVector = batch.cols[inputColumnNum];\n+    if (colVector.isRepeating) {\n+      if (colVector.noNulls || !colVector.isNull[0]) {\n+        countValue(colVector, 0);\n+      }\n+    } else {\n+      boolean[] batchIsNull = colVector.isNull;\n+      for (int i = 0; i < size; i++) {\n+        if (!batchIsNull[i]) {\n+          countValue(colVector, i);", "originalCommit": "bf24ff6f3924c7fe60ab06620f51740839acdd7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE3OTkwNg==", "url": "https://github.com/apache/hive/pull/1649#discussion_r530179906", "bodyText": "right! updating it", "author": "abstractdog", "createdAt": "2020-11-25T08:16:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgwMDQxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgyMDYzNQ==", "url": "https://github.com/apache/hive/pull/1649#discussion_r528820635", "bodyText": "What is the benefit of returning Murmur hash directly here? Adding a String to the HashSet will also hash the input (so essentially we are hashing twice)", "author": "pgaref", "createdAt": "2020-11-23T16:08:50Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/vector/ptf/VectorPTFEvaluatorBytesCountDistinct.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.exec.vector.ptf;\n+\n+import org.apache.hadoop.hive.ql.exec.vector.BytesColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.expressions.VectorExpression;\n+import org.apache.hadoop.hive.ql.plan.ptf.WindowFrameDef;\n+import org.apache.hive.common.util.Murmur3;\n+\n+/**\n+ * Bytes (String) implementation for VectorPTFEvaluatorCountDistinct.\n+ */\n+public class VectorPTFEvaluatorBytesCountDistinct extends VectorPTFEvaluatorCountDistinct {\n+\n+  public VectorPTFEvaluatorBytesCountDistinct(WindowFrameDef windowFrameDef,\n+      VectorExpression inputVecExpr, int outputColumnNum) {\n+    super(windowFrameDef, inputVecExpr, outputColumnNum);\n+    resetEvaluator();\n+  }\n+\n+  protected Object getValue(ColumnVector colVector, int i) {\n+    BytesColumnVector inV = (BytesColumnVector) colVector;\n+    return Murmur3.hash32(inV.vector[i], inV.start[i], inV.length[i], Murmur3.DEFAULT_SEED);", "originalCommit": "bf24ff6f3924c7fe60ab06620f51740839acdd7e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDE4MjQzOA==", "url": "https://github.com/apache/hive/pull/1649#discussion_r530182438", "bodyText": "I used hashing for memory considerations, I was hoping that this way the unique set will consume less memory (storing hashes instead of strings of arbitrary length)...now I think that we could be fine with storing strings and prevent additional hashing, as we tend to optimize CPU cycles instead of memory in the very-first round...I'll change this to new String(byte[])", "author": "abstractdog", "createdAt": "2020-11-25T08:21:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgyMDYzNQ=="}], "type": "inlineReview"}, {"oid": "86b53d35c302c7f92fd70aee52c67b896d6f40ba", "url": "https://github.com/apache/hive/commit/86b53d35c302c7f92fd70aee52c67b896d6f40ba", "message": "PR fixes", "committedDate": "2020-11-25T08:31:45Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDI2MTAxMA==", "url": "https://github.com/apache/hive/pull/1649#discussion_r530261010", "bodyText": "Thanks for taking care of this", "author": "pgaref", "createdAt": "2020-11-25T10:21:06Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCount.java", "diffHunk": "@@ -180,14 +181,13 @@ public void iterate(AggregationBuffer agg, Object[] parameters)\n           if (((CountAgg) agg).uniqueObjects == null) {\n             ((CountAgg) agg).uniqueObjects = new HashSet<ObjectInspectorObject>();\n           }\n-          HashSet<ObjectInspectorObject> uniqueObjs = ((CountAgg) agg).uniqueObjects;\n+          Set<ObjectInspectorObject> uniqueObjs = ((CountAgg) agg).uniqueObjects;\n \n           ObjectInspectorObject obj = new ObjectInspectorObject(\n               ObjectInspectorUtils.copyToStandardObject(parameters, inputOI, ObjectInspectorCopyOption.JAVA),\n               outputOI);\n-          if (!uniqueObjs.contains(obj)) {\n-            uniqueObjs.add(obj);\n-          } else {\n+          boolean inserted = uniqueObjs.add(obj);\n+          if (!inserted){", "originalCommit": "86b53d35c302c7f92fd70aee52c67b896d6f40ba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8d9f8941e4c9c497ce99c67ec7576031a70450a6", "url": "https://github.com/apache/hive/commit/8d9f8941e4c9c497ce99c67ec7576031a70450a6", "message": "PR fixes", "committedDate": "2020-11-26T10:32:12Z", "type": "forcePushed"}, {"oid": "f9a7a9a13ed2567c3b0dc9af385bf6e48e62e969", "url": "https://github.com/apache/hive/commit/f9a7a9a13ed2567c3b0dc9af385bf6e48e62e969", "message": "HIVE-24245: Vectorized PTF with count and distinct over partition producing incorrect results.", "committedDate": "2020-12-09T08:59:36Z", "type": "commit"}, {"oid": "f9a7a9a13ed2567c3b0dc9af385bf6e48e62e969", "url": "https://github.com/apache/hive/commit/f9a7a9a13ed2567c3b0dc9af385bf6e48e62e969", "message": "HIVE-24245: Vectorized PTF with count and distinct over partition producing incorrect results.", "committedDate": "2020-12-09T08:59:36Z", "type": "forcePushed"}]}