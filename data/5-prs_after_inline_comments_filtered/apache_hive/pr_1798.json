{"pr_number": 1798, "pr_title": "HIVE-22944: Upgrade to Kryo5", "pr_createdAt": "2020-12-21T17:10:55Z", "pr_url": "https://github.com/apache/hive/pull/1798", "timeline": [{"oid": "6567cef52592faecaa99055b40a5549376d95f23", "url": "https://github.com/apache/hive/commit/6567cef52592faecaa99055b40a5549376d95f23", "message": "HIVE-22944: Upgrade to Kryo5", "committedDate": "2020-12-21T18:50:08Z", "type": "forcePushed"}, {"oid": "aacc386571d9a573cb1a3d67ba3783e3783f6e5a", "url": "https://github.com/apache/hive/commit/aacc386571d9a573cb1a3d67ba3783e3783f6e5a", "message": "HIVE-22944: Upgrade to Kryo5 - benchmark", "committedDate": "2020-12-27T16:12:23Z", "type": "forcePushed"}, {"oid": "f569fd31f5ad25998258ed3f6c477dc47adcb109", "url": "https://github.com/apache/hive/commit/f569fd31f5ad25998258ed3f6c477dc47adcb109", "message": "HIVE-22944: Upgrade to Kryo5 - benchmark", "committedDate": "2020-12-28T09:17:54Z", "type": "forcePushed"}, {"oid": "d0452ecefbd73f88cea61f61deb47b573a671079", "url": "https://github.com/apache/hive/commit/d0452ecefbd73f88cea61f61deb47b573a671079", "message": "HIVE-22944: Upgrade to Kryo5 - benchmark", "committedDate": "2021-01-07T14:40:54Z", "type": "forcePushed"}, {"oid": "0cebb875cdf3f830425a7c1c4c62f81fbfc07408", "url": "https://github.com/apache/hive/commit/0cebb875cdf3f830425a7c1c4c62f81fbfc07408", "message": "@Ignore", "committedDate": "2021-01-08T06:42:55Z", "type": "forcePushed"}, {"oid": "a51fee9c4b5f8137ad83949d54858240dab221ec", "url": "https://github.com/apache/hive/commit/a51fee9c4b5f8137ad83949d54858240dab221ec", "message": "@Ignore", "committedDate": "2021-01-14T08:37:31Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3Mjk0Mg==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562072942", "bodyText": "nit: maybe move Sarg  Expr creation to separate method for consistency?", "author": "pgaref", "createdAt": "2021-01-21T17:39:54Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/io/sarg/TestConvertAstToSearchArg.java", "diffHunk": "@@ -2855,16 +2836,26 @@ public void TestBigintSarg() throws Exception {\n   }\n \n   @Test\n-  public void TestBooleanSarg() throws Exception {\n-    String serialAst =\n-        \"AQEAamF2YS51dGlsLkFycmF5TGlz9AECAQFvcmcuYXBhY2hlLmhhZG9vcC5oaXZlLnFsLnBsYW4uRXh\" +\n-            \"wck5vZGVHZW5lcmljRnVuY0Rlc+MBAQABAgECb3JnLmFwYWNoZS5oYWRvb3AuaGl2ZS5xbC5wbGFuLk\" +\n-            \"V4cHJOb2RlQ29sdW1uRGVz4wEBYrEAAAFib29sb3LjAQNvcmcuYXBhY2hlLmhhZG9vcC5oaXZlLnNlc\" +\n-            \"mRlMi50eXBlaW5mby5QcmltaXRpdmVUeXBlSW5m7wEBYm9vbGVh7gEEb3JnLmFwYWNoZS5oYWRvb3Au\" +\n-            \"aGl2ZS5xbC5wbGFuLkV4cHJOb2RlQ29uc3RhbnREZXPjAQEDCQUBAQVvcmcuYXBhY2hlLmhhZG9vcC5\" +\n-            \"oaXZlLnFsLnVkZi5nZW5lcmljLkdlbmVyaWNVREZPUEVxdWHsAQAAAYI9AUVRVUHMAQZvcmcuYXBhY2\" +\n-            \"hlLmhhZG9vcC5pby5Cb29sZWFuV3JpdGFibOUBAAABAwkBAgEBYrIAAAgBAwkBB29yZy5hcGFjaGUua\" +\n-            \"GFkb29wLmhpdmUucWwudWRmLmdlbmVyaWMuR2VuZXJpY1VERk9QQW7kAQEGAQAAAQMJ\";\n+  public void testBooleanSarg() throws Exception {\n+    ExprNodeDesc column1 =", "originalCommit": "a51fee9c4b5f8137ad83949d54858240dab221ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwMzI4Mw==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562103283", "bodyText": "the reason I haven't do that is this case differs from others in the class as we have two columns, and this is the only case...however, I can do a utility method", "author": "abstractdog", "createdAt": "2021-01-21T18:25:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3Mjk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3NDIwMQ==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562074201", "bodyText": "Does this mean this is a breaking change for Spark?", "author": "pgaref", "createdAt": "2021-01-21T17:41:45Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/exec/spark/TestSparkInvalidFileFormat.java", "diffHunk": "@@ -30,11 +30,13 @@\n import org.apache.hadoop.hive.ql.session.SessionState;\n \n import org.junit.Assert;\n+import org.junit.Ignore;\n import org.junit.Test;\n \n import java.io.File;\n import java.io.IOException;\n \n+@Ignore(\"HIVE-22944: Kryo 5 upgrade conflicts with Spark, which is not supported anymore\")", "originalCommit": "a51fee9c4b5f8137ad83949d54858240dab221ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA5NTk5NA==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562095994", "bodyText": "yes, it is\nmaybe I could hack with that, but it would be painful: using kryo5 for tez execution and kryo4 for spark execution", "author": "abstractdog", "createdAt": "2021-01-21T18:14:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3NDIwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3NTI1NQ==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562075255", "bodyText": "Maybe rename the method itself here as well?  something like obtainKryo() ?", "author": "pgaref", "createdAt": "2021-01-21T17:43:27Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/SerializationUtilities.java", "diffHunk": "@@ -278,7 +284,7 @@ public Kryo create() {\n    * @return kryo instance\n    */\n   public static Kryo borrowKryo() {\n-    Kryo kryo = kryoPool.borrow();\n+    Kryo kryo = kryoPool.obtain();", "originalCommit": "a51fee9c4b5f8137ad83949d54858240dab221ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwMDcxMg==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562100712", "bodyText": "it's very unfortunate that kryo changed this method name without any reasons (or just I don't understand that :) )...we might want a method name that reflects the behavior of \"getting a kryo instance from the pool\", I don't have a strong opinion about that, but I'm not sure if we need to change a public method name because kryo changed theirs", "author": "abstractdog", "createdAt": "2021-01-21T18:21:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3NTI1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3OTU3NA==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562079574", "bodyText": "This is cool! Shall we add a more complex Map for bench here and a perf number for reference?\nMaybe previous kryo4 vs kryo5?", "author": "pgaref", "createdAt": "2021-01-21T17:49:52Z", "path": "itests/hive-jmh/src/main/java/org/apache/hive/benchmark/ql/exec/KryoBench.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hive.benchmark.ql.exec;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.ql.exec.SerializationUtilities;\n+import org.apache.hadoop.hive.ql.exec.Utilities;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatchCtx;\n+import org.apache.hadoop.hive.ql.io.orc.OrcInputFormat;\n+import org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat;\n+import org.apache.hadoop.hive.ql.io.orc.OrcSerde;\n+import org.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.BigRowInspector;\n+import org.apache.hadoop.hive.ql.plan.MapWork;\n+import org.apache.hadoop.hive.ql.plan.PartitionDesc;\n+import org.apache.hadoop.hive.ql.plan.TableDesc;\n+import org.apache.hadoop.hive.ql.plan.VectorPartitionDesc;\n+import org.apache.hadoop.hive.serde.serdeConstants;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+\n+import com.google.common.io.ByteStreams;\n+\n+@State(Scope.Benchmark)\n+public class KryoBench {\n+\n+  @BenchmarkMode(Mode.AverageTime)\n+  @Fork(1)\n+  @State(Scope.Thread)\n+  @OutputTimeUnit(TimeUnit.MILLISECONDS)\n+  public static class BaseBench {\n+\n+    private MapWork mapWork;\n+\n+    @Setup\n+    public void setup() throws Exception {\n+      mapWork = KryoBench.mockMapWork(\"my_table\", 1000, new BigRowInspector());\n+    }\n+\n+    @Benchmark\n+    @Warmup(iterations = 2, time = 2, timeUnit = TimeUnit.SECONDS)\n+    @Measurement(iterations = 20, time = 2, timeUnit = TimeUnit.SECONDS)\n+    public void testSerializeMapWork() {\n+      SerializationUtilities.serializePlan(mapWork, ByteStreams.nullOutputStream());\n+    }\n+  }\n+\n+  public static void main(String[] args) throws RunnerException {", "originalCommit": "a51fee9c4b5f8137ad83949d54858240dab221ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA5NzY0Ng==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562097646", "bodyText": "there is a benchmark result kryo4 vs kryo5: https://issues.apache.org/jira/secure/attachment/13018768/kryo4_vs_5_benchmark.log\nnot an over-complicated MapWork, but contains 1000 partitions, which is the most weight of mapworks (+ a few columns)", "author": "abstractdog", "createdAt": "2021-01-21T18:17:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3OTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzMDA5Ng==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562130096", "bodyText": "Nice, I missed that -- the numbers are only for 5 though right?", "author": "pgaref", "createdAt": "2021-01-21T19:08:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3OTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzgzMDYxNA==", "url": "https://github.com/apache/hive/pull/1798#discussion_r563830614", "bodyText": "it's an edited file, scroll down in it for kryo4 results", "author": "abstractdog", "createdAt": "2021-01-25T15:51:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA3OTU3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA4MDIxOA==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562080218", "bodyText": "Maybe add a comment why the above 3 lines are needed?", "author": "pgaref", "createdAt": "2021-01-21T17:50:50Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/SerializationUtilities.java", "diffHunk": "@@ -224,51 +224,57 @@ public Registration readClass(Input input) {\n \n   private static final Object FAKE_REFERENCE = new Object();\n \n-  private static KryoFactory factory = new KryoFactory() {\n-    @Override\n-    public Kryo create() {\n-      KryoWithHooks kryo = new KryoWithHooks();\n-      kryo.register(java.sql.Date.class, new SqlDateSerializer());\n-      kryo.register(java.sql.Timestamp.class, new TimestampSerializer());\n-      kryo.register(TimestampTZ.class, new TimestampTZSerializer());\n-      kryo.register(Path.class, new PathSerializer());\n-      kryo.register(Arrays.asList(\"\").getClass(), new ArraysAsListSerializer());\n-      kryo.register(new java.util.ArrayList().subList(0,0).getClass(), new ArrayListSubListSerializer());\n-      kryo.register(CopyOnFirstWriteProperties.class, new CopyOnFirstWritePropertiesSerializer());\n-      kryo.register(PartitionDesc.class, new PartitionDescSerializer(kryo, PartitionDesc.class));\n-\n-      ((Kryo.DefaultInstantiatorStrategy) kryo.getInstantiatorStrategy())\n-          .setFallbackInstantiatorStrategy(\n-              new StdInstantiatorStrategy());\n-      removeField(kryo, AbstractOperatorDesc.class, \"colExprMap\");\n-      removeField(kryo, AbstractOperatorDesc.class, \"statistics\");\n-      kryo.register(ReduceWork.class);\n-      kryo.register(TableDesc.class);\n-      kryo.register(UnionOperator.class);\n-      kryo.register(FileSinkOperator.class);\n-      kryo.register(VectorFileSinkOperator.class);\n-      kryo.register(HiveIgnoreKeyTextOutputFormat.class);\n-      kryo.register(StandardConstantListObjectInspector.class);\n-      kryo.register(StandardConstantMapObjectInspector.class);\n-      kryo.register(StandardConstantStructObjectInspector.class);\n-      kryo.register(SequenceFileInputFormat.class);\n-      kryo.register(RCFileInputFormat.class);\n-      kryo.register(HiveSequenceFileOutputFormat.class);\n-      kryo.register(LlapOutputFormat.class);\n-      kryo.register(SparkEdgeProperty.class);\n-      kryo.register(SparkWork.class);\n-      kryo.register(Pair.class);\n-      kryo.register(MemoryMonitorInfo.class);\n-\n-      // This must be called after all the explicit register calls.\n-      return kryo.processHooks(kryoTypeHooks, globalHook);\n-    }\n-  };\n-\n   // Bounded queue could be specified here but that will lead to blocking.\n   // ConcurrentLinkedQueue is unbounded and will release soft referenced kryo instances under\n   // memory pressure.\n-  private static KryoPool kryoPool = new KryoPool.Builder(factory).softReferences().build();\n+  private static Pool<Kryo> kryoPool = new Pool<Kryo>(true, false, 8) {\n+    protected Kryo create() {\n+      return createNewKryo();\n+    }\n+  };\n+\n+  public static Kryo createNewKryo() {\n+    KryoWithHooks kryo = new KryoWithHooks();\n+\n+    kryo.setReferences(true);\n+    kryo.setCopyReferences(true);\n+    kryo.setRegistrationRequired(false);", "originalCommit": "a51fee9c4b5f8137ad83949d54858240dab221ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEwMTQzNg==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562101436", "bodyText": "to be honest, because it works this way :) worst case I'll comment about what issues can come without these options set", "author": "abstractdog", "createdAt": "2021-01-21T18:22:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA4MDIxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjEzMDMwMw==", "url": "https://github.com/apache/hive/pull/1798#discussion_r562130303", "bodyText": "Sure, makes sense!", "author": "pgaref", "createdAt": "2021-01-21T19:09:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjA4MDIxOA=="}], "type": "inlineReview"}, {"oid": "73d60e09bb97d7eac74afd5e528116962e4327c0", "url": "https://github.com/apache/hive/commit/73d60e09bb97d7eac74afd5e528116962e4327c0", "message": "HIVE-22944: Upgrade to Kryo5", "committedDate": "2021-01-25T15:49:05Z", "type": "commit"}, {"oid": "69392d8adcdb6c53df90180b1bf79ba1bec63b27", "url": "https://github.com/apache/hive/commit/69392d8adcdb6c53df90180b1bf79ba1bec63b27", "message": "HIVE-22944: Upgrade to Kryo5 - benchmark", "committedDate": "2021-01-25T15:49:05Z", "type": "commit"}, {"oid": "3d41336fe51f64d00ce1b3a59bb30c9c9bf7c8b7", "url": "https://github.com/apache/hive/commit/3d41336fe51f64d00ce1b3a59bb30c9c9bf7c8b7", "message": "@Ignore", "committedDate": "2021-01-25T15:49:05Z", "type": "commit"}, {"oid": "2a1ecd8393228885b66ccd2cab802b2706d3fa22", "url": "https://github.com/apache/hive/commit/2a1ecd8393228885b66ccd2cab802b2706d3fa22", "message": "some changes after PR comments", "committedDate": "2021-01-25T16:34:40Z", "type": "forcePushed"}, {"oid": "cf5921b071b23928d4df1075b4d01ee1aad04854", "url": "https://github.com/apache/hive/commit/cf5921b071b23928d4df1075b4d01ee1aad04854", "message": "some changes after PR comments", "committedDate": "2021-01-28T17:57:04Z", "type": "forcePushed"}, {"oid": "ec63776394ff2438e6d510566aa9820d1da7fa29", "url": "https://github.com/apache/hive/commit/ec63776394ff2438e6d510566aa9820d1da7fa29", "message": "some changes after PR comments", "committedDate": "2021-01-29T13:54:21Z", "type": "forcePushed"}, {"oid": "4accc489515366632ca84a77b3a99a99f2de19bb", "url": "https://github.com/apache/hive/commit/4accc489515366632ca84a77b3a99a99f2de19bb", "message": "some changes after PR comments", "committedDate": "2021-02-01T06:09:43Z", "type": "commit"}, {"oid": "4accc489515366632ca84a77b3a99a99f2de19bb", "url": "https://github.com/apache/hive/commit/4accc489515366632ca84a77b3a99a99f2de19bb", "message": "some changes after PR comments", "committedDate": "2021-02-01T06:09:43Z", "type": "forcePushed"}]}