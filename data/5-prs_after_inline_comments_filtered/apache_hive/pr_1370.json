{"pr_number": 1370, "pr_title": "HIVE-23887: Reset table level basic/column stats during import", "pr_createdAt": "2020-08-06T16:49:55Z", "pr_url": "https://github.com/apache/hive/pull/1370", "timeline": [{"oid": "8dc467e9f6e640e10807db8c438327130b99d913", "url": "https://github.com/apache/hive/commit/8dc467e9f6e640e10807db8c438327130b99d913", "message": "HIVE-23887:Reset Columns stats in Export Statement", "committedDate": "2020-08-06T17:10:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ2MTkzMg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r467461932", "bodyText": "Check the COLUMN_STATS_ACCURATE property is true on source table and partition before and after export operation to confirm we don't overwrite anything in their metadata.", "author": "sankarh", "createdAt": "2020-08-08T12:48:44Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +567,28 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+  @Test public void testExportPartitionedOrcWithOutColumnStats() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n+    final int[][] rows = { { 3 } };\n+    //now we have an archive with 3 partitions\n+    runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");", "originalCommit": "de32725390e55bf2af3aef791c80e7191075b87d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ2MTk0NA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r467461944", "bodyText": "Can we also check the partition properties?", "author": "sankarh", "createdAt": "2020-08-08T12:49:10Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +567,28 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+  @Test public void testExportPartitionedOrcWithOutColumnStats() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n+    final int[][] rows = { { 3 } };\n+    //now we have an archive with 3 partitions\n+    runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n+\n+    //load T\n+    runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");", "originalCommit": "de32725390e55bf2af3aef791c80e7191075b87d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ2MjI3MQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r467462271", "bodyText": "There is already parameters != null check above in this method. Can we move this code there itself?", "author": "sankarh", "createdAt": "2020-08-08T12:53:07Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/PartitionSerializer.java", "diffHunk": "@@ -59,6 +61,11 @@ public void writeTo(JsonWriter writer, ReplicationSpec additionalPropertiesProvi\n                   additionalPropertiesProvider.getCurrentReplicationState());\n         }\n       }\n+\n+      if (parameters != null && parameters.containsKey(COLUMN_STATS_ACCURATE)) {", "originalCommit": "de32725390e55bf2af3aef791c80e7191075b87d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ2MjI5OA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r467462298", "bodyText": "There is already parameters != null check above in this method. Can we move this code there itself?", "author": "sankarh", "createdAt": "2020-08-08T12:53:33Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/repl/dump/io/TableSerializer.java", "diffHunk": "@@ -96,6 +98,11 @@ private Table updatePropertiesInTable(Table table, ReplicationSpec additionalPro\n       // uncomment this else section, but currently unneeded. Will require a lot of golden file\n       // regen if we do so.\n     }\n+\n+    if (parameters != null && parameters.containsKey(COLUMN_STATS_ACCURATE)) {", "originalCommit": "de32725390e55bf2af3aef791c80e7191075b87d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ5OTE1MQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471499151", "bodyText": "Can be combined with previous if block which also does the same thing. Also, the comment says \"column stats will be inaccurate\" but we are resetting both basic and column stats. Correct the log message and comment accordingly.", "author": "sankarh", "createdAt": "2020-08-17T14:00:38Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -3185,7 +3185,7 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n     //column stats will be inaccurate\n     if (resetStatistics) {\n       LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.clearColumnStatsState(tbl.getParameters());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTQ5OTQzOQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471499439", "bodyText": "Nit: Need a space after comma \",\".", "author": "sankarh", "createdAt": "2020-08-17T14:01:05Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -3185,7 +3185,7 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n     //column stats will be inaccurate\n     if (resetStatistics) {\n       LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.clearColumnStatsState(tbl.getParameters());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUwODQyNg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471508426", "bodyText": "Even during loadPartition, we need to reset stats in table properties as well which is missing now.", "author": "sankarh", "createdAt": "2020-08-17T14:15:07Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -3185,7 +3185,7 @@ public void loadTable(Path loadPath, String tableName, LoadFileType loadFileType\n     //column stats will be inaccurate\n     if (resetStatistics) {\n       LOG.debug(\"Clearing table statistics for \" + tbl.getDbName() + \".\" + tbl.getTableName());\n-      StatsSetupConst.clearColumnStatsState(tbl.getParameters());\n+      StatsSetupConst.setBasicStatsState(tbl.getParameters(),StatsSetupConst.FALSE);", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMDE2OQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471510169", "bodyText": "Nit: Add space before \"(\"", "author": "sankarh", "createdAt": "2020-08-17T14:17:34Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -404,6 +404,21 @@ public void testImportPartitionedOrc() throws Exception {\n \n     //load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties\n+    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert\n+        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+\n+    //check basic stats in partition properties\n+    List<String> rsPartitions = runStatementOnDriver(\"show partitions T\");\n+    for(String rsPartition : rsPartitions) {", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMDQ3MA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471510470", "bodyText": "Nit: Add space before and after \"+\".", "author": "sankarh", "createdAt": "2020-08-17T14:17:58Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -404,6 +404,21 @@ public void testImportPartitionedOrc() throws Exception {\n \n     //load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties\n+    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert\n+        .assertEquals(\"COLUMN_STATS_ACCURATE of imported table\", rsProperties.contains(\"COLUMN_STATS_ACCURATE\"), false);\n+\n+    //check basic stats in partition properties\n+    List<String> rsPartitions = runStatementOnDriver(\"show partitions T\");\n+    for(String rsPartition : rsPartitions) {\n+      List<String> rsPartitionProperties = runStatementOnDriver(\"describe formatted T partition(\"+ rsPartition +\")\");", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMTM0OQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471511349", "bodyText": "Nit: Remove extra blank line.", "author": "sankarh", "createdAt": "2020-08-17T14:19:17Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMTQ4Nw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471511487", "bodyText": "Nit: Remove this blank line.", "author": "sankarh", "createdAt": "2020-08-17T14:19:31Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMTg4MA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471511880", "bodyText": "Nit: Add single blank line before a comment line. Check below places too.", "author": "sankarh", "createdAt": "2020-08-17T14:20:04Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMjcwNg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471512706", "bodyText": "The comment seems incorrect. This is non-partitioned table.", "author": "sankarh", "createdAt": "2020-08-17T14:21:21Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n+    final int[][] rows = { { 3 } };\n+    //now we have an archive with 3 partitions", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUxMzIyOA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471513228", "bodyText": "Comment incorrect. Tstage is source table.", "author": "sankarh", "createdAt": "2020-08-17T14:22:05Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUyMDk0MQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471520941", "bodyText": "Nit: The method definition and annotation can be in separate lines.", "author": "sankarh", "createdAt": "2020-08-17T14:33:10Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUyNDYzMg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471524632", "bodyText": "Can we check if stats are set in source table Tstage and their partitions?", "author": "sankarh", "createdAt": "2020-08-17T14:38:38Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -404,6 +404,21 @@ public void testImportPartitionedOrc() throws Exception {\n \n     //load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties\n+    List<String> rsProperties = runStatementOnDriver(\"show tblproperties T\");", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUyNTIxNA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471525214", "bodyText": "Can we check if stats are set in source table Tstage?", "author": "sankarh", "createdAt": "2020-08-17T14:39:26Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {\n+\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+    runStatementOnDriver(\"create table T (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //Tstage is the target table\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n+    final int[][] rows = { { 3 } };", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTUyNjM5Nw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r471526397", "bodyText": "Can we also check if import sets stats to true in case of autostats_gather is set to true? For both partitioned and non-partitioned tables. Also check the values of stats listed in StatsSetupConst.SUPPORTED_STATS (atleast ROWNUM should match) in both source and target tables and they should match.", "author": "sankarh", "createdAt": "2020-08-17T14:41:04Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +581,33 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+\n+  @Test public void testImportOrc() throws Exception {", "originalCommit": "93c7930fc5b997eea4d470a8c1f7bd47edbe940c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzNTU0Mw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472335543", "bodyText": "Unused import.", "author": "sankarh", "createdAt": "2020-08-18T16:44:11Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -70,6 +70,7 @@\n \n import com.google.common.collect.ImmutableList;\n \n+import org.antlr.runtime.misc.Stats;", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzNjc3Mw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472336773", "bodyText": "Shall check resetStatistics first as it take less cpu cycles in positive flow.", "author": "sankarh", "createdAt": "2020-08-18T16:46:18Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then\n+      //clear partition column stats and set basic stats to false\n+      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzODYzMg==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472338632", "bodyText": "The comment can answer the \"why\" rather than \"what\". The below if statement is self explanatory.", "author": "sankarh", "createdAt": "2020-08-18T16:49:25Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzOTQzNw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472339437", "bodyText": "Nit: Use upper-case for first character of log message.", "author": "sankarh", "createdAt": "2020-08-18T16:50:40Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then\n+      //clear partition column stats and set basic stats to false\n+      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+        LOG.debug(", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMzOTczMw==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472339733", "bodyText": "Nit: Add single space after \"//\"", "author": "sankarh", "createdAt": "2020-08-18T16:51:11Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then\n+      //clear partition column stats and set basic stats to false", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM0NjExMA==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472346110", "bodyText": "clearColumnStatsState call is redundant as setBasicStatsState(false) will remove the column stats as well.", "author": "sankarh", "createdAt": "2020-08-18T17:01:20Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -2452,9 +2448,16 @@ private Partition loadPartitionInternal(Path loadPath, Table tbl, Map<String, St\n         skewedInfo.setSkewedColValueLocationMaps(skewedColValueLocationMaps);\n         newCreatedTpart.getSd().setSkewedInfo(skewedInfo);\n       }\n-      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER)) {\n+\n+      //if hive.stats.autogather = false or resetStatistics = true then\n+      //clear partition column stats and set basic stats to false\n+      if (!this.getConf().getBoolVar(HiveConf.ConfVars.HIVESTATSAUTOGATHER) || resetStatistics) {\n+        LOG.debug(\n+            \"clear partition column statistics and setting basic stats to false for \" + newTPart.getCompleteName());\n+        StatsSetupConst.clearColumnStatsState(newTPart.getParameters());", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM1OTE1NQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472359155", "bodyText": "Can test the import with hive.stats.autogather=true and see if stats are accurate for both partitioned and non-partitioned tables.", "author": "sankarh", "createdAt": "2020-08-18T17:21:41Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -566,4 +602,44 @@ public void testMMExportAborted() throws Exception {\n         TestTxnCommands2.stringifyValues(data), rs);\n \n   }\n-}\n+\n+  @Test\n+  public void testImportOrc() throws Exception {\n+    //Clear and Drop T and Tstage if exist\n+    runStatementOnDriver(\"drop table if exists T\");\n+    runStatementOnDriver(\"drop table if exists Tstage\");\n+\n+    //create target table - T\n+    runStatementOnDriver(\"create table T (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    //Create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) stored\" + \" as orc tblproperties('transactional'='true')\");\n+\n+    //this creates an ORC data file with correct schema under table root\n+    runStatementOnDriver(\"insert into Tstage values(1,2),(3,4),(5,6)\");\n+    final int[][] rows = { { 3 } };\n+\n+    //check Tstage statistics\n+    List<String> rsTStageProperties = runStatementOnDriver(\"show tblproperties Tstage\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of Tstage table\", true,\n+        rsTStageProperties.contains(\"COLUMN_STATS_ACCURATE\\t{\\\"BASIC_STATS\\\":\\\"true\\\"}\"));\n+    Assert.assertEquals(\"numRows of Tstage table\", true, rsTStageProperties.contains(\"numRows\\t3\"));\n+    Assert.assertEquals(\"numFiles of Tstage table\", true, rsTStageProperties.contains(\"numFiles\\t1\"));\n+\n+    //now we have an archive Tstage table\n+    runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n+\n+    //load T\n+    runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM2MDYzOQ==", "url": "https://github.com/apache/hive/pull/1370#discussion_r472360639", "bodyText": "I think, stats are false as table T was already created. Can we check if it is set to false when import create the table.", "author": "sankarh", "createdAt": "2020-08-18T17:24:12Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnExIm.java", "diffHunk": "@@ -389,21 +390,56 @@ public void testImportPartitioned() throws Exception {\n \n   @Test\n   public void testImportPartitionedOrc() throws Exception {\n+    //clear and drop table T,Tstage\n     runStatementOnDriver(\"drop table if exists T\");\n     runStatementOnDriver(\"drop table if exists Tstage\");\n-    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n-    //Tstage is the target table\n-    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\" +\n-        \" as orc tblproperties('transactional'='true')\");\n+\n+    //create target table - T\n+    runStatementOnDriver(\"create table T (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+\n+    //create source table - Tstage\n+    runStatementOnDriver(\"create table Tstage (a int, b int) partitioned by (p int) stored\"\n+        + \" as orc tblproperties('transactional'='true')\");\n+\n     //this creates an ORC data file with correct schema under table root\n     runStatementOnDriver(\"insert into Tstage values(1,2,10),(3,4,11),(5,6,12)\");\n-    final int[][] rows = {{3}};\n-    //now we have an archive with 3 partitions\n+    final int[][] rows = { { 3 } };\n+\n+    //check Partitions statistics\n+    List<String> rsTstagePartitionsProperties = runStatementOnDriver(\"show partitions Tstage\");\n+    for (String rsTstagePartition : rsTstagePartitionsProperties) {\n+      List<String> rsPartitionProperties =\n+          runStatementOnDriver(\"describe formatted Tstage partition(\" + rsTstagePartition + \")\");\n+      Assert.assertEquals(\"COLUMN_STATS_ACCURATE of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tCOLUMN_STATS_ACCURATE\\t{\\\\\\\"BASIC_STATS\\\\\\\":\\\\\\\"true\\\\\\\"}\"));\n+      Assert.assertEquals(\" of partition \" + rsTstagePartition + \" of Tstage table\", true,\n+          rsPartitionProperties.contains(\"\\tnumRows             \\t1                   \"));\n+    }\n+\n+    //now we have an archive Tstage with 3 partitions\n     runStatementOnDriver(\"export table Tstage to '\" + getWarehouseDir() + \"/1'\");\n \n     //load T\n     runStatementOnDriver(\"import table T from '\" + getWarehouseDir() + \"/1'\");\n+\n+    //check basic stats in tblproperties of T\n+    List<String> rsTProperties = runStatementOnDriver(\"show tblproperties T\");\n+    Assert.assertEquals(\"COLUMN_STATS_ACCURATE of T table\", false,", "originalCommit": "3942237ead71d0abe1a2359f456107faa6f38a2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7b138022419df343e369a704c6c61d52fc7fecf7", "url": "https://github.com/apache/hive/commit/7b138022419df343e369a704c6c61d52fc7fecf7", "message": "HIVE-23887: Reset table level basic/column stats during import", "committedDate": "2020-08-21T11:18:16Z", "type": "commit"}, {"oid": "7b138022419df343e369a704c6c61d52fc7fecf7", "url": "https://github.com/apache/hive/commit/7b138022419df343e369a704c6c61d52fc7fecf7", "message": "HIVE-23887: Reset table level basic/column stats during import", "committedDate": "2020-08-21T11:18:16Z", "type": "forcePushed"}]}