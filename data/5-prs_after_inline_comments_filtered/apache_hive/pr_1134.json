{"pr_number": 1134, "pr_title": "HIVE-23703: Major QB compaction with multiple FileSinkOperators results in data loss and one original file", "pr_createdAt": "2020-06-17T07:59:15Z", "pr_url": "https://github.com/apache/hive/pull/1134", "timeline": [{"oid": "06e1ce9e18ad39431fa7d17a211047b2e6be9e1e", "url": "https://github.com/apache/hive/commit/06e1ce9e18ad39431fa7d17a211047b2e6be9e1e", "message": "HIVE-23703: Major QB compaction with multiple FileSinkOperators results in data loss and one original file", "committedDate": "2020-06-17T07:57:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4MjIzNQ==", "url": "https://github.com/apache/hive/pull/1134#discussion_r441382235", "bodyText": "Can we do this outside the process loop? Maybe saving some time, since this part of the code runs for every item, and this can cause performance degradation (I guess)", "author": "pvary", "createdAt": "2020-06-17T08:43:19Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/OrcFileMergeOperator.java", "diffHunk": "@@ -113,7 +116,11 @@ private void processKeyValuePairs(Object key, Object value)\n \n       // store the orc configuration from the first file. All other files should\n       // match this configuration before merging else will not be merged\n-      if (outWriter == null) {\n+      int bucketId = 0;\n+      if (conf.getIsCompactionTable()) {", "originalCommit": "06e1ce9e18ad39431fa7d17a211047b2e6be9e1e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQxNTk0NA==", "url": "https://github.com/apache/hive/pull/1134#discussion_r441415944", "bodyText": "Ok.. as discussed this was an overreaction \ud83d\ude04", "author": "pvary", "createdAt": "2020-06-17T09:36:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4MjIzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4MzY0NA==", "url": "https://github.com/apache/hive/pull/1134#discussion_r441383644", "bodyText": "Could you please add some clarification to the tables used in compaction, like technical/helper tables used in compaction.", "author": "deniskuzZ", "createdAt": "2020-06-17T08:45:20Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java", "diffHunk": "@@ -334,6 +334,18 @@ public void initializeBucketPaths(int filesIdx, String taskId, boolean isNativeT\n         if (!isMmTable && !isDirectInsert) {\n           if (!bDynParts && !isSkewedStoredAsSubDirectories) {\n             finalPaths[filesIdx] = new Path(parent, taskWithExt);\n+            if (conf.isCompactionTable()) {\n+              // tables used in compaction are external and non-acid. We need to keep track of", "originalCommit": "06e1ce9e18ad39431fa7d17a211047b2e6be9e1e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUxMDEwMg==", "url": "https://github.com/apache/hive/pull/1134#discussion_r441510102", "bodyText": "Done", "author": "klcopp", "createdAt": "2020-06-17T12:35:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4MzY0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4MzcxMA==", "url": "https://github.com/apache/hive/pull/1134#discussion_r441383710", "bodyText": "nit: I see this kind of formatting very rarely in Hive code", "author": "pvary", "createdAt": "2020-06-17T08:45:27Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java", "diffHunk": "@@ -4123,9 +4125,28 @@ private static void copyFiles(final HiveConf conf, final FileSystem destFs,\n           }\n           throw new HiveException(e);\n         }\n-      } else {\n+      else {", "originalCommit": "06e1ce9e18ad39431fa7d17a211047b2e6be9e1e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUxMDE3Mw==", "url": "https://github.com/apache/hive/pull/1134#discussion_r441510173", "bodyText": "Typo, done.", "author": "klcopp", "createdAt": "2020-06-17T12:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4MzcxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4NTAzMA==", "url": "https://github.com/apache/hive/pull/1134#discussion_r441385030", "bodyText": "nit: Maybe add a missing space too :)", "author": "pvary", "createdAt": "2020-06-17T08:47:36Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHiveCopyFiles.java", "diffHunk": "@@ -83,7 +83,8 @@ public void testRenameNewFilesOnSameFileSystem() throws IOException {\n     FileSystem targetFs = targetPath.getFileSystem(hiveConf);\n \n     try {\n-      Hive.copyFiles(hiveConf, sourcePath, targetPath, targetFs, isSourceLocal, NO_ACID, false,null, false, false, false);\n+      Hive.copyFiles(hiveConf, sourcePath, targetPath, targetFs, isSourceLocal, NO_ACID, false,null,", "originalCommit": "06e1ce9e18ad39431fa7d17a211047b2e6be9e1e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUxMDE4NQ==", "url": "https://github.com/apache/hive/pull/1134#discussion_r441510185", "bodyText": "Done", "author": "klcopp", "createdAt": "2020-06-17T12:35:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4NTAzMA=="}], "type": "inlineReview"}, {"oid": "eff3cb725ee8bfdc272c63416eb023083ca13a8d", "url": "https://github.com/apache/hive/commit/eff3cb725ee8bfdc272c63416eb023083ca13a8d", "message": "Addressed review comments, added a check for writeid/rowid ascending order in compaction result files", "committedDate": "2020-06-17T13:44:57Z", "type": "commit"}]}