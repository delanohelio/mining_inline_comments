{"pr_number": 1109, "pr_title": "HIVE-22015: Add table constraints in CachedStore", "pr_createdAt": "2020-06-15T10:29:36Z", "pr_url": "https://github.com/apache/hive/pull/1109", "timeline": [{"oid": "c6f370c129c3f977afb76740275841dabcc7ce34", "url": "https://github.com/apache/hive/commit/c6f370c129c3f977afb76740275841dabcc7ce34", "message": "renaming variables/reorganizing imports", "committedDate": "2020-06-15T17:00:08Z", "type": "forcePushed"}, {"oid": "111bf3dffed83715334e1d6c029febffdda2e6e7", "url": "https://github.com/apache/hive/commit/111bf3dffed83715334e1d6c029febffdda2e6e7", "message": "renaming variables/reorganizing imports", "committedDate": "2020-06-18T08:53:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU3NzU0MQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r445577541", "bodyText": "Should be 2 spaced indentation. Check other places too.", "author": "sankarh", "createdAt": "2020-06-25T13:55:56Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -402,6 +385,32 @@ private static void updateStatsForAlterTable(RawStore rawStore, Table tblBefore,\n         sharedCache.removePartitionColStatsFromCache(catalogName, dbName, tableName, msgPart.getPartValues(),\n             msgPart.getColName());\n         break;\n+      case MessageBuilder.ADD_PRIMARYKEY_EVENT:\n+          AddPrimaryKeyMessage addPrimaryKeyMessage = deserializer.getAddPrimaryKeyMessage(message);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU5OTYzOA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r445599638", "bodyText": "It seems missed to assign the return values from these rawStore calls to the local variables.", "author": "sankarh", "createdAt": "2020-06-25T14:26:18Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +556,24 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              rawStore.getPrimaryKeys(catName, dbName, tblName);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwMzUyNw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r445603527", "bodyText": "Too many arguments. Can we have another class (TableCacheObjects) to store all these arguments using set methods?", "author": "sankarh", "createdAt": "2020-06-25T14:31:32Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +556,24 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getForeignKeys\");\n+              rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getUniqueConstraints\");\n+              rawStore.getUniqueConstraints(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              Deadline.startTimer(\"getNotNullConstraints\");\n+              rawStore.getNotNullConstraints(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+\n               // If the table could not cached due to memory limit, stop prewarm\n               boolean isSuccess = sharedCache\n                   .populateTableInCache(table, tableColStats, partitions, partitionColStats, aggrStatsAllPartitions,", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg5ODQwNA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446898404", "bodyText": "Done. Though the new class just contains constraints objects for now, we can have a different refactoring jira for partition/column stat that can also refactor the array created to store size/dirtyCache variable.", "author": "adesh-rao", "createdAt": "2020-06-29T11:29:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwMzUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwMzQyMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448903420", "bodyText": "I think, we can make this refactoring also here itself. It needs change only in this method and so less risky. Having another ticket for this is time consuming.", "author": "sankarh", "createdAt": "2020-07-02T10:24:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwMzUyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYwOTY5OA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r445609698", "bodyText": "Failure logs can have catName and dbName too.", "author": "sankarh", "createdAt": "2020-06-25T14:39:33Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +902,73 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {\n+        LOG.info(\"Updating CachedStore: unable to read foreign keys of table: \" + tblName, e);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNDQ2MA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446104460", "bodyText": "Arguments names can be uks and uk.", "author": "sankarh", "createdAt": "2020-06-26T10:32:49Z", "path": "itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStoreUpdateUsingEvents.java", "diffHunk": "@@ -295,6 +295,178 @@ public void testTableOpsForUpdateUsingEvents() throws Exception {\n     sharedCache.getSdCache().clear();\n   }\n \n+  @Test\n+  public void testConstraintsForUpdateUsingEvents() throws Exception {\n+    long lastEventId = -1;\n+    RawStore rawStore = hmsHandler.getMS();\n+\n+    // Prewarm CachedStore\n+    CachedStore.setCachePrewarmedState(false);\n+    CachedStore.prewarm(rawStore);\n+\n+    // Add a db via rawStore\n+    String dbName = \"test_table_ops\";\n+    String dbOwner = \"user1\";\n+    Database db = createTestDb(dbName, dbOwner);\n+    hmsHandler.create_database(db);\n+    db = rawStore.getDatabase(DEFAULT_CATALOG_NAME, dbName);\n+\n+    String foreignDbName = \"test_table_ops_foreign\";\n+    Database foreignDb = createTestDb(foreignDbName, dbOwner);\n+    hmsHandler.create_database(foreignDb);\n+    foreignDb = rawStore.getDatabase(DEFAULT_CATALOG_NAME, foreignDbName);\n+    // Add a table via rawStore\n+    String tblName = \"tbl\";\n+    String tblOwner = \"user1\";\n+    FieldSchema col1 = new FieldSchema(\"col1\", \"int\", \"integer column\");\n+    FieldSchema col2 = new FieldSchema(\"col2\", \"string\", \"string column\");\n+    List<FieldSchema> cols = new ArrayList<FieldSchema>();\n+    cols.add(col1);\n+    cols.add(col2);\n+    List<FieldSchema> ptnCols = new ArrayList<FieldSchema>();\n+    Table tbl = createTestTbl(dbName, tblName, tblOwner, cols, ptnCols);\n+    String foreignTblName = \"ftbl\";\n+    Table foreignTbl = createTestTbl(foreignDbName, foreignTblName, tblOwner, cols, ptnCols);\n+\n+    SQLPrimaryKey key = new SQLPrimaryKey(dbName, tblName, col1.getName(), 1, \"pk1\",\n+            false, false, false);\n+    SQLUniqueConstraint uC = new SQLUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName,\n+            col1.getName(), 2, \"uc1\", false, false, false);\n+    SQLNotNullConstraint nN = new SQLNotNullConstraint(DEFAULT_CATALOG_NAME, dbName, tblName,\n+            col1.getName(), \"nn1\", false, false, false);\n+    SQLForeignKey foreignKey = new SQLForeignKey(key.getTable_db(), key.getTable_name(), key.getColumn_name(),\n+            foreignDbName, foreignTblName, key.getColumn_name(), 2, 1,2,\n+            \"fk1\", key.getPk_name(), false, false, false);\n+\n+    hmsHandler.create_table_with_constraints(tbl,\n+            Arrays.asList(key), null, Arrays.asList(uC), Arrays.asList(nN), null, null);\n+    hmsHandler.create_table_with_constraints(foreignTbl, null, Arrays.asList(foreignKey),\n+            null, null, null, null);\n+\n+    tbl = rawStore.getTable(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    foreignTbl = rawStore.getTable(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName);\n+\n+    // Read database, table via CachedStore\n+    Database dbRead= sharedCache.getDatabaseFromCache(DEFAULT_CATALOG_NAME, dbName);\n+    Assert.assertEquals(db, dbRead);\n+    Table tblRead = sharedCache.getTableFromCache(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    compareTables(tblRead, tbl);\n+\n+    Table foreignTblRead = sharedCache.getTableFromCache(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName);\n+    compareTables(foreignTblRead, foreignTbl);\n+\n+    List<SQLPrimaryKey> keys = rawStore.getPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLPrimaryKey> keysRead = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForPrimarkaryKey(keysRead, 1, 0, keys.get(0));\n+\n+    List<SQLNotNullConstraint> nNs = rawStore.getNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLNotNullConstraint> nNsRead = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForNotNullConstraints(nNsRead, 1, 0, nNs.get(0));\n+\n+    List<SQLUniqueConstraint> uns = rawStore.getUniqueConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    List<SQLUniqueConstraint> unsRead = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForUniqueConstraints(unsRead, 1, 0, uns.get(0));\n+\n+    List<SQLForeignKey> fks = rawStore.getForeignKeys(DEFAULT_CATALOG_NAME, dbName, tblName, foreignDbName, foreignTblName);\n+    List<SQLForeignKey> fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName,\n+            foreignTblName, dbName, tblName);\n+    assertsForForeignKey(fksRead, 1, 0, fks.get(0));\n+\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            dbName, foreignTblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            foreignDbName, tblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            foreignDbName, foreignTblName);\n+    Assert.assertEquals(fksRead.size(), 0);\n+\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName,\n+            null, null);\n+    Assert.assertEquals(fksRead.size(), 1);\n+\n+    // Dropping the constraint\n+    DropConstraintRequest dropConstraintRequest = new DropConstraintRequest(foreignDbName, foreignTblName, foreignKey.getFk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, key.getPk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, nN.getNn_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+    dropConstraintRequest = new DropConstraintRequest(dbName, tblName, uC.getUk_name());\n+    hmsHandler.drop_constraint(dropConstraintRequest);\n+\n+    keys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    nNs = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    uns = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName, dbName, tblName);\n+    Assert.assertEquals(keys.size(), 0);\n+    Assert.assertEquals(nNs.size(), 0);\n+    Assert.assertEquals(uns.size(), 0);\n+    Assert.assertEquals(fksRead.size(), 0);\n+\n+    // Adding keys back\n+    AddPrimaryKeyRequest req = new AddPrimaryKeyRequest(Arrays.asList(key));\n+    hmsHandler.add_primary_key(req);\n+    keys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForPrimarkaryKey(keys, 1, 0, key);\n+\n+    AddUniqueConstraintRequest uniqueConstraintRequest = new AddUniqueConstraintRequest(Arrays.asList(uC));\n+    hmsHandler.add_unique_constraint(uniqueConstraintRequest);\n+    uns = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForUniqueConstraints(uns, 1, 0, uC);\n+\n+    AddNotNullConstraintRequest notNullConstraintRequest = new AddNotNullConstraintRequest(Arrays.asList(nN));\n+    hmsHandler.add_not_null_constraint(notNullConstraintRequest);\n+    nNs = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, dbName, tblName);\n+    assertsForNotNullConstraints(nNs, 1, 0, nN);\n+\n+    AddForeignKeyRequest foreignKeyRequest = new AddForeignKeyRequest(Arrays.asList(foreignKey));\n+    hmsHandler.add_foreign_key(foreignKeyRequest);\n+    fksRead = sharedCache.listCachedForeignKeys(DEFAULT_CATALOG_NAME, foreignDbName, foreignTblName, dbName, tblName);\n+    assertsForForeignKey(fksRead, 1, 0, foreignKey);\n+\n+    sharedCache.getDatabaseCache().clear();\n+    sharedCache.clearTableCache();\n+    sharedCache.getSdCache().clear();\n+  }\n+\n+  private void assertsForPrimarkaryKey(List<SQLPrimaryKey> keys, int size, int ele, SQLPrimaryKey key) {\n+    Assert.assertEquals(keys.size(), size);\n+    Assert.assertEquals(keys.get(ele).getPk_name(), key.getPk_name());\n+    Assert.assertEquals(keys.get(ele).getColumn_name(), key.getColumn_name());\n+    Assert.assertEquals(keys.get(ele).getTable_name(), key.getTable_name());\n+    Assert.assertEquals(keys.get(ele).getTable_db(), key.getTable_db());\n+  }\n+\n+  private void assertsForForeignKey(List<SQLForeignKey> keys, int size, int ele, SQLForeignKey key) {\n+    Assert.assertEquals(keys.size(), size);\n+    Assert.assertEquals(keys.get(ele).getPk_name(), key.getPk_name());\n+    Assert.assertEquals(keys.get(ele).getFk_name(), key.getFk_name());\n+    Assert.assertEquals(keys.get(ele).getFktable_db(), key.getFktable_db());\n+    Assert.assertEquals(keys.get(ele).getFktable_name(), key.getFktable_name());\n+    Assert.assertEquals(keys.get(ele).getPktable_db(), key.getPktable_db());\n+    Assert.assertEquals(keys.get(ele).getPktable_name(), key.getPktable_name());\n+    Assert.assertEquals(keys.get(ele).getPkcolumn_name(), key.getPkcolumn_name());\n+    Assert.assertEquals(keys.get(ele).getFkcolumn_name(), key.getFkcolumn_name());\n+  }\n+\n+  private void assertsForNotNullConstraints(List<SQLNotNullConstraint> nns, int size, int ele, SQLNotNullConstraint nN) {\n+    Assert.assertEquals(nns.size(), size);\n+    Assert.assertEquals(nns.get(ele).getNn_name(), nN.getNn_name());\n+    Assert.assertEquals(nns.get(ele).getColumn_name(), nN.getColumn_name());\n+    Assert.assertEquals(nns.get(ele).getTable_name(), nN.getTable_name());\n+    Assert.assertEquals(nns.get(ele).getTable_db(), nN.getTable_db());\n+  }\n+\n+  private void assertsForUniqueConstraints(List<SQLUniqueConstraint> nns, int size, int ele, SQLUniqueConstraint nN) {", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446106308", "bodyText": "Is it possible that table is cached but not the constraints?", "author": "sankarh", "createdAt": "2020-06-26T10:37:18Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2599,82 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwMDc0Mw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446900743", "bodyText": "Yes, While updating the cache, there is a possibility that table got updated but constraints didn't (they are yet to be updated). But this is similar to partition/columnStats caching.", "author": "adesh-rao", "createdAt": "2020-06-29T11:33:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNTU4Ng==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448905586", "bodyText": "I think, we should handle the case where table object is cached but constraints are not cached. Now, it seems, we just return empty key list to caller but ideally, we should invoke rawStore.", "author": "sankarh", "createdAt": "2020-07-02T10:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNTc5OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449525799", "bodyText": "done. Fetching keys from rawStore if we got empty/null.", "author": "adesh-rao", "createdAt": "2020-07-03T11:07:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwNjMwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEwODU0NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446108545", "bodyText": "If foreign db or table names are null, then we should just invoke rawStore apis instead of using empty string. It can cause issues.", "author": "sankarh", "createdAt": "2020-06-26T10:42:48Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2599,82 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    catName = normalizeIdentifier(catName);\n+    foreignDbName = (foreignDbName == null) ? \"\" : normalizeIdentifier(foreignDbName);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExNTY5OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446115699", "bodyText": "Indentation of \"case' statement is not matching with others.", "author": "sankarh", "createdAt": "2020-06-26T11:00:57Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -410,6 +436,34 @@ private void updateMemberSize(MemberName mn, Integer size, SizeMode mode) {\n           aggrColStatsCacheSize = size;\n         }\n         break;\n+      case PRIMARY_KEY_CACHE:\n+        if (mode == SizeMode.Delta) {\n+          primaryKeyCacheSize += size;\n+        } else {\n+          primaryKeyCacheSize = size;\n+        }\n+        break;\n+        case FOREIGN_KEY_CACHE:", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExNzA4OA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446117088", "bodyText": "Shall consolidate all these size variables into an array(say, memberObjectsSize) of size = (number of items in enum MemberName) and can refer to it using enum value as index. It reduces lot of code especially the switch cases.", "author": "sankarh", "createdAt": "2020-06-26T11:04:29Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -265,6 +270,10 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private int partitionCacheSize;\n     private int partitionColStatsCacheSize;\n     private int aggrColStatsCacheSize;\n+    private int primaryKeyCacheSize;", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjExODQ2MA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446118460", "bodyText": "Same as size, even dirty check boolean also can be an array.", "author": "sankarh", "createdAt": "2020-06-26T11:07:39Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -287,6 +296,18 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n         new ConcurrentHashMap<String, List<ColumnStatisticsObj>>();\n     private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n \n+    private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n+    private AtomicBoolean isPrimaryKeyCacheDirty = new AtomicBoolean(false);", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyMjUxMQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446122511", "bodyText": "Why do we need to pass both member name and constraint class name. We can derive it from member name itself.", "author": "sankarh", "createdAt": "2020-06-26T11:17:09Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNDk3MQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446124971", "bodyText": "Can be a switch-case.", "author": "sankarh", "createdAt": "2020-06-26T11:22:45Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n+              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n+              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             Class constraintClass,\n+                             boolean fromPrewarm,\n+                             MemberName mn,\n+                             AtomicBoolean dirtyConstaintVariable) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {\n+          if (constraintClass == SQLPrimaryKey.class) {", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MDgxMQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446140811", "bodyText": "Double assignment. Shall directly return from here and avoid local variable.", "author": "sankarh", "createdAt": "2020-06-26T12:00:52Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +524,110 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, SQLPrimaryKey.class, fromPrewarm,\n+              MemberName.PRIMARY_KEY_CACHE, this.isPrimaryKeyCacheDirty);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, SQLForeignKey.class, fromPrewarm,\n+              MemberName.FOREIGN_KEY_CACHE, this.isForeignKeyCacheDirty);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, SQLUniqueConstraint.class, fromPrewarm,\n+              MemberName.UNIQUE_CONSTRAINT_CACHE, this.isUniqueConstraintCacheDirty);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, SQLNotNullConstraint.class, fromPrewarm,\n+              MemberName.NOTNULL_CONSTRAINT_CACHE, this.isNotNullConstraintCacheDirty);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             Class constraintClass,\n+                             boolean fromPrewarm,\n+                             MemberName mn,\n+                             AtomicBoolean dirtyConstaintVariable) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {\n+          if (constraintClass == SQLPrimaryKey.class) {\n+            SQLPrimaryKey key = (SQLPrimaryKey) constraintsList.get(i);\n+            this.primaryKeyCache.put(key.getPk_name(), key);\n+          } else if (constraintClass == SQLForeignKey.class) {\n+            SQLForeignKey key = (SQLForeignKey) constraintsList.get(i);\n+            this.foreignKeyCache.put(key.getFk_name(), key);\n+          } else if (constraintClass == SQLNotNullConstraint.class) {\n+            SQLNotNullConstraint key = (SQLNotNullConstraint) constraintsList.get(i);\n+            this.notNullConstraintCache.put(key.getNn_name(), key);\n+          } else if (constraintClass == SQLUniqueConstraint.class) {\n+            SQLUniqueConstraint key = (SQLUniqueConstraint) constraintsList.get(i);\n+            this.uniqueConstraintCache.put(key.getUk_name(), key);\n+          }\n+          size += getObjectSize(constraintClass, constraintsList.get(i));\n+        }\n+\n+        if (!fromPrewarm) {\n+          dirtyConstaintVariable.set(true);\n+        }\n+\n+        updateMemberSize(mn, size, SizeMode.Delta);\n+        return true;\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public List<SQLPrimaryKey> getPrimaryKeys() {\n+      List<SQLPrimaryKey> keys = new ArrayList<>();\n+      try {\n+        tableLock.readLock().lock();\n+        keys = new ArrayList<>(this.primaryKeyCache.values());", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MzQyMQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446143421", "bodyText": "It can happen that for multi HMS instance case, table can be cached but not constraints right? If yes, then it can hit here.", "author": "sankarh", "createdAt": "2020-06-26T12:06:51Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +672,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          isPrimaryKeyCacheDirty.set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          isForeignKeyCacheDirty.set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          isNotNullConstraintCacheDirty.set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          isUniqueConstraintCacheDirty.set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          // Should not reach here", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDUzNg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446144536", "bodyText": "Shouldn't we use ConcurrentHashMap here?", "author": "sankarh", "createdAt": "2020-06-26T12:09:37Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +672,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          isPrimaryKeyCacheDirty.set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          isForeignKeyCacheDirty.set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          isNotNullConstraintCacheDirty.set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          isUniqueConstraintCacheDirty.set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          // Should not reach here\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new HashMap<>();", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NjU1MQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446146551", "bodyText": "Shall use List.stream().filter() instead of loop and check.", "author": "sankarh", "createdAt": "2020-06-26T12:14:20Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1870,6 +2247,125 @@ public void removePartitionsFromCache(String catName, String dbName, String tblN\n     return parts;\n   }\n \n+  public List<SQLPrimaryKey> listCachedPrimaryKeys(String catName, String dbName, String tblName) {\n+    List<SQLPrimaryKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, dbName, tblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getPrimaryKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+    return keys;\n+  }\n+\n+  public List<SQLForeignKey> listCachedForeignKeys(String catName, String foreignDbName, String foreignTblName,\n+                                                   String parentDbName, String parentTblName) {\n+    List<SQLForeignKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, foreignDbName, foreignTblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getForeignKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+\n+    // filter out required foreign keys based on parent db/tbl name\n+    if (!StringUtils.isEmpty(parentTblName) && !StringUtils.isEmpty(parentDbName)) {\n+      List<SQLForeignKey> filteredKeys = new ArrayList<>();\n+      for (SQLForeignKey key : keys) {", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0ODM0OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r446148349", "bodyText": "Too many blank lines.", "author": "sankarh", "createdAt": "2020-06-26T12:18:27Z", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1507,6 +1490,305 @@ public Object call() {\n     cachedStore.shutdown();\n   }\n \n+  @Test\n+  public void testPrimaryKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLPrimaryKey> origKeys = createPrimaryKeys(tbl);\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLPrimaryKey> cachedKeys = sharedCache.listCachedPrimaryKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLPrimaryKey modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setPk_name(\"pk_modified\");\n+\n+    sharedCache.refreshPrimaryKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testNotNullConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLNotNullConstraint> origKeys = createNotNullConstraint(tbl);\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLNotNullConstraint> cachedKeys = sharedCache.listCachedNotNullConstraints(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLNotNullConstraint modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setNn_name(\"nn_modified\");\n+\n+    sharedCache.refreshNotNullConstraintsInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn_modified\");\n+\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testUniqueConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLUniqueConstraint> origKeys = createUniqueConstraint(tbl);\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLUniqueConstraint> cachedKeys = sharedCache.listCachedUniqueConstraint(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Refresh Operation\n+    SQLUniqueConstraint modifiedKey = origKeys.get(0);\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setUk_name(\"uk_modified\");\n+\n+    sharedCache.refreshUniqueConstraintsInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testForeignKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLForeignKey> origKeys = createForeignKeys(tbl, tbl);\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLForeignKey> cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // List operation with different parent table\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"dummyDB\", \"dummyTable\");\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    // Refresh Operation\n+    SQLForeignKey modifiedKey = origKeys.get(0);\n+    modifiedKey.setFkcolumn_name(\"col3\");\n+    modifiedKey.setFk_name(\"fk_modified\");\n+\n+    sharedCache.refreshForeignKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col3\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // Add more primary keys\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk1\");\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"fk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+", "originalCommit": "cb351c0a444bc8d5b5d88feff00a23f5b76d3ac8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "628f0e7fa1891f05946b843bdb2a3463b43d3d08", "url": "https://github.com/apache/hive/commit/628f0e7fa1891f05946b843bdb2a3463b43d3d08", "message": "address review comments part 2", "committedDate": "2020-06-29T10:53:15Z", "type": "forcePushed"}, {"oid": "f009640f85ff76ff1041ef75462b4e9058eae295", "url": "https://github.com/apache/hive/commit/f009640f85ff76ff1041ef75462b4e9058eae295", "message": "Fix compilation issue", "committedDate": "2020-06-30T10:48:44Z", "type": "forcePushed"}, {"oid": "22bcebbf2fa85625e1a78a01e9ce74ff480d08d0", "url": "https://github.com/apache/hive/commit/22bcebbf2fa85625e1a78a01e9ce74ff480d08d0", "message": "Fix compilation issue", "committedDate": "2020-07-01T10:52:57Z", "type": "forcePushed"}, {"oid": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "url": "https://github.com/apache/hive/commit/00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "message": "Fix compilation issue", "committedDate": "2020-07-02T07:23:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNDk2MA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r447414960", "bodyText": "We should take the same path if parentDbName or parentTblName is null.", "author": "sankarh", "createdAt": "2020-06-30T05:16:56Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2610,87 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    if (foreignDbName == null || foreignTblName == null) {", "originalCommit": "f7a7e0d79b5be5dc856591567daed4e825811757", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNTM2Mw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r447415363", "bodyText": "This flow is a candidate for improvement as it tries to fetch all foreignkeys of give parent table and vice-versa which is frequent operations. Pls create a follow-up JIRA to use CachedStore for this case too.", "author": "sankarh", "createdAt": "2020-06-30T05:18:25Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2497,26 +2610,87 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+\n+    return keys;\n   }\n \n   @Override public List<SQLForeignKey> getForeignKeys(String catName, String parentDbName, String parentTblName,\n       String foreignDbName, String foreignTblName) throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);\n+     // Get correct ForeignDBName and TableName\n+    if (foreignDbName == null || foreignTblName == null) {\n+      return rawStore.getForeignKeys(catName, parentDbName, parentTblName, foreignDbName, foreignTblName);", "originalCommit": "f7a7e0d79b5be5dc856591567daed4e825811757", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU5OTU2Ng==", "url": "https://github.com/apache/hive/pull/1109#discussion_r450599566", "bodyText": "Created https://issues.apache.org/jira/browse/HIVE-23810 for followup.", "author": "adesh-rao", "createdAt": "2020-07-07T04:05:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQxNTM2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDAwMw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448904003", "bodyText": "Method is to \"update\" but the log msg says \"read\"", "author": "sankarh", "createdAt": "2020-07-02T10:25:43Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +909,77 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {\n+        LOG.info(\"Updating CachedStore: unable to read foreign keys of catalog: \" + catName + \", database: \"", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyODgzNw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449528837", "bodyText": "Fixed.", "author": "adesh-rao", "createdAt": "2020-07-03T11:15:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDAwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDI2Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448904262", "bodyText": "Shall limit the try-catch block only for rawStore calls.", "author": "sankarh", "createdAt": "2020-07-02T10:26:13Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -867,6 +909,77 @@ private void updateTableColStats(RawStore rawStore, String catName, String dbNam\n       }\n     }\n \n+    private void updateTableForeignKeys(RawStore rawStore, String catName, String dbName, String tblName) {\n+      LOG.debug(\"CachedStore: updating cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+              dbName, tblName);\n+      try {\n+        Deadline.startTimer(\"getForeignKeys\");\n+        List<SQLForeignKey> fks = rawStore.getForeignKeys(catName, null, null, dbName, tblName);\n+        Deadline.stopTimer();\n+        sharedCache.refreshForeignKeysInCache(StringUtils.normalizeIdentifier(catName),\n+                StringUtils.normalizeIdentifier(dbName), StringUtils.normalizeIdentifier(tblName), fks);\n+        LOG.debug(\"CachedStore: updated cached foreign keys objects for catalog: {}, database: {}, table: {}\", catName,\n+                dbName, tblName);\n+      } catch (MetaException e) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNTUzOA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449525538", "bodyText": "done.", "author": "adesh-rao", "createdAt": "2020-07-03T11:06:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNDI2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448907251", "bodyText": "We need to check if the caller queries the foreign key constraints using parentDb and table as input. If yes, it make sense to map it against parent table object rather than foreign table.", "author": "sankarh", "createdAt": "2020-07-02T10:32:16Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -543,10 +557,30 @@ static void prewarm(RawStore rawStore) {\n                 tableColStats = rawStore.getTableColumnStatistics(catName, dbName, tblName, colNames, CacheUtils.HIVE_ENGINE);\n                 Deadline.stopTimer();\n               }\n+              Deadline.startTimer(\"getPrimaryKeys\");\n+              primaryKeys = rawStore.getPrimaryKeys(catName, dbName, tblName);\n+              Deadline.stopTimer();\n+              cacheObjects.setPrimaryKeys(primaryKeys);\n+\n+              Deadline.startTimer(\"getForeignKeys\");\n+              foreignKeys = rawStore.getForeignKeys(catName, null, null, dbName, tblName);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM4NzE2Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449387162", "bodyText": "Then should we store foreign key mappings against parentDb and table for quick access (otherwise we will be scanning all the db/tables in cache)?\nAnd this also means we will be keeping two copies, one with parent table and another with foreign table.", "author": "adesh-rao", "createdAt": "2020-07-03T05:47:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTc4OTQ3Nw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449789477", "bodyText": "We can have the foreignkeys kept under foreignkey table wrapper but the reference such as foreignkey db/table and key name in parent table wrapper. It will be useful when getForeignKeys is called with null for foreign db/tbl. I just want to confirm if this a frequent call with null as input. If yes, then let's do it, if not ignore this comment.", "author": "sankarh", "createdAt": "2020-07-04T17:11:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU5ODM5NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r450598395", "bodyText": "Current usages in code of getForeignKeys  contains null only for parentDb/table, foreignDb/table are always being populated. So let's skip it as you mentioned.", "author": "adesh-rao", "createdAt": "2020-07-07T03:59:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNzI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkzNjQ4NA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448936484", "bodyText": "We shall remove these variables for stats and partition too as we already have memberObjectsSize and memberCacheDirty.", "author": "sankarh", "createdAt": "2020-07-02T11:32:59Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -266,6 +272,13 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private int partitionColStatsCacheSize;", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk2ODg5Mw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448968893", "bodyText": "Shall do the following to avoid using variable i and get(i).\nconstraintsList.stream().forEach(constraint -> {\nswitch (mn) {\ncase PRIMARY_KEY_CACHE:\nSQLPrimaryKey pk = (SQLPrimaryKey) constraint;\nthis.primaryKeyCache.put(pk.getPk_name(), pk);\nsize += getObjectSize(SQLPrimaryKey.class, constraint);\nbreak;\n...\n}\n});", "author": "sankarh", "createdAt": "2020-07-02T12:36:09Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +510,107 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n+    }\n+\n+    boolean cacheNotNulConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             boolean fromPrewarm,\n+                             MemberName mn) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for(int i=0; i<constraintsList.size(); i++) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4NjczNA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448986734", "bodyText": "Check if we need to normalize the case of \"name\" before using for search. it might be coming from user input.", "author": "sankarh", "createdAt": "2020-07-02T13:05:40Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNzE3Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449527172", "bodyText": "Fixed.", "author": "adesh-rao", "createdAt": "2020-07-03T11:10:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4NjczNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5MjMxMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448992310", "bodyText": "memberCacheDirty.set is common code and can be moved outside if-else blocks.", "author": "sankarh", "createdAt": "2020-07-02T13:14:17Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5Mjc5OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448992799", "bodyText": "Extra blank line.", "author": "sankarh", "createdAt": "2020-07-02T13:15:02Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5NDAzMw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448994033", "bodyText": "We can directly use MemberName.PRIMARY_KEY_CACHE if we assign 0 to first member in the enum.", "author": "sankarh", "createdAt": "2020-07-02T13:16:54Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5NzEyMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r448997120", "bodyText": "What is the significance of this check? memberCacheDirty flag is confusing. Pls add a comment describing the meaning of this value and how read/write to cache behave for true or false. If true means, cache is already set, then pls rename it to give correct meaning. It sounds like true means invalid cache.", "author": "sankarh", "createdAt": "2020-07-02T13:21:42Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyODY3NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449528675", "bodyText": "Updated the name of the variable. This is used during refreshOperation. If a particular Object cache is set to true, means it was updated after the last refresh operation and should be refreshed now, otherwise, current refresh operation will not modify/refresh the cache.", "author": "adesh-rao", "createdAt": "2020-07-03T11:14:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk5NzEyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMDQ4NA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449000484", "bodyText": "Add a debug log to mark the cache refresh is successful.", "author": "sankarh", "createdAt": "2020-07-02T13:26:51Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +655,130 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          this.memberCacheDirty[mn.ordinal()].set(true);\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (this.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].compareAndSet(true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n+                    + \"; the primary keys we have is dirty.\");\n+            return;\n+          }\n+          newKeys.put(key.getPk_name(), key);\n+          size += getObjectSize(SQLPrimaryKey.class, key);\n+        }\n+        primaryKeyCache = newKeys;\n+        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTUyNzIyMw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449527223", "bodyText": "done.", "author": "adesh-rao", "createdAt": "2020-07-03T11:10:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMDQ4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMjg2Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449002862", "bodyText": "TableWrapper can have setMemberCacheDirty(MemberName, boolean) method to make it clean.", "author": "sankarh", "createdAt": "2020-07-02T13:30:29Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1434,6 +1699,35 @@ public boolean populateTableInCache(Table table, ColumnStatistics tableColStats,\n     tblWrapper.isTableColStatsCacheDirty.set(false);\n     tblWrapper.isPartitionColStatsCacheDirty.set(false);\n     tblWrapper.isAggrPartitionColStatsCacheDirty.set(false);\n+\n+    if (cacheObjects.getPrimaryKeys() != null) {\n+      if(!tblWrapper.cachePrimaryKeys(cacheObjects.getPrimaryKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMzQzMg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449003432", "bodyText": "Member name is incorrect. Check other places below.", "author": "sankarh", "createdAt": "2020-07-02T13:31:20Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1434,6 +1699,35 @@ public boolean populateTableInCache(Table table, ColumnStatistics tableColStats,\n     tblWrapper.isTableColStatsCacheDirty.set(false);\n     tblWrapper.isPartitionColStatsCacheDirty.set(false);\n     tblWrapper.isAggrPartitionColStatsCacheDirty.set(false);\n+\n+    if (cacheObjects.getPrimaryKeys() != null) {\n+      if(!tblWrapper.cachePrimaryKeys(cacheObjects.getPrimaryKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);\n+\n+    if (cacheObjects.getForeignKeys() != null) {\n+      if(!tblWrapper.cacheForeignKeys(cacheObjects.getForeignKeys(), true)) {\n+        return false;\n+      }\n+    }\n+    tblWrapper.memberCacheDirty[MemberName.PRIMARY_KEY_CACHE.ordinal()].set(false);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNDUwOA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449004508", "bodyText": "We are writing in to cache. Check if we need read or write lock here? Looks like we take write lock on the table. Pls confirm if this is fine.", "author": "sankarh", "createdAt": "2020-07-02T13:32:59Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1788,6 +2082,58 @@ public void addPartitionToCache(String catName, String dbName, String tblName, P\n     }\n   }\n \n+  public void addPrimaryKeysToCache(String catName, String dbName, String tblName, List<SQLPrimaryKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ4NjAxMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449486010", "bodyText": "This is fine, the below method (cachePrimaryKeys), takes the writeLock. the read lock here, is just to get the tblWrapper object.", "author": "adesh-rao", "createdAt": "2020-07-03T09:37:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNDUwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNzMxOQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449007319", "bodyText": "Shall move this if block under if (tblWrapper != null) block above.", "author": "sankarh", "createdAt": "2020-07-02T13:37:23Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1870,6 +2228,122 @@ public void removePartitionsFromCache(String catName, String dbName, String tblN\n     return parts;\n   }\n \n+  public List<SQLPrimaryKey> listCachedPrimaryKeys(String catName, String dbName, String tblName) {\n+    List<SQLPrimaryKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, dbName, tblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getPrimaryKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+    return keys;\n+  }\n+\n+  public List<SQLForeignKey> listCachedForeignKeys(String catName, String foreignDbName, String foreignTblName,\n+                                                   String parentDbName, String parentTblName) {\n+    List<SQLForeignKey> keys = new ArrayList<>();\n+    try {\n+      cacheLock.readLock().lock();\n+      TableWrapper tblWrapper = tableCache.getIfPresent(CacheUtils.buildTableKey(catName, foreignDbName, foreignTblName));\n+      if (tblWrapper != null) {\n+        keys = tblWrapper.getForeignKeys();\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+\n+    // filter out required foreign keys based on parent db/tbl name\n+    if (!StringUtils.isEmpty(parentTblName) && !StringUtils.isEmpty(parentDbName)) {", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwMTg5OA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449401898", "bodyText": "Even if tblWrapper is null, keys will be empty list and hence an empty list will be returned. So this should be fine, right?\nIn case we move it to above if block, and assuming the list is not-empty, we will keep the read lock on for a longer duration (though only in milliseconds or even less), that's why I added it below.", "author": "adesh-rao", "createdAt": "2020-07-03T06:37:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwNzMxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwODM1NA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r449008354", "bodyText": "Method name cacheNotNulConstraints missing one \"l\". :)", "author": "sankarh", "createdAt": "2020-07-02T13:38:54Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1788,6 +2082,58 @@ public void addPartitionToCache(String catName, String dbName, String tblName, P\n     }\n   }\n \n+  public void addPrimaryKeysToCache(String catName, String dbName, String tblName, List<SQLPrimaryKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cachePrimaryKeys(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addForeignKeysToCache(String catName, String dbName, String tblName, List<SQLForeignKey> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheForeignKeys(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addUniqueConstraintsToCache(String catName, String dbName, String tblName, List<SQLUniqueConstraint> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheUniqueConstraints(keys, false);\n+      }\n+    } finally {\n+      cacheLock.readLock().unlock();\n+    }\n+  }\n+\n+  public void addNotNullConstraintsToCache(String catName, String dbName, String tblName, List<SQLNotNullConstraint> keys) {\n+    try {\n+      cacheLock.readLock().lock();\n+      String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n+      TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n+      if (tblWrapper != null) {\n+        tblWrapper.cacheNotNulConstraints(keys, false);", "originalCommit": "00fcfd022c0f3d1448688d8c2b799a9d60f8881f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "url": "https://github.com/apache/hive/commit/6f5125dc6304cfa3d52aa39902df48b5605241f2", "message": "Review comments p3", "committedDate": "2020-07-03T11:05:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2NjY1NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452766655", "bodyText": "Can we have a flag in TableWrapper in Cache to tell if it was set or not? Can be a follow-up jira.", "author": "sankarh", "createdAt": "2020-07-10T10:40:21Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2490,26 +2616,99 @@ long getPartsFound() {\n \n   @Override public List<SQLPrimaryKey> getPrimaryKeys(String catName, String dbName, String tblName)\n       throws MetaException {\n-    // TODO constraintCache\n-    return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    catName = normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the primary keys is not yet loaded in cache\n+      return rawStore.getPrimaryKeys(catName, dbName, tblName);\n+    }\n+    List<SQLPrimaryKey> keys = sharedCache.listCachedPrimaryKeys(catName, dbName, tblName);\n+    if (keys == null || keys.isEmpty()) {", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3Nzc5Mw==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452777793", "bodyText": "Created a follow up jira. https://issues.apache.org/jira/browse/HIVE-23834", "author": "adesh-rao", "createdAt": "2020-07-10T11:06:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2NjY1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2ODM5OA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452768398", "bodyText": "Can't we just use mn instead of mn.getValue()?", "author": "sankarh", "createdAt": "2020-07-10T10:44:26Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -261,44 +283,57 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private Map<String, String> parameters;\n     private byte[] sdHash;\n     private int otherSize;\n-    private int tableColStatsCacheSize;\n-    private int partitionCacheSize;\n-    private int partitionColStatsCacheSize;\n-    private int aggrColStatsCacheSize;\n+\n+    // Arrays to hold the size/updated bit of cached objects.\n+    // These arrays are to be referenced using MemberName enum only.\n+    private int[] memberObjectsSize = new int[MemberName.values().length];\n+    private AtomicBoolean[] memberCacheUpdated = new AtomicBoolean[MemberName.values().length];\n \n     private ReentrantReadWriteLock tableLock = new ReentrantReadWriteLock(true);\n     // For caching column stats for an unpartitioned table\n     // Key is column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> tableColStatsCache = new ConcurrentHashMap<String, ColumnStatisticsObj>();\n-    private AtomicBoolean isTableColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching partition objects\n     // Ket is partition values and the value is a wrapper around the partition object\n     private Map<String, PartitionWrapper> partitionCache = new ConcurrentHashMap<String, PartitionWrapper>();\n-    private AtomicBoolean isPartitionCacheDirty = new AtomicBoolean(false);\n     // For caching column stats for a partitioned table\n     // Key is aggregate of partition values, column name and the value is the col stat object\n     private Map<String, ColumnStatisticsObj> partitionColStatsCache =\n         new ConcurrentHashMap<String, ColumnStatisticsObj>();\n-    private AtomicBoolean isPartitionColStatsCacheDirty = new AtomicBoolean(false);\n     // For caching aggregate column stats for all and all minus default partition\n     // Key is column name and the value is a list of 2 col stat objects\n     // (all partitions and all but default)\n     private Map<String, List<ColumnStatisticsObj>> aggrColStatsCache =\n         new ConcurrentHashMap<String, List<ColumnStatisticsObj>>();\n-    private AtomicBoolean isAggrPartitionColStatsCacheDirty = new AtomicBoolean(false);\n+\n+    private Map<String, SQLPrimaryKey> primaryKeyCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLForeignKey> foreignKeyCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLNotNullConstraint> notNullConstraintCache = new ConcurrentHashMap<>();\n+\n+    private Map<String, SQLUniqueConstraint> uniqueConstraintCache = new ConcurrentHashMap<>();\n \n     TableWrapper(Table t, byte[] sdHash, String location, Map<String, String> parameters) {\n       this.t = t;\n       this.sdHash = sdHash;\n       this.location = location;\n       this.parameters = parameters;\n-      this.tableColStatsCacheSize = 0;\n-      this.partitionCacheSize = 0;\n-      this.partitionColStatsCacheSize = 0;\n-      this.aggrColStatsCacheSize = 0;\n+      for(MemberName mn : MemberName.values()) {\n+        this.memberObjectsSize[mn.getValue()] = 0;", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc5OTg3OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452799879", "bodyText": "Java treats enum as objects. Array indexes can be integers only. Therefore, I have to use mn.getValue() only.\nPS: Enum also provides ordinal method that returns the position of enum member, but that can cause issues if order is changed. So, I decided to go ahead with creating own getValue() method.", "author": "adesh-rao", "createdAt": "2020-07-10T12:01:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2ODM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgxNjE0Mg==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452816142", "bodyText": "In second thought, I think ordinal is better as we freshly load cache entries during HMS startup. So, the ordering doesn't matter. However, setting values can be a problem if someone pass incorrect value or remove an element without updating other values.", "author": "sankarh", "createdAt": "2020-07-10T12:37:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc2ODM5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MDA2NQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452770065", "bodyText": "Why do we use int array if we just want to store one value? and why is it final?", "author": "sankarh", "createdAt": "2020-07-10T10:48:24Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -470,6 +484,107 @@ boolean cachePartitions(Iterable<Partition> parts, SharedCache sharedCache, bool\n       }\n     }\n \n+    boolean cachePrimaryKeys(List<SQLPrimaryKey> primaryKeys, boolean fromPrewarm) {\n+      return cacheConstraints(primaryKeys, fromPrewarm, MemberName.PRIMARY_KEY_CACHE);\n+    }\n+\n+    boolean cacheForeignKeys(List<SQLForeignKey> foreignKeys, boolean fromPrewarm) {\n+      return cacheConstraints(foreignKeys, fromPrewarm, MemberName.FOREIGN_KEY_CACHE);\n+    }\n+\n+    boolean cacheUniqueConstraints(List<SQLUniqueConstraint> uniqueConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(uniqueConstraints, fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE);\n+    }\n+\n+    boolean cacheNotNullConstraints(List<SQLNotNullConstraint> notNullConstraints, boolean fromPrewarm) {\n+      return cacheConstraints(notNullConstraints, fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE);\n+    }\n+\n+    // Common method to cache constraints\n+    private boolean cacheConstraints(List constraintsList,\n+                             boolean fromPrewarm,\n+                             MemberName mn) {\n+      if (constraintsList == null || constraintsList.isEmpty()) {\n+        return true;\n+      }\n+      try {\n+        tableLock.writeLock().lock();\n+        final int[] size = {0};", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3OTQ4Ng==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452779486", "bodyText": "This is being used inside lambda function. It requires the variable to be used as final. Because of this, I can't use int or Integer. So I chose int array instead.", "author": "adesh-rao", "createdAt": "2020-07-10T11:11:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MDA2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MTM5OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452771399", "bodyText": "Shall add catalog, db and table names in the log msg otherwise this is no use. Same for other methods too.", "author": "sankarh", "createdAt": "2020-07-10T10:51:19Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +629,131 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        name = name.toLowerCase();\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        setMemberCacheUpdated(mn, true);\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n+                    + \"; the primary keys we have is dirty.\");\n+            return;\n+          }\n+          newKeys.put(key.getPk_name().toLowerCase(), key);\n+          size += getObjectSize(SQLPrimaryKey.class, key);\n+        }\n+        primaryKeyCache = newKeys;\n+        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);\n+        LOG.debug(\"Primary keys refresh in cache was successful.\");", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3MjMwMA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452772300", "bodyText": "The debug log msg is confusing. It says, primary keys is dirty and so skipping the update. I think, it should be \"Skipping the primary keys update for table:  as it was already refreshed.\"\nSame for other methods too.", "author": "sankarh", "createdAt": "2020-07-10T10:53:25Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -514,6 +629,131 @@ public boolean containsPartition(List<String> partVals) {\n       return containsPart;\n     }\n \n+    public void removeConstraint(String name) {\n+      try {\n+        tableLock.writeLock().lock();\n+        Object constraint = null;\n+        MemberName mn = null;\n+        Class constraintClass = null;\n+        name = name.toLowerCase();\n+        if (this.primaryKeyCache.containsKey(name)) {\n+          constraint = this.primaryKeyCache.remove(name);\n+          mn = MemberName.PRIMARY_KEY_CACHE;\n+          constraintClass = SQLPrimaryKey.class;\n+        } else if (this.foreignKeyCache.containsKey(name)) {\n+          constraint = this.foreignKeyCache.remove(name);\n+          mn = MemberName.FOREIGN_KEY_CACHE;\n+          constraintClass = SQLForeignKey.class;\n+        } else if (this.notNullConstraintCache.containsKey(name)) {\n+          constraint = this.notNullConstraintCache.remove(name);\n+          mn = MemberName.NOTNULL_CONSTRAINT_CACHE;\n+          constraintClass = SQLNotNullConstraint.class;\n+        } else if (this.uniqueConstraintCache.containsKey(name)) {\n+          constraint = this.uniqueConstraintCache.remove(name);\n+          mn = MemberName.UNIQUE_CONSTRAINT_CACHE;\n+          constraintClass = SQLUniqueConstraint.class;\n+        }\n+\n+        if(constraint == null) {\n+          LOG.debug(\"Constraint: \" + name + \" does not exist in cache.\");\n+          return;\n+        }\n+        setMemberCacheUpdated(mn, true);\n+        int size = getObjectSize(constraintClass, constraint);\n+        updateMemberSize(mn, -1 * size, SizeMode.Delta);\n+      } finally {\n+        tableLock.writeLock().unlock();\n+      }\n+    }\n+\n+    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n+      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+      try {\n+        tableLock.writeLock().lock();\n+        int size = 0;\n+        for (SQLPrimaryKey key : keys) {\n+          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n+            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjc3NTc2MA==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452775760", "bodyText": "Can we add foreign keys for multiple parent db/tbl and get it from cache to verify if return correct fk?", "author": "sankarh", "createdAt": "2020-07-10T11:01:57Z", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1556,6 +1543,289 @@ public Object call() {\n     cachedStore.shutdown();\n   }\n \n+  @Test\n+  public void testPrimaryKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLPrimaryKey> origKeys = createPrimaryKeys(tbl);\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLPrimaryKey> cachedKeys = sharedCache.listCachedPrimaryKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLPrimaryKey modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setPk_name(\"pk_modified\");\n+\n+    sharedCache.addPrimaryKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+      Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk1\");\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    sharedCache.refreshPrimaryKeysInCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+      Arrays.asList(modifiedKey));\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getPk_name(), \"pk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    // remove constraints\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"pk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedPrimaryKeys(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testNotNullConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLNotNullConstraint> origKeys = createNotNullConstraint(tbl);\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLNotNullConstraint> cachedKeys = sharedCache.listCachedNotNullConstraints(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLNotNullConstraint modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setNn_name(\"nn_modified\");\n+\n+    sharedCache.addNotNullConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn1\");\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getNn_name(), \"nn_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"nn_modified\");\n+\n+    cachedKeys = sharedCache.listCachedNotNullConstraints(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testUniqueConstraint() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLUniqueConstraint> origKeys = createUniqueConstraint(tbl);\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLUniqueConstraint> cachedKeys = sharedCache.listCachedUniqueConstraint(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk1\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col1\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    SQLUniqueConstraint modifiedKey = origKeys.get(0).deepCopy();\n+    modifiedKey.setColumn_name(\"col2\");\n+    modifiedKey.setUk_name(\"uk_modified\");\n+\n+    sharedCache.addUniqueConstraintsToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(),\n+            Arrays.asList(modifiedKey));\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 2);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk1\");\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getUk_name(), \"uk_modified\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getTable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getColumn_name(), \"col2\");\n+    Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n+\n+    sharedCache.removeConstraintFromCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), \"uk_modified\");\n+\n+    cachedKeys = sharedCache.listCachedUniqueConstraint(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.size(), 0);\n+\n+    cachedStore.shutdown();\n+  }\n+\n+  @Test\n+  public void testForeignKeys() {\n+    Configuration conf = MetastoreConf.newMetastoreConf();\n+    MetastoreConf.setBoolVar(conf, MetastoreConf.ConfVars.HIVE_IN_TEST, true);\n+    MetastoreConf.setVar(conf, MetastoreConf.ConfVars.CACHED_RAW_STORE_MAX_CACHE_MEMORY, \"-1Kb\");\n+    MetaStoreTestUtils.setConfForStandloneMode(conf);\n+    CachedStore cachedStore = new CachedStore();\n+    CachedStore.clearSharedCache();\n+    cachedStore.setConfForTest(conf);\n+    SharedCache sharedCache = CachedStore.getSharedCache();\n+\n+    Database db = createDatabaseObject(\"db\", \"testUser\");\n+    Table tbl = createUnpartitionedTableObject(db);\n+\n+    sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+\n+    Assert.assertEquals(sharedCache.getCachedTableCount(), 1);\n+\n+    List<SQLForeignKey> origKeys = createForeignKeys(tbl, tbl);\n+    sharedCache.addForeignKeysToCache(DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), origKeys);\n+\n+    // List operation\n+    List<SQLForeignKey> cachedKeys = sharedCache.listCachedForeignKeys(", "originalCommit": "6f5125dc6304cfa3d52aa39902df48b5605241f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgwNjM3OQ==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452806379", "bodyText": "Also validate if parent tbl name is proper too.", "author": "sankarh", "createdAt": "2020-07-10T12:16:33Z", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1754,6 +1760,16 @@ public void testForeignKeys() {\n     Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col2\");\n     Assert.assertEquals(cachedKeys.get(0).getCatName(), DEFAULT_CATALOG_NAME);\n \n+    cachedKeys = sharedCache.listCachedForeignKeys(\n+            DEFAULT_CATALOG_NAME, tbl.getDbName(), tbl.getTableName(), tbl1.getDbName(), tbl1.getTableName());\n+\n+    Assert.assertEquals(cachedKeys.size(), 1);\n+    Assert.assertEquals(cachedKeys.get(0).getFk_name(), \"fk2\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_db(), \"db\");\n+    Assert.assertEquals(cachedKeys.get(0).getFktable_name(), tbl.getTableName());\n+    Assert.assertEquals(cachedKeys.get(0).getFkcolumn_name(), \"col1\");", "originalCommit": "fec5a1770f598b7f1d9c1d3c1dcd674e9a69d93c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgxNjI1Ng==", "url": "https://github.com/apache/hive/pull/1109#discussion_r452816256", "bodyText": "done.", "author": "adesh-rao", "createdAt": "2020-07-10T12:37:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjgwNjM3OQ=="}], "type": "inlineReview"}, {"oid": "73ad4f6db3ff0a4640347e88380a3055b9041880", "url": "https://github.com/apache/hive/commit/73ad4f6db3ff0a4640347e88380a3055b9041880", "message": "First cut for adding constraints", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "830cfe7fa3c5e4900e201aaf5f73413c2dbc2157", "url": "https://github.com/apache/hive/commit/830cfe7fa3c5e4900e201aaf5f73413c2dbc2157", "message": "Add updation of cache", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "005ea861cb6294d7dc41d5e92212d4596d5c502d", "url": "https://github.com/apache/hive/commit/005ea861cb6294d7dc41d5e92212d4596d5c502d", "message": "Remove check/default constraints", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "eccc6b05557e691449ecdb733db53a7d17e0dae9", "url": "https://github.com/apache/hive/commit/eccc6b05557e691449ecdb733db53a7d17e0dae9", "message": "Add foreign keys caching", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "f8a0b062f67192d9725938afbc74dbc76ab0cb84", "url": "https://github.com/apache/hive/commit/f8a0b062f67192d9725938afbc74dbc76ab0cb84", "message": "Add UT for constraints", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "29fb02300a3074fe2c42657573b9d5934c97167a", "url": "https://github.com/apache/hive/commit/29fb02300a3074fe2c42657573b9d5934c97167a", "message": "Add test for foreign key constraints", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "f5e877da60fdb8d085476ea13678c88e826f0359", "url": "https://github.com/apache/hive/commit/f5e877da60fdb8d085476ea13678c88e826f0359", "message": "renaming variables/reorganizing imports", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "ca64f7088f7a73570ff8dd870650dc6ea88c5cfc", "url": "https://github.com/apache/hive/commit/ca64f7088f7a73570ff8dd870650dc6ea88c5cfc", "message": "dummy commit to re-run the tests", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "c8828383f824cf3f52572175e4173e72f0fab15b", "url": "https://github.com/apache/hive/commit/c8828383f824cf3f52572175e4173e72f0fab15b", "message": "Fix review comment part 1", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "68a02acfbc700d2b8ca698a66061c44c6d1ec36b", "url": "https://github.com/apache/hive/commit/68a02acfbc700d2b8ca698a66061c44c6d1ec36b", "message": "address review comments part 2", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "936d24814cf6ad14e123fa40897b2a6a6deb0fa5", "url": "https://github.com/apache/hive/commit/936d24814cf6ad14e123fa40897b2a6a6deb0fa5", "message": "Fix tests failure", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "d0706fccc68e2660be42d8469d5d9a2d005ecc17", "url": "https://github.com/apache/hive/commit/d0706fccc68e2660be42d8469d5d9a2d005ecc17", "message": "Fix compilation issue", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "54b837f6c487d91071bb7dd14c0419507a61ecbd", "url": "https://github.com/apache/hive/commit/54b837f6c487d91071bb7dd14c0419507a61ecbd", "message": "Review comments p3", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "f5dacc72f1dab8cf77d296998cc05cf271179c03", "url": "https://github.com/apache/hive/commit/f5dacc72f1dab8cf77d296998cc05cf271179c03", "message": "review comments", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "3e980fd88bce3d98bef1216b08ab1e4b907c495b", "url": "https://github.com/apache/hive/commit/3e980fd88bce3d98bef1216b08ab1e4b907c495b", "message": "Validate parent db/table too for fk", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "7a9d425b708317de126943613d72228f94b502d1", "url": "https://github.com/apache/hive/commit/7a9d425b708317de126943613d72228f94b502d1", "message": "Fix enum accessor", "committedDate": "2020-07-12T03:56:25Z", "type": "commit"}, {"oid": "7a9d425b708317de126943613d72228f94b502d1", "url": "https://github.com/apache/hive/commit/7a9d425b708317de126943613d72228f94b502d1", "message": "Fix enum accessor", "committedDate": "2020-07-12T03:56:25Z", "type": "forcePushed"}]}