{"pr_number": 1374, "pr_title": "HIVE-24012: Support for rewriting with materialized views containing \u2026", "pr_createdAt": "2020-08-07T02:53:37Z", "pr_url": "https://github.com/apache/hive/pull/1374", "timeline": [{"oid": "05dd2cf9fe013cf66a0cbb719e90b5467ba6c5ac", "url": "https://github.com/apache/hive/commit/05dd2cf9fe013cf66a0cbb719e90b5467ba6c5ac", "message": "HIVE-24012: Support for rewriting with materialized views containing grouping sets", "committedDate": "2020-08-07T19:11:06Z", "type": "commit"}, {"oid": "05dd2cf9fe013cf66a0cbb719e90b5467ba6c5ac", "url": "https://github.com/apache/hive/commit/05dd2cf9fe013cf66a0cbb719e90b5467ba6c5ac", "message": "HIVE-24012: Support for rewriting with materialized views containing grouping sets", "committedDate": "2020-08-07T19:11:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2MzUwMA==", "url": "https://github.com/apache/hive/pull/1374#discussion_r467263500", "bodyText": "Precondition?", "author": "vineetgarg02", "createdAt": "2020-08-07T20:52:39Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/views/HiveMaterializedViewUtils.java", "diffHunk": "@@ -0,0 +1,368 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hive.ql.optimizer.calcite.rules.views;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.calcite.adapter.druid.DruidQuery;\n+import org.apache.calcite.interpreter.BindableConvention;\n+import org.apache.calcite.plan.RelOptCluster;\n+import org.apache.calcite.plan.RelOptMaterialization;\n+import org.apache.calcite.plan.RelOptUtil;\n+import org.apache.calcite.plan.hep.HepPlanner;\n+import org.apache.calcite.plan.hep.HepProgramBuilder;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.RelVisitor;\n+import org.apache.calcite.rel.core.Aggregate;\n+import org.apache.calcite.rel.core.Aggregate.Group;\n+import org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.calcite.rel.core.Filter;\n+import org.apache.calcite.rel.core.Project;\n+import org.apache.calcite.rel.core.TableScan;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.fun.SqlStdOperatorTable;\n+import org.apache.calcite.tools.RelBuilder;\n+import org.apache.calcite.util.ImmutableBitSet;\n+import org.apache.hadoop.hive.common.ValidTxnWriteIdList;\n+import org.apache.hadoop.hive.common.ValidWriteIdList;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.metastore.api.CreationMetadata;\n+import org.apache.hadoop.hive.ql.lockmgr.LockException;\n+import org.apache.hadoop.hive.ql.metadata.Table;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.HiveRelFactories;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveFilter;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveGroupingID;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveProject;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveRelNode;\n+import org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveTableScan;\n+import org.apache.hadoop.hive.ql.parse.DruidSqlOperatorConverter;\n+import org.apache.hadoop.hive.ql.session.SessionState;\n+import org.apache.hive.common.util.TxnIdUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.hadoop.hive.conf.Constants.MATERIALIZED_VIEW_REWRITING_TIME_WINDOW;\n+\n+public class HiveMaterializedViewUtils {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HiveMaterializedViewUtils.class);\n+\n+\n+  private HiveMaterializedViewUtils() {}\n+\n+  public static Table extractTable(RelOptMaterialization materialization) {\n+    RelOptHiveTable cachedMaterializedViewTable;\n+    if (materialization.tableRel instanceof Project) {\n+      // There is a Project on top (due to nullability)\n+      cachedMaterializedViewTable = (RelOptHiveTable) materialization.tableRel.getInput(0).getTable();\n+    } else {\n+      cachedMaterializedViewTable = (RelOptHiveTable) materialization.tableRel.getTable();\n+    }\n+    return cachedMaterializedViewTable.getHiveTableMD();\n+  }\n+\n+  /**\n+   * Utility method that returns whether a materialized view is outdated (true), not outdated\n+   * (false), or it cannot be determined (null). The latest case may happen e.g. when the\n+   * materialized view definition uses external tables.\n+   */\n+  public static Boolean isOutdatedMaterializedView(Table materializedViewTable, final ValidTxnWriteIdList currentTxnWriteIds,\n+      long defaultTimeWindow, List<String> tablesUsed, boolean forceMVContentsUpToDate) {\n+    // Check if materialization defined its own invalidation time window\n+    String timeWindowString = materializedViewTable.getProperty(MATERIALIZED_VIEW_REWRITING_TIME_WINDOW);\n+    long timeWindow = org.apache.commons.lang3.StringUtils.isEmpty(timeWindowString) ? defaultTimeWindow :\n+        HiveConf.toTime(timeWindowString,\n+            HiveConf.getDefaultTimeUnit(HiveConf.ConfVars.HIVE_MATERIALIZED_VIEW_REWRITING_TIME_WINDOW),\n+            TimeUnit.MILLISECONDS);\n+    CreationMetadata creationMetadata = materializedViewTable.getCreationMetadata();\n+    boolean outdated = false;\n+    if (timeWindow < 0L) {\n+      // We only consider the materialized view to be outdated if forceOutdated = true, i.e.,\n+      // if it is a rebuild. Otherwise, it passed the test and we use it as it is.\n+      outdated = forceMVContentsUpToDate;\n+    } else {\n+      // Check whether the materialized view is invalidated\n+      if (forceMVContentsUpToDate || timeWindow == 0L || creationMetadata.getMaterializationTime() < System.currentTimeMillis() - timeWindow) {\n+        if (currentTxnWriteIds == null) {\n+          LOG.debug(\"Materialized view \" + materializedViewTable.getFullyQualifiedName() +\n+              \" ignored for rewriting as we could not obtain current txn ids\");\n+          return null;\n+        }\n+        if (creationMetadata.getValidTxnList() == null ||\n+            creationMetadata.getValidTxnList().isEmpty()) {\n+          LOG.debug(\"Materialized view \" + materializedViewTable.getFullyQualifiedName() +\n+              \" ignored for rewriting as we could not obtain materialization txn ids\");\n+          return null;\n+        }\n+        boolean ignore = false;\n+        ValidTxnWriteIdList mvTxnWriteIds = new ValidTxnWriteIdList(\n+            creationMetadata.getValidTxnList());\n+        for (String qName : tablesUsed) {\n+          // Note. If the materialized view does not contain a table that is contained in the query,\n+          // we do not need to check whether that specific table is outdated or not. If a rewriting\n+          // is produced in those cases, it is because that additional table is joined with the\n+          // existing tables with an append-columns only join, i.e., PK-FK + not null.\n+          if (!creationMetadata.getTablesUsed().contains(qName)) {\n+            continue;\n+          }\n+          ValidWriteIdList tableCurrentWriteIds = currentTxnWriteIds.getTableValidWriteIdList(qName);\n+          if (tableCurrentWriteIds == null) {\n+            // Uses non-transactional table, cannot be considered\n+            LOG.debug(\"Materialized view \" + materializedViewTable.getFullyQualifiedName() +\n+                \" ignored for rewriting as it is outdated and cannot be considered for \" +\n+                \" rewriting because it uses non-transactional table \" + qName);\n+            ignore = true;\n+            break;\n+          }\n+          ValidWriteIdList tableWriteIds = mvTxnWriteIds.getTableValidWriteIdList(qName);\n+          if (tableWriteIds == null) {\n+            // This should not happen, but we ignore for safety\n+            LOG.warn(\"Materialized view \" + materializedViewTable.getFullyQualifiedName() +\n+                \" ignored for rewriting as details about txn ids for table \" + qName +\n+                \" could not be found in \" + mvTxnWriteIds);\n+            ignore = true;\n+            break;\n+          }\n+          if (!outdated && !TxnIdUtils.checkEquivalentWriteIds(tableCurrentWriteIds, tableWriteIds)) {\n+            LOG.debug(\"Materialized view \" + materializedViewTable.getFullyQualifiedName() +\n+                \" contents are outdated\");\n+            outdated = true;\n+          }\n+        }\n+        if (ignore) {\n+          return null;\n+        }\n+      }\n+    }\n+    return outdated;\n+  }\n+\n+  /**\n+   * Method to enrich the materialization query contained in the input with\n+   * its invalidation.\n+   */\n+  public static RelOptMaterialization augmentMaterializationWithTimeInformation(\n+      RelOptMaterialization materialization, String validTxnsList,\n+      ValidTxnWriteIdList materializationTxnList) throws LockException {\n+    // Extract tables used by the query which will in turn be used to generate\n+    // the corresponding txn write ids\n+    List<String> tablesUsed = new ArrayList<>();\n+    new RelVisitor() {\n+      @Override\n+      public void visit(RelNode node, int ordinal, RelNode parent) {\n+        if (node instanceof TableScan) {\n+          TableScan ts = (TableScan) node;\n+          tablesUsed.add(((RelOptHiveTable) ts.getTable()).getHiveTableMD().getFullyQualifiedName());\n+        }\n+        super.visit(node, ordinal, parent);\n+      }\n+    }.go(materialization.queryRel);\n+    ValidTxnWriteIdList currentTxnList =\n+        SessionState.get().getTxnMgr().getValidWriteIds(tablesUsed, validTxnsList);\n+    // Augment\n+    final RexBuilder rexBuilder = materialization.queryRel.getCluster().getRexBuilder();\n+    final HepProgramBuilder augmentMaterializationProgram = new HepProgramBuilder()\n+        .addRuleInstance(new HiveAugmentMaterializationRule(rexBuilder, currentTxnList, materializationTxnList));\n+    final HepPlanner augmentMaterializationPlanner = new HepPlanner(\n+        augmentMaterializationProgram.build());\n+    augmentMaterializationPlanner.setRoot(materialization.queryRel);\n+    final RelNode modifiedQueryRel = augmentMaterializationPlanner.findBestExp();\n+    return new RelOptMaterialization(materialization.tableRel, modifiedQueryRel,\n+        null, materialization.qualifiedTableName);\n+  }\n+\n+  /**\n+   * If a materialization does not contain grouping sets, it returns the materialization\n+   * itself. Otherwise, it will create one materialization for each grouping set.\n+   * For each grouping set, the query for the materialization will consist of the group by\n+   * columns in the grouping set, followed by a projection to recreate the literal null\n+   * values. The view scan will consist of the scan over the materialization followed by a\n+   * filter on the grouping id value corresponding to that grouping set.\n+   */\n+  public static List<RelOptMaterialization> deriveGroupingSetsMaterializedViews(RelOptMaterialization materialization) {\n+    final RelNode query = materialization.queryRel;\n+    final Project project;\n+    final Aggregate aggregate;\n+    if (query instanceof Aggregate) {\n+      project = null;\n+      aggregate = (Aggregate) query;\n+    } else if (query instanceof Project && query.getInput(0) instanceof Aggregate) {\n+      project = (Project) query;\n+      aggregate = (Aggregate) query.getInput(0);\n+    } else {\n+      project = null;\n+      aggregate = null;\n+    }\n+    if (aggregate == null) {\n+      // Not an aggregate materialized view, return original materialization\n+      return Collections.singletonList(materialization);\n+    }\n+    if (aggregate.getGroupType() == Group.SIMPLE) {\n+      // Not a grouping sets materialized view, return original materialization\n+      return Collections.singletonList(materialization);\n+    }\n+    int groupingIdIndex = -1;\n+    for (int i = 0; i < aggregate.getAggCallList().size(); i++) {\n+      if (aggregate.getAggCallList().get(i).getAggregation() == HiveGroupingID.INSTANCE) {\n+        groupingIdIndex = aggregate.getGroupCount() + i;\n+        break;\n+      }\n+    }\n+    assert groupingIdIndex != -1;", "originalCommit": "05dd2cf9fe013cf66a0cbb719e90b5467ba6c5ac", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "00ddcdce65ccceaff25bed962a64c34a942658d4", "url": "https://github.com/apache/hive/commit/00ddcdce65ccceaff25bed962a64c34a942658d4", "message": "fix for project index and addressing comments", "committedDate": "2020-08-07T21:28:39Z", "type": "commit"}, {"oid": "50ecd33da25fa45a312c08c950ad0cada4680257", "url": "https://github.com/apache/hive/commit/50ecd33da25fa45a312c08c950ad0cada4680257", "message": "proper fix", "committedDate": "2020-08-07T22:59:32Z", "type": "commit"}, {"oid": "50ecd33da25fa45a312c08c950ad0cada4680257", "url": "https://github.com/apache/hive/commit/50ecd33da25fa45a312c08c950ad0cada4680257", "message": "proper fix", "committedDate": "2020-08-07T22:59:32Z", "type": "forcePushed"}]}