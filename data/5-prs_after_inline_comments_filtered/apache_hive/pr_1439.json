{"pr_number": 1439, "pr_title": "HIVE-24084 Push Aggregates thru joins in case it re-groups previously unique columns\t", "pr_createdAt": "2020-08-27T15:58:20Z", "pr_url": "https://github.com/apache/hive/pull/1439", "timeline": [{"oid": "469c8fec41e15916758fa02330a45adf8980f51f", "url": "https://github.com/apache/hive/commit/469c8fec41e15916758fa02330a45adf8980f51f", "message": "a", "committedDate": "2020-08-03T15:55:33Z", "type": "commit"}, {"oid": "43701563c5f69780899a00ab125872094cf63d4b", "url": "https://github.com/apache/hive/commit/43701563c5f69780899a00ab125872094cf63d4b", "message": "disable unstable tests", "committedDate": "2020-08-04T09:56:40Z", "type": "commit"}, {"oid": "4560fc77d479a3d14492fc1957804dd5eaa62940", "url": "https://github.com/apache/hive/commit/4560fc77d479a3d14492fc1957804dd5eaa62940", "message": "some changes", "committedDate": "2020-08-11T08:26:50Z", "type": "commit"}, {"oid": "5eab19dbf84d05d030ecda567596008e1d7a07f6", "url": "https://github.com/apache/hive/commit/5eab19dbf84d05d030ecda567596008e1d7a07f6", "message": "git staMerge remote-tracking branch 'apache/master' into DWX-4878-aggpush", "committedDate": "2020-08-11T08:27:21Z", "type": "commit"}, {"oid": "92e2ef6d034cfeb6795daf386e8fd4e78f8f04ed", "url": "https://github.com/apache/hive/commit/92e2ef6d034cfeb6795daf386e8fd4e78f8f04ed", "message": "use tpch .001", "committedDate": "2020-08-11T08:29:50Z", "type": "commit"}, {"oid": "159bbc5e4a4acdae18c4e19b437768934c75e3a8", "url": "https://github.com/apache/hive/commit/159bbc5e4a4acdae18c4e19b437768934c75e3a8", "message": "update q.out", "committedDate": "2020-08-11T09:05:04Z", "type": "commit"}, {"oid": "b9fbd6a9dd869016240ee397748af94d9e0628ad", "url": "https://github.com/apache/hive/commit/b9fbd6a9dd869016240ee397748af94d9e0628ad", "message": "fix", "committedDate": "2020-08-25T08:33:44Z", "type": "commit"}, {"oid": "6b761df6b287f7fe0e32f3965d2b7236b1b168bc", "url": "https://github.com/apache/hive/commit/6b761df6b287f7fe0e32f3965d2b7236b1b168bc", "message": "add a", "committedDate": "2020-08-25T09:29:42Z", "type": "commit"}, {"oid": "2775462c430b24f6087af675b42f58964d4d9889", "url": "https://github.com/apache/hive/commit/2775462c430b24f6087af675b42f58964d4d9889", "message": "update", "committedDate": "2020-08-25T13:53:01Z", "type": "commit"}, {"oid": "e60a56c9a79e4bde40f58e84e44bda8fa4d098a3", "url": "https://github.com/apache/hive/commit/e60a56c9a79e4bde40f58e84e44bda8fa4d098a3", "message": "why intersect", "committedDate": "2020-08-25T14:28:01Z", "type": "commit"}, {"oid": "98cb30e6640c32cedca0cd39befa3017d94f09b0", "url": "https://github.com/apache/hive/commit/98cb30e6640c32cedca0cd39befa3017d94f09b0", "message": "add", "committedDate": "2020-08-25T15:41:04Z", "type": "commit"}, {"oid": "36816a9bccb358cd4483f9d8dbe56dac3463cd9d", "url": "https://github.com/apache/hive/commit/36816a9bccb358cd4483f9d8dbe56dac3463cd9d", "message": "cleanup", "committedDate": "2020-08-26T12:44:25Z", "type": "commit"}, {"oid": "a607be84e14d6ac111b5467f7140e221ed96ae09", "url": "https://github.com/apache/hive/commit/a607be84e14d6ac111b5467f7140e221ed96ae09", "message": "usee AggP", "committedDate": "2020-08-26T13:06:18Z", "type": "commit"}, {"oid": "8b4181007882f467cd1ff6b61811522e400d2cee", "url": "https://github.com/apache/hive/commit/8b4181007882f467cd1ff6b61811522e400d2cee", "message": "up[dates", "committedDate": "2020-08-26T13:24:15Z", "type": "commit"}, {"oid": "e38f82bd35f2567cd810b6e2f56b8497953000c3", "url": "https://github.com/apache/hive/commit/e38f82bd35f2567cd810b6e2f56b8497953000c3", "message": "changes", "committedDate": "2020-08-26T14:14:07Z", "type": "commit"}, {"oid": "ee9e0ded691bf131b7e79a2a8f46c928e85ad299", "url": "https://github.com/apache/hive/commit/ee9e0ded691bf131b7e79a2a8f46c928e85ad299", "message": "unde LE", "committedDate": "2020-08-26T14:15:24Z", "type": "commit"}, {"oid": "924008b021a0c3bf3e593ddfa8c1056cfb83cf61", "url": "https://github.com/apache/hive/commit/924008b021a0c3bf3e593ddfa8c1056cfb83cf61", "message": "aa", "committedDate": "2020-08-27T12:14:08Z", "type": "commit"}, {"oid": "22eb5bec3803c30a0b50b516c21e756e41d267db", "url": "https://github.com/apache/hive/commit/22eb5bec3803c30a0b50b516c21e756e41d267db", "message": "changes", "committedDate": "2020-08-27T14:04:00Z", "type": "commit"}, {"oid": "2291f4c05307fc53459c603a20ea9f5ae946c9b6", "url": "https://github.com/apache/hive/commit/2291f4c05307fc53459c603a20ea9f5ae946c9b6", "message": "cleanup", "committedDate": "2020-08-27T14:05:25Z", "type": "commit"}, {"oid": "d8a896e448360c7ecd5009ccdad34018279f109b", "url": "https://github.com/apache/hive/commit/d8a896e448360c7ecd5009ccdad34018279f109b", "message": "add more", "committedDate": "2020-08-27T14:50:33Z", "type": "commit"}, {"oid": "52fdee701d44a2183df4cefc26592e38c2c84540", "url": "https://github.com/apache/hive/commit/52fdee701d44a2183df4cefc26592e38c2c84540", "message": "remove stuff", "committedDate": "2020-08-27T14:52:42Z", "type": "commit"}, {"oid": "a851713a8aea523062bd1207a53019cae8328d69", "url": "https://github.com/apache/hive/commit/a851713a8aea523062bd1207a53019cae8328d69", "message": "cleanup", "committedDate": "2020-08-27T14:56:36Z", "type": "commit"}, {"oid": "18b179a3598e40532b51e37235d3b9e4bd21c527", "url": "https://github.com/apache/hive/commit/18b179a3598e40532b51e37235d3b9e4bd21c527", "message": "remove comment", "committedDate": "2020-08-27T14:57:13Z", "type": "commit"}, {"oid": "62ea2b79e007434cdf836ec2c3643278bf1f6d95", "url": "https://github.com/apache/hive/commit/62ea2b79e007434cdf836ec2c3643278bf1f6d95", "message": "def", "committedDate": "2020-08-27T14:58:14Z", "type": "commit"}, {"oid": "ca3fb9d79a22c455b688cfa3a3f6fab286ba6fe3", "url": "https://github.com/apache/hive/commit/ca3fb9d79a22c455b688cfa3a3f6fab286ba6fe3", "message": "f1", "committedDate": "2020-08-27T15:03:34Z", "type": "commit"}, {"oid": "57750a44529fcf9e779241c4466c03d34202e338", "url": "https://github.com/apache/hive/commit/57750a44529fcf9e779241c4466c03d34202e338", "message": "cleanup", "committedDate": "2020-08-27T15:12:11Z", "type": "commit"}, {"oid": "b84a24fc41d81dc936927ff239ab0e17f25a6c30", "url": "https://github.com/apache/hive/commit/b84a24fc41d81dc936927ff239ab0e17f25a6c30", "message": "update q.out", "committedDate": "2020-08-27T15:18:29Z", "type": "commit"}, {"oid": "74520518ba7afd974f4aae069286661768303651", "url": "https://github.com/apache/hive/commit/74520518ba7afd974f4aae069286661768303651", "message": "remove EXPLAIN; update q.out", "committedDate": "2020-08-27T15:21:34Z", "type": "commit"}, {"oid": "0b915d5a01c5d5d73d4428074175c1ebe279139b", "url": "https://github.com/apache/hive/commit/0b915d5a01c5d5d73d4428074175c1ebe279139b", "message": "resultset diffs against old", "committedDate": "2020-08-27T15:25:13Z", "type": "commit"}, {"oid": "fa705cb8e21b2f5f75574fd1288bf9ff0dba234c", "url": "https://github.com/apache/hive/commit/fa705cb8e21b2f5f75574fd1288bf9ff0dba234c", "message": "restore patch", "committedDate": "2020-08-27T15:25:38Z", "type": "commit"}, {"oid": "71b25cb7291e788d90e6ef6a0560d5b7ca7c520f", "url": "https://github.com/apache/hive/commit/71b25cb7291e788d90e6ef6a0560d5b7ca7c520f", "message": "it works...", "committedDate": "2020-08-28T13:36:48Z", "type": "commit"}, {"oid": "ad13df1838500f08da56278ed2e82e18a2529a2f", "url": "https://github.com/apache/hive/commit/ad13df1838500f08da56278ed2e82e18a2529a2f", "message": "cleanup", "committedDate": "2020-08-28T13:46:39Z", "type": "commit"}, {"oid": "80b8e6a7f5ed50ea6152a4577450813bf4e4acf7", "url": "https://github.com/apache/hive/commit/80b8e6a7f5ed50ea6152a4577450813bf4e4acf7", "message": "go back to old", "committedDate": "2020-08-28T13:47:54Z", "type": "commit"}, {"oid": "d3bf261b880716e44e346d020162bd5fe3a8d37c", "url": "https://github.com/apache/hive/commit/d3bf261b880716e44e346d020162bd5fe3a8d37c", "message": "undo", "committedDate": "2020-08-28T13:56:05Z", "type": "commit"}, {"oid": "36525d2e7c2f359c8c0f380ec7ac838db080046b", "url": "https://github.com/apache/hive/commit/36525d2e7c2f359c8c0f380ec7ac838db080046b", "message": "cleanup", "committedDate": "2020-08-28T13:57:07Z", "type": "commit"}, {"oid": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "url": "https://github.com/apache/hive/commit/e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "message": "remove", "committedDate": "2020-08-28T14:34:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NDUyMA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479474520", "bodyText": "Not sure about this change. If the algorithm is sort-based, you will still sort the complete input, right?", "author": "jcamachor", "createdAt": "2020-08-28T18:40:12Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/cost/HiveOnTezCostModel.java", "diffHunk": "@@ -89,22 +89,23 @@ public RelOptCost getAggregateCost(HiveAggregate aggregate) {\n     } else {\n       final RelMetadataQuery mq = aggregate.getCluster().getMetadataQuery();\n       // 1. Sum of input cardinalities\n-      final Double rCount = mq.getRowCount(aggregate.getInput());\n-      if (rCount == null) {\n+      final Double inputRowCount = mq.getRowCount(aggregate.getInput());\n+      final Double rowCount = mq.getRowCount(aggregate);\n+      if (inputRowCount == null || rowCount == null) {\n         return null;\n       }\n       // 2. CPU cost = sorting cost\n-      final double cpuCost = algoUtils.computeSortCPUCost(rCount);\n+      final double cpuCost = algoUtils.computeSortCPUCost(rowCount) + inputRowCount * algoUtils.getCpuUnitCost();", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjExOTA0Mw==", "url": "https://github.com/apache/hive/pull/1439#discussion_r482119043", "bodyText": "maybe...I'm trying to catch the case when inputRowCount >> outputRowCount; we are also grouping - so it will not be a full sort at all ; I was using the above to achieve:\nlog(outputRowCount)*outputRowCount + inputRowCount*COST\n\nthe rational behind this is that it needs to really sort oRC and read iRC rows - this could be an underestimation...but log(iRC)*iRC was highly overestimating the cost\none alternative for the above could be to use:\nlog(outputRowCount) * inputRowCount\n\nthe rational behind this:\nwe will need to find the place for every input row; but we also know that the output will be at most outputRowCount - so it shouldn't take more time to find the place for the actual row than log(outputRowCount)", "author": "kgyrtkirk", "createdAt": "2020-09-02T14:35:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NDUyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMwMTQwOQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r482301409", "bodyText": "I think the problem is that we are trying to encapsulate here the algorithm selection too: The fact that we are grouping in each node before sorting the data (I think this is also somehow reflected in the isLe discussion above). However, that is not represented with precision by current model, since output rows is supposed to be the output of the final step in the aggregation.\nWrt read, there is also the IO part of the cost, I am trying to understand whether some of the cost representation that you are talking about is IO.\nThere is some more info about the original formulas that were used to compute this here: https://cwiki.apache.org/confluence/display/Hive/Cost-based+optimization+in+Hive\nCan we split this into two patches and have the changes to the cost model on their own? This should also help to discuss this in more detail.", "author": "jcamachor", "createdAt": "2020-09-02T18:49:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NDUyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDQzNDg2NQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r484434865", "bodyText": "sure; I'll open a separate ticket for the cost model changes", "author": "kgyrtkirk", "createdAt": "2020-09-07T13:33:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NDUyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NDk1OQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479474959", "bodyText": "We could rely on mq.areColumnsUnique.", "author": "jcamachor", "createdAt": "2020-08-28T18:41:14Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveAggregateJoinTransposeRule.java", "diffHunk": "@@ -303,6 +305,90 @@ public void onMatch(RelOptRuleCall call) {\n     }\n   }\n \n+  /**\n+   * Determines weather the give grouping is unique.\n+   *\n+   * Consider a join which might produce non-unique rows; but later the results are aggregated again.\n+   * This method determines if there are sufficient columns in the grouping which have been present previously as unique column(s).\n+   */\n+  private boolean isGroupingUnique(RelNode input, ImmutableBitSet groups) {\n+    if (groups.isEmpty()) {\n+      return false;\n+    }\n+    RelMetadataQuery mq = input.getCluster().getMetadataQuery();\n+    Set<ImmutableBitSet> uKeys = mq.getUniqueKeys(input);", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUxMzY1NA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479513654", "bodyText": "If the purpose of this method is to determine that given a set of columns are unique or not you can use areColumnsUnique as @jcamachor  suggested.", "author": "vineetgarg02", "createdAt": "2020-08-28T20:12:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NDk1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAwMTkxMg==", "url": "https://github.com/apache/hive/pull/1439#discussion_r485001912", "bodyText": "yes; I've explored using areColumnsUnique because it matches the usecase here - however for some tests it emitted some NPEs so I've gone back to the getUniqueKeys approach\nI'll file a jira for areColumnsUnique when I know what's wrong with it..", "author": "kgyrtkirk", "createdAt": "2020-09-08T15:17:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NDk1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NzczMQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479477731", "bodyText": "The rule is enabled via config so we will only reach here if it is enabled.\nWe should be able to force the transform even if cost-based variant is disabled.", "author": "jcamachor", "createdAt": "2020-08-28T18:47:11Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveAggregateJoinTransposeRule.java", "diffHunk": "@@ -290,7 +291,8 @@ public void onMatch(RelOptRuleCall call) {\n       RelNode r = relBuilder.build();\n       RelOptCost afterCost = mq.getCumulativeCost(r);\n       RelOptCost beforeCost = mq.getCumulativeCost(aggregate);\n-      if (afterCost.isLt(beforeCost)) {\n+      boolean shouldForceTransform = isGroupingUnique(join, aggregate.getGroupSet());", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDQzOTA3NQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r484439075", "bodyText": "I've added a config: hive.transpose.aggr.join.unique to enable/disable this feature", "author": "kgyrtkirk", "createdAt": "2020-09-07T13:42:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3NzczMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3OTExMA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479479110", "bodyText": "This could call mq.areColumnsUnique instead of making the recursive call.", "author": "jcamachor", "createdAt": "2020-08-28T18:50:30Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveAggregateJoinTransposeRule.java", "diffHunk": "@@ -303,6 +305,90 @@ public void onMatch(RelOptRuleCall call) {\n     }\n   }\n \n+  /**\n+   * Determines weather the give grouping is unique.\n+   *\n+   * Consider a join which might produce non-unique rows; but later the results are aggregated again.\n+   * This method determines if there are sufficient columns in the grouping which have been present previously as unique column(s).\n+   */\n+  private boolean isGroupingUnique(RelNode input, ImmutableBitSet groups) {\n+    if (groups.isEmpty()) {\n+      return false;\n+    }\n+    RelMetadataQuery mq = input.getCluster().getMetadataQuery();\n+    Set<ImmutableBitSet> uKeys = mq.getUniqueKeys(input);\n+    for (ImmutableBitSet u : uKeys) {\n+      if (groups.contains(u)) {\n+        return true;\n+      }\n+    }\n+    if (input instanceof Join) {\n+      Join join = (Join) input;\n+      RexBuilder rexBuilder = input.getCluster().getRexBuilder();\n+      SimpleConditionInfo cond = new SimpleConditionInfo(join.getCondition(), rexBuilder);\n+\n+      if (cond.valid) {\n+        ImmutableBitSet newGroup = groups.intersect(ImmutableBitSet.fromBitSet(cond.fields));\n+        RelNode l = join.getLeft();\n+        RelNode r = join.getRight();\n+\n+        int joinFieldCount = join.getRowType().getFieldCount();\n+        int lFieldCount = l.getRowType().getFieldCount();\n+\n+        ImmutableBitSet groupL = newGroup.get(0, lFieldCount);\n+        ImmutableBitSet groupR = newGroup.get(lFieldCount, joinFieldCount).shift(-lFieldCount);\n+\n+        if (isGroupingUnique(l, groupL)) {", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA5MDI4OQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r482090289", "bodyText": "this method does a bit different thing - honestly I feeled like I'm in trouble when I've given this name to it :)\nthis method checks if the given columns contain an unique column somewhere in the covered joins; (this still sound fuzzy) so let's take an example\nconsider:\nselect c_id, sum(i_prize) from customer c join item i on(i.c_id=c.c_id)\n\n\ndo an aggregate grouping by the column C_ID  ; and sum up something\nbelow is a join which joins by C_ID\nasking wether C_ID  is a unique column on top of the join is false; but there is subtree in which C_ID is unique => so if we push the aggregate on that branch the aggregation will be a no-op\n\nI think this case is not handled by areColumnsUnique", "author": "kgyrtkirk", "createdAt": "2020-09-02T13:58:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3OTExMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjI0MzM3Ng==", "url": "https://github.com/apache/hive/pull/1439#discussion_r482243376", "bodyText": "Could you execute areColumnsUnique on the join input then? Wouldn't that simplify this logic?", "author": "jcamachor", "createdAt": "2020-09-02T17:27:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3OTExMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDQxOTc3Ng==", "url": "https://github.com/apache/hive/pull/1439#discussion_r484419776", "bodyText": "this method recursively checks that the above condition is satisfied or not - that's why it needs to call itself", "author": "kgyrtkirk", "createdAt": "2020-09-07T13:03:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3OTExMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTMzNTA2NQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r485335065", "bodyText": "As you go down recursively, you may start finding HepRelVertex as the rel node. I think you hit the instanceof Project below only for the first project because you create it using the builder.\nThat is why I think once you have gone through the first join, you will not hit another join; you could simply call areColumnsUnique in these if clauses, which could potentially uncover new cases.\nI may be wrong though, I just wanted to leave you a final note to make sure it was clear what I meant.", "author": "jcamachor", "createdAt": "2020-09-09T04:47:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3OTExMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzExNDYyMA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r487114620", "bodyText": "That could be done; and I'm sure it was true in this - but this logic will work better if it could walk down as many joins as it could - we might have an aggregate on top in the meantime a bunch of joins under it...so I feel that it will be beneficial to retain it.\nI feeled tempted to write a RelMd handler - however I don't think I could just introduce a new one easily.\nRelShuttle doesn't look like a good match - I'll leave it as a set of instanceof calls for now.\nI'll upload a new patch to see if digging deeper in the tree could do more or not.", "author": "kgyrtkirk", "createdAt": "2020-09-11T15:16:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3OTExMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEzMDgyMA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r487130820", "bodyText": "OK. If it turns out there are many changes and it may need some time to be fixed, feel free to defer to follow-up JIRA and let's merge this one.", "author": "jcamachor", "createdAt": "2020-09-11T15:43:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3OTExMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ3OTE1Mw==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479479153", "bodyText": "Same as above.", "author": "jcamachor", "createdAt": "2020-08-28T18:50:38Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveAggregateJoinTransposeRule.java", "diffHunk": "@@ -303,6 +305,90 @@ public void onMatch(RelOptRuleCall call) {\n     }\n   }\n \n+  /**\n+   * Determines weather the give grouping is unique.\n+   *\n+   * Consider a join which might produce non-unique rows; but later the results are aggregated again.\n+   * This method determines if there are sufficient columns in the grouping which have been present previously as unique column(s).\n+   */\n+  private boolean isGroupingUnique(RelNode input, ImmutableBitSet groups) {\n+    if (groups.isEmpty()) {\n+      return false;\n+    }\n+    RelMetadataQuery mq = input.getCluster().getMetadataQuery();\n+    Set<ImmutableBitSet> uKeys = mq.getUniqueKeys(input);\n+    for (ImmutableBitSet u : uKeys) {\n+      if (groups.contains(u)) {\n+        return true;\n+      }\n+    }\n+    if (input instanceof Join) {\n+      Join join = (Join) input;\n+      RexBuilder rexBuilder = input.getCluster().getRexBuilder();\n+      SimpleConditionInfo cond = new SimpleConditionInfo(join.getCondition(), rexBuilder);\n+\n+      if (cond.valid) {\n+        ImmutableBitSet newGroup = groups.intersect(ImmutableBitSet.fromBitSet(cond.fields));\n+        RelNode l = join.getLeft();\n+        RelNode r = join.getRight();\n+\n+        int joinFieldCount = join.getRowType().getFieldCount();\n+        int lFieldCount = l.getRowType().getFieldCount();\n+\n+        ImmutableBitSet groupL = newGroup.get(0, lFieldCount);\n+        ImmutableBitSet groupR = newGroup.get(lFieldCount, joinFieldCount).shift(-lFieldCount);\n+\n+        if (isGroupingUnique(l, groupL)) {\n+          return true;\n+        }\n+        if (isGroupingUnique(r, groupR)) {", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4NDkxOA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479484918", "bodyText": "I think you suggested changing this... Maybe isLe if we do not introduce an additional aggregate on top?", "author": "jcamachor", "createdAt": "2020-08-28T19:04:16Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveAggregateJoinTransposeRule.java", "diffHunk": "@@ -290,7 +291,8 @@ public void onMatch(RelOptRuleCall call) {\n       RelNode r = relBuilder.build();\n       RelOptCost afterCost = mq.getCumulativeCost(r);\n       RelOptCost beforeCost = mq.getCumulativeCost(aggregate);\n-      if (afterCost.isLt(beforeCost)) {", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA5MjI1NQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r482092255", "bodyText": "yes; if we use isLe the current cost model which only takes rowcount into account will prefer the pushing aggregates further\nthere is another alternative to the force based approach: the rule can be configured to use the more advanced cost system - so that it could take cpu/io cost into account", "author": "kgyrtkirk", "createdAt": "2020-09-02T14:00:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4NDkxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4ODU1Ng==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479488556", "bodyText": "Additionally, when we force triggering the transform, does it make sense to verify that we are not creating an aggregate on top (i.e., we end up with agg before join and after join?\nThat may narrow it down even further to a case when the pushdown should always be beneficial.", "author": "jcamachor", "createdAt": "2020-08-28T19:12:25Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveAggregateJoinTransposeRule.java", "diffHunk": "@@ -290,7 +291,8 @@ public void onMatch(RelOptRuleCall call) {\n       RelNode r = relBuilder.build();\n       RelOptCost afterCost = mq.getCumulativeCost(r);\n       RelOptCost beforeCost = mq.getCumulativeCost(aggregate);\n-      if (afterCost.isLt(beforeCost)) {\n+      boolean shouldForceTransform = isGroupingUnique(join, aggregate.getGroupSet());\n+      if (shouldForceTransform || afterCost.isLt(beforeCost)) {", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4ODk1OQ==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479488959", "bodyText": "Can you use JoinInfo.of for this? It seems it does something very similar.", "author": "jcamachor", "createdAt": "2020-08-28T19:13:22Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveAggregateJoinTransposeRule.java", "diffHunk": "@@ -303,6 +305,90 @@ public void onMatch(RelOptRuleCall call) {\n     }\n   }\n \n+  /**\n+   * Determines weather the give grouping is unique.\n+   *\n+   * Consider a join which might produce non-unique rows; but later the results are aggregated again.\n+   * This method determines if there are sufficient columns in the grouping which have been present previously as unique column(s).\n+   */\n+  private boolean isGroupingUnique(RelNode input, ImmutableBitSet groups) {\n+    if (groups.isEmpty()) {\n+      return false;\n+    }\n+    RelMetadataQuery mq = input.getCluster().getMetadataQuery();\n+    Set<ImmutableBitSet> uKeys = mq.getUniqueKeys(input);\n+    for (ImmutableBitSet u : uKeys) {\n+      if (groups.contains(u)) {\n+        return true;\n+      }\n+    }\n+    if (input instanceof Join) {\n+      Join join = (Join) input;\n+      RexBuilder rexBuilder = input.getCluster().getRexBuilder();\n+      SimpleConditionInfo cond = new SimpleConditionInfo(join.getCondition(), rexBuilder);\n+\n+      if (cond.valid) {\n+        ImmutableBitSet newGroup = groups.intersect(ImmutableBitSet.fromBitSet(cond.fields));\n+        RelNode l = join.getLeft();\n+        RelNode r = join.getRight();\n+\n+        int joinFieldCount = join.getRowType().getFieldCount();\n+        int lFieldCount = l.getRowType().getFieldCount();\n+\n+        ImmutableBitSet groupL = newGroup.get(0, lFieldCount);\n+        ImmutableBitSet groupR = newGroup.get(lFieldCount, joinFieldCount).shift(-lFieldCount);\n+\n+        if (isGroupingUnique(l, groupL)) {\n+          return true;\n+        }\n+        if (isGroupingUnique(r, groupR)) {\n+          return true;\n+        }\n+      }\n+    }\n+    return false;\n+  }\n+\n+  static class SimpleConditionInfo {", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUwODYxOA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479508618", "bodyText": "Can we change rowCount to outputRowCount? This will make the change more readable.", "author": "vineetgarg02", "createdAt": "2020-08-28T19:59:45Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/cost/HiveOnTezCostModel.java", "diffHunk": "@@ -89,22 +89,23 @@ public RelOptCost getAggregateCost(HiveAggregate aggregate) {\n     } else {\n       final RelMetadataQuery mq = aggregate.getCluster().getMetadataQuery();\n       // 1. Sum of input cardinalities\n-      final Double rCount = mq.getRowCount(aggregate.getInput());\n-      if (rCount == null) {\n+      final Double inputRowCount = mq.getRowCount(aggregate.getInput());\n+      final Double rowCount = mq.getRowCount(aggregate);", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUwOTA2NA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r479509064", "bodyText": "rAverageSize is based on input row count but rowCount is output row count. Is this intended or should average row size be computed based on output row count?", "author": "vineetgarg02", "createdAt": "2020-08-28T20:00:50Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/cost/HiveOnTezCostModel.java", "diffHunk": "@@ -89,22 +89,23 @@ public RelOptCost getAggregateCost(HiveAggregate aggregate) {\n     } else {\n       final RelMetadataQuery mq = aggregate.getCluster().getMetadataQuery();\n       // 1. Sum of input cardinalities\n-      final Double rCount = mq.getRowCount(aggregate.getInput());\n-      if (rCount == null) {\n+      final Double inputRowCount = mq.getRowCount(aggregate.getInput());\n+      final Double rowCount = mq.getRowCount(aggregate);\n+      if (inputRowCount == null || rowCount == null) {\n         return null;\n       }\n       // 2. CPU cost = sorting cost\n-      final double cpuCost = algoUtils.computeSortCPUCost(rCount);\n+      final double cpuCost = algoUtils.computeSortCPUCost(rowCount) + inputRowCount * algoUtils.getCpuUnitCost();\n       // 3. IO cost = cost of writing intermediary results to local FS +\n       //              cost of reading from local FS for transferring to GBy +\n       //              cost of transferring map outputs to GBy operator\n       final Double rAverageSize = mq.getAverageRowSize(aggregate.getInput());\n       if (rAverageSize == null) {\n         return null;\n       }\n-      final double ioCost = algoUtils.computeSortIOCost(new Pair<Double,Double>(rCount,rAverageSize));\n+      final double ioCost = algoUtils.computeSortIOCost(new Pair<Double, Double>(rowCount, rAverageSize));", "originalCommit": "e72417eee27e091c5a3e8ce4367bd8497f1c6d08", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjEyMzU0MA==", "url": "https://github.com/apache/hive/pull/1439#discussion_r482123540", "bodyText": "if we will be doing a 2 phase groupby: every mapper will do some grouping before it starts emitting; in case iRC >> oRC the mappers could eliminate a lot of rows ; and they will most likely utilize O(oRC) io\nthis is an underestimation ; I wanted to multiply it with the number of mappers - but I don't think that's known at this point....I can add a config key for a fixed multiplier.", "author": "kgyrtkirk", "createdAt": "2020-09-02T14:41:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUwOTA2NA=="}], "type": "inlineReview"}, {"oid": "adbd393aed0183c55b608aecfebcd147aeb4d1c1", "url": "https://github.com/apache/hive/commit/adbd393aed0183c55b608aecfebcd147aeb4d1c1", "message": "Merge remote-tracking branch 'apache/master' into HIVE-24084-cost-aggr", "committedDate": "2020-09-02T13:43:36Z", "type": "commit"}, {"oid": "683b63cf161128dbea670b606db849833388306c", "url": "https://github.com/apache/hive/commit/683b63cf161128dbea670b606db849833388306c", "message": "git stMerge remote-tracking branch 'apache/master' into HIVE-24072-aggjoin-mapping", "committedDate": "2020-09-02T14:03:35Z", "type": "commit"}, {"oid": "60359407d9a20a364bff92c6d0417f5f3995032c", "url": "https://github.com/apache/hive/commit/60359407d9a20a364bff92c6d0417f5f3995032c", "message": "remove duplicate semicolon", "committedDate": "2020-09-03T14:49:58Z", "type": "commit"}, {"oid": "f19549a7768c3a00b11e7093e167d47666c3c4d1", "url": "https://github.com/apache/hive/commit/f19549a7768c3a00b11e7093e167d47666c3c4d1", "message": "add tpch18", "committedDate": "2020-09-03T14:52:15Z", "type": "commit"}, {"oid": "cd6c9cda7c1ff8ed49ac61c2e417d1a2e724315c", "url": "https://github.com/apache/hive/commit/cd6c9cda7c1ff8ed49ac61c2e417d1a2e724315c", "message": "put back intersect", "committedDate": "2020-09-07T04:51:05Z", "type": "commit"}, {"oid": "ee00ba27aaea73461553143147c43be29b6e09ac", "url": "https://github.com/apache/hive/commit/ee00ba27aaea73461553143147c43be29b6e09ac", "message": "fix", "committedDate": "2020-09-07T11:47:53Z", "type": "commit"}, {"oid": "aef16e6b5bba03057ce03122506bbf87715561bb", "url": "https://github.com/apache/hive/commit/aef16e6b5bba03057ce03122506bbf87715561bb", "message": "redo", "committedDate": "2020-09-07T11:49:37Z", "type": "commit"}, {"oid": "845b86e3d3eaaa7f2169ad56432cd1918a1d571f", "url": "https://github.com/apache/hive/commit/845b86e3d3eaaa7f2169ad56432cd1918a1d571f", "message": "x", "committedDate": "2020-09-07T11:57:46Z", "type": "commit"}, {"oid": "e415e474b48216d56bc6c29c1d1e21ef2222c8a6", "url": "https://github.com/apache/hive/commit/e415e474b48216d56bc6c29c1d1e21ef2222c8a6", "message": "mx", "committedDate": "2020-09-07T12:04:56Z", "type": "commit"}, {"oid": "628f5a3989befbb69c843a958a7b0dd5add05484", "url": "https://github.com/apache/hive/commit/628f5a3989befbb69c843a958a7b0dd5add05484", "message": "PP", "committedDate": "2020-09-07T12:06:58Z", "type": "commit"}, {"oid": "3bdca364ac03473b967881f1d02fe54b454c2974", "url": "https://github.com/apache/hive/commit/3bdca364ac03473b967881f1d02fe54b454c2974", "message": "more", "committedDate": "2020-09-07T12:09:11Z", "type": "commit"}, {"oid": "7198ac40e4f49ea7d14f40980b38d6bed9888a64", "url": "https://github.com/apache/hive/commit/7198ac40e4f49ea7d14f40980b38d6bed9888a64", "message": "more wood", "committedDate": "2020-09-07T12:35:39Z", "type": "commit"}, {"oid": "d74b3602bfe5c435f57185d3ce44c00072413db7", "url": "https://github.com/apache/hive/commit/d74b3602bfe5c435f57185d3ce44c00072413db7", "message": "remove conditional", "committedDate": "2020-09-07T12:56:36Z", "type": "commit"}, {"oid": "0580687d53ce342e57e54a1daac2d171f17f33b4", "url": "https://github.com/apache/hive/commit/0580687d53ce342e57e54a1daac2d171f17f33b4", "message": "use JoinInfo instead of custom class", "committedDate": "2020-09-07T13:11:34Z", "type": "commit"}, {"oid": "fd77ca70c035ab4f6d1ce51c96883210cefc6b90", "url": "https://github.com/apache/hive/commit/fd77ca70c035ab4f6d1ce51c96883210cefc6b90", "message": "rename variable", "committedDate": "2020-09-07T13:12:46Z", "type": "commit"}, {"oid": "42d36cb4eb0a897f219f7457dffdc28e6adba439", "url": "https://github.com/apache/hive/commit/42d36cb4eb0a897f219f7457dffdc28e6adba439", "message": "undo model changes", "committedDate": "2020-09-07T13:14:49Z", "type": "commit"}, {"oid": "fc8bacccaaf2a8afdcd8f6139ec70b461b200972", "url": "https://github.com/apache/hive/commit/fc8bacccaaf2a8afdcd8f6139ec70b461b200972", "message": "update q.out", "committedDate": "2020-09-07T13:16:45Z", "type": "commit"}, {"oid": "07ca9037848c445fa37f06b58789edf4a7d1384a", "url": "https://github.com/apache/hive/commit/07ca9037848c445fa37f06b58789edf4a7d1384a", "message": "updates to q.out", "committedDate": "2020-09-07T13:21:55Z", "type": "commit"}, {"oid": "fca9a95aabf555bbe88a4d462289e6adfe158bed", "url": "https://github.com/apache/hive/commit/fca9a95aabf555bbe88a4d462289e6adfe158bed", "message": "use areColumnsUnique", "committedDate": "2020-09-07T13:31:55Z", "type": "commit"}, {"oid": "4679f91d44d69525a4a745f09297748c875c440b", "url": "https://github.com/apache/hive/commit/4679f91d44d69525a4a745f09297748c875c440b", "message": "add knob", "committedDate": "2020-09-07T13:47:39Z", "type": "commit"}, {"oid": "29ff2301f5f9b4f47e4a3851541184a9c66a1004", "url": "https://github.com/apache/hive/commit/29ff2301f5f9b4f47e4a3851541184a9c66a1004", "message": "restrict uniqueness based by aggconvertedtoprojects", "committedDate": "2020-09-07T13:54:26Z", "type": "commit"}, {"oid": "ae39544ff27c7ed3ce631e739fe4efa8dbc62af6", "url": "https://github.com/apache/hive/commit/ae39544ff27c7ed3ce631e739fe4efa8dbc62af6", "message": "Merge remote-tracking branch 'apache/master' into HIVE-24084-cost-aggr", "committedDate": "2020-09-08T13:40:02Z", "type": "commit"}, {"oid": "37fbbfbf3e7a7e50e23097ff2ee4dbc338f7d960", "url": "https://github.com/apache/hive/commit/37fbbfbf3e7a7e50e23097ff2ee4dbc338f7d960", "message": "add nullcheck", "committedDate": "2020-09-08T14:23:23Z", "type": "commit"}, {"oid": "7042d5ddeafeee18ed545c1addd71adf645ced85", "url": "https://github.com/apache/hive/commit/7042d5ddeafeee18ed545c1addd71adf645ced85", "message": "accept q.out changes: removed aggregates(and transform to semijoin) - or better placed aggregates", "committedDate": "2020-09-08T14:53:37Z", "type": "commit"}, {"oid": "95dfa8a1616a29c55ac779aad00975fb4cf96f58", "url": "https://github.com/apache/hive/commit/95dfa8a1616a29c55ac779aad00975fb4cf96f58", "message": "back to getUniqueKeys", "committedDate": "2020-09-08T15:14:53Z", "type": "commit"}, {"oid": "62480d110acb48fdc98c08a43dc3166d3df457c5", "url": "https://github.com/apache/hive/commit/62480d110acb48fdc98c08a43dc3166d3df457c5", "message": "temporary fix", "committedDate": "2020-09-08T15:25:26Z", "type": "commit"}, {"oid": "8a84c7513bfd9e8a72c9d19f2f69a92293ab2cc0", "url": "https://github.com/apache/hive/commit/8a84c7513bfd9e8a72c9d19f2f69a92293ab2cc0", "message": "Merge remote-tracking branch 'apache/master' into HIVE-24084-cost-aggr", "committedDate": "2020-09-09T08:53:16Z", "type": "commit"}, {"oid": "d823db8a3e45e694431f41626d3de6d6f1af8913", "url": "https://github.com/apache/hive/commit/d823db8a3e45e694431f41626d3de6d6f1af8913", "message": "add constraints", "committedDate": "2020-09-11T14:45:26Z", "type": "commit"}, {"oid": "76e27380f7df60bd54039dcf0065f3d64f7279d8", "url": "https://github.com/apache/hive/commit/76e27380f7df60bd54039dcf0065f3d64f7279d8", "message": "process HepVertex", "committedDate": "2020-09-11T14:57:55Z", "type": "commit"}, {"oid": "bde4c25b8b3a8621de3eef1d50ae89a129ec9a3e", "url": "https://github.com/apache/hive/commit/bde4c25b8b3a8621de3eef1d50ae89a129ec9a3e", "message": "early exit rule", "committedDate": "2020-09-11T15:16:00Z", "type": "commit"}, {"oid": "18df6b7dc1de8987bb4898c9cfc73d753d6a6ed7", "url": "https://github.com/apache/hive/commit/18df6b7dc1de8987bb4898c9cfc73d753d6a6ed7", "message": "q.out change", "committedDate": "2020-09-11T15:18:55Z", "type": "commit"}, {"oid": "2fd7e39d246b5f844038d58e6a3572c8f7c7a6c6", "url": "https://github.com/apache/hive/commit/2fd7e39d246b5f844038d58e6a3572c8f7c7a6c6", "message": "fix", "committedDate": "2020-09-15T12:09:12Z", "type": "commit"}, {"oid": "d3f7c6590910ffd6205a6411ecb975ab6f2553b5", "url": "https://github.com/apache/hive/commit/d3f7c6590910ffd6205a6411ecb975ab6f2553b5", "message": "Merge remote-tracking branch 'apache/master' into HIVE-24084-cost-aggr", "committedDate": "2020-09-15T12:25:43Z", "type": "commit"}]}