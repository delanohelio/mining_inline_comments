{"pr_number": 1610, "pr_title": "HIVE-24259: [CachedStore] Optimise get all constraint api", "pr_createdAt": "2020-10-25T09:19:49Z", "pr_url": "https://github.com/apache/hive/pull/1610", "timeline": [{"oid": "55eea4be1843fe2e6d61c926d22ccadcfe8a5f1d", "url": "https://github.com/apache/hive/commit/55eea4be1843fe2e6d61c926d22ccadcfe8a5f1d", "message": "First commit", "committedDate": "2020-10-25T09:18:22Z", "type": "forcePushed"}, {"oid": "7ae4031e8b6da4027665bf35b3c4c13b881f02ea", "url": "https://github.com/apache/hive/commit/7ae4031e8b6da4027665bf35b3c4c13b881f02ea", "message": "HIVE-24259: [CachedStore] Optimise getAlltableConstraint from 6 cache call to 1 cache call", "committedDate": "2020-10-25T12:45:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NTMzNQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r511995335", "bodyText": "Majority of the calls are likely to be redirected to RawStore and lose the advantage of cache. How about an optional flag in SQLAllTableConstraints and TableWrapper to mark if it is a complete snapshot of constraints?", "author": "sankarh", "createdAt": "2020-10-26T14:19:32Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2836,14 +2836,32 @@ long getPartsFound() {\n   @Override\n   public SQLAllTableConstraints getAllTableConstraints(String catName, String dbName, String tblName)\n       throws MetaException, NoSuchObjectException {\n-    SQLAllTableConstraints sqlAllTableConstraints = new SQLAllTableConstraints();\n-    sqlAllTableConstraints.setPrimaryKeys(getPrimaryKeys(catName, dbName, tblName));\n-    sqlAllTableConstraints.setForeignKeys(getForeignKeys(catName, null, null, dbName, tblName));\n-    sqlAllTableConstraints.setUniqueConstraints(getUniqueConstraints(catName, dbName, tblName));\n-    sqlAllTableConstraints.setDefaultConstraints(getDefaultConstraints(catName, dbName, tblName));\n-    sqlAllTableConstraints.setCheckConstraints(getCheckConstraints(catName, dbName, tblName));\n-    sqlAllTableConstraints.setNotNullConstraints(getNotNullConstraints(catName, dbName, tblName));\n-    return sqlAllTableConstraints;\n+\n+    catName = StringUtils.normalizeIdentifier(catName);\n+    dbName = StringUtils.normalizeIdentifier(dbName);\n+    tblName = StringUtils.normalizeIdentifier(tblName);\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+      return rawStore.getAllTableConstraints(catName, dbName, tblName);\n+    }\n+\n+    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n+    if (tbl == null) {\n+      // The table containing the constraints is not yet loaded in cache\n+      return rawStore.getAllTableConstraints(catName, dbName, tblName);\n+    }\n+    SQLAllTableConstraints constraints = sharedCache.listCachedAllTableConstraints(catName, dbName, tblName);\n+\n+    // if any of the constraint value is missing then there might be the case of partial constraints are stored in cached.\n+    // So fall back to raw store for correct values\n+    if (constraints != null && CollectionUtils.isNotEmpty(constraints.getPrimaryKeys()) && CollectionUtils", "originalCommit": "7ae4031e8b6da4027665bf35b3c4c13b881f02ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU2MjM3Ng==", "url": "https://github.com/apache/hive/pull/1610#discussion_r512562376", "bodyText": "+1.", "author": "adesh-rao", "createdAt": "2020-10-27T10:10:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NTMzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU2NDgyOA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r512564828", "bodyText": "Also, what if the table just has primary keys and no other constraints?\nnonEmpty(otherConstraints) will return true and we will not cache anything?", "author": "adesh-rao", "createdAt": "2020-10-27T10:14:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NTMzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU2NTA1Ng==", "url": "https://github.com/apache/hive/pull/1610#discussion_r512565056", "bodyText": "Good idea. I will check how we can implement a flag.", "author": "ashish-kumar-sharma", "createdAt": "2020-10-27T10:14:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NTMzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDgyOTI0NA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r514829244", "bodyText": "Adding a flag required bigger change. So for now I am reducing the scope of this PR to optimise following\n\nCheck only once if table exit in cached store.\nInstead of calling individual constraint in cached store. Add a method which return all constraint at once and if data is not consistent then fall back to rawstore.", "author": "ashish-kumar-sharma", "createdAt": "2020-10-30T04:21:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NTMzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg4MTkyNg==", "url": "https://github.com/apache/hive/pull/1610#discussion_r519881926", "bodyText": "Why is it hard to set a flag for consistency? If we hit else flow in this case, we shall try to update the cache and if that fails for some reason, then set the flag to false else set to true. Same with pre-warm and refresh flows.\nAlso, we need to check only the flag to validate the consistency of cache. No need to check for null or empty constraints.", "author": "sankarh", "createdAt": "2020-11-09T15:05:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NTMzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1ODQzOA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r531158438", "bodyText": "Added flag", "author": "ashish-kumar-sharma", "createdAt": "2020-11-26T17:19:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NTMzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg3NzY3Ng==", "url": "https://github.com/apache/hive/pull/1610#discussion_r519877676", "bodyText": "keys with null is accessed at line 2413", "author": "sankarh", "createdAt": "2020-11-09T14:59:57Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -2397,7 +2397,7 @@ public SQLAllTableConstraints listCachedAllTableConstraints(String catName, Stri\n \n   public List<SQLForeignKey> listCachedForeignKeys(String catName, String foreignDbName, String foreignTblName,\n                                                    String parentDbName, String parentTblName) {\n-    List<SQLForeignKey> keys = new ArrayList<>();\n+    List<SQLForeignKey> keys = null;", "originalCommit": "eea2fa7506907337b81becb277f71879a0d05fdd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1ODY1Mg==", "url": "https://github.com/apache/hive/pull/1610#discussion_r531158652", "bodyText": "done", "author": "ashish-kumar-sharma", "createdAt": "2020-11-26T17:20:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg3NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxNTMwMw==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574315303", "bodyText": "Still keys can be referenced with null at line 2365.", "author": "sankarh", "createdAt": "2021-02-11T08:23:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg3NzY3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk5NTUwOQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574995509", "bodyText": "Done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-12T05:21:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg3NzY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg3OTg3MA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r519879870", "bodyText": "Add a TODO that this check is inefficient as all calls will hit rawstore if even one of the constraint type is not set for the given table.", "author": "sankarh", "createdAt": "2020-11-09T15:02:55Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2844,15 +2814,10 @@ public SQLAllTableConstraints getAllTableConstraints(String catName, String dbNa\n       return rawStore.getAllTableConstraints(catName, dbName, tblName);\n     }\n \n-    Table tbl = sharedCache.getTableFromCache(catName, dbName, tblName);\n-    if (tbl == null) {\n-      // The table containing the constraints is not yet loaded in cache\n-      return rawStore.getAllTableConstraints(catName, dbName, tblName);\n-    }\n     SQLAllTableConstraints constraints = sharedCache.listCachedAllTableConstraints(catName, dbName, tblName);\n \n-    // if any of the constraint value is missing then there might be the case of partial constraints are stored in cached.\n-    // So fall back to raw store for correct values\n+    /* If constraint value is missing then there might be the case that table is not stored in cached or", "originalCommit": "eea2fa7506907337b81becb277f71879a0d05fdd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1ODc0NA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r531158744", "bodyText": "done", "author": "ashish-kumar-sharma", "createdAt": "2020-11-26T17:20:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg3OTg3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjA0MjA3OQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r532042079", "bodyText": "Keep one member per line to be more readable.", "author": "sankarh", "createdAt": "2020-11-28T13:47:13Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -134,17 +134,8 @@ public int getPosition() {\n     }\n   }\n \n-  private enum MemberName {\n-    TABLE_COL_STATS_CACHE,\n-    PARTITION_CACHE,\n-    PARTITION_COL_STATS_CACHE,\n-    AGGR_COL_STATS_CACHE,\n-    PRIMARY_KEY_CACHE,\n-    FOREIGN_KEY_CACHE,\n-    NOTNULL_CONSTRAINT_CACHE,\n-    UNIQUE_CONSTRAINT_CACHE,\n-    DEFAULT_CONSTRAINT_CACHE,\n-    CHECK_CONSTRAINT_CACHE\n+  public enum MemberName {\n+    TABLE_COL_STATS_CACHE, PARTITION_CACHE, PARTITION_COL_STATS_CACHE, AGGR_COL_STATS_CACHE, PRIMARY_KEY_CACHE, FOREIGN_KEY_CACHE, NOTNULL_CONSTRAINT_CACHE, UNIQUE_CONSTRAINT_CACHE, DEFAULT_CONSTRAINT_CACHE, CHECK_CONSTRAINT_CACHE, ALL_TABLE_CONSTRAINT", "originalCommit": "7e75fa6db9962fffa1900c6bf2a84d9481ff48ab", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjA0NTA5MA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r532045090", "bodyText": "Using too many flags is complex. Check if we can simplify it using below logic.\n\nFetch all constraints and update cache -> If this update is successful, then set \"isAllConstraintsSet=true\"\nIf partially successful due to memory constraint, then set \"isAllConstraintsSet=false\" and set bit position of completed constraint \"long constraintStatusBits\". We can assign one bit per constraintType and generally in the order in which we update it. It means, if we encounter a bit which is unset, then rest of the bits are unset too.\nWe never refresh individual constraints. Always try to update all constraints by using same method which follow above logic to set the flag. Shall remove all individual update(CachedStore.updateTablePrimaryKeys...) and refresh(SharedCache.refreshPrimaryKeysInCache...) methods for each types. This ensure, we always cache a valid snapshot.\nWhen read any constraint, first check isAllConstraintsSet==true. If true, then assume all are valid and return the cached entry immediately. If false, then just the corresponding bit in \"constraintStatusBits\" and if true, then return the cached entry or else return null and invoke RawStore.\n\nNote: We can also get rid of isAllConstraintsSet flag by using constraintStatusBits = -1 for \"true\" scenario.", "author": "sankarh", "createdAt": "2020-11-28T14:17:25Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -309,12 +302,19 @@ public int getObjectSize(Class<?> clazz, Object obj) {\n     private Map<String, SQLDefaultConstraint> defaultConstraintCache = new ConcurrentHashMap<>();\n     private Map<String, SQLCheckConstraint> checkConstraintCache = new ConcurrentHashMap<>();\n \n+    private boolean pk = false;", "originalCommit": "7e75fa6db9962fffa1900c6bf2a84d9481ff48ab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcwMzc1NA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r570703754", "bodyText": "Changes are as follows\n\nReplace 6 flag with 1 flag\nIn cache refresh/update flow removed 6 call to raw metastore with getAllTableConstraints()\nWhile adding table to cache via createTable and createTableWithConstraint isConstraintValid flag is set as true.\nIf  isConstraintValid flag is true then return data from cache else redirect to raw metastore.\nWhile adding individual constraint to metastore if  isConstraintValid is true that means constraints snapshot is valid and new constraint can be updated in cachestore else skip update.\nisConstraintValid will only be true if all the constraint value are valid in the metastore else redirect to raw metastore (For the case of partial constraint storage due to memory shortage)", "author": "ashish-kumar-sharma", "createdAt": "2021-02-05T03:54:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjA0NTA5MA=="}], "type": "inlineReview"}, {"oid": "a6c3bda00b7fdace0840e3f2e01495c46f57f970", "url": "https://github.com/apache/hive/commit/a6c3bda00b7fdace0840e3f2e01495c46f57f970", "message": "code reformat", "committedDate": "2021-01-29T09:22:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjE2ODI2MQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r572168261", "bodyText": "There is a separate api for createTableWithConstraints.\nIs this api also used when table is created with constraints?", "author": "adesh-rao", "createdAt": "2021-02-08T16:07:10Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -1325,6 +1204,7 @@ private void validateTableType(Table tbl) {\n     }\n     validateTableType(tbl);\n     sharedCache.addTableToCache(catName, dbName, tblName, tbl);\n+    sharedCache.addTableConstraintsToCache(catName,dbName,tblName,new SQLAllTableConstraints());", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjcyMzg0Mg==", "url": "https://github.com/apache/hive/pull/1610#discussion_r572723842", "bodyText": "This line was added to update table cache with all constraints null and flag set to true. So avoid redirection to raw store.", "author": "ashish-kumar-sharma", "createdAt": "2021-02-09T09:29:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjE2ODI2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjE3MjI3OQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r572172279", "bodyText": "nit: need extra spaces before case?", "author": "adesh-rao", "createdAt": "2021-02-08T16:12:18Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -418,12 +424,12 @@ private void updateMemberSize(MemberName mn, Integer size, SizeMode mode) {\n       }\n \n       switch (mode) {\n-        case Delta:\n-          this.memberObjectsSize[mn.ordinal()] += size;\n-          break;\n-        case Snapshot:\n-          this.memberObjectsSize[mn.ordinal()] = size;\n-          break;\n+      case Delta:", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjE3ODQxNg==", "url": "https://github.com/apache/hive/pull/1610#discussion_r572178416", "bodyText": "below check was present earlier:\nif (CollectionUtils.isEmpty(keys)) {\t\n      return rawStore.getCheckConstraints(catName, dbName, tblName);\t\n}\n\nWhy is this removed? Is this check moved somewhere else?", "author": "adesh-rao", "createdAt": "2021-02-08T16:20:14Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2814,21 +2649,12 @@ long getPartsFound() {\n     catName = StringUtils.normalizeIdentifier(catName);\n     dbName = StringUtils.normalizeIdentifier(dbName);\n     tblName = StringUtils.normalizeIdentifier(tblName);\n-    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction()) || !sharedCache\n+        .isTableConstraintValid(catName, dbName, tblName)) {\n       return rawStore.getCheckConstraints(catName, dbName, tblName);\n     }\n+    return sharedCache.listCachedCheckConstraint(catName, dbName, tblName);", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjcyNjUzOA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r572726538", "bodyText": "Added flag - isConstraintValid to check null value is consistent instead of going to raw store.", "author": "ashish-kumar-sharma", "createdAt": "2021-02-09T09:33:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjE3ODQxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDI5ODU3NQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574298575", "bodyText": "nit: Add space after comma.", "author": "sankarh", "createdAt": "2021-02-11T07:47:04Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -1325,6 +1204,7 @@ private void validateTableType(Table tbl) {\n     }\n     validateTableType(tbl);\n     sharedCache.addTableToCache(catName, dbName, tblName, tbl);\n+    sharedCache.addTableConstraintsToCache(catName,dbName,tblName,new SQLAllTableConstraints());", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDQwODk2NQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574408965", "bodyText": "done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-11T10:56:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDI5ODU3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMwMjg2NQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574302865", "bodyText": "This method never returns false. It means, isConstraintsValid flag is always true. Is it by design? If yes, when it will be false?", "author": "sankarh", "createdAt": "2021-02-11T07:56:31Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -506,10 +512,18 @@ boolean cacheCheckConstraints(List<SQLCheckConstraint> checkConstraints, boolean\n       return cacheConstraints(checkConstraints, fromPrewarm, MemberName.CHECK_CONSTRAINT_CACHE);\n     }\n \n+    boolean cacheConstraints(SQLAllTableConstraints constraints, boolean fromPrewarm) {\n+      this.isConstraintsValid =\n+          cacheConstraints(constraints.getPrimaryKeys(), fromPrewarm, MemberName.PRIMARY_KEY_CACHE) && cacheConstraints(\n+              constraints.getForeignKeys(), fromPrewarm, MemberName.FOREIGN_KEY_CACHE) && cacheConstraints(constraints.getDefaultConstraints(), fromPrewarm, MemberName.DEFAULT_CONSTRAINT_CACHE)\n+              && cacheConstraints(constraints.getUniqueConstraints(), fromPrewarm, MemberName.UNIQUE_CONSTRAINT_CACHE)\n+              && cacheConstraints(constraints.getNotNullConstraints(), fromPrewarm, MemberName.NOTNULL_CONSTRAINT_CACHE)\n+              && cacheConstraints(constraints.getCheckConstraints(), fromPrewarm, MemberName.CHECK_CONSTRAINT_CACHE);\n+      return this.isConstraintsValid;\n+    }\n+\n     // Common method to cache constraints\n-    private boolean cacheConstraints(List constraintsList,\n-                             boolean fromPrewarm,\n-                             MemberName mn) {\n+    private boolean cacheConstraints(List constraintsList, boolean fromPrewarm, MemberName mn) {", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTkyOTIzNQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r575929235", "bodyText": "In case of wrong member type.", "author": "ashish-kumar-sharma", "createdAt": "2021-02-15T03:51:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMwMjg2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMwNDY4MQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574304681", "bodyText": "This also always returns true and in tune make isConstraintsValid=true always.", "author": "sankarh", "createdAt": "2021-02-11T08:00:33Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -715,154 +747,105 @@ public void removeConstraint(String name) {\n       }\n     }\n \n-    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n-      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+    public void refreshAllTableConstraints(SQLAllTableConstraints constraints) {\n       try {\n         tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLPrimaryKey key : keys) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n-            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n-                    + \"; the primary keys are already refreshed.\");\n-            return;\n-          }\n-          String pkName = StringUtils.normalizeIdentifier(key.getPk_name());\n-          key.setPk_name(pkName);\n-          newKeys.put(pkName, key);\n-          size += getObjectSize(SQLPrimaryKey.class, key);\n-        }\n-        primaryKeyCache = newKeys;\n-        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Primary keys refresh in cache was successful for {}.{}.{}\",\n-            this.getTable().getCatName(), this.getTable().getDbName(), this.getTable().getTableName());\n+        this.isConstraintsValid =\n+            refreshConstraint(constraints.getPrimaryKeys(), MemberName.PRIMARY_KEY_CACHE) && refreshConstraint(\n+                constraints.getForeignKeys(), MemberName.FOREIGN_KEY_CACHE) && refreshConstraint(\n+                constraints.getUniqueConstraints(), MemberName.UNIQUE_CONSTRAINT_CACHE) && refreshConstraint(\n+                constraints.getDefaultConstraints(), MemberName.DEFAULT_CONSTRAINT_CACHE) && refreshConstraint(\n+                constraints.getNotNullConstraints(), MemberName.NOTNULL_CONSTRAINT_CACHE) && refreshConstraint(\n+                constraints.getCheckConstraints(), MemberName.CHECK_CONSTRAINT_CACHE);\n       } finally {\n         tableLock.writeLock().unlock();\n       }\n     }\n \n-    public void refreshForeignKeys(List<SQLForeignKey> keys) {\n-      Map<String, SQLForeignKey> newKeys = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLForeignKey key : keys) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.FOREIGN_KEY_CACHE, true, false)) {\n-            LOG.debug(\"Skipping foreign key cache update for table: \" + getTable().getTableName()\n-                    + \"; the foreign keys are already refreshed.\");\n-            return;\n+    private boolean refreshConstraint(List constraints, MemberName mn) {", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTkyOTE1Mg==", "url": "https://github.com/apache/hive/pull/1610#discussion_r575929152", "bodyText": "Yes", "author": "ashish-kumar-sharma", "createdAt": "2021-02-15T03:51:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMwNDY4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMwNTE3MA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574305170", "bodyText": "nit: Space before  ( and after comma", "author": "sankarh", "createdAt": "2021-02-11T08:01:39Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -1788,47 +1771,16 @@ public boolean populateTableInCache(Table table, TableCacheObjects cacheObjects)\n     tblWrapper.setMemberCacheUpdated(MemberName.PARTITION_COL_STATS_CACHE, false);\n     tblWrapper.setMemberCacheUpdated(MemberName.AGGR_COL_STATS_CACHE, false);\n \n-    if (CollectionUtils.isNotEmpty(constraints.getPrimaryKeys())) {\n-      if (!tblWrapper.cachePrimaryKeys(constraints.getPrimaryKeys(), true)) {\n-        return false;\n-      }\n-    }\n-    tblWrapper.setMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, false);\n-\n-    if (CollectionUtils.isNotEmpty(constraints.getForeignKeys())) {\n-      if (!tblWrapper.cacheForeignKeys(constraints.getForeignKeys(), true)) {\n-        return false;\n-      }\n-    }\n-    tblWrapper.setMemberCacheUpdated(MemberName.FOREIGN_KEY_CACHE, false);\n-\n-    if (CollectionUtils.isNotEmpty(constraints.getNotNullConstraints())) {\n-      if (!tblWrapper.cacheNotNullConstraints(constraints.getNotNullConstraints(), true)) {\n-        return false;\n-      }\n-    }\n-    tblWrapper.setMemberCacheUpdated(MemberName.NOTNULL_CONSTRAINT_CACHE, false);\n-\n-    if (CollectionUtils.isNotEmpty(constraints.getUniqueConstraints())) {\n-      if (!tblWrapper.cacheUniqueConstraints(constraints.getUniqueConstraints(), true)) {\n-        return false;\n-      }\n-    }\n-    tblWrapper.setMemberCacheUpdated(MemberName.UNIQUE_CONSTRAINT_CACHE, false);\n-\n-    if (CollectionUtils.isNotEmpty(constraints.getDefaultConstraints())) {\n-      if (!tblWrapper.cacheDefaultConstraints(constraints.getDefaultConstraints(), true)) {\n-        return false;\n-      }\n-    }\n-    tblWrapper.setMemberCacheUpdated(MemberName.DEFAULT_CONSTRAINT_CACHE, false);\n-\n-    if (CollectionUtils.isNotEmpty(constraints.getCheckConstraints())) {\n-      if (!tblWrapper.cacheCheckConstraints(constraints.getCheckConstraints(), true)) {\n-        return false;\n-      }\n+    if(tblWrapper.cacheConstraints(constraints,true)) {", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDQwOTE0Mw==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574409143", "bodyText": "done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-11T10:56:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMwNTE3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxMjYzNQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574312635", "bodyText": "Why do we set this flag to false?", "author": "sankarh", "createdAt": "2021-02-11T08:17:42Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -715,154 +747,105 @@ public void removeConstraint(String name) {\n       }\n     }\n \n-    public void refreshPrimaryKeys(List<SQLPrimaryKey> keys) {\n-      Map<String, SQLPrimaryKey> newKeys = new ConcurrentHashMap<>();\n+    public void refreshAllTableConstraints(SQLAllTableConstraints constraints) {\n       try {\n         tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLPrimaryKey key : keys) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.PRIMARY_KEY_CACHE, true, false)) {\n-            LOG.debug(\"Skipping primary key cache update for table: \" + getTable().getTableName()\n-                    + \"; the primary keys are already refreshed.\");\n-            return;\n-          }\n-          String pkName = StringUtils.normalizeIdentifier(key.getPk_name());\n-          key.setPk_name(pkName);\n-          newKeys.put(pkName, key);\n-          size += getObjectSize(SQLPrimaryKey.class, key);\n-        }\n-        primaryKeyCache = newKeys;\n-        updateMemberSize(MemberName.PRIMARY_KEY_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Primary keys refresh in cache was successful for {}.{}.{}\",\n-            this.getTable().getCatName(), this.getTable().getDbName(), this.getTable().getTableName());\n+        this.isConstraintsValid =\n+            refreshConstraint(constraints.getPrimaryKeys(), MemberName.PRIMARY_KEY_CACHE) && refreshConstraint(\n+                constraints.getForeignKeys(), MemberName.FOREIGN_KEY_CACHE) && refreshConstraint(\n+                constraints.getUniqueConstraints(), MemberName.UNIQUE_CONSTRAINT_CACHE) && refreshConstraint(\n+                constraints.getDefaultConstraints(), MemberName.DEFAULT_CONSTRAINT_CACHE) && refreshConstraint(\n+                constraints.getNotNullConstraints(), MemberName.NOTNULL_CONSTRAINT_CACHE) && refreshConstraint(\n+                constraints.getCheckConstraints(), MemberName.CHECK_CONSTRAINT_CACHE);\n       } finally {\n         tableLock.writeLock().unlock();\n       }\n     }\n \n-    public void refreshForeignKeys(List<SQLForeignKey> keys) {\n-      Map<String, SQLForeignKey> newKeys = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLForeignKey key : keys) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.FOREIGN_KEY_CACHE, true, false)) {\n-            LOG.debug(\"Skipping foreign key cache update for table: \" + getTable().getTableName()\n-                    + \"; the foreign keys are already refreshed.\");\n-            return;\n+    private boolean refreshConstraint(List constraints, MemberName mn) {\n+      int size = 0;\n+      switch (mn) {\n+      case PRIMARY_KEY_CACHE:\n+        Map<String, SQLPrimaryKey> newPk = new ConcurrentHashMap<>();\n+        if (!CollectionUtils.isEmpty(constraints)) {\n+          for (SQLPrimaryKey key : (List<SQLPrimaryKey>) constraints) {\n+            String pkName = StringUtils.normalizeIdentifier(key.getPk_name());\n+            key.setPk_name(pkName);\n+            newPk.put(pkName, key);\n+            size += getObjectSize(SQLPrimaryKey.class, key);\n           }\n-          String fkName = StringUtils.normalizeIdentifier(key.getFk_name());\n-          key.setFk_name(fkName);\n-          newKeys.put(fkName, key);\n-          size += getObjectSize(SQLForeignKey.class, key);\n         }\n-        foreignKeyCache = newKeys;\n-        updateMemberSize(MemberName.FOREIGN_KEY_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Foreign keys refresh in cache was successful for {}.{}.{}\",\n-            this.getTable().getCatName(), this.getTable().getDbName(), this.getTable().getTableName());\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshNotNullConstraints(List<SQLNotNullConstraint> constraints) {\n-      Map<String, SQLNotNullConstraint> newConstraints = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLNotNullConstraint constraint : constraints) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.NOTNULL_CONSTRAINT_CACHE, true, false)) {\n-            LOG.debug(\"Skipping not null constraints cache update for table: \" + getTable().getTableName()\n-                    + \"; the not null constraints are already refreshed.\");\n-            return;\n+        primaryKeyCache = newPk;\n+        break;\n+      case FOREIGN_KEY_CACHE:\n+        Map<String, SQLForeignKey> newFk = new ConcurrentHashMap<>();\n+        if (!CollectionUtils.isEmpty(constraints)) {\n+          for (SQLForeignKey key : (List<SQLForeignKey>) constraints) {\n+            String fkName = StringUtils.normalizeIdentifier(key.getFk_name());\n+            key.setFk_name(fkName);\n+            newFk.put(fkName, key);\n+            size += getObjectSize(SQLForeignKey.class, key);\n           }\n-          String nnName = StringUtils.normalizeIdentifier(constraint.getNn_name());\n-          constraint.setNn_name(nnName);\n-          newConstraints.put(nnName, constraint);\n-          size += getObjectSize(SQLNotNullConstraint.class, constraint);\n         }\n-        notNullConstraintCache = newConstraints;\n-        updateMemberSize(MemberName.NOTNULL_CONSTRAINT_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Not null constraints refresh in cache was successful for {}.{}.{}\",\n-            this.getTable().getCatName(), this.getTable().getDbName(), this.getTable().getTableName());\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshUniqueConstraints(List<SQLUniqueConstraint> constraints) {\n-      Map<String, SQLUniqueConstraint> newConstraints = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLUniqueConstraint constraint : constraints) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.UNIQUE_CONSTRAINT_CACHE, true, false)) {\n-            LOG.debug(\"Skipping unique constraints cache update for table: \" + getTable().getTableName()\n-                    + \"; the unique constraints are already refreshed.\");\n-            return;\n+        foreignKeyCache = newFk;\n+        break;\n+      case UNIQUE_CONSTRAINT_CACHE:\n+        Map<String, SQLUniqueConstraint> newUc = new ConcurrentHashMap<>();\n+        if (!CollectionUtils.isEmpty(constraints)) {\n+          for (SQLUniqueConstraint constraint : (List<SQLUniqueConstraint>) constraints) {\n+            String ucName = StringUtils.normalizeIdentifier(constraint.getUk_name());\n+            constraint.setUk_name(ucName);\n+            newUc.put(ucName, constraint);\n+            size += getObjectSize(SQLUniqueConstraint.class, constraint);\n           }\n-          String ucName = StringUtils.normalizeIdentifier(constraint.getUk_name());\n-          constraint.setUk_name(ucName);\n-          newConstraints.put(ucName, constraint);\n-          size += getObjectSize(SQLUniqueConstraint.class, constraint);\n         }\n-        uniqueConstraintCache = newConstraints;\n-        updateMemberSize(MemberName.UNIQUE_CONSTRAINT_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Unique constraints refresh in cache was successful for {}.{}.{}\",\n-            this.getTable().getCatName(), this.getTable().getDbName(), this.getTable().getTableName());\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshDefaultConstraints(List<SQLDefaultConstraint> constraints) {\n-      Map<String, SQLDefaultConstraint> newConstraints = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLDefaultConstraint constraint : constraints) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.DEFAULT_CONSTRAINT_CACHE, true, false)) {\n-            LOG.debug(\"Skipping default constraint cache update for table: \" + getTable().getTableName()\n-                + \"; the default constraint are already refreshed.\");\n-            return;\n+        uniqueConstraintCache = newUc;\n+        break;\n+      case NOTNULL_CONSTRAINT_CACHE:\n+        Map<String, SQLNotNullConstraint> newNn = new ConcurrentHashMap<>();\n+        if (!CollectionUtils.isEmpty(constraints)) {\n+          for (SQLNotNullConstraint constraint : (List<SQLNotNullConstraint>) constraints) {\n+            String nnName = StringUtils.normalizeIdentifier(constraint.getNn_name());\n+            constraint.setNn_name(nnName);\n+            newNn.put(nnName, constraint);\n+            size += getObjectSize(SQLNotNullConstraint.class, constraint);\n           }\n-          String dcName = StringUtils.normalizeIdentifier(constraint.getDc_name());\n-          constraint.setDc_name(dcName);\n-          newConstraints.put(dcName, constraint);\n-          size += getObjectSize(SQLDefaultConstraint.class, constraint);\n         }\n-        defaultConstraintCache = newConstraints;\n-        updateMemberSize(MemberName.DEFAULT_CONSTRAINT_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"Default constraints refresh in cache was successful for {}.{}.{}\", this.getTable().getCatName(),\n-            this.getTable().getDbName(), this.getTable().getTableName());\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n-    }\n-\n-    public void refreshCheckConstraints(List<SQLCheckConstraint> constraints) {\n-      Map<String, SQLCheckConstraint> newConstraints = new ConcurrentHashMap<>();\n-      try {\n-        tableLock.writeLock().lock();\n-        int size = 0;\n-        for (SQLCheckConstraint constraint : constraints) {\n-          if (compareAndSetMemberCacheUpdated(MemberName.CHECK_CONSTRAINT_CACHE, true, false)) {\n-            LOG.debug(\"Skipping check constraint cache update for table: \" + getTable().getTableName()\n-                + \"; the check constraint are already refreshed.\");\n-            return;\n+        notNullConstraintCache = newNn;\n+        break;\n+      case DEFAULT_CONSTRAINT_CACHE:\n+        Map<String, SQLDefaultConstraint> newDc = new ConcurrentHashMap<>();\n+        if (!CollectionUtils.isEmpty(constraints)) {\n+          for (SQLDefaultConstraint constraint : (List<SQLDefaultConstraint>) constraints) {\n+            String dcName = StringUtils.normalizeIdentifier(constraint.getDc_name());\n+            constraint.setDc_name(dcName);\n+            newDc.put(dcName, constraint);\n+            size += getObjectSize(SQLDefaultConstraint.class, constraint);\n           }\n-          String ccName = StringUtils.normalizeIdentifier(constraint.getDc_name());\n-          constraint.setDc_name(ccName);\n-          newConstraints.put(ccName, constraint);\n-          size += getObjectSize(SQLCheckConstraint.class, constraint);\n         }\n-        checkConstraintCache = newConstraints;\n-        updateMemberSize(MemberName.CHECK_CONSTRAINT_CACHE, size, SizeMode.Snapshot);\n-        LOG.debug(\"check constraints refresh in cache was successful for {}.{}.{}\", this.getTable().getCatName(),\n-            this.getTable().getDbName(), this.getTable().getTableName());\n-      } finally {\n-        tableLock.writeLock().unlock();\n-      }\n+        defaultConstraintCache = newDc;\n+        break;\n+      case CHECK_CONSTRAINT_CACHE:\n+        Map<String, SQLCheckConstraint> newCc = new ConcurrentHashMap<>();\n+        if (!CollectionUtils.isEmpty(constraints)) {\n+          for (SQLCheckConstraint constraint : (List<SQLCheckConstraint>) constraints) {\n+            String ccName = StringUtils.normalizeIdentifier(constraint.getDc_name());\n+            constraint.setDc_name(ccName);\n+            newCc.put(ccName, constraint);\n+            size += getObjectSize(SQLCheckConstraint.class, constraint);\n+          }\n+        }\n+        checkConstraintCache = newCc;\n+        break;\n+      default:\n+        LOG.error(\"Should not reach here\");\n+        break;\n+      }\n+      updateMemberSize(mn, size, SizeMode.Snapshot);\n+      setMemberCacheUpdated(mn, false);", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTAzODg3OA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r575038878", "bodyText": "because it is a snapshot", "author": "ashish-kumar-sharma", "createdAt": "2021-02-12T07:48:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxMjYzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxMzk1MA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574313950", "bodyText": "Keep tblWrapper != null within ().", "author": "sankarh", "createdAt": "2021-02-11T08:20:25Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -2187,7 +2139,7 @@ public void addPrimaryKeysToCache(String catName, String dbName, String tblName,\n       cacheLock.readLock().lock();\n       String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n       TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n-      if (tblWrapper != null) {\n+      if (tblWrapper != null && tblWrapper.isConstraintsValid()) {", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDQwOTUxNw==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574409517", "bodyText": "done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-11T10:57:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxMzk1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxNDUxOQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574314519", "bodyText": "Why do we update cache for each constraint individually? We should always cache a single snapshot of constraints of table. If not, isConstraintsValid flag wouldn't make sense.", "author": "sankarh", "createdAt": "2021-02-11T08:21:38Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -2187,7 +2139,7 @@ public void addPrimaryKeysToCache(String catName, String dbName, String tblName,\n       cacheLock.readLock().lock();\n       String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n       TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n-      if (tblWrapper != null) {\n+      if (tblWrapper != null && tblWrapper.isConstraintsValid()) {", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDQwODAzNg==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574408036", "bodyText": "Q Why do we update cache for each constraint individually?\nAns - To update the cache for specific constraint for query like \"ALTER TABLE table_name ADD CONSTRAINT\" instead of invalidating the whole cache and updating again because that will lead to cache miss or extra network call is required to delete and update all cache constraints.\nQ We should always cache a single snapshot of constraints of table. If not, isConstraintsValid flag wouldn't make sense.\nAns - So if isConstraintsValid is valid that means there is valid copy of constraint present then we can add the incoming constraint and save redundant call. if isConstraintsValid is false then skip because cached constraint are inaccessible and waiting for refreshed", "author": "ashish-kumar-sharma", "createdAt": "2021-02-11T10:55:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxNDUxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxNTg2OQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r574315869", "bodyText": "nit: Need space after comma", "author": "sankarh", "createdAt": "2021-02-11T08:24:10Z", "path": "standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/cache/TestCachedStore.java", "diffHunk": "@@ -1558,6 +1558,7 @@ public void testPrimaryKeys() {\n     Table tbl = createUnpartitionedTableObject(db);\n \n     sharedCache.addTableToCache(DEFAULT_CATALOG_NAME, \"db\", tbl.getTableName(), tbl);\n+    sharedCache.addTableConstraintsToCache(DEFAULT_CATALOG_NAME,\"db\", tbl.getTableName(), new SQLAllTableConstraints());", "originalCommit": "e2f6702d771a50f3caae8767e9d24f191080131b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTAzODk1NQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r575038955", "bodyText": "Done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-12T07:48:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDMxNTg2OQ=="}], "type": "inlineReview"}, {"oid": "255b2e02d7933dda1e23720dfd47d3ec6c24714e", "url": "https://github.com/apache/hive/commit/255b2e02d7933dda1e23720dfd47d3ec6c24714e", "message": "HIVE-24259: optimise allTableConstraint call in cache", "committedDate": "2021-02-16T16:10:36Z", "type": "forcePushed"}, {"oid": "b00d479ba6ab510378474637d7f37e6a79808532", "url": "https://github.com/apache/hive/commit/b00d479ba6ab510378474637d7f37e6a79808532", "message": "HIVE-24259: optimise get all table constraint from cache store", "committedDate": "2021-02-17T04:45:54Z", "type": "forcePushed"}, {"oid": "ffaa5a606ff8fe90fd6d08baccc8e15388b009f3", "url": "https://github.com/apache/hive/commit/ffaa5a606ff8fe90fd6d08baccc8e15388b009f3", "message": "HIVE-24259: fixed failing test", "committedDate": "2021-02-18T08:05:56Z", "type": "forcePushed"}, {"oid": "a738dab45dc1fd598371436ef3741e8928927662", "url": "https://github.com/apache/hive/commit/a738dab45dc1fd598371436ef3741e8928927662", "message": "HIVE-24259: optimise get all table constraint from cache store", "committedDate": "2021-02-18T08:39:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODI2MDAzNA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r578260034", "bodyText": "This check is done in several places. Shall add utility method for this.", "author": "sankarh", "createdAt": "2021-02-18T09:28:04Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2674,28 +2554,19 @@ long getPartsFound() {\n     catName = StringUtils.normalizeIdentifier(catName);\n     dbName = StringUtils.normalizeIdentifier(dbName);\n     tblName = StringUtils.normalizeIdentifier(tblName);\n-    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction())) {\n+    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction()) || !sharedCache", "originalCommit": "a738dab45dc1fd598371436ef3741e8928927662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODU3Mjk3Mg==", "url": "https://github.com/apache/hive/pull/1610#discussion_r578572972", "bodyText": "Done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-18T16:42:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODI2MDAzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODI2MjM4OA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r578262388", "bodyText": "invalidate is single word in this context.Change method name to invalidateConstraintsCache.", "author": "sankarh", "createdAt": "2021-02-18T09:31:16Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/SharedCache.java", "diffHunk": "@@ -2187,8 +2160,10 @@ public void addPrimaryKeysToCache(String catName, String dbName, String tblName,\n       cacheLock.readLock().lock();\n       String tblKey = CacheUtils.buildTableKey(catName, dbName, tblName);\n       TableWrapper tblWrapper = tableCache.getIfPresent(tblKey);\n-      if (tblWrapper != null) {\n-        tblWrapper.cachePrimaryKeys(keys, false);\n+      if ((tblWrapper != null) && tblWrapper.isConstraintsValid()) {\n+        // Because lake of snapshot freshness validation.\n+        // For now disabling cached constraint snapshot addition in parts by invalidating constraint snapshot.\n+        tblWrapper.inValidateConstraints();", "originalCommit": "a738dab45dc1fd598371436ef3741e8928927662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODU3Mjg3MA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r578572870", "bodyText": "Resolved", "author": "ashish-kumar-sharma", "createdAt": "2021-02-18T16:41:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODI2MjM4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODMxODA4Ng==", "url": "https://github.com/apache/hive/pull/1610#discussion_r578318086", "bodyText": "We have separate events for add individual constraints. I think, we need not keep it as part of create table event.\nIt adds additional overhead when transmit events for incremental replication. Also, takes additional storage in HMS.", "author": "sankarh", "createdAt": "2021-02-18T10:52:11Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/events/CreateTableEvent.java", "diffHunk": "@@ -29,11 +30,14 @@\n \n   private final Table table;\n   private final boolean isReplicated;\n+  private final SQLAllTableConstraints constraints;\n \n-  public CreateTableEvent(Table table, boolean status, IHMSHandler handler, boolean isReplicated) {\n+  public CreateTableEvent(Table table, boolean status, IHMSHandler handler, boolean isReplicated,\n+      SQLAllTableConstraints constraints) {", "originalCommit": "a738dab45dc1fd598371436ef3741e8928927662", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODU2Nzc0OA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r578567748", "bodyText": "Removed", "author": "ashish-kumar-sharma", "createdAt": "2021-02-18T16:35:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODMxODA4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM1ODQyNg==", "url": "https://github.com/apache/hive/pull/1610#discussion_r579358426", "bodyText": "It is not used anywhere other than below method. We can remove it and move these validations there.", "author": "sankarh", "createdAt": "2021-02-19T17:38:01Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CacheUtils.java", "diffHunk": "@@ -144,4 +147,15 @@ public static boolean matches(String name, String pattern) {\n     }\n     return false;\n   }\n+\n+  public static boolean validateShouldCacheTableCanUseEventIsActiveTransaction(String catName, String dbName,", "originalCommit": "b66d8ecc2a2064c336d830e4c72a3c605ebe8008", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTY0ODE4OQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r579648189", "bodyText": "removed", "author": "ashish-kumar-sharma", "createdAt": "2021-02-20T12:06:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM1ODQyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM2MzM2NA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r579363364", "bodyText": "The method name is too long and not readable. Shall make it shouldGetConstraintFromRawStore().", "author": "sankarh", "createdAt": "2021-02-19T17:46:25Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CacheUtils.java", "diffHunk": "@@ -144,4 +147,15 @@ public static boolean matches(String name, String pattern) {\n     }\n     return false;\n   }\n+\n+  public static boolean validateShouldCacheTableCanUseEventIsActiveTransaction(String catName, String dbName,\n+      String tblName, boolean canUseEvents, RawStore rawStore) {\n+    return !shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction());\n+  }\n+\n+  public static boolean validateShouldCacheTableCanUseEventIsActiveTransactionIsConstraintsValid(String catName,", "originalCommit": "b66d8ecc2a2064c336d830e4c72a3c605ebe8008", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTY0ODIwMA==", "url": "https://github.com/apache/hive/pull/1610#discussion_r579648200", "bodyText": "done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-20T12:06:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM2MzM2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM2NDYxNQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r579364615", "bodyText": "Shall move this method as private method inside CachedStore to avoid passing too many arguments.", "author": "sankarh", "createdAt": "2021-02-19T17:48:23Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CacheUtils.java", "diffHunk": "@@ -144,4 +147,15 @@ public static boolean matches(String name, String pattern) {\n     }\n     return false;\n   }\n+\n+  public static boolean validateShouldCacheTableCanUseEventIsActiveTransaction(String catName, String dbName,\n+      String tblName, boolean canUseEvents, RawStore rawStore) {\n+    return !shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction());\n+  }\n+\n+  public static boolean validateShouldCacheTableCanUseEventIsActiveTransactionIsConstraintsValid(String catName,", "originalCommit": "b66d8ecc2a2064c336d830e4c72a3c605ebe8008", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTY0ODIzOQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r579648239", "bodyText": "done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-20T12:07:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM2NDYxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM2NDk4Ng==", "url": "https://github.com/apache/hive/pull/1610#discussion_r579364986", "bodyText": "nit: Add space after each parameter.", "author": "sankarh", "createdAt": "2021-02-19T17:49:03Z", "path": "standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/cache/CachedStore.java", "diffHunk": "@@ -2554,8 +2554,7 @@ long getPartsFound() {\n     catName = StringUtils.normalizeIdentifier(catName);\n     dbName = StringUtils.normalizeIdentifier(dbName);\n     tblName = StringUtils.normalizeIdentifier(tblName);\n-    if (!shouldCacheTable(catName, dbName, tblName) || (canUseEvents && rawStore.isActiveTransaction()) || !sharedCache\n-        .isTableConstraintValid(catName, dbName, tblName)) {\n+    if (validateShouldCacheTableCanUseEventIsActiveTransactionIsConstraintsValid(catName,dbName,tblName,canUseEvents,rawStore,sharedCache)) {", "originalCommit": "b66d8ecc2a2064c336d830e4c72a3c605ebe8008", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTY0ODI2MQ==", "url": "https://github.com/apache/hive/pull/1610#discussion_r579648261", "bodyText": "done", "author": "ashish-kumar-sharma", "createdAt": "2021-02-20T12:07:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM2NDk4Ng=="}], "type": "inlineReview"}, {"oid": "bed562ca6a15bc15d614006c6fbde48904e542ff", "url": "https://github.com/apache/hive/commit/bed562ca6a15bc15d614006c6fbde48904e542ff", "message": "HIVE-24259: optimise get all table constraint from cache store", "committedDate": "2021-02-21T16:51:01Z", "type": "commit"}, {"oid": "bed562ca6a15bc15d614006c6fbde48904e542ff", "url": "https://github.com/apache/hive/commit/bed562ca6a15bc15d614006c6fbde48904e542ff", "message": "HIVE-24259: optimise get all table constraint from cache store", "committedDate": "2021-02-21T16:51:01Z", "type": "forcePushed"}]}