{"pr_number": 1553, "pr_title": "HIVE-24231: Enhance shared work optimizer to merge scans with filters on both sides", "pr_createdAt": "2020-10-05T16:48:47Z", "pr_url": "https://github.com/apache/hive/pull/1553", "timeline": [{"oid": "af0863b1318e6e38866ec420e4116eb6bdd4b9ec", "url": "https://github.com/apache/hive/commit/af0863b1318e6e38866ec420e4116eb6bdd4b9ec", "message": "existing work", "committedDate": "2020-10-05T14:36:08Z", "type": "commit"}, {"oid": "92ce37b832749aa6c813dafad9774da89a4ecdac", "url": "https://github.com/apache/hive/commit/92ce37b832749aa6c813dafad9774da89a4ecdac", "message": "add semi;", "committedDate": "2020-10-05T14:36:46Z", "type": "commit"}, {"oid": "3d5607da61ddf1943e4b0a9a031e467a6ce430c4", "url": "https://github.com/apache/hive/commit/3d5607da61ddf1943e4b0a9a031e467a6ce430c4", "message": "smi", "committedDate": "2020-10-05T14:40:14Z", "type": "commit"}, {"oid": "59c3d1f1641964969e3d18b6071264b038298931", "url": "https://github.com/apache/hive/commit/59c3d1f1641964969e3d18b6071264b038298931", "message": "x", "committedDate": "2020-10-05T16:05:44Z", "type": "commit"}, {"oid": "758c900cf823d9106ec6248d0aa587fa0fac3f49", "url": "https://github.com/apache/hive/commit/758c900cf823d9106ec6248d0aa587fa0fac3f49", "message": "remove exception", "committedDate": "2020-10-05T16:42:29Z", "type": "commit"}, {"oid": "1ee6e173f55c851517290960ff185c5375952b25", "url": "https://github.com/apache/hive/commit/1ee6e173f55c851517290960ff185c5375952b25", "message": "update tpcds", "committedDate": "2020-10-05T16:45:17Z", "type": "commit"}, {"oid": "d67efb6868282cbbb4c8e397b996ab2e35c390e1", "url": "https://github.com/apache/hive/commit/d67efb6868282cbbb4c8e397b996ab2e35c390e1", "message": "remove typo", "committedDate": "2020-10-05T16:49:56Z", "type": "commit"}, {"oid": "38470efc8211bc572ea2e73f23270528d2b50205", "url": "https://github.com/apache/hive/commit/38470efc8211bc572ea2e73f23270528d2b50205", "message": "update", "committedDate": "2020-10-06T07:03:57Z", "type": "commit"}, {"oid": "4bb84bf202b9918d40d4dd1abd901b8cb1c7b5c1", "url": "https://github.com/apache/hive/commit/4bb84bf202b9918d40d4dd1abd901b8cb1c7b5c1", "message": "disable dppu", "committedDate": "2020-10-06T07:10:04Z", "type": "commit"}, {"oid": "afd8a66a92cbd18ef99992112ac031d619f6485b", "url": "https://github.com/apache/hive/commit/afd8a66a92cbd18ef99992112ac031d619f6485b", "message": "add comment", "committedDate": "2020-10-06T07:20:04Z", "type": "commit"}, {"oid": "6c54baaabaefae4192b062caeb008540c9e5e37d", "url": "https://github.com/apache/hive/commit/6c54baaabaefae4192b062caeb008540c9e5e37d", "message": "add comment+fix", "committedDate": "2020-10-06T07:43:25Z", "type": "commit"}, {"oid": "e889d4b8db5ab1941025f43620f535cd164ae6c9", "url": "https://github.com/apache/hive/commit/e889d4b8db5ab1941025f43620f535cd164ae6c9", "message": "update mergeablecheck", "committedDate": "2020-10-06T08:00:23Z", "type": "commit"}, {"oid": "4a87c2ff86976e9f024b902b4f7d5a8054e3c576", "url": "https://github.com/apache/hive/commit/4a87c2ff86976e9f024b902b4f7d5a8054e3c576", "message": "q.out updates", "committedDate": "2020-10-06T08:28:24Z", "type": "commit"}, {"oid": "7d1584d89f5e606941b781bcdffe54873995003c", "url": "https://github.com/apache/hive/commit/7d1584d89f5e606941b781bcdffe54873995003c", "message": "update", "committedDate": "2020-10-06T08:38:49Z", "type": "commit"}, {"oid": "b43cb827ba2a0b2973e27e87422e62eb8678c724", "url": "https://github.com/apache/hive/commit/b43cb827ba2a0b2973e27e87422e62eb8678c724", "message": "en-x", "committedDate": "2020-10-06T12:55:00Z", "type": "commit"}, {"oid": "261fdcc93a6b6e15cdf96daaf8726d0636f7b725", "url": "https://github.com/apache/hive/commit/261fdcc93a6b6e15cdf96daaf8726d0636f7b725", "message": "Revert \"en-x\"\n\nThis reverts commit b43cb827ba2a0b2973e27e87422e62eb8678c724.", "committedDate": "2020-10-06T13:15:56Z", "type": "commit"}, {"oid": "c35896fb5ebaefcb742d257462f0685bab44cbc9", "url": "https://github.com/apache/hive/commit/c35896fb5ebaefcb742d257462f0685bab44cbc9", "message": "qqqqqqqqqqqqqqqqRevert \"Revert \"en-x\"\"\n\nThis reverts commit 261fdcc93a6b6e15cdf96daaf8726d0636f7b725.", "committedDate": "2020-10-06T13:21:42Z", "type": "commit"}, {"oid": "34c4423bdd30a1220f5c0bf9def94eefc70b847c", "url": "https://github.com/apache/hive/commit/34c4423bdd30a1220f5c0bf9def94eefc70b847c", "message": "accept q.out; small updates", "committedDate": "2020-10-06T15:48:04Z", "type": "commit"}, {"oid": "0320b9a2da55856ad9071d28725705798586cc0f", "url": "https://github.com/apache/hive/commit/0320b9a2da55856ad9071d28725705798586cc0f", "message": "accept dyn-op", "committedDate": "2020-10-07T08:06:56Z", "type": "commit"}, {"oid": "8c41061f78c969a9d33f058e56d7269f64f45d5a", "url": "https://github.com/apache/hive/commit/8c41061f78c969a9d33f058e56d7269f64f45d5a", "message": "update messages", "committedDate": "2020-10-07T08:25:55Z", "type": "commit"}, {"oid": "8d33c6ebc65ad04e7d4316a4d3c000007de8eef4", "url": "https://github.com/apache/hive/commit/8d33c6ebc65ad04e7d4316a4d3c000007de8eef4", "message": "updates", "committedDate": "2020-10-07T08:37:55Z", "type": "commit"}, {"oid": "e5b14a1c445d4618f3a3415b9c145eb561e6144d", "url": "https://github.com/apache/hive/commit/e5b14a1c445d4618f3a3415b9c145eb561e6144d", "message": "downstreammerge", "committedDate": "2020-10-07T09:06:23Z", "type": "commit"}, {"oid": "dda3523ff6342bc8452afd9bf002774edd25f805", "url": "https://github.com/apache/hive/commit/dda3523ff6342bc8452afd9bf002774edd25f805", "message": "fixes to downstream merge", "committedDate": "2020-10-07T11:18:57Z", "type": "commit"}, {"oid": "6f4faeaa9c2fa9604116bfaf6ac83d702ff10dbd", "url": "https://github.com/apache/hive/commit/6f4faeaa9c2fa9604116bfaf6ac83d702ff10dbd", "message": "remove fixme", "committedDate": "2020-10-07T11:38:31Z", "type": "commit"}, {"oid": "9b18ff94f42916b87c6441ebbcb98a5b9baa713e", "url": "https://github.com/apache/hive/commit/9b18ff94f42916b87c6441ebbcb98a5b9baa713e", "message": "fix npe", "committedDate": "2020-10-07T12:55:06Z", "type": "commit"}, {"oid": "ad629eb1e8ee19f949f66d577b3999895521abeb", "url": "https://github.com/apache/hive/commit/ad629eb1e8ee19f949f66d577b3999895521abeb", "message": "remove downstream-merge", "committedDate": "2020-10-07T12:56:35Z", "type": "commit"}, {"oid": "d1a62b4bc4c12ddb79332d669eae885457dc6792", "url": "https://github.com/apache/hive/commit/d1a62b4bc4c12ddb79332d669eae885457dc6792", "message": "accepted q.out changes", "committedDate": "2020-10-07T13:25:41Z", "type": "commit"}, {"oid": "610b7892c03fdd24a9e4c16f3998e6a1b7d4ed8b", "url": "https://github.com/apache/hive/commit/610b7892c03fdd24a9e4c16f3998e6a1b7d4ed8b", "message": "fix bug", "committedDate": "2020-10-07T14:29:18Z", "type": "commit"}, {"oid": "94608ec4b45105b752c0c9c9ed8766489060a60d", "url": "https://github.com/apache/hive/commit/94608ec4b45105b752c0c9c9ed8766489060a60d", "message": "back to 0 diff", "committedDate": "2020-10-07T15:04:06Z", "type": "commit"}, {"oid": "d4f41a311a592f0398413f9b29bfc6458022f88b", "url": "https://github.com/apache/hive/commit/d4f41a311a592f0398413f9b29bfc6458022f88b", "message": "fix", "committedDate": "2020-10-07T15:04:16Z", "type": "commit"}, {"oid": "06cfe04f9fcc2f3412c68fe7e062b930898b4bfc", "url": "https://github.com/apache/hive/commit/06cfe04f9fcc2f3412c68fe7e062b930898b4bfc", "message": "accept q.outs", "committedDate": "2020-10-07T15:15:49Z", "type": "commit"}, {"oid": "8d7b4f50611e6743a64e4b9d369f3f92e608b84b", "url": "https://github.com/apache/hive/commit/8d7b4f50611e6743a64e4b9d369f3f92e608b84b", "message": "accept syubquery_in", "committedDate": "2020-10-07T15:16:08Z", "type": "commit"}, {"oid": "15e5eff1e8bd9d97d16ce6e2a98b0c611611eb7b", "url": "https://github.com/apache/hive/commit/15e5eff1e8bd9d97d16ce6e2a98b0c611611eb7b", "message": "Revert \"remove downstream-merge\"\n\nThis reverts commit ad629eb1e8ee19f949f66d577b3999895521abeb.", "committedDate": "2020-10-07T15:16:22Z", "type": "commit"}, {"oid": "a97ac5117b5795c1a00805b8de81b0db76b9f887", "url": "https://github.com/apache/hive/commit/a97ac5117b5795c1a00805b8de81b0db76b9f887", "message": "Revert \"Revert \"remove downstream-merge\"\"\n\nThis reverts commit 15e5eff1e8bd9d97d16ce6e2a98b0c611611eb7b.", "committedDate": "2020-10-07T19:53:04Z", "type": "commit"}, {"oid": "e1021490b12c4289ee03b61ff85680d22d7d9843", "url": "https://github.com/apache/hive/commit/e1021490b12c4289ee03b61ff85680d22d7d9843", "message": "q.out updates", "committedDate": "2020-10-07T20:16:12Z", "type": "commit"}, {"oid": "aaccbdc062291001850b5d824565930b498d67c3", "url": "https://github.com/apache/hive/commit/aaccbdc062291001850b5d824565930b498d67c3", "message": "fix union", "committedDate": "2020-10-07T20:55:04Z", "type": "commit"}, {"oid": "9838961e57ebe20765ad7a046fc4283ec7b7f1f4", "url": "https://github.com/apache/hive/commit/9838961e57ebe20765ad7a046fc4283ec7b7f1f4", "message": "x", "committedDate": "2020-10-07T21:03:29Z", "type": "commit"}, {"oid": "90607e86627c57fe41e0db0f9f9d5f7764d87c71", "url": "https://github.com/apache/hive/commit/90607e86627c57fe41e0db0f9f9d5f7764d87c71", "message": "q5 back", "committedDate": "2020-10-07T21:08:36Z", "type": "commit"}, {"oid": "5656c7dc20fa1f904374b44b30270f7987f5b1de", "url": "https://github.com/apache/hive/commit/5656c7dc20fa1f904374b44b30270f7987f5b1de", "message": "changes relating to removal of downstream-merge", "committedDate": "2020-10-08T07:34:37Z", "type": "commit"}, {"oid": "199fee4b3bc338e0d5c153a9f8063c47f9bd9474", "url": "https://github.com/apache/hive/commit/199fee4b3bc338e0d5c153a9f8063c47f9bd9474", "message": "fix recompilation in SWO", "committedDate": "2020-10-08T07:37:54Z", "type": "commit"}, {"oid": "831c708df50f3cf433b35fe2c19d0e41f330d197", "url": "https://github.com/apache/hive/commit/831c708df50f3cf433b35fe2c19d0e41f330d197", "message": "Merge remote-tracking branch 'apache/master' into HIVE-swo-dppunion", "committedDate": "2020-10-08T08:16:42Z", "type": "commit"}, {"oid": "18678dc0b15bd11592eccf5929f8d0dabf25160d", "url": "https://github.com/apache/hive/commit/18678dc0b15bd11592eccf5929f8d0dabf25160d", "message": "remove logger changes", "committedDate": "2020-10-08T08:17:48Z", "type": "commit"}, {"oid": "f672130cc66044edbcb5718bb5ec7fdfb4368329", "url": "https://github.com/apache/hive/commit/f672130cc66044edbcb5718bb5ec7fdfb4368329", "message": "remove ws change", "committedDate": "2020-10-08T08:18:23Z", "type": "commit"}, {"oid": "b0d9aef86a0aaca6acc1e3d0f68a126b0eb8c6a7", "url": "https://github.com/apache/hive/commit/b0d9aef86a0aaca6acc1e3d0f68a126b0eb8c6a7", "message": "remove non-finished test", "committedDate": "2020-10-08T08:24:30Z", "type": "commit"}, {"oid": "e9bb99199899fc87048e680a04c086169782b2eb", "url": "https://github.com/apache/hive/commit/e9bb99199899fc87048e680a04c086169782b2eb", "message": "cleanup", "committedDate": "2020-10-08T09:42:03Z", "type": "commit"}, {"oid": "92f2951bf50a65abe655e952c22520abbd14caa4", "url": "https://github.com/apache/hive/commit/92f2951bf50a65abe655e952c22520abbd14caa4", "message": "archive testresult-xmls", "committedDate": "2020-10-08T20:18:52Z", "type": "commit"}, {"oid": "c210b8e48e5e3e593315764c7a946b22502e1ddc", "url": "https://github.com/apache/hive/commit/c210b8e48e5e3e593315764c7a946b22502e1ddc", "message": "archive results for each split", "committedDate": "2020-10-09T07:27:12Z", "type": "commit"}, {"oid": "6abc1ac36fcdb9dcaab91539fb55ffa8bccb4444", "url": "https://github.com/apache/hive/commit/6abc1ac36fcdb9dcaab91539fb55ffa8bccb4444", "message": "create test-results.tgz archive", "committedDate": "2020-10-09T08:14:23Z", "type": "commit"}, {"oid": "b4b9ce11e6b591ff702c43b847a2780da96afe9c", "url": "https://github.com/apache/hive/commit/b4b9ce11e6b591ff702c43b847a2780da96afe9c", "message": "fix typo", "committedDate": "2020-10-09T12:18:21Z", "type": "commit"}, {"oid": "31ddb97bf412a2679489a5a0d45d335d2708005c", "url": "https://github.com/apache/hive/commit/31ddb97bf412a2679489a5a0d45d335d2708005c", "message": "use surefire M5", "committedDate": "2020-10-09T12:34:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MTEzNg==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502941136", "bodyText": "Can we add a comment about each of these modes?", "author": "jcamachor", "createdAt": "2020-10-11T17:09:00Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -284,6 +294,41 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     return pctx;\n   }\n \n+  public enum Mode {\n+    RemoveSemijoin, SubtreeMerge, DPPUnion,", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MTU3MA==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502941570", "bodyText": "Does this need to be swapped with the one below? It seems that if HIVE_SHARED_WORK_MERGE_TS_SCHEMA is true, we should use the SchemaAwareSharedWorkOptimizer (or maybe the name is a bit misleading)?", "author": "jcamachor", "createdAt": "2020-10-11T17:12:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -159,9 +158,15 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     // Gather information about the DPP table scans and store it in the cache\n     gatherDPPTableScanOps(pctx, optimizerCache);\n \n+    BaseSharedWorkOptimizer swo;\n+    if (pctx.getConf().getBoolVar(ConfVars.HIVE_SHARED_WORK_MERGE_TS_SCHEMA)) {\n+      swo = new BaseSharedWorkOptimizer();", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzE2OTUzNw==", "url": "https://github.com/apache/hive/pull/1553#discussion_r503169537", "bodyText": "SchemaAwareSharedWorkOptimizer is the more strict version\n\n  \n    \n      hive/ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java\n    \n    \n         Line 591\n      in\n      78d42f0\n    \n    \n    \n    \n\n        \n          \n              * More strict implementation of shared work optimizer. \n        \n    \n  \n\n\nI just wanted to enable schema merge for all the optimizations - so I've moved it here", "author": "kgyrtkirk", "createdAt": "2020-10-12T09:39:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MTU3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MTk4MA==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502941980", "bodyText": "Comment about this class. It seems it holds a TS, the filter expression that does not include the SJ, and the SJ filters?", "author": "jcamachor", "createdAt": "2020-10-11T17:16:26Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -284,6 +294,41 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     return pctx;\n   }\n \n+  public enum Mode {\n+    RemoveSemijoin, SubtreeMerge, DPPUnion,\n+  }\n+\n+  static class SharedWorkModel {", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MjA2Nw==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502942067", "bodyText": "typo -> areMergeableDppUninon", "author": "jcamachor", "createdAt": "2020-10-11T17:17:15Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -338,8 +385,29 @@ public boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCach\n               // about the part of the tree that can be merged. We need to regenerate the\n               // cache because semijoin operators have been removed\n               sr = extractSharedOptimizationInfoForRoot(\n-                  pctx, optimizerCache, retainableTsOp, discardableTsOp);\n-            } else {\n+                  pctx, optimizerCache, retainableTsOp, discardableTsOp, true);\n+            } else if (mode == Mode.DPPUnion) {\n+              boolean mergeable = areMergeable(pctx, retainableTsOp, discardableTsOp);\n+              if (!mergeable) {\n+                LOG.debug(\"{} and {} cannot be merged\", retainableTsOp, discardableTsOp);\n+                continue;\n+              }\n+              boolean validMerge =\n+                  areMergeableDppUninon(pctx, optimizerCache, retainableTsOp, discardableTsOp);", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MjQxMQ==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502942411", "bodyText": "Is this a TODO for this patch or follow-up work?", "author": "jcamachor", "createdAt": "2020-10-11T17:20:49Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -386,125 +456,81 @@ public boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCach\n               LOG.debug(\"Merging subtree starting at {} into subtree starting at {}\",\n                   discardableTsOp, retainableTsOp);\n             } else {\n-              ExprNodeDesc newRetainableTsFilterExpr = null;\n-              List<ExprNodeDesc> semijoinExprNodes = new ArrayList<>();\n-              if (retainableTsOp.getConf().getFilterExpr() != null) {\n-                // Gather SJ expressions and normal expressions\n-                List<ExprNodeDesc> allExprNodesExceptSemijoin = new ArrayList<>();\n-                splitExpressions(retainableTsOp.getConf().getFilterExpr(),\n-                    allExprNodesExceptSemijoin, semijoinExprNodes);\n-                // Create new expressions\n-                if (allExprNodesExceptSemijoin.size() > 1) {\n-                  newRetainableTsFilterExpr = ExprNodeGenericFuncDesc.newInstance(\n-                      new GenericUDFOPAnd(), allExprNodesExceptSemijoin);\n-                } else if (allExprNodesExceptSemijoin.size() > 0 &&\n-                    allExprNodesExceptSemijoin.get(0) instanceof ExprNodeGenericFuncDesc) {\n-                  newRetainableTsFilterExpr = allExprNodesExceptSemijoin.get(0);\n-                }\n-                // Push filter on top of children for retainable\n-                pushFilterToTopOfTableScan(optimizerCache, retainableTsOp);\n+\n+              if (sr.discardableOps.size() > 1) {\n+                throw new RuntimeException(\"we can't discard more in this path\");\n               }\n-              ExprNodeDesc newDiscardableTsFilterExpr = null;\n-              if (discardableTsOp.getConf().getFilterExpr() != null) {\n-                // If there is a single discardable operator, it is a TableScanOperator\n-                // and it means that we will merge filter expressions for it. Thus, we\n-                // might need to remove DPP predicates before doing that\n-                List<ExprNodeDesc> allExprNodesExceptSemijoin = new ArrayList<>();\n-                splitExpressions(discardableTsOp.getConf().getFilterExpr(),\n-                    allExprNodesExceptSemijoin, new ArrayList<>());\n-                // Create new expressions\n-                if (allExprNodesExceptSemijoin.size() > 1) {\n-                  newDiscardableTsFilterExpr = ExprNodeGenericFuncDesc.newInstance(\n-                      new GenericUDFOPAnd(), allExprNodesExceptSemijoin);\n-                } else if (allExprNodesExceptSemijoin.size() > 0 &&\n-                    allExprNodesExceptSemijoin.get(0) instanceof ExprNodeGenericFuncDesc) {\n-                  newDiscardableTsFilterExpr = allExprNodesExceptSemijoin.get(0);\n-                }\n-                // Remove and add semijoin filter from expressions\n-                replaceSemijoinExpressions(discardableTsOp, semijoinExprNodes);\n-                // Push filter on top of children for discardable\n-                pushFilterToTopOfTableScan(optimizerCache, discardableTsOp);\n+\n+              SharedWorkModel modelR = new SharedWorkModel(retainableTsOp);\n+              SharedWorkModel modelD = new SharedWorkModel(discardableTsOp);\n+\n+              // Push filter on top of children for retainable\n+              pushFilterToTopOfTableScan(optimizerCache, retainableTsOp);\n+\n+              if (mode == Mode.RemoveSemijoin || mode == Mode.SubtreeMerge) {\n+                // FIXME: I think idea here is to clear the discardable's semijoin filter", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzgwNjc5OA==", "url": "https://github.com/apache/hive/pull/1553#discussion_r503806798", "bodyText": "I made this note - because it was not obvious to me what's happening here..I've rephrased it to be easier to understand", "author": "kgyrtkirk", "createdAt": "2020-10-13T09:32:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MjQxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MjU5OQ==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502942599", "bodyText": "Is this a TODO for this patch or follow-up work? Also there is a typo (assymetric)", "author": "jcamachor", "createdAt": "2020-10-11T17:22:20Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -326,6 +372,7 @@ public boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCach\n                 LOG.debug(\"{} and {} cannot be merged\", retainableTsOp, discardableTsOp);\n                 continue;\n               }\n+              // FIXME: I think this optimization is assymetric; but the check is symmetric", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzgwOTAzOQ==", "url": "https://github.com/apache/hive/pull/1553#discussion_r503809039", "bodyText": "this could be done as a cleanup - however I've already concluded that because of the table ordering the problematic case will actually never happen; so we are safe\nI've removed the FIXME", "author": "kgyrtkirk", "createdAt": "2020-10-13T09:35:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MjU5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MzM5NA==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502943394", "bodyText": "Can you leave a comment explaining how we could hit this error? What should have happened? Somehow we have something in retainable/discardable that should be equivalent but it is not?", "author": "jcamachor", "createdAt": "2020-10-11T17:28:58Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -386,125 +456,81 @@ public boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCach\n               LOG.debug(\"Merging subtree starting at {} into subtree starting at {}\",\n                   discardableTsOp, retainableTsOp);\n             } else {\n-              ExprNodeDesc newRetainableTsFilterExpr = null;\n-              List<ExprNodeDesc> semijoinExprNodes = new ArrayList<>();\n-              if (retainableTsOp.getConf().getFilterExpr() != null) {\n-                // Gather SJ expressions and normal expressions\n-                List<ExprNodeDesc> allExprNodesExceptSemijoin = new ArrayList<>();\n-                splitExpressions(retainableTsOp.getConf().getFilterExpr(),\n-                    allExprNodesExceptSemijoin, semijoinExprNodes);\n-                // Create new expressions\n-                if (allExprNodesExceptSemijoin.size() > 1) {\n-                  newRetainableTsFilterExpr = ExprNodeGenericFuncDesc.newInstance(\n-                      new GenericUDFOPAnd(), allExprNodesExceptSemijoin);\n-                } else if (allExprNodesExceptSemijoin.size() > 0 &&\n-                    allExprNodesExceptSemijoin.get(0) instanceof ExprNodeGenericFuncDesc) {\n-                  newRetainableTsFilterExpr = allExprNodesExceptSemijoin.get(0);\n-                }\n-                // Push filter on top of children for retainable\n-                pushFilterToTopOfTableScan(optimizerCache, retainableTsOp);\n+\n+              if (sr.discardableOps.size() > 1) {\n+                throw new RuntimeException(\"we can't discard more in this path\");", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzgxMjEzMg==", "url": "https://github.com/apache/hive/pull/1553#discussion_r503812132", "bodyText": "there could be a few things which could go south here - one is that pushing filters out from the discardable ts will most likely not work as desired.\nI feel tempted to remove this multi operator matching stuff in HIVE-24241 - because that approach is much simpler; more separated from merging of the operators.", "author": "kgyrtkirk", "createdAt": "2020-10-13T09:40:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MzM5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MzQ5Nw==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502943497", "bodyText": "it seems you can use conjunction method here too.", "author": "jcamachor", "createdAt": "2020-10-11T17:29:50Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -284,6 +294,41 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     return pctx;\n   }\n \n+  public enum Mode {\n+    RemoveSemijoin, SubtreeMerge, DPPUnion,\n+  }\n+\n+  static class SharedWorkModel {\n+\n+    private TableScanOperator ts;\n+    private ExprNodeDesc normalFilterExpr;\n+    private List<ExprNodeDesc> semijoinExprNodes = new ArrayList<>();\n+\n+    public SharedWorkModel(TableScanOperator ts) throws UDFArgumentException {\n+      this.ts = ts;\n+      TableScanOperator retainableTsOp = ts;\n+      if (retainableTsOp.getConf().getFilterExpr() != null) {\n+        // Gather SJ expressions and normal expressions\n+        List<ExprNodeDesc> allExprNodesExceptSemijoin = new ArrayList<>();\n+        splitExpressions(retainableTsOp.getConf().getFilterExpr(),\n+            allExprNodesExceptSemijoin, semijoinExprNodes);\n+        // Create new expressions\n+        if (allExprNodesExceptSemijoin.size() > 1) {\n+          normalFilterExpr = ExprNodeGenericFuncDesc.newInstance(", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MzYxMQ==", "url": "https://github.com/apache/hive/pull/1553#discussion_r502943611", "bodyText": "Probably this comment should go within the if clause now.", "author": "jcamachor", "createdAt": "2020-10-11T17:30:53Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -386,125 +456,81 @@ public boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCach\n               LOG.debug(\"Merging subtree starting at {} into subtree starting at {}\",\n                   discardableTsOp, retainableTsOp);\n             } else {\n-              ExprNodeDesc newRetainableTsFilterExpr = null;\n-              List<ExprNodeDesc> semijoinExprNodes = new ArrayList<>();\n-              if (retainableTsOp.getConf().getFilterExpr() != null) {\n-                // Gather SJ expressions and normal expressions\n-                List<ExprNodeDesc> allExprNodesExceptSemijoin = new ArrayList<>();\n-                splitExpressions(retainableTsOp.getConf().getFilterExpr(),\n-                    allExprNodesExceptSemijoin, semijoinExprNodes);\n-                // Create new expressions\n-                if (allExprNodesExceptSemijoin.size() > 1) {\n-                  newRetainableTsFilterExpr = ExprNodeGenericFuncDesc.newInstance(\n-                      new GenericUDFOPAnd(), allExprNodesExceptSemijoin);\n-                } else if (allExprNodesExceptSemijoin.size() > 0 &&\n-                    allExprNodesExceptSemijoin.get(0) instanceof ExprNodeGenericFuncDesc) {\n-                  newRetainableTsFilterExpr = allExprNodesExceptSemijoin.get(0);\n-                }\n-                // Push filter on top of children for retainable\n-                pushFilterToTopOfTableScan(optimizerCache, retainableTsOp);\n+\n+              if (sr.discardableOps.size() > 1) {\n+                throw new RuntimeException(\"we can't discard more in this path\");\n               }\n-              ExprNodeDesc newDiscardableTsFilterExpr = null;\n-              if (discardableTsOp.getConf().getFilterExpr() != null) {\n-                // If there is a single discardable operator, it is a TableScanOperator\n-                // and it means that we will merge filter expressions for it. Thus, we\n-                // might need to remove DPP predicates before doing that\n-                List<ExprNodeDesc> allExprNodesExceptSemijoin = new ArrayList<>();\n-                splitExpressions(discardableTsOp.getConf().getFilterExpr(),\n-                    allExprNodesExceptSemijoin, new ArrayList<>());\n-                // Create new expressions\n-                if (allExprNodesExceptSemijoin.size() > 1) {\n-                  newDiscardableTsFilterExpr = ExprNodeGenericFuncDesc.newInstance(\n-                      new GenericUDFOPAnd(), allExprNodesExceptSemijoin);\n-                } else if (allExprNodesExceptSemijoin.size() > 0 &&\n-                    allExprNodesExceptSemijoin.get(0) instanceof ExprNodeGenericFuncDesc) {\n-                  newDiscardableTsFilterExpr = allExprNodesExceptSemijoin.get(0);\n-                }\n-                // Remove and add semijoin filter from expressions\n-                replaceSemijoinExpressions(discardableTsOp, semijoinExprNodes);\n-                // Push filter on top of children for discardable\n-                pushFilterToTopOfTableScan(optimizerCache, discardableTsOp);\n+\n+              SharedWorkModel modelR = new SharedWorkModel(retainableTsOp);\n+              SharedWorkModel modelD = new SharedWorkModel(discardableTsOp);\n+\n+              // Push filter on top of children for retainable\n+              pushFilterToTopOfTableScan(optimizerCache, retainableTsOp);\n+\n+              if (mode == Mode.RemoveSemijoin || mode == Mode.SubtreeMerge) {\n+                // FIXME: I think idea here is to clear the discardable's semijoin filter\n+                // - by using the retainable's (which should be empty in case of this mode)\n+                replaceSemijoinExpressions(discardableTsOp, modelR.getSemiJoinFilter());\n               }\n+              // Push filter on top of children for discardable\n+              pushFilterToTopOfTableScan(optimizerCache, discardableTsOp);\n+\n               // Obtain filter for shared TS operator\n-              ExprNodeGenericFuncDesc exprNode = null;\n-              if (newRetainableTsFilterExpr != null && newDiscardableTsFilterExpr != null) {\n-                // Combine\n-                exprNode = (ExprNodeGenericFuncDesc) newRetainableTsFilterExpr;\n-                if (!exprNode.isSame(newDiscardableTsFilterExpr)) {\n-                  // We merge filters from previous scan by ORing with filters from current scan\n-                  if (exprNode.getGenericUDF() instanceof GenericUDFOPOr) {\n-                    List<ExprNodeDesc> newChildren = new ArrayList<>(exprNode.getChildren().size() + 1);\n-                    for (ExprNodeDesc childExprNode : exprNode.getChildren()) {\n-                      if (childExprNode.isSame(newDiscardableTsFilterExpr)) {\n-                        // We do not need to do anything, it is in the OR expression\n-                        break;\n-                      }\n-                      newChildren.add(childExprNode);\n-                    }\n-                    if (exprNode.getChildren().size() == newChildren.size()) {\n-                      newChildren.add(newDiscardableTsFilterExpr);\n-                      exprNode = ExprNodeGenericFuncDesc.newInstance(\n-                          new GenericUDFOPOr(),\n-                          newChildren);\n-                    }\n-                  } else {\n-                    exprNode = ExprNodeGenericFuncDesc.newInstance(\n-                        new GenericUDFOPOr(),\n-                        Arrays.asList(exprNode, newDiscardableTsFilterExpr));\n-                  }\n-                }\n+              ExprNodeDesc exprNode = null;\n+              if (modelR.normalFilterExpr != null && modelD.normalFilterExpr != null) {\n+                exprNode = disjunction(modelR.normalFilterExpr, modelD.normalFilterExpr);\n               }\n-              // Create expression node that will be used for the retainable table scan\n-              if (!semijoinExprNodes.isEmpty()) {\n-                if (exprNode != null) {\n-                  semijoinExprNodes.add(0, exprNode);\n-                }\n-                if (semijoinExprNodes.size() > 1) {\n-                  exprNode = ExprNodeGenericFuncDesc.newInstance(\n-                      new GenericUDFOPAnd(), semijoinExprNodes);\n-                } else {\n-                  exprNode = (ExprNodeGenericFuncDesc) semijoinExprNodes.get(0);\n-                }\n+              List<ExprNodeDesc> semiJoinExpr = null;\n+              if (mode == Mode.DPPUnion) {\n+                assert modelR.semijoinExprNodes != null;\n+                assert modelD.semijoinExprNodes != null;\n+                ExprNodeDesc disjunction = disjunction(conjunction(modelR.semijoinExprNodes), conjunction(modelD.semijoinExprNodes));\n+                semiJoinExpr = disjunction == null ? null : Lists.newArrayList(disjunction);\n+              } else {\n+                semiJoinExpr = modelR.semijoinExprNodes;\n               }\n+\n+              // Create expression node that will be used for the retainable table scan\n+              exprNode = conjunction(semiJoinExpr, exprNode);\n               // Replace filter\n-              retainableTsOp.getConf().setFilterExpr(exprNode);\n+              retainableTsOp.getConf().setFilterExpr((ExprNodeGenericFuncDesc) exprNode);\n               // Replace table scan operator\n               List<Operator<? extends OperatorDesc>> allChildren =\n                   Lists.newArrayList(discardableTsOp.getChildOperators());\n               for (Operator<? extends OperatorDesc> op : allChildren) {\n-                discardableTsOp.getChildOperators().remove(op);\n                 op.replaceParent(discardableTsOp, retainableTsOp);\n                 retainableTsOp.getChildOperators().add(op);\n               }\n+              discardableTsOp.getChildOperators().clear();\n \n               LOG.debug(\"Merging {} into {}\", discardableTsOp, retainableTsOp);\n             }\n \n             // First we remove the input operators of the expression that", "originalCommit": "31ddb97bf412a2679489a5a0d45d335d2708005c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzgyMTE2OQ==", "url": "https://github.com/apache/hive/pull/1553#discussion_r503821169", "bodyText": "this small block can be done with a function(adoptChildren) from the next patch; I've not yet noticed that I can use it here as well - I've added the method and called it", "author": "kgyrtkirk", "createdAt": "2020-10-13T09:54:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk0MzYxMQ=="}], "type": "inlineReview"}, {"oid": "053281c5e09a49caed5f00f494a15a77e4934fa5", "url": "https://github.com/apache/hive/commit/053281c5e09a49caed5f00f494a15a77e4934fa5", "message": "Merge remote-tracking branch 'apache/master' into HIVE-swo-dppunion", "committedDate": "2020-10-12T09:48:52Z", "type": "commit"}, {"oid": "520598f64691f0193be270b81d74a90eb9b8bcd7", "url": "https://github.com/apache/hive/commit/520598f64691f0193be270b81d74a90eb9b8bcd7", "message": "upgrade to M5 in other parts", "committedDate": "2020-10-12T10:31:34Z", "type": "commit"}, {"oid": "35fccf29e537fbb2c31d493ec9d9cacb3927897e", "url": "https://github.com/apache/hive/commit/35fccf29e537fbb2c31d493ec9d9cacb3927897e", "message": "remove HIVE-24624 related stuff", "committedDate": "2020-10-12T12:34:35Z", "type": "commit"}, {"oid": "84685724bc2c874e1d53640e8d4dccdd2d2605f8", "url": "https://github.com/apache/hive/commit/84685724bc2c874e1d53640e8d4dccdd2d2605f8", "message": "remove feature disable from subq tests", "committedDate": "2020-10-12T12:34:51Z", "type": "commit"}, {"oid": "b336b842e36a363d96ed8ec33d09d122fbe3ce6b", "url": "https://github.com/apache/hive/commit/b336b842e36a363d96ed8ec33d09d122fbe3ce6b", "message": "remove set from explain", "committedDate": "2020-10-12T12:54:20Z", "type": "commit"}, {"oid": "9e07afdd178f5abf75a985609f05ca3dab50c53b", "url": "https://github.com/apache/hive/commit/9e07afdd178f5abf75a985609f05ca3dab50c53b", "message": "update qfiles; go back to simpler changes", "committedDate": "2020-10-12T13:45:31Z", "type": "commit"}, {"oid": "e775b74ce740ab162a7164b7bad6652fd3c25d34", "url": "https://github.com/apache/hive/commit/e775b74ce740ab162a7164b7bad6652fd3c25d34", "message": "tests back to master state", "committedDate": "2020-10-13T08:24:02Z", "type": "commit"}, {"oid": "a54fc6a506dbb6ef603cac61fe0a04c3835fc990", "url": "https://github.com/apache/hive/commit/a54fc6a506dbb6ef603cac61fe0a04c3835fc990", "message": "cleanup", "committedDate": "2020-10-13T08:34:47Z", "type": "commit"}, {"oid": "c3087ae830ab55683b3ea06d6b664c6c8f15b1dd", "url": "https://github.com/apache/hive/commit/c3087ae830ab55683b3ea06d6b664c6c8f15b1dd", "message": "removal of ()", "committedDate": "2020-10-13T08:43:42Z", "type": "commit"}, {"oid": "70e4ac2e0f910ce1fd33984e183cd68e696abf1a", "url": "https://github.com/apache/hive/commit/70e4ac2e0f910ce1fd33984e183cd68e696abf1a", "message": "removal of ()", "committedDate": "2020-10-13T08:44:10Z", "type": "commit"}, {"oid": "acec785a26c159a5534afbd3875c99bb51b5232c", "url": "https://github.com/apache/hive/commit/acec785a26c159a5534afbd3875c99bb51b5232c", "message": "cleanup; move functions; address review comments", "committedDate": "2020-10-13T09:48:58Z", "type": "commit"}, {"oid": "7fa1eef1491570d93fb231561ab245f4504053ef", "url": "https://github.com/apache/hive/commit/7fa1eef1491570d93fb231561ab245f4504053ef", "message": "use adoptchildren", "committedDate": "2020-10-13T09:55:15Z", "type": "commit"}, {"oid": "c1e35d3e5c0bccd20ce51b223ec6aca189378c64", "url": "https://github.com/apache/hive/commit/c1e35d3e5c0bccd20ce51b223ec6aca189378c64", "message": "add doc to mode", "committedDate": "2020-10-13T10:36:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODIyMDM0NQ==", "url": "https://github.com/apache/hive/pull/1553#discussion_r508220345", "bodyText": "typo. onlt", "author": "jcamachor", "createdAt": "2020-10-20T05:35:32Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -284,6 +304,54 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     return pctx;\n   }\n \n+  /** SharedWorkOptimization strategy modes */\n+  public enum Mode {\n+    /**\n+     * Merges two identical subtrees.\n+     */\n+    SubtreeMerge,\n+    /**\n+     * Merges a filtered scan into a non-filtered scan.\n+     *\n+     * In case we are already scanning the whole table - we should not scan it twice.\n+     */\n+    RemoveSemijoin,\n+    /**\n+     * Fuses two filtered table scans into a single one.\n+     *\n+     * Dynamic filter subtree is kept on both sides - but the table is onlt scanned once.", "originalCommit": "c1e35d3e5c0bccd20ce51b223ec6aca189378c64", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQzODc3Ng==", "url": "https://github.com/apache/hive/pull/1553#discussion_r508438776", "bodyText": "added fix to HIVE-24241", "author": "kgyrtkirk", "createdAt": "2020-10-20T11:56:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODIyMDM0NQ=="}], "type": "inlineReview"}]}