{"pr_number": 1031, "pr_title": "HIVE-23462 rewrite cume_dist", "pr_createdAt": "2020-05-21T19:34:12Z", "pr_url": "https://github.com/apache/hive/pull/1031", "timeline": [{"oid": "2f7d09708ac0ad3ce7cbd844cbf97d7d883b9d57", "url": "https://github.com/apache/hive/commit/2f7d09708ac0ad3ce7cbd844cbf97d7d883b9d57", "message": "ss", "committedDate": "2020-05-29T08:18:23Z", "type": "commit"}, {"oid": "4e09052f5edf472f9fa77a1f435a5c9b89188fb0", "url": "https://github.com/apache/hive/commit/4e09052f5edf472f9fa77a1f435a5c9b89188fb0", "message": "review comments", "committedDate": "2020-05-29T10:14:07Z", "type": "commit"}, {"oid": "f770fdcebec0bc389ce8f7a48c03e72350316d3f", "url": "https://github.com/apache/hive/commit/f770fdcebec0bc389ce8f7a48c03e72350316d3f", "message": "expose stuff during scheduled executions", "committedDate": "2020-05-29T12:14:09Z", "type": "commit"}, {"oid": "083899db2a8820c081b11d31e4fffa068bc637bd", "url": "https://github.com/apache/hive/commit/083899db2a8820c081b11d31e4fffa068bc637bd", "message": "Revert \"expose stuff during scheduled executions\"\n\nThis reverts commit f770fdcebec0bc389ce8f7a48c03e72350316d3f.", "committedDate": "2020-05-29T12:15:14Z", "type": "commit"}, {"oid": "4df5011cc9fe4de1d0406e096f3726fd269eebef", "url": "https://github.com/apache/hive/commit/4df5011cc9fe4de1d0406e096f3726fd269eebef", "message": "updates", "committedDate": "2020-05-30T13:47:07Z", "type": "commit"}, {"oid": "64c35da25b46bc0b8a96e3a223a9a2972c8cbc4d", "url": "https://github.com/apache/hive/commit/64c35da25b46bc0b8a96e3a223a9a2972c8cbc4d", "message": "put back approx", "committedDate": "2020-06-02T18:22:21Z", "type": "commit"}, {"oid": "6aba9f60200c1692dc8e09af4d382f39e0fe85cb", "url": "https://github.com/apache/hive/commit/6aba9f60200c1692dc8e09af4d382f39e0fe85cb", "message": "use <=>", "committedDate": "2020-06-02T18:38:10Z", "type": "commit"}, {"oid": "50592da072be729933db133b86773c49288e81da", "url": "https://github.com/apache/hive/commit/50592da072be729933db133b86773c49288e81da", "message": "postpone introduction of sqlkind.cume_dist", "committedDate": "2020-06-02T19:00:27Z", "type": "commit"}, {"oid": "474338c1e1f9737e923b70895ac4f6e206d98b25", "url": "https://github.com/apache/hive/commit/474338c1e1f9737e923b70895ac4f6e206d98b25", "message": "approx-en", "committedDate": "2020-06-02T19:04:09Z", "type": "commit"}, {"oid": "d7c933f2d76504d16dbee0a14efe9213498b1a6d", "url": "https://github.com/apache/hive/commit/d7c933f2d76504d16dbee0a14efe9213498b1a6d", "message": "Merge remote-tracking branch 'apache/master' into HIVE-23462-rewrite-ntile", "committedDate": "2020-06-03T10:05:14Z", "type": "commit"}, {"oid": "50b616456bafcfcc15b80adf0af2dfba94d92012", "url": "https://github.com/apache/hive/commit/50b616456bafcfcc15b80adf0af2dfba94d92012", "message": "compute_stats changes", "committedDate": "2020-06-03T11:12:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUxMTk5Ng==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434511996", "bodyText": "about enabling other sketches for count-distinct: I think they should just work - however they might need a little testing; probably more important would be to provide some way to change sketch construction parameters...actually for our rewrites the sketch type could be considered as part of the parameters\nopened: HIVE-23600", "author": "kgyrtkirk", "createdAt": "2020-06-03T11:57:28Z", "path": "common/src/java/org/apache/hadoop/hive/conf/HiveConf.java", "diffHunk": "@@ -2495,19 +2495,22 @@ private static void populateLlapDaemonVarsSet(Set<String> llapDaemonVarsSetLocal\n     HIVE_OPTIMIZE_BI_REWRITE_COUNTDISTINCT_ENABLED(\"hive.optimize.bi.rewrite.countdistinct.enabled\",\n         true,\n         \"Enables to rewrite COUNT(DISTINCT(X)) queries to be rewritten to use sketch functions.\"),\n-    HIVE_OPTIMIZE_BI_REWRITE_COUNT_DISTINCT_SKETCH(\n-        \"hive.optimize.bi.rewrite.countdistinct.sketch\", \"hll\",\n+    HIVE_OPTIMIZE_BI_REWRITE_COUNT_DISTINCT_SKETCH(\"hive.optimize.bi.rewrite.countdistinct.sketch\", \"hll\",\n         new StringSet(\"hll\"),", "originalCommit": "50b616456bafcfcc15b80adf0af2dfba94d92012", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUxMjc5Nw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434512797", "bodyText": "this method is needed to use the relbuilder to create aggregates;\nthe overriden method is protected...and there is no way to access this level of detail without exposing it", "author": "kgyrtkirk", "createdAt": "2020-06-03T11:59:04Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelBuilder.java", "diffHunk": "@@ -165,4 +166,10 @@ protected boolean shouldMergeProject() {\n     return false;\n   }\n \n+  /** Make the method visible */\n+  @Override\n+  public AggCall aggregateCall(SqlAggFunction aggFunction, boolean distinct, boolean approximate, boolean ignoreNulls,", "originalCommit": "50b616456bafcfcc15b80adf0af2dfba94d92012", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUxMzYwOQ==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434513609", "bodyText": "I think these apidoc could be moved to the rewrite-rules - but they also have there meaning here as well...maybe move them and add a more brief description here?", "author": "kgyrtkirk", "createdAt": "2020-06-03T12:00:27Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -68,25 +82,32 @@\n  *       \u21d2 SELECT ds_kll_quantile(ds_kll_sketch(CAST(id AS FLOAT)), 0.2) FROM sketch_input;\n  *    </pre>\n  *  </li>\n+ *  <li>{@code cume_dist() over (order by id)}", "originalCommit": "50b616456bafcfcc15b80adf0af2dfba94d92012", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUxNzQwOA==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434517408", "bodyText": "interestingly: CUME_DIST returns NULLs when the partitioning coulmn is null - but the sketch based estimation (and postgres doesn't)\nopened HIVE-23599\nsince this is not a simple '=' we could possibly loose some optimizations...", "author": "kgyrtkirk", "createdAt": "2020-06-03T12:07:49Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +388,210 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()), HiveRelFactories.HIVE_BUILDER, null);\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject == project) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected final RelNode processProject(Project project) {\n+        RelNode origInput = project.getInput();\n+        relBuilder.push(origInput);\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+          newProjects.add(expr.accept(shuttle));\n+        }\n+        if (relBuilder.peek() == origInput) {\n+          relBuilder.clear();\n+          return project;\n+        }\n+        relBuilder.project(newProjects);\n+        return relBuilder.build();\n+      }\n+\n+      private final RexNode processCall(RexNode expr) {\n+        if (expr instanceof RexOver) {\n+          RexOver over = (RexOver) expr;\n+          if (isApplicable(over)) {\n+            return rewrite(over);\n+          }\n+        }\n+        return expr;\n+      }\n+\n+      protected final SqlOperator getSqlOperator(String fnName) {\n+        UDFDescriptor fn = DataSketchesFunctions.INSTANCE.getSketchFunction(sketchClass, fnName);\n+        if (!fn.getCalciteFunction().isPresent()) {\n+          throw new RuntimeException(fn.toString() + \" doesn't have a Calcite function associated with it\");\n+        }\n+        return fn.getCalciteFunction().get();\n+      }\n+\n+      /**\n+       * Do the rewrite for the given expression.\n+       *\n+       * When this method is invoked the {@link #relBuilder} will only contain the current input.\n+       * Expectation is to leave the new input there after the method finishes.\n+       */\n+      abstract RexNode rewrite(RexOver expr);\n+\n+      abstract boolean isApplicable(RexOver expr);\n+\n+    }\n+  }\n+\n+  public static class CumeDistRewrite extends WindowingToProjectAggregateJoinProject {\n+\n+    public CumeDistRewrite(String sketchType) {\n+      super(sketchType);\n+    }\n+\n+    @Override\n+    protected VbuilderPAP buildProcessor(RelOptRuleCall call) {\n+      return new VB(sketchType, call.builder());\n+    }\n+\n+    private static class VB extends VbuilderPAP {\n+\n+      protected VB(String sketchClass, RelBuilder relBuilder) {\n+        super(sketchClass, relBuilder);\n+      }\n+\n+      @Override\n+      boolean isApplicable(RexOver over) {\n+        SqlAggFunction aggOp = over.getAggOperator();\n+        RexWindow window = over.getWindow();\n+        if (aggOp.getName().equalsIgnoreCase(\"cume_dist\") && window.orderKeys.size() == 1\n+            && window.getLowerBound().isUnbounded() && window.getUpperBound().isUnbounded()) {\n+          return true;\n+        }\n+        return false;\n+      }\n+\n+      @Override\n+      RexNode rewrite(RexOver over) {\n+        RexWindow w = over.getWindow();\n+        RexFieldCollation orderKey = w.orderKeys.get(0);\n+        // we don't really support nulls in aggregate/etc...they are actually ignored\n+        // so some hack will be needed for NULLs anyway..\n+        ImmutableList<RexNode> partitionKeys = w.partitionKeys;\n+\n+        relBuilder.push(relBuilder.peek());\n+        // the CDF function utilizes the '<' operator;\n+        // negating the input will mirror the values on the x axis\n+        // by using 1-CDF(-x) we could get a <= operator\n+        RexNode key = orderKey.getKey();\n+        key = rexBuilder.makeCall(SqlStdOperatorTable.UNARY_MINUS, key);\n+        key = rexBuilder.makeCast(getFloatType(), key);\n+\n+        AggCall aggCall = ((HiveRelBuilder) relBuilder).aggregateCall(\n+            (SqlAggFunction) getSqlOperator(DataSketchesFunctions.DATA_TO_SKETCH),\n+            /* distinct */ false,\n+            /* approximate */ false,\n+            /* ignoreNulls */ true,\n+            null,\n+            ImmutableList.of(),\n+            null,\n+            ImmutableList.of(key));\n+\n+        relBuilder.aggregate(relBuilder.groupKey(partitionKeys), aggCall);\n+\n+        List<RexNode> joinConditions;\n+        joinConditions = Ord.zip(partitionKeys).stream().map(o -> {\n+          RexNode f = relBuilder.field(2, 1, o.i);\n+          return rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_DISTINCT_FROM, o.e, f);", "originalCommit": "50b616456bafcfcc15b80adf0af2dfba94d92012", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUxOTE2Mw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434519163", "bodyText": "I don't 100% like this approach - let's see if we could service everything this way...", "author": "kgyrtkirk", "createdAt": "2020-06-03T12:11:01Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +388,210 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()), HiveRelFactories.HIVE_BUILDER, null);\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject == project) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected final RelNode processProject(Project project) {\n+        RelNode origInput = project.getInput();\n+        relBuilder.push(origInput);\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+          newProjects.add(expr.accept(shuttle));\n+        }\n+        if (relBuilder.peek() == origInput) {\n+          relBuilder.clear();\n+          return project;\n+        }\n+        relBuilder.project(newProjects);\n+        return relBuilder.build();\n+      }\n+\n+      private final RexNode processCall(RexNode expr) {\n+        if (expr instanceof RexOver) {\n+          RexOver over = (RexOver) expr;\n+          if (isApplicable(over)) {\n+            return rewrite(over);\n+          }\n+        }\n+        return expr;\n+      }\n+\n+      protected final SqlOperator getSqlOperator(String fnName) {\n+        UDFDescriptor fn = DataSketchesFunctions.INSTANCE.getSketchFunction(sketchClass, fnName);\n+        if (!fn.getCalciteFunction().isPresent()) {\n+          throw new RuntimeException(fn.toString() + \" doesn't have a Calcite function associated with it\");\n+        }\n+        return fn.getCalciteFunction().get();\n+      }\n+\n+      /**\n+       * Do the rewrite for the given expression.\n+       *\n+       * When this method is invoked the {@link #relBuilder} will only contain the current input.\n+       * Expectation is to leave the new input there after the method finishes.\n+       */\n+      abstract RexNode rewrite(RexOver expr);\n+\n+      abstract boolean isApplicable(RexOver expr);\n+\n+    }\n+  }\n+\n+  public static class CumeDistRewrite extends WindowingToProjectAggregateJoinProject {\n+\n+    public CumeDistRewrite(String sketchType) {\n+      super(sketchType);\n+    }\n+\n+    @Override\n+    protected VbuilderPAP buildProcessor(RelOptRuleCall call) {\n+      return new VB(sketchType, call.builder());\n+    }\n+\n+    private static class VB extends VbuilderPAP {\n+\n+      protected VB(String sketchClass, RelBuilder relBuilder) {\n+        super(sketchClass, relBuilder);\n+      }\n+\n+      @Override\n+      boolean isApplicable(RexOver over) {\n+        SqlAggFunction aggOp = over.getAggOperator();\n+        RexWindow window = over.getWindow();\n+        if (aggOp.getName().equalsIgnoreCase(\"cume_dist\") && window.orderKeys.size() == 1\n+            && window.getLowerBound().isUnbounded() && window.getUpperBound().isUnbounded()) {\n+          return true;\n+        }\n+        return false;\n+      }\n+\n+      @Override\n+      RexNode rewrite(RexOver over) {\n+        RexWindow w = over.getWindow();\n+        RexFieldCollation orderKey = w.orderKeys.get(0);\n+        // we don't really support nulls in aggregate/etc...they are actually ignored\n+        // so some hack will be needed for NULLs anyway..\n+        ImmutableList<RexNode> partitionKeys = w.partitionKeys;\n+\n+        relBuilder.push(relBuilder.peek());\n+        // the CDF function utilizes the '<' operator;\n+        // negating the input will mirror the values on the x axis\n+        // by using 1-CDF(-x) we could get a <= operator\n+        RexNode key = orderKey.getKey();\n+        key = rexBuilder.makeCall(SqlStdOperatorTable.UNARY_MINUS, key);\n+        key = rexBuilder.makeCast(getFloatType(), key);\n+\n+        AggCall aggCall = ((HiveRelBuilder) relBuilder).aggregateCall(\n+            (SqlAggFunction) getSqlOperator(DataSketchesFunctions.DATA_TO_SKETCH),\n+            /* distinct */ false,\n+            /* approximate */ false,\n+            /* ignoreNulls */ true,\n+            null,\n+            ImmutableList.of(),\n+            null,\n+            ImmutableList.of(key));\n+\n+        relBuilder.aggregate(relBuilder.groupKey(partitionKeys), aggCall);\n+\n+        List<RexNode> joinConditions;\n+        joinConditions = Ord.zip(partitionKeys).stream().map(o -> {\n+          RexNode f = relBuilder.field(2, 1, o.i);\n+          return rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_DISTINCT_FROM, o.e, f);\n+        }).collect(Collectors.toList());\n+        relBuilder.join(JoinRelType.INNER, joinConditions);\n+\n+        int sketchFieldIndex = relBuilder.peek().getRowType().getFieldCount() - 1;\n+        RexInputRef sketchInputRef = relBuilder.field(sketchFieldIndex);\n+        SqlOperator projectOperator = getSqlOperator(DataSketchesFunctions.GET_CDF);\n+\n+        // NULLs will be replaced by this value - to be before / after the other values\n+        // note: the sketch will ignore NULLs entirely but they will be placed at 0.0 or 1.0\n+        final RexNode nullReplacement =\n+            relBuilder.literal(orderKey.getNullDirection() == NullDirection.FIRST ? Float.MAX_VALUE : -Float.MAX_VALUE);\n+\n+        // long story short: CAST(1.0f-CDF(CAST(COALESCE(-X, nullReplacement) AS FLOAT))[0] AS targetType)", "originalCommit": "50b616456bafcfcc15b80adf0af2dfba94d92012", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUxOTc0Ng==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434519746", "bodyText": "remove this line", "author": "kgyrtkirk", "createdAt": "2020-06-03T12:12:07Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/CalcitePlanner.java", "diffHunk": "@@ -1974,13 +1974,19 @@ private RelNode applyPreJoinOrderingTransforms(RelNode basePlan, RelMetadataProv\n       if (!isMaterializedViewMaintenance() && conf.getBoolVar(ConfVars.HIVE_OPTIMIZE_BI_ENABLED)) {\n         // Rewrite to datasketches if enabled\n         if (conf.getBoolVar(ConfVars.HIVE_OPTIMIZE_BI_REWRITE_COUNTDISTINCT_ENABLED)) {\n-          String countDistinctSketchType = conf.getVar(ConfVars.HIVE_OPTIMIZE_BI_REWRITE_COUNT_DISTINCT_SKETCH);\n-          RelOptRule rule = new HiveRewriteToDataSketchesRules.CountDistinctRewrite(countDistinctSketchType);\n+          String sketchType = conf.getVar(ConfVars.HIVE_OPTIMIZE_BI_REWRITE_COUNT_DISTINCT_SKETCH);\n+          RelOptRule rule = new HiveRewriteToDataSketchesRules.CountDistinctRewrite(sketchType);\n           generatePartialProgram(program, true, HepMatchOrder.TOP_DOWN, rule);\n         }\n         if (conf.getBoolVar(ConfVars.HIVE_OPTIMIZE_BI_REWRITE_PERCENTILE_DISC_ENABLED)) {\n-          String percentileDiscSketchType = conf.getVar(ConfVars.HIVE_OPTIMIZE_BI_REWRITE_PERCENTILE_DISC_SKETCH);\n-          RelOptRule rule = new HiveRewriteToDataSketchesRules.PercentileDiscRewrite(percentileDiscSketchType);\n+          String sketchType = conf.getVar(ConfVars.HIVE_OPTIMIZE_BI_REWRITE_PERCENTILE_DISC_SKETCH);\n+          RelOptRule rule = new HiveRewriteToDataSketchesRules.PercentileDiscRewrite(sketchType);\n+          generatePartialProgram(program, true, HepMatchOrder.TOP_DOWN, rule);\n+        }\n+        if (conf.getBoolVar(ConfVars.HIVE_OPTIMIZE_BI_REWRITE_CUME_DIST_ENABLED)) {\n+          String sketchType = conf.getVar(ConfVars.HIVE_OPTIMIZE_BI_REWRITE_CUME_DIST_SKETCH);\n+          //          RelBuilderFactory factory=HiveRelFactories.HIVE_BUILDER.create(basePlan.getCluster(), null);", "originalCommit": "50b616456bafcfcc15b80adf0af2dfba94d92012", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7017d3c719f23ade8e72f78a6ba28aae3b2c967c", "url": "https://github.com/apache/hive/commit/7017d3c719f23ade8e72f78a6ba28aae3b2c967c", "message": "remove", "committedDate": "2020-06-03T12:25:12Z", "type": "commit"}, {"oid": "d18554781fc965f559a34ec01cfc98eba4f436fb", "url": "https://github.com/apache/hive/commit/d18554781fc965f559a34ec01cfc98eba4f436fb", "message": "apidoc update", "committedDate": "2020-06-03T12:56:25Z", "type": "commit"}, {"oid": "1cf96ee85156125986d366858a52c484087993a8", "url": "https://github.com/apache/hive/commit/1cf96ee85156125986d366858a52c484087993a8", "message": "cume_dist returns double", "committedDate": "2020-06-04T09:04:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0NDY4NA==", "url": "https://github.com/apache/hive/pull/1031#discussion_r436444684", "bodyText": "Just to confirm, does this mean that is not distinct from was never used?", "author": "jcamachor", "createdAt": "2020-06-08T03:49:28Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java", "diffHunk": "@@ -392,10 +392,11 @@ private static String getName(GenericUDF hiveUDF) {\n       registerFunction(\"istrue\", SqlStdOperatorTable.IS_TRUE, hToken(HiveParser.Identifier, \"istrue\"));\n       registerFunction(\"isnotfalse\", SqlStdOperatorTable.IS_NOT_FALSE, hToken(HiveParser.Identifier, \"isnotfalse\"));\n       registerFunction(\"isfalse\", SqlStdOperatorTable.IS_FALSE, hToken(HiveParser.Identifier, \"isfalse\"));\n-      registerFunction(\"is not distinct from\", SqlStdOperatorTable.IS_NOT_DISTINCT_FROM, hToken(HiveParser.EQUAL_NS, \"<=>\"));", "originalCommit": "1cf96ee85156125986d366858a52c484087993a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA1NzA4Mw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r438057083", "bodyText": "the calcite2hive translation was not working - and thrown an exception\nI'm not sure about hive2calcite ; I've made a note on HIVE-23594 to check out what was happening", "author": "kgyrtkirk", "createdAt": "2020-06-10T11:39:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0NDY4NA=="}], "type": "inlineReview"}, {"oid": "c2309e3a7bc0d09d9742e45c1410031f2bed762c", "url": "https://github.com/apache/hive/commit/c2309e3a7bc0d09d9742e45c1410031f2bed762c", "message": "Merge remote-tracking branch 'apache/master' into HIVE-23462-rewrite-ntile", "committedDate": "2020-06-08T14:36:38Z", "type": "commit"}, {"oid": "96b22dee9a24b871c727b98ef2bef81a83f702fd", "url": "https://github.com/apache/hive/commit/96b22dee9a24b871c727b98ef2bef81a83f702fd", "message": "Merge remote-tracking branch 'apache/master' into HIVE-23462-rewrite-ntile", "committedDate": "2020-06-09T13:50:07Z", "type": "commit"}, {"oid": "b30f2e566f8192ce8af5a5c3509845f7963eba06", "url": "https://github.com/apache/hive/commit/b30f2e566f8192ce8af5a5c3509845f7963eba06", "message": "Merge remote-tracking branch 'apache/master' into HIVE-23462-rewrite-ntile", "committedDate": "2020-06-10T09:02:56Z", "type": "commit"}, {"oid": "dc2025804aeb848c4909b42896a5e8f95c5d78d7", "url": "https://github.com/apache/hive/commit/dc2025804aeb848c4909b42896a5e8f95c5d78d7", "message": "fi typo", "committedDate": "2020-05-11T15:19:23Z", "type": "commit"}, {"oid": "a6673965708ee62e7ff8ea3079ea5a93749774b8", "url": "https://github.com/apache/hive/commit/a6673965708ee62e7ff8ea3079ea5a93749774b8", "message": "Revert \"fi typo\"\n\nThis reverts commit dc2025804aeb848c4909b42896a5e8f95c5d78d7.", "committedDate": "2020-05-11T15:19:37Z", "type": "commit"}, {"oid": "e9248a82d58d45af4b7724cab1491ea6c029289e", "url": "https://github.com/apache/hive/commit/e9248a82d58d45af4b7724cab1491ea6c029289e", "message": "ax", "committedDate": "2020-05-11T15:44:25Z", "type": "commit"}, {"oid": "a23ac7f78002ecf918d963f3358f38002260c1f6", "url": "https://github.com/apache/hive/commit/a23ac7f78002ecf918d963f3358f38002260c1f6", "message": "fix", "committedDate": "2020-05-11T15:48:15Z", "type": "commit"}, {"oid": "2a54aa98daf3e7c575450ab8589ba2acd914e9e5", "url": "https://github.com/apache/hive/commit/2a54aa98daf3e7c575450ab8589ba2acd914e9e5", "message": "add extra project", "committedDate": "2020-05-11T15:53:35Z", "type": "commit"}, {"oid": "25b458df11c1901f43749833da04b2ddc4ffb3c1", "url": "https://github.com/apache/hive/commit/25b458df11c1901f43749833da04b2ddc4ffb3c1", "message": "fx", "committedDate": "2020-05-12T06:51:15Z", "type": "commit"}, {"oid": "48f5ff92cfc145e288189d6312251959ebd6d314", "url": "https://github.com/apache/hive/commit/48f5ff92cfc145e288189d6312251959ebd6d314", "message": "fx", "committedDate": "2020-05-12T11:55:24Z", "type": "commit"}, {"oid": "47509adf359af51628b86bb027adc4df1cacc750", "url": "https://github.com/apache/hive/commit/47509adf359af51628b86bb027adc4df1cacc750", "message": "i+i", "committedDate": "2020-05-12T12:15:45Z", "type": "commit"}, {"oid": "530a8bf097c49ec1f8891515df192e4542a18904", "url": "https://github.com/apache/hive/commit/530a8bf097c49ec1f8891515df192e4542a18904", "message": "copy/etc", "committedDate": "2020-05-12T12:22:44Z", "type": "commit"}, {"oid": "d40565e5ef10b40158708b15e6d4eb890d2f89d2", "url": "https://github.com/apache/hive/commit/d40565e5ef10b40158708b15e6d4eb890d2f89d2", "message": "cleanup", "committedDate": "2020-05-12T12:24:31Z", "type": "commit"}, {"oid": "3c4313ffc8581833a54fa5d9cbae237cb09cf58f", "url": "https://github.com/apache/hive/commit/3c4313ffc8581833a54fa5d9cbae237cb09cf58f", "message": "remove", "committedDate": "2020-05-12T12:26:43Z", "type": "commit"}, {"oid": "11ad500bddc3f1d990dbd7cf9c6279a0c8b4b1e2", "url": "https://github.com/apache/hive/commit/11ad500bddc3f1d990dbd7cf9c6279a0c8b4b1e2", "message": "r3", "committedDate": "2020-05-12T12:34:49Z", "type": "commit"}, {"oid": "fb83add813bcf19d74a127c2efb5b43178cddb80", "url": "https://github.com/apache/hive/commit/fb83add813bcf19d74a127c2efb5b43178cddb80", "message": "enable for kll", "committedDate": "2020-05-12T13:56:50Z", "type": "commit"}, {"oid": "be479b3552f7c8d55b1ccdb86e04fcc50ef0dd80", "url": "https://github.com/apache/hive/commit/be479b3552f7c8d55b1ccdb86e04fcc50ef0dd80", "message": "rename", "committedDate": "2020-05-12T13:57:51Z", "type": "commit"}, {"oid": "0b05107fec9980d57cf565af2aa2a595e737fbf7", "url": "https://github.com/apache/hive/commit/0b05107fec9980d57cf565af2aa2a595e737fbf7", "message": "cleanup", "committedDate": "2020-05-12T13:58:53Z", "type": "commit"}, {"oid": "42ee7bd3a79f53d295d07a591b69fa1180bf61d9", "url": "https://github.com/apache/hive/commit/42ee7bd3a79f53d295d07a591b69fa1180bf61d9", "message": "turn on null ignorance", "committedDate": "2020-05-12T13:59:30Z", "type": "commit"}, {"oid": "acac3c1d10e8c8ec35b8ee904939485b49d86b86", "url": "https://github.com/apache/hive/commit/acac3c1d10e8c8ec35b8ee904939485b49d86b86", "message": "create inner crap", "committedDate": "2020-05-12T14:03:33Z", "type": "commit"}, {"oid": "76a6e33b17c696d51ce73f0e8e654638bcdde650", "url": "https://github.com/apache/hive/commit/76a6e33b17c696d51ce73f0e8e654638bcdde650", "message": "renames", "committedDate": "2020-05-12T14:05:35Z", "type": "commit"}, {"oid": "344539f2b96d81a2538b07da430f88a6bb85600b", "url": "https://github.com/apache/hive/commit/344539f2b96d81a2538b07da430f88a6bb85600b", "message": "cleanup/etc", "committedDate": "2020-05-12T14:13:00Z", "type": "commit"}, {"oid": "24250f50c19ea9c3ee53a12e10c24c4830e327ab", "url": "https://github.com/apache/hive/commit/24250f50c19ea9c3ee53a12e10c24c4830e327ab", "message": "cleanup/inline/etc", "committedDate": "2020-05-12T14:27:37Z", "type": "commit"}, {"oid": "f7c8da190a143bc2b3ee3b55a4ac31c6723c6c83", "url": "https://github.com/apache/hive/commit/f7c8da190a143bc2b3ee3b55a4ac31c6723c6c83", "message": "straighten out configs", "committedDate": "2020-05-13T11:40:53Z", "type": "commit"}, {"oid": "c1ad720110c578da82d6d436897c65e15d36063c", "url": "https://github.com/apache/hive/commit/c1ad720110c578da82d6d436897c65e15d36063c", "message": "cleanup", "committedDate": "2020-05-13T11:45:15Z", "type": "commit"}, {"oid": "28840c038f60beff2a7231631a925a9fa62f3676", "url": "https://github.com/apache/hive/commit/28840c038f60beff2a7231631a925a9fa62f3676", "message": "renames/etc", "committedDate": "2020-05-13T11:50:51Z", "type": "commit"}, {"oid": "82251ab7ed2ef7175e935a89dfaebabe5e13d508", "url": "https://github.com/apache/hive/commit/82251ab7ed2ef7175e935a89dfaebabe5e13d508", "message": "apidoc", "committedDate": "2020-05-13T11:58:20Z", "type": "commit"}, {"oid": "7dd37078e28395689b72de442564c7672e324019", "url": "https://github.com/apache/hive/commit/7dd37078e28395689b72de442564c7672e324019", "message": "also add round to distinct", "committedDate": "2020-05-13T12:03:49Z", "type": "commit"}, {"oid": "2a6873af55e55d142099d95d69d82a608e8c3615", "url": "https://github.com/apache/hive/commit/2a6873af55e55d142099d95d69d82a608e8c3615", "message": "Merge remote-tracking branch 'apache/master' into HIVE-23434-rewrite-pcont", "committedDate": "2020-05-13T13:52:14Z", "type": "commit"}, {"oid": "67386f70523253dc0061fef9a49c9f07c0d49e16", "url": "https://github.com/apache/hive/commit/67386f70523253dc0061fef9a49c9f07c0d49e16", "message": "dont use crap", "committedDate": "2020-05-13T14:00:15Z", "type": "commit"}, {"oid": "7a1d5c544a28dd1d965c0b6b57217c81d855d4d3", "url": "https://github.com/apache/hive/commit/7a1d5c544a28dd1d965c0b6b57217c81d855d4d3", "message": "Merge remote-tracking branch 'kgyrtkirk/HIVE-23434-rewrite-pcont' into HIVE-23462-rewrite-ntile", "committedDate": "2020-05-13T14:05:09Z", "type": "commit"}, {"oid": "9e5bdc224d00e2e7e9821a05dad1be8b63b1a1e8", "url": "https://github.com/apache/hive/commit/9e5bdc224d00e2e7e9821a05dad1be8b63b1a1e8", "message": "Merge remote-tracking branch 'kgyrtkirk/HIVE-23434-rewrite-pcont' into HIVE-23462-rewrite-ntile", "committedDate": "2020-05-13T14:05:38Z", "type": "commit"}, {"oid": "6645a7c1a021a0169167c5a46ab6db31a69450fe", "url": "https://github.com/apache/hive/commit/6645a7c1a021a0169167c5a46ab6db31a69450fe", "message": "add round", "committedDate": "2020-05-13T20:41:12Z", "type": "commit"}, {"oid": "f6257547d2738190bfd966d942dcfc99b1a9cf98", "url": "https://github.com/apache/hive/commit/f6257547d2738190bfd966d942dcfc99b1a9cf98", "message": "add esxdamples", "committedDate": "2020-05-15T13:33:17Z", "type": "commit"}, {"oid": "14ba6be11314a67b30a4bc8a5fb5205b4e8045ff", "url": "https://github.com/apache/hive/commit/14ba6be11314a67b30a4bc8a5fb5205b4e8045ff", "message": "typo", "committedDate": "2020-05-15T13:34:53Z", "type": "commit"}, {"oid": "ad68128704dff9048d6b190cf31317f1c3881ba1", "url": "https://github.com/apache/hive/commit/ad68128704dff9048d6b190cf31317f1c3881ba1", "message": "format file", "committedDate": "2020-05-15T13:35:16Z", "type": "commit"}, {"oid": "ab0bc4e1a0e61b285f7822ad9e2c6d8c15193c58", "url": "https://github.com/apache/hive/commit/ab0bc4e1a0e61b285f7822ad9e2c6d8c15193c58", "message": "apudoc", "committedDate": "2020-05-15T13:45:17Z", "type": "commit"}, {"oid": "2bb7ea8e613b1b7e95ed35f066aff4da47773873", "url": "https://github.com/apache/hive/commit/2bb7ea8e613b1b7e95ed35f066aff4da47773873", "message": "Merge remote-tracking branch 'apache/master' into HIVE-23434-rewrite-pcont", "committedDate": "2020-05-18T11:46:33Z", "type": "commit"}, {"oid": "94502711781ccc45b6280a4a432c220adbcbe464", "url": "https://github.com/apache/hive/commit/94502711781ccc45b6280a4a432c220adbcbe464", "message": "add", "committedDate": "2020-05-18T11:47:17Z", "type": "commit"}, {"oid": "f63f8e09f6bf7d5d16c29baeffbe7331b16eabee", "url": "https://github.com/apache/hive/commit/f63f8e09f6bf7d5d16c29baeffbe7331b16eabee", "message": "aa", "committedDate": "2020-05-18T11:47:25Z", "type": "commit"}, {"oid": "492d20af5d4a62da2c2a41215e0e846ed6417efc", "url": "https://github.com/apache/hive/commit/492d20af5d4a62da2c2a41215e0e846ed6417efc", "message": "typo", "committedDate": "2020-05-18T12:46:14Z", "type": "commit"}, {"oid": "e991198da7b64da01916a0005fb6bf0df36a111b", "url": "https://github.com/apache/hive/commit/e991198da7b64da01916a0005fb6bf0df36a111b", "message": "review changes", "committedDate": "2020-05-18T13:35:54Z", "type": "commit"}, {"oid": "6ef6f7f3bdcc8f54b4586c886518d191ae4d1c01", "url": "https://github.com/apache/hive/commit/6ef6f7f3bdcc8f54b4586c886518d191ae4d1c01", "message": "agginoput", "committedDate": "2020-05-19T13:34:39Z", "type": "commit"}, {"oid": "e9ca1540e26470844afe98a399d0045ba8867d22", "url": "https://github.com/apache/hive/commit/e9ca1540e26470844afe98a399d0045ba8867d22", "message": "fix fixme", "committedDate": "2020-05-19T13:55:18Z", "type": "commit"}, {"oid": "8aea985330cc3cc70e6b8d68a7747726ae494577", "url": "https://github.com/apache/hive/commit/8aea985330cc3cc70e6b8d68a7747726ae494577", "message": "add m", "committedDate": "2020-05-19T15:04:07Z", "type": "commit"}, {"oid": "956391b3195738da85f5991f2508fb84f3272541", "url": "https://github.com/apache/hive/commit/956391b3195738da85f5991f2508fb84f3272541", "message": "Revert \"add m\"\n\nThis reverts commit 8aea985330cc3cc70e6b8d68a7747726ae494577.", "committedDate": "2020-05-19T15:04:09Z", "type": "commit"}, {"oid": "908a9322ee5f4b865229d7fb17ab99df1b47ba61", "url": "https://github.com/apache/hive/commit/908a9322ee5f4b865229d7fb17ab99df1b47ba61", "message": "add percentile_cont rewrite stuff", "committedDate": "2020-05-19T15:13:10Z", "type": "commit"}, {"oid": "212e9629cef5063b1980aaca1ab3d49b1c3a2b69", "url": "https://github.com/apache/hive/commit/212e9629cef5063b1980aaca1ab3d49b1c3a2b69", "message": "fix cast", "committedDate": "2020-05-19T16:12:46Z", "type": "commit"}, {"oid": "b0d02ae95cfdfd4a6479bca5f76261502f93530f", "url": "https://github.com/apache/hive/commit/b0d02ae95cfdfd4a6479bca5f76261502f93530f", "message": "percentile_disc", "committedDate": "2020-05-20T05:59:53Z", "type": "commit"}, {"oid": "7990c9c7ebda91652f5bf4ced5e23dbec1547e42", "url": "https://github.com/apache/hive/commit/7990c9c7ebda91652f5bf4ced5e23dbec1547e42", "message": "change to .3", "committedDate": "2020-05-20T07:39:02Z", "type": "commit"}, {"oid": "fd86c6899ca34ac64e844b469ce926ff09bc234e", "url": "https://github.com/apache/hive/commit/fd86c6899ca34ac64e844b469ce926ff09bc234e", "message": "Merge remote-tracking branch 'kgyrtkirk/HIVE-23434-rewrite-pcont' into HIVE-23462-rewrite-ntile", "committedDate": "2020-05-20T07:39:58Z", "type": "commit"}, {"oid": "5ea0a2d428be90746595848301ebe77ecdc311df", "url": "https://github.com/apache/hive/commit/5ea0a2d428be90746595848301ebe77ecdc311df", "message": "f", "committedDate": "2020-05-20T07:42:23Z", "type": "commit"}, {"oid": "c6265d2e3c18f37d3ba9f038b234f718647de68c", "url": "https://github.com/apache/hive/commit/c6265d2e3c18f37d3ba9f038b234f718647de68c", "message": "refactor", "committedDate": "2020-05-20T08:52:45Z", "type": "commit"}, {"oid": "e8132d6a289fdf7c558ac298f21178e5d99a2833", "url": "https://github.com/apache/hive/commit/e8132d6a289fdf7c558ac298f21178e5d99a2833", "message": "use new", "committedDate": "2020-05-20T08:56:00Z", "type": "commit"}, {"oid": "ca6e2d1f7acc937a889e204f7651329958ba20c7", "url": "https://github.com/apache/hive/commit/ca6e2d1f7acc937a889e204f7651329958ba20c7", "message": "finish refactor", "committedDate": "2020-05-20T10:10:30Z", "type": "commit"}, {"oid": "421dc08afdc7b69f88bb5962ed38c5e9a617a4a7", "url": "https://github.com/apache/hive/commit/421dc08afdc7b69f88bb5962ed38c5e9a617a4a7", "message": "copy stuff", "committedDate": "2020-05-20T10:35:04Z", "type": "commit"}, {"oid": "91e0f2661c08e9f24d9ced0ae93d80b0d1350082", "url": "https://github.com/apache/hive/commit/91e0f2661c08e9f24d9ced0ae93d80b0d1350082", "message": "add", "committedDate": "2020-05-20T10:46:48Z", "type": "commit"}, {"oid": "a00b8b2221f5c9a29ecafbe2673e80bd16819272", "url": "https://github.com/apache/hive/commit/a00b8b2221f5c9a29ecafbe2673e80bd16819272", "message": "add test", "committedDate": "2020-05-20T10:46:56Z", "type": "commit"}, {"oid": "f3b339fc07eaef34c05b57375f680020b4bea5b0", "url": "https://github.com/apache/hive/commit/f3b339fc07eaef34c05b57375f680020b4bea5b0", "message": "wip", "committedDate": "2020-05-20T12:08:08Z", "type": "commit"}, {"oid": "b1488d081ae809d89c141bc9f8008c107efc3f32", "url": "https://github.com/apache/hive/commit/b1488d081ae809d89c141bc9f8008c107efc3f32", "message": "wood", "committedDate": "2020-05-21T11:56:07Z", "type": "commit"}, {"oid": "7145e561cb23673e67e0730abc45b4d165df578c", "url": "https://github.com/apache/hive/commit/7145e561cb23673e67e0730abc45b4d165df578c", "message": "fixes", "committedDate": "2020-05-21T12:09:34Z", "type": "commit"}, {"oid": "46d9afe4df6425f47b4b181dbce09baebe7173df", "url": "https://github.com/apache/hive/commit/46d9afe4df6425f47b4b181dbce09baebe7173df", "message": "fixes", "committedDate": "2020-05-21T14:59:45Z", "type": "commit"}, {"oid": "3fd0c9e163967ca8c953d67cb26d691b1c6f6509", "url": "https://github.com/apache/hive/commit/3fd0c9e163967ca8c953d67cb26d691b1c6f6509", "message": "cleanupo", "committedDate": "2020-05-21T15:02:59Z", "type": "commit"}, {"oid": "bfc9edc07cd19e017d9632b37a07eb4b4f70bd22", "url": "https://github.com/apache/hive/commit/bfc9edc07cd19e017d9632b37a07eb4b4f70bd22", "message": "use kll in sample", "committedDate": "2020-05-21T15:04:42Z", "type": "commit"}, {"oid": "31967a1a2e13a908616470cea307a140353beb93", "url": "https://github.com/apache/hive/commit/31967a1a2e13a908616470cea307a140353beb93", "message": "ordered / adjusted/etc", "committedDate": "2020-05-21T15:24:49Z", "type": "commit"}, {"oid": "0e8cd530d8ed3bc3951784b146a180d705fdbe8a", "url": "https://github.com/apache/hive/commit/0e8cd530d8ed3bc3951784b146a180d705fdbe8a", "message": "cleanup", "committedDate": "2020-05-21T15:57:33Z", "type": "commit"}, {"oid": "8037bd089de4dcb982348fc3c3a52d97a10dbb45", "url": "https://github.com/apache/hive/commit/8037bd089de4dcb982348fc3c3a52d97a10dbb45", "message": "peek", "committedDate": "2020-05-21T16:01:41Z", "type": "commit"}, {"oid": "2e29757a5d1ca0267c593edc223f242e7da8883d", "url": "https://github.com/apache/hive/commit/2e29757a5d1ca0267c593edc223f242e7da8883d", "message": "cleanup", "committedDate": "2020-05-21T16:06:13Z", "type": "commit"}, {"oid": "3571e9021f44e774f1f7138e4df00b30332eb0ad", "url": "https://github.com/apache/hive/commit/3571e9021f44e774f1f7138e4df00b30332eb0ad", "message": "conf", "committedDate": "2020-05-21T16:11:50Z", "type": "commit"}, {"oid": "e08f282fbaa16e43b66986d4b73e235356e238bc", "url": "https://github.com/apache/hive/commit/e08f282fbaa16e43b66986d4b73e235356e238bc", "message": "cleanup", "committedDate": "2020-05-21T16:23:32Z", "type": "commit"}, {"oid": "52330c5fe480a880149c1e014d7f687416fb0cbb", "url": "https://github.com/apache/hive/commit/52330c5fe480a880149c1e014d7f687416fb0cbb", "message": "cleanup", "committedDate": "2020-05-21T16:27:03Z", "type": "commit"}, {"oid": "858c36635b5192d32bb00f4fc30447fa9368e295", "url": "https://github.com/apache/hive/commit/858c36635b5192d32bb00f4fc30447fa9368e295", "message": "cleanup", "committedDate": "2020-05-21T16:27:45Z", "type": "commit"}, {"oid": "b3c1fe15b39c6476336c1d8df4d2cae4fbed7aed", "url": "https://github.com/apache/hive/commit/b3c1fe15b39c6476336c1d8df4d2cae4fbed7aed", "message": "add cd q", "committedDate": "2020-05-21T16:41:40Z", "type": "commit"}, {"oid": "3c7e9e28ee25cab637548012754aa8b4452c4508", "url": "https://github.com/apache/hive/commit/3c7e9e28ee25cab637548012754aa8b4452c4508", "message": "add mv test - odesntwork", "committedDate": "2020-05-21T16:56:19Z", "type": "commit"}, {"oid": "03ab8f6b2b8cbcf691b2c636fedcd3010df94694", "url": "https://github.com/apache/hive/commit/03ab8f6b2b8cbcf691b2c636fedcd3010df94694", "message": "trace", "committedDate": "2020-05-21T19:23:41Z", "type": "commit"}, {"oid": "578921ae9741068b2f38738f8632f3a0f2dbcee1", "url": "https://github.com/apache/hive/commit/578921ae9741068b2f38738f8632f3a0f2dbcee1", "message": "Revert \"trace\"\n\nThis reverts commit 03ab8f6b2b8cbcf691b2c636fedcd3010df94694.", "committedDate": "2020-05-21T19:23:44Z", "type": "commit"}, {"oid": "58cfdfdbe10862dd2f6f0d996463d72d6901667f", "url": "https://github.com/apache/hive/commit/58cfdfdbe10862dd2f6f0d996463d72d6901667f", "message": "fix mv matching", "committedDate": "2020-05-21T19:29:32Z", "type": "commit"}, {"oid": "f56ebb9d26a77b06b32f453f944ca323b2100493", "url": "https://github.com/apache/hive/commit/f56ebb9d26a77b06b32f453f944ca323b2100493", "message": "undo ws changes", "committedDate": "2020-05-21T19:31:24Z", "type": "commit"}, {"oid": "daf5180f206aeb8c82e93e4365788cfa3862c38e", "url": "https://github.com/apache/hive/commit/daf5180f206aeb8c82e93e4365788cfa3862c38e", "message": "remove crappy test", "committedDate": "2020-05-21T19:32:31Z", "type": "commit"}, {"oid": "cd8070c108fe37053c75c9f7c99e8b13f1d4a9b5", "url": "https://github.com/apache/hive/commit/cd8070c108fe37053c75c9f7c99e8b13f1d4a9b5", "message": "Merge remote-tracking branch 'apache/master' into HIVE-23434-rewrite-pcont", "committedDate": "2020-05-27T07:04:14Z", "type": "commit"}, {"oid": "0225c44ae2a0dfd231b880a9a66e26520da40a8a", "url": "https://github.com/apache/hive/commit/0225c44ae2a0dfd231b880a9a66e26520da40a8a", "message": "Merge remote-tracking branch 'kgyrtkirk/HIVE-23434-rewrite-pcont' into HIVE-23462-rewrite-ntile", "committedDate": "2020-05-27T07:05:34Z", "type": "commit"}, {"oid": "f0259947c5c54aa45589813e54195bff877e936b", "url": "https://github.com/apache/hive/commit/f0259947c5c54aa45589813e54195bff877e936b", "message": "f", "committedDate": "2020-05-27T07:05:49Z", "type": "commit"}, {"oid": "ccb6f5ee96e1dc93d5bac7f871e5f1452c7242d6", "url": "https://github.com/apache/hive/commit/ccb6f5ee96e1dc93d5bac7f871e5f1452c7242d6", "message": "x", "committedDate": "2020-05-27T07:55:28Z", "type": "commit"}, {"oid": "35b5d089e91898b0cf14270eae90f7dcd09718ec", "url": "https://github.com/apache/hive/commit/35b5d089e91898b0cf14270eae90f7dcd09718ec", "message": "after all there is no problem with this rule...", "committedDate": "2020-05-27T12:05:32Z", "type": "commit"}, {"oid": "3e1a1c63c0c72e524d1f981dc6c848ae5369ad0c", "url": "https://github.com/apache/hive/commit/3e1a1c63c0c72e524d1f981dc6c848ae5369ad0c", "message": "Revert \"Revert \"trace\"\"\n\nThis reverts commit 578921ae9741068b2f38738f8632f3a0f2dbcee1.", "committedDate": "2020-05-27T12:06:09Z", "type": "commit"}, {"oid": "390e13fcd73190e986b3073527ec50a3aa138b5c", "url": "https://github.com/apache/hive/commit/390e13fcd73190e986b3073527ec50a3aa138b5c", "message": "Revert \"Revert \"Revert \"trace\"\"\"\n\nThis reverts commit 3e1a1c63c0c72e524d1f981dc6c848ae5369ad0c.", "committedDate": "2020-05-27T13:52:22Z", "type": "commit"}, {"oid": "1d84cf3a2b0f9d7818a3bba64f874790c224e5dc", "url": "https://github.com/apache/hive/commit/1d84cf3a2b0f9d7818a3bba64f874790c224e5dc", "message": "add the rifght testcase", "committedDate": "2020-05-27T13:59:53Z", "type": "commit"}, {"oid": "459efee45f3e82db0922f0d51648880aefd80bb0", "url": "https://github.com/apache/hive/commit/459efee45f3e82db0922f0d51648880aefd80bb0", "message": "add apidoc", "committedDate": "2020-05-27T14:02:00Z", "type": "commit"}, {"oid": "092002fdd6c780bf094432e393ce3a21cff145ff", "url": "https://github.com/apache/hive/commit/092002fdd6c780bf094432e393ce3a21cff145ff", "message": "cleanup", "committedDate": "2020-05-27T14:02:55Z", "type": "commit"}, {"oid": "ce3bca592a111b3332a9ce50f1e5b2e432a0b286", "url": "https://github.com/apache/hive/commit/ce3bca592a111b3332a9ce50f1e5b2e432a0b286", "message": "update docs", "committedDate": "2020-05-27T14:06:40Z", "type": "commit"}, {"oid": "1ae6295edadc70ae9e6ea0fac49211292d443abd", "url": "https://github.com/apache/hive/commit/1ae6295edadc70ae9e6ea0fac49211292d443abd", "message": "partition_by", "committedDate": "2020-05-28T09:53:06Z", "type": "commit"}, {"oid": "408e321014e7dc88f895bf83ebde42f2d57deea9", "url": "https://github.com/apache/hive/commit/408e321014e7dc88f895bf83ebde42f2d57deea9", "message": "works", "committedDate": "2020-05-28T13:27:59Z", "type": "commit"}, {"oid": "d40a1ca393cf26d3b6517635202b0c68908bdea1", "url": "https://github.com/apache/hive/commit/d40a1ca393cf26d3b6517635202b0c68908bdea1", "message": "it works with eps", "committedDate": "2020-05-28T13:36:15Z", "type": "commit"}, {"oid": "81addefe12c9bb9df23e66b388645ba3e428fb78", "url": "https://github.com/apache/hive/commit/81addefe12c9bb9df23e66b388645ba3e428fb78", "message": "use -x", "committedDate": "2020-05-28T13:43:14Z", "type": "commit"}, {"oid": "c33f82c09585a11d0f73401b7b256978553453a8", "url": "https://github.com/apache/hive/commit/c33f82c09585a11d0f73401b7b256978553453a8", "message": "unary_minus works", "committedDate": "2020-05-28T14:19:17Z", "type": "commit"}, {"oid": "26be839786ba7e86e7392a91b8a2003cce8892a5", "url": "https://github.com/apache/hive/commit/26be839786ba7e86e7392a91b8a2003cce8892a5", "message": "use shuttle", "committedDate": "2020-05-28T14:42:37Z", "type": "commit"}, {"oid": "e8de3b7b5e22791cb1b286c9e29953c93949dbc8", "url": "https://github.com/apache/hive/commit/e8de3b7b5e22791cb1b286c9e29953c93949dbc8", "message": "cleanup", "committedDate": "2020-05-28T14:44:24Z", "type": "commit"}, {"oid": "cd1fbd97c2af93bd8202215057c6276d08b87f5c", "url": "https://github.com/apache/hive/commit/cd1fbd97c2af93bd8202215057c6276d08b87f5c", "message": "order/etc", "committedDate": "2020-05-28T15:07:29Z", "type": "commit"}, {"oid": "74df109c139f9f9b51d57304f0abeb840795fcb6", "url": "https://github.com/apache/hive/commit/74df109c139f9f9b51d57304f0abeb840795fcb6", "message": "coal in", "committedDate": "2020-05-28T15:09:05Z", "type": "commit"}, {"oid": "b855107ac6761a5f7058ca546efb72e649647902", "url": "https://github.com/apache/hive/commit/b855107ac6761a5f7058ca546efb72e649647902", "message": "use rollup as well", "committedDate": "2020-05-28T15:18:55Z", "type": "commit"}, {"oid": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "url": "https://github.com/apache/hive/commit/5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "message": "update", "committedDate": "2020-05-28T15:21:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEwNTc2MQ==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432105761", "bodyText": "nit. indentation", "author": "jcamachor", "createdAt": "2020-05-28T20:30:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/DataSketchesFunctions.java", "diffHunk": "@@ -235,12 +232,21 @@ public String getFunctionName() {\n         return Optional.empty();\n       } else {\n         JavaTypeFactoryImpl typeFactory = new JavaTypeFactoryImpl(new HiveTypeSystemImpl());\n+        Type type = returnType;\n+        if (type instanceof ParameterizedType) {\n+          ParameterizedType parameterizedType = (ParameterizedType) type;\n+          if (parameterizedType.getRawType() == List.class) {\n+          final RelDataType componentRelType = typeFactory.createType(parameterizedType.getActualTypeArguments()[0]);", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEwNjY1MA==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432106650", "bodyText": "Is this variable needed? It seems to me its same as returnType.", "author": "jcamachor", "createdAt": "2020-05-28T20:32:33Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/DataSketchesFunctions.java", "diffHunk": "@@ -235,12 +232,21 @@ public String getFunctionName() {\n         return Optional.empty();\n       } else {\n         JavaTypeFactoryImpl typeFactory = new JavaTypeFactoryImpl(new HiveTypeSystemImpl());\n+        Type type = returnType;", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjExNjA2Mw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432116063", "bodyText": "What if it is a parameterized type but it is not a list? Should we throw an exception just to make sure?", "author": "jcamachor", "createdAt": "2020-05-28T20:51:45Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/DataSketchesFunctions.java", "diffHunk": "@@ -235,12 +232,21 @@ public String getFunctionName() {\n         return Optional.empty();\n       } else {\n         JavaTypeFactoryImpl typeFactory = new JavaTypeFactoryImpl(new HiveTypeSystemImpl());\n+        Type type = returnType;\n+        if (type instanceof ParameterizedType) {\n+          ParameterizedType parameterizedType = (ParameterizedType) type;\n+          if (parameterizedType.getRawType() == List.class) {\n+          final RelDataType componentRelType = typeFactory.createType(parameterizedType.getActualTypeArguments()[0]);\n+          return Optional\n+              .of(typeFactory.createArrayType(typeFactory.createTypeWithNullability(componentRelType, true), -1));\n+          }", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExMDkwNw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434110907", "bodyText": "idea was to leave \"typeFactory\" to handle it - although it will return something - but it will not work properly\nreturned Optional.empty()", "author": "kgyrtkirk", "createdAt": "2020-06-02T19:02:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjExNjA2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjExODIxMg==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432118212", "bodyText": "I have a general comment about the approach we are taking in these methods to infer the return type.\nI think we should rethink inferring the return type from the Java returned object from 'evaluate' and we could possibly take a step back.\nOne option could be create the necessary SqlReturnTypeInference strategies to be able to return the correct type depending on the functions. If the inference is simple, we could hardcode some of those return types. This is the general approach taken by Calcite functions. I think that will help simplifying this code a lot.\nWhat do you think? Do you have any other ideas?", "author": "jcamachor", "createdAt": "2020-05-28T20:55:55Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/DataSketchesFunctions.java", "diffHunk": "@@ -235,12 +232,21 @@ public String getFunctionName() {\n         return Optional.empty();\n       } else {\n         JavaTypeFactoryImpl typeFactory = new JavaTypeFactoryImpl(new HiveTypeSystemImpl());\n+        Type type = returnType;\n+        if (type instanceof ParameterizedType) {\n+          ParameterizedType parameterizedType = (ParameterizedType) type;\n+          if (parameterizedType.getRawType() == List.class) {\n+          final RelDataType componentRelType = typeFactory.createType(parameterizedType.getActualTypeArguments()[0]);\n+          return Optional\n+              .of(typeFactory.createArrayType(typeFactory.createTypeWithNullability(componentRelType, true), -1));\n+          }\n+        }\n         return Optional.of(typeFactory.createType(returnType));\n       }", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ3OTAxNw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432479017", "bodyText": "yes; I also wanted to use this only temporarily - because this approach would not work for GenericUDF - but instead of hardcoding stuff; I think the best would be to create a SqlReturnTypeInference  which could translate the opbindings to things which could be processed by GenericUDF#initialize\nopened: HIVE-23579", "author": "kgyrtkirk", "createdAt": "2020-05-29T13:23:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjExODIxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjExODk1NQ==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432118955", "bodyText": "Probably you want to delete CUME_DIST() OVER (ORDER BY id), in L88, since we are providing the equivalent rewriting.", "author": "jcamachor", "createdAt": "2020-05-28T20:57:25Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -68,25 +82,33 @@\n  *       \u21d2 SELECT ds_kll_quantile(ds_kll_sketch(CAST(id AS FLOAT)), 0.2) FROM sketch_input;\n  *    </pre>\n  *  </li>\n+ *  <li>{@code cume_dist() over (order by id)}\n+ *    <pre>\n+ *     SELECT id, CUME_DIST() OVER (ORDER BY id) FROM sketch_input;\n+ *       \u21d2 SELECT id, CUME_DIST() OVER (ORDER BY id),", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyMzkwMw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432123903", "bodyText": "Why are we overriding this on Hive side? Could we leave a comment?", "author": "jcamachor", "createdAt": "2020-05-28T21:07:14Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelBuilder.java", "diffHunk": "@@ -157,6 +159,12 @@ public static SqlAggFunction getRollup(SqlAggFunction aggregation) {\n     return null;\n   }\n \n+  @Override\n+  public AggCall aggregateCall(SqlAggFunction aggFunction, boolean distinct, boolean approximate, boolean ignoreNulls,", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyNDA3Mg==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432124072", "bodyText": "I did not know AggregateCall already had an approximate flag. Do you know what this is used for in Calcite?", "author": "jcamachor", "createdAt": "2020-05-28T21:07:36Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/HiveRelBuilder.java", "diffHunk": "@@ -157,6 +159,12 @@ public static SqlAggFunction getRollup(SqlAggFunction aggregation) {\n     return null;\n   }\n \n+  @Override\n+  public AggCall aggregateCall(SqlAggFunction aggFunction, boolean distinct, boolean approximate, boolean ignoreNulls,\n+      RexNode filter, ImmutableList<RexNode> orderKeys, String alias, ImmutableList<RexNode> operands) {\n+    return super.aggregateCall(aggFunction, distinct, approximate, ignoreNulls, filter, orderKeys, alias, operands);", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjMyMzM0NA==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432323344", "bodyText": "actually AggregateCall#isApproximate is only used at one place - to decide to merge or not aggregates (in AggregateMergeRule); I now think that I've incorrectly set it to true - although the sketch will collect some features of the dataset; the approximation will be done by the sketch_estimate function", "author": "kgyrtkirk", "createdAt": "2020-05-29T08:08:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyNDA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyNDYwOQ==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432124609", "bodyText": "nit. Indentation", "author": "jcamachor", "createdAt": "2020-05-28T21:08:35Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject instanceof Project && ((Project) newProject).getChildExps().equals(project.getChildExps())) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected RelNode processProject(Project project) {\n+        relBuilder.push(project.getInput());\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+                newProjects.add(expr.accept(shuttle));", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyNTEyMg==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432125122", "bodyText": "We should add a new type to Calcite for this function too.", "author": "jcamachor", "createdAt": "2020-05-28T21:09:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject instanceof Project && ((Project) newProject).getChildExps().equals(project.getChildExps())) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected RelNode processProject(Project project) {\n+        relBuilder.push(project.getInput());\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+                newProjects.add(expr.accept(shuttle));\n+        }\n+        relBuilder.project(newProjects);\n+        return relBuilder.build();\n+      }\n+\n+      private final RexNode processCall(RexNode expr) {\n+        if (expr instanceof RexOver) {\n+          RexOver over = (RexOver) expr;\n+          if (isApplicable(over)) {\n+            return rewrite(over);\n+          }\n+        }\n+        return expr;\n+      }\n+\n+      protected final SqlOperator getSqlOperator(String fnName) {\n+        UDFDescriptor fn = DataSketchesFunctions.INSTANCE.getSketchFunction(sketchClass, fnName);\n+        if (!fn.getCalciteFunction().isPresent()) {\n+          throw new RuntimeException(fn.toString() + \" doesn't have a Calcite function associated with it\");\n+        }\n+        return fn.getCalciteFunction().get();\n+      }\n+\n+      abstract RexNode rewrite(RexOver expr);\n+\n+      abstract boolean isApplicable(RexOver expr);\n+\n+    }\n+\n+  }\n+\n+  public static class CumeDistRewrite extends WindowingToProjectAggregateJoinProject {\n+\n+    public CumeDistRewrite(String sketchType) {\n+      super(sketchType);\n+    }\n+\n+    @Override\n+    protected VbuilderPAP buildProcessor(RelOptRuleCall call) {\n+      return new VB(sketchType, call.builder());\n+    }\n+\n+    private static class VB extends VbuilderPAP {\n+\n+      protected VB(String sketchClass, RelBuilder relBuilder) {\n+        super(sketchClass, relBuilder);\n+      }\n+\n+      @Override\n+      boolean isApplicable(RexOver over) {\n+        SqlAggFunction aggOp = over.getAggOperator();\n+        RexWindow window = over.getWindow();\n+        if (aggOp.getName().equalsIgnoreCase(\"cume_dist\") && window.orderKeys.size() == 1", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExNDIyMw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434114223", "bodyText": "sure; I've opened HIVE-23594 for this - as it also needs a new class/etc", "author": "kgyrtkirk", "createdAt": "2020-06-02T19:08:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyNTEyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyNTYxOA==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432125618", "bodyText": "nit. newline", "author": "jcamachor", "createdAt": "2020-05-28T21:10:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject instanceof Project && ((Project) newProject).getChildExps().equals(project.getChildExps())) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected RelNode processProject(Project project) {\n+        relBuilder.push(project.getInput());\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+                newProjects.add(expr.accept(shuttle));\n+        }\n+        relBuilder.project(newProjects);\n+        return relBuilder.build();\n+      }\n+\n+      private final RexNode processCall(RexNode expr) {\n+        if (expr instanceof RexOver) {\n+          RexOver over = (RexOver) expr;\n+          if (isApplicable(over)) {\n+            return rewrite(over);\n+          }\n+        }\n+        return expr;\n+      }\n+\n+      protected final SqlOperator getSqlOperator(String fnName) {\n+        UDFDescriptor fn = DataSketchesFunctions.INSTANCE.getSketchFunction(sketchClass, fnName);\n+        if (!fn.getCalciteFunction().isPresent()) {\n+          throw new RuntimeException(fn.toString() + \" doesn't have a Calcite function associated with it\");\n+        }\n+        return fn.getCalciteFunction().get();\n+      }\n+\n+      abstract RexNode rewrite(RexOver expr);\n+\n+      abstract boolean isApplicable(RexOver expr);\n+\n+    }\n+\n+  }\n+\n+  public static class CumeDistRewrite extends WindowingToProjectAggregateJoinProject {\n+\n+    public CumeDistRewrite(String sketchType) {\n+      super(sketchType);\n+    }\n+\n+    @Override\n+    protected VbuilderPAP buildProcessor(RelOptRuleCall call) {\n+      return new VB(sketchType, call.builder());\n+    }\n+\n+    private static class VB extends VbuilderPAP {\n+\n+      protected VB(String sketchClass, RelBuilder relBuilder) {\n+        super(sketchClass, relBuilder);\n+      }\n+\n+      @Override\n+      boolean isApplicable(RexOver over) {\n+        SqlAggFunction aggOp = over.getAggOperator();\n+        RexWindow window = over.getWindow();\n+        if (aggOp.getName().equalsIgnoreCase(\"cume_dist\") && window.orderKeys.size() == 1\n+            && window.getLowerBound().isUnbounded() && window.getUpperBound().isUnbounded()) {\n+          return true;\n+        }\n+        return false;\n+      }\n+\n+      @Override\n+      RexNode rewrite(RexOver over) {\n+", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyNTY3Ng==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432125676", "bodyText": "nit. newline", "author": "jcamachor", "createdAt": "2020-05-28T21:10:52Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyODU1MQ==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432128551", "bodyText": "I think this check could be done more efficiently, avoiding traversing all the expressions.\nWe need to make sure we only create a new project when there are rewritings in the RexNode expressions:\n\nIn the for loop in processProject, check for each expression whether it was modified by ProcessShuttle (==).\nOnly create a new Project operator if any of the expressions changed.\nCheck here newProject == project.", "author": "jcamachor", "createdAt": "2020-05-28T21:16:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject instanceof Project && ((Project) newProject).getChildExps().equals(project.getChildExps())) {", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ4MDMwMg==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432480302", "bodyText": "done it a bit differently - but the end result is the same", "author": "kgyrtkirk", "createdAt": "2020-05-29T13:25:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyODU1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyOTQ3Mw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432129473", "bodyText": "Is this needed?", "author": "jcamachor", "createdAt": "2020-05-28T21:18:47Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject instanceof Project && ((Project) newProject).getChildExps().equals(project.getChildExps())) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected RelNode processProject(Project project) {\n+        relBuilder.push(project.getInput());\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+                newProjects.add(expr.accept(shuttle));\n+        }\n+        relBuilder.project(newProjects);\n+        return relBuilder.build();\n+      }\n+\n+      private final RexNode processCall(RexNode expr) {\n+        if (expr instanceof RexOver) {\n+          RexOver over = (RexOver) expr;\n+          if (isApplicable(over)) {\n+            return rewrite(over);\n+          }\n+        }\n+        return expr;\n+      }\n+\n+      protected final SqlOperator getSqlOperator(String fnName) {\n+        UDFDescriptor fn = DataSketchesFunctions.INSTANCE.getSketchFunction(sketchClass, fnName);\n+        if (!fn.getCalciteFunction().isPresent()) {\n+          throw new RuntimeException(fn.toString() + \" doesn't have a Calcite function associated with it\");\n+        }\n+        return fn.getCalciteFunction().get();\n+      }\n+\n+      abstract RexNode rewrite(RexOver expr);\n+\n+      abstract boolean isApplicable(RexOver expr);\n+\n+    }\n+\n+  }\n+\n+  public static class CumeDistRewrite extends WindowingToProjectAggregateJoinProject {\n+\n+    public CumeDistRewrite(String sketchType) {\n+      super(sketchType);\n+    }\n+\n+    @Override\n+    protected VbuilderPAP buildProcessor(RelOptRuleCall call) {\n+      return new VB(sketchType, call.builder());\n+    }\n+\n+    private static class VB extends VbuilderPAP {\n+\n+      protected VB(String sketchClass, RelBuilder relBuilder) {\n+        super(sketchClass, relBuilder);\n+      }\n+\n+      @Override\n+      boolean isApplicable(RexOver over) {\n+        SqlAggFunction aggOp = over.getAggOperator();\n+        RexWindow window = over.getWindow();\n+        if (aggOp.getName().equalsIgnoreCase(\"cume_dist\") && window.orderKeys.size() == 1\n+            && window.getLowerBound().isUnbounded() && window.getUpperBound().isUnbounded()) {\n+          return true;\n+        }\n+        return false;\n+      }\n+\n+      @Override\n+      RexNode rewrite(RexOver over) {\n+\n+        over.getOperands();\n+        RexWindow w = over.getWindow();\n+\n+        RexFieldCollation orderKey = w.orderKeys.get(0);\n+        // we don't really support nulls in aggregate/etc...they are actually ignored\n+        // so some hack will be needed for NULLs anyway..\n+        ImmutableList<RexNode> partitionKeys = w.partitionKeys;\n+\n+        relBuilder.push(relBuilder.peek());", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjMxMDg2Ng==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432310866", "bodyText": "yes; this is the point where the other side of the join is getting started to being built\nadded some explanation to the #rewrite method about this", "author": "kgyrtkirk", "createdAt": "2020-05-29T07:43:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyOTQ3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEzOTI5NQ==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432139295", "bodyText": "Maybe it would have been easier to rely on the agg function in the relBuilder?", "author": "jcamachor", "createdAt": "2020-05-28T21:39:08Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject instanceof Project && ((Project) newProject).getChildExps().equals(project.getChildExps())) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected RelNode processProject(Project project) {\n+        relBuilder.push(project.getInput());\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+                newProjects.add(expr.accept(shuttle));\n+        }\n+        relBuilder.project(newProjects);\n+        return relBuilder.build();\n+      }\n+\n+      private final RexNode processCall(RexNode expr) {\n+        if (expr instanceof RexOver) {\n+          RexOver over = (RexOver) expr;\n+          if (isApplicable(over)) {\n+            return rewrite(over);\n+          }\n+        }\n+        return expr;\n+      }\n+\n+      protected final SqlOperator getSqlOperator(String fnName) {\n+        UDFDescriptor fn = DataSketchesFunctions.INSTANCE.getSketchFunction(sketchClass, fnName);\n+        if (!fn.getCalciteFunction().isPresent()) {\n+          throw new RuntimeException(fn.toString() + \" doesn't have a Calcite function associated with it\");\n+        }\n+        return fn.getCalciteFunction().get();\n+      }\n+\n+      abstract RexNode rewrite(RexOver expr);\n+\n+      abstract boolean isApplicable(RexOver expr);\n+\n+    }\n+\n+  }\n+\n+  public static class CumeDistRewrite extends WindowingToProjectAggregateJoinProject {\n+\n+    public CumeDistRewrite(String sketchType) {\n+      super(sketchType);\n+    }\n+\n+    @Override\n+    protected VbuilderPAP buildProcessor(RelOptRuleCall call) {\n+      return new VB(sketchType, call.builder());\n+    }\n+\n+    private static class VB extends VbuilderPAP {\n+\n+      protected VB(String sketchClass, RelBuilder relBuilder) {\n+        super(sketchClass, relBuilder);\n+      }\n+\n+      @Override\n+      boolean isApplicable(RexOver over) {\n+        SqlAggFunction aggOp = over.getAggOperator();\n+        RexWindow window = over.getWindow();\n+        if (aggOp.getName().equalsIgnoreCase(\"cume_dist\") && window.orderKeys.size() == 1\n+            && window.getLowerBound().isUnbounded() && window.getUpperBound().isUnbounded()) {\n+          return true;\n+        }\n+        return false;\n+      }\n+\n+      @Override\n+      RexNode rewrite(RexOver over) {\n+\n+        over.getOperands();\n+        RexWindow w = over.getWindow();\n+\n+        RexFieldCollation orderKey = w.orderKeys.get(0);\n+        // we don't really support nulls in aggregate/etc...they are actually ignored\n+        // so some hack will be needed for NULLs anyway..\n+        ImmutableList<RexNode> partitionKeys = w.partitionKeys;\n+\n+        relBuilder.push(relBuilder.peek());\n+        // the CDF function utilizes the '<' operator;\n+        // negating the input will mirror the values on the x axis\n+        // by using 1-CDF(-x) we could get a <= operator\n+        RexNode key = orderKey.getKey();\n+        key = rexBuilder.makeCall(SqlStdOperatorTable.UNARY_MINUS, key);\n+        key = rexBuilder.makeCast(getFloatType(), key);\n+\n+        ImmutableList<RexNode> projExprs = ImmutableList.<RexNode>builder().addAll(partitionKeys).add(key).build();\n+        relBuilder.project(projExprs);\n+        ImmutableBitSet groupSets = ImmutableBitSet.range(partitionKeys.size());\n+\n+        SqlAggFunction aggFunction = (SqlAggFunction) getSqlOperator(DataSketchesFunctions.DATA_TO_SKETCH);\n+        boolean distinct = false;\n+        boolean approximate = true;\n+        boolean ignoreNulls = true;\n+        List<Integer> argList = Lists.newArrayList(partitionKeys.size());\n+        int filterArg = -1;\n+        RelCollation collation = RelCollations.EMPTY;\n+        RelDataType type = rexBuilder.deriveReturnType(aggFunction, Collections.emptyList());\n+        String name = aggFunction.getName();\n+        AggregateCall newAgg = AggregateCall.create(aggFunction, distinct, approximate, ignoreNulls, argList, filterArg,\n+                      collation, type, name);\n+\n+        RelNode agg = HiveRelFactories.HIVE_AGGREGATE_FACTORY.createAggregate(", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExNTY4Ng==", "url": "https://github.com/apache/hive/pull/1031#discussion_r434115686", "bodyText": "I've tried this when I was not yet ready with the patch - then I abandoned it.\nNow that everything was working it was possible to do also do this.\nNote that this needs a few small changes including one in HiveRelBuilder to expose the more advanced aggregate method as public", "author": "kgyrtkirk", "createdAt": "2020-06-02T19:10:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEzOTI5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0MTE3Nw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432141177", "bodyText": "nit. newline", "author": "jcamachor", "createdAt": "2020-05-28T21:43:30Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject instanceof Project && ((Project) newProject).getChildExps().equals(project.getChildExps())) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected RelNode processProject(Project project) {\n+        relBuilder.push(project.getInput());\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+                newProjects.add(expr.accept(shuttle));\n+        }\n+        relBuilder.project(newProjects);\n+        return relBuilder.build();\n+      }\n+\n+      private final RexNode processCall(RexNode expr) {\n+        if (expr instanceof RexOver) {\n+          RexOver over = (RexOver) expr;\n+          if (isApplicable(over)) {\n+            return rewrite(over);\n+          }\n+        }\n+        return expr;\n+      }\n+\n+      protected final SqlOperator getSqlOperator(String fnName) {\n+        UDFDescriptor fn = DataSketchesFunctions.INSTANCE.getSketchFunction(sketchClass, fnName);\n+        if (!fn.getCalciteFunction().isPresent()) {\n+          throw new RuntimeException(fn.toString() + \" doesn't have a Calcite function associated with it\");\n+        }\n+        return fn.getCalciteFunction().get();\n+      }\n+\n+      abstract RexNode rewrite(RexOver expr);\n+\n+      abstract boolean isApplicable(RexOver expr);\n+\n+    }\n+\n+  }\n+\n+  public static class CumeDistRewrite extends WindowingToProjectAggregateJoinProject {\n+\n+    public CumeDistRewrite(String sketchType) {\n+      super(sketchType);\n+    }\n+\n+    @Override\n+    protected VbuilderPAP buildProcessor(RelOptRuleCall call) {\n+      return new VB(sketchType, call.builder());\n+    }\n+\n+    private static class VB extends VbuilderPAP {\n+\n+      protected VB(String sketchClass, RelBuilder relBuilder) {\n+        super(sketchClass, relBuilder);\n+      }\n+\n+      @Override\n+      boolean isApplicable(RexOver over) {\n+        SqlAggFunction aggOp = over.getAggOperator();\n+        RexWindow window = over.getWindow();\n+        if (aggOp.getName().equalsIgnoreCase(\"cume_dist\") && window.orderKeys.size() == 1\n+            && window.getLowerBound().isUnbounded() && window.getUpperBound().isUnbounded()) {\n+          return true;\n+        }\n+        return false;\n+      }\n+\n+      @Override\n+      RexNode rewrite(RexOver over) {\n+\n+        over.getOperands();\n+        RexWindow w = over.getWindow();\n+\n+        RexFieldCollation orderKey = w.orderKeys.get(0);\n+        // we don't really support nulls in aggregate/etc...they are actually ignored\n+        // so some hack will be needed for NULLs anyway..\n+        ImmutableList<RexNode> partitionKeys = w.partitionKeys;\n+\n+        relBuilder.push(relBuilder.peek());\n+        // the CDF function utilizes the '<' operator;\n+        // negating the input will mirror the values on the x axis\n+        // by using 1-CDF(-x) we could get a <= operator\n+        RexNode key = orderKey.getKey();\n+        key = rexBuilder.makeCall(SqlStdOperatorTable.UNARY_MINUS, key);\n+        key = rexBuilder.makeCast(getFloatType(), key);\n+\n+        ImmutableList<RexNode> projExprs = ImmutableList.<RexNode>builder().addAll(partitionKeys).add(key).build();\n+        relBuilder.project(projExprs);\n+        ImmutableBitSet groupSets = ImmutableBitSet.range(partitionKeys.size());\n+\n+        SqlAggFunction aggFunction = (SqlAggFunction) getSqlOperator(DataSketchesFunctions.DATA_TO_SKETCH);\n+        boolean distinct = false;\n+        boolean approximate = true;\n+        boolean ignoreNulls = true;\n+        List<Integer> argList = Lists.newArrayList(partitionKeys.size());\n+        int filterArg = -1;\n+        RelCollation collation = RelCollations.EMPTY;\n+        RelDataType type = rexBuilder.deriveReturnType(aggFunction, Collections.emptyList());\n+        String name = aggFunction.getName();\n+        AggregateCall newAgg = AggregateCall.create(aggFunction, distinct, approximate, ignoreNulls, argList, filterArg,\n+                      collation, type, name);\n+\n+        RelNode agg = HiveRelFactories.HIVE_AGGREGATE_FACTORY.createAggregate(\n+            relBuilder.build(),\n+            groupSets, ImmutableList.of(groupSets),\n+            Lists.newArrayList(newAgg));\n+        relBuilder.push(agg);\n+\n+        List<RexNode> joinConditions;\n+        joinConditions = Ord.zip(partitionKeys).stream().map(o -> {\n+          RexNode f = relBuilder.field(2, 1, o.i);\n+          return rexBuilder.makeCall(SqlStdOperatorTable.EQUALS, o.e, f);\n+        }).collect(Collectors.toList());\n+        relBuilder.join(JoinRelType.INNER, joinConditions);\n+\n+        int sketchFieldIndex = relBuilder.peek().getRowType().getFieldCount() - 1;\n+        RexInputRef sketchInputRef = relBuilder.field(sketchFieldIndex);\n+        SqlOperator projectOperator = getSqlOperator(DataSketchesFunctions.GET_CDF);\n+\n+        // NULLs will be replaced by this value - to be before / after the other values\n+        // note: the sketch will ignore NULLs entirely but they will be placed at 0.0 or 1.0\n+        final RexNode nullReplacement =\n+            relBuilder.literal(orderKey.getNullDirection() == NullDirection.FIRST ? Float.MAX_VALUE : -Float.MAX_VALUE);\n+\n+        // long story short: CAST(1.0f-CDF(CAST(COALESCE(-X, nullReplacement) AS FLOAT))[0] AS targetType)\n+        RexNode projRex = key;\n+        projRex = rexBuilder.makeCall(SqlStdOperatorTable.COALESCE, key, nullReplacement);\n+        projRex = rexBuilder.makeCast(getFloatType(), projRex);\n+        projRex = rexBuilder.makeCall(projectOperator, ImmutableList.of(sketchInputRef, projRex));\n+        projRex = makeItemCall(projRex, relBuilder.literal(0));\n+        projRex = rexBuilder.makeCall(SqlStdOperatorTable.MINUS, relBuilder.literal(1.0f), projRex);\n+        projRex = rexBuilder.makeCast(over.getType(), projRex);\n+\n+        return projRex;\n+      }\n+\n+      private RexNode makeItemCall(RexNode arr, RexNode offset) {\n+", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0MTQwOA==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432141408", "bodyText": "??", "author": "jcamachor", "createdAt": "2020-05-28T21:44:03Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/rules/HiveRewriteToDataSketchesRules.java", "diffHunk": "@@ -368,4 +389,216 @@ void rewrite(AggregateCall aggCall) {\n       }\n     }\n   }\n+\n+  /**\n+   * Generic support for rewriting Windowing expression into a different form usually using joins.\n+   */\n+  private static abstract class WindowingToProjectAggregateJoinProject extends RelOptRule {\n+\n+    protected final String sketchType;\n+\n+    public WindowingToProjectAggregateJoinProject(String sketchType) {\n+      super(operand(HiveProject.class, any()));\n+      this.sketchType = sketchType;\n+    }\n+\n+    @Override\n+    public void onMatch(RelOptRuleCall call) {\n+\n+      final Project project = call.rel(0);\n+\n+      VbuilderPAP vb = buildProcessor(call);\n+      RelNode newProject = vb.processProject(project);\n+\n+      if (newProject instanceof Project && ((Project) newProject).getChildExps().equals(project.getChildExps())) {\n+        return;\n+      } else {\n+        call.transformTo(newProject);\n+      }\n+    }\n+\n+    protected abstract VbuilderPAP buildProcessor(RelOptRuleCall call);\n+\n+\n+    protected static abstract class VbuilderPAP {\n+      private final String sketchClass;\n+      protected final RelBuilder relBuilder;\n+      protected final RexBuilder rexBuilder;\n+\n+      protected VbuilderPAP(String sketchClass, RelBuilder relBuilder) {\n+        this.sketchClass = sketchClass;\n+        this.relBuilder = relBuilder;\n+        rexBuilder = relBuilder.getRexBuilder();\n+      }\n+\n+      final class ProcessShuttle extends RexShuttle {\n+        public RexNode visitOver(RexOver over) {\n+          return processCall(over);\n+        }\n+      };\n+\n+      protected RelNode processProject(Project project) {\n+        relBuilder.push(project.getInput());\n+        RexShuttle shuttle = new ProcessShuttle();\n+        List<RexNode> newProjects = new ArrayList<RexNode>();\n+        for (RexNode expr : project.getChildExps()) {\n+                newProjects.add(expr.accept(shuttle));\n+        }\n+        relBuilder.project(newProjects);\n+        return relBuilder.build();\n+      }\n+\n+      private final RexNode processCall(RexNode expr) {\n+        if (expr instanceof RexOver) {\n+          RexOver over = (RexOver) expr;\n+          if (isApplicable(over)) {\n+            return rewrite(over);\n+          }\n+        }\n+        return expr;\n+      }\n+\n+      protected final SqlOperator getSqlOperator(String fnName) {\n+        UDFDescriptor fn = DataSketchesFunctions.INSTANCE.getSketchFunction(sketchClass, fnName);\n+        if (!fn.getCalciteFunction().isPresent()) {\n+          throw new RuntimeException(fn.toString() + \" doesn't have a Calcite function associated with it\");\n+        }\n+        return fn.getCalciteFunction().get();\n+      }\n+\n+      abstract RexNode rewrite(RexOver expr);\n+\n+      abstract boolean isApplicable(RexOver expr);\n+\n+    }\n+\n+  }\n+\n+  public static class CumeDistRewrite extends WindowingToProjectAggregateJoinProject {\n+\n+    public CumeDistRewrite(String sketchType) {\n+      super(sketchType);\n+    }\n+\n+    @Override\n+    protected VbuilderPAP buildProcessor(RelOptRuleCall call) {\n+      return new VB(sketchType, call.builder());\n+    }\n+\n+    private static class VB extends VbuilderPAP {\n+\n+      protected VB(String sketchClass, RelBuilder relBuilder) {\n+        super(sketchClass, relBuilder);\n+      }\n+\n+      @Override\n+      boolean isApplicable(RexOver over) {\n+        SqlAggFunction aggOp = over.getAggOperator();\n+        RexWindow window = over.getWindow();\n+        if (aggOp.getName().equalsIgnoreCase(\"cume_dist\") && window.orderKeys.size() == 1\n+            && window.getLowerBound().isUnbounded() && window.getUpperBound().isUnbounded()) {\n+          return true;\n+        }\n+        return false;\n+      }\n+\n+      @Override\n+      RexNode rewrite(RexOver over) {\n+\n+        over.getOperands();\n+        RexWindow w = over.getWindow();\n+\n+        RexFieldCollation orderKey = w.orderKeys.get(0);\n+        // we don't really support nulls in aggregate/etc...they are actually ignored\n+        // so some hack will be needed for NULLs anyway..\n+        ImmutableList<RexNode> partitionKeys = w.partitionKeys;\n+\n+        relBuilder.push(relBuilder.peek());\n+        // the CDF function utilizes the '<' operator;\n+        // negating the input will mirror the values on the x axis\n+        // by using 1-CDF(-x) we could get a <= operator\n+        RexNode key = orderKey.getKey();\n+        key = rexBuilder.makeCall(SqlStdOperatorTable.UNARY_MINUS, key);\n+        key = rexBuilder.makeCast(getFloatType(), key);\n+\n+        ImmutableList<RexNode> projExprs = ImmutableList.<RexNode>builder().addAll(partitionKeys).add(key).build();\n+        relBuilder.project(projExprs);\n+        ImmutableBitSet groupSets = ImmutableBitSet.range(partitionKeys.size());\n+\n+        SqlAggFunction aggFunction = (SqlAggFunction) getSqlOperator(DataSketchesFunctions.DATA_TO_SKETCH);\n+        boolean distinct = false;\n+        boolean approximate = true;\n+        boolean ignoreNulls = true;\n+        List<Integer> argList = Lists.newArrayList(partitionKeys.size());\n+        int filterArg = -1;\n+        RelCollation collation = RelCollations.EMPTY;\n+        RelDataType type = rexBuilder.deriveReturnType(aggFunction, Collections.emptyList());\n+        String name = aggFunction.getName();\n+        AggregateCall newAgg = AggregateCall.create(aggFunction, distinct, approximate, ignoreNulls, argList, filterArg,\n+                      collation, type, name);\n+\n+        RelNode agg = HiveRelFactories.HIVE_AGGREGATE_FACTORY.createAggregate(\n+            relBuilder.build(),\n+            groupSets, ImmutableList.of(groupSets),\n+            Lists.newArrayList(newAgg));\n+        relBuilder.push(agg);\n+\n+        List<RexNode> joinConditions;\n+        joinConditions = Ord.zip(partitionKeys).stream().map(o -> {\n+          RexNode f = relBuilder.field(2, 1, o.i);\n+          return rexBuilder.makeCall(SqlStdOperatorTable.EQUALS, o.e, f);\n+        }).collect(Collectors.toList());\n+        relBuilder.join(JoinRelType.INNER, joinConditions);\n+\n+        int sketchFieldIndex = relBuilder.peek().getRowType().getFieldCount() - 1;\n+        RexInputRef sketchInputRef = relBuilder.field(sketchFieldIndex);\n+        SqlOperator projectOperator = getSqlOperator(DataSketchesFunctions.GET_CDF);\n+\n+        // NULLs will be replaced by this value - to be before / after the other values\n+        // note: the sketch will ignore NULLs entirely but they will be placed at 0.0 or 1.0\n+        final RexNode nullReplacement =\n+            relBuilder.literal(orderKey.getNullDirection() == NullDirection.FIRST ? Float.MAX_VALUE : -Float.MAX_VALUE);\n+\n+        // long story short: CAST(1.0f-CDF(CAST(COALESCE(-X, nullReplacement) AS FLOAT))[0] AS targetType)\n+        RexNode projRex = key;\n+        projRex = rexBuilder.makeCall(SqlStdOperatorTable.COALESCE, key, nullReplacement);\n+        projRex = rexBuilder.makeCast(getFloatType(), projRex);\n+        projRex = rexBuilder.makeCall(projectOperator, ImmutableList.of(sketchInputRef, projRex));\n+        projRex = makeItemCall(projRex, relBuilder.literal(0));\n+        projRex = rexBuilder.makeCall(SqlStdOperatorTable.MINUS, relBuilder.literal(1.0f), projRex);\n+        projRex = rexBuilder.makeCast(over.getType(), projRex);\n+\n+        return projRex;\n+      }\n+\n+      private RexNode makeItemCall(RexNode arr, RexNode offset) {\n+\n+        if(getClass().desiredAssertionStatus()) {\n+          try {\n+            SqlKind.class.getField(\"ITEM\");\n+            throw new RuntimeException(\"bind SqlKind.ITEM instead of this workaround - C1.23 a02155a70a\");", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjMxNTQ4Ng==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432315486", "bodyText": "SqlKind.ITEM was introduced only recently in 1.23...this check is here to throw an error after we've upgraded\nall these things in this method would be unneccessary if SqlKind.ITEM would be available...\na simple rexBuilder.makeCall(SqlStdOperatorTable.ITEM, arr, offset)", "author": "kgyrtkirk", "createdAt": "2020-05-29T07:52:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0MTQwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE0MjEzMw==", "url": "https://github.com/apache/hive/pull/1031#discussion_r432142133", "bodyText": "Should this be removed?", "author": "jcamachor", "createdAt": "2020-05-28T21:45:46Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/translator/SqlFunctionConverter.java", "diffHunk": "@@ -672,6 +673,15 @@ public static SqlAggFunction getCalciteAggFn(String hiveUdfName, boolean isDisti\n             udfInfo.operandTypeInference,\n             udfInfo.operandTypeChecker);\n         break;\n+      case \"cume_dist\":", "originalCommit": "5bde236e6c5bcd744baf878ba7f1377dbc81f1d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "dafddf6b8bbbdbb4bbd5d41fb38c922746b06d79", "url": "https://github.com/apache/hive/commit/dafddf6b8bbbdbb4bbd5d41fb38c922746b06d79", "message": "address review comments", "committedDate": "2020-05-29T07:54:03Z", "type": "commit"}]}