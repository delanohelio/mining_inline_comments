{"pr_number": 1480, "pr_title": "Complete UndeleteOperation and add UndeleteOperationTracker", "pr_createdAt": "2020-04-21T02:16:39Z", "pr_url": "https://github.com/linkedin/ambry/pull/1480", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkzNTgzMA==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r413935830", "bodyText": "According to the design doc, the quorum target for the UNDELETE should be 2 per DC. Is there a follow up PR for this?", "author": "zzmao", "createdAt": "2020-04-23T16:17:48Z", "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "diffHunk": "@@ -121,8 +122,9 @@\n    * |     PUT          |           N                     |       N - 1      |\n    * |    DELETE        |          3~N                    |         2        |\n    * |   TTLUpdate      |          3~N                    |         2        |\n+   * |   UNDELETE       |          3~N                    |         2        |", "originalCommit": "5125da1335c70af075d5781b916db638cbed56f9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "88eaa9baa670727d7b08315c8e2232854c9e6378", "url": "https://github.com/linkedin/ambry/commit/88eaa9baa670727d7b08315c8e2232854c9e6378", "message": "Comments", "committedDate": "2020-04-23T18:23:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjA3NDczNQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416074735", "bodyText": "if there are machines that are offline, they won't be included in this set. Is it okay to ignore them? I believe this policy currently says that an undelete needs 100% success from replicas that are currently up.", "author": "cgtz", "createdAt": "2020-04-27T19:05:35Z", "path": "ambry-router/src/main/java/com/github/ambry/router/SimpleOperationTracker.java", "diffHunk": "@@ -176,6 +179,15 @@\n         eligibleReplicas = getEligibleReplicas(partitionId, null,\n             EnumSet.of(ReplicaState.BOOTSTRAP, ReplicaState.STANDBY, ReplicaState.LEADER));\n         break;\n+      case UndeleteOperation:\n+        diskParallelism = routerConfig.routerUndeleteRequestParallelism;\n+        crossColoEnabled = true;\n+        eligibleReplicas = getEligibleReplicas(partitionId, null,\n+            EnumSet.of(ReplicaState.BOOTSTRAP, ReplicaState.STANDBY, ReplicaState.LEADER));", "originalCommit": "88eaa9baa670727d7b08315c8e2232854c9e6378", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjExMTc2OQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416111769", "bodyText": "non-eligible hosts would be considered as a failure. for instance, if a dc has three hosts, and one is offline, then starting from the beginning, we already have a failure hosts. If we see another hosts returning a failure response, then the operation is considered as failed. But if the other two both return success, then undelete operation still is valid.", "author": "justinlin-linkedin", "createdAt": "2020-04-27T20:06:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjA3NDczNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjc1MTE4MQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416751181", "bodyText": "Ah, I think I got confused by the setting of disk success target, but that seems to just be a dummy value and isn't used anywhere in UndeleteOperationTracker.", "author": "cgtz", "createdAt": "2020-04-28T16:24:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjA3NDczNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk3NDMyOQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r415974329", "bodyText": "Is this parallelism for each dc or all dcs (that is, total # of inflight requests in all colos <= parallelism)?", "author": "jsjtzyy", "createdAt": "2020-04-27T16:43:27Z", "path": "ambry-api/src/main/java/com/github/ambry/config/RouterConfig.java", "diffHunk": "@@ -324,6 +325,13 @@\n   @Default(\"2\")\n   public final int routerTtlUpdateSuccessTarget;\n \n+  /**\n+   * The maximum number of parallel requests issued at a time by the undelete manager for a blob.\n+   */\n+  @Config(ROUTER_UNDELETE_REQUEST_PARALLELISM)\n+  @Default(\"3\")\n+  public final int routerUndeleteRequestParallelism;", "originalCommit": "88eaa9baa670727d7b08315c8e2232854c9e6378", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjEwOTk4MQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416109981", "bodyText": "it's the same meaning as other request's parallelism. If we have more than one DC, then it's on all DCs.", "author": "justinlin-linkedin", "createdAt": "2020-04-27T20:03:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk3NDMyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk4Mzc5NQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r415983795", "bodyText": "Is this if required? Seems it can removed.", "author": "jsjtzyy", "createdAt": "2020-04-27T16:56:03Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private Map<String, Integer> numReplicasInDcs = new HashMap<>();\n+  private Map<String, Integer> numSuccessInDcs = new HashMap<>();\n+  private Map<String, Integer> numFailureInDcs = new HashMap<>();\n+\n+  /**\n+   * Constructs an {@link UndeleteOperationTracker}\n+   * @param routerConfig The {@link RouterConfig} containing the configs for operation tracker.\n+   * @param partitionId The partition on which the operation is performed.\n+   * @param originatingDcName name of originating DC whose replicas should be tried first.\n+   */\n+  UndeleteOperationTracker(RouterConfig routerConfig, PartitionId partitionId, String originatingDcName) {\n+    super(routerConfig, RouterOperation.UndeleteOperation, partitionId, originatingDcName, false);\n+    List<? extends ReplicaId> replicas = partitionId.getReplicaIds();\n+    for (ReplicaId replica : replicas) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numReplicasInDcs.put(dcName, numReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+    Map<String, Integer> numEligibleReplicasInDcs = new HashMap<>();\n+    for (ReplicaId replica : replicaPool) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numEligibleReplicasInDcs.put(dcName, numEligibleReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+\n+    if (!hasReachedGlobalQuorum(numReplicasInDcs, numEligibleReplicasInDcs)) {\n+      throw new IllegalArgumentException(\n+          \"Eligible replicas are not sufficient for undelete operation for partition \" + partitionId);\n+    }\n+    // Consider not-eligible hosts as failure\n+    for (String dcName : numReplicasInDcs.keySet()) {\n+      int totalNum = numReplicasInDcs.get(dcName);\n+      if (numEligibleReplicasInDcs.containsKey(dcName)) {\n+        int eligibleNum = numEligibleReplicasInDcs.get(dcName);\n+        if (eligibleNum != totalNum) {", "originalCommit": "88eaa9baa670727d7b08315c8e2232854c9e6378", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjEyODI3OQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416128279", "bodyText": "updated.", "author": "justinlin-linkedin", "createdAt": "2020-04-27T20:32:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk4Mzc5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk4NTM2MQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r415985361", "bodyText": "nit: has reached", "author": "jsjtzyy", "createdAt": "2020-04-27T16:58:01Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private Map<String, Integer> numReplicasInDcs = new HashMap<>();\n+  private Map<String, Integer> numSuccessInDcs = new HashMap<>();\n+  private Map<String, Integer> numFailureInDcs = new HashMap<>();\n+\n+  /**\n+   * Constructs an {@link UndeleteOperationTracker}\n+   * @param routerConfig The {@link RouterConfig} containing the configs for operation tracker.\n+   * @param partitionId The partition on which the operation is performed.\n+   * @param originatingDcName name of originating DC whose replicas should be tried first.\n+   */\n+  UndeleteOperationTracker(RouterConfig routerConfig, PartitionId partitionId, String originatingDcName) {\n+    super(routerConfig, RouterOperation.UndeleteOperation, partitionId, originatingDcName, false);\n+    List<? extends ReplicaId> replicas = partitionId.getReplicaIds();\n+    for (ReplicaId replica : replicas) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numReplicasInDcs.put(dcName, numReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+    Map<String, Integer> numEligibleReplicasInDcs = new HashMap<>();\n+    for (ReplicaId replica : replicaPool) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numEligibleReplicasInDcs.put(dcName, numEligibleReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+\n+    if (!hasReachedGlobalQuorum(numReplicasInDcs, numEligibleReplicasInDcs)) {\n+      throw new IllegalArgumentException(\n+          \"Eligible replicas are not sufficient for undelete operation for partition \" + partitionId);\n+    }\n+    // Consider not-eligible hosts as failure\n+    for (String dcName : numReplicasInDcs.keySet()) {\n+      int totalNum = numReplicasInDcs.get(dcName);\n+      if (numEligibleReplicasInDcs.containsKey(dcName)) {\n+        int eligibleNum = numEligibleReplicasInDcs.get(dcName);\n+        if (eligibleNum != totalNum) {\n+          numFailureInDcs.put(dcName, totalNum - eligibleNum);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void onResponse(ReplicaId replicaId, TrackedRequestFinalState trackedRequestFinalState) {\n+    super.onResponse(replicaId, trackedRequestFinalState);\n+    String dcName = replicaId.getDataNodeId().getDatacenterName();\n+    if (trackedRequestFinalState == TrackedRequestFinalState.SUCCESS) {\n+      numSuccessInDcs.put(dcName, numSuccessInDcs.getOrDefault(dcName, 0) + 1);\n+    } else {\n+      numFailureInDcs.put(dcName, numFailureInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+  }\n+\n+  @Override\n+  public boolean hasSucceeded() {\n+    return hasReachedGlobalQuorum(numReplicasInDcs, numSuccessInDcs);\n+  }\n+\n+  @Override\n+  public boolean hasFailed() {\n+    return hasReachedAnyLocalQuorum(numReplicasInDcs, numFailureInDcs);\n+  }\n+\n+  /**\n+   * Return true if the {@code currentNumberInDcs}'s each value has reaches the quorum of corresponding value\n+   * in {@code totalNumberInDcs}.\n+   * @param totalNumberInDcs The total number of members in each datacenter.\n+   * @param currentNumberInDcs The current number of members in each datacenter.\n+   * @return true if current numbers reach the global quorum.\n+   */\n+  private static boolean hasReachedGlobalQuorum(Map<String, Integer> totalNumberInDcs,\n+      Map<String, Integer> currentNumberInDcs) {\n+    boolean hasReached = true;\n+    if (totalNumberInDcs.size() == currentNumberInDcs.size()) {\n+      for (String dcName : totalNumberInDcs.keySet()) {\n+        int totalNum = totalNumberInDcs.get(dcName);\n+        int currentNum = currentNumberInDcs.get(dcName);\n+        if (totalNum != 1 && currentNum <= totalNum / 2) {\n+          hasReached = false;\n+          break;\n+        }\n+      }\n+    } else {\n+      hasReached = false;\n+    }\n+    return hasReached;\n+  }\n+\n+  /**\n+   * Return true if any of the {@code currentNumberInDcs}'s value has reaches the quorum of corresponding value", "originalCommit": "88eaa9baa670727d7b08315c8e2232854c9e6378", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk5NzAxMg==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r415997012", "bodyText": "why we need totalNum != 1?  I think currentNum <= totalNum / 2 also applies to video cluster where some colos have only 1 replica.", "author": "jsjtzyy", "createdAt": "2020-04-27T17:14:27Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private Map<String, Integer> numReplicasInDcs = new HashMap<>();\n+  private Map<String, Integer> numSuccessInDcs = new HashMap<>();\n+  private Map<String, Integer> numFailureInDcs = new HashMap<>();\n+\n+  /**\n+   * Constructs an {@link UndeleteOperationTracker}\n+   * @param routerConfig The {@link RouterConfig} containing the configs for operation tracker.\n+   * @param partitionId The partition on which the operation is performed.\n+   * @param originatingDcName name of originating DC whose replicas should be tried first.\n+   */\n+  UndeleteOperationTracker(RouterConfig routerConfig, PartitionId partitionId, String originatingDcName) {\n+    super(routerConfig, RouterOperation.UndeleteOperation, partitionId, originatingDcName, false);\n+    List<? extends ReplicaId> replicas = partitionId.getReplicaIds();\n+    for (ReplicaId replica : replicas) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numReplicasInDcs.put(dcName, numReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+    Map<String, Integer> numEligibleReplicasInDcs = new HashMap<>();\n+    for (ReplicaId replica : replicaPool) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numEligibleReplicasInDcs.put(dcName, numEligibleReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+\n+    if (!hasReachedGlobalQuorum(numReplicasInDcs, numEligibleReplicasInDcs)) {\n+      throw new IllegalArgumentException(\n+          \"Eligible replicas are not sufficient for undelete operation for partition \" + partitionId);\n+    }\n+    // Consider not-eligible hosts as failure\n+    for (String dcName : numReplicasInDcs.keySet()) {\n+      int totalNum = numReplicasInDcs.get(dcName);\n+      if (numEligibleReplicasInDcs.containsKey(dcName)) {\n+        int eligibleNum = numEligibleReplicasInDcs.get(dcName);\n+        if (eligibleNum != totalNum) {\n+          numFailureInDcs.put(dcName, totalNum - eligibleNum);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void onResponse(ReplicaId replicaId, TrackedRequestFinalState trackedRequestFinalState) {\n+    super.onResponse(replicaId, trackedRequestFinalState);\n+    String dcName = replicaId.getDataNodeId().getDatacenterName();\n+    if (trackedRequestFinalState == TrackedRequestFinalState.SUCCESS) {\n+      numSuccessInDcs.put(dcName, numSuccessInDcs.getOrDefault(dcName, 0) + 1);\n+    } else {\n+      numFailureInDcs.put(dcName, numFailureInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+  }\n+\n+  @Override\n+  public boolean hasSucceeded() {\n+    return hasReachedGlobalQuorum(numReplicasInDcs, numSuccessInDcs);\n+  }\n+\n+  @Override\n+  public boolean hasFailed() {\n+    return hasReachedAnyLocalQuorum(numReplicasInDcs, numFailureInDcs);\n+  }\n+\n+  /**\n+   * Return true if the {@code currentNumberInDcs}'s each value has reaches the quorum of corresponding value\n+   * in {@code totalNumberInDcs}.\n+   * @param totalNumberInDcs The total number of members in each datacenter.\n+   * @param currentNumberInDcs The current number of members in each datacenter.\n+   * @return true if current numbers reach the global quorum.\n+   */\n+  private static boolean hasReachedGlobalQuorum(Map<String, Integer> totalNumberInDcs,\n+      Map<String, Integer> currentNumberInDcs) {\n+    boolean hasReached = true;\n+    if (totalNumberInDcs.size() == currentNumberInDcs.size()) {\n+      for (String dcName : totalNumberInDcs.keySet()) {\n+        int totalNum = totalNumberInDcs.get(dcName);\n+        int currentNum = currentNumberInDcs.get(dcName);\n+        if (totalNum != 1 && currentNum <= totalNum / 2) {", "originalCommit": "88eaa9baa670727d7b08315c8e2232854c9e6378", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjEyODQxMQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416128411", "bodyText": "you are right, updated.", "author": "justinlin-linkedin", "createdAt": "2020-04-27T20:33:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk5NzAxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk5NzQzNQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r415997435", "bodyText": "has reached", "author": "jsjtzyy", "createdAt": "2020-04-27T17:15:04Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private Map<String, Integer> numReplicasInDcs = new HashMap<>();\n+  private Map<String, Integer> numSuccessInDcs = new HashMap<>();\n+  private Map<String, Integer> numFailureInDcs = new HashMap<>();\n+\n+  /**\n+   * Constructs an {@link UndeleteOperationTracker}\n+   * @param routerConfig The {@link RouterConfig} containing the configs for operation tracker.\n+   * @param partitionId The partition on which the operation is performed.\n+   * @param originatingDcName name of originating DC whose replicas should be tried first.\n+   */\n+  UndeleteOperationTracker(RouterConfig routerConfig, PartitionId partitionId, String originatingDcName) {\n+    super(routerConfig, RouterOperation.UndeleteOperation, partitionId, originatingDcName, false);\n+    List<? extends ReplicaId> replicas = partitionId.getReplicaIds();\n+    for (ReplicaId replica : replicas) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numReplicasInDcs.put(dcName, numReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+    Map<String, Integer> numEligibleReplicasInDcs = new HashMap<>();\n+    for (ReplicaId replica : replicaPool) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numEligibleReplicasInDcs.put(dcName, numEligibleReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+\n+    if (!hasReachedGlobalQuorum(numReplicasInDcs, numEligibleReplicasInDcs)) {\n+      throw new IllegalArgumentException(\n+          \"Eligible replicas are not sufficient for undelete operation for partition \" + partitionId);\n+    }\n+    // Consider not-eligible hosts as failure\n+    for (String dcName : numReplicasInDcs.keySet()) {\n+      int totalNum = numReplicasInDcs.get(dcName);\n+      if (numEligibleReplicasInDcs.containsKey(dcName)) {\n+        int eligibleNum = numEligibleReplicasInDcs.get(dcName);\n+        if (eligibleNum != totalNum) {\n+          numFailureInDcs.put(dcName, totalNum - eligibleNum);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void onResponse(ReplicaId replicaId, TrackedRequestFinalState trackedRequestFinalState) {\n+    super.onResponse(replicaId, trackedRequestFinalState);\n+    String dcName = replicaId.getDataNodeId().getDatacenterName();\n+    if (trackedRequestFinalState == TrackedRequestFinalState.SUCCESS) {\n+      numSuccessInDcs.put(dcName, numSuccessInDcs.getOrDefault(dcName, 0) + 1);\n+    } else {\n+      numFailureInDcs.put(dcName, numFailureInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+  }\n+\n+  @Override\n+  public boolean hasSucceeded() {\n+    return hasReachedGlobalQuorum(numReplicasInDcs, numSuccessInDcs);\n+  }\n+\n+  @Override\n+  public boolean hasFailed() {\n+    return hasReachedAnyLocalQuorum(numReplicasInDcs, numFailureInDcs);\n+  }\n+\n+  /**\n+   * Return true if the {@code currentNumberInDcs}'s each value has reaches the quorum of corresponding value", "originalCommit": "88eaa9baa670727d7b08315c8e2232854c9e6378", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTk5OTk4MA==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r415999980", "bodyText": "same question here, do we account for the colo with single replica?", "author": "jsjtzyy", "createdAt": "2020-04-27T17:18:37Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private Map<String, Integer> numReplicasInDcs = new HashMap<>();\n+  private Map<String, Integer> numSuccessInDcs = new HashMap<>();\n+  private Map<String, Integer> numFailureInDcs = new HashMap<>();\n+\n+  /**\n+   * Constructs an {@link UndeleteOperationTracker}\n+   * @param routerConfig The {@link RouterConfig} containing the configs for operation tracker.\n+   * @param partitionId The partition on which the operation is performed.\n+   * @param originatingDcName name of originating DC whose replicas should be tried first.\n+   */\n+  UndeleteOperationTracker(RouterConfig routerConfig, PartitionId partitionId, String originatingDcName) {\n+    super(routerConfig, RouterOperation.UndeleteOperation, partitionId, originatingDcName, false);\n+    List<? extends ReplicaId> replicas = partitionId.getReplicaIds();\n+    for (ReplicaId replica : replicas) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numReplicasInDcs.put(dcName, numReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+    Map<String, Integer> numEligibleReplicasInDcs = new HashMap<>();\n+    for (ReplicaId replica : replicaPool) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numEligibleReplicasInDcs.put(dcName, numEligibleReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+\n+    if (!hasReachedGlobalQuorum(numReplicasInDcs, numEligibleReplicasInDcs)) {\n+      throw new IllegalArgumentException(\n+          \"Eligible replicas are not sufficient for undelete operation for partition \" + partitionId);\n+    }\n+    // Consider not-eligible hosts as failure\n+    for (String dcName : numReplicasInDcs.keySet()) {\n+      int totalNum = numReplicasInDcs.get(dcName);\n+      if (numEligibleReplicasInDcs.containsKey(dcName)) {\n+        int eligibleNum = numEligibleReplicasInDcs.get(dcName);\n+        if (eligibleNum != totalNum) {\n+          numFailureInDcs.put(dcName, totalNum - eligibleNum);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void onResponse(ReplicaId replicaId, TrackedRequestFinalState trackedRequestFinalState) {\n+    super.onResponse(replicaId, trackedRequestFinalState);\n+    String dcName = replicaId.getDataNodeId().getDatacenterName();\n+    if (trackedRequestFinalState == TrackedRequestFinalState.SUCCESS) {\n+      numSuccessInDcs.put(dcName, numSuccessInDcs.getOrDefault(dcName, 0) + 1);\n+    } else {\n+      numFailureInDcs.put(dcName, numFailureInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+  }\n+\n+  @Override\n+  public boolean hasSucceeded() {\n+    return hasReachedGlobalQuorum(numReplicasInDcs, numSuccessInDcs);\n+  }\n+\n+  @Override\n+  public boolean hasFailed() {\n+    return hasReachedAnyLocalQuorum(numReplicasInDcs, numFailureInDcs);\n+  }\n+\n+  /**\n+   * Return true if the {@code currentNumberInDcs}'s each value has reaches the quorum of corresponding value\n+   * in {@code totalNumberInDcs}.\n+   * @param totalNumberInDcs The total number of members in each datacenter.\n+   * @param currentNumberInDcs The current number of members in each datacenter.\n+   * @return true if current numbers reach the global quorum.\n+   */\n+  private static boolean hasReachedGlobalQuorum(Map<String, Integer> totalNumberInDcs,\n+      Map<String, Integer> currentNumberInDcs) {\n+    boolean hasReached = true;\n+    if (totalNumberInDcs.size() == currentNumberInDcs.size()) {\n+      for (String dcName : totalNumberInDcs.keySet()) {\n+        int totalNum = totalNumberInDcs.get(dcName);\n+        int currentNum = currentNumberInDcs.get(dcName);\n+        if (totalNum != 1 && currentNum <= totalNum / 2) {\n+          hasReached = false;\n+          break;\n+        }\n+      }\n+    } else {\n+      hasReached = false;\n+    }\n+    return hasReached;\n+  }\n+\n+  /**\n+   * Return true if any of the {@code currentNumberInDcs}'s value has reaches the quorum of corresponding value\n+   * in {@code totalNumberInDcs}.\n+   * @param totalNumberInDcs The total number of members in each datacenter.\n+   * @param currentNumberInDcs The current number of members in each datacenter.\n+   * @return true if any number reaches the quorum.\n+   */\n+  private static boolean hasReachedAnyLocalQuorum(Map<String, Integer> totalNumberInDcs,\n+      Map<String, Integer> currentNumberInDcs) {\n+    for (String dcName : totalNumberInDcs.keySet()) {\n+      int totalNum = totalNumberInDcs.get(dcName);\n+      if (currentNumberInDcs.containsKey(dcName)) {\n+        int currentNum = currentNumberInDcs.get(dcName);\n+        if (totalNum != 1 && currentNum > totalNum / 2) {", "originalCommit": "88eaa9baa670727d7b08315c8e2232854c9e6378", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjEwMTMxNQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416101315", "bodyText": "final", "author": "cgtz", "createdAt": "2020-04-27T19:48:52Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private Map<String, Integer> numReplicasInDcs = new HashMap<>();", "originalCommit": "88eaa9baa670727d7b08315c8e2232854c9e6378", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e80d4a16672f5f79ea175bc95d6894b9c7ad586f", "url": "https://github.com/linkedin/ambry/commit/e80d4a16672f5f79ea175bc95d6894b9c7ad586f", "message": "Comments", "committedDate": "2020-04-27T20:33:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgzNDUwNA==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416834504", "bodyText": "total number of replicas?", "author": "zzmao", "createdAt": "2020-04-28T18:32:21Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private final Map<String, Integer> numReplicasInDcs = new HashMap<>();\n+  private final Map<String, Integer> numSuccessInDcs = new HashMap<>();\n+  private final Map<String, Integer> numFailureInDcs = new HashMap<>();\n+\n+  /**\n+   * Constructs an {@link UndeleteOperationTracker}\n+   * @param routerConfig The {@link RouterConfig} containing the configs for operation tracker.\n+   * @param partitionId The partition on which the operation is performed.\n+   * @param originatingDcName name of originating DC whose replicas should be tried first.\n+   */\n+  UndeleteOperationTracker(RouterConfig routerConfig, PartitionId partitionId, String originatingDcName) {\n+    super(routerConfig, RouterOperation.UndeleteOperation, partitionId, originatingDcName, false);\n+    List<? extends ReplicaId> replicas = partitionId.getReplicaIds();\n+    for (ReplicaId replica : replicas) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numReplicasInDcs.put(dcName, numReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+    Map<String, Integer> numEligibleReplicasInDcs = new HashMap<>();\n+    for (ReplicaId replica : replicaPool) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numEligibleReplicasInDcs.put(dcName, numEligibleReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+\n+    if (!hasReachedGlobalQuorum(numReplicasInDcs, numEligibleReplicasInDcs)) {\n+      throw new IllegalArgumentException(\n+          \"Eligible replicas are not sufficient for undelete operation for partition \" + partitionId);\n+    }\n+    // Consider not-eligible hosts as failure\n+    for (String dcName : numReplicasInDcs.keySet()) {\n+      int totalNum = numReplicasInDcs.get(dcName);\n+      int eligibleNum = numEligibleReplicasInDcs.getOrDefault(dcName, 0);\n+      numFailureInDcs.put(dcName, totalNum - eligibleNum);\n+    }\n+  }\n+\n+  @Override\n+  public void onResponse(ReplicaId replicaId, TrackedRequestFinalState trackedRequestFinalState) {\n+    super.onResponse(replicaId, trackedRequestFinalState);\n+    String dcName = replicaId.getDataNodeId().getDatacenterName();\n+    if (trackedRequestFinalState == TrackedRequestFinalState.SUCCESS) {\n+      numSuccessInDcs.put(dcName, numSuccessInDcs.getOrDefault(dcName, 0) + 1);\n+    } else {\n+      numFailureInDcs.put(dcName, numFailureInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+  }\n+\n+  @Override\n+  public boolean hasSucceeded() {\n+    return hasReachedGlobalQuorum(numReplicasInDcs, numSuccessInDcs);\n+  }\n+\n+  @Override\n+  public boolean hasFailed() {\n+    return hasReachedAnyLocalQuorum(numReplicasInDcs, numFailureInDcs);\n+  }\n+\n+  /**\n+   * Return true if the {@code currentNumberInDcs}'s each value has reached the quorum of corresponding value\n+   * in {@code totalNumberInDcs}.\n+   * @param totalNumberInDcs The total number of members in each datacenter.", "originalCommit": "e80d4a16672f5f79ea175bc95d6894b9c7ad586f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgzNDc3NA==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416834774", "bodyText": "member -> replica?", "author": "zzmao", "createdAt": "2020-04-28T18:32:50Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private final Map<String, Integer> numReplicasInDcs = new HashMap<>();\n+  private final Map<String, Integer> numSuccessInDcs = new HashMap<>();\n+  private final Map<String, Integer> numFailureInDcs = new HashMap<>();\n+\n+  /**\n+   * Constructs an {@link UndeleteOperationTracker}\n+   * @param routerConfig The {@link RouterConfig} containing the configs for operation tracker.\n+   * @param partitionId The partition on which the operation is performed.\n+   * @param originatingDcName name of originating DC whose replicas should be tried first.\n+   */\n+  UndeleteOperationTracker(RouterConfig routerConfig, PartitionId partitionId, String originatingDcName) {\n+    super(routerConfig, RouterOperation.UndeleteOperation, partitionId, originatingDcName, false);\n+    List<? extends ReplicaId> replicas = partitionId.getReplicaIds();\n+    for (ReplicaId replica : replicas) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numReplicasInDcs.put(dcName, numReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+    Map<String, Integer> numEligibleReplicasInDcs = new HashMap<>();\n+    for (ReplicaId replica : replicaPool) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numEligibleReplicasInDcs.put(dcName, numEligibleReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+\n+    if (!hasReachedGlobalQuorum(numReplicasInDcs, numEligibleReplicasInDcs)) {\n+      throw new IllegalArgumentException(\n+          \"Eligible replicas are not sufficient for undelete operation for partition \" + partitionId);\n+    }\n+    // Consider not-eligible hosts as failure\n+    for (String dcName : numReplicasInDcs.keySet()) {\n+      int totalNum = numReplicasInDcs.get(dcName);\n+      int eligibleNum = numEligibleReplicasInDcs.getOrDefault(dcName, 0);\n+      numFailureInDcs.put(dcName, totalNum - eligibleNum);\n+    }\n+  }\n+\n+  @Override\n+  public void onResponse(ReplicaId replicaId, TrackedRequestFinalState trackedRequestFinalState) {\n+    super.onResponse(replicaId, trackedRequestFinalState);\n+    String dcName = replicaId.getDataNodeId().getDatacenterName();\n+    if (trackedRequestFinalState == TrackedRequestFinalState.SUCCESS) {\n+      numSuccessInDcs.put(dcName, numSuccessInDcs.getOrDefault(dcName, 0) + 1);\n+    } else {\n+      numFailureInDcs.put(dcName, numFailureInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+  }\n+\n+  @Override\n+  public boolean hasSucceeded() {\n+    return hasReachedGlobalQuorum(numReplicasInDcs, numSuccessInDcs);\n+  }\n+\n+  @Override\n+  public boolean hasFailed() {\n+    return hasReachedAnyLocalQuorum(numReplicasInDcs, numFailureInDcs);\n+  }\n+\n+  /**\n+   * Return true if the {@code currentNumberInDcs}'s each value has reached the quorum of corresponding value\n+   * in {@code totalNumberInDcs}.\n+   * @param totalNumberInDcs The total number of members in each datacenter.\n+   * @param currentNumberInDcs The current number of members in each datacenter.", "originalCommit": "e80d4a16672f5f79ea175bc95d6894b9c7ad586f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgzNTIwNg==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416835206", "bodyText": "as discussed, adding some tests will be good.", "author": "zzmao", "createdAt": "2020-04-28T18:33:36Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperationTracker.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.router;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.RouterConfig;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+\n+/**\n+ * An implementation of {@link OperationTracker}. It internally maintains the status of a corresponding operation, and\n+ * returns information that decides if the operation should continue or terminate.\n+ *\n+ * This OperationTracker only works for {@link UndeleteOperation}. Since an {@link UndeleteOperation} requires a global\n+ * quorum for success, a map of datacenter to number of success requests is used to keep track of how many success requests\n+ * tracker has seen in each datacenter. Once it reaches quorum in all the datacenter, it returns true for success. Or if\n+ * any datacenter see failure requests reach the quorum, it return true for failure.\n+ */\n+public class UndeleteOperationTracker extends SimpleOperationTracker {\n+  private final Map<String, Integer> numReplicasInDcs = new HashMap<>();\n+  private final Map<String, Integer> numSuccessInDcs = new HashMap<>();\n+  private final Map<String, Integer> numFailureInDcs = new HashMap<>();\n+\n+  /**\n+   * Constructs an {@link UndeleteOperationTracker}\n+   * @param routerConfig The {@link RouterConfig} containing the configs for operation tracker.\n+   * @param partitionId The partition on which the operation is performed.\n+   * @param originatingDcName name of originating DC whose replicas should be tried first.\n+   */\n+  UndeleteOperationTracker(RouterConfig routerConfig, PartitionId partitionId, String originatingDcName) {\n+    super(routerConfig, RouterOperation.UndeleteOperation, partitionId, originatingDcName, false);\n+    List<? extends ReplicaId> replicas = partitionId.getReplicaIds();\n+    for (ReplicaId replica : replicas) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numReplicasInDcs.put(dcName, numReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+    Map<String, Integer> numEligibleReplicasInDcs = new HashMap<>();\n+    for (ReplicaId replica : replicaPool) {\n+      String dcName = replica.getDataNodeId().getDatacenterName();\n+      numEligibleReplicasInDcs.put(dcName, numEligibleReplicasInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+\n+    if (!hasReachedGlobalQuorum(numReplicasInDcs, numEligibleReplicasInDcs)) {\n+      throw new IllegalArgumentException(\n+          \"Eligible replicas are not sufficient for undelete operation for partition \" + partitionId);\n+    }\n+    // Consider not-eligible hosts as failure\n+    for (String dcName : numReplicasInDcs.keySet()) {\n+      int totalNum = numReplicasInDcs.get(dcName);\n+      int eligibleNum = numEligibleReplicasInDcs.getOrDefault(dcName, 0);\n+      numFailureInDcs.put(dcName, totalNum - eligibleNum);\n+    }\n+  }\n+\n+  @Override\n+  public void onResponse(ReplicaId replicaId, TrackedRequestFinalState trackedRequestFinalState) {\n+    super.onResponse(replicaId, trackedRequestFinalState);\n+    String dcName = replicaId.getDataNodeId().getDatacenterName();\n+    if (trackedRequestFinalState == TrackedRequestFinalState.SUCCESS) {\n+      numSuccessInDcs.put(dcName, numSuccessInDcs.getOrDefault(dcName, 0) + 1);\n+    } else {\n+      numFailureInDcs.put(dcName, numFailureInDcs.getOrDefault(dcName, 0) + 1);\n+    }\n+  }\n+\n+  @Override\n+  public boolean hasSucceeded() {\n+    return hasReachedGlobalQuorum(numReplicasInDcs, numSuccessInDcs);\n+  }\n+\n+  @Override\n+  public boolean hasFailed() {\n+    return hasReachedAnyLocalQuorum(numReplicasInDcs, numFailureInDcs);\n+  }\n+\n+  /**\n+   * Return true if the {@code currentNumberInDcs}'s each value has reached the quorum of corresponding value\n+   * in {@code totalNumberInDcs}.\n+   * @param totalNumberInDcs The total number of members in each datacenter.\n+   * @param currentNumberInDcs The current number of members in each datacenter.\n+   * @return true if current numbers reach the global quorum.\n+   */\n+  private static boolean hasReachedGlobalQuorum(Map<String, Integer> totalNumberInDcs,\n+      Map<String, Integer> currentNumberInDcs) {\n+    boolean hasReached = true;\n+    if (totalNumberInDcs.size() == currentNumberInDcs.size()) {\n+      for (String dcName : totalNumberInDcs.keySet()) {\n+        int totalNum = totalNumberInDcs.get(dcName);\n+        int currentNum = currentNumberInDcs.getOrDefault(dcName, 0);", "originalCommit": "e80d4a16672f5f79ea175bc95d6894b9c7ad586f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "238bb7f0afe60976001c13c904f7f3dac4d4fb95", "url": "https://github.com/linkedin/ambry/commit/238bb7f0afe60976001c13c904f7f3dac4d4fb95", "message": "Complete UndeleteOperation and add UndeleteOperationTracker", "committedDate": "2020-04-28T18:35:29Z", "type": "commit"}, {"oid": "0e01804f47efa4f79292ade39307318f9258e310", "url": "https://github.com/linkedin/ambry/commit/0e01804f47efa4f79292ade39307318f9258e310", "message": "Add more tests", "committedDate": "2020-04-28T18:35:29Z", "type": "commit"}, {"oid": "9715642fb2ce053305890fb7cda77c33d5ca62b3", "url": "https://github.com/linkedin/ambry/commit/9715642fb2ce053305890fb7cda77c33d5ca62b3", "message": "more tests", "committedDate": "2020-04-28T18:35:29Z", "type": "commit"}, {"oid": "f062899fc440d0d182da5ca0c222818f959bdc5f", "url": "https://github.com/linkedin/ambry/commit/f062899fc440d0d182da5ca0c222818f959bdc5f", "message": "Comments", "committedDate": "2020-04-28T18:35:29Z", "type": "commit"}, {"oid": "dcb5700b6bca6c7a37fc1152350f36813ae826a1", "url": "https://github.com/linkedin/ambry/commit/dcb5700b6bca6c7a37fc1152350f36813ae826a1", "message": "Comments", "committedDate": "2020-04-28T18:35:29Z", "type": "commit"}, {"oid": "e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "url": "https://github.com/linkedin/ambry/commit/e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "message": "Add tests", "committedDate": "2020-04-28T20:18:51Z", "type": "commit"}, {"oid": "e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "url": "https://github.com/linkedin/ambry/commit/e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "message": "Add tests", "committedDate": "2020-04-28T20:18:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk1OTgyOA==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416959828", "bodyText": "probably copied from TtlUpdateOperation, but resolvedRouterErrorCode at line59 is never used here.", "author": "jsjtzyy", "createdAt": "2020-04-28T22:22:52Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperation.java", "diffHunk": "@@ -58,6 +61,10 @@\n   private boolean operationCompleted = false;", "originalCommit": "e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk2MjI2MA==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r416962260", "bodyText": "nit: these two lines can be combined to single line.", "author": "jsjtzyy", "createdAt": "2020-04-28T22:29:09Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperation.java", "diffHunk": "@@ -83,9 +90,7 @@\n     this.operationTimeMs = operationTimeMs;\n     byte blobDcId = blobId.getDatacenterId();\n     String originatingDcName = clusterMap.getDatacenterName(blobDcId);", "originalCommit": "e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQzMjk4MQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r417432981", "bodyText": "minor: unnecessary unboxing for lifeVersion.shortValue()", "author": "jsjtzyy", "createdAt": "2020-04-29T16:05:13Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperation.java", "diffHunk": "@@ -104,6 +151,89 @@ void poll(RequestRegistrationCallback<UndeleteOperation> requestRegistrationCall\n    * @param undeleteResponse The {@link UndeleteResponse} associated with this response.\n    */\n   void handleResponse(ResponseInfo responseInfo, UndeleteResponse undeleteResponse) {\n+    UndeleteRequest undeleteRequest = (UndeleteRequest) responseInfo.getRequestInfo().getRequest();\n+    UndeleteRequestInfo undeleteRequestInfo = undeleteRequestInfos.remove(undeleteRequest.getCorrelationId());\n+    // undeleteRequestInfo can be null if this request was timed out before this response is received. No\n+    // metric is updated here, as corresponding metrics have been updated when the request was timed out.\n+    if (undeleteRequestInfo == null) {\n+      return;\n+    }\n+    ReplicaId replica = undeleteRequestInfo.replica;\n+    long requestLatencyMs = time.milliseconds() - undeleteRequestInfo.startTimeMs;\n+    routerMetrics.routerRequestLatencyMs.update(requestLatencyMs);\n+    routerMetrics.getDataNodeBasedMetrics(replica.getDataNodeId()).undeleteRequestLatencyMs.update(requestLatencyMs);\n+    // Check the error code from NetworkClient.\n+    if (responseInfo.getError() != null) {\n+      LOGGER.trace(\"UndeleteRequest with response correlationId {} timed out for replica {} \",\n+          undeleteRequest.getCorrelationId(), replica.getDataNodeId());\n+      onErrorResponse(replica, new RouterException(\"Operation timed out\", RouterErrorCode.OperationTimedOut));\n+    } else {\n+      if (undeleteResponse == null) {\n+        LOGGER.trace(\n+            \"UndeleteRequest with response correlationId {} received UnexpectedInternalError on response deserialization for replica {} \",\n+            undeleteRequest.getCorrelationId(), replica.getDataNodeId());\n+        onErrorResponse(replica, new RouterException(\"Response deserialization received an unexpected error\",\n+            RouterErrorCode.UnexpectedInternalError));\n+      } else {\n+        // The true case below should not really happen. This means a response has been received\n+        // not for its original request. We will immediately fail this operation.\n+        if (undeleteResponse.getCorrelationId() != undeleteRequest.getCorrelationId()) {\n+          LOGGER.error(\"The correlation id in the DeleteResponse \" + undeleteResponse.getCorrelationId()\n+              + \" is not the same as the correlation id in the associated DeleteRequest: \"\n+              + undeleteRequest.getCorrelationId());\n+          routerMetrics.unknownReplicaResponseError.inc();\n+          onErrorResponse(replica,\n+              new RouterException(\"Received wrong response that is not for the corresponding request.\",\n+                  RouterErrorCode.UnexpectedInternalError));\n+        } else {\n+          ServerErrorCode serverError = undeleteResponse.getError();\n+          if (serverError == ServerErrorCode.No_Error) {\n+            operationTracker.onResponse(replica, TrackedRequestFinalState.SUCCESS);\n+            if (RouterUtils.isRemoteReplica(routerConfig, replica)) {\n+              LOGGER.trace(\"Cross colo request successful for remote replica {} in {} \", replica.getDataNodeId(),\n+                  replica.getDataNodeId().getDatacenterName());\n+              routerMetrics.crossColoSuccessCount.inc();\n+            }\n+            if (lifeVersion == null) {\n+              // This is first successful response.\n+              lifeVersion = undeleteResponse.getLifeVersion();\n+              firstResponseReplicaId = replica;\n+            } else {\n+              if (lifeVersion.shortValue() != undeleteResponse.getLifeVersion()) {", "originalCommit": "e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQzMzE4MQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r417433181", "bodyText": "minor: undelete request", "author": "jsjtzyy", "createdAt": "2020-04-29T16:05:30Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperation.java", "diffHunk": "@@ -104,6 +151,89 @@ void poll(RequestRegistrationCallback<UndeleteOperation> requestRegistrationCall\n    * @param undeleteResponse The {@link UndeleteResponse} associated with this response.\n    */\n   void handleResponse(ResponseInfo responseInfo, UndeleteResponse undeleteResponse) {\n+    UndeleteRequest undeleteRequest = (UndeleteRequest) responseInfo.getRequestInfo().getRequest();\n+    UndeleteRequestInfo undeleteRequestInfo = undeleteRequestInfos.remove(undeleteRequest.getCorrelationId());\n+    // undeleteRequestInfo can be null if this request was timed out before this response is received. No\n+    // metric is updated here, as corresponding metrics have been updated when the request was timed out.\n+    if (undeleteRequestInfo == null) {\n+      return;\n+    }\n+    ReplicaId replica = undeleteRequestInfo.replica;\n+    long requestLatencyMs = time.milliseconds() - undeleteRequestInfo.startTimeMs;\n+    routerMetrics.routerRequestLatencyMs.update(requestLatencyMs);\n+    routerMetrics.getDataNodeBasedMetrics(replica.getDataNodeId()).undeleteRequestLatencyMs.update(requestLatencyMs);\n+    // Check the error code from NetworkClient.\n+    if (responseInfo.getError() != null) {\n+      LOGGER.trace(\"UndeleteRequest with response correlationId {} timed out for replica {} \",\n+          undeleteRequest.getCorrelationId(), replica.getDataNodeId());\n+      onErrorResponse(replica, new RouterException(\"Operation timed out\", RouterErrorCode.OperationTimedOut));\n+    } else {\n+      if (undeleteResponse == null) {\n+        LOGGER.trace(\n+            \"UndeleteRequest with response correlationId {} received UnexpectedInternalError on response deserialization for replica {} \",\n+            undeleteRequest.getCorrelationId(), replica.getDataNodeId());\n+        onErrorResponse(replica, new RouterException(\"Response deserialization received an unexpected error\",\n+            RouterErrorCode.UnexpectedInternalError));\n+      } else {\n+        // The true case below should not really happen. This means a response has been received\n+        // not for its original request. We will immediately fail this operation.\n+        if (undeleteResponse.getCorrelationId() != undeleteRequest.getCorrelationId()) {\n+          LOGGER.error(\"The correlation id in the DeleteResponse \" + undeleteResponse.getCorrelationId()\n+              + \" is not the same as the correlation id in the associated DeleteRequest: \"\n+              + undeleteRequest.getCorrelationId());\n+          routerMetrics.unknownReplicaResponseError.inc();\n+          onErrorResponse(replica,\n+              new RouterException(\"Received wrong response that is not for the corresponding request.\",\n+                  RouterErrorCode.UnexpectedInternalError));\n+        } else {\n+          ServerErrorCode serverError = undeleteResponse.getError();\n+          if (serverError == ServerErrorCode.No_Error) {\n+            operationTracker.onResponse(replica, TrackedRequestFinalState.SUCCESS);\n+            if (RouterUtils.isRemoteReplica(routerConfig, replica)) {\n+              LOGGER.trace(\"Cross colo request successful for remote replica {} in {} \", replica.getDataNodeId(),\n+                  replica.getDataNodeId().getDatacenterName());\n+              routerMetrics.crossColoSuccessCount.inc();\n+            }\n+            if (lifeVersion == null) {\n+              // This is first successful response.\n+              lifeVersion = undeleteResponse.getLifeVersion();\n+              firstResponseReplicaId = replica;\n+            } else {\n+              if (lifeVersion.shortValue() != undeleteResponse.getLifeVersion()) {\n+                String message = String.format(\n+                    \"LifeVersion from Replica {} is different than the lifeVersion from replica {}, {} != {}\",\n+                    firstResponseReplicaId, replica, lifeVersion, undeleteResponse.getLifeVersion());\n+                LOGGER.error(message);\n+                // this is a successful response and one that completes the operation regardless of whether the\n+                // success target has been reached or not.\n+                operationCompleted = true;\n+                onErrorResponse(replica, new RouterException(message, RouterErrorCode.LifeVersionConflict));\n+              }\n+            }\n+          } else if (serverError == ServerErrorCode.Disk_Unavailable) {\n+            LOGGER.trace(\"Replica {} returned Disk_Unavailable for a delete request with correlationId : {} \", replica,", "originalCommit": "e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQzMzM0Mg==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r417433342", "bodyText": "undelete request", "author": "jsjtzyy", "createdAt": "2020-04-29T16:05:45Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperation.java", "diffHunk": "@@ -104,6 +151,89 @@ void poll(RequestRegistrationCallback<UndeleteOperation> requestRegistrationCall\n    * @param undeleteResponse The {@link UndeleteResponse} associated with this response.\n    */\n   void handleResponse(ResponseInfo responseInfo, UndeleteResponse undeleteResponse) {\n+    UndeleteRequest undeleteRequest = (UndeleteRequest) responseInfo.getRequestInfo().getRequest();\n+    UndeleteRequestInfo undeleteRequestInfo = undeleteRequestInfos.remove(undeleteRequest.getCorrelationId());\n+    // undeleteRequestInfo can be null if this request was timed out before this response is received. No\n+    // metric is updated here, as corresponding metrics have been updated when the request was timed out.\n+    if (undeleteRequestInfo == null) {\n+      return;\n+    }\n+    ReplicaId replica = undeleteRequestInfo.replica;\n+    long requestLatencyMs = time.milliseconds() - undeleteRequestInfo.startTimeMs;\n+    routerMetrics.routerRequestLatencyMs.update(requestLatencyMs);\n+    routerMetrics.getDataNodeBasedMetrics(replica.getDataNodeId()).undeleteRequestLatencyMs.update(requestLatencyMs);\n+    // Check the error code from NetworkClient.\n+    if (responseInfo.getError() != null) {\n+      LOGGER.trace(\"UndeleteRequest with response correlationId {} timed out for replica {} \",\n+          undeleteRequest.getCorrelationId(), replica.getDataNodeId());\n+      onErrorResponse(replica, new RouterException(\"Operation timed out\", RouterErrorCode.OperationTimedOut));\n+    } else {\n+      if (undeleteResponse == null) {\n+        LOGGER.trace(\n+            \"UndeleteRequest with response correlationId {} received UnexpectedInternalError on response deserialization for replica {} \",\n+            undeleteRequest.getCorrelationId(), replica.getDataNodeId());\n+        onErrorResponse(replica, new RouterException(\"Response deserialization received an unexpected error\",\n+            RouterErrorCode.UnexpectedInternalError));\n+      } else {\n+        // The true case below should not really happen. This means a response has been received\n+        // not for its original request. We will immediately fail this operation.\n+        if (undeleteResponse.getCorrelationId() != undeleteRequest.getCorrelationId()) {\n+          LOGGER.error(\"The correlation id in the DeleteResponse \" + undeleteResponse.getCorrelationId()\n+              + \" is not the same as the correlation id in the associated DeleteRequest: \"\n+              + undeleteRequest.getCorrelationId());\n+          routerMetrics.unknownReplicaResponseError.inc();\n+          onErrorResponse(replica,\n+              new RouterException(\"Received wrong response that is not for the corresponding request.\",\n+                  RouterErrorCode.UnexpectedInternalError));\n+        } else {\n+          ServerErrorCode serverError = undeleteResponse.getError();\n+          if (serverError == ServerErrorCode.No_Error) {\n+            operationTracker.onResponse(replica, TrackedRequestFinalState.SUCCESS);\n+            if (RouterUtils.isRemoteReplica(routerConfig, replica)) {\n+              LOGGER.trace(\"Cross colo request successful for remote replica {} in {} \", replica.getDataNodeId(),\n+                  replica.getDataNodeId().getDatacenterName());\n+              routerMetrics.crossColoSuccessCount.inc();\n+            }\n+            if (lifeVersion == null) {\n+              // This is first successful response.\n+              lifeVersion = undeleteResponse.getLifeVersion();\n+              firstResponseReplicaId = replica;\n+            } else {\n+              if (lifeVersion.shortValue() != undeleteResponse.getLifeVersion()) {\n+                String message = String.format(\n+                    \"LifeVersion from Replica {} is different than the lifeVersion from replica {}, {} != {}\",\n+                    firstResponseReplicaId, replica, lifeVersion, undeleteResponse.getLifeVersion());\n+                LOGGER.error(message);\n+                // this is a successful response and one that completes the operation regardless of whether the\n+                // success target has been reached or not.\n+                operationCompleted = true;\n+                onErrorResponse(replica, new RouterException(message, RouterErrorCode.LifeVersionConflict));\n+              }\n+            }\n+          } else if (serverError == ServerErrorCode.Disk_Unavailable) {\n+            LOGGER.trace(\"Replica {} returned Disk_Unavailable for a delete request with correlationId : {} \", replica,\n+                undeleteRequest.getCorrelationId());\n+            operationTracker.onResponse(replica, TrackedRequestFinalState.DISK_DOWN);\n+            setOperationException(\n+                new RouterException(\"Server returned: \" + serverError, RouterErrorCode.AmbryUnavailable));\n+            routerMetrics.routerRequestErrorCount.inc();\n+            routerMetrics.getDataNodeBasedMetrics(replica.getDataNodeId()).undeleteRequestErrorCount.inc();\n+          } else {\n+            LOGGER.trace(\"Replica {} returned an error {} for a delete request with response correlationId : {} \",", "originalCommit": "e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQzNzg2Ng==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r417437866", "bodyText": "I feel BlobNotDeleted may have higher precedence level than OperationTimedOut", "author": "jsjtzyy", "createdAt": "2020-04-29T16:12:11Z", "path": "ambry-router/src/main/java/com/github/ambry/router/UndeleteOperation.java", "diffHunk": "@@ -141,19 +361,19 @@ private int getPrecedenceLevel(RouterErrorCode routerErrorCode) {\n     switch (routerErrorCode) {\n       case BlobAuthorizationFailure:\n         return 0;\n-      case BlobDeleted:\n+      case LifeVersionConflict:\n         return 1;\n       case BlobExpired:\n         return 2;\n-      case BlobUpdateNotAllowed:\n-        return 3;\n       case AmbryUnavailable:\n-        return 4;\n+        return 3;\n       case UnexpectedInternalError:\n-        return 5;\n+        return 4;\n       case OperationTimedOut:\n-        return 6;\n+        return 5;\n       case BlobDoesNotExist:\n+        return 6;\n+      case BlobNotDeleted:", "originalCommit": "e26f630a4fd3fbe0e1471358b8440b2bbc4c4598", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQ0OTMzMQ==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r417449331", "bodyText": "this one is quite tricky. Two errors in one dc would render undelete operation a failure. Say if we have one BlobNotDeleted and one OperationTimeOut, it might be because there is only one host that doesn't have this blob deleted, but the other two are deleted and unfortunately one of these two returns OperationTimeOut. In this case, I think it's better to return OperationTimeOut.", "author": "justinlin-linkedin", "createdAt": "2020-04-29T16:29:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQzNzg2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzYxNjUxMA==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r417616510", "bodyText": "I think BlobNotDeleted means one server holds the blob but this blob is not deleted yet. If undelete succeeds on all servers except for one server that returns BlobNotDeleted, we still consider whole operation a success?", "author": "jsjtzyy", "createdAt": "2020-04-29T21:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQzNzg2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzYxNzk3NA==", "url": "https://github.com/linkedin/ambry/pull/1480#discussion_r417617974", "bodyText": "you are right, BlobNotDeleted does mean that. And BlobNotDeleted is not a terminating error, which means if we see this error, the undelete operation will continue. If undelete operation sees more than one error on one dc (assume there are 3 replicas), then it will fail the operation. But if undelete operation only sees one BlobNotDeleted and two success in one dc, then it's still considered a success.", "author": "justinlin-linkedin", "createdAt": "2020-04-29T21:18:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQzNzg2Ng=="}], "type": "inlineReview"}, {"oid": "0246b3d9dbe2b77e2608d72cb133a640b9aeb5f8", "url": "https://github.com/linkedin/ambry/commit/0246b3d9dbe2b77e2608d72cb133a640b9aeb5f8", "message": "Address comments", "committedDate": "2020-04-29T16:30:28Z", "type": "commit"}]}