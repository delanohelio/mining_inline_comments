{"pr_number": 1546, "pr_title": "Core changes of leader based replication. ", "pr_createdAt": "2020-06-02T05:27:26Z", "pr_url": "https://github.com/linkedin/ambry/pull/1546", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDY3MjU3Mw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r434672573", "bodyText": "Are these instanceof checks needed? Maybe the ReplicationEngine implementation can check during construction if LEADER_BASED replication is supported and throw an exception if it is misconfigured.", "author": "cgtz", "createdAt": "2020-06-03T15:52:37Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -459,8 +483,11 @@ public void replicate() {\n             // Skip stores that were stopped during call to getReplicaMetadataResponse\n             if (!remoteReplicaInfo.getLocalStore().isStarted()) {\n               exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n-              remoteReplicaInfo.setExchangeMetadataResponse(\n-                  new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n+              if (replicatingFromRemoteColo && replicationConfig.replicationModelType.equals(\n+                  ReplicationModelType.LEADER_BASED) && replicationEngine instanceof ReplicationManager) {", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NTE3NA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435685174", "bodyText": "Why this is a readLock? I think it's supposed to be writeLock.", "author": "jsjtzyy", "createdAt": "2020-06-05T04:35:53Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java", "diffHunk": "@@ -105,6 +106,24 @@ RemoteReplicaInfo removeReplicaInfoIfPresent(ReplicaId remoteReplica) {\n     return replicaInfoToRemove;\n   }\n \n+  /**\n+   * Go through remote replicas of this partition and compare the messages written to store with messages\n+   * found missing during the previous replication cycle. This is used during leader-based replication where missing\n+   * store messages found in metadata exchange are not fetched for non-leader remote replicas in cross colo\n+   * data centers. Instead, we wait for them to come from intra-dc replication.\n+   * @param messageInfoList list of messages written to local store.\n+   */\n+  void updateReplicaInfosOnMessageWrite(List<MessageInfo> messageInfoList) {\n+    rwLock.readLock().lock();", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NTUxMQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435685511", "bodyText": "nvm,  readLock is probably ok here.", "author": "jsjtzyy", "createdAt": "2020-06-05T04:37:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4NTE3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4ODIzNQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435688235", "bodyText": "minor: can use exchangeMetadataResponse.missingStoreMessages.isEmpty()", "author": "jsjtzyy", "createdAt": "2020-06-05T04:49:52Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -222,9 +242,104 @@ public boolean equals(Object obj) {\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n     // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // and replica threads updating missing store messages in compareAndRemoveMissingStoreMessages() after they are\n+    // written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in exchangeMetadataResponse are written to store by parallel replica\n+    // threads between the time exchangeMetadataResponse is calculated and set here. So, we look up the local store\n+    // again and remove messages that are now found from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * checks if the metadata response for this replica is empty or if there are no missing store keys present in it.\n+   * If this replica is a non-leader in remote colo and leader-based replication is enabled, replica threads will not\n+   * send next metadata request for it until all missing keys in this metadata response come via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.size() == 0;", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY4ODU3MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435688571", "bodyText": "nit: format this file", "author": "jsjtzyy", "createdAt": "2020-06-05T04:51:16Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/PartitionInfo.java", "diffHunk": "@@ -105,6 +106,24 @@ RemoteReplicaInfo removeReplicaInfoIfPresent(ReplicaId remoteReplica) {\n     return replicaInfoToRemove;\n   }\n \n+  /**\n+   * Go through remote replicas of this partition and compare the messages written to store with messages\n+   * found missing during the previous replication cycle. This is used during leader-based replication where missing\n+   * store messages found in metadata exchange are not fetched for non-leader remote replicas in cross colo\n+   * data centers. Instead, we wait for them to come from intra-dc replication.\n+   * @param messageInfoList list of messages written to local store.\n+   */\n+  void updateReplicaInfosOnMessageWrite(List<MessageInfo> messageInfoList) {\n+    rwLock.readLock().lock();\n+    try {\n+      for(RemoteReplicaInfo remoteReplicaInfo : remoteReplicas){", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY5MTEyNQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435691125", "bodyText": "You need to check if partitionInfo == null here,  it's possible partition is being concurrently removed from this node", "author": "jsjtzyy", "createdAt": "2020-06-05T05:02:22Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java", "diffHunk": "@@ -503,4 +507,23 @@ protected void stopPartitionReplication(PartitionId partitionId) {\n       }\n     }\n   }\n+\n+  /**\n+   * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+   * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+   * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+   * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+   * missing messages are written to store.\n+   * @param partitionId partition ID of the messages written to store\n+   * @param messageInfoList list of messages written to store\n+   */\n+  void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+    rwLock.readLock().lock();\n+    try {\n+      PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+      partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY5OTExNQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r435699115", "bodyText": "We probably don't need to pass in ReplicationEngine, instead we can pass in something like leaderBasedReplicationTracker or leaderBasedReplicationCoordinator or leaderBasedReplicationAdmin that helps to coordinate/update info across replication threads. The component is instantiated only when model == ReplicationModelType.LEADER_BASED. Thus, we can check if this component is null and don't have to check many other things like line350~351", "author": "jsjtzyy", "createdAt": "2020-06-05T05:35:39Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -122,15 +123,16 @@ public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, Cluster\n       ReplicaSyncUpManager replicaSyncUpManager) {\n     this(threadName, findTokenHelper, clusterMap, correlationIdGenerator, dataNodeId, connectionPool, replicationConfig,\n         replicationMetrics, notification, storeKeyConverter, transformer, metricRegistry, replicatingOverSsl,\n-        datacenterName, responseHandler, time, replicaSyncUpManager, null);\n+        datacenterName, responseHandler, time, replicaSyncUpManager, null, null);\n   }\n \n   public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, ClusterMap clusterMap,\n       AtomicInteger correlationIdGenerator, DataNodeId dataNodeId, ConnectionPool connectionPool,\n       ReplicationConfig replicationConfig, ReplicationMetrics replicationMetrics, NotificationSystem notification,\n       StoreKeyConverter storeKeyConverter, Transformer transformer, MetricRegistry metricRegistry,\n       boolean replicatingOverSsl, String datacenterName, ResponseHandler responseHandler, Time time,\n-      ReplicaSyncUpManager replicaSyncUpManager, PartitionLeaderInfo partitionLeaderInfo) {\n+      ReplicaSyncUpManager replicaSyncUpManager, PartitionLeaderInfo partitionLeaderInfo,\n+      ReplicationEngine replicationEngine) {", "originalCommit": "08416f80cee55cd12769577493076a74c9fe5262", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjAyMzc0Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436023746", "bodyText": "If we decide to pass in a component rather than ReplicationEngine, we can even move the method onMessageWriteForPartition() from ReplicationEngine to ReplicationManager (for better isolation). The component should be simple and lightweight, which is an inner class like ClusterMapChangeListenerImpl and PartitionStateChangeListenerImpl, what do you think?", "author": "jsjtzyy", "createdAt": "2020-06-05T16:13:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY5OTExNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA3ODQ4Mw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436078483", "bodyText": "cc @cgtz  because you have a similar comment. Feel free to offer your insights here.", "author": "jsjtzyy", "createdAt": "2020-06-05T18:00:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY5OTExNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0MTc1NQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436441755", "bodyText": "To align with naming convention in this file, could you rename the config name of ReplicationModelType?\npublic final ReplicationModelType replicationModelAcrossDatacenters;", "author": "jsjtzyy", "createdAt": "2020-06-08T03:31:40Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -202,6 +202,14 @@\n   @Default(\"false\")\n   public final boolean replicationEnableHttp2;\n \n+  /**", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0Mjk3Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436442976", "bodyText": "Can we rename this to \"replication.standby.wait.timeout.to.tigger.cross.colo.fetch.second\"?\nCan we use second as time unit? 5000 ms is a little short, I would suggest 120 secs (2min)\n(Also, could you elaborate a little more about the purpose to introduce such timeout? It's better to present more context in the comment.)", "author": "jsjtzyy", "createdAt": "2020-06-08T03:39:26Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -202,6 +202,14 @@\n   @Default(\"false\")\n   public final boolean replicationEnableHttp2;\n \n+  /**\n+   * The time (in ms) to wait before doing cross colo fetch for standby replicas.\n+   * This is applicable if leader based replication is enabled.\n+   */\n+  @Config(\"replication.wait.time.for.cross.colo.fetch.for.standby.replicas.ms\")\n+  @Default(\"5000\")\n+  public final long replicationWaitTimeForCrossColoFetchForStandbyReplicasMs;", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ0MzUwMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436443500", "bodyText": "Can we use -1 to represent no timeout?", "author": "jsjtzyy", "createdAt": "2020-06-08T03:42:20Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -247,5 +255,8 @@ public ReplicationConfig(VerifiableProperties verifiableProperties) {\n     replicationModelType = ReplicationModelType.valueOf(\n         verifiableProperties.getString(\"replication.model.across.datacenters\", ReplicationModelType.ALL_TO_ALL.name()));\n     replicationEnableHttp2 = verifiableProperties.getBoolean(\"replication.enable.http2\", false);\n+    replicationWaitTimeForCrossColoFetchForStandbyReplicasMs =\n+        verifiableProperties.getLongInRange(\"replication.wait.time.for.cross.colo.fetch.for.standby.replicas.ms\", 5000,\n+            0, Long.MAX_VALUE);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ1NDEyOQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436454129", "bodyText": "typo: occurred", "author": "jsjtzyy", "createdAt": "2020-06-08T04:43:02Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n+\n+        if (messagesWrittenToStore != null) {\n+          // Check missing store messages in the list of messages newly written to store\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // This is hit when we call compareAndRemoveMissingStoreMessages() from setExchangeMetadataResponse(). It is\n+          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n+          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n+          // again to find if any missing messages are written.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : messagesFoundInStore) {\n+          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);\n+          }\n+\n+          // 2. remove found message from the missing set\n+          exchangeMetadataResponse.missingStoreMessages.remove(messageInfo);\n+\n+          // 3. if all missing store messages are found, move token and store local lag from remote\n+          if (exchangeMetadataResponse.missingStoreMessages.size() == 0) {\n+            setToken(exchangeMetadataResponse.remoteToken);\n+            setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+\n+            logger.trace(\"Updating token {} and lag {} for remote replica: {} in Remote node: {}\",\n+                exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes, replicaId,\n+                replicaId.getDataNodeId());\n+\n+            exchangeMetadataResponse = new ReplicaThread.ExchangeMetadataResponse(ServerErrorCode.No_Error);\n+\n+            break;\n+          }\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occured while updating exchangeMetadataResponse for Remote replica: {}\", replicaId, e);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ1OTk3NQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436459975", "bodyText": "Do we need to execute this piece of code every time compareAndRemoveMissingStoreMessages is called? Can we cache the converted result?", "author": "jsjtzyy", "createdAt": "2020-06-08T05:11:58Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEwMjU1NQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439102555", "bodyText": "Yeah, we don't need to execute this code to convert remote keys (of stored missing message infos) to local keys every time as it is duplicate work. Made changes to store the remoteKeyToLocalKeyMap along with missing message information in the ExchangeMetadataResponse itself.", "author": "Arun-LinkedIn", "createdAt": "2020-06-11T22:19:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ1OTk3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NDM4Mw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436464383", "bodyText": "add a log here as well for debugging purpose", "author": "jsjtzyy", "createdAt": "2020-06-08T05:31:47Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n+\n+        if (messagesWrittenToStore != null) {\n+          // Check missing store messages in the list of messages newly written to store\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // This is hit when we call compareAndRemoveMissingStoreMessages() from setExchangeMetadataResponse(). It is\n+          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n+          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n+          // again to find if any missing messages are written.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : messagesFoundInStore) {\n+          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);\n+          }\n+\n+          // 2. remove found message from the missing set\n+          exchangeMetadataResponse.missingStoreMessages.remove(messageInfo);\n+\n+          // 3. if all missing store messages are found, move token and store local lag from remote\n+          if (exchangeMetadataResponse.missingStoreMessages.size() == 0) {\n+            setToken(exchangeMetadataResponse.remoteToken);\n+            setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+\n+            logger.trace(\"Updating token {} and lag {} for remote replica: {} in Remote node: {}\",\n+                exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes, replicaId,\n+                replicaId.getDataNodeId());\n+\n+            exchangeMetadataResponse = new ReplicaThread.ExchangeMetadataResponse(ServerErrorCode.No_Error);\n+\n+            break;\n+          }\n+        }\n+      } catch (Exception e) {\n+        logger.error(\"Exception occured while updating exchangeMetadataResponse for Remote replica: {}\", replicaId, e);\n+        // reset stored metadata response so that metadata request is sent again for this replica\n+        exchangeMetadataResponse = new ReplicaThread.ExchangeMetadataResponse(ServerErrorCode.No_Error);\n+      }\n+    } else {\n+      // reset stored metadata response so that metadata request is sent again for this replica", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyMjQwNA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439922404", "bodyText": "and also I wonder in which case this else branch will happen?", "author": "jsjtzyy", "createdAt": "2020-06-15T04:16:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NDM4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NTIxNQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436465215", "bodyText": "if the messageInfo is a PUT, can we skip applyUpdatesOnLocalStoreKey?", "author": "jsjtzyy", "createdAt": "2020-06-08T05:35:17Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n+\n+        if (messagesWrittenToStore != null) {\n+          // Check missing store messages in the list of messages newly written to store\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // This is hit when we call compareAndRemoveMissingStoreMessages() from setExchangeMetadataResponse(). It is\n+          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n+          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n+          // again to find if any missing messages are written.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : messagesFoundInStore) {\n+          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEwNzQzMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439107430", "bodyText": "Sure, we can skip applying updates (ttlupdate, delete or undelete) to blob in local store if received message info is a PUT.  But, I am just thinking if is safe to leave as it is to have this operation identical to what we do in processReplicaMetadataResponse() when messages received in metadata response are found in local store.", "author": "Arun-LinkedIn", "createdAt": "2020-06-11T22:33:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NTIxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NTY5Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r436465692", "bodyText": "A general question: how do we deal with several messages associated with same key? (i.e. during on replication cycle, we have both PUT and DELETE message associated with certain blob id)", "author": "jsjtzyy", "createdAt": "2020-06-08T05:37:13Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle\n+   * for this replica.\n+   *  If there are matching messages (based on store key), do the following:\n+   *  1. Compare the blob metadata and reconcile delete, ttl-update and un-delete states.\n+   *  2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *  3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null && storeKeyConverter != null) {\n+      try {\n+        List<MessageInfo> messagesFoundInStore = new ArrayList<>();\n+\n+        //collect store keys to convert\n+        List<StoreKey> storeKeysToConvert = exchangeMetadataResponse.missingStoreMessages.stream()\n+            .map(MessageInfo::getStoreKey)\n+            .collect(Collectors.toList());\n+        storeKeyConverter.dropCache();\n+        Map<StoreKey, StoreKey> remoteKeyToLocalKeyMap = storeKeyConverter.convert(storeKeysToConvert);\n+\n+        if (messagesWrittenToStore != null) {\n+          // Check missing store messages in the list of messages newly written to store\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // This is hit when we call compareAndRemoveMissingStoreMessages() from setExchangeMetadataResponse(). It is\n+          // possible that missing store messages in exchangeMetadataResponse are written by other replica threads\n+          // in parallel between the time 'exchangeMetadataResponse' is calculated and set. So, we check the local store\n+          // again to find if any missing messages are written.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              messagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : messagesFoundInStore) {\n+          BlobId localStoreKey = (BlobId) remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesOnLocalStoreKey(messageInfo, this, localStoreKey);\n+          }\n+\n+          // 2. remove found message from the missing set\n+          exchangeMetadataResponse.missingStoreMessages.remove(messageInfo);", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTIxNTc5OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439215798", "bodyText": "It seems like in a given metadata response, if there are several messages associated with same key in remote node, we get a consolidated/merged message info reflecting its latest value. For example, if we find both PUT and DELETE for same blob id, we only get DELETE. Similarly, if we find PUT and TTLUPDATE, we get one message info with TTL field updated to PUT message. Please correct me in case I am wrong here.\nJust wanted to note that I just separated code to apply ttlupdate/delete/undelete that we do currently in processReplicaMetadataResponse() when we find a key in local store during metadata exchange to the method 'applyUpdatesToBlobInLocalStore()' in order to reapply the same logic when we find key later in this case.", "author": "Arun-LinkedIn", "createdAt": "2020-06-12T05:35:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQ2NTY5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4NDU1MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r437684551", "bodyText": "newly to new", "author": "cgtz", "createdAt": "2020-06-09T20:01:34Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Compare newly messages written to store with missing store messages found in the previous replication cycle", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzNjE0NQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438236145", "bodyText": "exiting -> existing?", "author": "cgtz", "createdAt": "2020-06-10T16:00:18Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +228,130 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in exiting metadata response (via compareAndRemoveMissingStoreMessages())", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI0NDA2OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438244068", "bodyText": "Since ReplicationManager extends ReplicationEngine, it seems more natural to either move LeaderBasedReplicationAdmin to ReplicationEngine or have it in its own file", "author": "cgtz", "createdAt": "2020-06-10T16:10:35Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java", "diffHunk": "@@ -302,26 +335,32 @@ private int getReplicaThreadIndexToUse(String datacenter) {\n    * Get thread pool for given datacenter. Create thread pool for a datacenter if its thread pool doesn't exist.\n    * @param datacenter The datacenter String.\n    * @param startThread If thread needs to be started when create.\n+   * @param leaderBasedReplicationAdmin to co-ordinate replication between leader and standby replicas of a partition\n+   *                                    during leader based replication.\n    * @return List of {@link ReplicaThread}s. Return null if number of replication thread in config is 0 for this DC.\n    */\n-  private List<ReplicaThread> getOrCreateThreadPoolIfNecessary(String datacenter, boolean startThread) {\n+  private List<ReplicaThread> getOrCreateThreadPoolIfNecessary(String datacenter, boolean startThread,\n+      ReplicationManager.LeaderBasedReplicationAdmin leaderBasedReplicationAdmin) {\n     int numOfThreadsInPool =\n         datacenter.equals(dataNodeId.getDatacenterName()) ? replicationConfig.replicationNumOfIntraDCReplicaThreads\n             : replicationConfig.replicationNumOfInterDCReplicaThreads;\n     if (numOfThreadsInPool <= 0) {\n       return null;\n     }\n     return replicaThreadPoolByDc.computeIfAbsent(datacenter,\n-        key -> createThreadPool(datacenter, numOfThreadsInPool, startThread));\n+        key -> createThreadPool(datacenter, numOfThreadsInPool, startThread, leaderBasedReplicationAdmin));\n   }\n \n   /**\n    * Create thread pool for a datacenter.\n    * @param datacenter The datacenter String.\n    * @param numberOfThreads Number of threads to create for the thread pool.\n    * @param startThread If thread needs to be started when create.\n+   * @param leaderBasedReplicationAdmin to co-ordinate replication between leader and standby replicas of a partition\n+   *                                    during leader based replication.\n    */\n-  private List<ReplicaThread> createThreadPool(String datacenter, int numberOfThreads, boolean startThread) {\n+  private List<ReplicaThread> createThreadPool(String datacenter, int numberOfThreads, boolean startThread,\n+      ReplicationManager.LeaderBasedReplicationAdmin leaderBasedReplicationAdmin) {", "originalCommit": "0aec5f32529034a62feb32e36be9610695dd6358", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg5NjI1Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438896252", "bodyText": "swallowing this exception means that one may end up with a partial list of remoteReplicaInfos. Is that ok for the callers of this method?", "author": "cgtz", "createdAt": "2020-06-11T15:56:32Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -210,20 +229,27 @@ public boolean removeReplica(ReplicaId replicaId) {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n     PartitionId partition = replicaId.getPartitionId();\n     Store store = storeManager.getStore(partition);\n-    for (ReplicaId remoteReplica : peerReplicas) {\n-      // We need to ensure that a replica token gets persisted only after the corresponding data in the\n-      // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n-      // to determine the token flush interval\n-      FindToken findToken =\n-          this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n-      RemoteReplicaInfo remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n-          TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n-          SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n-      replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n-      remoteReplicaInfos.add(remoteReplicaInfo);\n-    }\n-    if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n-      replicationMetrics.addLagMetricForPartition(partition);\n+    try {\n+      for (ReplicaId remoteReplica : peerReplicas) {\n+        // We need to ensure that a replica token gets persisted only after the corresponding data in the\n+        // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n+        // to determine the token flush interval\n+        FindToken findToken =\n+            this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+        RemoteReplicaInfo remoteReplicaInfo = null;\n+        remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n+            TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n+            SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo(),\n+            storeKeyConverterFactory.getStoreKeyConverter());\n+\n+        replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n+        remoteReplicaInfos.add(remoteReplicaInfo);\n+      }\n+      if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n+        replicationMetrics.addLagMetricForPartition(partition);\n+      }\n+    } catch (Exception e) {\n+      logger.error(\"Encountered exception instantiating RemoteReplicaInfos\", e);", "originalCommit": "f72bbbeeb65b88bc4287c837deade10937c8b012", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTEwMTEwMg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439101102", "bodyText": "Sure, you are right, may be it is not ok to end up with partial list of remoteReplicaInfos. Removed try/catch block for handling the exception now. Previously, added this to handle exception from instantiation of StoreKeyConverter object being passed (added in this PR) to RemoteReplicaInfo constructor. Made changes to avoid passing StoreKeyConverter to RemoteReplicaInfo and instead directly store the converted keys in RemoteReplicaInfo.exchageMetadataResponse.remoteKeyToLocalKeyMap.", "author": "Arun-LinkedIn", "createdAt": "2020-06-11T22:15:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg5NjI1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg5ODI2NA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438898264", "bodyText": "looks like this line isn't needed: remoteReplicaInfo = null; remoteReplicaInfo = ...; -> remoteReplicaInfo = ...", "author": "cgtz", "createdAt": "2020-06-11T15:59:23Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -210,20 +229,27 @@ public boolean removeReplica(ReplicaId replicaId) {\n     List<RemoteReplicaInfo> remoteReplicaInfos = new ArrayList<>();\n     PartitionId partition = replicaId.getPartitionId();\n     Store store = storeManager.getStore(partition);\n-    for (ReplicaId remoteReplica : peerReplicas) {\n-      // We need to ensure that a replica token gets persisted only after the corresponding data in the\n-      // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n-      // to determine the token flush interval\n-      FindToken findToken =\n-          this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n-      RemoteReplicaInfo remoteReplicaInfo = new RemoteReplicaInfo(remoteReplica, replicaId, store, findToken,\n-          TimeUnit.SECONDS.toMillis(storeConfig.storeDataFlushIntervalSeconds) * Replication_Delay_Multiplier,\n-          SystemTime.getInstance(), remoteReplica.getDataNodeId().getPortToConnectTo());\n-      replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerPartitionLagInMetric);\n-      remoteReplicaInfos.add(remoteReplicaInfo);\n-    }\n-    if (replicationConfig.replicationTrackPerPartitionLagFromRemote) {\n-      replicationMetrics.addLagMetricForPartition(partition);\n+    try {\n+      for (ReplicaId remoteReplica : peerReplicas) {\n+        // We need to ensure that a replica token gets persisted only after the corresponding data in the\n+        // store gets flushed to disk. We use the store flush interval multiplied by a constant factor\n+        // to determine the token flush interval\n+        FindToken findToken =\n+            this.tokenHelper.getFindTokenFactoryFromReplicaType(remoteReplica.getReplicaType()).getNewFindToken();\n+        RemoteReplicaInfo remoteReplicaInfo = null;", "originalCommit": "f72bbbeeb65b88bc4287c837deade10937c8b012", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkwMTUyMg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438901522", "bodyText": "Could PartitionLeaderInfo be compressed into LeaderBasedReplicationAdmin unless there is a future use case for PLI to be used separately from LBRA? It seems like most methods of LBRA just call the similarly named method of PLI.", "author": "cgtz", "createdAt": "2020-06-11T16:04:39Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -451,4 +487,197 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+    private final PartitionLeaderInfo partitionLeaderInfo;\n+\n+    LeaderBasedReplicationAdmin() {\n+      partitionLeaderInfo = new PartitionLeaderInfo();\n+    }\n+\n+    /**\n+     * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+     * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+     * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+     * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+     * missing messages are written to store.\n+     * @param partitionId partition ID of the messages written to store\n+     * @param messageInfoList list of messages written to store\n+     */\n+    void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+      rwLock.readLock().lock();\n+      try {\n+        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n+      } finally {\n+        rwLock.readLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Add a leader partition and its set of peer leader replicas.\n+     * @param partitionName name of the partition to be added\n+     */\n+    public void addLeaderPartition(String partitionName) {\n+      partitionLeaderInfo.addPartition(partitionName);\n+    }\n+\n+    /**\n+     * Remove a leader partition from the map of leader partitions.\n+     * @param partitionName name of the partition to be removed\n+     */\n+    public void removeLeaderPartition(String partitionName) {\n+      partitionLeaderInfo.removePartition(partitionName);\n+    }\n+\n+    /**\n+     * Refreshes the list of remote leaders for all leader partitions by querying the latest information from\n+     * RoutingTableSnapshots of all data centers.\n+     */\n+    public void refreshPeerLeadersForLeaderPartitions() {\n+      partitionLeaderInfo.refreshPeerLeadersForAllPartitions();\n+    }\n+\n+    /**\n+     * Get a map of partitions to their sets of peer leader replicas (this method is only by ReplicationTest for now)\n+     * @return an unmodifiable map of peer leader replicas stored by partition\n+     */\n+    public Map<String, Set<ReplicaId>> getPeerLeaderReplicasByPartition() {\n+      return partitionLeaderInfo.getPeerLeaderReplicasByPartition();\n+    }\n+\n+    /**\n+     * Checks if a remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).\n+     * @param partitionName name of local leader partition\n+     * @param replicaId remote replica to be checked\n+     * @return true if remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).\n+     */\n+    public boolean isPeerReplicaLeaderForPartition(String partitionName, ReplicaId replicaId) {\n+      return partitionLeaderInfo.isPeerReplicaLeaderForPartition(partitionName, replicaId);\n+    }\n+\n+    /**\n+     * Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+     */\n+    class PartitionLeaderInfo {", "originalCommit": "f72bbbeeb65b88bc4287c837deade10937c8b012", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzNTg3Mw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439935873", "bodyText": "Sure, compressed PartitionLeaderInfo into LeaderBasedReplicationAdmin.", "author": "Arun-LinkedIn", "createdAt": "2020-06-15T05:22:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkwMTUyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkxNzQ3MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r438917471", "bodyText": "It looks like refreshPeerLeadersForAllPartitions has a slightly different way of building the set of peerLeaderReplicas. Could both of these methods use the same approach (whichever one you prefer)?", "author": "cgtz", "createdAt": "2020-06-11T16:29:47Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -451,4 +487,197 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+    private final PartitionLeaderInfo partitionLeaderInfo;\n+\n+    LeaderBasedReplicationAdmin() {\n+      partitionLeaderInfo = new PartitionLeaderInfo();\n+    }\n+\n+    /**\n+     * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+     * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+     * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+     * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+     * missing messages are written to store.\n+     * @param partitionId partition ID of the messages written to store\n+     * @param messageInfoList list of messages written to store\n+     */\n+    void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+      rwLock.readLock().lock();\n+      try {\n+        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n+      } finally {\n+        rwLock.readLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Add a leader partition and its set of peer leader replicas.\n+     * @param partitionName name of the partition to be added\n+     */\n+    public void addLeaderPartition(String partitionName) {\n+      partitionLeaderInfo.addPartition(partitionName);\n+    }\n+\n+    /**\n+     * Remove a leader partition from the map of leader partitions.\n+     * @param partitionName name of the partition to be removed\n+     */\n+    public void removeLeaderPartition(String partitionName) {\n+      partitionLeaderInfo.removePartition(partitionName);\n+    }\n+\n+    /**\n+     * Refreshes the list of remote leaders for all leader partitions by querying the latest information from\n+     * RoutingTableSnapshots of all data centers.\n+     */\n+    public void refreshPeerLeadersForLeaderPartitions() {\n+      partitionLeaderInfo.refreshPeerLeadersForAllPartitions();\n+    }\n+\n+    /**\n+     * Get a map of partitions to their sets of peer leader replicas (this method is only by ReplicationTest for now)\n+     * @return an unmodifiable map of peer leader replicas stored by partition\n+     */\n+    public Map<String, Set<ReplicaId>> getPeerLeaderReplicasByPartition() {\n+      return partitionLeaderInfo.getPeerLeaderReplicasByPartition();\n+    }\n+\n+    /**\n+     * Checks if a remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).\n+     * @param partitionName name of local leader partition\n+     * @param replicaId remote replica to be checked\n+     * @return true if remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).\n+     */\n+    public boolean isPeerReplicaLeaderForPartition(String partitionName, ReplicaId replicaId) {\n+      return partitionLeaderInfo.isPeerReplicaLeaderForPartition(partitionName, replicaId);\n+    }\n+\n+    /**\n+     * Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+     */\n+    class PartitionLeaderInfo {\n+\n+      private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();\n+      private final ReadWriteLock rwLockForLeaderReplicaUpdates = new ReentrantReadWriteLock();\n+\n+      public PartitionLeaderInfo() {\n+\n+        // We can't initialize the peerLeaderReplicasByPartition map on startup because we don't know the leader partitions\n+        // on local server until it has finished participating with Helix. It will be updated after server participates\n+        // with Helix and receives LEADER transition (via onPartitionBecomeLeaderFromStandby()).\n+      }\n+\n+      /**\n+       * Get a map of partitions to their sets of peer leader replicas (this method is only by ReplicationTest for now)\n+       * @return an unmodifiable map of peer leader replicas stored by partition\n+       */\n+      public Map<String, Set<ReplicaId>> getPeerLeaderReplicasByPartition() {\n+        return Collections.unmodifiableMap(peerLeaderReplicasByPartition);\n+      }\n+\n+      /**\n+       * Add a leader partition and its set of peer leader replicas. This method is thread safe.\n+       * @param partitionName name of the partition to be added\n+       */\n+      public void addPartition(String partitionName) {\n+\n+        // 1. get local replica from store manager\n+        ReplicaId localReplica = storeManager.getReplica(partitionName);\n+\n+        // Read-write lock avoids contention from threads removing old leader partitions (removePartition()) and\n+        // threads updating existing leader partitions (refreshPeerLeadersForAllPartitions())\n+        rwLockForLeaderReplicaUpdates.writeLock().lock();\n+        try {\n+          // 2. Get the peer leader replicas from all data centers for this partition\n+          List<? extends ReplicaId> leaderReplicas =\n+              localReplica.getPartitionId().getReplicaIdsByState(ReplicaState.LEADER, null);\n+\n+          // 3. Collect and log the list of peer leader replicas associated with this partition\n+          Set<ReplicaId> peerLeaderReplicas = new HashSet<>();", "originalCommit": "f72bbbeeb65b88bc4287c837deade10937c8b012", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzNjExNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439936116", "bodyText": "Yeah, true. Made changes to keep the approach same in both methods.", "author": "Arun-LinkedIn", "createdAt": "2020-06-15T05:23:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkxNzQ3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTY2MzY2Nw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439663667", "bodyText": "Can we add logger.info here to print out the replication model that is adopted in this class?", "author": "jsjtzyy", "createdAt": "2020-06-12T22:17:27Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -58,22 +63,36 @@\n   protected boolean started = false;\n   private final StoreConfig storeConfig;\n   private final DataNodeId currentNode;\n-  private final ReadWriteLock rwLock = new ReentrantReadWriteLock();\n   private final boolean trackPerPartitionLagInMetric;\n+  protected LeaderBasedReplicationAdmin leaderBasedReplicationAdmin = null;\n \n   public ReplicationManager(ReplicationConfig replicationConfig, ClusterMapConfig clusterMapConfig,\n       StoreConfig storeConfig, StoreManager storeManager, StoreKeyFactory storeKeyFactory, ClusterMap clusterMap,\n       ScheduledExecutorService scheduler, DataNodeId dataNode, ConnectionPool connectionPool,\n       MetricRegistry metricRegistry, NotificationSystem requestNotification,\n       StoreKeyConverterFactory storeKeyConverterFactory, String transformerClassName,\n       ClusterParticipant clusterParticipant) throws ReplicationException {\n+    this(replicationConfig, clusterMapConfig, storeConfig, storeManager, storeKeyFactory, clusterMap, scheduler,\n+        dataNode, connectionPool, metricRegistry, requestNotification, storeKeyConverterFactory, transformerClassName,\n+        clusterParticipant, null);\n+  }\n+\n+  public ReplicationManager(ReplicationConfig replicationConfig, ClusterMapConfig clusterMapConfig,\n+      StoreConfig storeConfig, StoreManager storeManager, StoreKeyFactory storeKeyFactory, ClusterMap clusterMap,\n+      ScheduledExecutorService scheduler, DataNodeId dataNode, ConnectionPool connectionPool,\n+      MetricRegistry metricRegistry, NotificationSystem requestNotification,\n+      StoreKeyConverterFactory storeKeyConverterFactory, String transformerClassName,\n+      ClusterParticipant clusterParticipant, FindTokenHelper findTokenHelper) throws ReplicationException {\n     super(replicationConfig, clusterMapConfig, storeKeyFactory, clusterMap, scheduler, dataNode,\n         clusterMap.getReplicaIds(dataNode), connectionPool, metricRegistry, requestNotification,\n-        storeKeyConverterFactory, transformerClassName, clusterParticipant, storeManager);\n+        storeKeyConverterFactory, transformerClassName, clusterParticipant, storeManager, findTokenHelper);\n     this.storeConfig = storeConfig;\n     this.currentNode = dataNode;\n     trackPerPartitionLagInMetric = replicationConfig.replicationTrackPerDatacenterLagFromLocal;\n     clusterMap.registerClusterMapListener(new ClusterMapChangeListenerImpl());\n+    if (replicationConfig.replicationModelAcrossDatacenters.equals(ReplicationModelType.LEADER_BASED)) {\n+      leaderBasedReplicationAdmin = new LeaderBasedReplicationAdmin();\n+    }", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkxMzM4Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439913386", "bodyText": "minor: complete the comment please", "author": "jsjtzyy", "createdAt": "2020-06-15T03:28:53Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -99,6 +111,16 @@ Port getPort() {\n     return this.port;\n   }\n \n+  /**\n+   * Set the store information.\n+   * This is ONLY used in UNIT TEST to set mock in-memory local store to be used during replication. For production\n+   * code, store will be provided during construction of this object from StorageManager.\n+   * @param localStore", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkxOTk1OQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439919959", "bodyText": "I would like to double check the condition, isn't it supposed to be convertedMissingStoreKeys.contains(convertedKey)? Correct me if I misunderstood this.", "author": "jsjtzyy", "createdAt": "2020-06-15T04:03:34Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +230,126 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Check if missing store messages for this replica (cached in previous replication cycle) are now found in store by\n+   * comparing with list of messages that are recently added to store (input param: messagesWrittenToStore). If input\n+   * list 'messagesWrittenToStore' is not provided, check for missing messages by directly looking into store.\n+   * If there are matching messages (based on store key), do the following:\n+   *    1. Compare blob metadata in local store with cached remote message info and reconcile ttl-update, delete and un-delete states.\n+   *    2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *    3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null) {\n+      try {\n+        List<MessageInfo> missingMessagesFoundInStore = new ArrayList<>();\n+        if (messagesWrittenToStore != null) {\n+          // Check if missing messages for this replica are now found to store by comparing with\n+          // messages provided in input parameter.\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              missingMessagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // If input list 'messagesWrittenToStore' is not provided, check for missing messages in the local store directly\n+          // by doing findMissingKeys() operation on store.\n+          // This is needed while we are setting the metadata response on this replica as it is possible that missing\n+          // store messages in exchangeMetadataResponse are written by other replica threads in parallel between the\n+          // time 'exchangeMetadataResponse' is calculated and set. So, we check with local store again.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE4MzM4NA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r441183384", "bodyText": "Ignore this comment, the initial logic is correct.", "author": "jsjtzyy", "createdAt": "2020-06-16T22:45:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkxOTk1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyMTQ0Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439921442", "bodyText": "If you look at AmbryServerReplica toString() method, replicaId already contains node info. You can either remove replicaId.getDataNodeId() or change replicaId to replicaId.getPartitionId().toPathString().", "author": "jsjtzyy", "createdAt": "2020-06-15T04:11:38Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,23 +230,126 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n+\n+    // It is possible that missing store messages in this exchangeMetadataResponse are written to store in parallel\n+    // between the time it is calculated and set here. So, we look up the local store\n+    // again and remove any messages found in store from exchangeMetadataResponse.missingStoreMessages set.\n+    compareAndRemoveMissingStoreMessages(null);\n+  }\n+\n+  /**\n+   * Checks if the metadata response for this replica is empty or if there are no missing store messages present in it.\n+   * This is used in leader-based replication to avoid sending next metadata request for cross colo standby replicas\n+   * until all the missing store messages in metadata response are received via intra-dc replication.\n+   * @return true if metadata response is empty (null) or there are no missing store keys in it.\n+   */\n+  synchronized boolean isExchangeMetadataResponseEmpty() {\n+    return exchangeMetadataResponse == null || exchangeMetadataResponse.missingStoreMessages == null\n+        || exchangeMetadataResponse.missingStoreMessages.isEmpty();\n+  }\n+\n+  /**\n+   * Check if missing store messages for this replica (cached in previous replication cycle) are now found in store by\n+   * comparing with list of messages that are recently added to store (input param: messagesWrittenToStore). If input\n+   * list 'messagesWrittenToStore' is not provided, check for missing messages by directly looking into store.\n+   * If there are matching messages (based on store key), do the following:\n+   *    1. Compare blob metadata in local store with cached remote message info and reconcile ttl-update, delete and un-delete states.\n+   *    2. Remove them from set of missing messages (exchangeMetadataResponse.missingStoreMessages).\n+   *    3. When all the missing store messages are found in store, move the token forward.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void compareAndRemoveMissingStoreMessages(List<MessageInfo> messagesWrittenToStore) {\n+    if (exchangeMetadataResponse != null && exchangeMetadataResponse.missingStoreMessages != null\n+        && replicaThread != null) {\n+      try {\n+        List<MessageInfo> missingMessagesFoundInStore = new ArrayList<>();\n+        if (messagesWrittenToStore != null) {\n+          // Check if missing messages for this replica are now found to store by comparing with\n+          // messages provided in input parameter.\n+          Set<StoreKey> keysWrittenToStore =\n+              messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+              missingMessagesFoundInStore.add(messageInfo);\n+            }\n+          }\n+        } else {\n+          // If input list 'messagesWrittenToStore' is not provided, check for missing messages in the local store directly\n+          // by doing findMissingKeys() operation on store.\n+          // This is needed while we are setting the metadata response on this replica as it is possible that missing\n+          // store messages in exchangeMetadataResponse are written by other replica threads in parallel between the\n+          // time 'exchangeMetadataResponse' is calculated and set. So, we check with local store again.\n+          Map<MessageInfo, StoreKey> remoteMessageToConvertedKeyNonNull = new HashMap<>();\n+          for (MessageInfo messageInfo : exchangeMetadataResponse.missingStoreMessages) {\n+            StoreKey convertedKey = exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+            if (convertedKey != null) {\n+              remoteMessageToConvertedKeyNonNull.put(messageInfo, convertedKey);\n+            }\n+          }\n+          Set<StoreKey> convertedMissingStoreKeys =\n+              localStore.findMissingKeys(new ArrayList<>(remoteMessageToConvertedKeyNonNull.values()));\n+          remoteMessageToConvertedKeyNonNull.forEach((messageInfo, convertedKey) -> {\n+            if (!convertedMissingStoreKeys.contains(convertedKey)) {\n+              missingMessagesFoundInStore.add(messageInfo);\n+            }\n+          });\n+        }\n+\n+        // Go through the messages that are now found in store and reconcile delete, ttl-update and un-delete states.\n+        // After that, delete them from the missingStoreMessages set and move the token forward if all missing messages\n+        // are found.\n+        for (MessageInfo messageInfo : missingMessagesFoundInStore) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+\n+          // 1. compare blob metadata of newly written message with the cached remote message info and\n+          // reconcile delete, ttl-update and un-delete states.\n+          if (localStoreKey != null) {\n+            replicaThread.applyUpdatesToBlobInLocalStore(messageInfo, this, localStoreKey);\n+          }\n+\n+          // 2. remove found message from the missing set\n+          exchangeMetadataResponse.missingStoreMessages.remove(messageInfo);\n+\n+          // 3. if all missing store messages are found, move token and store local lag from remote\n+          if (exchangeMetadataResponse.missingStoreMessages.size() == 0) {\n+            setToken(exchangeMetadataResponse.remoteToken);\n+            setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+\n+            logger.trace(\"Updating token {} and lag {} for remote replica: {} in Remote node: {}\",\n+                exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes, replicaId,", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyNDQ4MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439924480", "bodyText": "nit: let's directly use leaderBasedReplicationAdmin as argument name to align with its class name.", "author": "jsjtzyy", "createdAt": "2020-06-15T04:27:16Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -130,7 +130,8 @@ public ReplicaThread(String threadName, FindTokenHelper findTokenHelper, Cluster\n       ReplicationConfig replicationConfig, ReplicationMetrics replicationMetrics, NotificationSystem notification,\n       StoreKeyConverter storeKeyConverter, Transformer transformer, MetricRegistry metricRegistry,\n       boolean replicatingOverSsl, String datacenterName, ResponseHandler responseHandler, Time time,\n-      ReplicaSyncUpManager replicaSyncUpManager, PartitionLeaderInfo partitionLeaderInfo) {\n+      ReplicaSyncUpManager replicaSyncUpManager,\n+      ReplicationManager.LeaderBasedReplicationAdmin leaderBasedReplicationTracker) {", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyNzE0Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439927142", "bodyText": "The partitionName is a pure number, it's supposed to be toPathString() instead of toString()", "author": "jsjtzyy", "createdAt": "2020-06-15T04:41:27Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -340,9 +341,21 @@ public void replicate() {\n             || !remoteReplicaInfo.getLocalStore().isStarted()) {\n           continue;\n         }\n+\n+        // If leader based replication is enabled, don't include standby replicas until their missing store\n+        // keys from previous metadata exchange are received via intra-dc replication.\n+        if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+          String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyODE3Nw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439928177", "bodyText": "Updating fixMissingStoreKeysTimeInMs can be out of if block", "author": "jsjtzyy", "createdAt": "2020-06-15T04:46:50Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -369,7 +382,32 @@ public void replicate() {\n                 exchangeMetadata(connectedChannel, replicaSubList);\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             startTimeInMs = SystemTime.getInstance().milliseconds();\n-            fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+\n+            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n+            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n+                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n+\n+            if (replicasToFetchMissingStoreKeys.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,\n+                  exchangeMetadataResponseListForReplicasToFetch);\n+              fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyOTIzNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439929236", "bodyText": "Let's move this into if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) block.", "author": "jsjtzyy", "createdAt": "2020-06-15T04:51:53Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1123,6 +1204,74 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n+      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkyOTQ2MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439929460", "bodyText": "Use toPathString() instead of toString().", "author": "jsjtzyy", "createdAt": "2020-06-15T04:53:00Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1123,6 +1204,74 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n+      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzMDQxOA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439930418", "bodyText": "Note that fixMissingStoreKeys() method has replicasToReplicatePerNode.size() == 0 check at the very beginning. If the size is 0, it throws exception. However, in a rare case where all replicas in this subList are standby replicas, the replicasToFetchMissingStoreKeys could be 0, we should graceful skip it rather than throw an exception. Could you make a minor change in fixMissingStoreKeys ?", "author": "jsjtzyy", "createdAt": "2020-06-15T04:57:55Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -369,7 +382,32 @@ public void replicate() {\n                 exchangeMetadata(connectedChannel, replicaSubList);\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             startTimeInMs = SystemTime.getInstance().milliseconds();\n-            fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+\n+            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n+            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n+                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n+\n+            if (replicasToFetchMissingStoreKeys.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzNjQzNw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439936437", "bodyText": "Add a metric for this case to evaluate how many cross-colo requests are sent due to no progress on specific replicas.\nAlso, we can add a to-do here to improve this: fetch blob from local leader first, if the result is Blob_Not_Found, we do the cross-colo request.\nIn most cases, fetching blob from local leader should be able to unblock the replication on standby replica.", "author": "jsjtzyy", "createdAt": "2020-06-15T05:25:20Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -369,7 +382,32 @@ public void replicate() {\n                 exchangeMetadata(connectedChannel, replicaSubList);\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n             startTimeInMs = SystemTime.getInstance().milliseconds();\n-            fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+\n+            List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys = new ArrayList<>();\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch = new ArrayList<>();\n+            getRemoteReplicasToFetchMissingStoreKeys(replicaSubList, exchangeMetadataResponseList,\n+                replicasToFetchMissingStoreKeys, exchangeMetadataResponseListForReplicasToFetch);\n+\n+            if (replicasToFetchMissingStoreKeys.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicasToFetchMissingStoreKeys,\n+                  exchangeMetadataResponseListForReplicasToFetch);\n+              fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+            }\n+          }\n+\n+          // Send a special request to do cross colo fetches for all standby replicas if their missing keys\n+          // in previous metadata exchange have not arrived for\n+          // time duration > replicationConfig.replicationWaitTimeForCrossColoFetchForStandbyReplicasMs.\n+          // This is applicable only for LEADER_BASED replication and cross-colo threads.\n+          List<RemoteReplicaInfo> remoteReplicasWithOldMissingKeys = getRemoteReplicasWithOldMissingKeys(remoteNode);\n+          if (remoteReplicasWithOldMissingKeys.size() > 0) {\n+            logger.debug(\"Cross colo replication request for standby remote replicas {} on remote node {}\",\n+                remoteReplicasWithOldMissingKeys, remoteNode);\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseList = remoteReplicasWithOldMissingKeys.stream()\n+                .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n+                .collect(Collectors.toList());\n+            fixMissingStoreKeysTimeInMs = -1;\n+            fixMissingStoreKeys(connectedChannel, remoteReplicasWithOldMissingKeys, exchangeMetadataResponseList);", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkzODAwMw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439938003", "bodyText": "How about renaming this to getRemoteReplicasTimedOutOnNoProgress?", "author": "jsjtzyy", "createdAt": "2020-06-15T05:32:10Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1123,6 +1204,74 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param replicasToFetchMissingStoreKeys output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForReplicasToFetch output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getRemoteReplicasToFetchMissingStoreKeys(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList,\n+      List<RemoteReplicaInfo> replicasToFetchMissingStoreKeys,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForReplicasToFetch) throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        ExchangeMetadataResponse exchangeMetadataResponse = exchangeMetadataResponseList.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          replicasToFetchMissingStoreKeys.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForReplicasToFetch.add(exchangeMetadataResponse);\n+        }\n+      }\n+    } else {\n+      replicasToFetchMissingStoreKeys.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForReplicasToFetch.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of standby remote replica infos from a given remote node whose keys in their metadata responses\n+   * haven't arrived for long time so that we can do cross colo fetches on them.\n+   * @return list of remote replica infos\n+   */\n+  private List<RemoteReplicaInfo> getRemoteReplicasWithOldMissingKeys(DataNodeId remoteNode) {", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTk0ODAxOQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r439948019", "bodyText": "Could you explain the purpose of this class and where it is used?", "author": "jsjtzyy", "createdAt": "2020-06-15T06:09:03Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1161,6 +1320,19 @@ ReplicationMetrics getReplicationMetrics() {\n     }\n   }\n \n+  /**\n+   *\n+   */\n+  public static class RemoteMessageAndLocalStoreKeyInfo {", "originalCommit": "1378a6e122fab7467f5af5bcd135301a1c6668e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5c3a4e66ac5069624d780d0497a748db9572dbcc", "url": "https://github.com/linkedin/ambry/commit/5c3a4e66ac5069624d780d0497a748db9572dbcc", "message": "Changes for:\n1. Adding logger.info when leader-based replication is used.\n2. Using correct string ID for Partitions, i.e. partitionId.toPathString() instead of partitionId.toString().\n3. Few other minor changes like renaming of methods, variable names, etc.", "committedDate": "2020-06-16T01:03:44Z", "type": "forcePushed"}, {"oid": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "url": "https://github.com/linkedin/ambry/commit/511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "message": "1. Move setup and helper methods in ReplicationTest to seperate file 'ReplicationTestHelper'\n2. Move leader based replication tests to seperate file 'LeaderBasedReplicationTest'", "committedDate": "2020-06-23T19:48:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1NzkyNA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444557924", "bodyText": "I have a problem with changing configuration name here. It's a high risk action, which might break the close source ambryli. Please make sure that nothing will break before moving on with this change.", "author": "justinlin-linkedin", "createdAt": "2020-06-23T23:13:10Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -192,7 +192,7 @@\n    */\n   @Config(\"replication.model.across.datacenters\")\n   @Default(\"ALL_TO_ALL\")\n-  public final ReplicationModelType replicationModelType;\n+  public final ReplicationModelType replicationModelAcrossDatacenters;", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1ODkyMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444558920", "bodyText": "nit: Can we use a constant string for config here, since this is a newly add config. Check out REPLICATION_CLOUD_TOKEN_FACTORY in the same file.", "author": "justinlin-linkedin", "createdAt": "2020-06-23T23:16:22Z", "path": "ambry-api/src/main/java/com/github/ambry/config/ReplicationConfig.java", "diffHunk": "@@ -216,6 +216,19 @@\n   @Default(\"false\")\n   public final boolean replicationContainerDeletionEnabled;\n \n+  /**\n+   * The time (in seconds) for standby replicas to wait before fetching missing keys from replicas in cross colo\n+   * data centers. This is applicable during leader based replication where standby replicas don't fetch the missing\n+   * keys found in metadata exchange from cross colo replicas and expect them to come from leader replica in\n+   * local data center via intra-dc replication. This time out ensures that standby replicas are not stuck indefinitely\n+   * waiting for the missing keys to come via intra-dc replication by doing cross colo fetch themselves.\n+   * Default value is 120 seconds. If configured to -1, this timeout doesn't take effect, i.e. cross colo fetch for\n+   * standby replicas is never done.\n+   */\n+  @Config(\"replication.standby.wait.timeout.to.trigger.cross.colo.fetch.seconds\")\n+  @Default(\"120\")\n+  public final int replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds;\n+", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU2MDM4Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444560382", "bodyText": "typo: ttl_update, undelete", "author": "justinlin-linkedin", "createdAt": "2020-06-23T23:20:55Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -739,68 +856,10 @@ private void processReplicaMetadataResponse(Set<MessageInfo> missingRemoteStoreM\n               remoteNode, threadName, remoteReplicaInfo.getReplicaId(), localKey);\n         }\n       } else {\n-        // the key is present in the local store. Mark it for deletion if it is deleted in the remote store and not\n-        // deleted yet locally\n-        MessageInfo localMessageInfo = remoteReplicaInfo.getLocalStore().findKey(localKey);\n-        boolean deletedLocally = localMessageInfo.isDeleted();\n-        boolean ttlUpdatedLocally = localMessageInfo.isTtlUpdated();\n-        short localLifeVersion = localMessageInfo.getLifeVersion();\n-        short remoteLifeVersion = messageInfo.getLifeVersion();\n-        if (localLifeVersion > remoteLifeVersion) {\n-          // if the lifeVersion in local store is greater than the remote lifeVersion, then nothing needs to be done.\n-          continue;\n-        } else if (localLifeVersion == remoteLifeVersion) {\n-          // we are operating in the same version, in this case, delete would be the final state.\n-          if (!deletedLocally) {\n-            // Only adds record when it's not deleted yet. Since delete is the final state for this lifeVersion, if there\n-            // is a delete record for the current lifeVersion, then nothing needs to be done.\n-            MessageInfo info = new MessageInfo(localKey, 0, localKey.getAccountId(), localKey.getContainerId(),\n-                messageInfo.getOperationTimeMs(), remoteLifeVersion);\n-            if (messageInfo.isTtlUpdated() && !ttlUpdatedLocally) {\n-              applyTtlUpdate(info, remoteReplicaInfo);\n-            }\n-            if (messageInfo.isDeleted()) {\n-              applyDelete(info, remoteReplicaInfo);\n-            }\n-          }\n-        } else {\n-          // if we are here, then the remote lifeVersion is greater than the local lifeVersion.\n-          // we need to reconcile the local state with the remote state.\n-          //\n-          // There are three states we have to reconcile: lifeVersion, ttl_update, is_deleted.\n-          // To reconcile lifeVersion and is_deleted, we have to add a Delete or Undelete record, based on what the final state is.\n-          // to reconcile ttl_update, if the final state is delete, then, we have to add ttl_update before delete, other, we can add ttl_update after undelete.\n-          MessageInfo info = new MessageInfo(localKey, 0, localKey.getAccountId(), localKey.getContainerId(),\n-              messageInfo.getOperationTimeMs(), remoteLifeVersion);\n-          boolean shouldInsertTtlUpdate = false;\n-          if (messageInfo.isTtlUpdated() && !ttlUpdatedLocally) {\n-            // make a patch for ttl update\n-            // if the remote state is delete, then we can't insert TTL_UPDATE after delete, we have to insert a ttl_update here\n-            if (messageInfo.isDeleted()) {\n-              // since ttl update can only follow Put or Undelete, make sure it's not locally deleted.\n-              // we can reuse the lifeVersion for undelete and ttl update, since the delete would be the final state of\n-              // this lifeVersion.\n-              if (deletedLocally) {\n-                applyUndelete(info, remoteReplicaInfo);\n-              }\n-              applyTtlUpdate(info, remoteReplicaInfo);\n-            } else {\n-              // if final state is not delete, then to bump lifeVersion in local store to remote lifeVersion, we have to\n-              // add a undelete, and then add a ttl update.\n-              shouldInsertTtlUpdate = true;\n-            }\n-          }\n-\n-          // if we are here, then the ttl update is matched\n-          if (messageInfo.isDeleted()) {\n-            applyDelete(info, remoteReplicaInfo);\n-          } else {\n-            applyUndelete(info, remoteReplicaInfo);\n-            if (shouldInsertTtlUpdate) {\n-              applyTtlUpdate(info, remoteReplicaInfo);\n-            }\n-          }\n-        }\n+        // The key is present in the local store. Compare blob properties (ttl-update, delete, un-delete fields) in", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3MjE3MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444572171", "bodyText": "nit: we should probably pass dataNodeToRemoteReplicaInfo map to this method, instead of replicasToReplicateGroupedByNode inside the method.", "author": "justinlin-linkedin", "createdAt": "2020-06-24T00:02:07Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -343,43 +345,114 @@ public void replicate() {\n             || !remoteReplicaInfo.getLocalStore().isStarted()) {\n           continue;\n         }\n+\n+        if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+          // If leader based replication is enabled, don't include remote standby replicas until their missing store\n+          // keys from previous metadata exchange are received via intra-dc replication.\n+          String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+          ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();\n+          if (!leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplica)\n+              && !remoteReplicaInfo.isExchangeMetadataResponseEmpty()) {\n+            continue;\n+          }\n+        }\n         activeReplicasPerNode.add(remoteReplicaInfo);\n       }\n       logger.trace(\"Replicating from {} RemoteReplicaInfos.\", activeReplicasPerNode.size());\n-      if (activeReplicasPerNode.size() > 0) {\n+\n+      // Get a list of inactive standby replicas whose missing keys haven't arrived for long time. This is applicable\n+      // only in leader-based replication.\n+      // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+      // metadata exchange and expect them to come via leader in local data center through intra-dc replication.\n+      // This is a safety feature to ensure that standby replicas are not stuck waiting for the keys to come from leader\n+      // by fetching the missing keys themselves.\n+      // TODO: As an improvement to this, we can first fetch missing blobs from local leader/other replicas in intra-dc first.\n+      // TODO: If the result to fetch a blob from local dc is Blob_Not_Found, then we can fetch it from replicas in remote datacenter.\n+      // This will involve co-ordination between replica threads containing replicas of same partition.\n+      List<RemoteReplicaInfo> inactiveReplicasPerNodeTimedOutOnNoProgress =\n+          getRemoteReplicasTimedOutOnNoProgress(remoteNode);", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxNTIzOQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r444615239", "bodyText": "I have noticed that every time we have a statement exchangeMetadataResponseList.add, this statement follows, can we move this statement outside of the exchangeMetadata method, or put it in the finally block of exchangeMetadata method.", "author": "justinlin-linkedin", "createdAt": "2020-06-24T02:50:43Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -517,25 +627,31 @@ public void replicate() {\n                 // Must have just been stopped, just skip it and move on.\n                 logger.info(\"Local store not started for remote replica: {}\", remoteReplicaInfo.getReplicaId());\n                 exchangeMetadataResponseList.add(new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n-                remoteReplicaInfo.setExchangeMetadataResponse(\n-                    new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n+                if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+                  remoteReplicaInfo.setExchangeMetadataResponse(\n+                      new ExchangeMetadataResponse(ServerErrorCode.Temporarily_Disabled));\n+                }", "originalCommit": "511b2089f3dff064db1d7ac4c390d5adc8b0ac42", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQyNjg5MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446426890", "bodyText": "nit: I find the words here are confusing, \"should be a leader locally\" doesn't really convey what this function would do, which is it checks if the local and remote replica are both the  leaders for given partition.\nSay if the partition is 100, and when the local replica becomes leader from standby, this map would have an entry {\"100\": List of remote leaders} inserted. But if the local replica becomes standby from leader, this entry would be removed.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T21:52:32Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -455,4 +484,142 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+\n+    //Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+    private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();\n+    private final ReadWriteLock rwLockForLeaderReplicaUpdates = new ReentrantReadWriteLock();\n+\n+    LeaderBasedReplicationAdmin() {\n+      // We can't initialize the peerLeaderReplicasByPartition map on startup because we don't know the leader partitions\n+      // on local server until it has finished participating with Helix. The map will be updated after server participates\n+      // with Helix and receives LEADER transition notifications via onPartitionBecomeLeaderFromStandby().\n+    }\n+\n+    /**\n+     * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+     * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+     * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+     * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+     * missing messages are written to store.\n+     * @param partitionId partition ID of the messages written to store\n+     * @param messageInfoList list of messages written to store\n+     */\n+    void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+      rwLock.readLock().lock();\n+      try {\n+        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n+      } finally {\n+        rwLock.readLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Add a leader partition and its set of peer leader replicas. This method is thread safe.\n+     * @param partitionName name of the partition to be added\n+     */\n+    public void addLeaderPartition(String partitionName) {\n+\n+      // Read-write lock avoids contention from threads removing old leader partitions (removePartition()) and\n+      // threads updating existing leader partitions (refreshPeerLeadersForAllPartitions())\n+      rwLockForLeaderReplicaUpdates.writeLock().lock();\n+      try {\n+        // Get the peer leader replicas from all data centers for this partition\n+        Set<ReplicaId> peerLeaderReplicas = getPeerLeaderReplicaSet(partitionName);\n+        logger.info(\"Adding leader Partition {} with list of peer leader replicas {}\", partitionName,\n+            peerLeaderReplicas);\n+        peerLeaderReplicasByPartition.put(partitionName, peerLeaderReplicas);\n+      } finally {\n+        rwLockForLeaderReplicaUpdates.writeLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Remove a partition from the map of leader partitions. This method is thread safe.\n+     * @param partitionName name of the partition to be removed\n+     */\n+    public void removeLeaderPartition(String partitionName) {\n+      // Read-write lock avoids contention from threads adding new leaders (addPartition()) and\n+      // threads updating existing leader partitions (refreshPeerLeadersForAllPartitions())\n+      rwLockForLeaderReplicaUpdates.writeLock().lock();\n+      try {\n+        logger.info(\"Removing leader Partition {}\", partitionName);\n+        peerLeaderReplicasByPartition.remove(partitionName);\n+      } finally {\n+        rwLockForLeaderReplicaUpdates.writeLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Refreshes the list of remote leaders for all leader partitions by querying the latest information from\n+     * RoutingTableSnapshots of all data centers. This method is thread safe.\n+     */\n+    public void refreshPeerLeadersForLeaderPartitions() {\n+      // Read-write lock usage: Avoids contention between threads doing the following activities:\n+      // 1. Adding new leaders (in addPeerLeadersByPartition())\n+      // 2. Removing old leaders (in removePartition())\n+      // 3. Refreshing remote leader set for existing leaders (current method).\n+      // Explanation for point 3: Multiple threads from different cluster change handlers (we have one cluster change handler for each DC)\n+      // can trigger onRoutingTableUpdate() in parallel which calls this method to refresh leader partitions.\n+      // We need to make sure that the sequence of gathering remote leaders (from RoutingTableSnapshot of each DC) and updating the map is an atomic operation.\n+\n+      rwLockForLeaderReplicaUpdates.writeLock().lock();\n+      try {\n+        for (Map.Entry<String, Set<ReplicaId>> entry : peerLeaderReplicasByPartition.entrySet()) {\n+          String partitionName = entry.getKey();\n+          Set<ReplicaId> previousPeerLeaderReplicas = entry.getValue();\n+          Set<ReplicaId> currentPeerLeaderReplicas = getPeerLeaderReplicaSet(partitionName);\n+          if (!previousPeerLeaderReplicas.equals(currentPeerLeaderReplicas)) {\n+            logger.info(\"Refreshing leader Partition {} with list of peer leader replicas {}\", partitionName,\n+                currentPeerLeaderReplicas);\n+            peerLeaderReplicasByPartition.put(partitionName, currentPeerLeaderReplicas);\n+          }\n+        }\n+      } finally {\n+        rwLockForLeaderReplicaUpdates.writeLock().unlock();\n+      }\n+    }\n+\n+    /**\n+     * Get a map of partitions to their sets of peer leader replicas (this method is only by ReplicationTest for now)\n+     * @return an unmodifiable map of peer leader replicas stored by partition\n+     */\n+    public Map<String, Set<ReplicaId>> getPeerLeaderReplicasByPartition() {\n+      return Collections.unmodifiableMap(peerLeaderReplicasByPartition);\n+    }\n+\n+    /**\n+     * Checks if a remote replica is a leader for a partition (Pre-requisite: the partition itself should be a leader locally).", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQzMjY1OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446432658", "bodyText": "why use concurrentHashMap here, if all the operations are protected by a read write lock?", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:11:46Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -455,4 +484,142 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+\n+    //Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+    private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQzNjMyMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446436320", "bodyText": "We should probably add a metric here to record this error, just in case we want to be alerted.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:25:28Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating from remote colo, limit the replication between\n+      // leader replicas only, i.e. fetch the missing blobs only for leader replicas. Standby replicas will get their\n+      // missing blobs from their leaders in local data center via intra-dc replication.\n+\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+        }\n+      }\n+    } else {\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  private List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(\n+      List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponseForStandbyReplica(RemoteReplicaInfo remoteReplicaInfo) {\n+    try {\n+      ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+      if (!exchangeMetadataResponse.isEmpty()) {\n+\n+        Set<MessageInfo> receivedStoreMessagesWithUpdatesPending =\n+            exchangeMetadataResponse.getReceivedStoreMessagesWithUpdatesPending();\n+        Set<MessageInfo> receivedMessagesWithUpdatesCompleted = new HashSet<>();\n+\n+        // 1. Go through messages whose blobs are received now (via other replicas) and compare blob metadata of\n+        // remote message info with local blob in store and reconcile delete, ttl_update and undelete states\n+        for (MessageInfo messageInfo : receivedStoreMessagesWithUpdatesPending) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+          if (localStoreKey != null) {\n+            applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localStoreKey);\n+          }\n+          receivedMessagesWithUpdatesCompleted.add(messageInfo);\n+        }\n+\n+        // 2. Remove the messages whose updates have been completed\n+        exchangeMetadataResponse.removeReceivedStoreMessagesWithUpdatesPending(receivedMessagesWithUpdatesCompleted);\n+\n+        // 3. If metadata response for this replica is now empty, i.e. updates for all the messages are completed and\n+        // there are no more \"missingMessages + receivedMessagesWithUpdatesPending\", move the remote token forward and\n+        // update local lag from remote for this replica.\n+        if (exchangeMetadataResponse.isEmpty()) {\n+          remoteReplicaInfo.setToken(exchangeMetadataResponse.remoteToken);\n+          remoteReplicaInfo.setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+          logger.trace(\"Updating token {} and lag {} for partition {} in Remote replica: {}\",\n+              exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes,\n+              remoteReplicaInfo.getReplicaId().getPartitionId().toPathString(), remoteReplicaInfo.getReplicaId());\n+          remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+        }\n+      }\n+    } catch (StoreException e) {\n+      logger.error(\"Exception occurred while updating exchangeMetadataResponse for Remote replica info: {}\",\n+          remoteReplicaInfo, e);", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQzNzE2MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446437160", "bodyText": "nit: the function's name is too verbose, can we make it a bit shorter, something like applyUpdatesForMissingKeys.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:28:40Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating from remote colo, limit the replication between\n+      // leader replicas only, i.e. fetch the missing blobs only for leader replicas. Standby replicas will get their\n+      // missing blobs from their leaders in local data center via intra-dc replication.\n+\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+        }\n+      }\n+    } else {\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  private List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(\n+      List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponseForStandbyReplica(RemoteReplicaInfo remoteReplicaInfo) {", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQzODQ3OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446438478", "bodyText": "nit: same here, can we find a shorter name?", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:33:32Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating from remote colo, limit the replication between\n+      // leader replicas only, i.e. fetch the missing blobs only for leader replicas. Standby replicas will get their\n+      // missing blobs from their leaders in local data center via intra-dc replication.\n+\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+        }\n+      }\n+    } else {\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  private List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(\n+      List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null\n+        && replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponseForStandbyReplica(RemoteReplicaInfo remoteReplicaInfo) {\n+    try {\n+      ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+      if (!exchangeMetadataResponse.isEmpty()) {\n+\n+        Set<MessageInfo> receivedStoreMessagesWithUpdatesPending =\n+            exchangeMetadataResponse.getReceivedStoreMessagesWithUpdatesPending();\n+        Set<MessageInfo> receivedMessagesWithUpdatesCompleted = new HashSet<>();\n+\n+        // 1. Go through messages whose blobs are received now (via other replicas) and compare blob metadata of\n+        // remote message info with local blob in store and reconcile delete, ttl_update and undelete states\n+        for (MessageInfo messageInfo : receivedStoreMessagesWithUpdatesPending) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+          if (localStoreKey != null) {\n+            applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localStoreKey);\n+          }\n+          receivedMessagesWithUpdatesCompleted.add(messageInfo);\n+        }\n+\n+        // 2. Remove the messages whose updates have been completed\n+        exchangeMetadataResponse.removeReceivedStoreMessagesWithUpdatesPending(receivedMessagesWithUpdatesCompleted);\n+\n+        // 3. If metadata response for this replica is now empty, i.e. updates for all the messages are completed and\n+        // there are no more \"missingMessages + receivedMessagesWithUpdatesPending\", move the remote token forward and\n+        // update local lag from remote for this replica.\n+        if (exchangeMetadataResponse.isEmpty()) {\n+          remoteReplicaInfo.setToken(exchangeMetadataResponse.remoteToken);\n+          remoteReplicaInfo.setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+          logger.trace(\"Updating token {} and lag {} for partition {} in Remote replica: {}\",\n+              exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes,\n+              remoteReplicaInfo.getReplicaId().getPartitionId().toPathString(), remoteReplicaInfo.getReplicaId());\n+          remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+        }\n+      }\n+    } catch (StoreException e) {\n+      logger.error(\"Exception occurred while updating exchangeMetadataResponse for Remote replica info: {}\",\n+          remoteReplicaInfo, e);\n+      // reset stored metadata response so that metadata request is sent again for this replica\n+      remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+    }\n+  }\n+\n+  /**\n+   * Checks if the input remote replica is a standby replica and has any messages from its previous metadata\n+   * exchange still missing in local store, i.e. they haven't arrived from leader via intra-dc replication.\n+   * @param remoteReplicaInfo remote replica information\n+   * @return true if missing messages in previous metadata exchange are not yet received\n+   */\n+  private boolean containsMissingKeysFromPreviousMetadataExchangeForStandbyReplica(", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0NDIwNw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446444207", "bodyText": "nit: the function name and comments are misleading, it's not only between leaders, it's also between standby and leader if it's local.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T22:57:21Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc4MTgwNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446781806", "bodyText": "Actually, I didn't see fetches between local standby <-> standby, local standby <-> leader in replicate() method.", "author": "jsjtzyy", "createdAt": "2020-06-29T05:34:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0NDIwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4NDA2MA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447884060", "bodyText": "The method is changed. It used to have replicatingFromRemoteColo if-else statement here within the method. Now it's moved outside. This is fine. It's less confusing.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:11:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0NDIwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0ODg4OA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446448888", "bodyText": "nit: the repilcatingFromRemoteColo and leaderBaseReplicationAdmin check seem unnecessary, for this method only used when they are true.", "author": "justinlin-linkedin", "createdAt": "2020-06-26T23:19:11Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1267,200 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Filter list of leader replicas to fetch missing store keys. During leader-based replication, we only fetch\n+   * missing keys from remote leader replicas. For non-leader replicas, we will wait the missing keys to come from\n+   * intra-dc replication via leader in local data center.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+\n+      // If leader based replication is enabled and we are replicating from remote colo, limit the replication between\n+      // leader replicas only, i.e. fetch the missing blobs only for leader replicas. Standby replicas will get their\n+      // missing blobs from their leaders in local data center via intra-dc replication.\n+\n+      if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+        throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+            + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+      }\n+\n+      for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+        RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+        String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+        ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+        // Check if local replica and remote replica are leaders for this partition.\n+        if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+          leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+          exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+        }\n+      }\n+    } else {\n+      // if leader based replication is disabled or we are replicating within intra-colo, include all remote replicas for\n+      // replication.\n+      leaderReplicaInfosOutput.addAll(remoteReplicaInfos);\n+      exchangeMetadataResponseListForLeaderReplicaInfosOutput.addAll(exchangeMetadataResponseList);\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  private List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(\n+      List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null", "originalCommit": "1ac15790d0677ff5918252b81da4b28aa0ea7ea7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxMjIxNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446712216", "bodyText": "minor:  that are written to store by other replica threads", "author": "jsjtzyy", "createdAt": "2020-06-28T23:31:00Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,25 +224,46 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n   }\n \n+  /**\n+   * Compare missing store messages of this replica (found in its exchange metadata response for previous replication\n+   * cycle) with messages that are written to store by other replicas. If there", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxNzIyMA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446717220", "bodyText": "Although readLock may not cause any issue, I think we can simplify this and rely on concurrent map to enforce strict protection in multi-threaded environment:\n        partitionToPartitionInfo.computeIfPresent(partitionId, (k, v) -> {\n          v.updateReplicaInfosOnMessageWrite(messageInfoList);\n          return v;\n        });", "author": "jsjtzyy", "createdAt": "2020-06-29T00:15:41Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationManager.java", "diffHunk": "@@ -455,4 +484,143 @@ public void onPartitionBecomeDroppedFromOffline(String partitionName) {\n       removeReplica(replica);\n     }\n   }\n+\n+  /**\n+   * To co-ordinate replication between leader and standby replicas of a partition during leader based replication.\n+   */\n+  class LeaderBasedReplicationAdmin {\n+\n+    //Maintains the list of leader partitions on local node and their corresponding peer leaders in remote data centers\n+    private final Map<String, Set<ReplicaId>> peerLeaderReplicasByPartition = new ConcurrentHashMap<>();\n+    private final ReadWriteLock rwLockForLeaderReplicaUpdates = new ReentrantReadWriteLock();\n+\n+    LeaderBasedReplicationAdmin() {\n+      // We can't initialize the peerLeaderReplicasByPartition map on startup because we don't know the leader partitions\n+      // on local server until it has finished participating with Helix. The map will be updated after server participates\n+      // with Helix and receives LEADER transition notifications via onPartitionBecomeLeaderFromStandby().\n+    }\n+\n+    /**\n+     * Go through remote replicas for this partition and compare messages written to local store with the missing messages\n+     * found during previous meta data exchange. If there are matching messages (based on store key), remove them from the missing message set.\n+     * This is used during leader-based replication to update token for standby replicas. Standby replicas store the\n+     * missing messages in metadata exchange, track them through intra-dc replication and update token when all the\n+     * missing messages are written to store.\n+     * @param partitionId partition ID of the messages written to store\n+     * @param messageInfoList list of messages written to store\n+     */\n+    void onMessageWriteForPartition(PartitionId partitionId, List<MessageInfo> messageInfoList) {\n+      rwLock.readLock().lock();\n+      try {\n+        PartitionInfo partitionInfo = partitionToPartitionInfo.get(partitionId);\n+        partitionInfo.updateReplicaInfosOnMessageWrite(messageInfoList);\n+      } finally {\n+        rwLock.readLock().unlock();", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxODkzNA==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446718934", "bodyText": "I need a little more clarification here:  if messageInfo from missingStoreMessages is DELETE/TTLUpdate etc rather than PUT, do we apply these updates?", "author": "jsjtzyy", "createdAt": "2020-06-29T00:29:48Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,25 +224,46 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse\n+    // and replica threads updating missing store messages in existing metadata response (via compareAndRemoveMissingStoreMessages())\n+    // after they are written to local store via intra-dc replication.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n   }\n \n+  /**\n+   * Compare missing store messages of this replica (found in its exchange metadata response for previous replication\n+   * cycle) with messages that are written to store by other replicas. If there\n+   * are matching messages (based on their store key), remove them from stored metadata response information.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void updateMissingMessagesInMetadataResponse(List<MessageInfo> messagesWrittenToStore) {\n+\n+    Set<MessageInfo> missingStoreMessages = exchangeMetadataResponse.getMissingStoreMessages();\n+    if (missingStoreMessages != null && !missingStoreMessages.isEmpty()) {\n+      Set<StoreKey> keysWrittenToStore =\n+          messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+      Set<MessageInfo> missingMessagesFoundInStore = new HashSet<>();\n+      for (MessageInfo messageInfo : missingStoreMessages) {\n+        if (keysWrittenToStore.contains(messageInfo.getStoreKey())) {\n+          missingMessagesFoundInStore.add(messageInfo);\n+        }\n+      }\n+      exchangeMetadataResponse.removeMissingStoreMessages(missingMessagesFoundInStore);", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg3NjE5Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447876196", "bodyText": "if it's delete, then we don't need it. a Delete MessageInfo would remove the blob key from the missingStoreMessages. So the blob key will not be in this set at the first beginning.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T17:57:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjcxODkzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc0Nzg2MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446747861", "bodyText": "minor: can be removed. (Also, please format this file)", "author": "jsjtzyy", "createdAt": "2020-06-29T03:05:47Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicationEngine.java", "diffHunk": "@@ -28,13 +28,15 @@\n import com.github.ambry.network.ConnectionPool;\n import com.github.ambry.notification.NotificationSystem;\n import com.github.ambry.server.StoreManager;\n+import com.github.ambry.store.MessageInfo;", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc2NDk3MQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446764971", "bodyText": "minor: you might need to rebase. My recent PR has updated this condition.", "author": "jsjtzyy", "createdAt": "2020-06-29T04:26:14Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -335,28 +336,46 @@ public void replicate() {\n       long replicationStartTimeInMs = SystemTime.getInstance().milliseconds();\n       long startTimeInMs = replicationStartTimeInMs;\n \n-      List<RemoteReplicaInfo> activeReplicasPerNode = new ArrayList<>();\n-      for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicatePerNode) {\n-        ReplicaId replicaId = remoteReplicaInfo.getReplicaId();\n-        boolean inBackoff = time.milliseconds() < remoteReplicaInfo.getReEnableReplicationTime();\n-        if (replicationDisabledPartitions.contains(replicaId.getPartitionId()) || replicaId.isDown() || inBackoff\n-            || !remoteReplicaInfo.getLocalStore().isStarted()) {\n-          continue;\n+      // use a variable to track current replica list to replicate (for logging purpose)\n+      List<RemoteReplicaInfo> currentReplicaList = new ArrayList<>();\n+      try {\n+        // Get a list of active replicas that needs be included for this replication cycle\n+        List<RemoteReplicaInfo> activeReplicasPerNode = new ArrayList<>();\n+        for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicatePerNode) {\n+          ReplicaId replicaId = remoteReplicaInfo.getReplicaId();\n+          boolean inBackoff = time.milliseconds() < remoteReplicaInfo.getReEnableReplicationTime();\n+          if (replicationDisabledPartitions.contains(replicaId.getPartitionId()) || replicaId.isDown() || inBackoff\n+              || !remoteReplicaInfo.getLocalStore().isStarted()) {", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc2NTgwMQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446765801", "bodyText": "May I ask why we moved try to here?", "author": "jsjtzyy", "createdAt": "2020-06-29T04:29:54Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -335,28 +336,46 @@ public void replicate() {\n       long replicationStartTimeInMs = SystemTime.getInstance().milliseconds();\n       long startTimeInMs = replicationStartTimeInMs;\n \n-      List<RemoteReplicaInfo> activeReplicasPerNode = new ArrayList<>();\n-      for (RemoteReplicaInfo remoteReplicaInfo : replicasToReplicatePerNode) {\n-        ReplicaId replicaId = remoteReplicaInfo.getReplicaId();\n-        boolean inBackoff = time.milliseconds() < remoteReplicaInfo.getReEnableReplicationTime();\n-        if (replicationDisabledPartitions.contains(replicaId.getPartitionId()) || replicaId.isDown() || inBackoff\n-            || !remoteReplicaInfo.getLocalStore().isStarted()) {\n-          continue;\n+      // use a variable to track current replica list to replicate (for logging purpose)\n+      List<RemoteReplicaInfo> currentReplicaList = new ArrayList<>();\n+      try {", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc3MDMzOQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446770339", "bodyText": "Imagine a scenario where we are applying TtlUpdate or Delete, the store returns Already_Updated or ID_Deleted (it might be updated by other threads concurrently), then we reset the ExchangeMetadataResponse and send metadata request again. This should be fine eventually because next time the update should succeed. However, can we consider this scenario a success without resetting the ExchangeMetadataResponse? (I think this is more efficient)", "author": "jsjtzyy", "createdAt": "2020-06-29T04:49:15Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1282,186 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. During leader-based replication, we only fetch\n+   * missing keys for these leader replicas. For non-leader replica pairs (leader <-> standby, standby <-> leader,\n+   * standby <-> standby), we will wait the missing keys to come from their leader interactions.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+      throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+          + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+    }\n+\n+    for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+      RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+      String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+      ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+      // Check if local replica and remote replica are leaders for this partition.\n+      if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+        leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+        exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponse(RemoteReplicaInfo remoteReplicaInfo) {\n+    try {\n+      ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+      if (!exchangeMetadataResponse.isEmpty()) {\n+\n+        Set<MessageInfo> receivedStoreMessagesWithUpdatesPending =\n+            exchangeMetadataResponse.getReceivedStoreMessagesWithUpdatesPending();\n+        Set<MessageInfo> receivedMessagesWithUpdatesCompleted = new HashSet<>();\n+\n+        // 1. Go through messages whose blobs are received now (via other replicas) and compare blob metadata of\n+        // remote message info with local blob in store and reconcile delete, ttl_update and undelete states\n+        for (MessageInfo messageInfo : receivedStoreMessagesWithUpdatesPending) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+          if (localStoreKey != null) {\n+            applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localStoreKey);", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4NTUzMg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447885532", "bodyText": "Don't worry about this case, since the applyTtlUpdate method already catches the Already_Updated exception. We will not see the 'Already_UpdatedandID_Deleted` exception being promoted here.", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:13:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc3MDMzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc3NTYwMQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446775601", "bodyText": "minor:  String partitionName = remoteReplica.getPartitionId().toPathString();", "author": "jsjtzyy", "createdAt": "2020-06-29T05:11:16Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1129,6 +1282,186 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. During leader-based replication, we only fetch\n+   * missing keys for these leader replicas. For non-leader replica pairs (leader <-> standby, standby <-> leader,\n+   * standby <-> standby), we will wait the missing keys to come from their leader interactions.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+      throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+          + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+    }\n+\n+    for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+      RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+      String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+      ReplicaId remoteReplicaId = remoteReplicaInfo.getReplicaId();\n+\n+      // Check if local replica and remote replica are leaders for this partition.\n+      if (leaderBasedReplicationAdmin.isPeerReplicaLeaderForPartition(partitionName, remoteReplicaId)) {\n+        leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+        exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos from a given remote node whose missing blobs in their metadata response\n+   * haven't arrived within time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   *\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {\n+          remoteReplicasTimedOut.add(remoteReplicaInfo);\n+        }\n+      }\n+    }\n+    return remoteReplicasTimedOut;\n+  }\n+\n+  /**\n+   * Compare message infos of remote standby replica (whose blobs are now received from leader replicas) with message info\n+   * of blobs in local store and reconcile blob properties like ttl_update, delete, undelete. If blobs for all the missing messages\n+   * of the standby replica are received and updated, move the remote token of the standby forward.\n+   * @param remoteReplicaInfo remote replica information\n+   */\n+  void processMissingKeysFromPreviousMetadataResponse(RemoteReplicaInfo remoteReplicaInfo) {\n+    try {\n+      ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+      if (!exchangeMetadataResponse.isEmpty()) {\n+\n+        Set<MessageInfo> receivedStoreMessagesWithUpdatesPending =\n+            exchangeMetadataResponse.getReceivedStoreMessagesWithUpdatesPending();\n+        Set<MessageInfo> receivedMessagesWithUpdatesCompleted = new HashSet<>();\n+\n+        // 1. Go through messages whose blobs are received now (via other replicas) and compare blob metadata of\n+        // remote message info with local blob in store and reconcile delete, ttl_update and undelete states\n+        for (MessageInfo messageInfo : receivedStoreMessagesWithUpdatesPending) {\n+          BlobId localStoreKey =\n+              (BlobId) exchangeMetadataResponse.remoteKeyToLocalKeyMap.get(messageInfo.getStoreKey());\n+          if (localStoreKey != null) {\n+            applyUpdatesToBlobInLocalStore(messageInfo, remoteReplicaInfo, localStoreKey);\n+          }\n+          receivedMessagesWithUpdatesCompleted.add(messageInfo);\n+        }\n+\n+        // 2. Remove the messages whose updates have been completed\n+        exchangeMetadataResponse.removeReceivedStoreMessagesWithUpdatesPending(receivedMessagesWithUpdatesCompleted);\n+\n+        // 3. If metadata response for this replica is now empty, i.e. updates for all the messages are completed and\n+        // there are no more \"missingMessages + receivedMessagesWithUpdatesPending\", move the remote token forward and\n+        // update local lag from remote for this replica.\n+        if (exchangeMetadataResponse.isEmpty()) {\n+          remoteReplicaInfo.setToken(exchangeMetadataResponse.remoteToken);\n+          remoteReplicaInfo.setLocalLagFromRemoteInBytes(exchangeMetadataResponse.localLagFromRemoteInBytes);\n+          logger.trace(\"Updating token {} and lag {} for partition {} in Remote replica: {}\",\n+              exchangeMetadataResponse.remoteToken, exchangeMetadataResponse.localLagFromRemoteInBytes,\n+              remoteReplicaInfo.getReplicaId().getPartitionId().toPathString(), remoteReplicaInfo.getReplicaId());\n+          remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+        }\n+      }\n+    } catch (StoreException e) {\n+      logger.error(\"Exception occurred while updating exchangeMetadataResponse for Remote replica info: {}\",\n+          remoteReplicaInfo, e);\n+      // reset stored metadata response so that metadata request is sent again for this replica\n+      remoteReplicaInfo.setExchangeMetadataResponse(new ExchangeMetadataResponse(ServerErrorCode.No_Error));\n+    }\n+  }\n+\n+  /**\n+   * Checks if the input remote replica is a standby replica and has any messages from its previous metadata\n+   * exchange still missing in local store, i.e. they haven't arrived from leader via intra-dc replication.\n+   * @param remoteReplicaInfo remote replica information\n+   * @return true if missing messages in previous metadata exchange are not yet received\n+   */\n+  boolean containsMissingKeysFromPreviousMetadataExchange(RemoteReplicaInfo remoteReplicaInfo) {\n+    String partitionName = remoteReplicaInfo.getLocalReplicaId().getPartitionId().toPathString();\n+    ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njc3NzMzMw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r446777333", "bodyText": "minor: we probably can replace all SystemTime.getInstance() with time in this file.", "author": "jsjtzyy", "createdAt": "2020-06-29T05:18:52Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -371,44 +390,96 @@ public void replicate() {\n             List<ExchangeMetadataResponse> exchangeMetadataResponseList =\n                 exchangeMetadata(connectedChannel, replicaSubList);\n             exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+\n+            if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+              // If leader based replication is enabled and we are replicating from remote colo, fetch the missing blobs\n+              // only for local leader replicas from their corresponding peer leader replicas (Leader <-> Leader).\n+              // Non-leader replica pairs (standby <-> leaders, leader <-> standby, standby <-> standby) will get their\n+              // missing blobs from their leader pair exchanges and intra-dc replication.\n+              List<RemoteReplicaInfo> leaderReplicaList = new ArrayList<>();\n+              List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicas = new ArrayList<>();\n+              getLeaderReplicaList(replicaSubList, exchangeMetadataResponseList, leaderReplicaList,\n+                  exchangeMetadataResponseListForLeaderReplicas);\n+              replicaSubList = leaderReplicaList;\n+              exchangeMetadataResponseList = exchangeMetadataResponseListForLeaderReplicas;\n+            }\n+\n             startTimeInMs = SystemTime.getInstance().milliseconds();\n-            fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+            if (replicaSubList.size() > 0) {\n+              fixMissingStoreKeys(connectedChannel, replicaSubList, exchangeMetadataResponseList);\n+            }\n             fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n           }\n-        } catch (Throwable e) {\n-          if (checkoutConnectionTimeInMs == -1) {\n-            // throwable happened in checkout connection phase\n-            checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-            responseHandler.onEvent(activeReplicasPerNode.get(0).getReplicaId(), e);\n-          } else if (exchangeMetadataTimeInMs == -1) {\n-            // throwable happened in exchange metadata phase\n-            exchangeMetadataTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n-          } else if (fixMissingStoreKeysTimeInMs == -1) {\n-            // throwable happened in fix missing store phase\n+        }\n+\n+        if (replicatingFromRemoteColo && leaderBasedReplicationAdmin != null) {\n+          // Get a list of inactive standby replicas whose missing keys haven't arrived for long time.\n+          // Use case: In leader-based replication, standby replicas don't send GET requests for missing keys found in\n+          // metadata exchange and expect them to come via leader in local data center through intra-dc replication.\n+          // This is a safety condition to ensure that standby replicas are not stuck waiting for the keys to come from leader\n+          // by fetching the missing keys themselves.\n+          // TODO: As an improvement to this, we can first fetch missing blobs from local leader/other replicas in intra-dc first.\n+          // TODO: If the result to fetch a blob from local dc is Blob_Not_Found, then we can fetch it from replicas in remote datacenter.\n+          // This will involve co-ordination between replica threads containing replicas of same partition.\n+          List<RemoteReplicaInfo> standbyReplicasTimedOutOnNoProgress =\n+              getRemoteStandbyReplicasTimedOutOnNoProgress(replicasToReplicatePerNode);\n+          if (standbyReplicasTimedOutOnNoProgress.size() > 0) {\n+            allCaughtUp = false;\n+            currentReplicaList = standbyReplicasTimedOutOnNoProgress;\n+            if (connectedChannel == null) {\n+              connectedChannel = connectionPool.checkOutConnection(remoteNode.getHostname(),\n+                  standbyReplicasTimedOutOnNoProgress.get(0).getPort(),\n+                  replicationConfig.replicationConnectionPoolCheckoutTimeoutMs);\n+              checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n+            }\n+            List<ExchangeMetadataResponse> exchangeMetadataResponseListForInactiveReplicas =\n+                standbyReplicasTimedOutOnNoProgress.stream()\n+                    .map(RemoteReplicaInfo::getExchangeMetadataResponse)\n+                    .collect(Collectors.toList());\n+            exchangeMetadataTimeInMs = 0;\n+            fixMissingStoreKeysTimeInMs = -1;\n+            logger.debug(\n+                \"Sending GET request to fetch missing keys for standby remote replicas {} timed out on no progress\",\n+                currentReplicaList);\n+            fixMissingStoreKeys(connectedChannel, standbyReplicasTimedOutOnNoProgress,\n+                exchangeMetadataResponseListForInactiveReplicas);\n             fixMissingStoreKeysTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;\n           }\n-          logger.error(\n-              \"Error while talking to peer: Remote node: {}, Thread name: {}, Remote replicas: {}, Current active \"\n-                  + \"remote replica list: {}, Checkout connection time: {}, Exchange metadata time: {}, Fix missing \"\n-                  + \"store key time {}\", remoteNode, threadName, replicasToReplicatePerNode, currentReplicaList,\n-              checkoutConnectionTimeInMs, exchangeMetadataTimeInMs, fixMissingStoreKeysTimeInMs, e);\n-          replicationMetrics.incrementReplicationErrors(replicatingOverSsl);\n-          if (connectedChannel != null) {\n-            connectionPool.destroyConnection(connectedChannel);\n-            connectedChannel = null;\n-          }\n-        } finally {\n-          long totalReplicationTime = SystemTime.getInstance().milliseconds() - replicationStartTimeInMs;\n-          replicationMetrics.updateTotalReplicationTime(totalReplicationTime, replicatingFromRemoteColo,\n-              replicatingOverSsl, datacenterName);\n-          if (connectedChannel != null) {\n-            connectionPool.checkInConnection(connectedChannel);\n-          }\n-          context.stop();\n-          portTypeBasedContext.stop();\n         }\n+      } catch (Throwable e) {\n+        if (checkoutConnectionTimeInMs == -1) {\n+          // throwable happened in checkout connection phase\n+          checkoutConnectionTimeInMs = SystemTime.getInstance().milliseconds() - startTimeInMs;", "originalCommit": "f01ceb98a1a4df998016aef51c9e86743871ae22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2360821368cc9e35edf30a99ad2291b1b21336f8", "url": "https://github.com/linkedin/ambry/commit/2360821368cc9e35edf30a99ad2291b1b21336f8", "message": "Squashing commits into one\n\nCore changes of leader based replication. It contains following:\n1. Filter leader and non-leader replicas in replica threads.\n2. Limit cross colo fetching of missing keys to leaders only.\n3. Store the missing keys information for standby replicas and track them via intra-dc replication.\n4. Update the remote token for standby replicas once all the missing keys are obtained.\n5. Changes to do cross colo fetch for standby replicas if missing keys haven't arrived for long time\n\nAdding unit test cases for leader based replication\n\nChanges:\n1. Extended range of config param replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds to take -1 to indicate that time out is disbled.\n2. Stored remoteKeyToLocalKeyMap in exchangeMetadataResponse to make use of converted keys when standby replicas update local blob properties of missing keys (lazily) after they are written to store via intra-dc replication.\n\nChanges to merge class PartitionLeaderInfo into LeaderBasedReplicationAdmin and unit testing force cross colo fetches for standby replicas\n\nAdd metrics to track number of cross colo get requests sent and bytes fetch rate for standby replicas which timed out waiting for missing keys to come from local leader.\n\nUnit test changes to verify following:\n 1. Standby replicas use up to date remote token when they become leaders.\n 2. Replication metrics for tracking cross colo get requests for standby replicas timed out on waiting for missing keys.\n\n1. Move setup and helper methods in ReplicationTest to seperate file 'ReplicationTestHelper'\n2. Move leader based replication tests to seperate file 'LeaderBasedReplicationTest'\n\nChanges to move mutable logic out of class RemoteReplicaInfo into Replica threads\n\nAddressing following review comments:\n 1. Replace systemTime.getInstance() with member variable time in ReplicaThread\n 2. Using ConcurrentHashMap.computeIfPresent() instead of read lock\n 3. Few other minor comments", "committedDate": "2020-06-29T22:10:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM2MDM5Mg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447360392", "bodyText": "Minor: can use  stream().filter().collect()", "author": "lightningrob", "createdAt": "2020-06-30T01:51:30Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/RemoteReplicaInfo.java", "diffHunk": "@@ -208,25 +224,45 @@ public boolean equals(Object obj) {\n   }\n \n   /**\n-   * Get the meta data response information received for this replica in the most recent replication cycle.\n+   * Get the meta data response received for this replica in the most recent replication cycle.\n    * @return exchangeMetadataResponse contains the meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized ReplicaThread.ExchangeMetadataResponse getExchangeMetadataResponse() {\n     return exchangeMetadataResponse;\n   }\n \n   /**\n-   * Set the meta data exchange information received for this replica in the most recent replication cycle.\n-   * Replica threads calls this method to store the metadata responses during replication cycles.\n+   * Set the meta data response received for this replica in the most recent replication cycle.\n    * @param exchangeMetadataResponse contains meta data response (missing keys, token info, local lag from remote, etc.).\n    */\n   synchronized void setExchangeMetadataResponse(ReplicaThread.ExchangeMetadataResponse exchangeMetadataResponse) {\n-    // We are having this thread safe to avoid conflict between replica thread setting new exchangeMetadataResponse\n-    // and replica threads updating the missing store messages in current exchangeMetadataResponse after they are\n-    // written to local store via intra-dc replication (method will be added in future PR).\n+    // Synchronized to avoid conflict between replica threads setting new exchangeMetadataResponse received for this replica\n+    // and replica threads going through existing metadata response (via updateMissingMessagesInMetadataResponse()) to\n+    // to compare newly written messages to store with missing message set in metadata response.\n     this.exchangeMetadataResponse = exchangeMetadataResponse;\n   }\n \n+  /**\n+   * Update missing store messages found for this replica in its recent exchange metadata response by comparing\n+   * (based on the store key) with messages that are written to store by other replica threads.\n+   * @param messagesWrittenToStore list of messages written to local store\n+   */\n+  synchronized void updateMissingMessagesInMetadataResponse(List<MessageInfo> messagesWrittenToStore) {\n+\n+    Set<MessageInfo> missingStoreMessages = exchangeMetadataResponse.getMissingStoreMessages();\n+    if (missingStoreMessages != null && !missingStoreMessages.isEmpty()) {\n+      Set<StoreKey> keysWrittenToStore =\n+          messagesWrittenToStore.stream().map(MessageInfo::getStoreKey).collect(Collectors.toSet());\n+      Set<MessageInfo> missingMessagesFoundInStore = new HashSet<>();", "originalCommit": "2360821368cc9e35edf30a99ad2291b1b21336f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzNDE2OQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448034169", "bodyText": "Sure, updated code to use stream().filter().collect()", "author": "Arun-LinkedIn", "createdAt": "2020-06-30T23:29:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzM2MDM5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg1Mzc5OQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447853799", "bodyText": "@Arun-LinkedIn you need to add license here to pass the travis test. See other file for reference.", "author": "jsjtzyy", "createdAt": "2020-06-30T17:22:10Z", "path": "ambry-replication/src/test/java/com/github/ambry/replication/LeaderBasedReplicationTest.java", "diffHunk": "@@ -0,0 +1,1177 @@\n+package com.github.ambry.replication;", "originalCommit": "4ece61e6d5ef9a2f41dda612d6eb42016e143540", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzNDQ2OQ==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448034469", "bodyText": "Thanks for letting me know. Added the license text.", "author": "Arun-LinkedIn", "createdAt": "2020-06-30T23:29:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg1Mzc5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4MjAxNg==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r447882016", "bodyText": "the indentation is wonky", "author": "justinlin-linkedin", "createdAt": "2020-06-30T18:07:49Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -298,6 +297,22 @@ public void addRemoteReplicaInfo(RemoteReplicaInfo remoteReplicaInfo) {\n \n   /**\n    * Do replication for replicas grouped by {@link DataNodeId}\n+   * A replication cycle between two replicas involves the following steps:\n+   *    1. Exchange metadata : to fetch the blobs added to remote replica since the last synchronization offset and go through\n+   *       the local store to filter the ones missing locally\n+   *    2. Fetch missing keys: to fetch the blobs missing locally from remote replica by issuing GET requests and add them to\n+   *       the local store\n+   *  During cross-colo replication, depending on the {@link ReplicationModelType}, the second step to fetch missing\n+   *  keys happens in either all-to-all fashion (i.e. fetched from all cross colo replicas) or is limited to only leader\n+   *  replica pairs (i.e both local and remote replicas should be leaders of their partition).\n+   *  Here is a table listing on what is exchanged between local and remote replicas based on their roles (leader or\n+   *  standby) when {@link ReplicationModelType is LEADER_BASED}.\n+   *\n+   *                   |   Local Leader\t    |    Local Standby\t  |     Remote Leader\t  |  Remote Standby\n+   *      --------------------------------------------------------------------------------------------------\n+   *       Leader: \t   |        ---         |  metadata and data  |   metadata and data\t|   metadata only", "originalCommit": "4ece61e6d5ef9a2f41dda612d6eb42016e143540", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODEzMzEwNw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448133107", "bodyText": "I wonder why not put this logic in the code block starting from line 438 and pass in a boolean value to fixMissingStoreKeys and getMessagesForMissingKeys.  I see two benefits:\n\nyou don't have to if leaderBasedReplicationAdmin = null again;\nyou can skip some RemoteReplicaInfo associated with local leader replica;", "author": "jsjtzyy", "createdAt": "2020-07-01T06:02:09Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -884,14 +1029,25 @@ private GetResponse getMessagesForMissingKeys(ConnectedChannel connectedChannel,\n           GetRequest.Replication_Client_Id_Prefix + dataNodeId.getHostname() + \"[\" + dataNodeId.getDatacenterName()\n               + \"]\", MessageFormatFlags.All, partitionRequestInfoList,\n           replicationConfig.replicationIncludeAll ? GetOption.Include_All : GetOption.None);\n-      long startTime = SystemTime.getInstance().milliseconds();\n+      long startTime = time.milliseconds();\n       try {\n         connectedChannel.send(getRequest);\n         ChannelOutput channelOutput = connectedChannel.receive();\n         getResponse = GetResponse.readFrom(new DataInputStream(channelOutput.getInputStream()), clusterMap);\n-        long getRequestTime = SystemTime.getInstance().milliseconds() - startTime;\n+        long getRequestTime = time.milliseconds() - startTime;\n+        boolean remoteColoGetRequestForStandby = false;\n+        if (leaderBasedReplicationAdmin != null && replicatingFromRemoteColo) {\n+          // If leader-based replication is enabled, we should ideally send cross colo GET requests only between leaders.\n+          // However, if standby replicas time out waiting for their keys to come from leader, we send cross colo GETs\n+          // for them. Set 'remoteColoGetRequestForStandby' to true so that we track number of such cross colo GETs for standby replicas.\n+          ReplicaId localReplica = replicasToReplicatePerNode.get(0).getLocalReplicaId();\n+          ReplicaId remoteReplica = replicasToReplicatePerNode.get(0).getReplicaId();\n+          if (!leaderBasedReplicationAdmin.isLeaderPair(localReplica, remoteReplica)) {\n+            remoteColoGetRequestForStandby = true;\n+          }\n+        }", "originalCommit": "62994a9e5a1a62640ae9b9af87cc0a96c1bae64f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODEzNDA0Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448134046", "bodyText": "This condition can be improved. Instead of using metadata received timestamp. We can use the last timestamp when at least one messageInfo is removed from missing set. This is more reasonable for the method name \"no progress\", it may make a slow progress and timed out in middle way.  (This comment is optional, you can add a TODO here for further improvement)", "author": "jsjtzyy", "createdAt": "2020-07-01T06:05:16Z", "path": "ambry-replication/src/main/java/com/github/ambry/replication/ReplicaThread.java", "diffHunk": "@@ -1135,6 +1306,189 @@ private void applyDelete(MessageInfo messageInfo, RemoteReplicaInfo remoteReplic\n     }\n   }\n \n+  /**\n+   * Get list of remote replica infos whose local replica is a leader of the partition of this data center and\n+   * remote replica is a leader of the partition of remote data center. This list is used for leader-based cross colo\n+   * replication to exchange missing blobs between only leader replicas. For non-leader replica pairs (leader <->\n+   * standby, standby <-> leader, standby <-> standby), we will wait the missing blobs to come from their leader interactions.\n+   * @param remoteReplicaInfos list of all remote replicas\n+   * @param exchangeMetadataResponseList list of metadata responses received from the remote replicas\n+   * @param leaderReplicaInfosOutput output list of leader replicas. It will populated in this method.\n+   * @param exchangeMetadataResponseListForLeaderReplicaInfosOutput output list of metadata responses received for the leader\n+   *                                                       replicas. It will be populated in this method.\n+   * @throws IllegalArgumentException\n+   */\n+  void getLeaderReplicaList(List<RemoteReplicaInfo> remoteReplicaInfos,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseList, List<RemoteReplicaInfo> leaderReplicaInfosOutput,\n+      List<ExchangeMetadataResponse> exchangeMetadataResponseListForLeaderReplicaInfosOutput)\n+      throws IllegalArgumentException {\n+\n+    if (exchangeMetadataResponseList.size() != remoteReplicaInfos.size()) {\n+      throw new IllegalArgumentException(\"ExchangeMetadataResponseList size \" + exchangeMetadataResponseList.size()\n+          + \" and replicasToReplicatePerNode size \" + remoteReplicaInfos.size() + \" should be the same\");\n+    }\n+\n+    for (int i = 0; i < remoteReplicaInfos.size(); i++) {\n+      RemoteReplicaInfo remoteReplicaInfo = remoteReplicaInfos.get(i);\n+      ReplicaId localReplica = remoteReplicaInfo.getLocalReplicaId();\n+      ReplicaId remoteReplica = remoteReplicaInfo.getReplicaId();\n+      // Check if local replica and remote replica are leaders for their partition.\n+      if (leaderBasedReplicationAdmin.isLeaderPair(localReplica, remoteReplica)) {\n+        leaderReplicaInfosOutput.add(remoteReplicaInfo);\n+        exchangeMetadataResponseListForLeaderReplicaInfosOutput.add(exchangeMetadataResponseList.get(i));\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Returns list of remote replica infos whose missing blobs in their metadata response haven't arrived within\n+   * time = replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds.\n+   * @param remoteReplicaInfos list of remote replica infos\n+   * @return list of remote replica infos which have timed out due to no progress\n+   */\n+  List<RemoteReplicaInfo> getRemoteStandbyReplicasTimedOutOnNoProgress(List<RemoteReplicaInfo> remoteReplicaInfos) {\n+\n+    // Use case: In leader-based replication, standby replicas don't send replication GET requests for missing keys\n+    // found in their metadata exchange and expect them to come from leader in local data center via intra-dc replication.\n+    // However, if for any reason, their missing blobs never arrive via local leader, this is a safety feature to fetch\n+    // the blobs themselves in order to avoid being stuck.\n+\n+    // Example scenario: For DELETE after PUT use case in remote data center, it is possible that standby replicas get\n+    // only PUT record in its replication cycle (DELETE record will come in next cycle) while leader gets both\n+    // PUT and DELETE together in its replication cycle. Due to that, leader doesn't fetch\n+    // the deleted blob from remote data center and the blob is never replicated from leader to standby.\n+    // As a result, the PUT record in standby's missing blobs set is never emptied.\n+\n+    // Time out period is configurable via replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds. If\n+    // replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds == -1, this safety feature is disabled.\n+\n+    List<RemoteReplicaInfo> remoteReplicasTimedOut = new ArrayList<>();\n+    if (replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds != -1) {\n+      for (RemoteReplicaInfo remoteReplicaInfo : remoteReplicaInfos) {\n+        ExchangeMetadataResponse exchangeMetadataResponse = remoteReplicaInfo.getExchangeMetadataResponse();\n+        if (exchangeMetadataResponse.hasMissingStoreMessages()\n+            && (time.seconds() - exchangeMetadataResponse.metadataReceivedTimeSec)\n+            > replicationConfig.replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds) {", "originalCommit": "62994a9e5a1a62640ae9b9af87cc0a96c1bae64f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY1NDc3Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448654776", "bodyText": "minor: can be package private", "author": "jsjtzyy", "createdAt": "2020-07-01T22:48:05Z", "path": "ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java", "diffHunk": "@@ -51,6 +51,28 @@\n     this.clusterMap = clusterMap;\n   }\n \n+  /**\n+   * Adds an in-memory store to a partition if not present already\n+   * @param partitionId partition id\n+   * @param listener listener for store events\n+   */\n+  public void addStore(PartitionId partitionId, ReplicationTest.StoreEventListener listener) {", "originalCommit": "76cb1065917f7b65c2076dd9e0624654ad4439d2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY1NDg1Nw==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448654857", "bodyText": "same here, can be package private", "author": "jsjtzyy", "createdAt": "2020-07-01T22:48:19Z", "path": "ambry-replication/src/test/java/com/github/ambry/replication/MockHost.java", "diffHunk": "@@ -51,6 +51,28 @@\n     this.clusterMap = clusterMap;\n   }\n \n+  /**\n+   * Adds an in-memory store to a partition if not present already\n+   * @param partitionId partition id\n+   * @param listener listener for store events\n+   */\n+  public void addStore(PartitionId partitionId, ReplicationTest.StoreEventListener listener) {\n+    storesByPartition.computeIfAbsent(partitionId, partitionId1 -> new InMemoryStore(partitionId,\n+        infosByPartition.computeIfAbsent(partitionId1,\n+            (Function<PartitionId, List<MessageInfo>>) partitionId2 -> new ArrayList<>()),\n+        buffersByPartition.computeIfAbsent(partitionId1,\n+            (Function<PartitionId, List<ByteBuffer>>) partitionId22 -> new ArrayList<>()), listener));\n+  }\n+\n+  /**\n+   * Gets the in-memory store for the partition\n+   * @param partitionId partition id\n+   * @return in-memory store\n+   */\n+  public InMemoryStore getStore(PartitionId partitionId) {", "originalCommit": "76cb1065917f7b65c2076dd9e0624654ad4439d2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY1NzE2Ng==", "url": "https://github.com/linkedin/ambry/pull/1546#discussion_r448657166", "bodyText": "Minor: this can be simplified as:\nSet<ReplicaId> peerLeaderReplicasInClusterMap =\nnew HashSet<>(existingPartition.getReplicaIdsByState(ReplicaState.LEADER, null));", "author": "jsjtzyy", "createdAt": "2020-07-01T22:55:28Z", "path": "ambry-replication/src/test/java/com/github/ambry/replication/ReplicationTest.java", "diffHunk": "@@ -705,23 +553,36 @@ public void replicaFromStandbyToLeaderTest() throws Exception {\n     ClusterMapConfig clusterMapConfig = new ClusterMapConfig(verifiableProperties);\n     MockHelixParticipant.metricRegistry = new MetricRegistry();\n     MockHelixParticipant mockHelixParticipant = new MockHelixParticipant(clusterMapConfig);\n+\n+    ReplicationConfig initialReplicationConfig = replicationConfig;\n+    properties.setProperty(\"replication.model.across.datacenters\", \"LEADER_BASED\");\n+    replicationConfig = new ReplicationConfig(new VerifiableProperties(properties));\n+\n     Pair<StorageManager, ReplicationManager> managers =\n         createStorageManagerAndReplicationManager(clusterMap, clusterMapConfig, mockHelixParticipant);\n     StorageManager storageManager = managers.getFirst();\n     MockReplicationManager replicationManager = (MockReplicationManager) managers.getSecond();\n-    PartitionId existingPartition = replicationManager.partitionToPartitionInfo.keySet().iterator().next();\n-    String currentDataCenter =\n-        storageManager.getReplica(existingPartition.toString()).getDataNodeId().getDatacenterName();\n-    mockHelixParticipant.onPartitionBecomeLeaderFromStandby(existingPartition.toPathString());\n-    Set<ReplicaId> peerLeaderReplicasInReplicationManager =\n-        replicationManager.partitionLeaderInfo.getPeerLeaderReplicasByPartition().get(existingPartition.toPathString());\n-    Set<ReplicaId> peerLeaderReplicasInClusterMap = existingPartition.getReplicaIdsByState(ReplicaState.LEADER, null)\n-        .stream()\n-        .filter(r -> !r.getDataNodeId().getDatacenterName().equals(currentDataCenter))\n-        .collect(Collectors.toSet());\n-    assertThat(\"Mismatch in list of leader peer replicas stored by partition in replication manager and cluster map\",\n-        peerLeaderReplicasInReplicationManager, is(peerLeaderReplicasInClusterMap));\n+\n+    List<ReplicaId> replicaIds = clusterMap.getReplicaIds(replicationManager.dataNodeId);\n+    for (ReplicaId replicaId : replicaIds) {\n+      MockReplicaId mockReplicaId = (MockReplicaId) replicaId;\n+      if (mockReplicaId.getReplicaState() == ReplicaState.LEADER) {\n+        PartitionId existingPartition = mockReplicaId.getPartitionId();\n+        mockHelixParticipant.onPartitionBecomeLeaderFromStandby(existingPartition.toPathString());\n+        Set<ReplicaId> peerLeaderReplicasInReplicationManager =\n+            replicationManager.leaderBasedReplicationAdmin.getLeaderPartitionToPeerLeaderReplicas()\n+                .get(existingPartition.toPathString());\n+        Set<ReplicaId> peerLeaderReplicasInClusterMap =\n+            existingPartition.getReplicaIdsByState(ReplicaState.LEADER, null).stream().collect(Collectors.toSet());", "originalCommit": "76cb1065917f7b65c2076dd9e0624654ad4439d2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "01180f8ffb17df83bd13648ac5f4dce48e224a19", "url": "https://github.com/linkedin/ambry/commit/01180f8ffb17df83bd13648ac5f4dce48e224a19", "message": "Make methods package-private", "committedDate": "2020-07-02T16:46:22Z", "type": "forcePushed"}, {"oid": "d684f9304301899e86f39c2d576bfb463b3d0396", "url": "https://github.com/linkedin/ambry/commit/d684f9304301899e86f39c2d576bfb463b3d0396", "message": "Squashing commits into one\n\nCore changes of leader based replication. It contains following:\n1. Filter leader and non-leader replicas in replica threads.\n2. Limit cross colo fetching of missing keys to leaders only.\n3. Store the missing keys information for standby replicas and track them via intra-dc replication.\n4. Update the remote token for standby replicas once all the missing keys are obtained.\n5. Changes to do cross colo fetch for standby replicas if missing keys haven't arrived for long time\n\nAdding unit test cases for leader based replication\n\nChanges:\n1. Extended range of config param replicationStandbyWaitTimeoutToTriggerCrossColoFetchSeconds to take -1 to indicate that time out is disbled.\n2. Stored remoteKeyToLocalKeyMap in exchangeMetadataResponse to make use of converted keys when standby replicas update local blob properties of missing keys (lazily) after they are written to store via intra-dc replication.\n\nChanges to merge class PartitionLeaderInfo into LeaderBasedReplicationAdmin and unit testing force cross colo fetches for standby replicas\n\nAdd metrics to track number of cross colo get requests sent and bytes fetch rate for standby replicas which timed out waiting for missing keys to come from local leader.\n\nUnit test changes to verify following:\n 1. Standby replicas use up to date remote token when they become leaders.\n 2. Replication metrics for tracking cross colo get requests for standby replicas timed out on waiting for missing keys.\n\n1. Move setup and helper methods in ReplicationTest to seperate file 'ReplicationTestHelper'\n2. Move leader based replication tests to seperate file 'LeaderBasedReplicationTest'\n\nChanges to move mutable logic out of class RemoteReplicaInfo into Replica threads\n\nAddressing following review comments:\n 1. Replace systemTime.getInstance() with member variable time in ReplicaThread\n 2. Using ConcurrentHashMap.computeIfPresent() instead of read lock\n 3. Few other minor comments", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "f59adab6b3eb2beb6b912815e13176cf320cacd0", "url": "https://github.com/linkedin/ambry/commit/f59adab6b3eb2beb6b912815e13176cf320cacd0", "message": "Move LeaderBasedReplicationAdmin into ReplicationEngine", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "fe62e68db29e95e0d14b8230afdd118e070718d3", "url": "https://github.com/linkedin/ambry/commit/fe62e68db29e95e0d14b8230afdd118e070718d3", "message": "Add license text to new unit test files", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "eab7daa5ae11d3fa7f7026d7e78734c49641389a", "url": "https://github.com/linkedin/ambry/commit/eab7daa5ae11d3fa7f7026d7e78734c49641389a", "message": "Refine explanation in comments further and move try statement in replicate() method to right place", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "13f19075714b120e4f08d3cdedc5e4a2d2806573", "url": "https://github.com/linkedin/ambry/commit/13f19075714b120e4f08d3cdedc5e4a2d2806573", "message": "1. Pass in a boolean value to fixMissingStoreKeys to tell if we fetching blobs for standby replicas\n2. Use the last timestamp when at least one messageInfo is removed from missing set instead of metadata received timestamp", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "e2e94d3d6081c70ae750faeb192e318b50ed7fea", "url": "https://github.com/linkedin/ambry/commit/e2e94d3d6081c70ae750faeb192e318b50ed7fea", "message": "Make methods package-private", "committedDate": "2020-07-02T19:27:35Z", "type": "commit"}, {"oid": "e2e94d3d6081c70ae750faeb192e318b50ed7fea", "url": "https://github.com/linkedin/ambry/commit/e2e94d3d6081c70ae750faeb192e318b50ed7fea", "message": "Make methods package-private", "committedDate": "2020-07-02T19:27:35Z", "type": "forcePushed"}]}