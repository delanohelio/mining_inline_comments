{"pr_number": 1571, "pr_title": "Force empty store to stay in BOOTSTRAP before catchup completes", "pr_createdAt": "2020-06-21T21:29:01Z", "pr_url": "https://github.com/linkedin/ambry/pull/1571", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYzNDE0Nw==", "url": "https://github.com/linkedin/ambry/pull/1571#discussion_r444634147", "bodyText": "Sorry I didn't quite follow with this part. From the comments, the store will be forced in BOOTSTRAP state if capacity is less or equal to header size, but looks like no matter what the value of the storeUsedCapacity is, the store will be forced in BOOTSTRAP state. Is this intended?", "author": "SophieGuo410", "createdAt": "2020-06-24T04:12:49Z", "path": "ambry-store/src/main/java/com/github/ambry/store/StorageManager.java", "diffHunk": "@@ -476,16 +477,40 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {\n         // able to get new replica from storageManager without querying Helix\n       } else {\n         // if the replica is already on current node, there are 3 cases need to discuss:\n-        // 1. replica was initially present in clustermap;\n-        // 2. replica was dynamically added to this node but may fail during BOOTSTRAP -> STANDBY transition\n+        // 1. replica was initially present in clustermap and this is a regular reboot.\n+        // 2. replica was dynamically added to this node but may fail during BOOTSTRAP -> STANDBY transition.\n         // 3. replica is on current node but its disk is offline. The replica is not able to start.\n+        // 4. replica was initially present in clustermap but it's current being recreated due to disk failure before.\n+\n         // For case 1 and 2, OFFLINE -> BOOTSTRAP is complete, we leave remaining actions (if there any) to other transition.\n         // For case 3, we should throw exception to make replica stay in ERROR state (thus, frontends won't pick this replica)\n-        if (getStore(replica.getPartitionId(), false) == null) {\n+        // For case 4, we check it's current used capacity and put it in BOOTSTRAP state if necessary. This is to ensure\n+        //             it catches up with peers before serving PUT traffic (or being selected as LEADER)\n+        Store store = getStore(replica.getPartitionId(), false);\n+        if (store == null) {\n           throw new StateTransitionException(\n               \"Store \" + partitionName + \" didn't start correctly, replica should be set to ERROR state\",\n               StoreNotStarted);\n         }\n+        // if store's used capacity is less than or equal to header size, we create a bootstrap_in_progress file and force\n+        // it to stay in BOOTSTRAP state when catching up with peers.\n+        long storeUsedCapacity = store.getSizeInBytes();\n+        if (storeUsedCapacity <= HEADER_SIZE) {\n+          logger.info(\n+              \"Store {} has used capacity {} less than or equal to {} bytes, consider it recently created and make it go through bootstrap process.\",\n+              partitionName, storeUsedCapacity, HEADER_SIZE);\n+          try {\n+            File bootstrapFile = new File(replica.getReplicaPath(), BlobStore.BOOTSTRAP_FILE_NAME);\n+            if (!bootstrapFile.exists()) {\n+              bootstrapFile.createNewFile();\n+            }\n+          } catch (IOException e) {\n+            logger.error(\"Failed to create bootstrap file for store {}\", partitionName);\n+            throw new StateTransitionException(\"Failed to create bootstrap file for \" + partitionName,\n+                ReplicaOperationFailure);\n+          }\n+        }\n+        store.setCurrentState(ReplicaState.BOOTSTRAP);", "originalCommit": "5e51d46695f9ce28959a4e91a0fbf31d6458661e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTIxODMwMw==", "url": "https://github.com/linkedin/ambry/pull/1571#discussion_r445218303", "bodyText": "Yes, it's intended to update store current state to BOOTSTRAP.  The difference is, if storeUsedCapacity is <= 18 (header size which means it's empty), we create a bootstrap_in_progress file in that store. Within onPartitionBecomeStandbyFromBootstrap, the replication manager will force stores that have bootstrap_in_progress file to stay in BOOTSTRAP before catchup completes. No actions will be taken on other stores (non-empty), they will quickly complete BOOTSTRAP -> STANDBY transition.", "author": "jsjtzyy", "createdAt": "2020-06-24T23:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYzNDE0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA5MTEyOQ==", "url": "https://github.com/linkedin/ambry/pull/1571#discussion_r445091129", "bodyText": "creating a bootstrap_in_progress file and set setting currentstate to bootstrap has to go toe to toe, I suppose we can make a method out of them.", "author": "justinlin-linkedin", "createdAt": "2020-06-24T18:31:30Z", "path": "ambry-store/src/main/java/com/github/ambry/store/StorageManager.java", "diffHunk": "@@ -476,16 +477,40 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {\n         // able to get new replica from storageManager without querying Helix\n       } else {\n         // if the replica is already on current node, there are 3 cases need to discuss:\n-        // 1. replica was initially present in clustermap;\n-        // 2. replica was dynamically added to this node but may fail during BOOTSTRAP -> STANDBY transition\n+        // 1. replica was initially present in clustermap and this is a regular reboot.\n+        // 2. replica was dynamically added to this node but may fail during BOOTSTRAP -> STANDBY transition.\n         // 3. replica is on current node but its disk is offline. The replica is not able to start.\n+        // 4. replica was initially present in clustermap but it's current being recreated due to disk failure before.\n+\n         // For case 1 and 2, OFFLINE -> BOOTSTRAP is complete, we leave remaining actions (if there any) to other transition.\n         // For case 3, we should throw exception to make replica stay in ERROR state (thus, frontends won't pick this replica)\n-        if (getStore(replica.getPartitionId(), false) == null) {\n+        // For case 4, we check it's current used capacity and put it in BOOTSTRAP state if necessary. This is to ensure\n+        //             it catches up with peers before serving PUT traffic (or being selected as LEADER)\n+        Store store = getStore(replica.getPartitionId(), false);\n+        if (store == null) {\n           throw new StateTransitionException(\n               \"Store \" + partitionName + \" didn't start correctly, replica should be set to ERROR state\",\n               StoreNotStarted);\n         }\n+        // if store's used capacity is less than or equal to header size, we create a bootstrap_in_progress file and force\n+        // it to stay in BOOTSTRAP state when catching up with peers.\n+        long storeUsedCapacity = store.getSizeInBytes();\n+        if (storeUsedCapacity <= HEADER_SIZE) {\n+          logger.info(\n+              \"Store {} has used capacity {} less than or equal to {} bytes, consider it recently created and make it go through bootstrap process.\",\n+              partitionName, storeUsedCapacity, HEADER_SIZE);\n+          try {\n+            File bootstrapFile = new File(replica.getReplicaPath(), BlobStore.BOOTSTRAP_FILE_NAME);\n+            if (!bootstrapFile.exists()) {\n+              bootstrapFile.createNewFile();\n+            }\n+          } catch (IOException e) {\n+            logger.error(\"Failed to create bootstrap file for store {}\", partitionName);\n+            throw new StateTransitionException(\"Failed to create bootstrap file for \" + partitionName,\n+                ReplicaOperationFailure);\n+          }\n+        }\n+        store.setCurrentState(ReplicaState.BOOTSTRAP);", "originalCommit": "5e51d46695f9ce28959a4e91a0fbf31d6458661e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA5MTI3Nw==", "url": "https://github.com/linkedin/ambry/pull/1571#discussion_r445091277", "bodyText": "there are 4 cases need to discuss:", "author": "justinlin-linkedin", "createdAt": "2020-06-24T18:31:47Z", "path": "ambry-store/src/main/java/com/github/ambry/store/StorageManager.java", "diffHunk": "@@ -476,16 +477,40 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {\n         // able to get new replica from storageManager without querying Helix\n       } else {\n         // if the replica is already on current node, there are 3 cases need to discuss:", "originalCommit": "5e51d46695f9ce28959a4e91a0fbf31d6458661e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA5NTkwMg==", "url": "https://github.com/linkedin/ambry/pull/1571#discussion_r445095902", "bodyText": "I wonder if this is really necessary. If we create a bootstrap_in_progress file no matter the used capacity and let the remaining transition remove it later. In this way I think we can address another corner case where only half of the data in this partition gets wiped out.\nImagine that we have two log segment files in this partition, somehow we remove the second log segment file and then we restart the process. Here since the used capacity is no less then HEADER_SIZE, so the bootstrap_in_progress file will not be created, then the replicationmanager's callback would just mark it as standby on the onPartitionBecomeStandByFromBootstrap.\nBut if we create the bootstrap without checking the HEADER_SIZE, then we can avoid this issue.", "author": "justinlin-linkedin", "createdAt": "2020-06-24T18:40:31Z", "path": "ambry-store/src/main/java/com/github/ambry/store/StorageManager.java", "diffHunk": "@@ -476,16 +477,40 @@ public void onPartitionBecomeBootstrapFromOffline(String partitionName) {\n         // able to get new replica from storageManager without querying Helix\n       } else {\n         // if the replica is already on current node, there are 3 cases need to discuss:\n-        // 1. replica was initially present in clustermap;\n-        // 2. replica was dynamically added to this node but may fail during BOOTSTRAP -> STANDBY transition\n+        // 1. replica was initially present in clustermap and this is a regular reboot.\n+        // 2. replica was dynamically added to this node but may fail during BOOTSTRAP -> STANDBY transition.\n         // 3. replica is on current node but its disk is offline. The replica is not able to start.\n+        // 4. replica was initially present in clustermap but it's current being recreated due to disk failure before.\n+\n         // For case 1 and 2, OFFLINE -> BOOTSTRAP is complete, we leave remaining actions (if there any) to other transition.\n         // For case 3, we should throw exception to make replica stay in ERROR state (thus, frontends won't pick this replica)\n-        if (getStore(replica.getPartitionId(), false) == null) {\n+        // For case 4, we check it's current used capacity and put it in BOOTSTRAP state if necessary. This is to ensure\n+        //             it catches up with peers before serving PUT traffic (or being selected as LEADER)\n+        Store store = getStore(replica.getPartitionId(), false);\n+        if (store == null) {\n           throw new StateTransitionException(\n               \"Store \" + partitionName + \" didn't start correctly, replica should be set to ERROR state\",\n               StoreNotStarted);\n         }\n+        // if store's used capacity is less than or equal to header size, we create a bootstrap_in_progress file and force\n+        // it to stay in BOOTSTRAP state when catching up with peers.\n+        long storeUsedCapacity = store.getSizeInBytes();\n+        if (storeUsedCapacity <= HEADER_SIZE) {", "originalCommit": "5e51d46695f9ce28959a4e91a0fbf31d6458661e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTIzNTk4OA==", "url": "https://github.com/linkedin/ambry/pull/1571#discussion_r445235988", "bodyText": "We can extend this to some other interesting edge cases, I will talk with you offline. For now, let's start with empty store first, that's the most common case when we wipe out whole partition or replace the disk.", "author": "jsjtzyy", "createdAt": "2020-06-25T00:01:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA5NTkwMg=="}], "type": "inlineReview"}, {"oid": "ecba601d1e51ad912ba80889253e460a4ccd0c07", "url": "https://github.com/linkedin/ambry/commit/ecba601d1e51ad912ba80889253e460a4ccd0c07", "message": "Force empty store to stay in BOOTSTRAP before catchup completes\n\nWhen disk crashed due to I/O error, we lost partitions on this disk. After new disk\nis mounted, Ambry is able to recreate the stores on new disk during reboot. These\nrecreated stores are empty and probably way behind their peer replicas, so we need\nto put them in BOOTSTRAP state until they have caught up with peers. Considering\nLeader-based Replication will be introduced, this PR guarantees those empty store\nwon't be selected LEADER because they are in BOOTSTRAP state. (Otherwise, some stores\nare selected as LEADER but they have to spend a couple of hours/days completing catchup.\nMeanwhile new data in remote dc(s) cannot be replicated to current dc.)", "committedDate": "2020-06-24T23:12:58Z", "type": "commit"}, {"oid": "56f80e3a3c03f2ac6eb9866202f5b8492b8c15cc", "url": "https://github.com/linkedin/ambry/commit/56f80e3a3c03f2ac6eb9866202f5b8492b8c15cc", "message": "added unit tests", "committedDate": "2020-06-24T23:12:58Z", "type": "commit"}, {"oid": "4b4cf3836810b2915141818eab150441f2f247c9", "url": "https://github.com/linkedin/ambry/commit/4b4cf3836810b2915141818eab150441f2f247c9", "message": "fix test failure", "committedDate": "2020-06-24T23:42:21Z", "type": "commit"}, {"oid": "29b018720bfc1f4ac2b9041dc430e0f5e9af9741", "url": "https://github.com/linkedin/ambry/commit/29b018720bfc1f4ac2b9041dc430e0f5e9af9741", "message": "rebased and addressed comments", "committedDate": "2020-06-25T00:56:03Z", "type": "commit"}, {"oid": "29b018720bfc1f4ac2b9041dc430e0f5e9af9741", "url": "https://github.com/linkedin/ambry/commit/29b018720bfc1f4ac2b9041dc430e0f5e9af9741", "message": "rebased and addressed comments", "committedDate": "2020-06-25T00:56:03Z", "type": "forcePushed"}]}