{"pr_number": 1536, "pr_title": "Fix incorrect offline partition count in HelixParticipant", "pr_createdAt": "2020-05-27T03:58:44Z", "pr_url": "https://github.com/linkedin/ambry/pull/1536", "timeline": [{"oid": "75a3544e530bc785ff9d89611282001533e3b681", "url": "https://github.com/linkedin/ambry/commit/75a3544e530bc785ff9d89611282001533e3b681", "message": "Fix incorrect offline partition count in HelixParticipant\n\nOffline partition is currently counted based how many times the reset\nmethod is called. However, Helix may call reset method against same\npartition multiple times during zk disconnection or graceful shutdown.\nThis causes incorrect number of offline partitions and triggers false\nalarm. To fix that, this PR keeps track of each local partition and its\nstate, which also supports tracking added/removed replicas on local node.", "committedDate": "2020-05-27T03:41:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTUwNDIxNA==", "url": "https://github.com/linkedin/ambry/pull/1536#discussion_r431504214", "bodyText": "This definitely is cleaner logic wise.\nMy only concern is that the gauge readings will result in 6 full scans of the map every minute (or whatever frequency), which could get expensive if the number of replicas is large.  A possible optimization would be to do a single scan periodically and update local counters for each state, which the gauges could read as before.  But the performance benefit may be too small to justify this.", "author": "lightningrob", "createdAt": "2020-05-27T23:44:18Z", "path": "ambry-clustermap/src/main/java/com/github/ambry/clustermap/HelixParticipantMetrics.java", "diffHunk": "@@ -16,55 +16,47 @@\n import com.codahale.metrics.Counter;\n import com.codahale.metrics.Gauge;\n import com.codahale.metrics.MetricRegistry;\n+import java.util.Collections;\n+import java.util.Map;\n import java.util.concurrent.atomic.AtomicInteger;\n \n \n /**\n  * Metrics for {@link HelixParticipant} to monitor partition state transitions.\n  */\n class HelixParticipantMetrics {\n-  final AtomicInteger bootstrapCount = new AtomicInteger();\n-  final AtomicInteger standbyCount = new AtomicInteger();\n-  final AtomicInteger leaderCount = new AtomicInteger();\n-  final AtomicInteger inactiveCount = new AtomicInteger();\n   final AtomicInteger offlineCount = new AtomicInteger();\n-  final AtomicInteger errorStateCount = new AtomicInteger();\n   // no need to record exact number of \"dropped\" partition, a counter to track partition-dropped events would suffice\n   final Counter partitionDroppedCount;\n \n-  HelixParticipantMetrics(MetricRegistry metricRegistry, String zkConnectStr) {\n+  HelixParticipantMetrics(MetricRegistry metricRegistry, String zkConnectStr,\n+      Map<String, ReplicaState> localPartitionAndState) {\n     String zkSuffix = zkConnectStr == null ? \"\" : \"-\" + zkConnectStr;\n-    Gauge<Integer> bootstrapPartitionCount = bootstrapCount::get;\n+    Gauge<Integer> bootstrapPartitionCount =\n+        () -> Collections.frequency(localPartitionAndState.values(), ReplicaState.BOOTSTRAP);\n     metricRegistry.register(MetricRegistry.name(HelixParticipant.class, \"bootstrapPartitionCount\" + zkSuffix),\n         bootstrapPartitionCount);\n-    Gauge<Integer> standbyPartitionCount = standbyCount::get;\n+    Gauge<Integer> standbyPartitionCount =\n+        () -> Collections.frequency(localPartitionAndState.values(), ReplicaState.STANDBY);\n     metricRegistry.register(MetricRegistry.name(HelixParticipant.class, \"standbyPartitionCount\" + zkSuffix),\n         standbyPartitionCount);\n-    Gauge<Integer> leaderPartitionCount = leaderCount::get;\n+    Gauge<Integer> leaderPartitionCount =\n+        () -> Collections.frequency(localPartitionAndState.values(), ReplicaState.LEADER);\n     metricRegistry.register(MetricRegistry.name(HelixParticipant.class, \"leaderPartitionCount\" + zkSuffix),\n         leaderPartitionCount);\n-    Gauge<Integer> inactivePartitionCount = inactiveCount::get;\n+    Gauge<Integer> inactivePartitionCount =\n+        () -> Collections.frequency(localPartitionAndState.values(), ReplicaState.INACTIVE);\n     metricRegistry.register(MetricRegistry.name(HelixParticipant.class, \"inactivePartitionCount\" + zkSuffix),\n         inactivePartitionCount);\n-    Gauge<Integer> offlinePartitionCount = offlineCount::get;\n+    Gauge<Integer> offlinePartitionCount =\n+        () -> Collections.frequency(localPartitionAndState.values(), ReplicaState.OFFLINE);\n     metricRegistry.register(MetricRegistry.name(HelixParticipant.class, \"offlinePartitionCount\" + zkSuffix),\n         offlinePartitionCount);\n-    Gauge<Integer> errorStatePartitionCount = errorStateCount::get;\n+    Gauge<Integer> errorStatePartitionCount =\n+        () -> Collections.frequency(localPartitionAndState.values(), ReplicaState.ERROR);", "originalCommit": "75a3544e530bc785ff9d89611282001533e3b681", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTU1OTA1NQ==", "url": "https://github.com/linkedin/ambry/pull/1536#discussion_r431559055", "bodyText": "Fair point, I will try to scan once and cache the result for other 5 metrics.", "author": "jsjtzyy", "createdAt": "2020-05-28T03:16:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTUwNDIxNA=="}], "type": "inlineReview"}, {"oid": "d17eb2b35c53804d6e2daef1c976b902867cec07", "url": "https://github.com/linkedin/ambry/commit/d17eb2b35c53804d6e2daef1c976b902867cec07", "message": "cache result for partition count metrics", "committedDate": "2020-05-28T05:22:28Z", "type": "commit"}]}