{"pr_number": 1383, "pr_title": "Create RecoveryTestClusterAgentsFactory and RecoveryTestClusterManager", "pr_createdAt": "2020-02-13T02:55:05Z", "pr_url": "https://github.com/linkedin/ambry/pull/1383", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEyNDYxMA==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379124610", "bodyText": "if this method can be called more than once, then clusterParticipant should be either volatile or AtomicReference.", "author": "lightningrob", "createdAt": "2020-02-13T21:20:12Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterAgentsFactory.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.io.IOException;\n+import org.json.JSONException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ *\n+ */\n+public class RecoveryTestClusterAgentsFactory implements ClusterAgentsFactory {\n+  private static final Logger logger = LoggerFactory.getLogger(CompositeClusterAgentsFactory.class);\n+  private final StaticClusterAgentsFactory staticClusterAgentsFactory;\n+  private final HelixClusterAgentsFactory helixClusterAgentsFactory;\n+  private RecoveryTestClusterManager recoveryTestClusterManager;\n+  private ClusterParticipant clusterParticipant;\n+\n+  /**\n+   * Create an instance of this class.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n+   * @param hardwareLayoutFilePath the path to the hardware layout file.\n+   * @param partitionLayoutFilePath the path to the partition layout file.\n+   * @throws JSONException if there is an exception parsing the layout files.\n+   * @throws IOException if there is an IO error accessing or reading the layout files.\n+   */\n+  public RecoveryTestClusterAgentsFactory(ClusterMapConfig clusterMapConfig, String hardwareLayoutFilePath,\n+      String partitionLayoutFilePath) throws JSONException {\n+    PartitionLayout partitionLayout =\n+        new PartitionLayout(new HardwareLayout(clusterMapConfig.clustermapRecoveryTestHardwareLayout, clusterMapConfig),\n+            clusterMapConfig.clustermapRecoveryTestPartitionLayout, clusterMapConfig);\n+    staticClusterAgentsFactory = new StaticClusterAgentsFactory(clusterMapConfig, partitionLayout);\n+    helixClusterAgentsFactory =\n+        new HelixClusterAgentsFactory(clusterMapConfig, staticClusterAgentsFactory.getMetricRegistry());\n+  }\n+\n+  /**\n+   * Create and return a {@link RecoveryTestClusterManager}.\n+   * @return the constructed {@link RecoveryTestClusterManager}.\n+   * @throws Exception if constructing the underlying {@link StaticClusterManager} or the {@link HelixClusterManager}\n+   * throws an Exception.\n+   */\n+  @Override\n+  public RecoveryTestClusterManager getClusterMap() throws IOException {\n+    if (recoveryTestClusterManager == null) {\n+      StaticClusterManager staticClusterManager = staticClusterAgentsFactory.getClusterMap();\n+      HelixClusterManager helixClusterManager = null;\n+      try {\n+        helixClusterManager = helixClusterAgentsFactory.getClusterMap();\n+      } catch (Exception e) {\n+        logger.error(\"Helix cluster manager instantiation failed with exception\", e);\n+      }\n+      recoveryTestClusterManager = new RecoveryTestClusterManager(staticClusterManager, helixClusterManager);\n+    }\n+    return recoveryTestClusterManager;\n+  }\n+\n+  @Override\n+  public ClusterParticipant getClusterParticipant() throws IOException {\n+    if (clusterParticipant == null) {", "originalCommit": "89bd3d8a27be52509f4e14fe4ba2d7f074af6679", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NTI2Nw==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379165267", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-02-13T22:54:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEyNDYxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEyNTE0OQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379125149", "bodyText": "combine two lines", "author": "lightningrob", "createdAt": "2020-02-13T21:21:14Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterManager.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A cluster manager that is a composed of a {@link StaticClusterManager} and a {@link HelixClusterManager}.\n+ * It provides a merged view of the static and helix clusters.\n+ */\n+public class RecoveryTestClusterManager implements ClusterMap {\n+  private final Logger logger = LoggerFactory.getLogger(CompositeClusterManager.class);\n+  final StaticClusterManager staticClusterManager;\n+  final HelixClusterManager helixClusterManager;\n+  final Map<AmbryDisk, Disk> ambryDiskToDiskMap;\n+  final Map<AmbryDataNode, DataNode> ambryDataNodeToDataNodeMap;\n+\n+  /**\n+   * Construct a RecoveryTestClusterManager instance.\n+   * @param staticClusterManager the {@link StaticClusterManager} object.\n+   * @param helixClusterManager the {@link HelixClusterManager} object.\n+   */\n+  RecoveryTestClusterManager(StaticClusterManager staticClusterManager, HelixClusterManager helixClusterManager) {\n+    this.staticClusterManager = staticClusterManager;\n+    this.helixClusterManager = helixClusterManager;\n+    ambryDataNodeToDataNodeMap = new HashMap<>();\n+    ambryDiskToDiskMap = new HashMap<>();\n+  }\n+\n+  @Override\n+  public PartitionId getPartitionIdFromStream(InputStream stream) throws IOException {\n+    DuplicatingInputStream duplicatingInputStream = new DuplicatingInputStream(stream);\n+    duplicatingInputStream.mark(0);\n+    PartitionId partitionIdStatic = staticClusterManager.getPartitionIdFromStream(duplicatingInputStream);\n+    return partitionIdStatic;\n+  }\n+\n+  @Override\n+  public List<PartitionId> getWritablePartitionIds(String partitionClass) {\n+    throw new UnsupportedOperationException(String.format(\"getWritablePartitionIds method is not supported\"));\n+  }\n+\n+  @Override\n+  public PartitionId getRandomWritablePartition(String partitionClass, List<PartitionId> partitionsToExclude) {\n+    throw new UnsupportedOperationException(String.format(\"getRandomWritablePartition method is not supported\"));\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Get all partition ids from both the underlying {@link StaticClusterManager}.\n+   * @param partitionClass the partition class whose partitions are required. Can be {@code null}\n+   * @return a list of partition ids from the underlying {@link StaticClusterManager}.\n+   */\n+  @Override\n+  public List<PartitionId> getAllPartitionIds(String partitionClass) {\n+    List<PartitionId> staticPartitionIds = staticClusterManager.getAllPartitionIds(partitionClass);\n+    return staticPartitionIds;", "originalCommit": "89bd3d8a27be52509f4e14fe4ba2d7f074af6679", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NTMzNg==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379165336", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-02-13T22:55:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEyNTE0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEyNjM4NQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379126385", "bodyText": "do Objects.requireNonNull() on params", "author": "lightningrob", "createdAt": "2020-02-13T21:23:57Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterManager.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A cluster manager that is a composed of a {@link StaticClusterManager} and a {@link HelixClusterManager}.\n+ * It provides a merged view of the static and helix clusters.\n+ */\n+public class RecoveryTestClusterManager implements ClusterMap {\n+  private final Logger logger = LoggerFactory.getLogger(CompositeClusterManager.class);\n+  final StaticClusterManager staticClusterManager;\n+  final HelixClusterManager helixClusterManager;\n+  final Map<AmbryDisk, Disk> ambryDiskToDiskMap;\n+  final Map<AmbryDataNode, DataNode> ambryDataNodeToDataNodeMap;\n+\n+  /**\n+   * Construct a RecoveryTestClusterManager instance.\n+   * @param staticClusterManager the {@link StaticClusterManager} object.\n+   * @param helixClusterManager the {@link HelixClusterManager} object.\n+   */\n+  RecoveryTestClusterManager(StaticClusterManager staticClusterManager, HelixClusterManager helixClusterManager) {\n+    this.staticClusterManager = staticClusterManager;\n+    this.helixClusterManager = helixClusterManager;", "originalCommit": "89bd3d8a27be52509f4e14fe4ba2d7f074af6679", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NTI5OA==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379165298", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-02-13T22:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEyNjM4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEyNzAxMg==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379127012", "bodyText": "Can it be null?  You assume it's not in other places.", "author": "lightningrob", "createdAt": "2020-02-13T21:25:13Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterManager.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.json.JSONObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A cluster manager that is a composed of a {@link StaticClusterManager} and a {@link HelixClusterManager}.\n+ * It provides a merged view of the static and helix clusters.\n+ */\n+public class RecoveryTestClusterManager implements ClusterMap {\n+  private final Logger logger = LoggerFactory.getLogger(CompositeClusterManager.class);\n+  final StaticClusterManager staticClusterManager;\n+  final HelixClusterManager helixClusterManager;\n+  final Map<AmbryDisk, Disk> ambryDiskToDiskMap;\n+  final Map<AmbryDataNode, DataNode> ambryDataNodeToDataNodeMap;\n+\n+  /**\n+   * Construct a RecoveryTestClusterManager instance.\n+   * @param staticClusterManager the {@link StaticClusterManager} object.\n+   * @param helixClusterManager the {@link HelixClusterManager} object.\n+   */\n+  RecoveryTestClusterManager(StaticClusterManager staticClusterManager, HelixClusterManager helixClusterManager) {\n+    this.staticClusterManager = staticClusterManager;\n+    this.helixClusterManager = helixClusterManager;\n+    ambryDataNodeToDataNodeMap = new HashMap<>();\n+    ambryDiskToDiskMap = new HashMap<>();\n+  }\n+\n+  @Override\n+  public PartitionId getPartitionIdFromStream(InputStream stream) throws IOException {\n+    DuplicatingInputStream duplicatingInputStream = new DuplicatingInputStream(stream);\n+    duplicatingInputStream.mark(0);\n+    PartitionId partitionIdStatic = staticClusterManager.getPartitionIdFromStream(duplicatingInputStream);\n+    return partitionIdStatic;\n+  }\n+\n+  @Override\n+  public List<PartitionId> getWritablePartitionIds(String partitionClass) {\n+    throw new UnsupportedOperationException(String.format(\"getWritablePartitionIds method is not supported\"));\n+  }\n+\n+  @Override\n+  public PartitionId getRandomWritablePartition(String partitionClass, List<PartitionId> partitionsToExclude) {\n+    throw new UnsupportedOperationException(String.format(\"getRandomWritablePartition method is not supported\"));\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   * Get all partition ids from both the underlying {@link StaticClusterManager}.\n+   * @param partitionClass the partition class whose partitions are required. Can be {@code null}\n+   * @return a list of partition ids from the underlying {@link StaticClusterManager}.\n+   */\n+  @Override\n+  public List<PartitionId> getAllPartitionIds(String partitionClass) {\n+    List<PartitionId> staticPartitionIds = staticClusterManager.getAllPartitionIds(partitionClass);\n+    return staticPartitionIds;\n+  }\n+\n+  /**\n+   * Check for existence of the given datacenter from both the static and the helix based cluster managers and update\n+   * a metric if there is a mismatch.\n+   * @param datacenterName name of datacenter\n+   * @return true if the datacenter exists in the underlying {@link StaticClusterManager}; false otherwise.\n+   */\n+  @Override\n+  public boolean hasDatacenter(String datacenterName) {\n+    boolean staticHas = staticClusterManager.hasDatacenter(datacenterName);\n+    boolean helixHas = helixClusterManager.hasDatacenter(datacenterName);\n+    return staticHas || helixHas;\n+  }\n+\n+  @Override\n+  public byte getLocalDatacenterId() {\n+    return staticClusterManager.getLocalDatacenterId();\n+  }\n+\n+  @Override\n+  public String getDatacenterName(byte id) {\n+    String dcName = staticClusterManager.getDatacenterName(id);\n+    return (dcName != null) ? dcName : helixClusterManager.getDatacenterName(id);\n+  }\n+\n+  /**\n+   * Return the {@link DataNodeId} associated with the given hostname and port in the underlying\n+   * {@link StaticClusterManager}. If not found in static cluster map, then get the same from helix cluster map.\n+   * @param hostname of the DataNodeId\n+   * @param port of the DataNodeId\n+   * @return the {@link DataNodeId} associated with the given hostname and port.\n+   */\n+  @Override\n+  public DataNodeId getDataNodeId(String hostname, int port) {\n+    DataNodeId dataNode = staticClusterManager.getDataNodeId(hostname, port);\n+    if (dataNode == null) {\n+      dataNode = helixClusterManager.getDataNodeId(hostname, port);\n+    }\n+    return dataNode;\n+  }\n+\n+  /**\n+   * Get the list of {@link ReplicaId}s associated with the given {@link DataNodeId} in the underlying\n+   * {@link StaticClusterManager}. The list of {@link ReplicaId}s is obtained by merging replica lists from\n+   * {@link HelixClusterManager} and {@link StaticClusterManager}.\n+   * @param dataNodeId the {@link DataNodeId} for which the replicas are to be listed.\n+   * @return merged list of {@link ReplicaId}s as present in the underlying {@link StaticClusterManager} and\n+   * {@link HelixClusterManager} for the given node.\n+   */\n+  @Override\n+  public List<ReplicaId> getReplicaIds(DataNodeId dataNodeId) {\n+    List<ReplicaId> mergedReplicas = new ArrayList<>();\n+    for (ReplicaId staticReplica : staticClusterManager.getReplicaIds(dataNodeId)) {\n+      AmbryPartition partitionId = (AmbryPartition) getHelixPartition(staticReplica);\n+      if (partitionId == null) {\n+        throw new IllegalStateException(String.format(\"No partition %s not found in helix clustermap\",\n+            staticReplica.getPartitionId().toPathString()));\n+      }\n+      Partition partition = (Partition) staticReplica.getPartitionId();\n+      Partition compositePartition =\n+          new Partition(Long.parseLong(partitionId.toPathString()), partition.getPartitionClass(),\n+              partition.getPartitionState(), partition.getReplicaCapacityInBytes());\n+      for (ReplicaId replicaId : partitionId.getReplicaIds()) {\n+        compositePartition.addReplica(replicaId);\n+      }\n+      Replica compositeReplica = new Replica(compositePartition, (Disk) staticReplica.getDiskId(),\n+          ((Replica) staticReplica).getClusterMapConfig());\n+      compositePartition.addReplica(compositeReplica);\n+      mergedReplicas.add(compositeReplica);\n+    }\n+    return mergedReplicas;\n+  }\n+\n+  /**\n+   * Search from all the partitions of {@link HelixClusterManager}, the {@link PartitionId} with same partition id as\n+   * one in the {@link ReplicaId} passed.\n+   * @param replicaId {@link ReplicaId} object.\n+   * @return {@link PartitionId} of {@link HelixClusterManager}.\n+   */\n+  PartitionId getHelixPartition(ReplicaId replicaId) {\n+    return helixClusterManager.getAllPartitionIds(null)\n+        .stream()\n+        .filter(partitionId -> replicaId.getPartitionId().toPathString().equals(partitionId.toPathString()))\n+        .findAny()\n+        .get();\n+  }\n+\n+  /**\n+   * The list of {@link DataNodeId}s present in the underlying {@link HelixClusterManager}\n+   * @return the list of {@link DataNodeId}s present in the underlying {@link HelixClusterManager}\n+   */\n+  @Override\n+  public List<? extends DataNodeId> getDataNodeIds() {\n+    return helixClusterManager.getDataNodeIds();\n+  }\n+\n+  @Override\n+  public MetricRegistry getMetricRegistry() {\n+    return staticClusterManager.getMetricRegistry();\n+  }\n+\n+  /**\n+   * Relay the event to both the underlying {@link StaticClusterManager} and the underlying {@link HelixClusterManager}.\n+   * @param replicaId the {@link ReplicaId} for which this event has occurred.\n+   * @param event the {@link ReplicaEventType}.\n+   */\n+  @Override\n+  public void onReplicaEvent(ReplicaId replicaId, ReplicaEventType event) {\n+    helixClusterManager.onReplicaEvent(replicaId, event);\n+  }\n+\n+  @Override\n+  public JSONObject getSnapshot() {\n+    return staticClusterManager.getSnapshot();\n+  }\n+\n+  @Override\n+  public ReplicaId getBootstrapReplica(String partitionIdStr, DataNodeId dataNodeId) {\n+    return helixClusterManager.getBootstrapReplica(partitionIdStr, dataNodeId);\n+  }\n+\n+  @Override\n+  public void registerClusterMapListener(ClusterMapChangeListener clusterMapChangeListener) {\n+    if (helixClusterManager != null) {", "originalCommit": "89bd3d8a27be52509f4e14fe4ba2d7f074af6679", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NTM4Mg==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379165382", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-02-13T22:55:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEyNzAxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEzMTMxOA==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379131318", "bodyText": "These things look out of place here.\nAlso, if the cluster agents factories are constructed with the two layout files, why do we even need the config properties?", "author": "lightningrob", "createdAt": "2020-02-13T21:34:53Z", "path": "ambry-api/src/main/java/com.github.ambry/config/ClusterMapConfig.java", "diffHunk": "@@ -231,6 +232,20 @@\n   @Default(\"false\")\n   public final boolean clustermapUpdateDatanodeInfo;\n \n+  /**\n+   * Partition layout json for recovery test cluster map.\n+   */\n+  @Config(\"clustermap.recovery.test.partition.layout\")\n+  @Default(\"{}\")\n+  public final JSONObject clustermapRecoveryTestPartitionLayout;", "originalCommit": "89bd3d8a27be52509f4e14fe4ba2d7f074af6679", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NTA0NQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379165045", "bodyText": "As discussed offline, these are needed for make operations easy when running ambryserver to get SoT data for recoverytest.", "author": "ankagrawal", "createdAt": "2020-02-13T22:54:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTEzMTMxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0MDE5MA==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379140190", "bodyText": "CompositeClusterAgentsFactory -> RecoveryTestClusterAgentsFactory", "author": "jsjtzyy", "createdAt": "2020-02-13T21:53:50Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterAgentsFactory.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.io.IOException;\n+import org.json.JSONException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ *\n+ */\n+public class RecoveryTestClusterAgentsFactory implements ClusterAgentsFactory {\n+  private static final Logger logger = LoggerFactory.getLogger(CompositeClusterAgentsFactory.class);", "originalCommit": "89bd3d8a27be52509f4e14fe4ba2d7f074af6679", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NTIxNg==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379165216", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-02-13T22:54:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0MDE5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0MDc2OQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379140769", "bodyText": "complete the java doc", "author": "jsjtzyy", "createdAt": "2020-02-13T21:55:09Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterAgentsFactory.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.io.IOException;\n+import org.json.JSONException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ *", "originalCommit": "89bd3d8a27be52509f4e14fe4ba2d7f074af6679", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NTE5MQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379165191", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-02-13T22:54:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0MDc2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0OTAxMA==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379149010", "bodyText": "As discussed offline, we can remove this config.", "author": "jsjtzyy", "createdAt": "2020-02-13T22:13:24Z", "path": "ambry-api/src/main/java/com.github.ambry/config/ServerConfig.java", "diffHunk": "@@ -93,6 +93,13 @@\n   @Default(\"false\")\n   public final boolean serverValidateRequestBasedOnStoreState;\n \n+  /**\n+   * Should the server participate in any cluster.\n+   */\n+  @Config(\"server.should.not.participate.in.cluster\")\n+  @Default(\"false\")\n+  public boolean serverShouldNotParticipateInCluster;", "originalCommit": "89bd3d8a27be52509f4e14fe4ba2d7f074af6679", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE2NTEyNA==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379165124", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-02-13T22:54:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0OTAxMA=="}], "type": "inlineReview"}, {"oid": "246f5cf00cab24b3c50891d0346929fccd20e3be", "url": "https://github.com/linkedin/ambry/commit/246f5cf00cab24b3c50891d0346929fccd20e3be", "message": "Create a no op ClusterParticipant. Remove shouldParticipate config. Address other review comments.", "committedDate": "2020-02-13T23:17:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE4Nzk5MQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379187991", "bodyText": "Any reason to change Replica to ReplicaId?  Partittion, Replica and Disk are for static clustermap. I think in this class, it is supposed to be Replica and cannot be another implementation of ReplicaId.", "author": "jsjtzyy", "createdAt": "2020-02-14T00:05:54Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/Partition.java", "diffHunk": "@@ -44,7 +44,7 @@\n   private static final short Current_Version = 1;\n   private static final int Partition_Size_In_Bytes = Version_Field_Size_In_Bytes + 8;\n \n-  private final List<Replica> replicas;\n+  private final List<ReplicaId> replicas;", "originalCommit": "246f5cf00cab24b3c50891d0346929fccd20e3be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTcwODA1MQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379708051", "bodyText": "As discussed offline this was needed to make APIs generic, so that merging on cluster maps becomes easy in RecoveryTestClusterManager.", "author": "ankagrawal", "createdAt": "2020-02-15T01:39:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE4Nzk5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE5MTc0MA==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379191740", "bodyText": "can remove this", "author": "jsjtzyy", "createdAt": "2020-02-14T00:19:13Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterAgentsFactory.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AmbryHealthReport;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.json.JSONException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A factory class to construct {@link RecoveryTestClusterManager} and a no op {@link ClusterParticipant}.\n+ * Only one instance of each type of objects will ever be created by this factory.\n+ */\n+public class RecoveryTestClusterAgentsFactory implements ClusterAgentsFactory {\n+  private static final Logger logger = LoggerFactory.getLogger(RecoveryTestClusterAgentsFactory.class);\n+  private final StaticClusterAgentsFactory staticClusterAgentsFactory;\n+  private final HelixClusterAgentsFactory helixClusterAgentsFactory;\n+  private final AtomicReference<RecoveryTestClusterManager> recoveryTestClusterManagerRef = new AtomicReference<>();\n+  private final AtomicReference<ClusterParticipant> clusterParticipantRef = new AtomicReference<>();\n+\n+  /**\n+   * Create an instance of this class.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n+   * @param hardwareLayoutFilePath the path to the hardware layout file.\n+   * @param partitionLayoutFilePath the path to the partition layout file.\n+   * @throws JSONException if there is an exception parsing the layout files.\n+   * @throws IOException if there is an IO error accessing or reading the layout files.", "originalCommit": "246f5cf00cab24b3c50891d0346929fccd20e3be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTcwODYyMQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379708621", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-02-15T01:46:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE5MTc0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE5NDk0OA==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379194948", "bodyText": "return can be removed", "author": "jsjtzyy", "createdAt": "2020-02-14T00:31:48Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterAgentsFactory.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AmbryHealthReport;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.json.JSONException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A factory class to construct {@link RecoveryTestClusterManager} and a no op {@link ClusterParticipant}.\n+ * Only one instance of each type of objects will ever be created by this factory.\n+ */\n+public class RecoveryTestClusterAgentsFactory implements ClusterAgentsFactory {\n+  private static final Logger logger = LoggerFactory.getLogger(RecoveryTestClusterAgentsFactory.class);\n+  private final StaticClusterAgentsFactory staticClusterAgentsFactory;\n+  private final HelixClusterAgentsFactory helixClusterAgentsFactory;\n+  private final AtomicReference<RecoveryTestClusterManager> recoveryTestClusterManagerRef = new AtomicReference<>();\n+  private final AtomicReference<ClusterParticipant> clusterParticipantRef = new AtomicReference<>();\n+\n+  /**\n+   * Create an instance of this class.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n+   * @param hardwareLayoutFilePath the path to the hardware layout file.\n+   * @param partitionLayoutFilePath the path to the partition layout file.\n+   * @throws JSONException if there is an exception parsing the layout files.\n+   * @throws IOException if there is an IO error accessing or reading the layout files.\n+   */\n+  public RecoveryTestClusterAgentsFactory(ClusterMapConfig clusterMapConfig, String hardwareLayoutFilePath,\n+      String partitionLayoutFilePath) throws JSONException {\n+    PartitionLayout partitionLayout =\n+        new PartitionLayout(new HardwareLayout(clusterMapConfig.clustermapRecoveryTestHardwareLayout, clusterMapConfig),\n+            clusterMapConfig.clustermapRecoveryTestPartitionLayout, clusterMapConfig);\n+    staticClusterAgentsFactory = new StaticClusterAgentsFactory(clusterMapConfig, partitionLayout);\n+    helixClusterAgentsFactory =\n+        new HelixClusterAgentsFactory(clusterMapConfig, staticClusterAgentsFactory.getMetricRegistry());\n+  }\n+\n+  /**\n+   * Create and return a {@link RecoveryTestClusterManager}.\n+   * @return the constructed {@link RecoveryTestClusterManager}.\n+   * @throws Exception if constructing the underlying {@link StaticClusterManager} or the {@link HelixClusterManager}\n+   * throws an Exception.\n+   */\n+  @Override\n+  public RecoveryTestClusterManager getClusterMap() throws IOException {\n+    if (recoveryTestClusterManagerRef.get() == null) {\n+      StaticClusterManager staticClusterManager = staticClusterAgentsFactory.getClusterMap();\n+      HelixClusterManager helixClusterManager = null;\n+      try {\n+        helixClusterManager = helixClusterAgentsFactory.getClusterMap();\n+      } catch (Exception e) {\n+        logger.error(\"Helix cluster manager instantiation failed with exception\", e);\n+      }\n+      recoveryTestClusterManagerRef.compareAndSet(null,\n+          new RecoveryTestClusterManager(staticClusterManager, helixClusterManager));\n+    }\n+    return recoveryTestClusterManagerRef.get();\n+  }\n+\n+  @Override\n+  public ClusterParticipant getClusterParticipant() throws IOException {\n+    if (clusterParticipantRef.get() == null) {\n+      // create a no op cluster participant that does nothing. Just sits idly by!!! \u00af\\_(\u30c4)_/\u00af\n+      ClusterParticipant clusterParticipant = new ClusterParticipant() {\n+        @Override\n+        public void participate(List<AmbryHealthReport> ambryHealthReports) {\n+          return;", "originalCommit": "246f5cf00cab24b3c50891d0346929fccd20e3be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTcwODg2MQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379708861", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-02-15T01:50:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE5NDk0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE5NTM4Mw==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379195383", "bodyText": "If there is an exception when getting helix cluster manager, should we terminate the startup?", "author": "jsjtzyy", "createdAt": "2020-02-14T00:33:17Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/RecoveryTestClusterAgentsFactory.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.server.AmbryHealthReport;\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.json.JSONException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A factory class to construct {@link RecoveryTestClusterManager} and a no op {@link ClusterParticipant}.\n+ * Only one instance of each type of objects will ever be created by this factory.\n+ */\n+public class RecoveryTestClusterAgentsFactory implements ClusterAgentsFactory {\n+  private static final Logger logger = LoggerFactory.getLogger(RecoveryTestClusterAgentsFactory.class);\n+  private final StaticClusterAgentsFactory staticClusterAgentsFactory;\n+  private final HelixClusterAgentsFactory helixClusterAgentsFactory;\n+  private final AtomicReference<RecoveryTestClusterManager> recoveryTestClusterManagerRef = new AtomicReference<>();\n+  private final AtomicReference<ClusterParticipant> clusterParticipantRef = new AtomicReference<>();\n+\n+  /**\n+   * Create an instance of this class.\n+   * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n+   * @param hardwareLayoutFilePath the path to the hardware layout file.\n+   * @param partitionLayoutFilePath the path to the partition layout file.\n+   * @throws JSONException if there is an exception parsing the layout files.\n+   * @throws IOException if there is an IO error accessing or reading the layout files.\n+   */\n+  public RecoveryTestClusterAgentsFactory(ClusterMapConfig clusterMapConfig, String hardwareLayoutFilePath,\n+      String partitionLayoutFilePath) throws JSONException {\n+    PartitionLayout partitionLayout =\n+        new PartitionLayout(new HardwareLayout(clusterMapConfig.clustermapRecoveryTestHardwareLayout, clusterMapConfig),\n+            clusterMapConfig.clustermapRecoveryTestPartitionLayout, clusterMapConfig);\n+    staticClusterAgentsFactory = new StaticClusterAgentsFactory(clusterMapConfig, partitionLayout);\n+    helixClusterAgentsFactory =\n+        new HelixClusterAgentsFactory(clusterMapConfig, staticClusterAgentsFactory.getMetricRegistry());\n+  }\n+\n+  /**\n+   * Create and return a {@link RecoveryTestClusterManager}.\n+   * @return the constructed {@link RecoveryTestClusterManager}.\n+   * @throws Exception if constructing the underlying {@link StaticClusterManager} or the {@link HelixClusterManager}\n+   * throws an Exception.\n+   */\n+  @Override\n+  public RecoveryTestClusterManager getClusterMap() throws IOException {\n+    if (recoveryTestClusterManagerRef.get() == null) {\n+      StaticClusterManager staticClusterManager = staticClusterAgentsFactory.getClusterMap();\n+      HelixClusterManager helixClusterManager = null;\n+      try {\n+        helixClusterManager = helixClusterAgentsFactory.getClusterMap();\n+      } catch (Exception e) {\n+        logger.error(\"Helix cluster manager instantiation failed with exception\", e);", "originalCommit": "246f5cf00cab24b3c50891d0346929fccd20e3be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTcwODgzMg==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379708832", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-02-15T01:49:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE5NTM4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY3MTEwMg==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379671102", "bodyText": "Why we need this change? They might have different types?", "author": "jsjtzyy", "createdAt": "2020-02-14T22:21:10Z", "path": "ambry-protocol/src/main/java/com.github.ambry.protocol/PartitionRequestInfo.java", "diffHunk": "@@ -42,7 +42,7 @@ public PartitionRequestInfo(PartitionId partitionId, List<BlobId> blobIds) {\n     totalIdSize = 0;\n     for (BlobId id : blobIds) {\n       totalIdSize += id.sizeInBytes();\n-      if (!partitionId.equals(id.getPartition())) {\n+      if (!partitionId.toPathString().equals(id.getPartition().toPathString())) {", "originalCommit": "246f5cf00cab24b3c50891d0346929fccd20e3be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTcwOTI1MQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379709251", "bodyText": "Thats why I have this change. In case of a cluster map where local partition comes from static cluster map(Partition.java), while the remote replicas comes from helix cluster map(AmbryPartition.java), it will not to possible to compare them because they will have different types. However, since replication can happen, the blobs returned in replication will have AmbryPartition as partition type. Hence in order to make sure they have the same partition, matching of just the id should suffice.", "author": "ankagrawal", "createdAt": "2020-02-15T01:54:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY3MTEwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY3MTc5MQ==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379671791", "bodyText": "same here, I feel compareTo would suffice", "author": "jsjtzyy", "createdAt": "2020-02-14T22:23:27Z", "path": "ambry-replication/src/main/java/com.github.ambry.replication/ReplicaThread.java", "diffHunk": "@@ -851,7 +851,9 @@ private void writeMessagesToLocalStoreAndAdvanceTokens(List<ExchangeMetadataResp\n               getResponse.getPartitionResponseInfoList().get(partitionResponseInfoIndex);\n           responseHandler.onEvent(remoteReplicaInfo.getReplicaId(), partitionResponseInfo.getErrorCode());\n           partitionResponseInfoIndex++;\n-          if (partitionResponseInfo.getPartition().compareTo(remoteReplicaInfo.getReplicaId().getPartitionId()) != 0) {\n+          if (!partitionResponseInfo.getPartition()", "originalCommit": "246f5cf00cab24b3c50891d0346929fccd20e3be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTcwOTI3Mg==", "url": "https://github.com/linkedin/ambry/pull/1383#discussion_r379709272", "bodyText": "Thats why I have this change. In case of a cluster map where local partition comes from static cluster map(Partition.java), while the remote replicas comes from helix cluster map(AmbryPartition.java), it will not to possible to compare them because they will have different types. However, since replication can happen, the remote replicas will have AmbryPartition as partition type. Hence in order to make sure they have the same partition, matching of just the id should suffice.", "author": "ankagrawal", "createdAt": "2020-02-15T01:55:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY3MTc5MQ=="}], "type": "inlineReview"}, {"oid": "7d6df3216b4f85fa7261543583432896e1d4058a", "url": "https://github.com/linkedin/ambry/commit/7d6df3216b4f85fa7261543583432896e1d4058a", "message": "Create RecoveryTestClusterAgentsFactory and RecoveryTestClusterManager to enable replication of source of truth data for recovery verification.", "committedDate": "2020-02-15T02:42:58Z", "type": "commit"}, {"oid": "45e308feadf34c3398e5e39300bd554bcd131669", "url": "https://github.com/linkedin/ambry/commit/45e308feadf34c3398e5e39300bd554bcd131669", "message": "Fix a unit test", "committedDate": "2020-02-15T02:42:59Z", "type": "commit"}, {"oid": "4d503d63cc4f5b88fd042ac4b2b0cf5bc016cfe6", "url": "https://github.com/linkedin/ambry/commit/4d503d63cc4f5b88fd042ac4b2b0cf5bc016cfe6", "message": "Create a no op ClusterParticipant. Remove shouldParticipate config. Address other review comments.", "committedDate": "2020-02-15T02:44:57Z", "type": "commit"}, {"oid": "ee5ac869c9da1fddfec29672a7f42442cf2ca25f", "url": "https://github.com/linkedin/ambry/commit/ee5ac869c9da1fddfec29672a7f42442cf2ca25f", "message": "Address review comments", "committedDate": "2020-02-15T02:44:57Z", "type": "commit"}, {"oid": "ee5ac869c9da1fddfec29672a7f42442cf2ca25f", "url": "https://github.com/linkedin/ambry/commit/ee5ac869c9da1fddfec29672a7f42442cf2ca25f", "message": "Address review comments", "committedDate": "2020-02-15T02:44:57Z", "type": "forcePushed"}]}