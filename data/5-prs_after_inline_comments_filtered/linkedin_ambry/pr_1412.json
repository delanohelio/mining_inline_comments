{"pr_number": 1412, "pr_title": "Add basic support for cloud replicas in clustermap", "pr_createdAt": "2020-03-02T21:57:22Z", "pr_url": "https://github.com/linkedin/ambry/pull/1412", "timeline": [{"oid": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "url": "https://github.com/linkedin/ambry/commit/b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "message": "Add basic support for cloud replicas in clustermap\n\n- Add a representation of a cloud datacenter to configs\n- Refactor AmbryReplica into abstract class to allow for cloud and disk\n  backed replicas in HelixClusterManager.\n- Implement listener logic to create a CloudAmbryReplica whenever a new\n  partition is registered in the clustermap. This makes the assumption\n  that any partition that exists in Ambry will be accessible via a cloud\n  store if a cloud datacenter is present.\n\nNote that this PR does not add first-class support for VCR clusters in\nHelixClusterManager. That will come later.", "committedDate": "2020-03-02T23:53:27Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczNDI4MA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r388734280", "bodyText": "CLOUD_BACKED", "author": "lightningrob", "createdAt": "2020-03-06T06:36:45Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudAmbryReplica.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import org.json.JSONObject;\n+\n+import static com.github.ambry.clustermap.ClusterMapSnapshotConstants.*;\n+\n+\n+class CloudAmbryReplica extends AmbryReplica {\n+  /**\n+   * Instantiate an AmbryReplica instance for a virtual cloud replica. This does no\n+   * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n+   * @param partition the {@link AmbryPartition} of which this is a replica.\n+   * @param capacityBytes the capacity in bytes for this replica.\n+   */\n+  CloudAmbryReplica(ClusterMapConfig clusterMapConfig, AmbryPartition partition, long capacityBytes) throws Exception {\n+    super(clusterMapConfig, partition, false, capacityBytes, false);\n+  }\n+\n+  @Override\n+  public AmbryDisk getDiskId() {\n+    throw new UnsupportedOperationException(\"No disk for cloud replica\");\n+  }\n+\n+  @Override\n+  public AmbryDataNode getDataNodeId() {\n+    // TODO figure out callers, if too many change this behavior\n+    throw new UnsupportedOperationException(\"No datanode for cloud replica\");\n+  }\n+\n+  @Override\n+  public String getMountPath() {\n+    throw new UnsupportedOperationException(\"No mount path for cloud replica\");\n+  }\n+\n+  @Override\n+  public String getReplicaPath() {\n+    throw new UnsupportedOperationException(\"No replica path for cloud replica\");\n+  }\n+\n+  @Override\n+  public ReplicaType getReplicaType() {\n+    return ReplicaType.DISK_BACKED;", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczNDYxOQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r388734619", "bodyText": "Should these also throw UnsupportedOperationException?", "author": "lightningrob", "createdAt": "2020-03-06T06:38:22Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudAmbryReplica.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import org.json.JSONObject;\n+\n+import static com.github.ambry.clustermap.ClusterMapSnapshotConstants.*;\n+\n+\n+class CloudAmbryReplica extends AmbryReplica {\n+  /**\n+   * Instantiate an AmbryReplica instance for a virtual cloud replica. This does no\n+   * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n+   * @param partition the {@link AmbryPartition} of which this is a replica.\n+   * @param capacityBytes the capacity in bytes for this replica.\n+   */\n+  CloudAmbryReplica(ClusterMapConfig clusterMapConfig, AmbryPartition partition, long capacityBytes) throws Exception {\n+    super(clusterMapConfig, partition, false, capacityBytes, false);\n+  }\n+\n+  @Override\n+  public AmbryDisk getDiskId() {\n+    throw new UnsupportedOperationException(\"No disk for cloud replica\");\n+  }\n+\n+  @Override\n+  public AmbryDataNode getDataNodeId() {\n+    // TODO figure out callers, if too many change this behavior\n+    throw new UnsupportedOperationException(\"No datanode for cloud replica\");\n+  }\n+\n+  @Override\n+  public String getMountPath() {\n+    throw new UnsupportedOperationException(\"No mount path for cloud replica\");\n+  }\n+\n+  @Override\n+  public String getReplicaPath() {\n+    throw new UnsupportedOperationException(\"No replica path for cloud replica\");\n+  }\n+\n+  @Override\n+  public ReplicaType getReplicaType() {\n+    return ReplicaType.DISK_BACKED;\n+  }\n+\n+  @Override\n+  public JSONObject getSnapshot() {\n+    JSONObject snapshot = new JSONObject();\n+    snapshot.put(REPLICA_PARTITION, getPartitionId().toPathString());\n+    snapshot.put(REPLICA_TYPE, getReplicaType());\n+    snapshot.put(CAPACITY_BYTES, getCapacityInBytes());\n+    snapshot.put(REPLICA_WRITE_STATE, isSealed() ? PartitionState.READ_ONLY.name() : PartitionState.READ_WRITE.name());\n+    String replicaLiveness = UP;\n+    if (isStopped) {\n+      replicaLiveness = REPLICA_STOPPED;\n+    } else if (resourceStatePolicy.isHardDown()) {\n+      replicaLiveness = DOWN;\n+    } else if (resourceStatePolicy.isDown()) {\n+      replicaLiveness = SOFT_DOWN;\n+    }\n+    snapshot.put(LIVENESS, replicaLiveness);\n+    return snapshot;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"Replica[cloud:\" + getPartitionId().toPathString() + \"]\";\n+  }\n+\n+  @Override\n+  public void markDiskDown() {\n+  }\n+\n+  @Override\n+  public void markDiskUp() {", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjczMTI2OA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392731268", "bodyText": "Changed it to throw UnsupportedOperationException. Before I was unsure since i didn't know how many callers it had, but all of them are specific to AmbryServer/BlobStore, so its ok to do so.", "author": "cgtz", "createdAt": "2020-03-16T00:22:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczNDYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczNjc3OQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r388736779", "bodyText": "Reason for this?", "author": "lightningrob", "createdAt": "2020-03-06T06:46:54Z", "path": "ambry-utils/src/main/java/com.github.ambry.utils/Utils.java", "diffHunk": "@@ -310,7 +310,7 @@ public static ByteBuf readNettyByteBufFromCrcInputStream(CrcInputStream crcStrea\n    * @param <T> The exception to throw in this operation.\n    */\n   @FunctionalInterface\n-  public static interface ByteBufferFunction<T extends Throwable> {\n+  public interface ByteBufferFunction<T extends Throwable> {", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIyNjQzNA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r391226434", "bodyText": "It was a suggested change from intellij. The static is redundant since inner interfaces are inherently static (no outer class instance variables can be accessed)", "author": "cgtz", "createdAt": "2020-03-11T19:56:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczNjc3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczODU2MQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r388738561", "bodyText": "I'm confused - how was this working before?", "author": "lightningrob", "createdAt": "2020-03-06T06:53:44Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterSpectator.java", "diffHunk": "@@ -63,15 +63,17 @@ public void spectate() throws Exception {\n     // zk connection fails on both data centers, then things like replication between data centers might just stop.\n     // For now, since we have only one fabric in cloud, and the spectator is being used for only cloud to store replication, this will work.\n     // Once we add more fabrics, we should revisit this.\n-    for (Map.Entry<String, DcZkInfo> entry : dataCenterToZkAddress.entrySet()) {\n-      String zkConnectStr = entry.getValue().getZkConnectStr();\n-      HelixManager helixManager =\n-          helixFactory.getZKHelixManager(cloudConfig.vcrClusterName, selfInstanceName, InstanceType.SPECTATOR,\n-              zkConnectStr);\n-      helixManager.connect();\n+    for (DcZkInfo dcZkInfo: dataCenterToZkAddress.values()) {\n+      // only handle vcr clusters for now\n+      if (dcZkInfo.getReplicaType() == ReplicaType.CLOUD_BACKED) {", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIzMjc0Nw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r391232747", "bodyText": "I think it worked based on the assumption that the dczkinfo config would be set to only include the VCR cluster and no native clusters, which is fine for recovery, but not live replication.", "author": "cgtz", "createdAt": "2020-03-11T20:03:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczODU2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA4NTI3NA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394085274", "bodyText": "According to codecov this code is never tested (though presumably does run).", "author": "lightningrob", "createdAt": "2020-03-18T03:18:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczODU2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczOTA4NA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r388739084", "bodyText": "Minor: since you're refactoring, is it possible to separate this out to its own class file?  This one is very long.", "author": "lightningrob", "createdAt": "2020-03-06T06:55:42Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -870,4 +802,132 @@ long getAllocatedUsableCapacity() {\n       return clusterWideAllocatedUsableCapacityBytes.get();\n     }\n   }\n+\n+  private class DatacenterInitializer implements Runnable {", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjczMTM5MQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392731391", "bodyText": "Moved it out into its own class. Unfortunately, I had to pass a lot of variables in to make it work, but this can probably be refactored a bit further in the future when SimpleClusterChangeHandler is removed", "author": "cgtz", "createdAt": "2020-03-16T00:23:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczOTA4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODczOTQ0OA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r388739448", "bodyText": "private class shouldn't need public constructor", "author": "lightningrob", "createdAt": "2020-03-06T06:56:55Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -870,4 +802,132 @@ long getAllocatedUsableCapacity() {\n       return clusterWideAllocatedUsableCapacityBytes.get();\n     }\n   }\n+\n+  private class DatacenterInitializer implements Runnable {\n+    private final String dcName;\n+    private final ClusterMapConfig clusterMapConfig;\n+    private final HelixManager localManager;\n+    private final HelixFactory helixFactory;\n+    private final DcZkInfo dcZkInfo;\n+    private final CountDownLatch initializationAttemptComplete;\n+\n+    public DatacenterInitializer(String dcName, ClusterMapConfig clusterMapConfig, HelixManager localManager,", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODc0MTQ1NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r388741455", "bodyText": "Minor: add javadoc that it returns null in this case.", "author": "lightningrob", "createdAt": "2020-03-06T07:04:32Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -254,8 +179,11 @@ private HelixManager initializeHelixManagerAndPropertyStoreInLocalDC(Map<String,\n       String instanceName, HelixFactory helixFactory) throws Exception {\n     DcZkInfo dcZkInfo = dataCenterToZkAddress.get(clusterMapConfig.clusterMapDatacenterName);\n     String zkConnectStr = dcZkInfo.getZkConnectStr();\n-    HelixManager manager;\n-    manager = helixFactory.getZKHelixManager(clusterName, instanceName, InstanceType.SPECTATOR, zkConnectStr);\n+    if (dcZkInfo.getReplicaType() == ReplicaType.CLOUD_BACKED) {\n+      return null;", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODc0MzMwOQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r388743309", "bodyText": "Minor: suggest CloudClusterMapChangeListener.", "author": "lightningrob", "createdAt": "2020-03-06T07:11:28Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudChangeListener.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.clustermap.HelixClusterManager.ClusterChangeHandlerCallback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Currently, this just adds a single {@link ReplicaType#CLOUD_BACKED} replica every time a partition is added to allow\n+ * for requests to be routed to cloud services. Currently it is only registered as a {@link ClusterMapChangeListener},\n+ * but once the clustermap natively supports VCR clusters, this class can implement {@link ClusterChangeHandler} and\n+ * listen for changes in the VCR cluster.\n+ */\n+class CloudChangeListener implements ClusterMapChangeListener {", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjczMjE2OQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392732169", "bodyText": "Changed it to CloudServiceClusterChangeHandler, since it now implements that interface as well.", "author": "cgtz", "createdAt": "2020-03-16T00:31:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODc0MzMwOQ=="}], "type": "inlineReview"}, {"oid": "954d08744cbe3ec37e403ebe14c1309cba5db009", "url": "https://github.com/linkedin/ambry/commit/954d08744cbe3ec37e403ebe14c1309cba5db009", "message": "Add basic support for cloud replicas in clustermap\n\n- Add a representation of a cloud datacenter to configs\n- Refactor AmbryReplica into abstract class to allow for cloud and disk\n  backed replicas in HelixClusterManager.\n- Implement listener logic to create a CloudAmbryReplica whenever a new\n  partition is registered in the clustermap. This makes the assumption\n  that any partition that exists in Ambry will be accessible via a cloud\n  store if a cloud datacenter is present.\n\nNote that this PR does not add first-class support for VCR clusters in\nHelixClusterManager. That will come later.", "committedDate": "2020-03-14T13:21:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1Njg3MA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392556870", "bodyText": "Can we use a special zkConnectStr rather than replicaType here for cloud dc?", "author": "jsjtzyy", "createdAt": "2020-03-14T04:51:05Z", "path": "ambry-api/src/main/java/com.github.ambry/config/ClusterMapConfig.java", "diffHunk": "@@ -111,10 +111,15 @@\n    *       \"datacenter\":\"dc2\",\n    *       \"id\" : \"2\",\n    *       \"zkConnectStr\":\"def.example.com:2300\",\n+   *     },\n+   *     {\n+   *       \"datacenter\":\"cloud-dc\",\n+   *       \"id\" : \"3\",\n+   *       \"replicaType\": \"CLOUD_BACKED\"", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjcwMjA0Mg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392702042", "bodyText": "Here I wanted to leave the option open to have HelixClusterManager connect to VCRs in the future, where the replicaType will be CLOUD_BACKED and the zookeeper connect string will be set.", "author": "cgtz", "createdAt": "2020-03-15T19:00:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1Njg3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3NTkyOA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395375928", "bodyText": "Got it. Two minor questions: 1. for VCR, how zookeeper connect string is set? Will it be added into this json eventually?  2. To be consistent, can we introduce replicaType for regular dc's zk connection string entry?", "author": "jsjtzyy", "createdAt": "2020-03-19T23:32:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1Njg3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1Njk0NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392556945", "bodyText": "minor: format this file please", "author": "jsjtzyy", "createdAt": "2020-03-14T04:52:45Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryReplica.java", "diffHunk": "@@ -18,6 +18,7 @@\n import java.io.File;\n import java.util.ArrayList;\n import java.util.List;\n+import java.util.Objects;", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1Njk4NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392556985", "bodyText": "minor: format this file please", "author": "jsjtzyy", "createdAt": "2020-03-14T04:53:36Z", "path": "ambry-api/src/main/java/com.github.ambry/router/CryptoService.java", "diffHunk": "@@ -49,9 +49,7 @@\n    * @throws {@link GeneralSecurityException} on any exception with encryption\n    */\n   default ByteBuf encrypt(ByteBuf toEncrypt, T key) throws GeneralSecurityException {\n-    return Utils.applyByteBufferFunctionToByteBuf(toEncrypt, (buffer) -> {\n-      return encrypt(buffer, key);\n-    });\n+    return Utils.applyByteBufferFunctionToByteBuf(toEncrypt, buffer -> encrypt(buffer, key));", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNTQ2NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392625465", "bodyText": "minor: complete the java doc please.", "author": "jsjtzyy", "createdAt": "2020-03-14T22:49:00Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudAmbryReplica.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import org.json.JSONObject;\n+\n+import static com.github.ambry.clustermap.ClusterMapSnapshotConstants.*;\n+\n+\n+class CloudAmbryReplica extends AmbryReplica {\n+  /**\n+   * Instantiate an AmbryReplica instance for a virtual cloud replica. This does no", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNTUzNg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392625536", "bodyText": "Could you add java doc for this class? Basically, make it easier to distinguish this from CloudReplica", "author": "jsjtzyy", "createdAt": "2020-03-14T22:50:30Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudAmbryReplica.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import org.json.JSONObject;\n+\n+import static com.github.ambry.clustermap.ClusterMapSnapshotConstants.*;\n+\n+\n+class CloudAmbryReplica extends AmbryReplica {", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjcwMjIwNQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392702205", "bodyText": "I changed the name to hopefully be more descriptive of the difference too.", "author": "cgtz", "createdAt": "2020-03-15T19:01:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNTUzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNTg3NA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392625874", "bodyText": "The ReplicaType in this comment is different from that in CloudAmbryReplica, is this intended?", "author": "jsjtzyy", "createdAt": "2020-03-14T22:55:54Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudChangeListener.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.clustermap.HelixClusterManager.ClusterChangeHandlerCallback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Currently, this just adds a single {@link ReplicaType#CLOUD_BACKED} replica every time a partition is added to allow", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjcwMjIyOA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392702228", "bodyText": "No, will fix.", "author": "cgtz", "createdAt": "2020-03-15T19:02:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNTg3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNjIxMg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392626212", "bodyText": "I think INFO level would be better here.", "author": "jsjtzyy", "createdAt": "2020-03-14T23:02:40Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudChangeListener.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.clustermap.HelixClusterManager.ClusterChangeHandlerCallback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Currently, this just adds a single {@link ReplicaType#CLOUD_BACKED} replica every time a partition is added to allow\n+ * for requests to be routed to cloud services. Currently it is only registered as a {@link ClusterMapChangeListener},\n+ * but once the clustermap natively supports VCR clusters, this class can implement {@link ClusterChangeHandler} and\n+ * listen for changes in the VCR cluster.\n+ */\n+class CloudChangeListener implements ClusterMapChangeListener {\n+  private static final Logger logger = LoggerFactory.getLogger(CloudChangeListener.class);\n+  private final Set<String> knownPartitions = ConcurrentHashMap.newKeySet();\n+  private final String dcName;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final ClusterChangeHandlerCallback changeHandlerCallback;\n+\n+  public CloudChangeListener(String dcName, ClusterMapConfig clusterMapConfig,\n+      ClusterChangeHandlerCallback changeHandlerCallback) {\n+    this.dcName = dcName;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.changeHandlerCallback = changeHandlerCallback;\n+  }\n+\n+  @Override\n+  public void onReplicaAddedOrRemoved(Collection<? extends ReplicaId> addedReplicas,\n+      Collection<? extends ReplicaId> removedReplicas) {\n+    // This impl assumes that no partition will ever be completely removed.\n+    for (ReplicaId replica : addedReplicas) {\n+      AmbryPartition partition = (AmbryPartition) replica.getPartitionId();\n+      String partitionName = replica.getPartitionId().toPathString();\n+      if (knownPartitions.add(partitionName)) {\n+        try {\n+          logger.debug(\"Adding cloud replica: dc={}, partition={}\", dcName, partitionName);", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjczMTU0Nw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392731547", "bodyText": "Setting it to info would log for every partition in the cluster on startup. Is that okay, or does it seem too noisy?", "author": "cgtz", "createdAt": "2020-03-16T00:25:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNjIxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNzY0MA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392627640", "bodyText": "After rebasing master branch, we should be able to remove this. In #1405, clustermap change listeners are called within DynamicClusterChangeHandler. If you have additional concern, we can talk offline.", "author": "jsjtzyy", "createdAt": "2020-03-14T23:31:10Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -663,6 +592,9 @@ void addReplicasToPartition(AmbryPartition partition, List<AmbryReplica> replica\n         return v;\n       });\n       clusterWideAllocatedRawCapacityBytes.getAndAdd(replicas.get(0).getCapacityInBytes() * replicas.size());\n+      for (ClusterMapChangeListener listener : clusterMapChangeListeners) {\n+        listener.onReplicaAddedOrRemoved(replicas, Collections.emptyList());", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY4Mjg3OQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392682879", "bodyText": "One concern now is that we can't add a listener from the background startup thread since the DcInfo object for other datacenters may not be present yet. Here I can either add the listener after all of the startup threads are joined, or make a new type of listener that is notified on new partitions added.", "author": "cgtz", "createdAt": "2020-03-15T15:11:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNzY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjczMTY0NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392731645", "bodyText": "I chose to connect the listeners after the other startup threads are finished.", "author": "cgtz", "createdAt": "2020-03-16T00:26:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyNzY0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyODA0OQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392628049", "bodyText": "After adding CloudAmbryReplica to AmbryPartition, when getReplicaIdsForPartition is called, is there any check on if the replica is DiskAmbryReplica or CloudAmbryReplica ?", "author": "jsjtzyy", "createdAt": "2020-03-14T23:38:55Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudChangeListener.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.clustermap.HelixClusterManager.ClusterChangeHandlerCallback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Currently, this just adds a single {@link ReplicaType#CLOUD_BACKED} replica every time a partition is added to allow\n+ * for requests to be routed to cloud services. Currently it is only registered as a {@link ClusterMapChangeListener},\n+ * but once the clustermap natively supports VCR clusters, this class can implement {@link ClusterChangeHandler} and\n+ * listen for changes in the VCR cluster.\n+ */\n+class CloudChangeListener implements ClusterMapChangeListener {\n+  private static final Logger logger = LoggerFactory.getLogger(CloudChangeListener.class);\n+  private final Set<String> knownPartitions = ConcurrentHashMap.newKeySet();\n+  private final String dcName;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final ClusterChangeHandlerCallback changeHandlerCallback;\n+\n+  public CloudChangeListener(String dcName, ClusterMapConfig clusterMapConfig,\n+      ClusterChangeHandlerCallback changeHandlerCallback) {\n+    this.dcName = dcName;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.changeHandlerCallback = changeHandlerCallback;\n+  }\n+\n+  @Override\n+  public void onReplicaAddedOrRemoved(Collection<? extends ReplicaId> addedReplicas,\n+      Collection<? extends ReplicaId> removedReplicas) {\n+    // This impl assumes that no partition will ever be completely removed.\n+    for (ReplicaId replica : addedReplicas) {\n+      AmbryPartition partition = (AmbryPartition) replica.getPartitionId();\n+      String partitionName = replica.getPartitionId().toPathString();\n+      if (knownPartitions.add(partitionName)) {\n+        try {\n+          logger.debug(\"Adding cloud replica: dc={}, partition={}\", dcName, partitionName);\n+          // Copy the capacity from an existing replica\n+          AmbryReplica cloudAmbryReplica =\n+              new CloudAmbryReplica(clusterMapConfig, partition, replica.getCapacityInBytes());\n+          changeHandlerCallback.addReplicasToPartition(partition, Collections.singletonList(cloudAmbryReplica));", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjczMjAyNg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392732026", "bodyText": "There are no such checks right now. Do you know of any places where including cloud replicas in the list of partitions will break something in the frontend? This feature should not be used for the server (until VCR support is integrated)", "author": "cgtz", "createdAt": "2020-03-16T00:30:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyODA0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyODUxMA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392628510", "bodyText": "I don't quite understand this part. Will talk with you offline.", "author": "jsjtzyy", "createdAt": "2020-03-14T23:48:20Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -870,4 +802,132 @@ long getAllocatedUsableCapacity() {\n       return clusterWideAllocatedUsableCapacityBytes.get();\n     }\n   }\n+\n+  private class DatacenterInitializer implements Runnable {\n+    private final String dcName;\n+    private final ClusterMapConfig clusterMapConfig;\n+    private final HelixManager localManager;\n+    private final HelixFactory helixFactory;\n+    private final DcZkInfo dcZkInfo;\n+    private final CountDownLatch initializationAttemptComplete;\n+\n+    public DatacenterInitializer(String dcName, ClusterMapConfig clusterMapConfig, HelixManager localManager,\n+        HelixFactory helixFactory, DcZkInfo dcZkInfo, CountDownLatch initializationAttemptComplete) {\n+      this.dcName = dcName;\n+      this.clusterMapConfig = clusterMapConfig;\n+      this.localManager = localManager;\n+      this.helixFactory = helixFactory;\n+      this.dcZkInfo = dcZkInfo;\n+      this.initializationAttemptComplete = initializationAttemptComplete;\n+    }\n+\n+    @Override\n+    public void run() {\n+      try {\n+        switch (dcZkInfo.getReplicaType()) {\n+          case DISK_BACKED:\n+            initializeHelixDatacenter();\n+            break;\n+          case CLOUD_BACKED:\n+            initializeCloudDatacenter();\n+            break;\n+          default:\n+            throw new UnsupportedOperationException(\"Unknown replica type: \" + dcZkInfo.getReplicaType());\n+        }\n+      } catch (Exception e) {\n+        initializationFailureMap.putIfAbsent(dcName, e);\n+      } finally {\n+        initializationAttemptComplete.countDown();\n+      }\n+    }\n+\n+    private void initializeHelixDatacenter() throws Exception {\n+      String zkConnectStr = dcZkInfo.getZkConnectStr();\n+      HelixManager manager;\n+      if (dcName.equals(clusterMapConfig.clusterMapDatacenterName)) {\n+        manager = Objects.requireNonNull(localManager, \"localManager should have been set\");\n+      } else {\n+        manager = helixFactory.getZKHelixManager(clusterName, selfInstanceName, InstanceType.SPECTATOR, zkConnectStr);\n+        logger.info(\"Connecting to Helix manager at {}\", zkConnectStr);\n+        manager.connect();\n+        logger.info(\"Established connection to Helix manager at {}\", zkConnectStr);\n+      }\n+      ClusterChangeHandler clusterChangeHandler;\n+      String clusterChangeHandlerType = clusterMapConfig.clusterMapClusterChangeHandlerType;\n+      if (clusterChangeHandlerType.equals(SimpleClusterChangeHandler.class.getSimpleName())) {\n+        clusterChangeHandler =\n+            new SimpleClusterChangeHandler(clusterMapConfig, dcName, selfInstanceName, partitionOverrideInfoMap,\n+                partitionMap, partitionNameToAmbryPartition, ambryPartitionToAmbryReplicas, helixClusterManagerCallback,\n+                helixClusterManagerMetrics, initializationFailureMap, sealedStateChangeCounter);\n+      } else if (clusterChangeHandlerType.equals(DynamicClusterChangeHandler.class.getSimpleName())) {\n+        clusterChangeHandler =\n+            new DynamicClusterChangeHandler(clusterMapConfig, dcName, selfInstanceName, partitionOverrideInfoMap,\n+                helixClusterManagerCallback, clusterChangeHandlerCallback, helixClusterManagerMetrics,\n+                initializationFailureMap, sealedStateChangeCounter);\n+      } else {\n+        throw new IllegalArgumentException(\"Unsupported cluster change handler type: \" + clusterChangeHandlerType);\n+      }\n+      // Create RoutingTableProvider of each DC to keep track of partition(replicas) state. Here, we use current\n+      // state based RoutingTableProvider to remove dependency on Helix's pipeline and reduce notification latency.\n+      logger.info(\"Creating routing table provider associated with Helix manager at {}\", zkConnectStr);\n+      RoutingTableProvider routingTableProvider = new RoutingTableProvider(manager, PropertyType.CURRENTSTATES);\n+      logger.info(\"Routing table provider is created in {}\", dcName);\n+      DcInfo dcInfo = new DcInfo(dcName, dcZkInfo, manager, clusterChangeHandler);\n+      dcToDcInfo.put(dcName, dcInfo);\n+      dcIdToDcName.put(dcInfo.dcZkInfo.getDcId(), dcName);\n+      routingTableProvider.addRoutingTableChangeListener(clusterChangeHandler, null);\n+      logger.info(\"Registered routing table change listeners in {}\", dcName);\n+\n+      // The initial instance config change notification is required to populate the static cluster\n+      // information, and only after that is complete do we want the live instance change notification to\n+      // come in. We do not need to do anything extra to ensure this, however, since Helix provides the initial\n+      // notification for a change from within the same thread that adds the listener, in the context of the add\n+      // call. Therefore, when the call to add a listener returns, the initial notification will have been\n+      // received and handled.\n+      manager.addInstanceConfigChangeListener(clusterChangeHandler);\n+      logger.info(\"Registered instance config change listeners for Helix manager at {}\", zkConnectStr);\n+      manager.addIdealStateChangeListener(clusterChangeHandler);\n+      logger.info(\"Registered ideal state change listeners for Helix manager at {}\", zkConnectStr);\n+      // Now register listeners to get notified on live instance change in every datacenter.\n+      manager.addLiveInstanceChangeListener(clusterChangeHandler);\n+      logger.info(\"Registered live instance change listeners for Helix manager at {}\", zkConnectStr);\n+\n+      // in case initial event occurs before adding routing table listener, here we explicitly set snapshot in\n+      // ClusterChangeHandler. The reason is, if listener missed initial event, snapshot inside routing table\n+      // provider should be already populated.\n+      clusterChangeHandler.setRoutingTableSnapshot(routingTableProvider.getRoutingTableSnapshot());\n+      // the initial routing table change should populate the instanceConfigs. If it's empty that means initial\n+      // change didn't come and thread should wait on the init latch to ensure routing table snapshot is non-empty\n+      if (clusterChangeHandler.getRoutingTableSnapshot().getInstanceConfigs().isEmpty()) {\n+        // Periodic refresh in routing table provider is enabled by default. In worst case, routerUpdater should\n+        // trigger routing table change within 5 minutes\n+        logger.info(\"Routing table snapshot in {} is currently empty. Waiting for initial notification.\", dcName);\n+        clusterChangeHandler.waitForInitNotification();\n+      }\n+\n+      if (!clusterMapConfig.clustermapListenCrossColo && manager != localManager) {\n+        manager.disconnect();\n+        logger.info(\"Stopped listening to cross colo ZK server {}\", zkConnectStr);\n+      }\n+    }\n+\n+    /**\n+     * Currently, this does not connect to the VCR zookeeper and assumes that all partitions are supported in the cloud\n+     * datacenter. This will be the case until the VCR and native storage clusters are unified under the same\n+     * {@link ClusterMap}. Once this happens, we can use the VCR cluster as a source of truth for supported partitions\n+     * in the cloud datacenter.\n+     */\n+    private void initializeCloudDatacenter() {\n+      DcInfo dcInfo = new DcInfo(dcName, dcZkInfo, null, null);\n+      dcToDcInfo.put(dcName, dcInfo);\n+      dcIdToDcName.put(dcZkInfo.getDcId(), dcName);\n+      CloudChangeListener listener =\n+          new CloudChangeListener(dcName, clusterMapConfig, clusterChangeHandlerCallback);\n+      registerClusterMapListener(listener);\n+      // seed existing replicas.\n+      for (Set<AmbryReplica> replicas : ambryPartitionToAmbryReplicas.values()) {", "originalCommit": "b33737ebd4b8470ab04c4630a0e1c84b9aa391eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY4MTY4NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r392681685", "bodyText": "This logic will have to change a bit since I am rebasing on your changes to listening. However, the main goal is to add any ambry partitions that already exist.\nI am roughly trying to accomplish what ReplicationManager does where it first adds the listener, and then iterates through all existing replicas right afterwards so that it knows about all replicas added before the listener was added.\nI may just make a new listener for just newly added partitions for this use case since I envision it would be somewhat temporary, as eventually ClusterMap will get the set of managed partitions from the VCR.", "author": "cgtz", "createdAt": "2020-03-15T14:56:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyODUxMA=="}], "type": "inlineReview"}, {"oid": "a45a78e5198c0614eabe221398366e60b11a61a8", "url": "https://github.com/linkedin/ambry/commit/a45a78e5198c0614eabe221398366e60b11a61a8", "message": "Address comments, make fixes, and add unit tests\n\n- Changed some names to make purpose of special Datanodes and Replicas\n  clearer\n- Implemented ClusterChangeHandler for cloud services, which helps it\n  fit better into the methods in HelixClusterManager.\n- Refactored initialization logic into a separate class.\n- Added unit test", "committedDate": "2020-03-16T00:12:21Z", "type": "commit"}, {"oid": "a45a78e5198c0614eabe221398366e60b11a61a8", "url": "https://github.com/linkedin/ambry/commit/a45a78e5198c0614eabe221398366e60b11a61a8", "message": "Address comments, make fixes, and add unit tests\n\n- Changed some names to make purpose of special Datanodes and Replicas\n  clearer\n- Implemented ClusterChangeHandler for cloud services, which helps it\n  fit better into the methods in HelixClusterManager.\n- Refactored initialization logic into a separate class.\n- Added unit test", "committedDate": "2020-03-16T00:12:21Z", "type": "forcePushed"}, {"oid": "b6bd0183fe95dbe81384a42cbc16238064e3245e", "url": "https://github.com/linkedin/ambry/commit/b6bd0183fe95dbe81384a42cbc16238064e3245e", "message": "Fix one more comment", "committedDate": "2020-03-16T00:32:07Z", "type": "commit"}, {"oid": "041238f84036f88399df2cee904d21f5446f7264", "url": "https://github.com/linkedin/ambry/commit/041238f84036f88399df2cee904d21f5446f7264", "message": "Add cloud dc tests to HelixClusterManagerTest", "committedDate": "2020-03-16T03:56:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3MTU0OQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394071549", "bodyText": "I'm a little unclear on why this method would be in an interface called ClusterChangeHandler.", "author": "lightningrob", "createdAt": "2020-03-18T02:20:53Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/ClusterChangeHandler.java", "diffHunk": "@@ -10,42 +10,36 @@\n  * Unless required by applicable law or agreed to in writing, software\n  * distributed under the License is distributed on an \"AS IS\" BASIS,\n  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n  */\n+\n package com.github.ambry.clustermap;\n \n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import org.apache.helix.api.listeners.IdealStateChangeListener;\n-import org.apache.helix.api.listeners.InstanceConfigChangeListener;\n-import org.apache.helix.api.listeners.LiveInstanceChangeListener;\n-import org.apache.helix.api.listeners.RoutingTableChangeListener;\n-import org.apache.helix.spectator.RoutingTableSnapshot;\n+import java.util.stream.Stream;\n \n \n /**\n  * General handler that handles any resource or state changes in cluster. It exposes API(s) for cluster manager to\n- * access up-to-date cluster info. Each data center has its own {@link ClusterChangeHandler}.\n+ * access up-to-date cluster info for a data center. Each data center has its own\n+ * {@link ClusterChangeHandler}.\n  */\n-interface ClusterChangeHandler\n-    extends InstanceConfigChangeListener, LiveInstanceChangeListener, IdealStateChangeListener,\n-            RoutingTableChangeListener {\n+public interface ClusterChangeHandler {\n   /**\n    * Register a listener of cluster map for any changes.\n    * @param clusterMapChangeListener the {@link ClusterMapChangeListener} to add.\n    */\n   void registerClusterMapListener(ClusterMapChangeListener clusterMapChangeListener);\n \n   /**\n-   * Set the initial snapshot in this {@link ClusterChangeHandler}.\n-   * @param routingTableSnapshot the snapshot to set\n-   */\n-  void setRoutingTableSnapshot(RoutingTableSnapshot routingTableSnapshot);\n-\n-  /**\n-   * @return current snapshot held by this {@link ClusterChangeHandler}.\n+   * Get replicas of given partition from this datacenter that are in required state\n+   * @param partition the {@link PartitionId} for which to get the list of replicas.\n+   * @param state {@link ReplicaState} associated with replica\n+   * @return the {@link ReplicaId}s satisfying requirements.\n    */\n-  RoutingTableSnapshot getRoutingTableSnapshot();\n+  Stream<AmbryReplica> getReplicaIdsByState(AmbryPartition partition, ReplicaState state);", "originalCommit": "a45a78e5198c0614eabe221398366e60b11a61a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYzMTE1Ng==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394631156", "bodyText": "Incidentally, most of the methods in ClusterChangeHandler are about getting a view of the datanodes, and replicas in that datacenter. This was the case before this change. I added this method to make the interface more general to things that do not have a helix RoutingTableProvider.\nPerhaps a better name would be DatacenterView for this interface, but I would probably prefer changing the name in a separate PR since this one is already big.", "author": "cgtz", "createdAt": "2020-03-18T20:50:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3MTU0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3MjM0NA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394072344", "bodyText": "I'd prefer if we put miscellaneous cleanup items in their own separate reviews, but okay this time.", "author": "lightningrob", "createdAt": "2020-03-18T02:23:51Z", "path": "ambry-api/src/main/java/com.github.ambry/router/CryptoService.java", "diffHunk": "@@ -15,8 +15,6 @@\n \n import com.github.ambry.utils.Utils;\n import io.netty.buffer.ByteBuf;\n-import io.netty.buffer.ByteBufAllocator;\n-import io.netty.buffer.Unpooled;", "originalCommit": "a45a78e5198c0614eabe221398366e60b11a61a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYzMTkyOA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394631928", "bodyText": "Will do in the future. I'm not sure why I even did this cleanup on this branch.", "author": "cgtz", "createdAt": "2020-03-18T20:51:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3MjM0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3MjUyMA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394072520", "bodyText": "if only subclasses need them, shouldn't they be protected?", "author": "lightningrob", "createdAt": "2020-03-18T02:24:42Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryDatanode.java", "diffHunk": "@@ -30,53 +26,35 @@\n /**\n  * {@link DataNodeId} implementation to use within dynamic cluster managers.\n  */\n-class AmbryDataNode implements DataNodeId {\n+abstract class AmbryDataNode implements DataNodeId {\n   private final String hostName;\n-  private final Port plainTextPort;\n-  private final Port sslPort;\n-  private final Port http2Port;\n+  // exposed for subclass access", "originalCommit": "a45a78e5198c0614eabe221398366e60b11a61a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYzNDU4NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394634585", "bodyText": "Well, protected provides more access than package private, so I went with the modifier that gave the least access needed (no access needed for extenders outside of the package).\n\n\n\nModifier\nClass\nPackage\nSubclass\nWorld\n\n\n\n\npublic\nY\nY\nY\nY\n\n\nprotected\nY\nY\nY\nN\n\n\nno modifier\nY\nY\nN\nN\n\n\nprivate\nY\nN\nN\nN\n\n\n\nBut I will make them protected, since it probably makes it clearer what the intent is.", "author": "cgtz", "createdAt": "2020-03-18T20:56:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3MjUyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3MzI1OA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394073258", "bodyText": "Can simplify to one line, no?  Or if you're going for readability, you can eliminate the local variable and just do \"return ...\" everywhere.", "author": "lightningrob", "createdAt": "2020-03-18T02:27:48Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryDatanode.java", "diffHunk": "@@ -209,4 +138,17 @@ void onNodeTimeout() {\n   void onNodeResponse() {\n     resourceStatePolicy.onSuccess();\n   }\n+\n+  /**\n+   * @return the status of the node according to its {@link ResourceStatePolicy}\n+   */\n+  String getLiveness() {\n+    String liveness = UP;\n+    if (resourceStatePolicy.isHardDown()) {\n+      liveness = NODE_DOWN;\n+    } else if (resourceStatePolicy.isDown()) {\n+      liveness = SOFT_DOWN;\n+    }\n+    return liveness;", "originalCommit": "a45a78e5198c0614eabe221398366e60b11a61a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NDg1Ng==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394074856", "bodyText": "This is total errors from system startup, as opposed to what a counter metric does?", "author": "lightningrob", "createdAt": "2020-03-18T02:34:49Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudServiceClusterChangeHandler.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.clustermap.HelixClusterManager.ClusterChangeHandlerCallback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.CopyOnWriteArrayList;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Stream;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Currently, this just adds a single {@link ReplicaType#CLOUD_BACKED} replica every time a partition is added to allow\n+ * for requests to be routed to cloud services. Currently it is only registered as a {@link ClusterMapChangeListener},\n+ * but once the clustermap natively supports VCR clusters, this class can implement {@link HelixAwareClusterChangeHandler} and\n+ * listen for changes in the VCR cluster.\n+ */\n+class CloudServiceClusterChangeHandler implements ClusterMapChangeListener, ClusterChangeHandler {\n+  private static final Logger logger = LoggerFactory.getLogger(CloudServiceClusterChangeHandler.class);\n+  private final Set<String> knownPartitions = ConcurrentHashMap.newKeySet();\n+  private final ConcurrentHashMap<String, CloudServiceReplica> partitionToReplica = new ConcurrentHashMap<>();\n+  private final List<ClusterMapChangeListener> listeners = new CopyOnWriteArrayList<>();\n+  private final AtomicLong errorCount = new AtomicLong(0);", "originalCommit": "a45a78e5198c0614eabe221398366e60b11a61a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYzODE4OQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394638189", "bodyText": "Yes, this method is a bit weird to me, but apparently the method isn't used for codahale metrics, but for HelixBootstrapUpgradeTool. Maybe I can get rid of it from the interface in the future.", "author": "cgtz", "createdAt": "2020-03-18T21:03:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NDg1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0Njk3Mw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395446973", "bodyText": "This is used by Validating Cluster Manager in HelixBootstrapTool to verify boostrap/upgrade succeeds.", "author": "jsjtzyy", "createdAt": "2020-03-20T05:41:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NDg1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NTIzOA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394075238", "bodyText": "Comment is a bit confusing since you are only conditionally ignoring it.", "author": "lightningrob", "createdAt": "2020-03-18T02:36:28Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudServiceClusterChangeHandler.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.clustermap.HelixClusterManager.ClusterChangeHandlerCallback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.CopyOnWriteArrayList;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Stream;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Currently, this just adds a single {@link ReplicaType#CLOUD_BACKED} replica every time a partition is added to allow\n+ * for requests to be routed to cloud services. Currently it is only registered as a {@link ClusterMapChangeListener},\n+ * but once the clustermap natively supports VCR clusters, this class can implement {@link HelixAwareClusterChangeHandler} and\n+ * listen for changes in the VCR cluster.\n+ */\n+class CloudServiceClusterChangeHandler implements ClusterMapChangeListener, ClusterChangeHandler {\n+  private static final Logger logger = LoggerFactory.getLogger(CloudServiceClusterChangeHandler.class);\n+  private final Set<String> knownPartitions = ConcurrentHashMap.newKeySet();\n+  private final ConcurrentHashMap<String, CloudServiceReplica> partitionToReplica = new ConcurrentHashMap<>();\n+  private final List<ClusterMapChangeListener> listeners = new CopyOnWriteArrayList<>();\n+  private final AtomicLong errorCount = new AtomicLong(0);\n+  private final String dcName;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final ClusterChangeHandlerCallback changeHandlerCallback;\n+  private final CloudServiceDataNode cloudServiceDataNode;\n+  private final String cloudServiceInstanceName;\n+\n+  public CloudServiceClusterChangeHandler(String dcName, ClusterMapConfig clusterMapConfig,\n+      ClusterChangeHandlerCallback changeHandlerCallback) throws Exception {\n+    this.dcName = dcName;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.changeHandlerCallback = changeHandlerCallback;\n+    cloudServiceDataNode = new CloudServiceDataNode(dcName, clusterMapConfig);\n+    cloudServiceInstanceName =\n+        ClusterMapUtils.getInstanceName(cloudServiceDataNode.getDatacenterName(), cloudServiceDataNode.getPort());\n+  }\n+\n+  @Override\n+  public void onReplicaAddedOrRemoved(List<ReplicaId> addedReplicas, List<ReplicaId> removedReplicas) {\n+    // This impl assumes that no partition will ever be completely removed.\n+    List<ReplicaId> newReplicas = new ArrayList<>();\n+    for (ReplicaId replica : addedReplicas) {\n+      AmbryPartition partition = (AmbryPartition) replica.getPartitionId();\n+      String partitionName = partition.toPathString();\n+      // Only add one replica object for each partition\n+      if (knownPartitions.add(partitionName)) {\n+        try {\n+          logger.debug(\"Adding cloud replica: dc={}, partition={}\", dcName, partitionName);\n+          // Copy the capacity from an existing replica\n+          CloudServiceReplica cloudServiceReplica =\n+              new CloudServiceReplica(clusterMapConfig, cloudServiceDataNode, partition, replica.getCapacityInBytes());\n+          partitionToReplica.put(partitionName, cloudServiceReplica);\n+          changeHandlerCallback.addReplicasToPartition(partition, Collections.singletonList(cloudServiceReplica));\n+          newReplicas.add(cloudServiceReplica);\n+        } catch (Exception e) {\n+          errorCount.getAndIncrement();\n+          logger.error(\"Exception while adding cloud replica: dc={}, partition={}\", dcName, partitionName, e);\n+        }\n+      }\n+    }\n+    listeners.forEach(listener -> listener.onReplicaAddedOrRemoved(newReplicas, Collections.emptyList()));\n+  }\n+\n+  @Override\n+  public void registerClusterMapListener(ClusterMapChangeListener clusterMapChangeListener) {\n+    // Ignoring since this class implements ClusterMapChangeListener", "originalCommit": "a45a78e5198c0614eabe221398366e60b11a61a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NjkwMw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394076903", "bodyText": "DatacenterInitializer", "author": "lightningrob", "createdAt": "2020-03-18T02:43:28Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/DatacenterInitializer.java", "diffHunk": "@@ -0,0 +1,248 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.utils.Utils;\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.InstanceType;\n+import org.apache.helix.PropertyType;\n+import org.apache.helix.spectator.RoutingTableProvider;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * This class represents the startup procedure for a datacenter. Calling the start method will begin the startup\n+ * procedure in a background thread. Calling the {@link #join} method let's the main thread wait for startup of a\n+ * datacenter to either succeed or fail.\n+ */\n+class DatacenterInitializer {\n+  private static final Logger logger = LoggerFactory.getLogger(HelixClusterManager.class);", "originalCommit": "a45a78e5198c0614eabe221398366e60b11a61a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NzI0MA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394077240", "bodyText": "Can these be declared Map?", "author": "lightningrob", "createdAt": "2020-03-18T02:44:52Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/DatacenterInitializer.java", "diffHunk": "@@ -0,0 +1,248 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.utils.Utils;\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n+import org.apache.helix.HelixManager;\n+import org.apache.helix.InstanceType;\n+import org.apache.helix.PropertyType;\n+import org.apache.helix.spectator.RoutingTableProvider;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * This class represents the startup procedure for a datacenter. Calling the start method will begin the startup\n+ * procedure in a background thread. Calling the {@link #join} method let's the main thread wait for startup of a\n+ * datacenter to either succeed or fail.\n+ */\n+class DatacenterInitializer {\n+  private static final Logger logger = LoggerFactory.getLogger(HelixClusterManager.class);\n+  private final CompletableFuture<DcInfo> initializationFuture = new CompletableFuture<>();\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final HelixManager localManager;\n+  private final HelixFactory helixFactory;\n+  private final ClusterMapUtils.DcZkInfo dcZkInfo;\n+  private final String dcName;\n+\n+  // Fields to pass into both ClusterChangeHandlers\n+  private final String selfInstanceName;\n+  private final Map<String, Map<String, String>> partitionOverrideInfoMap;\n+  private final HelixClusterManager.ClusterChangeHandlerCallback clusterChangeHandlerCallback;\n+  private final HelixClusterManager.HelixClusterManagerCallback helixClusterManagerCallback;\n+  private final HelixClusterManagerMetrics helixClusterManagerMetrics;\n+  private final AtomicLong sealedStateChangeCounter;\n+  // Fields to pass into only SimpleClusterChangeHandler (These can be removed if SimpleClusterChangeHandler is removed)\n+  private final ConcurrentHashMap<ByteBuffer, AmbryPartition> partitionMap;\n+  private final ConcurrentHashMap<String, AmbryPartition> partitionNameToAmbryPartition;\n+  private final ConcurrentHashMap<AmbryPartition, Set<AmbryReplica>> ambryPartitionToAmbryReplicas;", "originalCommit": "a45a78e5198c0614eabe221398366e60b11a61a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY0MTI5MA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394641290", "bodyText": "The child class constructors require ConcurrentHashMaps. I believe it was done this way to indicate that the implementations will only work correctly if the instances are ConcurrentHashMap, due to their usage of various CAS-style methods where atomicity is expected. @jsjtzyy may be able to explain more.", "author": "cgtz", "createdAt": "2020-03-18T21:09:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NzI0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgyNDAyMA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395824020", "bodyText": "Yeah, I remember @ankagrawal  suggested using ConcurrentHashMap to explicitly declare these maps will be updated concurrently by multiple threads (one per data center).", "author": "jsjtzyy", "createdAt": "2020-03-20T18:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NzI0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA4MTU1Mw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394081553", "bodyText": "?", "author": "lightningrob", "createdAt": "2020-03-18T03:02:16Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -134,6 +134,7 @@ public HelixClusterManager(ClusterMapConfig clusterMapConfig, String instanceNam\n       }\n \n       for (DcInfo dcInfo : dcToDcInfo.values()) {\n+        System.out.println(\"AKAKAKA\" + dcInfo.clusterChangeHandler);", "originalCommit": "041238f84036f88399df2cee904d21f5446f7264", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA4MjE1Mg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394082152", "bodyText": "newline", "author": "lightningrob", "createdAt": "2020-03-18T03:04:49Z", "path": "ambry-clustermap/src/test/java/com.github.ambry.clustermap/CloudServiceClusterChangeHandlerTest.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+import static org.mockito.Mockito.*;\n+\n+\n+/**\n+ * Test {@link CloudServiceClusterChangeHandler}.\n+ */\n+public class CloudServiceClusterChangeHandlerTest {\n+  private final long replicaCapacity = 27 * 1024 * 1024 * 1024L;\n+  private final ClusterMapConfig config = TestUtils.getDummyConfig();\n+\n+  @Test\n+  public void testHandler() throws Exception {\n+    HelixClusterManager.ClusterChangeHandlerCallback clusterChangeHandlerCallback =\n+        mock(HelixClusterManager.ClusterChangeHandlerCallback.class);\n+    CloudServiceClusterChangeHandler handler =\n+        new CloudServiceClusterChangeHandler(\"dc1\", TestUtils.getDummyConfig(), clusterChangeHandlerCallback);\n+\n+    CloudServiceDataNode cloudServiceDataNode =\n+        (CloudServiceDataNode) handler.getDataNode(ClusterMapUtils.getInstanceName(\"dc1\", -1));\n+    assertEquals(\"Only CloudServiceDataNode should be present\", Collections.singletonList(cloudServiceDataNode),\n+        handler.getAllDataNodes());\n+\n+    AmbryPartition p1 = new AmbryPartition(1, \"class\", mock(ClusterManagerCallback.class));\n+    AmbryPartition p2 = new AmbryPartition(2, \"class\", mock(ClusterManagerCallback.class));\n+    AmbryPartition p3 = new AmbryPartition(3, \"class\", mock(ClusterManagerCallback.class));\n+    handler.onReplicaAddedOrRemoved(makeReplicas(p1, p1, p1, p3, p2, p3), makeReplicas(p2));\n+    verify(clusterChangeHandlerCallback).addReplicasToPartition(eq(p1), any());\n+    verify(clusterChangeHandlerCallback).addReplicasToPartition(eq(p2), any());\n+    verify(clusterChangeHandlerCallback).addReplicasToPartition(eq(p3), any());\n+    verify(clusterChangeHandlerCallback, never()).removeReplicasFromPartition(any(), any());\n+    verifyNoMoreInteractions(clusterChangeHandlerCallback);\n+\n+    reset(clusterChangeHandlerCallback);\n+    AmbryPartition p4 = new AmbryPartition(4, \"class\", mock(ClusterManagerCallback.class));\n+    ClusterMapChangeListener listener = mock(ClusterMapChangeListener.class);\n+    handler.registerClusterMapListener(listener);\n+    handler.registerClusterMapListener(handler);\n+    handler.onReplicaAddedOrRemoved(makeReplicas(p2, p4), makeReplicas(p4));\n+    verify(clusterChangeHandlerCallback).addReplicasToPartition(eq(p4), any());\n+    verify(clusterChangeHandlerCallback, never()).removeReplicasFromPartition(any(), any());\n+    verifyNoMoreInteractions(clusterChangeHandlerCallback);\n+    verify(listener).onReplicaAddedOrRemoved(\n+        Collections.singletonList(handler.getReplicaId(cloudServiceDataNode, p4.toPathString())),\n+        Collections.emptyList());\n+\n+    // test basic datacenter view methods\n+    assertEquals(Collections.singletonList(handler.getReplicaId(cloudServiceDataNode, p3.toPathString())),\n+        handler.getReplicaIdsByState(p3, ReplicaState.LEADER).collect(Collectors.toList()));\n+    AmbryPartition p5 = new AmbryPartition(5, \"class\", mock(ClusterManagerCallback.class));\n+    assertEquals(Collections.emptyList(),\n+        handler.getReplicaIdsByState(p5, ReplicaState.LEADER).collect(Collectors.toList()));\n+    assertEquals(Collections.emptyMap(), handler.getDataNodeToDisksMap());\n+    assertEquals(4, handler.getReplicaIds(cloudServiceDataNode).size());\n+    assertEquals(Collections.emptyList(), handler.getReplicaIds(mock(AmbryDataNode.class)));\n+    assertEquals(Collections.emptySet(), handler.getDisks(cloudServiceDataNode));\n+    assertEquals(Collections.emptyMap(), handler.getPartitionToResourceMap());\n+    assertEquals(0, handler.getErrorCount());\n+\n+    // simulate failure\n+    doThrow(new RuntimeException()).when(clusterChangeHandlerCallback).addReplicasToPartition(any(), any());\n+    handler.onReplicaAddedOrRemoved(makeReplicas(p5), makeReplicas());\n+    assertEquals(1, handler.getErrorCount());\n+\n+  }\n+\n+  private List<ReplicaId> makeReplicas(AmbryPartition... partitionIds) throws Exception {\n+    List<ReplicaId> replicaIds = new ArrayList<>(partitionIds.length);\n+    for (AmbryPartition partitionId : partitionIds) {\n+      replicaIds.add(new AmbryServerReplica(config, partitionId, mock(AmbryDisk.class), false, replicaCapacity, false));\n+    }\n+    return replicaIds;\n+  }\n+}", "originalCommit": "041238f84036f88399df2cee904d21f5446f7264", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA4MjcwMw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r394082703", "bodyText": "remove blank line", "author": "lightningrob", "createdAt": "2020-03-18T03:07:13Z", "path": "ambry-clustermap/src/test/java/com.github.ambry.clustermap/CloudServiceClusterChangeHandlerTest.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+import static org.mockito.Mockito.*;\n+\n+\n+/**\n+ * Test {@link CloudServiceClusterChangeHandler}.\n+ */\n+public class CloudServiceClusterChangeHandlerTest {\n+  private final long replicaCapacity = 27 * 1024 * 1024 * 1024L;\n+  private final ClusterMapConfig config = TestUtils.getDummyConfig();\n+\n+  @Test\n+  public void testHandler() throws Exception {\n+    HelixClusterManager.ClusterChangeHandlerCallback clusterChangeHandlerCallback =\n+        mock(HelixClusterManager.ClusterChangeHandlerCallback.class);\n+    CloudServiceClusterChangeHandler handler =\n+        new CloudServiceClusterChangeHandler(\"dc1\", TestUtils.getDummyConfig(), clusterChangeHandlerCallback);\n+\n+    CloudServiceDataNode cloudServiceDataNode =\n+        (CloudServiceDataNode) handler.getDataNode(ClusterMapUtils.getInstanceName(\"dc1\", -1));\n+    assertEquals(\"Only CloudServiceDataNode should be present\", Collections.singletonList(cloudServiceDataNode),\n+        handler.getAllDataNodes());\n+\n+    AmbryPartition p1 = new AmbryPartition(1, \"class\", mock(ClusterManagerCallback.class));\n+    AmbryPartition p2 = new AmbryPartition(2, \"class\", mock(ClusterManagerCallback.class));\n+    AmbryPartition p3 = new AmbryPartition(3, \"class\", mock(ClusterManagerCallback.class));\n+    handler.onReplicaAddedOrRemoved(makeReplicas(p1, p1, p1, p3, p2, p3), makeReplicas(p2));\n+    verify(clusterChangeHandlerCallback).addReplicasToPartition(eq(p1), any());\n+    verify(clusterChangeHandlerCallback).addReplicasToPartition(eq(p2), any());\n+    verify(clusterChangeHandlerCallback).addReplicasToPartition(eq(p3), any());\n+    verify(clusterChangeHandlerCallback, never()).removeReplicasFromPartition(any(), any());\n+    verifyNoMoreInteractions(clusterChangeHandlerCallback);\n+\n+    reset(clusterChangeHandlerCallback);\n+    AmbryPartition p4 = new AmbryPartition(4, \"class\", mock(ClusterManagerCallback.class));\n+    ClusterMapChangeListener listener = mock(ClusterMapChangeListener.class);\n+    handler.registerClusterMapListener(listener);\n+    handler.registerClusterMapListener(handler);\n+    handler.onReplicaAddedOrRemoved(makeReplicas(p2, p4), makeReplicas(p4));\n+    verify(clusterChangeHandlerCallback).addReplicasToPartition(eq(p4), any());\n+    verify(clusterChangeHandlerCallback, never()).removeReplicasFromPartition(any(), any());\n+    verifyNoMoreInteractions(clusterChangeHandlerCallback);\n+    verify(listener).onReplicaAddedOrRemoved(\n+        Collections.singletonList(handler.getReplicaId(cloudServiceDataNode, p4.toPathString())),\n+        Collections.emptyList());\n+\n+    // test basic datacenter view methods\n+    assertEquals(Collections.singletonList(handler.getReplicaId(cloudServiceDataNode, p3.toPathString())),\n+        handler.getReplicaIdsByState(p3, ReplicaState.LEADER).collect(Collectors.toList()));\n+    AmbryPartition p5 = new AmbryPartition(5, \"class\", mock(ClusterManagerCallback.class));\n+    assertEquals(Collections.emptyList(),\n+        handler.getReplicaIdsByState(p5, ReplicaState.LEADER).collect(Collectors.toList()));\n+    assertEquals(Collections.emptyMap(), handler.getDataNodeToDisksMap());\n+    assertEquals(4, handler.getReplicaIds(cloudServiceDataNode).size());\n+    assertEquals(Collections.emptyList(), handler.getReplicaIds(mock(AmbryDataNode.class)));\n+    assertEquals(Collections.emptySet(), handler.getDisks(cloudServiceDataNode));\n+    assertEquals(Collections.emptyMap(), handler.getPartitionToResourceMap());\n+    assertEquals(0, handler.getErrorCount());\n+\n+    // simulate failure\n+    doThrow(new RuntimeException()).when(clusterChangeHandlerCallback).addReplicasToPartition(any(), any());\n+    handler.onReplicaAddedOrRemoved(makeReplicas(p5), makeReplicas());\n+    assertEquals(1, handler.getErrorCount());\n+", "originalCommit": "041238f84036f88399df2cee904d21f5446f7264", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f7cb070fa7e959735104b3d91db7bc970ac15523", "url": "https://github.com/linkedin/ambry/commit/f7cb070fa7e959735104b3d91db7bc970ac15523", "message": "Address Rob's comments", "committedDate": "2020-03-19T01:01:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3OTMxMA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395379310", "bodyText": "minor: add java doc for these ports", "author": "jsjtzyy", "createdAt": "2020-03-19T23:44:30Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryDatanode.java", "diffHunk": "@@ -30,53 +26,34 @@\n /**\n  * {@link DataNodeId} implementation to use within dynamic cluster managers.\n  */\n-class AmbryDataNode implements DataNodeId {\n+abstract class AmbryDataNode implements DataNodeId {\n   private final String hostName;\n-  private final Port plainTextPort;\n-  private final Port sslPort;\n-  private final Port http2Port;\n+  // exposed for subclass access\n+  protected final Port plainTextPort;\n+  protected final Port sslPort;\n+  protected final Port http2Port;\n   private final String dataCenterName;\n-  private final String rackId;\n-  private final long xid;\n-  private final List<String> sslEnabledDataCenters;\n   private final ResourceStatePolicy resourceStatePolicy;\n-  private final boolean http2ClientEnabled;\n-  private final ClusterManagerCallback<AmbryReplica, AmbryDisk, AmbryPartition, AmbryDataNode> clusterManagerCallback;\n   private static final Logger logger = LoggerFactory.getLogger(AmbryDataNode.class);\n \n   /**\n    * Instantiate an AmbryDataNode object.\n    * @param dataCenterName the name of the dataCenter associated with this data node.\n    * @param clusterMapConfig the {@link ClusterMapConfig} to use.\n    * @param hostName the hostName identifying this data node.\n-   * @param portNum the port identifying this data node.\n-   * @param rackId the rack Id associated with this data node (may be null).\n-   * @param sslPortNum the ssl port associated with this data node (may be null).\n-   * @param http2PortNumber the http2 ssl port associated with this data node (may be null).\n-   * @param xid the xid associated with this data node.\n-   * @param clusterManagerCallback the {@link ClusterManagerCallback} to use\n    * @throws Exception if there is an exception in instantiating the {@link ResourceStatePolicy}\n    */\n-  AmbryDataNode(String dataCenterName, ClusterMapConfig clusterMapConfig, String hostName, int portNum, String rackId,\n-      Integer sslPortNum, Integer http2PortNumber, long xid,\n-      ClusterManagerCallback<AmbryReplica, AmbryDisk, AmbryPartition, AmbryDataNode> clusterManagerCallback)\n-      throws Exception {\n+  AmbryDataNode(String dataCenterName, ClusterMapConfig clusterMapConfig, String hostName, Port plainTextPort,\n+      Port sslPort, Port http2Port) throws Exception {", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM4MDE5Mw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395380193", "bodyText": "Any benefit we can get by changing this?", "author": "jsjtzyy", "createdAt": "2020-03-19T23:47:46Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryDatanode.java", "diffHunk": "@@ -95,7 +72,7 @@ public int getSSLPort() {\n       return sslPort.getPort();\n     } else {\n       throw new IllegalStateException(\n-          \"No HTTP2 port exists for the Data Node \" + hostName + \":\" + plainTextPort.getPort());\n+          \"No HTTP2 port exists for the Data Node \" + getHostname() + \":\" + plainTextPort.getPort());", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU4Mjk2MQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396582961", "bodyText": "changed back", "author": "cgtz", "createdAt": "2020-03-23T16:26:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM4MDE5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MDQwNw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395440407", "bodyText": "I wonder if onReplicaUnavailable() and onReplicaResponse() in this class are really needed for CloudServiceReplica. If not, we can move it into AmbryServerReplica.", "author": "jsjtzyy", "createdAt": "2020-03-20T05:03:39Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/AmbryReplica.java", "diffHunk": "@@ -15,84 +15,58 @@\n \n import com.github.ambry.config.ClusterMapConfig;\n import com.github.ambry.utils.Utils;\n-import java.io.File;\n-import java.util.ArrayList;\n import java.util.List;\n-import org.json.JSONObject;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n \n-import static com.github.ambry.clustermap.ClusterMapSnapshotConstants.*;\n import static com.github.ambry.clustermap.ClusterMapUtils.*;\n \n \n /**\n  * {@link ReplicaId} implementation to use within dynamic cluster managers.\n  */\n-class AmbryReplica implements ReplicaId {\n+abstract class AmbryReplica implements ReplicaId {\n   private final AmbryPartition partition;\n-  private final AmbryDisk disk;\n   private final long capacityBytes;\n   private volatile boolean isSealed;\n-  private volatile boolean isStopped;\n-  private final ResourceStatePolicy resourceStatePolicy;\n+  volatile boolean isStopped;\n+  final ResourceStatePolicy resourceStatePolicy;", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU4ODQ4NA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396588484", "bodyText": "I suppose they are at least needed as abstract methods in AmbryReplica since onReplicaEvent calls them and it would be unclean IMO to have onReplicaEvent have to check the replica type and cast before calling the method.\nWhether the ResourceStatePolicy is needed for cloud replicas is another question. One could just make the CloudServiceReplica always up and not have any failure tracking. For our preliminary testing environment I am inclined to leave it in and let the CloudServiceReplica go \"down\" when faced with service unavailability and see how it behaves. We definitely would need to take a second look at this though.", "author": "cgtz", "createdAt": "2020-03-23T16:34:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MDQwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MTczNw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395441737", "bodyText": "Thanks for explaining the difference. So, ClouldServiceReplica is used by frontend for now and primarily used to route requests to cloud, right? For server, it interacts with CloudReplica to perform two-way replication. (Correct me if I have misunderstood)", "author": "jsjtzyy", "createdAt": "2020-03-20T05:11:37Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudServiceReplica.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import org.json.JSONObject;\n+\n+import static com.github.ambry.clustermap.ClusterMapSnapshotConstants.*;\n+\n+\n+/**\n+ * An implementation of {@link AmbryReplica} that is meant to route requests towards cloud destinations using a standard\n+ * client library. The difference between this and {@link CloudReplica} is that {@link CloudReplica} is meant to\n+ * represent a VCR host instead of just being used to route requests towards a local client library. Additionally,\n+ * implementing {@link AmbryReplica} currently allows for easier interop with the rest of the helix cluster management\n+ * codebase.", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MjMzNw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395442337", "bodyText": "Since CloudServiceReplica will be in HelixClusterManager, so server is able to see it. I guess there is no server logic directly depends on CloudServiceReplica.", "author": "jsjtzyy", "createdAt": "2020-03-20T05:15:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MTczNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU5MjEyNg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396592126", "bodyText": "Yes it is for frontends, but it would only be present for the nodes that are configured to see it, using clusterMapDcsZkConnectStrings. Frontends can be configured to include it, and servers could be configured without it.\nYes a CloudReplica currently represents a replica that is present on a VCR host. In the long run, I would hope to also fold this one into the regular clustermap as a VcrReplica. I think that would help to clean up our 2-way replication story and allow us to share more code between the many ReplicationEngine variants that currently exist.", "author": "cgtz", "createdAt": "2020-03-23T16:39:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MTczNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0NDU0Mw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395444543", "bodyText": "Could this dataCenter be the same with regular datacenter (where regular ambry data nodes sit)? Or this should be a special datacenter representing the cloud?", "author": "jsjtzyy", "createdAt": "2020-03-20T05:27:37Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudServiceDataNode.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.network.Port;\n+import com.github.ambry.network.PortType;\n+import org.json.JSONObject;\n+\n+import static com.github.ambry.clustermap.ClusterMapSnapshotConstants.*;\n+import static com.github.ambry.clustermap.ClusterMapUtils.*;\n+\n+\n+/**\n+ * This is a place for {@link CloudServiceReplica}s to live on. This represents a location for in-process managed\n+ * service clients (not a VCR like {@link CloudDataNode}). This will not contain any ports, as it is not meant to\n+ * represent a remote network location. The hostname will just be the datacenter name. For logging purposes, the\n+ * plaintext port will show as -1.\n+ */\n+class CloudServiceDataNode extends AmbryDataNode {\n+\n+  /**\n+   * Instantiate a {@link CloudServiceDataNode}.\n+   * @param dataCenterName the name of the dataCenter associated with this data node.", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU5Mjg5OA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396592898", "bodyText": "No, a cloud DC is currently modeled as a separate datacenter.", "author": "cgtz", "createdAt": "2020-03-23T16:40:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0NDU0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0NjQxMA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395446410", "bodyText": "Is there a doc briefly describing how to support VCR clusters in clustermap? I am interested in this part and probably can work on some of its implementation. Can I envision that clustermap will incorporate both CloudReplica (for server's two-way replication) and CloudServiceReplica (for router to issue request)?", "author": "jsjtzyy", "createdAt": "2020-03-20T05:37:53Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudServiceClusterChangeHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.clustermap.HelixClusterManager.ClusterChangeHandlerCallback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.CopyOnWriteArrayList;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Stream;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Currently, this just adds a single {@link ReplicaType#CLOUD_BACKED} replica every time a partition is added to allow\n+ * for requests to be routed to cloud services. Currently it is only registered as a {@link ClusterMapChangeListener},\n+ * but once the clustermap natively supports VCR clusters, this class can implement {@link HelixAwareClusterChangeHandler} and", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjU5NjQ1MQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396596451", "bodyText": "No, there is no up to date doc, but I think our end goal should be that ClusterMap provides full support for spectating vcr and server state such that we can unify CloudToStoreReplicationManager and ReplicationManager (since an ambry-server will soon have to be able to replicate from both servers and vcrs simultaneously).", "author": "cgtz", "createdAt": "2020-03-23T16:45:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0NjQxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NDg3OA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395794878", "bodyText": "Can we just call this HelixClusterChangeHandler ?", "author": "jsjtzyy", "createdAt": "2020-03-20T17:42:26Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixAwareClusterChangeHandler.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Copyright 2019 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import java.util.stream.Stream;\n+import org.apache.helix.api.listeners.IdealStateChangeListener;\n+import org.apache.helix.api.listeners.InstanceConfigChangeListener;\n+import org.apache.helix.api.listeners.LiveInstanceChangeListener;\n+import org.apache.helix.api.listeners.RoutingTableChangeListener;\n+import org.apache.helix.spectator.RoutingTableSnapshot;\n+\n+\n+/**\n+ * An extension of {@link ClusterChangeHandler} for data centers that use helix for cluster management. This interface\n+ * implements various helix listeners and provides facilities for using routing tables.\n+ */\n+interface HelixAwareClusterChangeHandler", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5ODk0MA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395798940", "bodyText": "Since in CloudServiceDataNode hostname will be datacenter name, I think we can use cloudServiceDataNode.getHostname() to generate instance name.", "author": "jsjtzyy", "createdAt": "2020-03-20T17:50:05Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/CloudServiceClusterChangeHandler.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.clustermap;\n+\n+import com.github.ambry.clustermap.HelixClusterManager.ClusterChangeHandlerCallback;\n+import com.github.ambry.config.ClusterMapConfig;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.CopyOnWriteArrayList;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Stream;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Currently, this just adds a single {@link ReplicaType#CLOUD_BACKED} replica every time a partition is added to allow\n+ * for requests to be routed to cloud services. Currently it is only registered as a {@link ClusterMapChangeListener},\n+ * but once the clustermap natively supports VCR clusters, this class can implement {@link HelixAwareClusterChangeHandler} and\n+ * listen for changes in the VCR cluster.\n+ */\n+class CloudServiceClusterChangeHandler implements ClusterMapChangeListener, ClusterChangeHandler {\n+  private static final Logger logger = LoggerFactory.getLogger(CloudServiceClusterChangeHandler.class);\n+  private final Set<String> knownPartitions = ConcurrentHashMap.newKeySet();\n+  private final ConcurrentHashMap<String, CloudServiceReplica> partitionToReplica = new ConcurrentHashMap<>();\n+  private final List<ClusterMapChangeListener> listeners = new CopyOnWriteArrayList<>();\n+  private final AtomicLong errorCount = new AtomicLong(0);\n+  private final String dcName;\n+  private final ClusterMapConfig clusterMapConfig;\n+  private final ClusterChangeHandlerCallback changeHandlerCallback;\n+  private final CloudServiceDataNode cloudServiceDataNode;\n+  private final String cloudServiceInstanceName;\n+\n+  public CloudServiceClusterChangeHandler(String dcName, ClusterMapConfig clusterMapConfig,\n+      ClusterChangeHandlerCallback changeHandlerCallback) throws Exception {\n+    this.dcName = dcName;\n+    this.clusterMapConfig = clusterMapConfig;\n+    this.changeHandlerCallback = changeHandlerCallback;\n+    cloudServiceDataNode = new CloudServiceDataNode(dcName, clusterMapConfig);\n+    cloudServiceInstanceName =\n+        ClusterMapUtils.getInstanceName(cloudServiceDataNode.getDatacenterName(), cloudServiceDataNode.getPort());", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYwOTUwNQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396609505", "bodyText": "I tried this. The problem I ran into is that the method ClusterMap.getDataNodeId(...) requires an int port number to be passed in and generates the instance name before calling ClusterChangeHandler.getDataNode.\nThe options would be:\n\nKeep it as it is with a -1 port for CloudServiceDataNodes\nDon't support getDataNode in CloudServiceClusterChangeHandler. This could be a possibility since it probably has very limited value in this case.\nChange ClusterMap.getDataNodeId method to take a nullable Integer instead of int\n\nWhich do you prefer, @jsjtzyy?", "author": "cgtz", "createdAt": "2020-03-23T17:03:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5ODk0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyOTUyNg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396629526", "bodyText": "If getDataNode is unlikely to be used in CloudServiceClusterChangeHandler, yeah, we don't have to support it. (Let's go with option 2, what do you think?)", "author": "jsjtzyy", "createdAt": "2020-03-23T17:31:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5ODk0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjcwNzI2OQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396707269", "bodyText": "implemented 2", "author": "cgtz", "createdAt": "2020-03-23T19:36:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5ODk0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgxODU3Mw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395818573", "bodyText": "Like I said, we can add ReplicaType to standard datacenter and also introduce zkString for cloud. This would make the json format more consistent and simplify code logic here.  My two cents.", "author": "jsjtzyy", "createdAt": "2020-03-20T18:26:30Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/ClusterMapUtils.java", "diffHunk": "@@ -141,8 +149,12 @@ public static String getInstanceName(String host, Integer port) {\n     JSONArray all = root.getJSONArray(ZKINFO_STR);\n     for (int i = 0; i < all.length(); i++) {\n       JSONObject entry = all.getJSONObject(i);\n+      String name = entry.getString(DATACENTER_STR);\n       byte id = (byte) entry.getInt(DATACENTER_ID_STR);\n-      DcZkInfo dcZkInfo = new DcZkInfo(entry.getString(DATACENTER_STR), id, entry.getString(ZKCONNECTSTR_STR));\n+      ReplicaType replicaType = entry.optEnum(ReplicaType.class, REPLICA_TYPE_STR, ReplicaType.DISK_BACKED);", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY0NDMwMA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396644300", "bodyText": "That would break backwards compatibility with existing configs by adding a new required field, replicaType. Personally, I don't find having default values too complicated. I also wanted to resist having a dummy value for cloud_backed datacenters, since the work I'm doing here is admittedly a little transient. Eventually, the zk string for cloud dcs will likely be set to the VCR zk for things like getting partition override info and additional metadata.", "author": "cgtz", "createdAt": "2020-03-23T17:54:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgxODU3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNTY3Ng==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395935676", "bodyText": "typo: relevant", "author": "jsjtzyy", "createdAt": "2020-03-20T23:52:31Z", "path": "ambry-utils/src/main/java/com.github.ambry.utils/Utils.java", "diffHunk": "@@ -304,13 +305,29 @@ public static ByteBuf readNettyByteBufFromCrcInputStream(CrcInputStream crcStrea\n     return output;\n   }\n \n+  /**\n+   * Extracts the cause of an {@link ExecutionException}. This is used to get the relevent domain-specific exception", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNTc0Mg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395935742", "bodyText": "typo: return", "author": "jsjtzyy", "createdAt": "2020-03-20T23:52:51Z", "path": "ambry-utils/src/main/java/com.github.ambry.utils/Utils.java", "diffHunk": "@@ -304,13 +305,29 @@ public static ByteBuf readNettyByteBufFromCrcInputStream(CrcInputStream crcStrea\n     return output;\n   }\n \n+  /**\n+   * Extracts the cause of an {@link ExecutionException}. This is used to get the relevent domain-specific exception\n+   * after unboxing a future.\n+   * @param e the {@link Exception}\n+   * @return if the cause is {@code null}, return {@code e} itself. If the cause is not an instance\n+   *         of exception, return the {@link Throwable} wrapped in an exception. If not {@link ExecutionException},\n+   *         retun the exception itself. Otherwise, return the cause {@link Exception}.", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0MTY5Mw==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395941693", "bodyText": "if (!(e instanceof ExecutionException) || e.getCause() == null) {\n      return e;\n    }\n    Throwable cause = e.getCause();\n    return cause instanceof Exception ? (Exception) cause : new Exception(cause);\n\nHow about making return statement simpler?", "author": "jsjtzyy", "createdAt": "2020-03-21T00:29:55Z", "path": "ambry-utils/src/main/java/com.github.ambry.utils/Utils.java", "diffHunk": "@@ -304,13 +305,29 @@ public static ByteBuf readNettyByteBufFromCrcInputStream(CrcInputStream crcStrea\n     return output;\n   }\n \n+  /**\n+   * Extracts the cause of an {@link ExecutionException}. This is used to get the relevent domain-specific exception\n+   * after unboxing a future.\n+   * @param e the {@link Exception}\n+   * @return if the cause is {@code null}, return {@code e} itself. If the cause is not an instance\n+   *         of exception, return the {@link Throwable} wrapped in an exception. If not {@link ExecutionException},\n+   *         retun the exception itself. Otherwise, return the cause {@link Exception}.\n+   */\n+  public static Exception extractExecutionExceptionCause(Exception e) {\n+    if (!(e instanceof ExecutionException)) {\n+      return e;\n+    }\n+    Throwable cause = e.getCause();\n+    return cause == null ? e : (cause instanceof Exception ? (Exception) cause : new Exception(cause));\n+  }", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0MzUyMA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395943520", "bodyText": "Do you think it's worthwhile to make this a base class and introduce classes something like HelixDcInfo and CloudDcInfo that extend this? One of the benefits is we can remove HelixManager from DcInfo that is constructed for cloud.", "author": "jsjtzyy", "createdAt": "2020-03-21T00:43:40Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/DcInfo.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *\n+ */\n+\n+package com.github.ambry.clustermap;\n+\n+import org.apache.helix.HelixManager;\n+\n+\n+/**\n+ * Class that stores all the information associated with a datacenter.\n+ */\n+class DcInfo {\n+  final String dcName;\n+  final ClusterMapUtils.DcZkInfo dcZkInfo;\n+  final HelixManager helixManager;\n+  final ClusterChangeHandler clusterChangeHandler;\n+\n+  /**\n+   * Construct a DcInfo object with the given parameters.\n+   * @param dcName the associated datacenter name.\n+   * @param dcZkInfo the {@link ClusterMapUtils.DcZkInfo} associated with the DC.\n+   * @param helixManager the associated {@link HelixManager} for this datacenter. This can be null if the datacenter is", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0NjcyMg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395946722", "bodyText": "(Not an issue, just want to make sure my understanding here is correct)\nWith CompletableFuture in the DatacenterInitializer, even though exception may occur immediately after initializer.start(), the initializer is still added into the list. The exception not thrown until initializer.join() is called when iterating all initializers. Hence, all exceptions should be caught (if any), right?", "author": "jsjtzyy", "createdAt": "2020-03-21T01:12:51Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -106,105 +101,48 @@ public HelixClusterManager(ClusterMapConfig clusterMapConfig, String instanceNam\n     clusterChangeHandlerCallback = new ClusterChangeHandlerCallback();\n     helixClusterManagerMetrics = new HelixClusterManagerMetrics(metricRegistry, helixClusterManagerCallback);\n     Map<String, DcZkInfo> dataCenterToZkAddress = null;\n-    HelixManager localManager_ = null;\n+    HelixManager localManager = null;\n+    Map<String, Exception> initializationFailureMap = new HashMap<>();\n     try {\n       dataCenterToZkAddress = parseDcJsonAndPopulateDcInfo(clusterMapConfig.clusterMapDcsZkConnectStrings);\n       // Make sure the HelixManager of local datacenter gets connected first and partitionOverrideInfoMap use PropertyStore\n       // in local DC for initialization.\n-      localManager_ =\n-          initializeHelixManagerAndPropertyStoreInLocalDC(dataCenterToZkAddress, instanceName, helixFactory);\n+      localManager = initializeHelixManagerAndPropertyStoreInLocalDC(dataCenterToZkAddress, instanceName, helixFactory);\n     } catch (Exception e) {\n       initializationFailureMap.putIfAbsent(clusterMapConfig.clusterMapDatacenterName, e);\n     }\n     if (initializationFailureMap.get(clusterMapConfig.clusterMapDatacenterName) == null) {\n-      HelixManager localManager = localManager_;\n-      final CountDownLatch initializationAttemptComplete = new CountDownLatch(dataCenterToZkAddress.size());\n-      for (Map.Entry<String, DcZkInfo> entry : dataCenterToZkAddress.entrySet()) {\n-        String dcName = entry.getKey();\n-        String zkConnectStr = entry.getValue().getZkConnectStr();\n+      List<DatacenterInitializer> initializers = new ArrayList<>();\n+      for (DcZkInfo dcZkInfo : dataCenterToZkAddress.values()) {\n         // Initialize from every remote datacenter in a separate thread to speed things up.\n-        Utils.newThread(() -> {\n-          try {\n-            HelixManager manager;\n-            if (dcName.equals(clusterMapConfig.clusterMapDatacenterName)) {\n-              manager = localManager;\n-            } else {\n-              manager =\n-                  helixFactory.getZKHelixManager(clusterName, selfInstanceName, InstanceType.SPECTATOR, zkConnectStr);\n-              logger.info(\"Connecting to Helix manager at {}\", zkConnectStr);\n-              manager.connect();\n-              logger.info(\"Established connection to Helix manager at {}\", zkConnectStr);\n-            }\n-            ClusterChangeHandler clusterChangeHandler;\n-            String clusterChangeHandlerType = clusterMapConfig.clusterMapClusterChangeHandlerType;\n-            if (clusterChangeHandlerType.equals(SimpleClusterChangeHandler.class.getSimpleName())) {\n-              clusterChangeHandler =\n-                  new SimpleClusterChangeHandler(clusterMapConfig, dcName, selfInstanceName, partitionOverrideInfoMap,\n-                      partitionMap, partitionNameToAmbryPartition, ambryPartitionToAmbryReplicas,\n-                      helixClusterManagerCallback, helixClusterManagerMetrics, initializationFailureMap,\n-                      sealedStateChangeCounter);\n-            } else if (clusterChangeHandlerType.equals(DynamicClusterChangeHandler.class.getSimpleName())) {\n-              clusterChangeHandler =\n-                  new DynamicClusterChangeHandler(clusterMapConfig, dcName, selfInstanceName, partitionOverrideInfoMap,\n-                      helixClusterManagerCallback, clusterChangeHandlerCallback, helixClusterManagerMetrics,\n-                      initializationFailureMap, sealedStateChangeCounter);\n-            } else {\n-              throw new IllegalArgumentException(\n-                  \"Unsupported cluster change handler type: \" + clusterChangeHandlerType);\n-            }\n-            // Create RoutingTableProvider of each DC to keep track of partition(replicas) state. Here, we use current\n-            // state based RoutingTableProvider to remove dependency on Helix's pipeline and reduce notification latency.\n-            logger.info(\"Creating routing table provider associated with Helix manager at {}\", zkConnectStr);\n-            RoutingTableProvider routingTableProvider = new RoutingTableProvider(manager, PropertyType.CURRENTSTATES);\n-            logger.info(\"Routing table provider is created in {}\", dcName);\n-            DcInfo dcInfo = new DcInfo(dcName, entry.getValue(), manager, clusterChangeHandler);\n-            dcToDcZkInfo.put(dcName, dcInfo);\n-            dcIdToDcName.put(dcInfo.dcZkInfo.getDcId(), dcName);\n-            routingTableProvider.addRoutingTableChangeListener(clusterChangeHandler, null);\n-            logger.info(\"Registered routing table change listeners in {}\", dcName);\n-\n-            // The initial instance config change notification is required to populate the static cluster\n-            // information, and only after that is complete do we want the live instance change notification to\n-            // come in. We do not need to do anything extra to ensure this, however, since Helix provides the initial\n-            // notification for a change from within the same thread that adds the listener, in the context of the add\n-            // call. Therefore, when the call to add a listener returns, the initial notification will have been\n-            // received and handled.\n-            manager.addInstanceConfigChangeListener(clusterChangeHandler);\n-            logger.info(\"Registered instance config change listeners for Helix manager at {}\", zkConnectStr);\n-            manager.addIdealStateChangeListener(clusterChangeHandler);\n-            logger.info(\"Registered ideal state change listeners for Helix manager at {}\", zkConnectStr);\n-            // Now register listeners to get notified on live instance change in every datacenter.\n-            manager.addLiveInstanceChangeListener(clusterChangeHandler);\n-            logger.info(\"Registered live instance change listeners for Helix manager at {}\", zkConnectStr);\n-\n-            // in case initial event occurs before adding routing table listener, here we explicitly set snapshot in\n-            // ClusterChangeHandler. The reason is, if listener missed initial event, snapshot inside routing table\n-            // provider should be already populated.\n-            clusterChangeHandler.setRoutingTableSnapshot(routingTableProvider.getRoutingTableSnapshot());\n-            // the initial routing table change should populate the instanceConfigs. If it's empty that means initial\n-            // change didn't come and thread should wait on the init latch to ensure routing table snapshot is non-empty\n-            if (clusterChangeHandler.getRoutingTableSnapshot().getInstanceConfigs().isEmpty()) {\n-              // Periodic refresh in routing table provider is enabled by default. In worst case, routerUpdater should\n-              // trigger routing table change within 5 minutes\n-              logger.info(\"Routing table snapshot in {} is currently empty. Waiting for initial notification.\", dcName);\n-              clusterChangeHandler.waitForInitNotification();\n-            }\n-\n-            if (!clusterMapConfig.clustermapListenCrossColo && manager != localManager) {\n-              manager.disconnect();\n-              logger.info(\"Stopped listening to cross colo ZK server {}\", zkConnectStr);\n-            }\n-          } catch (Exception e) {\n-            initializationFailureMap.putIfAbsent(dcName, e);\n-          } finally {\n-            initializationAttemptComplete.countDown();\n-          }\n-        }, false).start();\n+        DatacenterInitializer initializer =\n+            new DatacenterInitializer(clusterMapConfig, localManager, helixFactory, dcZkInfo, selfInstanceName,\n+                partitionOverrideInfoMap, clusterChangeHandlerCallback, helixClusterManagerCallback,\n+                helixClusterManagerMetrics, sealedStateChangeCounter, partitionMap, partitionNameToAmbryPartition,\n+                ambryPartitionToAmbryReplicas);\n+        initializer.start();\n+        initializers.add(initializer);", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzMDc3Mg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396630772", "bodyText": "Yes, that is right.", "author": "cgtz", "createdAt": "2020-03-23T17:33:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0NjcyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0ODc2OA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395948768", "bodyText": "I think one replica from each partition would suffice (as opposed to adding same partition 12 times in CloudServiceClusterChangeHandler) :\n            if (!replicas.isEmpty()) {\n              allReplicas.add(replicas.iterator().next());\n            }", "author": "jsjtzyy", "createdAt": "2020-03-21T01:35:12Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -106,105 +101,48 @@ public HelixClusterManager(ClusterMapConfig clusterMapConfig, String instanceNam\n     clusterChangeHandlerCallback = new ClusterChangeHandlerCallback();\n     helixClusterManagerMetrics = new HelixClusterManagerMetrics(metricRegistry, helixClusterManagerCallback);\n     Map<String, DcZkInfo> dataCenterToZkAddress = null;\n-    HelixManager localManager_ = null;\n+    HelixManager localManager = null;\n+    Map<String, Exception> initializationFailureMap = new HashMap<>();\n     try {\n       dataCenterToZkAddress = parseDcJsonAndPopulateDcInfo(clusterMapConfig.clusterMapDcsZkConnectStrings);\n       // Make sure the HelixManager of local datacenter gets connected first and partitionOverrideInfoMap use PropertyStore\n       // in local DC for initialization.\n-      localManager_ =\n-          initializeHelixManagerAndPropertyStoreInLocalDC(dataCenterToZkAddress, instanceName, helixFactory);\n+      localManager = initializeHelixManagerAndPropertyStoreInLocalDC(dataCenterToZkAddress, instanceName, helixFactory);\n     } catch (Exception e) {\n       initializationFailureMap.putIfAbsent(clusterMapConfig.clusterMapDatacenterName, e);\n     }\n     if (initializationFailureMap.get(clusterMapConfig.clusterMapDatacenterName) == null) {\n-      HelixManager localManager = localManager_;\n-      final CountDownLatch initializationAttemptComplete = new CountDownLatch(dataCenterToZkAddress.size());\n-      for (Map.Entry<String, DcZkInfo> entry : dataCenterToZkAddress.entrySet()) {\n-        String dcName = entry.getKey();\n-        String zkConnectStr = entry.getValue().getZkConnectStr();\n+      List<DatacenterInitializer> initializers = new ArrayList<>();\n+      for (DcZkInfo dcZkInfo : dataCenterToZkAddress.values()) {\n         // Initialize from every remote datacenter in a separate thread to speed things up.\n-        Utils.newThread(() -> {\n-          try {\n-            HelixManager manager;\n-            if (dcName.equals(clusterMapConfig.clusterMapDatacenterName)) {\n-              manager = localManager;\n-            } else {\n-              manager =\n-                  helixFactory.getZKHelixManager(clusterName, selfInstanceName, InstanceType.SPECTATOR, zkConnectStr);\n-              logger.info(\"Connecting to Helix manager at {}\", zkConnectStr);\n-              manager.connect();\n-              logger.info(\"Established connection to Helix manager at {}\", zkConnectStr);\n-            }\n-            ClusterChangeHandler clusterChangeHandler;\n-            String clusterChangeHandlerType = clusterMapConfig.clusterMapClusterChangeHandlerType;\n-            if (clusterChangeHandlerType.equals(SimpleClusterChangeHandler.class.getSimpleName())) {\n-              clusterChangeHandler =\n-                  new SimpleClusterChangeHandler(clusterMapConfig, dcName, selfInstanceName, partitionOverrideInfoMap,\n-                      partitionMap, partitionNameToAmbryPartition, ambryPartitionToAmbryReplicas,\n-                      helixClusterManagerCallback, helixClusterManagerMetrics, initializationFailureMap,\n-                      sealedStateChangeCounter);\n-            } else if (clusterChangeHandlerType.equals(DynamicClusterChangeHandler.class.getSimpleName())) {\n-              clusterChangeHandler =\n-                  new DynamicClusterChangeHandler(clusterMapConfig, dcName, selfInstanceName, partitionOverrideInfoMap,\n-                      helixClusterManagerCallback, clusterChangeHandlerCallback, helixClusterManagerMetrics,\n-                      initializationFailureMap, sealedStateChangeCounter);\n-            } else {\n-              throw new IllegalArgumentException(\n-                  \"Unsupported cluster change handler type: \" + clusterChangeHandlerType);\n-            }\n-            // Create RoutingTableProvider of each DC to keep track of partition(replicas) state. Here, we use current\n-            // state based RoutingTableProvider to remove dependency on Helix's pipeline and reduce notification latency.\n-            logger.info(\"Creating routing table provider associated with Helix manager at {}\", zkConnectStr);\n-            RoutingTableProvider routingTableProvider = new RoutingTableProvider(manager, PropertyType.CURRENTSTATES);\n-            logger.info(\"Routing table provider is created in {}\", dcName);\n-            DcInfo dcInfo = new DcInfo(dcName, entry.getValue(), manager, clusterChangeHandler);\n-            dcToDcZkInfo.put(dcName, dcInfo);\n-            dcIdToDcName.put(dcInfo.dcZkInfo.getDcId(), dcName);\n-            routingTableProvider.addRoutingTableChangeListener(clusterChangeHandler, null);\n-            logger.info(\"Registered routing table change listeners in {}\", dcName);\n-\n-            // The initial instance config change notification is required to populate the static cluster\n-            // information, and only after that is complete do we want the live instance change notification to\n-            // come in. We do not need to do anything extra to ensure this, however, since Helix provides the initial\n-            // notification for a change from within the same thread that adds the listener, in the context of the add\n-            // call. Therefore, when the call to add a listener returns, the initial notification will have been\n-            // received and handled.\n-            manager.addInstanceConfigChangeListener(clusterChangeHandler);\n-            logger.info(\"Registered instance config change listeners for Helix manager at {}\", zkConnectStr);\n-            manager.addIdealStateChangeListener(clusterChangeHandler);\n-            logger.info(\"Registered ideal state change listeners for Helix manager at {}\", zkConnectStr);\n-            // Now register listeners to get notified on live instance change in every datacenter.\n-            manager.addLiveInstanceChangeListener(clusterChangeHandler);\n-            logger.info(\"Registered live instance change listeners for Helix manager at {}\", zkConnectStr);\n-\n-            // in case initial event occurs before adding routing table listener, here we explicitly set snapshot in\n-            // ClusterChangeHandler. The reason is, if listener missed initial event, snapshot inside routing table\n-            // provider should be already populated.\n-            clusterChangeHandler.setRoutingTableSnapshot(routingTableProvider.getRoutingTableSnapshot());\n-            // the initial routing table change should populate the instanceConfigs. If it's empty that means initial\n-            // change didn't come and thread should wait on the init latch to ensure routing table snapshot is non-empty\n-            if (clusterChangeHandler.getRoutingTableSnapshot().getInstanceConfigs().isEmpty()) {\n-              // Periodic refresh in routing table provider is enabled by default. In worst case, routerUpdater should\n-              // trigger routing table change within 5 minutes\n-              logger.info(\"Routing table snapshot in {} is currently empty. Waiting for initial notification.\", dcName);\n-              clusterChangeHandler.waitForInitNotification();\n-            }\n-\n-            if (!clusterMapConfig.clustermapListenCrossColo && manager != localManager) {\n-              manager.disconnect();\n-              logger.info(\"Stopped listening to cross colo ZK server {}\", zkConnectStr);\n-            }\n-          } catch (Exception e) {\n-            initializationFailureMap.putIfAbsent(dcName, e);\n-          } finally {\n-            initializationAttemptComplete.countDown();\n-          }\n-        }, false).start();\n+        DatacenterInitializer initializer =\n+            new DatacenterInitializer(clusterMapConfig, localManager, helixFactory, dcZkInfo, selfInstanceName,\n+                partitionOverrideInfoMap, clusterChangeHandlerCallback, helixClusterManagerCallback,\n+                helixClusterManagerMetrics, sealedStateChangeCounter, partitionMap, partitionNameToAmbryPartition,\n+                ambryPartitionToAmbryReplicas);\n+        initializer.start();\n+        initializers.add(initializer);\n       }\n-      try {\n-        initializationAttemptComplete.await();\n-      } catch (InterruptedException e) {\n-        initializationFailureMap.putIfAbsent(clusterMapConfig.clusterMapDatacenterName, e);\n+      for (DatacenterInitializer initializer : initializers) {\n+        try {\n+          DcInfo dcInfo = initializer.join();\n+          dcToDcInfo.put(dcInfo.dcName, dcInfo);\n+          dcIdToDcName.put(dcInfo.dcZkInfo.getDcId(), dcInfo.dcName);\n+        } catch (Exception e) {\n+          initializationFailureMap.putIfAbsent(initializer.getDcName(), e);\n+        }\n+      }\n+\n+      for (DcInfo dcInfo : dcToDcInfo.values()) {\n+        if (dcInfo.clusterChangeHandler instanceof ClusterMapChangeListener) {\n+          ClusterMapChangeListener listener = (ClusterMapChangeListener) dcInfo.clusterChangeHandler;\n+          registerClusterMapListener(listener);\n+          List<ReplicaId> allReplicas = new ArrayList<>();\n+          for (Set<AmbryReplica> replicas : ambryPartitionToAmbryReplicas.values()) {\n+            allReplicas.addAll(replicas);", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyMzExNg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396623116", "bodyText": "That is true. I will do that! However, we should be careful in making it clear that this is specifically tailored to `CloudServiceClusterChangeHandler, since in most cases one would expect all replicas to be provided.", "author": "cgtz", "createdAt": "2020-03-23T17:22:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0ODc2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0OTEzMA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395949130", "bodyText": "Do you think we need to skip DcInfo of cloud here? Does partitionSelectionHelper really need to listen to CloudServiceClusterChangeHandler?", "author": "jsjtzyy", "createdAt": "2020-03-21T01:39:06Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -234,30 +172,35 @@ public HelixClusterManager(ClusterMapConfig clusterMapConfig, String instanceNam\n       helixClusterManagerMetrics.initializePartitionMetrics();\n       helixClusterManagerMetrics.initializeCapacityMetrics();\n     }\n-    localDatacenterId = dcToDcZkInfo.get(clusterMapConfig.clusterMapDatacenterName).dcZkInfo.getDcId();\n+    localDatacenterId = dcToDcInfo.get(clusterMapConfig.clusterMapDatacenterName).dcZkInfo.getDcId();\n     partitionSelectionHelper =\n         new PartitionSelectionHelper(helixClusterManagerCallback, clusterMapConfig.clusterMapDatacenterName,\n             clusterMapConfig.clustermapWritablePartitionMinReplicaCount);\n     // register partition selection helper as a listener of cluster map changes.\n-    dcToDcZkInfo.values()\n-        .forEach(info -> info.clusterChangeHandler.registerClusterMapListener(partitionSelectionHelper));\n+    registerClusterMapListener(partitionSelectionHelper);", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyNTA2Ng==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396625066", "bodyText": "I feel like it would, otherwise there would be no way to make a put request to newly added partitions in a cloud datacenter since the partitionSelectionHelper will not be fed CloudServiceReplicas as new partitions get added? Please correct me if my understanding is incorrect.", "author": "cgtz", "createdAt": "2020-03-23T17:25:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk0OTEzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk2MDYxOQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395960619", "bodyText": "Does dcZkInfo.getZkConnectStr() return empty string for now?", "author": "jsjtzyy", "createdAt": "2020-03-21T04:32:33Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterSpectator.java", "diffHunk": "@@ -63,15 +63,17 @@ public void spectate() throws Exception {\n     // zk connection fails on both data centers, then things like replication between data centers might just stop.\n     // For now, since we have only one fabric in cloud, and the spectator is being used for only cloud to store replication, this will work.\n     // Once we add more fabrics, we should revisit this.\n-    for (Map.Entry<String, DcZkInfo> entry : dataCenterToZkAddress.entrySet()) {\n-      String zkConnectStr = entry.getValue().getZkConnectStr();\n-      HelixManager helixManager =\n-          helixFactory.getZKHelixManager(cloudConfig.vcrClusterName, selfInstanceName, InstanceType.SPECTATOR,\n-              zkConnectStr);\n-      helixManager.connect();\n+    for (DcZkInfo dcZkInfo: dataCenterToZkAddress.values()) {\n+      // only handle vcr clusters for now\n+      if (dcZkInfo.getReplicaType() == ReplicaType.CLOUD_BACKED) {\n+        HelixManager helixManager =\n+            helixFactory.getZKHelixManager(cloudConfig.vcrClusterName, selfInstanceName, InstanceType.SPECTATOR,\n+                dcZkInfo.getZkConnectStr());", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyMDQ1Mg==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396620452", "bodyText": "No, this would be a case where it would be set to the vcr cluster address. Hopefully, we can find a way to unify HelixClusterSpectator with the rest of the ClusterMap eventually.", "author": "cgtz", "createdAt": "2020-03-23T17:18:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk2MDYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk2MDgyMQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395960821", "bodyText": "Suggest using a constant for -1 and put it into somewhere like TestUtil that can be shared by all tests.", "author": "jsjtzyy", "createdAt": "2020-03-21T04:36:14Z", "path": "ambry-clustermap/src/test/java/com.github.ambry.clustermap/MockHelixCluster.java", "diffHunk": "@@ -158,6 +158,11 @@ void setReplicaState(AmbryPartition partition, String instance, TestUtils.Replic\n     for (MockHelixAdmin helixAdmin : helixAdmins.values()) {\n       upInstances.addAll(helixAdmin.getUpInstances());\n     }\n+    // add cloud datanodes\n+    dataCenterToZkAddress.values()\n+        .stream()\n+        .filter(info -> info.getReplicaType() == ReplicaType.CLOUD_BACKED)\n+        .forEach(info -> upInstances.add(ClusterMapUtils.getInstanceName(info.getDcName(), -1)));", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk2MTc2NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r395961765", "bodyText": "I am not quite sure returning null for cloud dc is reasonable here.  For now, it makes some sense but in the future we need to reconsider.\nLet's say a frontend is brought up in cloud dc and this method should populate partitionOverrideInfoMap for the frontend. With current logic, partitionOverrideInfoMap is empty and frontend may route PUT to those partitions which should be temporarily sealed.\nIf frontend in cloud will be initialized with different code path, then just ignore this comment.", "author": "jsjtzyy", "createdAt": "2020-03-21T04:54:10Z", "path": "ambry-clustermap/src/main/java/com.github.ambry.clustermap/HelixClusterManager.java", "diffHunk": "@@ -234,30 +172,35 @@ public HelixClusterManager(ClusterMapConfig clusterMapConfig, String instanceNam\n       helixClusterManagerMetrics.initializePartitionMetrics();\n       helixClusterManagerMetrics.initializeCapacityMetrics();\n     }\n-    localDatacenterId = dcToDcZkInfo.get(clusterMapConfig.clusterMapDatacenterName).dcZkInfo.getDcId();\n+    localDatacenterId = dcToDcInfo.get(clusterMapConfig.clusterMapDatacenterName).dcZkInfo.getDcId();\n     partitionSelectionHelper =\n         new PartitionSelectionHelper(helixClusterManagerCallback, clusterMapConfig.clusterMapDatacenterName,\n             clusterMapConfig.clustermapWritablePartitionMinReplicaCount);\n     // register partition selection helper as a listener of cluster map changes.\n-    dcToDcZkInfo.values()\n-        .forEach(info -> info.clusterChangeHandler.registerClusterMapListener(partitionSelectionHelper));\n+    registerClusterMapListener(partitionSelectionHelper);\n   }\n \n   /**\n    * Initialize HelixManager in local datacenter and complete subscription of HelixPropertyStore to listen for\n-   * PartitionOverride zNode.\n+   * PartitionOverride zNode. This needs to happen before other datacenters are initialized so that any partition\n+   * overrides can be properly honored.\n    * @param dataCenterToZkAddress the map mapping each datacenter to its corresponding ZkAddress.\n    * @param instanceName the String representation of the instance associated with this manager.\n    * @param helixFactory the factory class to construct and get a reference to a {@link HelixManager}.\n-   * @return the HelixManager of local datacenter\n+   * @return the HelixManager of local datacenter, or {@code null} if the local datacenter is\n+   *         {@link ReplicaType#CLOUD_BACKED}, as we currently do not support getting cluster state from Helix for cloud\n+   *         datacenters.\n    * @throws Exception\n    */\n   private HelixManager initializeHelixManagerAndPropertyStoreInLocalDC(Map<String, DcZkInfo> dataCenterToZkAddress,\n       String instanceName, HelixFactory helixFactory) throws Exception {\n     DcZkInfo dcZkInfo = dataCenterToZkAddress.get(clusterMapConfig.clusterMapDatacenterName);\n     String zkConnectStr = dcZkInfo.getZkConnectStr();\n-    HelixManager manager;\n-    manager = helixFactory.getZKHelixManager(clusterName, instanceName, InstanceType.SPECTATOR, zkConnectStr);\n+    if (dcZkInfo.getReplicaType() == ReplicaType.CLOUD_BACKED) {\n+      return null;\n+    }", "originalCommit": "f7cb070fa7e959735104b3d91db7bc970ac15523", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYxNjk0NA==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396616944", "bodyText": "Where should a frontend in a datacenter without a helix ambry-server cluster get partitionOverrideInfo from? Some other datacenter? VCR cluster?\nI think that not having partition override is not a blocker for to start testing so I would prefer to keep this as is. In the future, I feel that storing partition override info in the VCR cluster would be the right way forward, since configuring an alternate zk to get this from seems like a hack. However, that would require the extra dev effort to support spectating VCR clusters described in some of the other comments.", "author": "cgtz", "createdAt": "2020-03-23T17:13:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk2MTc2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzNDY4NQ==", "url": "https://github.com/linkedin/ambry/pull/1412#discussion_r396634685", "bodyText": "Correct, VCR cluster is the right place to store partition override info.  (I agree this is not a blocker now, we can keep this in mind if we are doing cluster expansion in the future. Previously, I just want to mention a case where some partitions are administratively sealed in linkedin dc. However, if frontends in cloud still believe them unsealed, the PUT requests are still able to write into these partitions via cloud frontend)", "author": "jsjtzyy", "createdAt": "2020-03-23T17:39:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk2MTc2NQ=="}], "type": "inlineReview"}, {"oid": "2bc912292d138a03278b0dd5a7b46970fb4fe79c", "url": "https://github.com/linkedin/ambry/commit/2bc912292d138a03278b0dd5a7b46970fb4fe79c", "message": "Address Yingyi's comments", "committedDate": "2020-03-23T19:34:26Z", "type": "commit"}]}