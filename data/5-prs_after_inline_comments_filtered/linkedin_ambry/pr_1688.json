{"pr_number": 1688, "pr_title": "[AZURE_AD_AUTH] Add refresh logic for access token in ADAuthBasedStorgeClient.", "pr_createdAt": "2020-11-05T11:26:50Z", "pr_url": "https://github.com/linkedin/ambry/pull/1688", "timeline": [{"oid": "97ea2b69aa28fefb23068d2639f1361106472526", "url": "https://github.com/linkedin/ambry/commit/97ea2b69aa28fefb23068d2639f1361106472526", "message": "Add refresh logic for access token in ADAuthBasedStorgeClient.\nRefactor code.", "committedDate": "2020-11-05T11:16:43Z", "type": "commit"}, {"oid": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "url": "https://github.com/linkedin/ambry/commit/d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "message": "cleanup access token ref initialization", "committedDate": "2020-11-05T20:48:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1OTg2OA==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r520859868", "bodyText": "Looks ReflectiveOperationException is good enough. Why Exception is used?", "author": "zzmao", "createdAt": "2020-11-10T20:40:07Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -91,7 +91,7 @@\n    */\n   AzureCloudDestination(CloudConfig cloudConfig, AzureCloudConfig azureCloudConfig, String clusterName,\n       VcrMetrics vcrMetrics, AzureMetrics azureMetrics, AzureReplicationFeed.FeedType azureReplicationFeedType,\n-      ClusterMap clusterMap) throws ReflectiveOperationException {\n+      ClusterMap clusterMap) throws Exception {", "originalCommit": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzNzA4NQ==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521037085", "bodyText": "ReflectiveOperationException was rethrown as IllegalStateException.  Not sure if other exceptions are thrown.", "author": "lightningrob", "createdAt": "2020-11-11T02:29:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1OTg2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyNDI2NA==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521624264", "bodyText": "Actually Ze is right. IllegalStateException is being thrown for exceptions in AzureStorageClient class. We need to catch ReflectiveOperationException here that could be thrown while instantiating the AzureStorageClient class in AzureBlobDataAccessor using Utils.getObj.", "author": "ankagrawal", "createdAt": "2020-11-11T20:38:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1OTg2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNzEyNg==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r520907126", "bodyText": "Can reference be constructed in class constructor?", "author": "lightningrob", "createdAt": "2020-11-10T22:12:37Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/ADAuthBasedStorageClient.java", "diffHunk": "@@ -29,26 +32,56 @@\n import java.time.OffsetDateTime;\n import java.util.Collections;\n import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.apache.http.HttpStatus;\n import reactor.core.publisher.Mono;\n \n \n /**\n- * {@link StorageClientFactory} implementation for AD based authentication.\n+ * {@link StorageClient} implementation for AD based authentication.\n  */\n-public class ADAuthBasedStorageClientFactory extends StorageClientFactory {\n+public class ADAuthBasedStorageClient extends StorageClient {\n+  private AtomicReference<AccessToken> accessTokenRef;\n+\n+  /**\n+   * Constructor for {@link ADAuthBasedStorageClient} object.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @param cloudConfig {@link CloudConfig} object.\n+   */\n+  public ADAuthBasedStorageClient(AzureCloudConfig azureCloudConfig, CloudConfig cloudConfig,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    super(azureCloudConfig, cloudConfig, blobLayoutStrategy);\n+  }\n+\n+  /**\n+   * Constructor for {@link ADAuthBasedStorageClient} object for testing.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   * @param blobBatchClient {@link BlobBatchClient} object.\n+   * @param blobLayoutStrategy {@link AzureBlobLayoutStrategy} object.\n+   */\n+  public ADAuthBasedStorageClient(BlobServiceClient blobServiceClient, BlobBatchClient blobBatchClient,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    super(blobServiceClient, blobBatchClient, blobLayoutStrategy);\n+  }\n \n   @Override\n   protected BlobServiceClient buildBlobServiceClient(HttpClient httpClient, Configuration configuration,\n       RequestRetryOptions retryOptions, AzureCloudConfig azureCloudConfig)\n       throws MalformedURLException, InterruptedException, ExecutionException {\n     IAuthenticationResult iAuthenticationResult = getAccessTokenByClientCredentialGrant(azureCloudConfig);\n+    AccessToken accessToken = new AccessToken(iAuthenticationResult.accessToken(),\n+        iAuthenticationResult.expiresOnDate().toInstant().atOffset(OffsetDateTime.now().getOffset()));\n     TokenCredential tokenCredential = new TokenCredential() {\n       @Override\n       public Mono<AccessToken> getToken(TokenRequestContext request) {\n-        return Mono.just(new AccessToken(iAuthenticationResult.accessToken(),\n-            iAuthenticationResult.expiresOnDate().toInstant().atOffset(OffsetDateTime.now().getOffset())));\n+        return Mono.just(accessToken);\n       }\n     };\n+    if (accessTokenRef == null) {\n+      accessTokenRef = new AtomicReference<>(accessToken);", "originalCommit": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyODMxMA==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521028310", "bodyText": "The base class shouldn't know anything about expired tokens.", "author": "lightningrob", "createdAt": "2020-11-11T02:17:45Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/StorageClient.java", "diffHunk": "@@ -0,0 +1,413 @@\n+/**\n+ * Copyright 2020  LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud.azure;\n+\n+import com.azure.core.exception.UnexpectedLengthException;\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.ProxyOptions;\n+import com.azure.core.http.netty.NettyAsyncHttpClientBuilder;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Configuration;\n+import com.azure.core.util.Context;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.batch.BlobBatch;\n+import com.azure.storage.blob.batch.BlobBatchClient;\n+import com.azure.storage.blob.batch.BlobBatchClientBuilder;\n+import com.azure.storage.blob.batch.BlobBatchStorageException;\n+import com.azure.storage.blob.models.AccessTier;\n+import com.azure.storage.blob.models.BlobDownloadResponse;\n+import com.azure.storage.blob.models.BlobErrorCode;\n+import com.azure.storage.blob.models.BlobHttpHeaders;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobRange;\n+import com.azure.storage.blob.models.BlobRequestConditions;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.BlockBlobItem;\n+import com.azure.storage.blob.models.DownloadRetryOptions;\n+import com.azure.storage.blob.specialized.BlockBlobClient;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+import com.github.ambry.cloud.CloudBlobMetadata;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.config.CloudConfig;\n+import com.microsoft.azure.cosmosdb.RetryOptions;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.UncheckedIOException;\n+import java.net.InetSocketAddress;\n+import java.net.MalformedURLException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract class encapsulation ABS client operations.\n+ */\n+public abstract class StorageClient {\n+  Logger logger = LoggerFactory.getLogger(StorageClient.class);\n+  private final AtomicReference<BlobServiceClient> storageClientRef;\n+  private final AtomicReference<BlobBatchClient> blobBatchClientRef;\n+  private final CloudConfig cloudConfig;\n+  private final AzureCloudConfig azureCloudConfig;\n+  private final AzureBlobLayoutStrategy blobLayoutStrategy;\n+  // Containers known to exist in the storage account\n+  private final Set<String> knownContainers = ConcurrentHashMap.newKeySet();\n+\n+  /**\n+   * Constructor for {@link StorageClient}.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @param cloudConfig {@link CloudConfig} object.\n+   */\n+  public StorageClient(AzureCloudConfig azureCloudConfig, CloudConfig cloudConfig,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    this.azureCloudConfig = azureCloudConfig;\n+    this.cloudConfig = cloudConfig;\n+    this.blobLayoutStrategy = blobLayoutStrategy;\n+    storageClientRef = new AtomicReference<>(createBlobStorageClient());\n+    blobBatchClientRef = new AtomicReference<>(new BlobBatchClientBuilder(storageClientRef.get()).buildClient());\n+  }\n+\n+  /**\n+   * Constructor for {@link StorageClient}.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   * @param blobBatchClient {@link BlobBatchClient} object.\n+   */\n+  public StorageClient(BlobServiceClient blobServiceClient, BlobBatchClient blobBatchClient,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    this.storageClientRef = new AtomicReference<>(blobServiceClient);\n+    this.blobBatchClientRef = new AtomicReference<>(blobBatchClient);\n+    this.blobLayoutStrategy = blobLayoutStrategy;\n+    this.cloudConfig = null;\n+    this.azureCloudConfig = null;\n+  }\n+\n+  /**\n+   * Visible for testing.\n+   * @return the underlying {@link BlobServiceClient}.\n+   */\n+  public BlobServiceClient getStorageClient() {\n+    return storageClientRef.get();\n+  }\n+\n+  /**\n+   * Creates a new block blob, or updates the content of an existing block blob.\n+   * @param blobId {@link BlobId} of the blob to upload.\n+   * @param data The data to write to the blob.\n+   * @param length The exact length of the data. It is important that this value match precisely the length of the\n+   * data provided in the {@link InputStream}.\n+   * @param headers {@link BlobHttpHeaders}\n+   * @param metadata Metadata to associate with the blob.\n+   * @param tier {@link AccessTier} for the destination blob.\n+   * @param contentMd5 An MD5 hash of the block content.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The information of the uploaded block blob.\n+   * @throws UnexpectedLengthException when the length of data does not match the input {@code length}.\n+   * @throws NullPointerException if the input data is null.\n+   * @throws UncheckedIOException If an I/O error occurs\n+   */\n+  public Response<BlockBlobItem> uploadWithResponse(BlobId blobId, InputStream data, long length,\n+      BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, byte[] contentMd5,\n+      BlobRequestConditions requestConditions, Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, true).uploadWithResponse(data, length, headers, metadata, tier, contentMd5,\n+            requestConditions, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Creates a new block blob, or updates the content of an existing block blob.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @param data The data to write to the blob.\n+   * @param length The exact length of the data. It is important that this value match precisely the length of the\n+   * data provided in the {@link InputStream}.\n+   * @param headers {@link BlobHttpHeaders}\n+   * @param metadata Metadata to associate with the blob.\n+   * @param tier {@link AccessTier} for the destination blob.\n+   * @param contentMd5 An MD5 hash of the block content.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The information of the uploaded block blob.\n+   * @throws UnexpectedLengthException when the length of data does not match the input {@code length}.\n+   * @throws NullPointerException if the input data is null.\n+   * @throws UncheckedIOException If an I/O error occurs\n+   */\n+  public Response<BlockBlobItem> uploadWithResponse(String containerName, String blobName, boolean autoCreateContainer,\n+      InputStream data, long length, BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier,\n+      byte[] contentMd5, BlobRequestConditions requestConditions, Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(containerName, blobName, autoCreateContainer).uploadWithResponse(data, length, headers,\n+            metadata, tier, contentMd5, requestConditions, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Downloads a range of bytes from a blob into an output stream.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @param stream A non-null {@link OutputStream} instance where the downloaded data will be written.\n+   * @param range {@link BlobRange}\n+   * @param options {@link DownloadRetryOptions}\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param getRangeContentMd5 Whether the contentMD5 for the specified blob range should be returned.\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return A response containing status code and HTTP headers.\n+   * @throws UncheckedIOException If an I/O error occurs.\n+   * @throws NullPointerException if {@code stream} is null\n+   */\n+  public BlobDownloadResponse downloadWithResponse(String containerName, String blobName, boolean autoCreateContainer,\n+      OutputStream stream, BlobRange range, DownloadRetryOptions options, BlobRequestConditions requestConditions,\n+      boolean getRangeContentMd5, Duration timeout) {\n+    // Might as well use same timeout for upload and download\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(containerName, blobName, false).downloadWithResponse(stream, null, null,\n+            requestConditions, false, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Delete a file from blob storage, if it exists.\n+   * @param containerName name of the container containing file to delete.\n+   * @param fileName name of the file to delete.\n+   * @return true if the file was deleted, otherwise false.\n+   * @throws BlobStorageException for any error on ABS side.\n+   */\n+  boolean deleteFile(String containerName, String fileName) throws BlobStorageException {\n+    AtomicReference<Boolean> retValRef = new AtomicReference<>(false);\n+    doStorageClientOperation(() -> {\n+      BlockBlobClient blobClient = getBlockBlobClient(containerName, fileName, false);\n+      if (blobClient.exists()) {\n+        blobClient.delete();\n+        retValRef.set(true);\n+      }\n+      return null;\n+    });\n+    return retValRef.get();\n+  }\n+\n+  /**\n+   * Perform basic connectivity test.\n+   */\n+  void testConnectivity() {\n+    storageClientRef.get()\n+        .getBlobContainerClient(\"partition-0\")\n+        .existsWithResponse(Duration.ofSeconds(5), Context.NONE);\n+  }\n+\n+  /**\n+   * Returns the blob's metadata and properties.\n+   * @param blobId {@link BlobId}\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The blob properties and metadata.\n+   */\n+  public BlobProperties getPropertiesWithResponse(BlobId blobId, BlobRequestConditions requestConditions,\n+      Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, false).getPropertiesWithResponse(requestConditions, timeout, Context.NONE)\n+            .getValue());\n+  }\n+\n+  /**\n+   * Changes a blob's metadata. The specified metadata in this method will replace existing metadata. If old values\n+   * must be preserved, they must be downloaded and included in the call to this method.\n+   * @param blobId {@link BlobId} object.\n+   * @param metadata Metadata to associate with the blob.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @param context Additional context that is passed through the Http pipeline during the service call.\n+   */\n+  public void setMetadataWithResponse(BlobId blobId, Map<String, String> metadata,\n+      BlobRequestConditions requestConditions, Duration timeout, Context context) {\n+    doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, false).setMetadataWithResponse(metadata, requestConditions, timeout,\n+            Context.NONE));\n+  }\n+\n+  /**\n+   * Deletes a list of blobs.\n+   * @param batchOfBlobs {@link List} of {@link CloudBlobMetadata} objects.\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return {@link List} of {@link Response}s for the blobs in the batch.\n+   * @throws RuntimeException If the {@code timeout} duration completes before a response is returned.\n+   * @throws BlobStorageException If the batch request is malformed.\n+   * @throws BlobBatchStorageException If {@code throwOnAnyFailure} is {@code true} and any request in the\n+   * {@link BlobBatch} failed.\n+   */\n+  public List<Response<Void>> deleteBatch(List<CloudBlobMetadata> batchOfBlobs, Duration timeout) {\n+    List<Response<Void>> responseList = new ArrayList<>();\n+    doStorageClientOperation(() -> {\n+      BlobBatch blobBatch = blobBatchClientRef.get().getBlobBatch();\n+      for (CloudBlobMetadata blobMetadata : batchOfBlobs) {\n+        AzureBlobLayoutStrategy.BlobLayout blobLayout = blobLayoutStrategy.getDataBlobLayout(blobMetadata);\n+        responseList.add(blobBatch.deleteBlob(blobLayout.containerName, blobLayout.blobFilePath));\n+      }\n+      blobBatchClientRef.get().submitBatchWithResponse(blobBatch, false, timeout, Context.NONE);\n+      return null;\n+    });\n+    return responseList;\n+  }\n+\n+  /**\n+   * Get the block blob client for the supplied blobid.\n+   * @param blobId id of the blob for which {@code BlockBlobClient} is needed.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @return {@code BlockBlobClient} reference.\n+   */\n+  private BlockBlobClient getBlockBlobClient(BlobId blobId, boolean autoCreateContainer) {\n+    AzureBlobLayoutStrategy.BlobLayout blobLayout = blobLayoutStrategy.getDataBlobLayout(blobId);\n+    return getBlockBlobClient(blobLayout.containerName, blobLayout.blobFilePath, autoCreateContainer);\n+  }\n+\n+  /**\n+   * Get the block blob client for the supplied Azure container and blob name.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @return {@code BlockBlobClient} reference.\n+   */\n+  BlockBlobClient getBlockBlobClient(String containerName, String blobName, boolean autoCreateContainer) {\n+    BlobContainerClient containerClient = getContainer(containerName, autoCreateContainer);\n+    return containerClient.getBlobClient(blobName).getBlockBlobClient();\n+  }\n+\n+  /**\n+   * Get a reference to an Azure container, creating it if necessary.\n+   * @param containerName the container name.\n+   * @param autoCreate flag indicating whether to create the container if it does not exist.\n+   * @return the created {@link BlobContainerClient}.\n+   */\n+  private BlobContainerClient getContainer(String containerName, boolean autoCreate) {\n+    BlobContainerClient containerClient = storageClientRef.get().getBlobContainerClient(containerName);\n+    if (autoCreate) {\n+      if (!knownContainers.contains(containerName)) {\n+        try {\n+          if (!containerClient.exists()) {\n+            containerClient.create();\n+            logger.info(\"Created container {}\", containerName);\n+          }\n+        } catch (BlobStorageException ex) {\n+          if (ex.getErrorCode() != BlobErrorCode.CONTAINER_ALREADY_EXISTS) {\n+            logger.error(\"Failed to create container {}\", containerName);\n+            throw ex;\n+          }\n+        }\n+        knownContainers.add(containerName);\n+      }\n+    }\n+    return containerClient;\n+  }\n+\n+  /**\n+   * Create the {@link BlobServiceClient} object.\n+   * @param {@link CloudConfig} object.\n+   * @param {@link AzureCloudConfig} object.\n+   * @return {@link BlobServiceClient} object.\n+   */\n+  protected BlobServiceClient createBlobStorageClient() {\n+    validateABSAuthConfigs(azureCloudConfig);\n+    Configuration storageConfiguration = new Configuration();\n+    // Check for network proxy\n+    ProxyOptions proxyOptions = (cloudConfig.vcrProxyHost == null) ? null : new ProxyOptions(ProxyOptions.Type.HTTP,\n+        new InetSocketAddress(cloudConfig.vcrProxyHost, cloudConfig.vcrProxyPort));\n+    if (proxyOptions != null) {\n+      logger.info(\"Using proxy: {}:{}\", cloudConfig.vcrProxyHost, cloudConfig.vcrProxyPort);\n+    }\n+    HttpClient client = new NettyAsyncHttpClientBuilder().proxy(proxyOptions).build();\n+\n+    // Note: retry decisions are made at CloudBlobStore level.  Configure storageClient with no retries.\n+    RequestRetryOptions noRetries = new RequestRetryOptions(RetryPolicyType.FIXED, 1, null, null, null, null);\n+    try {\n+      return buildBlobServiceClient(client, storageConfiguration, noRetries, azureCloudConfig);\n+    } catch (MalformedURLException | InterruptedException | ExecutionException ex) {\n+      logger.error(\"Error building ABS blob service client: {}\", ex.getMessage());\n+      throw new IllegalStateException(ex);\n+    }\n+  }\n+\n+  /**\n+   * Set the references for storage and blob clients atomically. Note this method is not thread safe and must always be\n+   * called within a thread safe context.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   */\n+  protected void setClientReferences(BlobServiceClient blobServiceClient) {\n+    storageClientRef.set(blobServiceClient);\n+    blobBatchClientRef.set(new BlobBatchClientBuilder(storageClientRef.get()).buildClient());\n+  }\n+\n+  /**\n+   * Execute the storage client operation represented by {@code operation}\n+   * @param operation {@link Callable} representing the operation.\n+   * @param <T> type of return value.\n+   * @return the return value of the operation.\n+   * @throws BlobStorageException\n+   */\n+  private <T> T doStorageClientOperation(Callable<T> operation) {\n+    int attempts = 0;\n+    T result = null;\n+    while (attempts <= 1) {\n+      attempts++;\n+      try {\n+        result = operation.call();\n+        break;\n+      } catch (BlobStorageException bsEx) {\n+        if (attempts == 1 && tryHandleExceptionAndHintRetry(bsEx)) {\n+          logger.info(\"Retrying blob store operation due to expired token\");", "originalCommit": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyNzUxOA==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521627518", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-11-11T20:44:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyODMxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyOTQ3NQ==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521029475", "bodyText": "Not sure the word \"try\" belongs in this name.", "author": "lightningrob", "createdAt": "2020-11-11T02:19:36Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/StorageClient.java", "diffHunk": "@@ -0,0 +1,413 @@\n+/**\n+ * Copyright 2020  LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud.azure;\n+\n+import com.azure.core.exception.UnexpectedLengthException;\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.ProxyOptions;\n+import com.azure.core.http.netty.NettyAsyncHttpClientBuilder;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Configuration;\n+import com.azure.core.util.Context;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.batch.BlobBatch;\n+import com.azure.storage.blob.batch.BlobBatchClient;\n+import com.azure.storage.blob.batch.BlobBatchClientBuilder;\n+import com.azure.storage.blob.batch.BlobBatchStorageException;\n+import com.azure.storage.blob.models.AccessTier;\n+import com.azure.storage.blob.models.BlobDownloadResponse;\n+import com.azure.storage.blob.models.BlobErrorCode;\n+import com.azure.storage.blob.models.BlobHttpHeaders;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobRange;\n+import com.azure.storage.blob.models.BlobRequestConditions;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.BlockBlobItem;\n+import com.azure.storage.blob.models.DownloadRetryOptions;\n+import com.azure.storage.blob.specialized.BlockBlobClient;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+import com.github.ambry.cloud.CloudBlobMetadata;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.config.CloudConfig;\n+import com.microsoft.azure.cosmosdb.RetryOptions;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.UncheckedIOException;\n+import java.net.InetSocketAddress;\n+import java.net.MalformedURLException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Abstract class encapsulation ABS client operations.\n+ */\n+public abstract class StorageClient {\n+  Logger logger = LoggerFactory.getLogger(StorageClient.class);\n+  private final AtomicReference<BlobServiceClient> storageClientRef;\n+  private final AtomicReference<BlobBatchClient> blobBatchClientRef;\n+  private final CloudConfig cloudConfig;\n+  private final AzureCloudConfig azureCloudConfig;\n+  private final AzureBlobLayoutStrategy blobLayoutStrategy;\n+  // Containers known to exist in the storage account\n+  private final Set<String> knownContainers = ConcurrentHashMap.newKeySet();\n+\n+  /**\n+   * Constructor for {@link StorageClient}.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @param cloudConfig {@link CloudConfig} object.\n+   */\n+  public StorageClient(AzureCloudConfig azureCloudConfig, CloudConfig cloudConfig,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    this.azureCloudConfig = azureCloudConfig;\n+    this.cloudConfig = cloudConfig;\n+    this.blobLayoutStrategy = blobLayoutStrategy;\n+    storageClientRef = new AtomicReference<>(createBlobStorageClient());\n+    blobBatchClientRef = new AtomicReference<>(new BlobBatchClientBuilder(storageClientRef.get()).buildClient());\n+  }\n+\n+  /**\n+   * Constructor for {@link StorageClient}.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   * @param blobBatchClient {@link BlobBatchClient} object.\n+   */\n+  public StorageClient(BlobServiceClient blobServiceClient, BlobBatchClient blobBatchClient,\n+      AzureBlobLayoutStrategy blobLayoutStrategy) {\n+    this.storageClientRef = new AtomicReference<>(blobServiceClient);\n+    this.blobBatchClientRef = new AtomicReference<>(blobBatchClient);\n+    this.blobLayoutStrategy = blobLayoutStrategy;\n+    this.cloudConfig = null;\n+    this.azureCloudConfig = null;\n+  }\n+\n+  /**\n+   * Visible for testing.\n+   * @return the underlying {@link BlobServiceClient}.\n+   */\n+  public BlobServiceClient getStorageClient() {\n+    return storageClientRef.get();\n+  }\n+\n+  /**\n+   * Creates a new block blob, or updates the content of an existing block blob.\n+   * @param blobId {@link BlobId} of the blob to upload.\n+   * @param data The data to write to the blob.\n+   * @param length The exact length of the data. It is important that this value match precisely the length of the\n+   * data provided in the {@link InputStream}.\n+   * @param headers {@link BlobHttpHeaders}\n+   * @param metadata Metadata to associate with the blob.\n+   * @param tier {@link AccessTier} for the destination blob.\n+   * @param contentMd5 An MD5 hash of the block content.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The information of the uploaded block blob.\n+   * @throws UnexpectedLengthException when the length of data does not match the input {@code length}.\n+   * @throws NullPointerException if the input data is null.\n+   * @throws UncheckedIOException If an I/O error occurs\n+   */\n+  public Response<BlockBlobItem> uploadWithResponse(BlobId blobId, InputStream data, long length,\n+      BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier, byte[] contentMd5,\n+      BlobRequestConditions requestConditions, Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, true).uploadWithResponse(data, length, headers, metadata, tier, contentMd5,\n+            requestConditions, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Creates a new block blob, or updates the content of an existing block blob.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @param data The data to write to the blob.\n+   * @param length The exact length of the data. It is important that this value match precisely the length of the\n+   * data provided in the {@link InputStream}.\n+   * @param headers {@link BlobHttpHeaders}\n+   * @param metadata Metadata to associate with the blob.\n+   * @param tier {@link AccessTier} for the destination blob.\n+   * @param contentMd5 An MD5 hash of the block content.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The information of the uploaded block blob.\n+   * @throws UnexpectedLengthException when the length of data does not match the input {@code length}.\n+   * @throws NullPointerException if the input data is null.\n+   * @throws UncheckedIOException If an I/O error occurs\n+   */\n+  public Response<BlockBlobItem> uploadWithResponse(String containerName, String blobName, boolean autoCreateContainer,\n+      InputStream data, long length, BlobHttpHeaders headers, Map<String, String> metadata, AccessTier tier,\n+      byte[] contentMd5, BlobRequestConditions requestConditions, Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(containerName, blobName, autoCreateContainer).uploadWithResponse(data, length, headers,\n+            metadata, tier, contentMd5, requestConditions, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Downloads a range of bytes from a blob into an output stream.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @param stream A non-null {@link OutputStream} instance where the downloaded data will be written.\n+   * @param range {@link BlobRange}\n+   * @param options {@link DownloadRetryOptions}\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param getRangeContentMd5 Whether the contentMD5 for the specified blob range should be returned.\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return A response containing status code and HTTP headers.\n+   * @throws UncheckedIOException If an I/O error occurs.\n+   * @throws NullPointerException if {@code stream} is null\n+   */\n+  public BlobDownloadResponse downloadWithResponse(String containerName, String blobName, boolean autoCreateContainer,\n+      OutputStream stream, BlobRange range, DownloadRetryOptions options, BlobRequestConditions requestConditions,\n+      boolean getRangeContentMd5, Duration timeout) {\n+    // Might as well use same timeout for upload and download\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(containerName, blobName, false).downloadWithResponse(stream, null, null,\n+            requestConditions, false, timeout, Context.NONE));\n+  }\n+\n+  /**\n+   * Delete a file from blob storage, if it exists.\n+   * @param containerName name of the container containing file to delete.\n+   * @param fileName name of the file to delete.\n+   * @return true if the file was deleted, otherwise false.\n+   * @throws BlobStorageException for any error on ABS side.\n+   */\n+  boolean deleteFile(String containerName, String fileName) throws BlobStorageException {\n+    AtomicReference<Boolean> retValRef = new AtomicReference<>(false);\n+    doStorageClientOperation(() -> {\n+      BlockBlobClient blobClient = getBlockBlobClient(containerName, fileName, false);\n+      if (blobClient.exists()) {\n+        blobClient.delete();\n+        retValRef.set(true);\n+      }\n+      return null;\n+    });\n+    return retValRef.get();\n+  }\n+\n+  /**\n+   * Perform basic connectivity test.\n+   */\n+  void testConnectivity() {\n+    storageClientRef.get()\n+        .getBlobContainerClient(\"partition-0\")\n+        .existsWithResponse(Duration.ofSeconds(5), Context.NONE);\n+  }\n+\n+  /**\n+   * Returns the blob's metadata and properties.\n+   * @param blobId {@link BlobId}\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return The blob properties and metadata.\n+   */\n+  public BlobProperties getPropertiesWithResponse(BlobId blobId, BlobRequestConditions requestConditions,\n+      Duration timeout) {\n+    return doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, false).getPropertiesWithResponse(requestConditions, timeout, Context.NONE)\n+            .getValue());\n+  }\n+\n+  /**\n+   * Changes a blob's metadata. The specified metadata in this method will replace existing metadata. If old values\n+   * must be preserved, they must be downloaded and included in the call to this method.\n+   * @param blobId {@link BlobId} object.\n+   * @param metadata Metadata to associate with the blob.\n+   * @param requestConditions {@link BlobRequestConditions}\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @param context Additional context that is passed through the Http pipeline during the service call.\n+   */\n+  public void setMetadataWithResponse(BlobId blobId, Map<String, String> metadata,\n+      BlobRequestConditions requestConditions, Duration timeout, Context context) {\n+    doStorageClientOperation(\n+        () -> getBlockBlobClient(blobId, false).setMetadataWithResponse(metadata, requestConditions, timeout,\n+            Context.NONE));\n+  }\n+\n+  /**\n+   * Deletes a list of blobs.\n+   * @param batchOfBlobs {@link List} of {@link CloudBlobMetadata} objects.\n+   * @param timeout An optional timeout value beyond which a {@link RuntimeException} will be raised.\n+   * @return {@link List} of {@link Response}s for the blobs in the batch.\n+   * @throws RuntimeException If the {@code timeout} duration completes before a response is returned.\n+   * @throws BlobStorageException If the batch request is malformed.\n+   * @throws BlobBatchStorageException If {@code throwOnAnyFailure} is {@code true} and any request in the\n+   * {@link BlobBatch} failed.\n+   */\n+  public List<Response<Void>> deleteBatch(List<CloudBlobMetadata> batchOfBlobs, Duration timeout) {\n+    List<Response<Void>> responseList = new ArrayList<>();\n+    doStorageClientOperation(() -> {\n+      BlobBatch blobBatch = blobBatchClientRef.get().getBlobBatch();\n+      for (CloudBlobMetadata blobMetadata : batchOfBlobs) {\n+        AzureBlobLayoutStrategy.BlobLayout blobLayout = blobLayoutStrategy.getDataBlobLayout(blobMetadata);\n+        responseList.add(blobBatch.deleteBlob(blobLayout.containerName, blobLayout.blobFilePath));\n+      }\n+      blobBatchClientRef.get().submitBatchWithResponse(blobBatch, false, timeout, Context.NONE);\n+      return null;\n+    });\n+    return responseList;\n+  }\n+\n+  /**\n+   * Get the block blob client for the supplied blobid.\n+   * @param blobId id of the blob for which {@code BlockBlobClient} is needed.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @return {@code BlockBlobClient} reference.\n+   */\n+  private BlockBlobClient getBlockBlobClient(BlobId blobId, boolean autoCreateContainer) {\n+    AzureBlobLayoutStrategy.BlobLayout blobLayout = blobLayoutStrategy.getDataBlobLayout(blobId);\n+    return getBlockBlobClient(blobLayout.containerName, blobLayout.blobFilePath, autoCreateContainer);\n+  }\n+\n+  /**\n+   * Get the block blob client for the supplied Azure container and blob name.\n+   * @param containerName name of the Azure container where the blob lives.\n+   * @param blobName name of the blob.\n+   * @param autoCreateContainer flag indicating whether to create the container if it does not exist.\n+   * @return {@code BlockBlobClient} reference.\n+   */\n+  BlockBlobClient getBlockBlobClient(String containerName, String blobName, boolean autoCreateContainer) {\n+    BlobContainerClient containerClient = getContainer(containerName, autoCreateContainer);\n+    return containerClient.getBlobClient(blobName).getBlockBlobClient();\n+  }\n+\n+  /**\n+   * Get a reference to an Azure container, creating it if necessary.\n+   * @param containerName the container name.\n+   * @param autoCreate flag indicating whether to create the container if it does not exist.\n+   * @return the created {@link BlobContainerClient}.\n+   */\n+  private BlobContainerClient getContainer(String containerName, boolean autoCreate) {\n+    BlobContainerClient containerClient = storageClientRef.get().getBlobContainerClient(containerName);\n+    if (autoCreate) {\n+      if (!knownContainers.contains(containerName)) {\n+        try {\n+          if (!containerClient.exists()) {\n+            containerClient.create();\n+            logger.info(\"Created container {}\", containerName);\n+          }\n+        } catch (BlobStorageException ex) {\n+          if (ex.getErrorCode() != BlobErrorCode.CONTAINER_ALREADY_EXISTS) {\n+            logger.error(\"Failed to create container {}\", containerName);\n+            throw ex;\n+          }\n+        }\n+        knownContainers.add(containerName);\n+      }\n+    }\n+    return containerClient;\n+  }\n+\n+  /**\n+   * Create the {@link BlobServiceClient} object.\n+   * @param {@link CloudConfig} object.\n+   * @param {@link AzureCloudConfig} object.\n+   * @return {@link BlobServiceClient} object.\n+   */\n+  protected BlobServiceClient createBlobStorageClient() {\n+    validateABSAuthConfigs(azureCloudConfig);\n+    Configuration storageConfiguration = new Configuration();\n+    // Check for network proxy\n+    ProxyOptions proxyOptions = (cloudConfig.vcrProxyHost == null) ? null : new ProxyOptions(ProxyOptions.Type.HTTP,\n+        new InetSocketAddress(cloudConfig.vcrProxyHost, cloudConfig.vcrProxyPort));\n+    if (proxyOptions != null) {\n+      logger.info(\"Using proxy: {}:{}\", cloudConfig.vcrProxyHost, cloudConfig.vcrProxyPort);\n+    }\n+    HttpClient client = new NettyAsyncHttpClientBuilder().proxy(proxyOptions).build();\n+\n+    // Note: retry decisions are made at CloudBlobStore level.  Configure storageClient with no retries.\n+    RequestRetryOptions noRetries = new RequestRetryOptions(RetryPolicyType.FIXED, 1, null, null, null, null);\n+    try {\n+      return buildBlobServiceClient(client, storageConfiguration, noRetries, azureCloudConfig);\n+    } catch (MalformedURLException | InterruptedException | ExecutionException ex) {\n+      logger.error(\"Error building ABS blob service client: {}\", ex.getMessage());\n+      throw new IllegalStateException(ex);\n+    }\n+  }\n+\n+  /**\n+   * Set the references for storage and blob clients atomically. Note this method is not thread safe and must always be\n+   * called within a thread safe context.\n+   * @param blobServiceClient {@link BlobServiceClient} object.\n+   */\n+  protected void setClientReferences(BlobServiceClient blobServiceClient) {\n+    storageClientRef.set(blobServiceClient);\n+    blobBatchClientRef.set(new BlobBatchClientBuilder(storageClientRef.get()).buildClient());\n+  }\n+\n+  /**\n+   * Execute the storage client operation represented by {@code operation}\n+   * @param operation {@link Callable} representing the operation.\n+   * @param <T> type of return value.\n+   * @return the return value of the operation.\n+   * @throws BlobStorageException\n+   */\n+  private <T> T doStorageClientOperation(Callable<T> operation) {\n+    int attempts = 0;\n+    T result = null;\n+    while (attempts <= 1) {\n+      attempts++;\n+      try {\n+        result = operation.call();\n+        break;\n+      } catch (BlobStorageException bsEx) {\n+        if (attempts == 1 && tryHandleExceptionAndHintRetry(bsEx)) {\n+          logger.info(\"Retrying blob store operation due to expired token\");\n+          continue;\n+        }\n+        throw bsEx;\n+      } catch (Exception ex) {\n+        // this should never happen.\n+        throw new IllegalStateException(\"Unknown blob storage exception\", ex);\n+      }\n+    }\n+    return result;\n+  }\n+\n+  /**\n+   * Validate that all the required configs for ABS authentication are present.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   */\n+  protected abstract void validateABSAuthConfigs(AzureCloudConfig azureCloudConfig);\n+\n+  /**\n+   * Build {@link BlobServiceClient}.\n+   * @param httpClient {@link HttpClient} object.\n+   * @param configuration {@link Configuration} object.\n+   * @param retryOptions {@link RetryOptions} object.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @return {@link BlobServiceClient} object.\n+   */\n+  protected abstract BlobServiceClient buildBlobServiceClient(HttpClient httpClient, Configuration configuration,\n+      RequestRetryOptions retryOptions, AzureCloudConfig azureCloudConfig)\n+      throws MalformedURLException, InterruptedException, ExecutionException;\n+\n+  /**\n+   * Check if the exception can be handled and return a flag indicating if it can be retried.\n+   * Note that if this method changes state of this class, then it should do it in a thread safe way.\n+   * @param blobStorageException {@link BlobStorageException} object.\n+   * @return true if the operation can be retried. false otherwise.\n+   */\n+  protected abstract boolean tryHandleExceptionAndHintRetry(BlobStorageException blobStorageException);", "originalCommit": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyODYyNg==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521628626", "bodyText": "fixed. Changed the name to handleExceptionAndHintRetry.", "author": "ankagrawal", "createdAt": "2020-11-11T20:46:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyOTQ3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzMTc2NA==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521031764", "bodyText": "If the token was not expired, should we still retry?  What if it's a non-transient permission issue?", "author": "lightningrob", "createdAt": "2020-11-11T02:22:54Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/ADAuthBasedStorageClient.java", "diffHunk": "@@ -87,4 +121,22 @@ private IAuthenticationResult getAccessTokenByClientCredentialGrant(AzureCloudCo\n         ClientCredentialParameters.builder(Collections.singleton(azureCloudConfig.azureStorageScope)).build();\n     return app.acquireToken(clientCredentialParam).get();\n   }\n+\n+  @Override\n+  protected boolean tryHandleExceptionAndHintRetry(BlobStorageException blobStorageException) {\n+    // If the exception has status code 403, refresh the token and create a new storage client with the new token.\n+    if (blobStorageException.getStatusCode() == HttpStatus.SC_FORBIDDEN) {\n+      synchronized (this) {\n+        // check if the access token has expired before refreshing the token. This is done to prevent multiple threads\n+        // to attempt token refresh at the same time. It is expected that as a result of token refresh, accessTokenRef\n+        // will updated with the new token.\n+        if (accessTokenRef.get().isExpired()) {\n+          BlobServiceClient blobServiceClient = createBlobStorageClient();\n+          setClientReferences(blobServiceClient);\n+        }\n+      }\n+      return true;", "originalCommit": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyMDkwOA==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521620908", "bodyText": "The retry happens only once. So even if it is a non-transient issue, the second retry will fail.\nWhen the token has expired, and while its being refreshed, multiple threads could be calling the ABS APIs. That means multiple threads might get FORBIDDEN exception, while only one of the threads is still refreshing the token. Since we want only one thread to refresh the token, we want other threads to go through retry at least once, even if they might actually find that the token is not expired, because the unexpired token might be due to the recently refreshed token.", "author": "ankagrawal", "createdAt": "2020-11-11T20:31:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzMTc2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzMzg5NA==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521033894", "bodyText": "It's kind of unconventional to instantiate impl's instead of factories, but I'm not strongly opposed to it.", "author": "lightningrob", "createdAt": "2020-11-11T02:24:56Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureBlobDataAccessor.java", "diffHunk": "@@ -93,24 +84,28 @@ public AzureBlobDataAccessor(CloudConfig cloudConfig, AzureCloudConfig azureClou\n     uploadTimeout = Duration.ofMillis(cloudConfig.cloudUploadRequestTimeout);\n     batchTimeout = Duration.ofMillis(cloudConfig.cloudBatchRequestTimeout);\n \n-    StorageClientFactory storageClientFactory = Utils.getObj(azureCloudConfig.azureStorageClientFactoryClass);\n-    storageClient = storageClientFactory.createBlobStorageClient(cloudConfig, azureCloudConfig);\n-    blobBatchClient = new BlobBatchClientBuilder(storageClient).buildClient();\n+    storageClient =\n+        Utils.getObj(azureCloudConfig.azureStorageClientClass, azureCloudConfig, cloudConfig, blobLayoutStrategy);\n   }\n \n   /**\n    * Test constructor\n-   * @param storageClient the {@link BlobServiceClient} to use.\n+   * @param blobServiceClient the {@link BlobServiceClient} to use.\n    * @param blobBatchClient the {@link BlobBatchClient} to use.\n    * @param clusterName the cluster name to use.\n    * @param azureMetrics the {@link AzureMetrics} to use.\n    */\n-  AzureBlobDataAccessor(BlobServiceClient storageClient, BlobBatchClient blobBatchClient, String clusterName,\n+  AzureBlobDataAccessor(BlobServiceClient blobServiceClient, BlobBatchClient blobBatchClient, String clusterName,\n       AzureMetrics azureMetrics) {\n-    this.storageClient = storageClient;\n     this.blobLayoutStrategy = new AzureBlobLayoutStrategy(clusterName);\n+    try {\n+      this.storageClient =\n+          Utils.getObj(AzureCloudConfig.DEFAULT_AZURE_STORAGE_CLIENT_CLASS, blobServiceClient, blobBatchClient,", "originalCommit": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyMTE5OA==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521621198", "bodyText": "Yeah, I just couldn't see any reason to create extra factories in this case.", "author": "ankagrawal", "createdAt": "2020-11-11T20:32:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzMzg5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzNzQxMw==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521037413", "bodyText": "Nit: cloudConfig before azureCloudConfig to be consistent.", "author": "lightningrob", "createdAt": "2020-11-11T02:30:01Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/ConnectionStringBasedStorageClient.java", "diffHunk": "@@ -17,13 +17,37 @@\n import com.azure.core.util.Configuration;\n import com.azure.storage.blob.BlobServiceClient;\n import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.batch.BlobBatchClient;\n+import com.azure.storage.blob.models.BlobStorageException;\n import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.github.ambry.config.CloudConfig;\n \n \n /**\n- * {@link StorageClientFactory} implementation based on connection string authentication.\n+ * {@link StorageClient} implementation based on connection string authentication.\n  */\n-public class ConnectionStringBasedStorageClientFactory extends StorageClientFactory {\n+public class ConnectionStringBasedStorageClient extends StorageClient {\n+\n+  /**\n+   * Constructor for {@link ConnectionStringBasedStorageClient}.\n+   * @param azureCloudConfig {@link AzureCloudConfig} object.\n+   * @param cloudConfig {@link CloudConfig} object.\n+   */\n+  public ConnectionStringBasedStorageClient(AzureCloudConfig azureCloudConfig, CloudConfig cloudConfig,", "originalCommit": "d79e254009d53d839cf5dc1f9d1e8fa533e917e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyNjQ2NQ==", "url": "https://github.com/linkedin/ambry/pull/1688#discussion_r521626465", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-11-11T20:42:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAzNzQxMw=="}], "type": "inlineReview"}, {"oid": "2a76a3745f5f4725c841eafb6bbda9e96e323185", "url": "https://github.com/linkedin/ambry/commit/2a76a3745f5f4725c841eafb6bbda9e96e323185", "message": "Address review comments", "committedDate": "2020-11-11T20:57:13Z", "type": "commit"}, {"oid": "85ee1f77b215135a78e28010a4321933216c26b6", "url": "https://github.com/linkedin/ambry/commit/85ee1f77b215135a78e28010a4321933216c26b6", "message": "Add metrics", "committedDate": "2020-11-12T08:52:22Z", "type": "commit"}, {"oid": "16d19c4ba19a7bd0a45ae565123e0f2cce2b1d90", "url": "https://github.com/linkedin/ambry/commit/16d19c4ba19a7bd0a45ae565123e0f2cce2b1d90", "message": "Fix test", "committedDate": "2020-11-12T19:16:02Z", "type": "commit"}]}