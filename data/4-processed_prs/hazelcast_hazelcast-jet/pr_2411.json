{"pr_number": 2411, "pr_title": "Suspend jobs on failure", "pr_createdAt": "2020-07-21T09:07:36Z", "pr_url": "https://github.com/hazelcast/hazelcast-jet/pull/2411", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNDgwNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458134805", "bodyText": "It's not about \"streaming jobs\" but about \"fault-tolerant jobs\"", "author": "viliam-durina", "createdAt": "2020-07-21T14:20:54Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU1NjU5Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r465556596", "bodyText": "Ok, I see your point, but this feature is basically for jobs which you can't just restart and maybe \"streaming jobs\" communicates that better.", "author": "jbartok", "createdAt": "2020-08-05T08:20:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNDgwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU4MTY2OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r465581668", "bodyText": "Most of the time batch jobs are not configured to be fault tolerant and streaming jobs are. We don't even support fault-tolerant batch jobs - you can enable it, but it's broken. But we should be precise.", "author": "viliam-durina", "createdAt": "2020-08-05T09:03:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNDgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNTUwMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458135500", "bodyText": "Same here, non-fault-tolerant streaming can be simple resubmitted, fault-tolerant can't without losing the state.", "author": "viliam-durina", "createdAt": "2020-07-21T14:21:45Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU1Njg4Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r465556882", "bodyText": "I'll make it more explicit.", "author": "jbartok", "createdAt": "2020-08-05T08:21:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNTUwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNTk2Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458135963", "bodyText": "we can be more specific: significant loss -> loss of computation state", "author": "viliam-durina", "createdAt": "2020-07-21T14:22:20Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNjQwMQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458136401", "bodyText": "i would say to only ever fail if the user requests so.", "author": "viliam-durina", "createdAt": "2020-07-21T14:22:52Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUyNzI2Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r475527263", "bodyText": "After we have agreed that processors, as they are now, can't really deal with their internal errors and resume work correctly, this statement doesn't seem realistic to me.", "author": "jbartok", "createdAt": "2020-08-24T11:15:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNjQwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNzEzNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458137137", "bodyText": "unexpected null value in the input is more illustrative.", "author": "viliam-durina", "createdAt": "2020-07-21T14:23:46Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNzQ5OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458137499", "bodyText": "not lost, but deleted.", "author": "viliam-durina", "createdAt": "2020-07-21T14:24:13Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNzk2Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458137963", "bodyText": "no dash: \"breaking-change\"", "author": "viliam-durina", "createdAt": "2020-07-21T14:24:50Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzOTg2NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458139865", "bodyText": "We're not notifying the client: the client is not listening. We provide means for the client to get the error.", "author": "viliam-durina", "createdAt": "2020-07-21T14:27:16Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE1MzExNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458153114", "bodyText": "This won't work. Job.join() returns only after the job completes, it doesn't return when the job is suspended.\nI would suggest to not introduce a new status, but to add a method String getSuspensionCause(), which will return Requested by user if suspended due to a user request or it will return the exception with stack tract as a string if the job was suspended due to an error. If the job is not suspended, it can throw or return Job not suspended.\nAnd why use string and not the exception itself? Because the client might not have the exception class.", "author": "viliam-durina", "createdAt": "2020-07-21T14:44:07Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUzOTUwMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r475539502", "bodyText": "Hmm... ok, but that's a bit shady... Since join is pretty much irrelevant for streaming jobs, how about we introduce another similar operation, which would be more useful? Something like Job.track() or Job.monitor(), which would return when the streaming job is suspended? (Probably the choice of names is terrible, but you get the idea.) Seems cleaner to me.", "author": "jbartok", "createdAt": "2020-08-24T11:40:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE1MzExNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE1MzYxNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458153614", "bodyText": "loose -> lose", "author": "viliam-durina", "createdAt": "2020-07-21T14:44:44Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE1NDM4MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458154380", "bodyText": "loose -> lose", "author": "viliam-durina", "createdAt": "2020-07-21T14:45:43Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE1NTU4OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458155588", "bodyText": "We can say that the state for non-snapshotted jobs is immutable. The state is the DAG (Pipeline) and the config. A suspended job can be resumed from the mancenter, a failed job must be resubmitted from a java client.", "author": "viliam-durina", "createdAt": "2020-07-21T14:47:18Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do\n+jobs have state outside snapshots?\n+\n+Plus there is not much to gain by not allowing this feature for\n+\"stateless\" jobs... Maybe we should not discriminate on these grounds.", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE1Njc2MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458156760", "bodyText": "Stream/batch distinction isn't important hare, FT/non-FT is. We discussed non-FT jobs above, this chapter can be removed.", "author": "viliam-durina", "createdAt": "2020-07-21T14:48:44Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do\n+jobs have state outside snapshots?\n+\n+Plus there is not much to gain by not allowing this feature for\n+\"stateless\" jobs... Maybe we should not discriminate on these grounds.\n+\n+## Batch jobs\n+\n+Batch jobs can always just be restarted, as the mantra goes. But still,", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE1OTIwMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458159202", "bodyText": "I would rather discuss how enterprise users benefit from this: they can cancel the suspended job with exported snapshot, fix the DAG and resubmit it and preserve the state. We don't need to discuss why some feature isn't OS here...", "author": "viliam-durina", "createdAt": "2020-07-21T14:51:51Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do\n+jobs have state outside snapshots?\n+\n+Plus there is not much to gain by not allowing this feature for\n+\"stateless\" jobs... Maybe we should not discriminate on these grounds.\n+\n+## Batch jobs\n+\n+Batch jobs can always just be restarted, as the mantra goes. But still,\n+they can take a long time to restart, so we probably should allow them\n+to work in this way too.\n+\n+As with other aspects mentioned above we don't gain anything by\n+disabling this functionality for batch jobs.\n+\n+## Job upgrade\n+\n+Even if we enable this feature some fixable problems won't be actually\n+possible to handle in open-source Jet, because they might require\n+pipeline code change and that will need snapshot export and job upgrades\n+which are enterprise features.\n+\n+Not sure what we can do about this, besides being aware of it.", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2MDY4Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458160683", "bodyText": "loosing -> losing", "author": "viliam-durina", "createdAt": "2020-07-21T14:53:48Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do\n+jobs have state outside snapshots?\n+\n+Plus there is not much to gain by not allowing this feature for\n+\"stateless\" jobs... Maybe we should not discriminate on these grounds.\n+\n+## Batch jobs\n+\n+Batch jobs can always just be restarted, as the mantra goes. But still,\n+they can take a long time to restart, so we probably should allow them\n+to work in this way too.\n+\n+As with other aspects mentioned above we don't gain anything by\n+disabling this functionality for batch jobs.\n+\n+## Job upgrade\n+\n+Even if we enable this feature some fixable problems won't be actually\n+possible to handle in open-source Jet, because they might require\n+pipeline code change and that will need snapshot export and job upgrades\n+which are enterprise features.\n+\n+Not sure what we can do about this, besides being aware of it.\n+\n+## Failure snapshot\n+\n+Ideally, when an error happens, which will be handled by suspending the\n+job, we would prefer to make all processors take a snapshot right then\n+so that we can later resume execution from the most advanced state. But\n+this, unfortunately doesn't seem possible.\n+\n+Snapshots can be taken only when all processors are functioning properly\n+(due to the nature of how distributed snapshots happen).\n+\n+But, even some slightly obsolete snapshot should be better than loosing", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2MzI5Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458163293", "bodyText": "loosing -> losing", "author": "viliam-durina", "createdAt": "2020-07-21T14:57:03Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do\n+jobs have state outside snapshots?\n+\n+Plus there is not much to gain by not allowing this feature for\n+\"stateless\" jobs... Maybe we should not discriminate on these grounds.\n+\n+## Batch jobs\n+\n+Batch jobs can always just be restarted, as the mantra goes. But still,\n+they can take a long time to restart, so we probably should allow them\n+to work in this way too.\n+\n+As with other aspects mentioned above we don't gain anything by\n+disabling this functionality for batch jobs.\n+\n+## Job upgrade\n+\n+Even if we enable this feature some fixable problems won't be actually\n+possible to handle in open-source Jet, because they might require\n+pipeline code change and that will need snapshot export and job upgrades\n+which are enterprise features.\n+\n+Not sure what we can do about this, besides being aware of it.\n+\n+## Failure snapshot\n+\n+Ideally, when an error happens, which will be handled by suspending the\n+job, we would prefer to make all processors take a snapshot right then\n+so that we can later resume execution from the most advanced state. But\n+this, unfortunately doesn't seem possible.\n+\n+Snapshots can be taken only when all processors are functioning properly\n+(due to the nature of how distributed snapshots happen).\n+\n+But, even some slightly obsolete snapshot should be better than loosing\n+the whole computation, so I guess this is a weakness we can live with.\n+\n+## In-processor error handling\n+\n+This functionality should be a solution of last resort, meaning that all\n+errors that can be handled without user intervention should be handled\n+automatically. For example sources and sinks loosing connection to", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2NDI4OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458164289", "bodyText": "attempt a back-off after a certain number of tries\n->\nattempt a back off (no dash) after a certain number of tries attempts", "author": "viliam-durina", "createdAt": "2020-07-21T14:58:22Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do\n+jobs have state outside snapshots?\n+\n+Plus there is not much to gain by not allowing this feature for\n+\"stateless\" jobs... Maybe we should not discriminate on these grounds.\n+\n+## Batch jobs\n+\n+Batch jobs can always just be restarted, as the mantra goes. But still,\n+they can take a long time to restart, so we probably should allow them\n+to work in this way too.\n+\n+As with other aspects mentioned above we don't gain anything by\n+disabling this functionality for batch jobs.\n+\n+## Job upgrade\n+\n+Even if we enable this feature some fixable problems won't be actually\n+possible to handle in open-source Jet, because they might require\n+pipeline code change and that will need snapshot export and job upgrades\n+which are enterprise features.\n+\n+Not sure what we can do about this, besides being aware of it.\n+\n+## Failure snapshot\n+\n+Ideally, when an error happens, which will be handled by suspending the\n+job, we would prefer to make all processors take a snapshot right then\n+so that we can later resume execution from the most advanced state. But\n+this, unfortunately doesn't seem possible.\n+\n+Snapshots can be taken only when all processors are functioning properly\n+(due to the nature of how distributed snapshots happen).\n+\n+But, even some slightly obsolete snapshot should be better than loosing\n+the whole computation, so I guess this is a weakness we can live with.\n+\n+## In-processor error handling\n+\n+This functionality should be a solution of last resort, meaning that all\n+errors that can be handled without user intervention should be handled\n+automatically. For example sources and sinks loosing connection to\n+external systems should attempt reconnection internally, attempt a\n+back-off after a certain number of tries, in general have their internal", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2ODAwNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r458168007", "bodyText": "Here we can distinguish streaming and batch sources. Streaming sources are typically run in a fault-tolerant job, batch sources are not. So streaming sources should attempt to reconnect as much as possible or throw RestartableException. Batch sources, on the other hand, should not attempt to retry. When you process a remote file and that file is not accessible, there's no point in retrying. Users would be surprised to submit such a job, see it running, and then, after an hour, figure out that the job just keeps trying to connect.", "author": "viliam-durina", "createdAt": "2020-07-21T15:03:11Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do\n+jobs have state outside snapshots?\n+\n+Plus there is not much to gain by not allowing this feature for\n+\"stateless\" jobs... Maybe we should not discriminate on these grounds.\n+\n+## Batch jobs\n+\n+Batch jobs can always just be restarted, as the mantra goes. But still,\n+they can take a long time to restart, so we probably should allow them\n+to work in this way too.\n+\n+As with other aspects mentioned above we don't gain anything by\n+disabling this functionality for batch jobs.\n+\n+## Job upgrade\n+\n+Even if we enable this feature some fixable problems won't be actually\n+possible to handle in open-source Jet, because they might require\n+pipeline code change and that will need snapshot export and job upgrades\n+which are enterprise features.\n+\n+Not sure what we can do about this, besides being aware of it.\n+\n+## Failure snapshot\n+\n+Ideally, when an error happens, which will be handled by suspending the\n+job, we would prefer to make all processors take a snapshot right then\n+so that we can later resume execution from the most advanced state. But\n+this, unfortunately doesn't seem possible.\n+\n+Snapshots can be taken only when all processors are functioning properly\n+(due to the nature of how distributed snapshots happen).\n+\n+But, even some slightly obsolete snapshot should be better than loosing\n+the whole computation, so I guess this is a weakness we can live with.\n+\n+## In-processor error handling\n+\n+This functionality should be a solution of last resort, meaning that all\n+errors that can be handled without user intervention should be handled\n+automatically. For example sources and sinks loosing connection to", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYwODk5NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r465608995", "bodyText": "I don't agree with Batch sources, on the other hand, should not attempt to retry..\nIf you have a batch job which takes several days to finish, you don't want the job to fail in the middle because of some intermittent network hiccup, which can be easily handled by a retry couple of seconds later.", "author": "frant-hartm", "createdAt": "2020-08-05T09:51:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2ODAwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY4MDQ4Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r465680483", "bodyText": "Yeah, I agree. But for a streaming source it's a must. For a batch source it's nice to have.", "author": "viliam-durina", "createdAt": "2020-08-05T12:11:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2ODAwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjIxMzQ2OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r476213468", "bodyText": "Source behaviour will be independent of this feature. I think we can and should make their behaviour configurable. They should/will be able to attempt retries to a certain degree, but at the end, their solution of last resort will be throwing an exception.", "author": "jbartok", "createdAt": "2020-08-25T06:45:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2ODAwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYwNTQ3OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r465605479", "bodyText": "They certainly hold resources. Is Processor#close() called when suspending a job?", "author": "frant-hartm", "createdAt": "2020-08-05T09:45:31Z", "path": "site/docs/design-docs/012-improved-error-handling.md", "diffHunk": "@@ -0,0 +1,113 @@\n+---\n+title: 012 - Improved Error Tolerance of Streaming Jobs\n+description: Make stream jobs capable of surviving errors with fixable causes.\n+---\n+\n+*Target Release*: 4.3\n+\n+## Goal\n+\n+Since streaming jobs can't simply be re-run, like batch ones, having\n+them fail can result in significant loss. We want them to be as\n+resilient as possible and only ever really fail due to the most severe\n+of causes.\n+\n+Right now any kind of failure, like exceptions in user code or thrown\n+by sources or sinks will stop the execution of a job. Moreover, not only\n+does execution stop, snapshots of the job are also lost, so even if\n+the root problem can be fixed, there is no way to recover or resume\n+the failed job.\n+\n+We want to improve on this by only suspending jobs with such failures\n+and preserving their snapshots.\n+\n+## Breaking-change\n+\n+It might be argued that suspending a job on failure, instead of letting\n+it fail completely is a breaking-change, as far as behaviour is\n+concerned.\n+\n+One might also argue that it's broken behaviour which just took a long\n+time to fix.\n+\n+Anyways, to be safe we might preserve the current behaviour as default\n+and make the suggested changes optional. Maybe as a new element in\n+`JobConfig`, called `suspend_on_failure`, disabled unless otherwise\n+specified.\n+\n+## Notify client\n+\n+When we suspend a job due to a failure we need to notify the client that\n+submitted it and give enough information to facilitate the repair of the\n+underlying root cause.\n+\n+For this reason we should introduce a new `JobStatus`, called\n+`SUSPENDED_DUE_TO_ERROR` and provide details in the `Exception` set in\n+the `CompletableFuture` returned by `job.getFuture()` (also used by\n+`job.join()`).\n+\n+Since we will use a new state we need to make sure that it behaves\n+exactly like the regular suspend: the job can be cancelled, snapshots\n+can be exported (enterprise feature) and so on.\n+\n+## When to use\n+\n+Do we always want to suspend jobs when there is a failure? It doesn't\n+make sense to do it for failures that can't be remedied, but which are\n+those? Hard to tell, hard to exhaust all the possibilities.\n+\n+Since the suspend feature will be optional and will need explicit\n+setting, it's probably ok to do it for any failure (not just some\n+whitelisted ones). There is nothing to loose anyways. If the failure\n+can't be remedied, then the user can just cancel the job. They will be\n+no worse off than if it had failed automatically.\n+\n+## Processing guarantees\n+\n+Should we enable this feature only for jobs with processing guarantees?\n+The answer is probably yes. Jobs without a processing guarantee don't\n+save snapshots, so there's not much state to loose. But is this true? Do\n+jobs have state outside snapshots?", "originalCommit": "c71fedd96778cf2212d0dcbb80ded9ea6e3ccc3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY3OTIxNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r465679217", "bodyText": "Is Processor#close() called when suspending a job?\n\nYes.", "author": "viliam-durina", "createdAt": "2020-08-05T12:08:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYwNTQ3OQ=="}], "type": "inlineReview"}, {"oid": "f89b1d2c689f75f901063942f3545fe71d6a78cb", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f89b1d2c689f75f901063942f3545fe71d6a78cb", "message": "Write design doc draft", "committedDate": "2020-08-24T11:01:14Z", "type": "commit"}, {"oid": "f89b1d2c689f75f901063942f3545fe71d6a78cb", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f89b1d2c689f75f901063942f3545fe71d6a78cb", "message": "Write design doc draft", "committedDate": "2020-08-24T11:01:14Z", "type": "forcePushed"}, {"oid": "af9ffef845994d0bb1f9ba05b3c73d9fc0879980", "url": "https://github.com/hazelcast/hazelcast-jet/commit/af9ffef845994d0bb1f9ba05b3c73d9fc0879980", "message": "Address review concerns", "committedDate": "2020-08-25T06:51:12Z", "type": "commit"}, {"oid": "d85d45a68d36320cf27eca8b4ee0868d4c5b030e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/d85d45a68d36320cf27eca8b4ee0868d4c5b030e", "message": "Implement suspend-on-failure mechanics", "committedDate": "2020-09-02T11:05:36Z", "type": "commit"}, {"oid": "13c06a49cfd08a09dceed895c90dfb673737b110", "url": "https://github.com/hazelcast/hazelcast-jet/commit/13c06a49cfd08a09dceed895c90dfb673737b110", "message": "Review design document", "committedDate": "2020-09-03T10:04:52Z", "type": "commit"}, {"oid": "bfec42cd4c2c52f9657219ddcff29b013144338c", "url": "https://github.com/hazelcast/hazelcast-jet/commit/bfec42cd4c2c52f9657219ddcff29b013144338c", "message": "Fix grammar, improve wording", "committedDate": "2020-09-03T14:18:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk4NDA2OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r482984069", "bodyText": "writeUTF argument must be non-null, see 4 lines above.", "author": "viliam-durina", "createdAt": "2020-09-03T13:38:13Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/JobExecutionRecord.java", "diffHunk": "@@ -251,7 +262,7 @@ public void writeData(ObjectDataOutput out) throws IOException {\n         out.writeObject(lastSnapshotFailure);\n         out.writeObject(snapshotStats);\n         out.writeObject(exportedSnapshotMapName);\n-        out.writeBoolean(suspended);\n+        out.writeUTF(suspensionCause);", "originalCommit": "13c06a49cfd08a09dceed895c90dfb673737b110", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk4NTUzMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r482985532", "bodyText": "This will fail with current master after #2484 was merged.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            null,\n          \n          \n            \n                            jobRecord -> { throw new IllegalStateException(\"Job not suspended\"); },", "author": "viliam-durina", "createdAt": "2020-09-03T13:40:22Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/JobCoordinationService.java", "diffHunk": "@@ -421,6 +422,36 @@ public void reset() {\n         );\n     }\n \n+    /**\n+     * Returns the reason why this job has been suspended in a human readable\n+     * form.\n+     * <p>\n+     * Fails with {@link JobNotFoundException} if the requested job is not found.\n+     * <p>\n+     * Fails with {@link IllegalStateException} if the requested job is not\n+     * actually in a suspended state.\n+     */\n+    public CompletableFuture<String> getJobSuspensionCause(long jobId) {\n+        FunctionEx<JobExecutionRecord, String> jobExecutionRecordHandler = jobExecutionRecord -> {\n+            String cause = jobExecutionRecord.getSuspensionCause();\n+            if (cause == null) {\n+                throw new IllegalStateException(\"Job not suspended\");\n+            }\n+            return cause;\n+        };\n+        return callWithJob(jobId,\n+                mc -> {\n+                    JobExecutionRecord jobExecutionRecord = mc.jobExecutionRecord();\n+                    return jobExecutionRecordHandler.apply(jobExecutionRecord);\n+                },\n+                (FunctionEx<JobResult, String>) o -> {\n+                    throw new IllegalStateException(\"Job not suspended\");\n+                },\n+                null,", "originalCommit": "13c06a49cfd08a09dceed895c90dfb673737b110", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5MDk2NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r482990964", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                mc.jobExecutionRecord().setSuspended(\"Due to failure:\\n\" + ExceptionUtil.stackTraceToString(failure));\n          \n          \n            \n                                mc.jobExecutionRecord().setSuspended(\"Execution failure:\\n\" + ExceptionUtil.stackTraceToString(failure));", "author": "viliam-durina", "createdAt": "2020-09-03T13:47:48Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/MasterJobContext.java", "diffHunk": "@@ -638,7 +639,11 @@ void finalizeJob(@Nullable Throwable failure) {\n                         && mc.jobConfig().getProcessingGuarantee() != NONE\n                 ) {\n                     mc.setJobStatus(SUSPENDED);\n-                    mc.jobExecutionRecord().setSuspended(true);\n+                    mc.jobExecutionRecord().setSuspended(\"Requested by user\");\n+                    nonSynchronizedAction = () -> mc.writeJobExecutionRecord(false);\n+                } else if (failure != null && !wasCancelled && mc.jobConfig().isSuspendOnFailure()) {\n+                    mc.setJobStatus(SUSPENDED);\n+                    mc.jobExecutionRecord().setSuspended(\"Due to failure:\\n\" + ExceptionUtil.stackTraceToString(failure));", "originalCommit": "13c06a49cfd08a09dceed895c90dfb673737b110", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5OTM3OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r482999378", "bodyText": "We can simply join the job:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    DAG dag = new DAG().vertex(new Vertex(\"test\", new MockPS(NoOutputSourceP::new, MEMBER_COUNT)));\n          \n          \n            \n                    Job job = jet().newJob(dag, jobConfig);\n          \n          \n            \n                    assertJobStatusEventually(job, RUNNING);\n          \n          \n            \n            \n          \n          \n            \n                    // When\n          \n          \n            \n                    NoOutputSourceP.proceedLatch.countDown();\n          \n          \n            \n                    assertJobStatusEventually(job, COMPLETED);\n          \n          \n            \n                    DAG dag = new DAG().vertex(new Vertex(\"test\", Processors.noopP()));\n          \n          \n            \n                    Job job = jet().newJob(dag, jobConfig);\n          \n          \n            \n            \n          \n          \n            \n                    // When\n          \n          \n            \n                    job.join();\n          \n          \n            \n                    assertEquals(job.getStatus(), COMPLETED);", "author": "viliam-durina", "createdAt": "2020-09-03T13:58:54Z", "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/core/SuspendExecutionOnFailureTest.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.core;\n+\n+import com.hazelcast.jet.Job;\n+import com.hazelcast.jet.TestInClusterSupport;\n+import com.hazelcast.jet.config.JobConfig;\n+import com.hazelcast.jet.core.TestProcessors.ListSource;\n+import com.hazelcast.jet.core.TestProcessors.MockP;\n+import com.hazelcast.jet.core.TestProcessors.MockPMS;\n+import com.hazelcast.jet.core.TestProcessors.MockPS;\n+import com.hazelcast.jet.core.TestProcessors.NoOutputSourceP;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static com.hazelcast.jet.core.Edge.between;\n+import static com.hazelcast.jet.core.JobStatus.COMPLETED;\n+import static com.hazelcast.jet.core.JobStatus.RUNNING;\n+import static com.hazelcast.jet.core.JobStatus.SUSPENDED;\n+import static java.util.Collections.singletonList;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class SuspendExecutionOnFailureTest extends TestInClusterSupport {\n+\n+    private static final Throwable MOCK_ERROR = new AssertionError(\"mock error\");\n+\n+    private JobConfig jobConfig;\n+\n+    @Before\n+    public void before() {\n+        jobConfig = new JobConfig().setSuspendOnFailure(true);\n+        TestProcessors.reset(0);\n+    }\n+\n+    @Test\n+    public void when_jobRunning_then_suspensionCauseThrows() {\n+        // Given\n+        DAG dag = new DAG().vertex(new Vertex(\"test\", new MockPS(NoOutputSourceP::new, MEMBER_COUNT)));\n+        Job job = jet().newJob(dag, jobConfig);\n+        assertJobStatusEventually(job, RUNNING);\n+\n+        // Then\n+        assertThatThrownBy(job::getSuspensionCause)\n+                .isInstanceOf(IllegalStateException.class)\n+                .hasMessage(\"Job not suspended\");\n+\n+        cancelAndJoin(job);\n+    }\n+\n+    @Test\n+    public void when_jobCompleted_then_suspensionCauseThrows() {\n+        // Given\n+        DAG dag = new DAG().vertex(new Vertex(\"test\", new MockPS(NoOutputSourceP::new, MEMBER_COUNT)));\n+        Job job = jet().newJob(dag, jobConfig);\n+        assertJobStatusEventually(job, RUNNING);\n+\n+        // When\n+        NoOutputSourceP.proceedLatch.countDown();\n+        assertJobStatusEventually(job, COMPLETED);", "originalCommit": "13c06a49cfd08a09dceed895c90dfb673737b110", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5OTk1NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r482999955", "bodyText": "No need to wrap in MockPS:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    DAG dag = new DAG().vertex(new Vertex(\"test\", new MockPS(NoOutputSourceP::new, MEMBER_COUNT)));\n          \n          \n            \n                    DAG dag = new DAG().vertex(new Vertex(\"test\", () -> new NoOutputSourceP()));", "author": "viliam-durina", "createdAt": "2020-09-03T13:59:41Z", "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/core/SuspendExecutionOnFailureTest.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.core;\n+\n+import com.hazelcast.jet.Job;\n+import com.hazelcast.jet.TestInClusterSupport;\n+import com.hazelcast.jet.config.JobConfig;\n+import com.hazelcast.jet.core.TestProcessors.ListSource;\n+import com.hazelcast.jet.core.TestProcessors.MockP;\n+import com.hazelcast.jet.core.TestProcessors.MockPMS;\n+import com.hazelcast.jet.core.TestProcessors.MockPS;\n+import com.hazelcast.jet.core.TestProcessors.NoOutputSourceP;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static com.hazelcast.jet.core.Edge.between;\n+import static com.hazelcast.jet.core.JobStatus.COMPLETED;\n+import static com.hazelcast.jet.core.JobStatus.RUNNING;\n+import static com.hazelcast.jet.core.JobStatus.SUSPENDED;\n+import static java.util.Collections.singletonList;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class SuspendExecutionOnFailureTest extends TestInClusterSupport {\n+\n+    private static final Throwable MOCK_ERROR = new AssertionError(\"mock error\");\n+\n+    private JobConfig jobConfig;\n+\n+    @Before\n+    public void before() {\n+        jobConfig = new JobConfig().setSuspendOnFailure(true);\n+        TestProcessors.reset(0);\n+    }\n+\n+    @Test\n+    public void when_jobRunning_then_suspensionCauseThrows() {\n+        // Given\n+        DAG dag = new DAG().vertex(new Vertex(\"test\", new MockPS(NoOutputSourceP::new, MEMBER_COUNT)));", "originalCommit": "13c06a49cfd08a09dceed895c90dfb673737b110", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzAwNTYzMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r483005630", "bodyText": "We can use setCompleteError and avoid the source vertex.", "author": "viliam-durina", "createdAt": "2020-09-03T14:07:21Z", "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/core/SuspendExecutionOnFailureTest.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.core;\n+\n+import com.hazelcast.jet.Job;\n+import com.hazelcast.jet.TestInClusterSupport;\n+import com.hazelcast.jet.config.JobConfig;\n+import com.hazelcast.jet.core.TestProcessors.ListSource;\n+import com.hazelcast.jet.core.TestProcessors.MockP;\n+import com.hazelcast.jet.core.TestProcessors.MockPMS;\n+import com.hazelcast.jet.core.TestProcessors.MockPS;\n+import com.hazelcast.jet.core.TestProcessors.NoOutputSourceP;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static com.hazelcast.jet.core.Edge.between;\n+import static com.hazelcast.jet.core.JobStatus.COMPLETED;\n+import static com.hazelcast.jet.core.JobStatus.RUNNING;\n+import static com.hazelcast.jet.core.JobStatus.SUSPENDED;\n+import static java.util.Collections.singletonList;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class SuspendExecutionOnFailureTest extends TestInClusterSupport {\n+\n+    private static final Throwable MOCK_ERROR = new AssertionError(\"mock error\");\n+\n+    private JobConfig jobConfig;\n+\n+    @Before\n+    public void before() {\n+        jobConfig = new JobConfig().setSuspendOnFailure(true);\n+        TestProcessors.reset(0);\n+    }\n+\n+    @Test\n+    public void when_jobRunning_then_suspensionCauseThrows() {\n+        // Given\n+        DAG dag = new DAG().vertex(new Vertex(\"test\", new MockPS(NoOutputSourceP::new, MEMBER_COUNT)));\n+        Job job = jet().newJob(dag, jobConfig);\n+        assertJobStatusEventually(job, RUNNING);\n+\n+        // Then\n+        assertThatThrownBy(job::getSuspensionCause)\n+                .isInstanceOf(IllegalStateException.class)\n+                .hasMessage(\"Job not suspended\");\n+\n+        cancelAndJoin(job);\n+    }\n+\n+    @Test\n+    public void when_jobCompleted_then_suspensionCauseThrows() {\n+        // Given\n+        DAG dag = new DAG().vertex(new Vertex(\"test\", new MockPS(NoOutputSourceP::new, MEMBER_COUNT)));\n+        Job job = jet().newJob(dag, jobConfig);\n+        assertJobStatusEventually(job, RUNNING);\n+\n+        // When\n+        NoOutputSourceP.proceedLatch.countDown();\n+        assertJobStatusEventually(job, COMPLETED);\n+\n+        // Then\n+        assertThatThrownBy(job::getSuspensionCause)\n+                .isInstanceOf(IllegalStateException.class)\n+                .hasMessage(\"Job not suspended\");\n+\n+        job.join();\n+    }\n+\n+    @Test\n+    public void when_jobSuspendedByUser_then_suspensionCauseSaysSo() {\n+        // Given\n+        DAG dag = new DAG().vertex(new Vertex(\"test\", new MockPS(NoOutputSourceP::new, MEMBER_COUNT)));\n+\n+        // When\n+        Job job = jet().newJob(dag, jobConfig);\n+        assertJobStatusEventually(job, RUNNING);\n+        job.suspend();\n+        assertJobStatusEventually(job, SUSPENDED);\n+        assertEquals(\"Requested by user\", job.getSuspensionCause());\n+\n+        cancelAndJoin(job);\n+    }\n+\n+    @Test\n+    public void when_jobSuspendedDueToFailure_then_suspensionCauseDescribeProblem() {\n+        // Given\n+        DAG dag = new DAG();\n+        Vertex source = dag.newVertex(\"source\", ListSource.supplier(singletonList(1)));\n+        Vertex process = dag.newVertex(\"faulty\",\n+                new MockPMS(() -> new MockPS(() -> new MockP().setProcessError(MOCK_ERROR), MEMBER_COUNT)));", "originalCommit": "13c06a49cfd08a09dceed895c90dfb673737b110", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1f4a5d5a54c040d93eeb9bf302cb7c8bc3760f98", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1f4a5d5a54c040d93eeb9bf302cb7c8bc3760f98", "message": "Address review concerns", "committedDate": "2020-09-04T06:16:26Z", "type": "commit"}, {"oid": "0474817f484f77db40f034480d497152507f6beb", "url": "https://github.com/hazelcast/hazelcast-jet/commit/0474817f484f77db40f034480d497152507f6beb", "message": "Merge branch 'master' into suspend-job-on-failure", "committedDate": "2020-09-04T06:16:34Z", "type": "commit"}, {"oid": "25bb61b6aea164bda38eddc2634374a1f5d5c08d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/25bb61b6aea164bda38eddc2634374a1f5d5c08d", "message": "Address review concerns", "committedDate": "2020-09-04T06:52:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQyNjEyOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r483426128", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    dag.newVertex(\"faulty\",\n          \n          \n            \n                            new MockPMS(() -> new MockPS(() -> new MockP().setCompleteError(MOCK_ERROR), MEMBER_COUNT)))\n          \n          \n            \n                    dag.newVertex(\"faulty\", () -> new MockP().setCompleteError(MOCK_ERROR))", "author": "viliam-durina", "createdAt": "2020-09-04T07:00:00Z", "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/core/SuspendExecutionOnFailureTest.java", "diffHunk": "@@ -101,17 +96,16 @@ public void when_jobSuspendedByUser_then_suspensionCauseSaysSo() {\n     public void when_jobSuspendedDueToFailure_then_suspensionCauseDescribeProblem() {\n         // Given\n         DAG dag = new DAG();\n-        Vertex source = dag.newVertex(\"source\", ListSource.supplier(singletonList(1)));\n-        Vertex process = dag.newVertex(\"faulty\",\n-                new MockPMS(() -> new MockPS(() -> new MockP().setProcessError(MOCK_ERROR), MEMBER_COUNT)));\n-        dag.edge(between(source, process));\n+        dag.newVertex(\"faulty\",\n+                new MockPMS(() -> new MockPS(() -> new MockP().setCompleteError(MOCK_ERROR), MEMBER_COUNT)))", "originalCommit": "25bb61b6aea164bda38eddc2634374a1f5d5c08d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQzMDcwMw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2411#discussion_r483430703", "bodyText": "The job can also fail in faulty#1. It actually fails in all processor instances, it's only a matter of chance which one is first:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertTrue(job.getSuspensionCause().startsWith(\"Execution failure:\\n\" +\n          \n          \n            \n                            \"com.hazelcast.jet.JetException: Exception in ProcessorTasklet{faulty#0}: \" +\n          \n          \n            \n                            \"java.lang.AssertionError: mock error\"));\n          \n          \n            \n                    assertThat(job.getSuspensionCause()).matches(\"(?s)Execution failure:\\n\" +\n          \n          \n            \n                            \"com.hazelcast.jet.JetException: Exception in ProcessorTasklet\\\\{faulty#[0-9]}: \" +\n          \n          \n            \n                            \"java.lang.AssertionError: mock error.*\");", "author": "viliam-durina", "createdAt": "2020-09-04T07:10:43Z", "path": "hazelcast-jet-core/src/test/java/com/hazelcast/jet/core/SuspendExecutionOnFailureTest.java", "diffHunk": "@@ -101,17 +96,16 @@ public void when_jobSuspendedByUser_then_suspensionCauseSaysSo() {\n     public void when_jobSuspendedDueToFailure_then_suspensionCauseDescribeProblem() {\n         // Given\n         DAG dag = new DAG();\n-        Vertex source = dag.newVertex(\"source\", ListSource.supplier(singletonList(1)));\n-        Vertex process = dag.newVertex(\"faulty\",\n-                new MockPMS(() -> new MockPS(() -> new MockP().setProcessError(MOCK_ERROR), MEMBER_COUNT)));\n-        dag.edge(between(source, process));\n+        dag.newVertex(\"faulty\",\n+                new MockPMS(() -> new MockPS(() -> new MockP().setCompleteError(MOCK_ERROR), MEMBER_COUNT)))\n+                .localParallelism(1);\n \n         // When\n         Job job = jet().newJob(dag, jobConfig);\n \n         // Then\n         assertJobStatusEventually(job, JobStatus.SUSPENDED);\n-        assertTrue(job.getSuspensionCause().startsWith(\"Due to failure:\\n\" +\n+        assertTrue(job.getSuspensionCause().startsWith(\"Execution failure:\\n\" +\n                 \"com.hazelcast.jet.JetException: Exception in ProcessorTasklet{faulty#0}: \" +\n                 \"java.lang.AssertionError: mock error\"));", "originalCommit": "25bb61b6aea164bda38eddc2634374a1f5d5c08d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ffdcf3b291c6aad4e5cae63810937e391e0af495", "url": "https://github.com/hazelcast/hazelcast-jet/commit/ffdcf3b291c6aad4e5cae63810937e391e0af495", "message": "Address review concerns", "committedDate": "2020-09-04T07:37:19Z", "type": "commit"}]}