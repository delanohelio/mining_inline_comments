{"pr_number": 2620, "pr_title": "Add SQL support", "pr_createdAt": "2020-10-28T16:12:49Z", "pr_url": "https://github.com/hazelcast/hazelcast-jet/pull/2620", "timeline": [{"oid": "454799244ee17b39c872f3e419521f2dadbcf92f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/454799244ee17b39c872f3e419521f2dadbcf92f", "message": "Add SQL support", "committedDate": "2020-10-28T16:11:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDIxNjExMQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r514216111", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                private static final UpsertInjector DISCARDING_INJECTOR = value -> { };", "author": "gierlachg", "createdAt": "2020-10-29T12:22:20Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/keyvalue/KvProjector.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector.keyvalue;\n+\n+import com.hazelcast.jet.sql.impl.inject.UpsertInjector;\n+import com.hazelcast.jet.sql.impl.inject.UpsertTarget;\n+import com.hazelcast.sql.impl.extract.QueryPath;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+\n+import java.util.Map.Entry;\n+\n+import static com.hazelcast.jet.Util.entry;\n+import static com.hazelcast.jet.sql.impl.type.converter.ToConverters.getToConverter;\n+\n+class KvProjector {\n+\n+    private static final UpsertInjector DISCARDING_INJECTOR = value -> { };\n+", "originalCommit": "454799244ee17b39c872f3e419521f2dadbcf92f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDIxNzgzNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r514217835", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                    <!-- FILE --> <!-- TODO: cleanup after File works -->\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.avro</groupId>\n          \n          \n            \n                        <artifactId>avro-mapred</artifactId>\n          \n          \n            \n                        <version>${avro.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.parquet</groupId>\n          \n          \n            \n                        <artifactId>parquet-avro</artifactId>\n          \n          \n            \n                        <version>${parquet.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n            \n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>com.hazelcast.jet</groupId>\n          \n          \n            \n                        <artifactId>hazelcast-jet-hadoop</artifactId>\n          \n          \n            \n                        <version>${project.parent.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.hadoop</groupId>\n          \n          \n            \n                        <artifactId>hadoop-hdfs</artifactId>\n          \n          \n            \n                        <version>${hadoop.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.hadoop</groupId>\n          \n          \n            \n                        <artifactId>hadoop-common</artifactId>\n          \n          \n            \n                        <version>${hadoop.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.hadoop</groupId>\n          \n          \n            \n                        <artifactId>hadoop-mapreduce-client-core</artifactId>\n          \n          \n            \n                        <version>${hadoop.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <!-- Amazon S3 -->\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.hadoop</groupId>\n          \n          \n            \n                        <artifactId>hadoop-aws</artifactId>\n          \n          \n            \n                        <version>${hadoop.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.hadoop</groupId>\n          \n          \n            \n                        <artifactId>hadoop-client</artifactId>\n          \n          \n            \n                        <version>${hadoop.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <!-- Google Cloud Storage -->\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>com.google.cloud.bigdataoss</groupId>\n          \n          \n            \n                        <artifactId>gcs-connector</artifactId>\n          \n          \n            \n                        <version>hadoop2-2.0.0</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <!-- Azure Cloud Storage -->\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.hadoop</groupId>\n          \n          \n            \n                        <artifactId>hadoop-azure</artifactId>\n          \n          \n            \n                        <version>${hadoop.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>\n          \n          \n            \n                    <!-- Azure Data Lake -->\n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>org.apache.hadoop</groupId>\n          \n          \n            \n                        <artifactId>hadoop-azure-datalake</artifactId>\n          \n          \n            \n                        <version>${hadoop.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>", "author": "gierlachg", "createdAt": "2020-10-29T12:25:24Z", "path": "hazelcast-jet-sql/pom.xml", "diffHunk": "@@ -0,0 +1,468 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+  ~\n+  ~ Licensed under the Apache License, Version 2.0 (the \"License\");\n+  ~ you may not use this file except in compliance with the License.\n+  ~ You may obtain a copy of the License at\n+  ~\n+  ~ http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <packaging>jar</packaging>\n+    <name>hazelcast-jet-sql</name>\n+    <description>SQL support for Hazelcast Jet</description>\n+    <url>http://www.hazelcast.com/</url>\n+\n+    <artifactId>hazelcast-jet-sql</artifactId>\n+\n+    <parent>\n+        <groupId>com.hazelcast.jet</groupId>\n+        <artifactId>hazelcast-jet-root</artifactId>\n+        <version>4.4-SNAPSHOT</version>\n+    </parent>\n+\n+    <properties>\n+        <confluent.version>4.1.0</confluent.version>\n+        <parquet.version>1.10.1</parquet.version>\n+    </properties>\n+\n+    <repositories>\n+        <repository>\n+            <id>confluent</id>\n+            <url>https://packages.confluent.io/maven/</url>\n+            <snapshots>\n+                <enabled>false</enabled>\n+            </snapshots>\n+        </repository>\n+    </repositories>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-core</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.hazelcast</groupId>\n+            <artifactId>hazelcast-sql</artifactId>\n+            <version>${hazelcast.version}</version>\n+            <classifier>jar-with-dependencies</classifier>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>com.hazelcast</groupId>\n+                    <artifactId>hazelcast</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <!-- TODO: json & json libs part of sql by default ??? -->\n+        <!-- TODO: how to package i.e. Kafka ??? -->\n+\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-avro</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <!-- KAFKA -->\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-kafka</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.kafka</groupId>\n+            <artifactId>kafka_${scala.version}</artifactId>\n+            <version>${kafka.version}</version>\n+            <scope>provided</scope>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.slf4j</groupId>\n+                    <artifactId>slf4j-log4j12</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.kafka</groupId>\n+            <artifactId>kafka-clients</artifactId>\n+            <version>${kafka.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <!-- Json -->\n+        <dependency>\n+            <groupId>org.apache.kafka</groupId>\n+            <artifactId>connect-json</artifactId>\n+            <version>${kafka.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <!-- Avro -->\n+        <dependency>\n+            <groupId>io.confluent</groupId>\n+            <artifactId>kafka-schema-registry</artifactId>\n+            <version>${confluent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.confluent</groupId>\n+            <artifactId>kafka-avro-serializer</artifactId>\n+            <version>${confluent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>log4j</groupId>\n+            <artifactId>log4j</artifactId>\n+            <version>1.2.17</version>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <!-- FILE --> <!-- TODO: cleanup after File works -->\n+        <dependency>\n+            <groupId>org.apache.avro</groupId>\n+            <artifactId>avro-mapred</artifactId>\n+            <version>${avro.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.parquet</groupId>\n+            <artifactId>parquet-avro</artifactId>\n+            <version>${parquet.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-hadoop</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.hadoop</groupId>\n+            <artifactId>hadoop-hdfs</artifactId>\n+            <version>${hadoop.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.hadoop</groupId>\n+            <artifactId>hadoop-common</artifactId>\n+            <version>${hadoop.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.hadoop</groupId>\n+            <artifactId>hadoop-mapreduce-client-core</artifactId>\n+            <version>${hadoop.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <!-- Amazon S3 -->\n+        <dependency>\n+            <groupId>org.apache.hadoop</groupId>\n+            <artifactId>hadoop-aws</artifactId>\n+            <version>${hadoop.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.hadoop</groupId>\n+            <artifactId>hadoop-client</artifactId>\n+            <version>${hadoop.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <!-- Google Cloud Storage -->\n+        <dependency>\n+            <groupId>com.google.cloud.bigdataoss</groupId>\n+            <artifactId>gcs-connector</artifactId>\n+            <version>hadoop2-2.0.0</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <!-- Azure Cloud Storage -->\n+        <dependency>\n+            <groupId>org.apache.hadoop</groupId>\n+            <artifactId>hadoop-azure</artifactId>\n+            <version>${hadoop.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <!-- Azure Data Lake -->\n+        <dependency>\n+            <groupId>org.apache.hadoop</groupId>\n+            <artifactId>hadoop-azure-datalake</artifactId>\n+            <version>${hadoop.version}</version>\n+            <scope>provided</scope>\n+        </dependency>", "originalCommit": "454799244ee17b39c872f3e419521f2dadbcf92f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDIxOTkwMQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r514219901", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>log4j</groupId>\n          \n          \n            \n                        <artifactId>log4j</artifactId>\n          \n          \n            \n                        <version>1.2.17</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>", "author": "gierlachg", "createdAt": "2020-10-29T12:29:05Z", "path": "hazelcast-jet-sql/pom.xml", "diffHunk": "@@ -0,0 +1,468 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+  ~\n+  ~ Licensed under the Apache License, Version 2.0 (the \"License\");\n+  ~ you may not use this file except in compliance with the License.\n+  ~ You may obtain a copy of the License at\n+  ~\n+  ~ http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <packaging>jar</packaging>\n+    <name>hazelcast-jet-sql</name>\n+    <description>SQL support for Hazelcast Jet</description>\n+    <url>http://www.hazelcast.com/</url>\n+\n+    <artifactId>hazelcast-jet-sql</artifactId>\n+\n+    <parent>\n+        <groupId>com.hazelcast.jet</groupId>\n+        <artifactId>hazelcast-jet-root</artifactId>\n+        <version>4.4-SNAPSHOT</version>\n+    </parent>\n+\n+    <properties>\n+        <confluent.version>4.1.0</confluent.version>\n+        <parquet.version>1.10.1</parquet.version>\n+    </properties>\n+\n+    <repositories>\n+        <repository>\n+            <id>confluent</id>\n+            <url>https://packages.confluent.io/maven/</url>\n+            <snapshots>\n+                <enabled>false</enabled>\n+            </snapshots>\n+        </repository>\n+    </repositories>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-core</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.hazelcast</groupId>\n+            <artifactId>hazelcast-sql</artifactId>\n+            <version>${hazelcast.version}</version>\n+            <classifier>jar-with-dependencies</classifier>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>com.hazelcast</groupId>\n+                    <artifactId>hazelcast</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <!-- TODO: json & json libs part of sql by default ??? -->\n+        <!-- TODO: how to package i.e. Kafka ??? -->\n+\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-avro</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <!-- KAFKA -->\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-kafka</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.kafka</groupId>\n+            <artifactId>kafka_${scala.version}</artifactId>\n+            <version>${kafka.version}</version>\n+            <scope>provided</scope>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.slf4j</groupId>\n+                    <artifactId>slf4j-log4j12</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.kafka</groupId>\n+            <artifactId>kafka-clients</artifactId>\n+            <version>${kafka.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <!-- Json -->\n+        <dependency>\n+            <groupId>org.apache.kafka</groupId>\n+            <artifactId>connect-json</artifactId>\n+            <version>${kafka.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <!-- Avro -->\n+        <dependency>\n+            <groupId>io.confluent</groupId>\n+            <artifactId>kafka-schema-registry</artifactId>\n+            <version>${confluent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.confluent</groupId>\n+            <artifactId>kafka-avro-serializer</artifactId>\n+            <version>${confluent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+        <dependency>\n+            <groupId>log4j</groupId>\n+            <artifactId>log4j</artifactId>\n+            <version>1.2.17</version>\n+            <scope>provided</scope>\n+        </dependency>", "originalCommit": "454799244ee17b39c872f3e419521f2dadbcf92f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDIyMDIxNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r514220217", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                    <!-- TODO: json & json libs part of sql by default ??? -->\n          \n          \n            \n                    <!-- TODO: how to package i.e. Kafka ??? -->\n          \n          \n            \n            \n          \n          \n            \n                    <dependency>\n          \n          \n            \n                        <groupId>com.hazelcast.jet</groupId>\n          \n          \n            \n                        <artifactId>hazelcast-jet-avro</artifactId>\n          \n          \n            \n                        <version>${project.parent.version}</version>\n          \n          \n            \n                        <scope>provided</scope>\n          \n          \n            \n                    </dependency>", "author": "gierlachg", "createdAt": "2020-10-29T12:29:38Z", "path": "hazelcast-jet-sql/pom.xml", "diffHunk": "@@ -0,0 +1,468 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+  ~\n+  ~ Licensed under the Apache License, Version 2.0 (the \"License\");\n+  ~ you may not use this file except in compliance with the License.\n+  ~ You may obtain a copy of the License at\n+  ~\n+  ~ http://www.apache.org/licenses/LICENSE-2.0\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  ~ See the License for the specific language governing permissions and\n+  ~ limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <packaging>jar</packaging>\n+    <name>hazelcast-jet-sql</name>\n+    <description>SQL support for Hazelcast Jet</description>\n+    <url>http://www.hazelcast.com/</url>\n+\n+    <artifactId>hazelcast-jet-sql</artifactId>\n+\n+    <parent>\n+        <groupId>com.hazelcast.jet</groupId>\n+        <artifactId>hazelcast-jet-root</artifactId>\n+        <version>4.4-SNAPSHOT</version>\n+    </parent>\n+\n+    <properties>\n+        <confluent.version>4.1.0</confluent.version>\n+        <parquet.version>1.10.1</parquet.version>\n+    </properties>\n+\n+    <repositories>\n+        <repository>\n+            <id>confluent</id>\n+            <url>https://packages.confluent.io/maven/</url>\n+            <snapshots>\n+                <enabled>false</enabled>\n+            </snapshots>\n+        </repository>\n+    </repositories>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-core</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.hazelcast</groupId>\n+            <artifactId>hazelcast-sql</artifactId>\n+            <version>${hazelcast.version}</version>\n+            <classifier>jar-with-dependencies</classifier>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>com.hazelcast</groupId>\n+                    <artifactId>hazelcast</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <!-- TODO: json & json libs part of sql by default ??? -->\n+        <!-- TODO: how to package i.e. Kafka ??? -->\n+\n+        <dependency>\n+            <groupId>com.hazelcast.jet</groupId>\n+            <artifactId>hazelcast-jet-avro</artifactId>\n+            <version>${project.parent.version}</version>\n+            <scope>provided</scope>\n+        </dependency>", "originalCommit": "454799244ee17b39c872f3e419521f2dadbcf92f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDIyODM1OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r514228358", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                @Override\n          \n          \n            \n                public RelWriter explainTerms(RelWriter pw) {\n          \n          \n            \n                    return super.explainTerms(pw)\n          \n          \n            \n                                .item(\"group\", groupSet);\n          \n          \n            \n                }", "author": "gierlachg", "createdAt": "2020-10-29T12:43:19Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/physical/AggregateCombineByKeyPhysicalRel.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.physical;\n+\n+import com.hazelcast.jet.aggregate.AggregateOperation;\n+import com.hazelcast.jet.core.Vertex;\n+import com.hazelcast.jet.sql.impl.aggregate.SqlAggregations;\n+import com.hazelcast.jet.sql.impl.opt.OptUtils;\n+import com.hazelcast.jet.sql.impl.opt.physical.visitor.CreateDagVisitor;\n+import com.hazelcast.sql.impl.plan.node.PlanNodeSchema;\n+import org.apache.calcite.plan.RelOptCluster;\n+import org.apache.calcite.plan.RelTraitSet;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.RelWriter;\n+import org.apache.calcite.rel.core.Aggregate;\n+import org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.calcite.util.ImmutableBitSet;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class AggregateCombineByKeyPhysicalRel extends Aggregate implements PhysicalRel {\n+\n+    private final AggregateOperation<SqlAggregations, Object[]> aggrOp;\n+\n+    AggregateCombineByKeyPhysicalRel(\n+            RelOptCluster cluster,\n+            RelTraitSet traits,\n+            RelNode input,\n+            ImmutableBitSet groupSet,\n+            List<ImmutableBitSet> groupSets,\n+            List<AggregateCall> aggCalls,\n+            AggregateOperation<SqlAggregations, Object[]> aggrOp\n+    ) {\n+        super(cluster, traits, new ArrayList<>(), input, groupSet, groupSets, aggCalls);\n+\n+        this.aggrOp = aggrOp;\n+    }\n+\n+    public AggregateOperation<SqlAggregations, Object[]> aggrOp() {\n+        return aggrOp;\n+    }\n+\n+    @Override\n+    public PlanNodeSchema schema() {\n+        return OptUtils.schema(getRowType());\n+    }\n+\n+    @Override\n+    public Vertex visit(CreateDagVisitor visitor) {\n+        return visitor.onCombineByKey(this);\n+    }\n+\n+    @Override\n+    public RelWriter explainTerms(RelWriter pw) {\n+        return super.explainTerms(pw)\n+                    .item(\"group\", groupSet);\n+    }", "originalCommit": "454799244ee17b39c872f3e419521f2dadbcf92f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDIyODQ5NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r514228495", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            import org.apache.calcite.rel.RelWriter;", "author": "gierlachg", "createdAt": "2020-10-29T12:43:31Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/physical/AggregateCombineByKeyPhysicalRel.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.physical;\n+\n+import com.hazelcast.jet.aggregate.AggregateOperation;\n+import com.hazelcast.jet.core.Vertex;\n+import com.hazelcast.jet.sql.impl.aggregate.SqlAggregations;\n+import com.hazelcast.jet.sql.impl.opt.OptUtils;\n+import com.hazelcast.jet.sql.impl.opt.physical.visitor.CreateDagVisitor;\n+import com.hazelcast.sql.impl.plan.node.PlanNodeSchema;\n+import org.apache.calcite.plan.RelOptCluster;\n+import org.apache.calcite.plan.RelTraitSet;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.RelWriter;", "originalCommit": "454799244ee17b39c872f3e419521f2dadbcf92f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a74135c24bcc046e939d991a60b5084f9174dd90", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a74135c24bcc046e939d991a60b5084f9174dd90", "message": "Address review comments by gg", "committedDate": "2020-10-29T13:07:46Z", "type": "commit"}, {"oid": "e55493488e56a3d68134aaa5317545b2bc1f9013", "url": "https://github.com/hazelcast/hazelcast-jet/commit/e55493488e56a3d68134aaa5317545b2bc1f9013", "message": "Improve vertex naming", "committedDate": "2020-10-29T13:08:02Z", "type": "commit"}, {"oid": "4b83960de7ed80e9f4a2604279eaa8b80bb6e058", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4b83960de7ed80e9f4a2604279eaa8b80bb6e058", "message": "Fix validation in SqlExtendedInsert\n\nFixes #2618", "committedDate": "2020-10-29T13:35:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkyMjQ3OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r514922478", "bodyText": "Is there a reason to expose this interface in addition to the existing SqlService HazelcastInstance.getSql()?", "author": "devozerov", "createdAt": "2020-10-30T07:53:47Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/JetSqlService.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet;\n+\n+import com.hazelcast.sql.SqlService;\n+\n+/**\n+ * The Hazelcast Jet SQL service.\n+ * <p>\n+ * The service is in beta state. Behavior and API might change in future\n+ * releases. Binary compatibility is not guaranteed between minor or patch\n+ * releases.\n+ * <p>\n+ * Hazelcast can execute SQL statements using either the default SQL\n+ * backend contained in the Hazelcast IMDG code, or using the Jet SQL\n+ * backend in this package. The algorithm is this: we first try the\n+ * default backend, if it can't execute a particular statement, we try the\n+ * Jet backend.\n+ * <p>\n+ * For proper functionality the {@code hazelcast-jet-sql.jar} has to be on\n+ * the class path.\n+ * <p>\n+ * The text below summarizes Hazelcast Jet SQL features. For a summary of\n+ * the default SQL engine features, see the {@linkplain SqlService\n+ * superclass} documentation.\n+ *\n+ * <h1>Overview</h1>\n+ *\n+ * Hazelcast Jet is able to execute distributed SQL statements over any Jet\n+ * connector that supports the SQL integration. Currently those are:\n+ *\n+ * <ul>\n+ *     <li>local IMaps (writing only)\n+ *     <li>Apache Kafka topics\n+ * </ul>\n+ *\n+ * Each connector specifies its own serialization formats and a way of\n+ * mapping the stored objects to records with column names and SQL types.\n+ * See the individual connectors for details.\n+ * <p>\n+ * In the first release we support a very limited set of features,\n+ * essentially only reading and writing from/to the above connectors and\n+ * projection + filtering. Currently these are unsupported: joins,\n+ * grouping, aggregation. We plan to support these in the future.\n+ *\n+ * <h1>Full Documentation</h1>\n+ *\n+ * The full documentation of all SQL features is available at <a\n+ * href='https://jet-start.sh/docs/sql/'>https://jet-start.sh/docs/sql/</a>.\n+ *\n+ * @since 4.4\n+ */\n+public interface JetSqlService extends SqlService {", "originalCommit": "454799244ee17b39c872f3e419521f2dadbcf92f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTExMTU3MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r515111571", "bodyText": "I think the only reason was to have a place to put the javadoc. I moved the javadoc to JetInstance.getSql() and removed this class. This class would introduce confusion and questions like \"can I use SqlService to run Jet SQL query?\" We can add it in the future if we need some specific method for Jet (which I don't expect).", "author": "viliam-durina", "createdAt": "2020-10-30T13:51:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDkyMjQ3OA=="}], "type": "inlineReview"}, {"oid": "80720b829d4204767d8760855e76c25923dfad80", "url": "https://github.com/hazelcast/hazelcast-jet/commit/80720b829d4204767d8760855e76c25923dfad80", "message": "Remove JetSqlService (address VO's comment)", "committedDate": "2020-10-30T13:49:01Z", "type": "commit"}, {"oid": "25f275a95acd2d4a55bf5844bec1619878a673e7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/25f275a95acd2d4a55bf5844bec1619878a673e7", "message": "Merge remote-tracking branch 'remotes/hazelcast/master' into sql-pr1", "committedDate": "2020-10-30T13:49:21Z", "type": "commit"}, {"oid": "a64033ef89b42852fbeb08005d93c87c119fd7fd", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a64033ef89b42852fbeb08005d93c87c119fd7fd", "message": "Extract failing top injector.", "committedDate": "2020-11-02T07:39:57Z", "type": "commit"}, {"oid": "22d29c29873a0a0b8b9738bae649eb352b5700f5", "url": "https://github.com/hazelcast/hazelcast-jet/commit/22d29c29873a0a0b8b9738bae649eb352b5700f5", "message": "Add sql module to distribution package.", "committedDate": "2020-11-02T08:28:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk4MTYzOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r515981639", "bodyText": "AFAIU this rules out builder-style setters. Do we really need to reject such setters?", "author": "devozerov", "createdAt": "2020-11-02T13:47:45Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/ReflectionUtils.java", "diffHunk": "@@ -61,6 +101,72 @@ private ReflectionUtils() {\n         return (T) field.get(null);\n     }\n \n+    /**\n+     * Return a set-method for a class and a property. The setter must start\n+     * with \"set\", must be public, non-static, must return void and take one\n+     * argument of type {@code type}.\n+     *\n+     * @param clazz The containing class\n+     * @param propertyName Name of the property\n+     * @param type The type of the property\n+     *\n+     * @return The found setter or null if one matching the criteria doesn't exist\n+     */\n+    @Nullable\n+    public static Method findPropertySetter(\n+            @Nonnull Class<?> clazz,\n+            @Nonnull String propertyName,\n+            @Nonnull Class<?> type\n+    ) {\n+        String setterName = \"set\" + toUpperCase(propertyName.charAt(0)) + propertyName.substring(1);\n+\n+        Method method;\n+        try {\n+            method = clazz.getMethod(setterName, type);\n+        } catch (NoSuchMethodException e) {\n+            return null;\n+        }\n+\n+        if (!Modifier.isPublic(method.getModifiers())) {\n+            return null;\n+        }\n+\n+        if (Modifier.isStatic(method.getModifiers())) {\n+            return null;\n+        }\n+\n+        Class<?> returnType = method.getReturnType();\n+        if (returnType != void.class && returnType != Void.class) {\n+            return null;", "originalCommit": "22d29c29873a0a0b8b9738bae649eb352b5700f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQ3OTgxMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516479812", "bodyText": "fixed", "author": "viliam-durina", "createdAt": "2020-11-03T08:02:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk4MTYzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk4Nzk3OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r515987978", "bodyText": "Converging the type to DECIMAL aggressively may have bad performance consequences, working with BigDecimal is resource-intensive. For IMDG we generally do not extend the type to DECIMAL. E.g. BIGINT+BIGINT=>BIGINT, not DECIMAL. This brings better performance, and in the case of overflow, we may always ask the user to add an explicit CAST. When it is time to implement aggregations in IMDG, we are likely to follow the same approach. E.g. SUM(INTEGER)=>BIGINT, but SUM(BIGINT)=>BIGINT.\nI would suggest you considering less aggressive type widening rules, to avoid BigDecimal as much as possible.", "author": "devozerov", "createdAt": "2020-11-02T13:57:50Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/aggregate/AvgSqlAggregation.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.aggregate;\n+\n+import com.hazelcast.nio.ObjectDataInput;\n+import com.hazelcast.nio.ObjectDataOutput;\n+import com.hazelcast.sql.impl.QueryException;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import com.hazelcast.sql.impl.type.QueryDataTypeFamily;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.util.Objects;\n+\n+import static com.hazelcast.sql.impl.expression.math.ExpressionMath.DECIMAL_MATH_CONTEXT;\n+\n+@NotThreadSafe\n+public class AvgSqlAggregation extends SqlAggregation {\n+\n+    private QueryDataType resultType;\n+\n+    private SumSqlAggregation sum;\n+    private CountSqlAggregation count;\n+\n+    @SuppressWarnings(\"unused\")\n+    private AvgSqlAggregation() {\n+    }\n+\n+    public AvgSqlAggregation(int index, QueryDataType operandType) {\n+        this(index, operandType, false);\n+    }\n+\n+    public AvgSqlAggregation(int index, QueryDataType operandType, boolean distinct) {\n+        super(index, true, distinct);\n+        this.resultType = inferResultType(operandType);\n+        this.sum = new SumSqlAggregation(index, operandType);\n+        this.count = new CountSqlAggregation();\n+    }\n+\n+    private static QueryDataType inferResultType(QueryDataType operandType) {\n+        switch (operandType.getTypeFamily()) {\n+            case TINYINT:\n+            case SMALLINT:\n+            case INTEGER:\n+            case BIGINT:\n+            case DECIMAL:", "originalCommit": "22d29c29873a0a0b8b9738bae649eb352b5700f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA0MDA1NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516040055", "bodyText": "For sums we have BIGINT+BIGINT=>BIGINT. How would you represent a fraction with BIGINT for averages?", "author": "gierlachg", "createdAt": "2020-11-02T15:13:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk4Nzk3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQ4MDMxNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516480315", "bodyText": "In postgres it also returns a decimal likely, certainly not an int: https://dbfiddle.uk/?rdbms=postgres_13&fiddle=af9ef053f45de269a71cf41ab8fdf9fb", "author": "viliam-durina", "createdAt": "2020-11-03T08:03:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk4Nzk3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUyMTgyNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516521827", "bodyText": "Ah, sorry. So BigDecimal appears at the very end, and sum/count is performed without decimals for most type", "author": "devozerov", "createdAt": "2020-11-03T09:21:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk4Nzk3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk5MjQ4MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r515992481", "bodyText": "Please note that in IMDG we moved type inference to Calcite-related classes. This was a tedious task, but ultimately it gives us full control of possible conversions, type inference, error messages with the exact parser positions, etc.\nFor aggregations we are likely to follow a similar approach - the inference will be implemented at the Calcite level. We may have a kind of mismatch here going forward, that will require you to change the implementation if we want to have a common aggregation-related code base. This doesn't seem critical to me at the moment, since your implementation of inference is simple, so just informing you about the possible mismatch in approaches.", "author": "devozerov", "createdAt": "2020-11-02T14:04:48Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/aggregate/AvgSqlAggregation.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.aggregate;\n+\n+import com.hazelcast.nio.ObjectDataInput;\n+import com.hazelcast.nio.ObjectDataOutput;\n+import com.hazelcast.sql.impl.QueryException;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import com.hazelcast.sql.impl.type.QueryDataTypeFamily;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.util.Objects;\n+\n+import static com.hazelcast.sql.impl.expression.math.ExpressionMath.DECIMAL_MATH_CONTEXT;\n+\n+@NotThreadSafe\n+public class AvgSqlAggregation extends SqlAggregation {\n+\n+    private QueryDataType resultType;\n+\n+    private SumSqlAggregation sum;\n+    private CountSqlAggregation count;\n+\n+    @SuppressWarnings(\"unused\")\n+    private AvgSqlAggregation() {\n+    }\n+\n+    public AvgSqlAggregation(int index, QueryDataType operandType) {\n+        this(index, operandType, false);\n+    }\n+\n+    public AvgSqlAggregation(int index, QueryDataType operandType, boolean distinct) {\n+        super(index, true, distinct);\n+        this.resultType = inferResultType(operandType);\n+        this.sum = new SumSqlAggregation(index, operandType);\n+        this.count = new CountSqlAggregation();\n+    }\n+\n+    private static QueryDataType inferResultType(QueryDataType operandType) {", "originalCommit": "22d29c29873a0a0b8b9738bae649eb352b5700f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA0Mjk3NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516042974", "bodyText": "We do rely on HazelcastTypeSystem (see HazelcastTypeSystem#deriveSumType & HazelcastTypeSystem#deriveAvgAggType), is that what you mean? The duplication here is for a reason i think - most probably I could not find a way to relay that information from Calcite - but I can't remember the details right now... I'll try to recall what was the problem.", "author": "gierlachg", "createdAt": "2020-11-02T15:17:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk5MjQ4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjYwMTQ0Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516601442", "bodyText": "I tried to reuse HazelcastTypeSystem derive methods but because RelDataType is not serializable the code became quite convoluted. The duplication isn't substantial, I think we can live with that, the discrepancy should be pretty quickly apparent.", "author": "gierlachg", "createdAt": "2020-11-03T11:34:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk5MjQ4MQ=="}], "type": "inlineReview"}, {"oid": "9160d8e36bbde0e2b51bac63c50349eb810cd332", "url": "https://github.com/hazelcast/hazelcast-jet/commit/9160d8e36bbde0e2b51bac63c50349eb810cd332", "message": "Allow builder-style setters", "committedDate": "2020-11-03T08:14:45Z", "type": "commit"}, {"oid": "ac00ae0e0a5c57ce35b24cafabf072c664d5817b", "url": "https://github.com/hazelcast/hazelcast-jet/commit/ac00ae0e0a5c57ce35b24cafabf072c664d5817b", "message": "Fix grammar", "committedDate": "2020-11-03T08:15:57Z", "type": "commit"}, {"oid": "f455eb9b77e30e36d29ed6a76308fc9668a33843", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f455eb9b77e30e36d29ed6a76308fc9668a33843", "message": "Merge remote-tracking branch 'remotes/hazelcast/master' into sql-pr1", "committedDate": "2020-11-03T08:25:50Z", "type": "commit"}, {"oid": "6aad27680ae85a3e286ae8ebac6dfb85abbe0762", "url": "https://github.com/hazelcast/hazelcast-jet/commit/6aad27680ae85a3e286ae8ebac6dfb85abbe0762", "message": "Support SELECT ALL, tests for MAX(DISTINCT e)", "committedDate": "2020-11-03T09:17:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUyNTk5MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516525991", "bodyText": "AFAIK columns is a reserved name for the view that exposes table columns. Given that we will need inforamtion_schema in IMDG in the future, I would propose to rename this view to mapping_columns. Otherwise, we will violate the standard.", "author": "devozerov", "createdAt": "2020-11-03T09:28:16Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/infoschema/MappingColumnsTable.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector.infoschema;\n+\n+import com.hazelcast.jet.sql.impl.schema.MappingDefinition;\n+import com.hazelcast.jet.sql.impl.type.QueryDataTypeUtils;\n+import com.hazelcast.sql.impl.schema.ConstantTableStatistics;\n+import com.hazelcast.sql.impl.schema.TableField;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static java.util.Arrays.asList;\n+\n+/**\n+ * Table object for the {@code information_schema.columns} table.\n+ */\n+public class MappingColumnsTable extends InfoSchemaTable {\n+\n+    private static final String NAME = \"columns\";", "originalCommit": "f455eb9b77e30e36d29ed6a76308fc9668a33843", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjczNTU2OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516735568", "bodyText": "In information_schema the columns table is used columns of both tables and views. I think it can also be used for columns of mappings. I think when you're doing it, we need to integrate our work and display all columns there.", "author": "viliam-durina", "createdAt": "2020-11-03T15:05:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUyNTk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc3MjI5NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516772295", "bodyText": "True, but columns is part of the standard, and it must have columns with specific names: table_name instead of mapping_name, etc (see \"Schemata\" document of the standard, the paragraph \"COLUMNS view\"). The current implementation violates the standard. We should either rename columns or rename the table.", "author": "devozerov", "createdAt": "2020-11-03T15:54:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUyNTk5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUzNzkxOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516537919", "bodyText": "Note that in IMDG we currently follow the rules below:\n\nInteger type is reported as INTEGER, not INT\nTimestamp with time zone is reported as TIMESTAMP_WITH_TIME_ZONE\n\nWe do not have DML/DDL commands in IMDG now, so we are not concerned with this naming on the parser level. However, these names are reported in query metadata and error messages. Going forward, we are going to utilize them on the parser level as well. The canonical type names are enum names from SqlColumnType.\nI would suggest you consider following the common naming scheme here, otherwise, users might be confused when to and how to use type names.", "author": "devozerov", "createdAt": "2020-11-03T09:47:13Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/type/QueryDataTypeUtils.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.type;\n+\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import com.hazelcast.sql.impl.type.QueryDataTypeFamily;\n+\n+public final class QueryDataTypeUtils {\n+\n+    private QueryDataTypeUtils() {\n+    }\n+\n+    public static String sqlTypeName(QueryDataType type) {", "originalCommit": "f455eb9b77e30e36d29ed6a76308fc9668a33843", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NTA2Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516745066", "bodyText": "This method is also used in unparse() where it should produce text that's parseable. And in IMDG you already use CAST(a AS INT), not AS INTEGER. It's also used in information_schema.columns.data_type - here we could use INTEGER. Also in one error message.\nI don't understand why we actually have this dichotomy: INT and INTEGER... I think having one would be the least confusing.", "author": "viliam-durina", "createdAt": "2020-11-03T15:18:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUzNzkxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc4Nzg4MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516787881", "bodyText": "Unparse is largely unused in IMDG (at least I am not aware of when it might be needed and exposed to the user).\nWhat I am saying that the current decision in IMDG is to display the 4-byte type as INTEGER everywhere. There could be possible places where we missed it, but still. In tests we also use as INTEGER, e.g. CastIntegrationTest.testInteger", "author": "devozerov", "createdAt": "2020-11-03T16:15:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUzNzkxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM3ODkxMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r517378912", "bodyText": "Refactored the code that it's only used in the unparse. We have a method to recreate the DDL command from an existing mapping. It's not used in this PR, but I'd like to keep the code there.", "author": "viliam-durina", "createdAt": "2020-11-04T14:22:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUzNzkxOQ=="}], "type": "inlineReview"}, {"oid": "ec9de2b4db62cdeb9df2cfaceec8a65b64b219ec", "url": "https://github.com/hazelcast/hazelcast-jet/commit/ec9de2b4db62cdeb9df2cfaceec8a65b64b219ec", "message": "Make TestBatchSqlConnector distributed", "committedDate": "2020-11-03T11:30:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUxNTE5NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516515195", "bodyText": "This method should be called accept, so it's not confused with visitor.visit.", "author": "mtopolnik", "createdAt": "2020-11-03T09:09:59Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/physical/PhysicalRel.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.physical;\n+\n+import com.hazelcast.jet.core.Vertex;\n+import com.hazelcast.jet.sql.impl.opt.OptUtils;\n+import com.hazelcast.jet.sql.impl.opt.physical.visitor.CreateDagVisitor;\n+import com.hazelcast.sql.impl.calcite.schema.HazelcastTable;\n+import com.hazelcast.sql.impl.expression.Expression;\n+import com.hazelcast.sql.impl.plan.node.PlanNodeFieldTypeProvider;\n+import com.hazelcast.sql.impl.plan.node.PlanNodeSchema;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexVisitor;\n+\n+import java.util.List;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+/**\n+ * Marker interface for physical relations.\n+ */\n+public interface PhysicalRel extends RelNode {\n+\n+    PlanNodeSchema schema();\n+\n+    @SuppressWarnings(\"unchecked\")\n+    default Expression<Boolean> filter(PlanNodeFieldTypeProvider schema, RexNode node) {\n+        if (node == null) {\n+            return null;\n+        }\n+        RexVisitor<Expression<?>> converter = OptUtils.converter(schema);\n+        return (Expression<Boolean>) node.accept(converter);\n+    }\n+\n+    default List<Expression<?>> project(PlanNodeFieldTypeProvider schema, List<RexNode> nodes) {\n+        RexVisitor<Expression<?>> converter = OptUtils.converter(schema);\n+        return nodes.stream()\n+                    .map(node -> (Expression<?>) node.accept(converter))\n+                    .collect(toList());\n+    }\n+\n+    @Override\n+    default RelDataType getRowType() {\n+        return getTable().unwrap(HazelcastTable.class).getRowType(getCluster().getTypeFactory());\n+    }\n+\n+    /**\n+     * Visit a physical rel.\n+     *\n+     * @param visitor Visitor.\n+     * @return the DAG vertex created for this rel\n+     */\n+    Vertex visit(CreateDagVisitor visitor);", "originalCommit": "f455eb9b77e30e36d29ed6a76308fc9668a33843", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NjAxMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516746010", "bodyText": "That's true, but there's also PhysicalRel.visit() in IMDG. Wdyt, @devozerov?", "author": "viliam-durina", "createdAt": "2020-11-03T15:19:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUxNTE5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc3NDg4Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516774882", "bodyText": "I guess so. We picked the wrong name accidentally and then propagated it to many visitors here and there.", "author": "devozerov", "createdAt": "2020-11-03T15:57:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUxNTE5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc4NjkxMQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516786911", "bodyText": "I think I can rename ours, you can rename yours if you wish. It's internal.\nRenamed.", "author": "viliam-durina", "createdAt": "2020-11-03T16:14:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUxNTE5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUyMzU2OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516523569", "bodyText": "Would it be possible to use  forceTotalParallelismOne or an equivalent that works with distributeTo, so that the redundant processors complete immediately?", "author": "mtopolnik", "createdAt": "2020-11-03T09:24:20Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/physical/visitor/CreateDagVisitor.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.physical.visitor;\n+\n+import com.hazelcast.cluster.Address;\n+import com.hazelcast.function.ConsumerEx;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.function.PredicateEx;\n+import com.hazelcast.jet.aggregate.AggregateOperation;\n+import com.hazelcast.jet.core.DAG;\n+import com.hazelcast.jet.core.Edge;\n+import com.hazelcast.jet.core.ProcessorMetaSupplier;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.core.Vertex;\n+import com.hazelcast.jet.core.processor.Processors;\n+import com.hazelcast.jet.sql.impl.aggregate.ObjectArrayKey;\n+import com.hazelcast.jet.sql.impl.expression.ExpressionUtil;\n+import com.hazelcast.jet.sql.impl.opt.physical.AggregateAccumulateByKeyPhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.AggregateAccumulatePhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.AggregateByKeyPhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.AggregateCombineByKeyPhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.AggregateCombinePhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.AggregatePhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.FilterPhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.FullScanPhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.InsertPhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.JetRootRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.PhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.ProjectPhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.ValuesPhysicalRel;\n+import com.hazelcast.sql.impl.calcite.schema.HazelcastTable;\n+import com.hazelcast.sql.impl.schema.Table;\n+import org.apache.calcite.rel.RelNode;\n+\n+import javax.annotation.Nullable;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Consumer;\n+\n+import static com.hazelcast.function.Functions.entryKey;\n+import static com.hazelcast.jet.core.Edge.between;\n+import static com.hazelcast.jet.core.processor.Processors.filterP;\n+import static com.hazelcast.jet.core.processor.Processors.mapP;\n+import static com.hazelcast.jet.core.processor.SourceProcessors.convenientSourceP;\n+import static com.hazelcast.jet.sql.impl.connector.SqlConnectorUtil.getJetSqlConnector;\n+import static com.hazelcast.jet.sql.impl.processors.RootResultConsumerSink.rootResultConsumerSink;\n+import static java.util.Collections.singletonList;\n+\n+public class CreateDagVisitor {\n+\n+    private final DAG dag = new DAG();\n+    private final Address localMemberAddress;\n+\n+    private final Map<String, Integer> vertexNameIndexes = new HashMap<>();\n+\n+    public CreateDagVisitor(Address localMemberAddress) {\n+        this.localMemberAddress = localMemberAddress;\n+    }\n+\n+    public Vertex onValues(ValuesPhysicalRel rel) {\n+        List<Object[]> values = rel.values();\n+\n+        return dag.newVertex(name(\"Values\"), convenientSourceP(\n+                pCtx -> null,\n+                (ignored, buffer) -> {\n+                    values.forEach(buffer::add);\n+                    buffer.close();\n+                },\n+                ctx -> null,\n+                (ctx, states) -> {\n+                },\n+                ConsumerEx.noop(),\n+                0,\n+                true)\n+        );\n+    }\n+\n+    public Vertex onInsert(InsertPhysicalRel rel) {\n+        Table table = rel.getTable().unwrap(HazelcastTable.class).getTarget();\n+\n+        Vertex vertex = getJetSqlConnector(table).sink(dag, table);\n+        connectInput(rel.getInput(), vertex, null);\n+        return vertex;\n+    }\n+\n+    public Vertex onFullScan(FullScanPhysicalRel rel) {\n+        Table table = rel.getTable().unwrap(HazelcastTable.class).getTarget();\n+\n+        return getJetSqlConnector(table)\n+                .fullScanReader(dag, table, null, rel.filter(), rel.projection());\n+    }\n+\n+    public Vertex onFilter(FilterPhysicalRel rel) {\n+        PredicateEx<Object[]> filter = ExpressionUtil.filterFn(rel.filter());\n+\n+        Vertex vertex = dag.newVertex(name(\"Filter\"), filterP(filter::test));\n+        connectInput(rel.getInput(), vertex, null);\n+        return vertex;\n+    }\n+\n+    public Vertex onProject(ProjectPhysicalRel rel) {\n+        FunctionEx<Object[], Object[]> projection = ExpressionUtil.projectionFn(rel.projection());\n+\n+        Vertex vertex = dag.newVertex(name(\"Project\"), mapP(projection));\n+        connectInput(rel.getInput(), vertex, null);\n+        return vertex;\n+    }\n+\n+    public Vertex onAggregate(AggregatePhysicalRel rel) {\n+        AggregateOperation<?, Object[]> aggregateOperation = rel.aggrOp();\n+\n+        Vertex vertex = dag.newVertex(\n+                name(\"Aggregate\"),\n+                ProcessorMetaSupplier.forceTotalParallelismOne(\n+                        ProcessorSupplier.of(Processors.aggregateP(aggregateOperation)),\n+                        localMemberAddress\n+                )\n+        );\n+        connectInput(rel.getInput(), vertex, edge -> edge.allToOne(\"\").distributeTo(localMemberAddress));\n+        return vertex;\n+    }\n+\n+    public Vertex onAccumulate(AggregateAccumulatePhysicalRel rel) {\n+        AggregateOperation<?, Object[]> aggregateOperation = rel.aggrOp();\n+\n+        Vertex vertex = dag.newVertex(\n+                name(\"Accumulate\"),\n+                Processors.accumulateP(aggregateOperation)\n+        );\n+        connectInput(rel.getInput(), vertex, null);\n+        return vertex;\n+    }\n+\n+    public Vertex onCombine(AggregateCombinePhysicalRel rel) {\n+        AggregateOperation<?, Object[]> aggregateOperation = rel.aggrOp();\n+\n+        Vertex vertex = dag.newVertex(\n+                name(\"Combine\"),\n+                ProcessorMetaSupplier.forceTotalParallelismOne(\n+                        ProcessorSupplier.of(Processors.combineP(aggregateOperation)),\n+                        localMemberAddress\n+                )\n+        );\n+        connectInput(rel.getInput(), vertex, edge -> edge.allToOne(\"\").distributeTo(localMemberAddress));\n+        return vertex;\n+    }\n+\n+    public Vertex onAggregateByKey(AggregateByKeyPhysicalRel rel) {\n+        FunctionEx<Object[], ObjectArrayKey> groupKeyFn = rel.groupKeyFn();\n+        AggregateOperation<?, Object[]> aggregateOperation = rel.aggrOp();\n+\n+        Vertex vertex = dag.newVertex(\n+                name(\"AggregateByKey\"),\n+                Processors.aggregateByKeyP(singletonList(groupKeyFn), aggregateOperation, (key, value) -> value)\n+        );\n+        connectInput(rel.getInput(), vertex, edge -> edge.partitioned(groupKeyFn).distributed());\n+        return vertex;\n+    }\n+\n+    public Vertex onAccumulateByKey(AggregateAccumulateByKeyPhysicalRel rel) {\n+        FunctionEx<Object[], ObjectArrayKey> groupKeyFn = rel.groupKeyFn();\n+        AggregateOperation<?, Object[]> aggregateOperation = rel.aggrOp();\n+\n+        Vertex vertex = dag.newVertex(\n+                name(\"AccumulateByKey\"),\n+                Processors.accumulateByKeyP(singletonList(groupKeyFn), aggregateOperation)\n+        );\n+        connectInput(rel.getInput(), vertex, edge -> edge.partitioned(groupKeyFn));\n+        return vertex;\n+    }\n+\n+    public Vertex onCombineByKey(AggregateCombineByKeyPhysicalRel rel) {\n+        AggregateOperation<?, Object[]> aggregateOperation = rel.aggrOp();\n+\n+        Vertex vertex = dag.newVertex(\n+                name(\"CombineByKey\"),\n+                Processors.combineByKeyP(aggregateOperation, (key, value) -> value)\n+        );\n+        connectInput(rel.getInput(), vertex, edge -> edge.partitioned(entryKey()).distributed());\n+        return vertex;\n+    }\n+\n+    public Vertex onRoot(JetRootRel rootRel) {\n+        Vertex vertex = dag.newVertex(name(\"ClientSink\"),\n+                rootResultConsumerSink(rootRel.getInitiatorAddress(), rootRel.getQueryId()));\n+\n+        // We use distribute-to-one edge to send all the items to the initiator member.\n+        // Such edge has to be partitioned, but the sink is LP=1 anyway, so we can use\n+        // allToOne with any key, it goes to a single processor on a single member anyway.\n+        connectInput(rootRel.getInput(), vertex, edge -> edge.allToOne(\"\").distributeTo(localMemberAddress));", "originalCommit": "6aad27680ae85a3e286ae8ebac6dfb85abbe0762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NzA0Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516747043", "bodyText": "we do use it: \n  \n    \n      hazelcast-jet/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/processors/RootResultConsumerSink.java\n    \n    \n         Line 72\n      in\n      1ccff79\n    \n    \n    \n    \n\n        \n          \n           return forceTotalParallelismOne(pSupplier, initiatorAddress);", "author": "viliam-durina", "createdAt": "2020-11-03T15:21:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjUyMzU2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjU2MzYyNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516563625", "bodyText": "This is a lone class in this package. Maybe move to the upper level.", "author": "mtopolnik", "createdAt": "2020-11-03T10:27:59Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/physical/visitor/CreateDagVisitor.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.physical.visitor;", "originalCommit": "6aad27680ae85a3e286ae8ebac6dfb85abbe0762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NzMwMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516747302", "bodyText": "moved", "author": "viliam-durina", "createdAt": "2020-11-03T15:21:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjU2MzYyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjYyMjgxNg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516622816", "bodyText": "This lone method could be moved to the SqlConnector interface. Or maybe the opposite -- move the constants from SqlConnector here.", "author": "mtopolnik", "createdAt": "2020-11-03T12:14:49Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/SqlConnectorUtil.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector;\n+\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.sql.impl.connector.map.IMapSqlConnector;\n+import com.hazelcast.jet.sql.impl.schema.JetTable;\n+import com.hazelcast.sql.impl.schema.Table;\n+import com.hazelcast.sql.impl.schema.map.PartitionedMapTable;\n+\n+public final class SqlConnectorUtil {", "originalCommit": "ec9de2b4db62cdeb9df2cfaceec8a65b64b219ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc1MTcyOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516751728", "bodyText": "SqlConnector will eventually become public API (on the Core level). SqlConnectorUtil will not, it's a utility method for Jet, not for the users.\nThe constants will probably remain public. So I suggest leaving it as it is.", "author": "viliam-durina", "createdAt": "2020-11-03T15:27:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjYyMjgxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjYyNzU4MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516627580", "bodyText": "There's a documentation TODO here, I'm missing more docs in this interface while trying to figure out the purpose and meaning of the option constants.", "author": "mtopolnik", "createdAt": "2020-11-03T12:23:59Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/SqlConnector.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector;\n+\n+import com.hazelcast.jet.core.DAG;\n+import com.hazelcast.jet.core.Vertex;\n+import com.hazelcast.jet.sql.impl.schema.MappingField;\n+import com.hazelcast.spi.impl.NodeEngine;\n+import com.hazelcast.sql.impl.expression.Expression;\n+import com.hazelcast.sql.impl.schema.Table;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * TODO", "originalCommit": "ec9de2b4db62cdeb9df2cfaceec8a65b64b219ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc1MTg3MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516751871", "bodyText": "fixed", "author": "viliam-durina", "createdAt": "2020-11-03T15:27:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjYyNzU4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY1MjM0Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516652343", "bodyText": "The only callers of these supports methods are the corresponding \"action\" methods (fullScanReader here). Is this system really necessary?", "author": "mtopolnik", "createdAt": "2020-11-03T13:07:36Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/SqlConnector.java", "diffHunk": "@@ -0,0 +1,260 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.connector;\n+\n+import com.hazelcast.jet.core.DAG;\n+import com.hazelcast.jet.core.Vertex;\n+import com.hazelcast.jet.sql.impl.schema.MappingField;\n+import com.hazelcast.spi.impl.NodeEngine;\n+import com.hazelcast.sql.impl.expression.Expression;\n+import com.hazelcast.sql.impl.schema.Table;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * TODO\n+ */\n+public interface SqlConnector {\n+\n+    // TODO do these options apply to every SQL connector? Should we move them?\n+\n+    /**\n+     * The key serialization format for key-value connectors.\n+     */\n+    String OPTION_KEY_FORMAT = \"keyFormat\";\n+\n+    /**\n+     * The value serialization format for key-value connectors.\n+     */\n+    String OPTION_VALUE_FORMAT = \"valueFormat\";\n+\n+    /**\n+     * The key Java class, if {@value #OPTION_KEY_FORMAT} is {@value\n+     * JAVA_FORMAT}.\n+     */\n+    String OPTION_KEY_CLASS = \"keyJavaClass\";\n+\n+    /**\n+     * The value Java class, if {@value #OPTION_VALUE_FORMAT} is {@value\n+     * JAVA_FORMAT}.\n+     */\n+    String OPTION_VALUE_CLASS = \"valueJavaClass\";\n+\n+    /**\n+     * The key Portable factory ID, if {@value #OPTION_KEY_FORMAT} is {@value\n+     * PORTABLE_FORMAT}.\n+     */\n+    String OPTION_KEY_FACTORY_ID = \"keyPortableFactoryId\";\n+\n+    /**\n+     * The key Portable class ID, if {@value #OPTION_KEY_FORMAT} is {@value\n+     * PORTABLE_FORMAT}.\n+     */\n+    String OPTION_KEY_CLASS_ID = \"keyPortableClassId\";\n+\n+    /**\n+     * The key Portable class version, if {@value #OPTION_KEY_FORMAT} is\n+     * {@value PORTABLE_FORMAT}.\n+     */\n+    String OPTION_KEY_CLASS_VERSION = \"keyPortableClassVersion\";\n+\n+    /**\n+     * The value Portable factory ID, if {@value #OPTION_VALUE_FORMAT} is\n+     * {@value PORTABLE_FORMAT}.\n+     */\n+    String OPTION_VALUE_FACTORY_ID = \"valuePortableFactoryId\";\n+\n+    /**\n+     * The value Portable class ID, if {@value #OPTION_VALUE_FORMAT} is {@value\n+     * PORTABLE_FORMAT}.\n+     */\n+    String OPTION_VALUE_CLASS_ID = \"valuePortableClassId\";\n+\n+    /**\n+     * The value Portable class version, if {@value #OPTION_VALUE_FORMAT} is\n+     * {@value PORTABLE_FORMAT}.\n+     */\n+    String OPTION_VALUE_CLASS_VERSION = \"valuePortableClassVersion\";\n+\n+    /**\n+     * Value for {@value #OPTION_KEY_FORMAT} and {@value #OPTION_VALUE_FORMAT}\n+     * for Java serialization.\n+     */\n+    String JAVA_FORMAT = \"java\";\n+\n+    /**\n+     * Value for {@value #OPTION_KEY_FORMAT} and {@value #OPTION_VALUE_FORMAT}\n+     * for Portable serialization.\n+     */\n+    String PORTABLE_FORMAT = \"portable\";\n+\n+    /**\n+     * Value for {@value #OPTION_KEY_FORMAT} and {@value #OPTION_VALUE_FORMAT}\n+     * for JSON serialization.\n+     */\n+    String JSON_FORMAT = \"json\";\n+\n+    /**\n+     * Value for {@value #OPTION_KEY_FORMAT} and {@value #OPTION_VALUE_FORMAT}\n+     * for Avro serialization.\n+     */\n+    String AVRO_FORMAT = \"avro\";\n+\n+    /**\n+     * A key in the table options (TO).\n+     * <p>\n+     * Specifies the accessed object name. If missing, the external table name\n+     * itself is used.\n+     */\n+    String OPTION_OBJECT_NAME = \"objectName\";\n+\n+    /**\n+     * Return the name of the connector as seen in the {@code TYPE} clause in\n+     * the {@code CREATE EXTERNAL MAPPING} command.\n+     */\n+    String typeName();\n+\n+    /**\n+     * Returns {@code true}, if {@link #fullScanReader} is an unbounded source.\n+     */\n+    boolean isStream();\n+\n+    /**\n+     * Resolve a final field list given a field list and options from the user.\n+     * This method is called when processing a CREATE MAPPING statement.\n+     * <p>\n+     * The {@code userFields} can be empty, in this case the connector is\n+     * supposed to resolve them from a sample or from options. If it's not\n+     * empty, it should be only validated - no columns should be added or\n+     * removed or type changed. The external name can be added.\n+     * <p>\n+     *  The returned list must not be empty. It will be stored in the catalog\n+     *  and if the user lists the catalog, they will be visible to the user. It\n+     *  will be later passed to {@link #createTable}.\n+     *\n+     * @param nodeEngine an instance of {@link NodeEngine}\n+     * @param options    user-provided options\n+     * @param userFields user-provided list of fields, possibly empty\n+     * @return final field list, must not be empty\n+     */\n+    @Nonnull\n+    List<MappingField> resolveAndValidateFields(\n+            @Nonnull NodeEngine nodeEngine,\n+            @Nonnull Map<String, String> options,\n+            @Nonnull List<MappingField> userFields\n+    );\n+\n+    /**\n+     * Creates a {@link Table} object with the given fields. Should not not\n+     * attempt to connect to the remote service and be fast.\n+     * <p>\n+     * This method is called for each statement execution and for each mapping.\n+     *\n+     * @param nodeEngine     an instance of {@link NodeEngine}\n+     * @param options        connector specific options\n+     * @param resolvedFields list of fields as returned from {@link\n+     *                       #resolveAndValidateFields}\n+     */\n+    @Nonnull\n+    Table createTable(\n+            @Nonnull NodeEngine nodeEngine,\n+            @Nonnull String schemaName,\n+            @Nonnull String tableName,\n+            @Nonnull Map<String, String> options,\n+            @Nonnull List<MappingField> resolvedFields\n+    );\n+\n+    /**\n+     * Returns whether the {@link #fullScanReader} is supported for this\n+     * connector. The default implementation returns {@code false}.\n+     */\n+    default boolean supportsFullScanReader() {", "originalCommit": "ec9de2b4db62cdeb9df2cfaceec8a65b64b219ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc4ODMxOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516788319", "bodyText": "Actually it's only true for this method, not for the other \"supports\" methods. They were supposed to be queried by the validation to see if a feature is supported without resorting to calling the method itself and checking for exceptions. A connector is free to not support any of these methods. I'd keep them for now, we'll finalize the API in the future when we make it public.", "author": "viliam-durina", "createdAt": "2020-11-03T16:16:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY1MjM0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY5NDM1Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516694356", "bodyText": "This is also a single-class package.", "author": "mtopolnik", "createdAt": "2020-11-03T14:12:00Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/convert/JetSqlToRelConverter.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.convert;", "originalCommit": "ec9de2b4db62cdeb9df2cfaceec8a65b64b219ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc2NDg0Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516764842", "bodyText": "fixed", "author": "viliam-durina", "createdAt": "2020-11-03T15:44:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY5NDM1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY5NDc2NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516694765", "bodyText": "Also a single-class package.", "author": "mtopolnik", "createdAt": "2020-11-03T14:12:31Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/expression/ExpressionUtil.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.expression;", "originalCommit": "ec9de2b4db62cdeb9df2cfaceec8a65b64b219ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc2NjY4NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516766684", "bodyText": "fixed", "author": "viliam-durina", "createdAt": "2020-11-03T15:46:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY5NDc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjcwMDA1OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516700059", "bodyText": "Also a single-class package", "author": "mtopolnik", "createdAt": "2020-11-03T14:19:49Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/processors/RootResultConsumerSink.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.processors;", "originalCommit": "ec9de2b4db62cdeb9df2cfaceec8a65b64b219ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc2NjYyOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516766629", "bodyText": "I'll keep this one, there will be more processors", "author": "viliam-durina", "createdAt": "2020-11-03T15:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjcwMDA1OQ=="}], "type": "inlineReview"}, {"oid": "e4758f3167431c64470a0c77148897c98d49acfe", "url": "https://github.com/hazelcast/hazelcast-jet/commit/e4758f3167431c64470a0c77148897c98d49acfe", "message": "Upgrade to Hazelcast 4.2-SNAPSHOT", "committedDate": "2020-11-03T14:51:13Z", "type": "commit"}, {"oid": "6990682730da4eb2f083a1ae44073546969c961c", "url": "https://github.com/hazelcast/hazelcast-jet/commit/6990682730da4eb2f083a1ae44073546969c961c", "message": "Edit SqlConnector Javadoc", "committedDate": "2020-11-03T14:51:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0MjkwMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516742900", "bodyText": "From what I understand, you decided to implement this rule to trim columns only, similarly to IMDG part. Generally, many (if not all) logical rules are going to be exactly the same between IMDG and Jet. Have you considered using IMDG rules? If not, do you plan to merge the rule sets eventually?", "author": "devozerov", "createdAt": "2020-11-03T15:15:26Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/logical/ProjectIntoScanLogicalRule.java", "diffHunk": "@@ -0,0 +1,279 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.logical;\n+\n+import com.hazelcast.jet.sql.impl.opt.OptUtils;\n+import com.hazelcast.sql.impl.calcite.schema.HazelcastTable;\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.core.Project;\n+import org.apache.calcite.rel.core.RelFactories;\n+import org.apache.calcite.rel.core.TableScan;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexCall;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.rex.RexVisitorImpl;\n+import org.apache.calcite.util.mapping.Mapping;\n+import org.apache.calcite.util.mapping.Mappings;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Logical rule that pushes down column references from a {@link Project}\n+ * into a {@link TableScan} to allow for constrained scans. See {@link HazelcastTable}\n+ * for more information about constrained scans.\n+ * <p>\n+ * <b>Case 1: </b>projects that have only column expressions are eliminated completely,\n+ * unused columns returned from the {@code TableScan} are trimmed.\n+ * <p>\n+ * Before:\n+ * <pre>\n+ * LogicalProject[projects=[$2, $1]]]\n+ *   LogicalTableScan[table[projects=[0, 1, 2]]]\n+ * </pre>\n+ * After:\n+ * <pre>\n+ * LogicalTableScan[table[projects=[2, 1]]]\n+ * </pre>\n+ * <b>Case 2: </b>projects with non-column expressions trim the unused columns only.\n+ * <p>\n+ * Before:\n+ * <pre>\n+ * LogicalProject[projects=[+$2, $0]]]\n+ *   LogicalTableScan[table[projects=[0, 1, 2]]]\n+ * </pre>\n+ * After:\n+ * <pre>\n+ * LogicalProject[projects=[+$0, $1]]]\n+ *   LogicalTableScan[table[projects=[2, 0]]]\n+ * </pre>\n+ */\n+final class ProjectIntoScanLogicalRule extends RelOptRule {", "originalCommit": "6aad27680ae85a3e286ae8ebac6dfb85abbe0762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjgwMDQ1Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516800452", "bodyText": "I compared the two files. Besides formatting there are these differences:\n\nJet uses operand(TableScan.class, any()), imdg uses operandJ(LogicalTableScan.class, null, OptUtils::isHazelcastTable, none()). I think the additional predicate is ok for us.\njet uses OptUtils.createLogicalScan, imdg uses OptUtils.createLogicalScanWithNewTable. I guess there's some issue fixed in the imdg variant\n\nI tried to drop Jet's rule and use imdg's all tests passed. Did the same for FilterIntoSchanLogicalRule, the differences were the same. So I committed it.", "author": "viliam-durina", "createdAt": "2020-11-03T16:33:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0MjkwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NjIzOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516746239", "bodyText": "What is the purpose of this rule? AFAIU it is used to simplify (values UNION values) or alike, but at the same time there are no tests, and the UNION keyword is not allowed in the UnsupportedOperationVisitor. Looks like a dead code to me.", "author": "devozerov", "createdAt": "2020-11-03T15:19:55Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/logical/ValuesUnionLogicalRule.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.logical;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.hazelcast.jet.sql.impl.opt.OptUtils;\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rel.core.RelFactories;\n+import org.apache.calcite.rel.core.Union;\n+import org.apache.calcite.rel.logical.LogicalUnion;\n+import org.apache.calcite.rel.logical.LogicalValues;\n+import org.apache.calcite.rex.RexLiteral;\n+\n+import static java.util.stream.Collectors.collectingAndThen;\n+import static java.util.stream.Collectors.toList;\n+\n+final class ValuesUnionLogicalRule extends RelOptRule {\n+\n+    static final RelOptRule INSTANCE;\n+\n+    private static final RelOptRuleOperand CHILD_OPERAND;\n+\n+    static {\n+        CHILD_OPERAND = operand(LogicalValues.class, none());\n+        INSTANCE = new ValuesUnionLogicalRule();\n+    }\n+\n+    private ValuesUnionLogicalRule() {", "originalCommit": "6aad27680ae85a3e286ae8ebac6dfb85abbe0762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc1NDc1MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516754750", "bodyText": "Queries like SELECT * FROM (VALUES (1), (1 + 2)) (with an expression in one of the rows) are translated to UNION of VALUEs by Calcite. For such cases we have tests.", "author": "gierlachg", "createdAt": "2020-11-03T15:30:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NjIzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc2OTI0MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516769241", "bodyText": "It also allows VALUES (1), (2), that is multiple rows in VALUES. See for example here.", "author": "viliam-durina", "createdAt": "2020-11-03T15:50:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NjIzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc3MTE5Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516771193", "bodyText": "However, VALUES (1), (2) does not need support from ValuesUnionLogicalRule.", "author": "gierlachg", "createdAt": "2020-11-03T15:52:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NjIzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc3NTM0OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516775349", "bodyText": "I see, thanks.", "author": "devozerov", "createdAt": "2020-11-03T15:58:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0NjIzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0ODM1OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516748358", "bodyText": "AFAIU joins are not supported in this release. If so, the rule ProjectJoinTransposeRule is not needed here.", "author": "devozerov", "createdAt": "2020-11-03T15:22:39Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/logical/LogicalRules.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.logical;\n+\n+import org.apache.calcite.rel.rules.FilterMergeRule;\n+import org.apache.calcite.rel.rules.FilterProjectTransposeRule;\n+import org.apache.calcite.rel.rules.ProjectFilterTransposeRule;\n+import org.apache.calcite.rel.rules.ProjectJoinTransposeRule;\n+import org.apache.calcite.rel.rules.ProjectMergeRule;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.rules.PruneEmptyRules;\n+import org.apache.calcite.tools.RuleSet;\n+import org.apache.calcite.tools.RuleSets;\n+\n+public final class LogicalRules {\n+\n+    private LogicalRules() {\n+    }\n+\n+    public static RuleSet getRuleSet() {\n+        return RuleSets.ofList(\n+                // Filter rules.\n+                FilterLogicalRule.INSTANCE,\n+                FilterMergeRule.INSTANCE,\n+                FilterProjectTransposeRule.INSTANCE,\n+                FilterIntoScanLogicalRule.INSTANCE,\n+\n+                // Project rules\n+                ProjectLogicalRule.INSTANCE,\n+                ProjectMergeRule.INSTANCE,\n+                ProjectRemoveRule.INSTANCE,\n+                ProjectFilterTransposeRule.INSTANCE,\n+                ProjectJoinTransposeRule.INSTANCE,", "originalCommit": "6aad27680ae85a3e286ae8ebac6dfb85abbe0762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc4MTU3MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516781570", "bodyText": "Removed.\nBut it's also in IMDG's LogicalRules :)", "author": "viliam-durina", "createdAt": "2020-11-03T16:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc0ODM1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc1MjU0NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516752544", "bodyText": "This code is copy-paste from the IMDG planner. Please beware that PHYICAL.canConvertConvention=true is a kind of hack to simulate bottom-up physical optimization. We borrowed this idea from the Apache Drill project. Without it, the optimizer cannot derive the physical properties of children nodes and hence cannot plan optimal physical implementations. The side effect of this hack is excessive invocations of physical rules, which could become a problem when we introduce joins.\nI analyzed other possible solutions to the problem recently. Another approach is to use a custom converter rule (instead of the new AbstractConverter.ExpandConversionRule that is used in PhysicalRules) that pulls physical properties in a top-down way. Apache Flink works this way. In the future, we will need to understand which of this approaches is better for complex queries. So there is a risk that we will have to rework it from \"Drill-way\" to \"Flink-way\".\nI do not propose any changes now, just be aware of this possibility.", "author": "devozerov", "createdAt": "2020-11-03T15:28:06Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/JetConventions.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt;\n+\n+import com.hazelcast.jet.sql.impl.opt.logical.LogicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.PhysicalRel;\n+import org.apache.calcite.plan.Convention;\n+import org.apache.calcite.plan.RelTraitSet;\n+\n+public final class JetConventions {\n+\n+    public static final Convention LOGICAL = new Convention.Impl(\"LOGICAL\", LogicalRel.class);\n+\n+    public static final Convention PHYSICAL = new Convention.Impl(\"PHYSICAL\", PhysicalRel.class) {\n+        @Override\n+        public boolean canConvertConvention(Convention toConvention) {\n+            return true;", "originalCommit": "6aad27680ae85a3e286ae8ebac6dfb85abbe0762", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc2Mzg5Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516763896", "bodyText": "Hmm, PHYICAL.canConvertConvention=true does not seem to have any influence on Jet, setting it to false does not break any tests...", "author": "gierlachg", "createdAt": "2020-11-03T15:42:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc1MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc4MzA3OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516783078", "bodyText": "Maybe the test queries are not complicated enough, or maybe something changed in Apache Calcite. In IMDG the problem manifested in complex TPC-H queries. I tried to change it to false, and tests also worked. But we do not have join planning yet, this is where the problem may re-appear. I think just demonstrates once again that we should better understand what we are doing here in the future :-)", "author": "devozerov", "createdAt": "2020-11-03T16:08:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc1MjU0NA=="}], "type": "inlineReview"}, {"oid": "278f87e7d1c5d9499596bc5eb6fd6fd0482bf42a", "url": "https://github.com/hazelcast/hazelcast-jet/commit/278f87e7d1c5d9499596bc5eb6fd6fd0482bf42a", "message": "Move CreateDagVisitor", "committedDate": "2020-11-03T15:34:41Z", "type": "commit"}, {"oid": "22226feec740f815d39efaad1ee0ed5b20a5e211", "url": "https://github.com/hazelcast/hazelcast-jet/commit/22226feec740f815d39efaad1ee0ed5b20a5e211", "message": "Document SqlConnector", "committedDate": "2020-11-03T15:34:42Z", "type": "commit"}, {"oid": "4ec97b46b184292898a3a33f417c38fa3ce549fa", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4ec97b46b184292898a3a33f417c38fa3ce549fa", "message": "Remove unused timestampField", "committedDate": "2020-11-03T15:35:18Z", "type": "commit"}, {"oid": "a336e729ce7a62eb885439ee08c87811c8e51587", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a336e729ce7a62eb885439ee08c87811c8e51587", "message": "Move JetSqlToRelConverter, ExpressionUtil", "committedDate": "2020-11-03T15:45:46Z", "type": "commit"}, {"oid": "f185de455d31b436dbd9d8daf544707aeeb53b91", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f185de455d31b436dbd9d8daf544707aeeb53b91", "message": "Remove ProjectJoinTransposeRule", "committedDate": "2020-11-03T16:07:34Z", "type": "commit"}, {"oid": "bea35e9233d5466a65f8baef04d578c2e096b2f5", "url": "https://github.com/hazelcast/hazelcast-jet/commit/bea35e9233d5466a65f8baef04d578c2e096b2f5", "message": "Revert the dependency", "committedDate": "2020-11-03T16:10:59Z", "type": "commit"}, {"oid": "fc2fca3d16f968920399c0d28a8eb383945ccad3", "url": "https://github.com/hazelcast/hazelcast-jet/commit/fc2fca3d16f968920399c0d28a8eb383945ccad3", "message": "Rename visit -> accept", "committedDate": "2020-11-03T16:14:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc5NTc0Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516795743", "bodyText": "Looks like Jet couldn't use indexes at the moment. Is this the case? If yes, then it should be relatively simple to refactor IMDG part (IndexResolver) a bit, to allow for index planning in Jet.", "author": "devozerov", "createdAt": "2020-11-03T16:26:53Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/opt/physical/FullScanPhysicalRule.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl.opt.physical;\n+\n+import com.hazelcast.jet.sql.impl.opt.OptUtils;\n+import com.hazelcast.jet.sql.impl.opt.logical.FullScanLogicalRel;\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.convert.ConverterRule;\n+\n+import static com.hazelcast.jet.sql.impl.opt.JetConventions.LOGICAL;\n+import static com.hazelcast.jet.sql.impl.opt.JetConventions.PHYSICAL;\n+\n+final class FullScanPhysicalRule extends ConverterRule {\n+\n+    static final RelOptRule INSTANCE = new FullScanPhysicalRule();\n+\n+    private FullScanPhysicalRule() {\n+        super(\n+                FullScanLogicalRel.class, LOGICAL, PHYSICAL,\n+                FullScanPhysicalRule.class.getSimpleName()\n+        );\n+    }\n+\n+    @Override\n+    public RelNode convert(RelNode rel) {\n+        FullScanLogicalRel logicalScan = (FullScanLogicalRel) rel;\n+\n+        return new FullScanPhysicalRel(", "originalCommit": "4ec97b46b184292898a3a33f417c38fa3ce549fa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjgwMTM3Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516801373", "bodyText": "This PR cannot read IMaps at all using Jet for now.", "author": "viliam-durina", "createdAt": "2020-11-03T16:34:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc5NTc0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc5NjgzMw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r516796833", "bodyText": "When looking at the physical part I was surprised that you do not use distribution during planning. For example, it seems that the query like SELECT * FROM VALUES (1) (2) will be executed in distributed mode. Is this the case?", "author": "devozerov", "createdAt": "2020-11-03T16:28:28Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/JetSqlBackend.java", "diffHunk": "@@ -0,0 +1,308 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.sql.impl;\n+\n+import com.hazelcast.jet.core.DAG;\n+import com.hazelcast.jet.sql.impl.JetPlan.AlterJobPlan;\n+import com.hazelcast.jet.sql.impl.JetPlan.CreateJobPlan;\n+import com.hazelcast.jet.sql.impl.JetPlan.CreateMappingPlan;\n+import com.hazelcast.jet.sql.impl.JetPlan.CreateSnapshotPlan;\n+import com.hazelcast.jet.sql.impl.JetPlan.DropJobPlan;\n+import com.hazelcast.jet.sql.impl.JetPlan.DropMappingPlan;\n+import com.hazelcast.jet.sql.impl.JetPlan.DropSnapshotPlan;\n+import com.hazelcast.jet.sql.impl.JetPlan.ExecutionPlan;\n+import com.hazelcast.jet.sql.impl.calcite.parser.JetSqlParser;\n+import com.hazelcast.jet.sql.impl.convert.JetSqlToRelConverter;\n+import com.hazelcast.jet.sql.impl.opt.OptUtils;\n+import com.hazelcast.jet.sql.impl.opt.logical.LogicalRel;\n+import com.hazelcast.jet.sql.impl.opt.logical.LogicalRules;\n+import com.hazelcast.jet.sql.impl.opt.physical.JetRootRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.PhysicalRel;\n+import com.hazelcast.jet.sql.impl.opt.physical.PhysicalRules;\n+import com.hazelcast.jet.sql.impl.opt.physical.CreateDagVisitor;\n+import com.hazelcast.jet.sql.impl.parse.SqlAlterJob;\n+import com.hazelcast.jet.sql.impl.parse.SqlCreateJob;\n+import com.hazelcast.jet.sql.impl.parse.SqlCreateMapping;\n+import com.hazelcast.jet.sql.impl.parse.SqlCreateSnapshot;\n+import com.hazelcast.jet.sql.impl.parse.SqlDropJob;\n+import com.hazelcast.jet.sql.impl.parse.SqlDropMapping;\n+import com.hazelcast.jet.sql.impl.parse.SqlDropSnapshot;\n+import com.hazelcast.jet.sql.impl.schema.JetTable;\n+import com.hazelcast.jet.sql.impl.schema.Mapping;\n+import com.hazelcast.jet.sql.impl.schema.MappingField;\n+import com.hazelcast.jet.sql.impl.validate.JetSqlValidator;\n+import com.hazelcast.jet.sql.impl.validate.UnsupportedOperationVisitor;\n+import com.hazelcast.logging.ILogger;\n+import com.hazelcast.spi.impl.NodeEngine;\n+import com.hazelcast.sql.SqlColumnMetadata;\n+import com.hazelcast.sql.SqlRowMetadata;\n+import com.hazelcast.sql.impl.QueryId;\n+import com.hazelcast.sql.impl.QueryUtils;\n+import com.hazelcast.sql.impl.calcite.OptimizerContext;\n+import com.hazelcast.sql.impl.calcite.SqlBackend;\n+import com.hazelcast.sql.impl.calcite.parse.QueryConvertResult;\n+import com.hazelcast.sql.impl.calcite.parse.QueryParseResult;\n+import com.hazelcast.sql.impl.calcite.validate.types.HazelcastTypeFactory;\n+import com.hazelcast.sql.impl.optimizer.OptimizationTask;\n+import com.hazelcast.sql.impl.optimizer.SqlPlan;\n+import com.hazelcast.sql.impl.type.QueryDataType;\n+import org.apache.calcite.plan.RelOptCluster;\n+import org.apache.calcite.plan.RelOptTable.ViewExpander;\n+import org.apache.calcite.plan.RelOptUtil;\n+import org.apache.calcite.prepare.Prepare.CatalogReader;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.RelVisitor;\n+import org.apache.calcite.rel.core.TableModify;\n+import org.apache.calcite.rel.core.TableScan;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.parser.SqlParserImplFactory;\n+import org.apache.calcite.sql.util.SqlVisitor;\n+import org.apache.calcite.sql.validate.SqlConformance;\n+import org.apache.calcite.sql.validate.SqlValidator;\n+import org.apache.calcite.sql2rel.SqlRexConvertletTable;\n+import org.apache.calcite.sql2rel.SqlToRelConverter;\n+import org.apache.calcite.sql2rel.SqlToRelConverter.Config;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+class JetSqlBackend implements SqlBackend {\n+\n+    private final NodeEngine nodeEngine;\n+    private final JetPlanExecutor planExecutor;\n+\n+    private final ILogger logger;\n+\n+    JetSqlBackend(NodeEngine nodeEngine, JetPlanExecutor planExecutor) {\n+        this.nodeEngine = nodeEngine;\n+        this.planExecutor = planExecutor;\n+\n+        this.logger = nodeEngine.getLogger(getClass());\n+    }\n+\n+    @Override\n+    public SqlParserImplFactory parserFactory() {\n+        return JetSqlParser.FACTORY;\n+    }\n+\n+    @Override\n+    public SqlValidator validator(\n+            CatalogReader catalogReader,\n+            HazelcastTypeFactory typeFactory,\n+            SqlConformance sqlConformance\n+    ) {\n+        return new JetSqlValidator(catalogReader, typeFactory, sqlConformance);\n+    }\n+\n+    @Override\n+    public SqlVisitor<Void> unsupportedOperationVisitor(CatalogReader catalogReader) {\n+        return UnsupportedOperationVisitor.INSTANCE;\n+    }\n+\n+    @Override\n+    public SqlToRelConverter converter(\n+            ViewExpander viewExpander,\n+            SqlValidator sqlValidator,\n+            CatalogReader catalogReader,\n+            RelOptCluster relOptCluster,\n+            SqlRexConvertletTable sqlRexConvertletTable,\n+            Config config\n+    ) {\n+        return new JetSqlToRelConverter(\n+                viewExpander,\n+                sqlValidator,\n+                catalogReader,\n+                relOptCluster,\n+                sqlRexConvertletTable,\n+                config\n+        );\n+    }\n+\n+    @Override\n+    public SqlPlan createPlan(\n+            OptimizationTask task,\n+            QueryParseResult parseResult,\n+            OptimizerContext context\n+    ) {\n+        SqlNode node = parseResult.getNode();\n+\n+        if (node instanceof SqlCreateMapping) {\n+            return toCreateMappingPlan((SqlCreateMapping) node);\n+        } else if (node instanceof SqlDropMapping) {\n+            return toDropMappingPlan((SqlDropMapping) node);\n+        } else if (node instanceof SqlCreateJob) {\n+            return toCreateJobPlan(parseResult, context);\n+        } else if (node instanceof SqlAlterJob) {\n+            return toAlterJobPlan((SqlAlterJob) node);\n+        } else if (node instanceof SqlDropJob) {\n+            return toDropJobPlan((SqlDropJob) node);\n+        } else if (node instanceof SqlCreateSnapshot) {\n+            return toCreateSnapshotPlan((SqlCreateSnapshot) node);\n+        } else if (node instanceof SqlDropSnapshot) {\n+            return toDropSnapshotPlan((SqlDropSnapshot) node);\n+        } else {\n+            QueryConvertResult convertResult = context.convert(parseResult);\n+            return toPlan(convertResult.getRel(), convertResult.getFieldNames(), context);\n+        }\n+    }\n+\n+    private SqlPlan toCreateMappingPlan(SqlCreateMapping sqlCreateMapping) {\n+        List<MappingField> mappingFields = sqlCreateMapping.columns()\n+                .map(field -> new MappingField(field.name(), field.type(), field.externalName()))\n+                .collect(toList());\n+        Mapping mapping = new Mapping(\n+                sqlCreateMapping.name(),\n+                sqlCreateMapping.type(),\n+                mappingFields,\n+                sqlCreateMapping.options()\n+        );\n+\n+        return new CreateMappingPlan(\n+                mapping,\n+                sqlCreateMapping.getReplace(),\n+                sqlCreateMapping.ifNotExists(),\n+                planExecutor\n+        );\n+    }\n+\n+    private SqlPlan toDropMappingPlan(SqlDropMapping sqlDropMapping) {\n+        return new DropMappingPlan(sqlDropMapping.name(), sqlDropMapping.ifExists(), planExecutor);\n+    }\n+\n+    private SqlPlan toCreateJobPlan(QueryParseResult parseResult, OptimizerContext context) {\n+        SqlCreateJob sqlCreateJob = (SqlCreateJob) parseResult.getNode();\n+        SqlNode source = sqlCreateJob.dmlStatement();\n+\n+        QueryParseResult dmlParseResult =\n+                new QueryParseResult(source, parseResult.getParameterRowType(), parseResult.getValidator(), this);\n+        QueryConvertResult dmlConvertedResult = context.convert(dmlParseResult);\n+        ExecutionPlan dmlPlan = toPlan(dmlConvertedResult.getRel(), dmlConvertedResult.getFieldNames(), context);\n+\n+        return new CreateJobPlan(\n+                sqlCreateJob.name(),\n+                sqlCreateJob.jobConfig(),\n+                sqlCreateJob.ifNotExists(),\n+                dmlPlan,\n+                planExecutor\n+        );\n+    }\n+\n+    private SqlPlan toAlterJobPlan(SqlAlterJob sqlAlterJob) {\n+        return new AlterJobPlan(sqlAlterJob.name(), sqlAlterJob.getOperation(), planExecutor);\n+    }\n+\n+    private SqlPlan toDropJobPlan(SqlDropJob sqlDropJob) {\n+        return new DropJobPlan(sqlDropJob.name(), sqlDropJob.ifExists(), sqlDropJob.withSnapshotName(), planExecutor);\n+    }\n+\n+    private SqlPlan toCreateSnapshotPlan(SqlCreateSnapshot sqlNode) {\n+        return new CreateSnapshotPlan(sqlNode.getSnapshotName(), sqlNode.getJobName(), planExecutor);\n+    }\n+\n+    private SqlPlan toDropSnapshotPlan(SqlDropSnapshot sqlNode) {\n+        return new DropSnapshotPlan(sqlNode.getSnapshotName(), sqlNode.isIfExists(), planExecutor);\n+    }\n+\n+    private ExecutionPlan toPlan(RelNode rel, List<String> fieldNames, OptimizerContext context) {\n+        logger.fine(\"Before logical opt:\\n\" + RelOptUtil.toString(rel));\n+        LogicalRel logicalRel = optimizeLogical(context, rel);\n+        logger.fine(\"After logical opt:\\n\" + RelOptUtil.toString(logicalRel));\n+        PhysicalRel physicalRel = optimizePhysical(context, logicalRel);\n+        logger.fine(\"After physical opt:\\n\" + RelOptUtil.toString(physicalRel));\n+\n+        boolean isStreaming = containsStreamSource(rel);\n+        boolean isInsert = physicalRel instanceof TableModify;\n+\n+        if (isInsert) {\n+            DAG dag = createDag(physicalRel);\n+            return new ExecutionPlan(dag, isStreaming, true, null, null, planExecutor);\n+        } else {\n+            QueryId queryId = QueryId.create(nodeEngine.getLocalMember().getUuid());\n+            DAG dag = createDag(new JetRootRel(physicalRel, nodeEngine.getThisAddress(), queryId));\n+            SqlRowMetadata rowMetadata = createRowMetadata(fieldNames, physicalRel.schema().getTypes());\n+            return new ExecutionPlan(dag, isStreaming, false, queryId, rowMetadata, planExecutor);\n+        }\n+    }\n+\n+    /**\n+     * Perform logical optimization.\n+     *\n+     * @param rel Original logical tree.\n+     * @return Optimized logical tree.\n+     */\n+    private LogicalRel optimizeLogical(OptimizerContext context, RelNode rel) {\n+        return (LogicalRel) context.optimize(\n+                rel,\n+                LogicalRules.getRuleSet(),\n+                OptUtils.toLogicalConvention(rel.getTraitSet())\n+        );\n+    }\n+\n+    /**\n+     * Perform physical optimization.\n+     * This is where proper access methods and algorithms for joins and aggregations are chosen.\n+     *\n+     * @param rel Optimized logical tree.\n+     * @return Optimized physical tree.\n+     */\n+    private PhysicalRel optimizePhysical(OptimizerContext context, RelNode rel) {", "originalCommit": "4ec97b46b184292898a3a33f417c38fa3ce549fa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzM3NjM1Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2620#discussion_r517376352", "bodyText": "Yes. Jet doesn't have means to dispatch some processors to some members. It always goes to all members, but some members will do nothing.", "author": "viliam-durina", "createdAt": "2020-11-04T14:19:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc5NjgzMw=="}], "type": "inlineReview"}, {"oid": "96a747d873321f10efcac65aaeedb922cdc64bc3", "url": "https://github.com/hazelcast/hazelcast-jet/commit/96a747d873321f10efcac65aaeedb922cdc64bc3", "message": "Remove Jet rules and use those from IMDG", "committedDate": "2020-11-03T16:31:29Z", "type": "commit"}, {"oid": "441bfbb42bf4df5d3288b18128c488190a23877d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/441bfbb42bf4df5d3288b18128c488190a23877d", "message": "Follow IMDG changes - use slim jar.", "committedDate": "2020-11-03T19:02:30Z", "type": "commit"}, {"oid": "c03ce0a4df1cf9d6d34ab93c23fa9aa07a6e33d7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/c03ce0a4df1cf9d6d34ab93c23fa9aa07a6e33d7", "message": "Adjust NOTICE", "committedDate": "2020-11-04T10:06:50Z", "type": "commit"}, {"oid": "5372fe3ffd258262a18ed755eca66a29e3f4a496", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5372fe3ffd258262a18ed755eca66a29e3f4a496", "message": "Fix __key & this extraction from json IMap + tests", "committedDate": "2020-11-04T14:30:07Z", "type": "commit"}, {"oid": "cc2bb1d3d7cec65070a805bfd3925c177e193118", "url": "https://github.com/hazelcast/hazelcast-jet/commit/cc2bb1d3d7cec65070a805bfd3925c177e193118", "message": "Simplify", "committedDate": "2020-11-04T14:42:48Z", "type": "commit"}, {"oid": "e70975061ad18725547a0bd37be56841480cace0", "url": "https://github.com/hazelcast/hazelcast-jet/commit/e70975061ad18725547a0bd37be56841480cace0", "message": "Remove unused import", "committedDate": "2020-11-04T14:46:06Z", "type": "commit"}, {"oid": "909440bccf0a02b1f2cc5b9dccdcdaffcf2b458d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/909440bccf0a02b1f2cc5b9dccdcdaffcf2b458d", "message": "Use the sqlTypeName only in unparse()", "committedDate": "2020-11-04T14:55:31Z", "type": "commit"}, {"oid": "c8b62778f13c1e79659646775207f5b65dc2be8e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/c8b62778f13c1e79659646775207f5b65dc2be8e", "message": "Improve the asserts", "committedDate": "2020-11-04T14:55:32Z", "type": "commit"}, {"oid": "0e3bfa49295b21f6c1db7b21335f90b98ca0ceb3", "url": "https://github.com/hazelcast/hazelcast-jet/commit/0e3bfa49295b21f6c1db7b21335f90b98ca0ceb3", "message": "Use standard names in information_schema.columns", "committedDate": "2020-11-04T14:55:34Z", "type": "commit"}, {"oid": "e058898b6536ca97efa5c700443705eb8e772b17", "url": "https://github.com/hazelcast/hazelcast-jet/commit/e058898b6536ca97efa5c700443705eb8e772b17", "message": "Format", "committedDate": "2020-11-04T15:07:42Z", "type": "commit"}, {"oid": "9896184b6d61907013a6ee6843af61c60d68b6e2", "url": "https://github.com/hazelcast/hazelcast-jet/commit/9896184b6d61907013a6ee6843af61c60d68b6e2", "message": "Fix tests, fix type of `ordinal_position`", "committedDate": "2020-11-04T15:12:58Z", "type": "commit"}, {"oid": "78e9796702276ff6cc812104cee6e41623875dc7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/78e9796702276ff6cc812104cee6e41623875dc7", "message": "Fix test failures", "committedDate": "2020-11-04T15:19:46Z", "type": "commit"}, {"oid": "6f2a2cfa391c50475c53b19770a26ca36bb2bc39", "url": "https://github.com/hazelcast/hazelcast-jet/commit/6f2a2cfa391c50475c53b19770a26ca36bb2bc39", "message": "Fix race in JetQueryResultProducer\n\nWe've set `done` and then `error`. An `isDone` call could observe `done==true`, but not yet the error.", "committedDate": "2020-11-04T16:08:58Z", "type": "commit"}, {"oid": "8f57de5def9a9c4b60758cebf60afb836414a9ad", "url": "https://github.com/hazelcast/hazelcast-jet/commit/8f57de5def9a9c4b60758cebf60afb836414a9ad", "message": "Fix __key & this extraction from Kafka", "committedDate": "2020-11-05T07:18:29Z", "type": "commit"}, {"oid": "b1cf8f8572c292d4dd0d307e79d3f82f7117b6ef", "url": "https://github.com/hazelcast/hazelcast-jet/commit/b1cf8f8572c292d4dd0d307e79d3f82f7117b6ef", "message": "Add INTEGER as alias to INT", "committedDate": "2020-11-05T10:08:52Z", "type": "commit"}, {"oid": "12adf16a0e853d3b2363dd8dd73b294483c0f798", "url": "https://github.com/hazelcast/hazelcast-jet/commit/12adf16a0e853d3b2363dd8dd73b294483c0f798", "message": "Support all Calcite aliases", "committedDate": "2020-11-05T10:32:37Z", "type": "commit"}]}