{"pr_number": 2387, "pr_title": "[005] - Add CDC Join tutorial and fix other minor issues", "pr_createdAt": "2020-07-02T10:44:26Z", "pr_url": "https://github.com/hazelcast/hazelcast-jet/pull/2387", "timeline": [{"oid": "f5d391425cf35d3f1a686584bf52d3c395ff34a4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f5d391425cf35d3f1a686584bf52d3c395ff34a4", "message": "Add join tutorial and various fixes", "committedDate": "2020-07-02T10:34:18Z", "type": "commit"}, {"oid": "4db75ddf15cd00081ebb1171a127c68f50065041", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4db75ddf15cd00081ebb1171a127c68f50065041", "message": "Merge branch 'master' into docs-improvements", "committedDate": "2020-07-02T10:46:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyMTExNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r448921117", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            for the **streaming of changes from databases**, which can be\n          \n          \n            \n            **streaming changes from a database**, which can be", "author": "frant-hartm", "createdAt": "2020-07-02T11:00:04Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwNTgwMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449405800", "bodyText": "In my opinion the correction is not grammatically correct and does not improve the original version.", "author": "jbartok", "createdAt": "2020-07-03T06:48:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyMTExNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyMjczOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r448922739", "bodyText": "There should be a comma somewhere :-).\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            [MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've\n          \n          \n            \n            [MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases, we've", "author": "frant-hartm", "createdAt": "2020-07-02T11:03:48Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyMzE5MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r448923190", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            seen how to monitor single database tables and how maintain an\n          \n          \n            \n            seen how to monitor a single database table and how to maintain an", "author": "frant-hartm", "createdAt": "2020-07-02T11:04:48Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've\n+seen how to monitor single database tables and how maintain an", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNDAwMw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r448924003", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            up-to-date image of them in memory, as a map.\n          \n          \n            \n            up-to-date image of the table in memory, in a form of a map.", "author": "frant-hartm", "createdAt": "2020-07-02T11:06:28Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've\n+seen how to monitor single database tables and how maintain an\n+up-to-date image of them in memory, as a map.", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNDgyMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r448924820", "bodyText": "Is this for just postgres or both postgres and mysql?", "author": "frant-hartm", "createdAt": "2020-07-02T11:08:13Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've\n+seen how to monitor single database tables and how maintain an\n+up-to-date image of them in memory, as a map.\n+\n+Here we will examine how to make our map hold enriched data, combined\n+(joined, if you will) from multiple tables. Let's say customers and all\n+the orders belonging to them, as one entity.\n+\n+## 1. Install Docker\n+\n+This tutorial uses [Docker](https://www.docker.com/) to simplify the\n+setup of a PostgreSQL database, which you can freely experiment on.", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwNjkwNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449406905", "bodyText": "Good catch, copy-paste error.", "author": "jbartok", "createdAt": "2020-07-03T06:51:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNDgyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNTIwOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r448925209", "bodyText": "Seems to contain both?", "author": "frant-hartm", "createdAt": "2020-07-02T11:09:11Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've\n+seen how to monitor single database tables and how maintain an\n+up-to-date image of them in memory, as a map.\n+\n+Here we will examine how to make our map hold enriched data, combined\n+(joined, if you will) from multiple tables. Let's say customers and all\n+the orders belonging to them, as one entity.\n+\n+## 1. Install Docker\n+\n+This tutorial uses [Docker](https://www.docker.com/) to simplify the\n+setup of a PostgreSQL database, which you can freely experiment on.\n+\n+1. Follow Docker's [Get Started](https://www.docker.com/get-started)\n+   instructions and install it on your system.\n+2. Test that it works:\n+   * Run `docker version` to check that you have the latest release\n+     installed.\n+   * Run `docker run hello-world` to verify that Docker is pulling\n+     images and running as expected.\n+\n+## 2. Start Database\n+\n+In this tutorial we will provide all code and configs for MySQL, but", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwNzQzOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449407439", "bodyText": "Yeah, I was thorn between covering both or focusing on one of them and this is a left-over. Will fix.", "author": "jbartok", "createdAt": "2020-07-03T06:52:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNTIwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNjA4NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r448926085", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            processing stage which handles and fixes event reoreding that might\n          \n          \n            \n            processing stage which handles and fixes event reordering that might", "author": "frant-hartm", "createdAt": "2020-07-02T11:11:08Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've\n+seen how to monitor single database tables and how maintain an\n+up-to-date image of them in memory, as a map.\n+\n+Here we will examine how to make our map hold enriched data, combined\n+(joined, if you will) from multiple tables. Let's say customers and all\n+the orders belonging to them, as one entity.\n+\n+## 1. Install Docker\n+\n+This tutorial uses [Docker](https://www.docker.com/) to simplify the\n+setup of a PostgreSQL database, which you can freely experiment on.\n+\n+1. Follow Docker's [Get Started](https://www.docker.com/get-started)\n+   instructions and install it on your system.\n+2. Test that it works:\n+   * Run `docker version` to check that you have the latest release\n+     installed.\n+   * Run `docker run hello-world` to verify that Docker is pulling\n+     images and running as expected.\n+\n+## 2. Start Database\n+\n+In this tutorial we will provide all code and configs for MySQL, but\n+adapting them to any of the databases covered by the previous tutorials\n+should be pretty straightforward.\n+\n+Exact instructions for starting the supported databases are as follows:\n+\n+* [MySQL](cdc-mysql.md#2-start-mysql-database)\n+* [Postgres](cdc-postgres.md#2-start-postgresql-database).\n+\n+## 3. Start Command Line Client\n+\n+Exact instructions for starting the specific Command Line Client of the\n+supported databases are as follows:\n+\n+* [MySQL](cdc-mysql.md#3-start-mysql-command-line-client)\n+* [Postgres](cdc-postgres.md#3-start-postgresql-command-line-client)\n+\n+## 4. Create a New Java Project\n+\n+The configuration needed differs based on which database will be used.\n+See exact instructions here:\n+\n+* [MySQL](cdc-mysql.md#5-create-a-new-java-project)\n+* [Postgres](cdc-postgres.md#5-create-a-new-java-project)\n+\n+## 5. Define Jet Job\n+\n+Let's write the Jet code for the processing we want to accomplish:\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.Jet;\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.mysql.MySqlCdcSources;\n+import com.hazelcast.jet.config.JobConfig;\n+import com.hazelcast.jet.pipeline.Pipeline;\n+import com.hazelcast.jet.pipeline.Sinks;\n+import com.hazelcast.jet.pipeline.StreamSource;\n+import com.hazelcast.jet.pipeline.StreamStage;\n+\n+public class JetJob {\n+\n+    private static final int MAX_CONCURRENT_OPERATIONS = 1;\n+\n+    public static void main(String[] args) {\n+        StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+            .setDatabaseAddress(\"127.0.0.1\")\n+            .setDatabasePort(3306)\n+            .setDatabaseUser(\"debezium\")\n+            .setDatabasePassword(\"dbz\")\n+            .setClusterName(\"dbserver1\")\n+            .setDatabaseWhitelist(\"inventory\")\n+            .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+            .build();\n+\n+        Pipeline pipeline = Pipeline.create();\n+        StreamStage<ChangeRecord> allRecords = pipeline.readFrom(source)\n+                .withNativeTimestamps(0);\n+\n+        allRecords.filter(r -> r.table().equals(\"customers\"))\n+                .apply(Ordering::fix)\n+                .peek()\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, \"cache\",\n+                        record -> (Integer) record.key().toMap().get(\"id\"),\n+                        CustomerEntryProcessor::new\n+                ));\n+\n+        allRecords.filter(r -> r.table().equals(\"orders\"))\n+                .apply(Ordering::fix)\n+                .peek()\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, \"cache\",\n+                        record -> (Integer) record.value().toMap().get(\"purchaser\"),\n+                        OrderEntryProcessor::new\n+                ));\n+\n+        JobConfig cfg = new JobConfig().setName(\"monitor\");\n+        Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+    }\n+\n+}\n+```\n+\n+If using Postgres, only the source would need to change, like this:\n+\n+```java\n+StreamSource<ChangeRecord> source = PostgresCdcSources.postgres(\"source\")\n+    .setDatabaseAddress(\"127.0.0.1\")\n+    .setDatabasePort(5432)\n+    .setDatabaseUser(\"postgres\")\n+    .setDatabasePassword(\"postgres\")\n+    .setDatabaseName(\"postgres\")\n+    .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+    .build();\n+```\n+\n+As we can see from the pipeline code, our `Sink` is `EntryProcessor`\n+based. The two `EntryProcessors` we use are:\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.map.EntryProcessor;\n+\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class CustomerEntryProcessor implements EntryProcessor<Integer, OrdersOfCustomer, Object> {\n+\n+    private final Customer customer;\n+\n+    public CustomerEntryProcessor(ChangeRecord record) {\n+        try {\n+            this.customer = Operation.DELETE.equals(record.operation()) ? null :\n+                    record.value().toObject(Customer.class);\n+        } catch (ParsingException e) {\n+            throw rethrow(e);\n+        }\n+    }\n+\n+    @Override\n+    public Object process(Map.Entry<Integer, OrdersOfCustomer> entry) {\n+        OrdersOfCustomer value = entry.getValue();\n+        if (customer == null) {\n+            if (value != null) {\n+                value.setCustomer(null);\n+            }\n+        } else {\n+            if (value == null) {\n+                value = new OrdersOfCustomer();\n+            }\n+            value.setCustomer(customer);\n+        }\n+        entry.setValue(value);\n+        return null;\n+    }\n+}\n+```\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.map.EntryProcessor;\n+\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class OrderEntryProcessor implements EntryProcessor<Integer, OrdersOfCustomer, Object> {\n+\n+    private final Operation operation;\n+    private final Order order;\n+\n+    public OrderEntryProcessor(ChangeRecord record) {\n+        try {\n+            this.order = record.value().toObject(Order.class);\n+            this.operation = record.operation();\n+        } catch (ParsingException e) {\n+            throw rethrow(e);\n+        }\n+    }\n+\n+    @Override\n+    public Object process(Map.Entry<Integer, OrdersOfCustomer> entry) {\n+        OrdersOfCustomer value = entry.getValue();\n+        if (Operation.DELETE.equals(operation)) {\n+            if (value != null) {\n+                value.deleteOrder(order);\n+            }\n+        } else {\n+            if (value == null) {\n+                value = new OrdersOfCustomer();\n+            }\n+            value.addOrUpdateOrder(order);\n+        }\n+        entry.setValue(value);\n+        return null;\n+    }\n+}\n+```\n+\n+In them we use a `Customer` and an `Order` for data to object mapping,\n+basically a convenient way of parsing:\n+\n+```java\n+package org.example;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import java.io.Serializable;\n+import java.util.Objects;\n+\n+public class Customer implements Serializable {\n+\n+    @JsonProperty(\"id\")\n+    public int id;\n+\n+    @JsonProperty(\"first_name\")\n+    public String firstName;\n+\n+    @JsonProperty(\"last_name\")\n+    public String lastName;\n+\n+    @JsonProperty(\"email\")\n+    public String email;\n+\n+    Customer() {\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(email, firstName, id, lastName);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        Customer other = (Customer) obj;\n+        return id == other.id\n+                && Objects.equals(firstName, other.firstName)\n+                && Objects.equals(lastName, other.lastName)\n+                && Objects.equals(email, other.email);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Customer {id=\" + id + \", firstName=\" + firstName + \", lastName=\" + lastName + \", email=\" + email + '}';\n+    }\n+}\n+```\n+\n+```java\n+package org.example;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import java.io.Serializable;\n+import java.util.Date;\n+import java.util.Objects;\n+import java.util.concurrent.TimeUnit;\n+\n+public class Order implements Serializable {\n+\n+    @JsonProperty(\"order_number\")\n+    public int orderNumber;\n+\n+    @JsonProperty(\"order_date\")\n+    public Date orderDate;\n+\n+    @JsonProperty(\"purchaser\")\n+    public int purchaser;\n+\n+    @JsonProperty(\"quantity\")\n+    public int quantity;\n+\n+    @JsonProperty(\"product_id\")\n+    public int productId;\n+\n+    Order() {\n+    }\n+\n+    public void setOrderDate(Date orderDate) { //used by object mapping\n+        long days = orderDate.getTime();\n+        this.orderDate = new Date(TimeUnit.DAYS.toMillis(days));\n+    }\n+\n+    public int getOrderNumber() {\n+        return orderNumber;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(orderNumber, orderDate, purchaser, quantity, productId);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        Order other = (Order) obj;\n+        return orderNumber == other.orderNumber\n+                && Objects.equals(orderDate, other.orderDate)\n+                && Objects.equals(purchaser, other.purchaser)\n+                && Objects.equals(quantity, other.quantity)\n+                && Objects.equals(productId, other.productId);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Order {orderNumber=\" + orderNumber + \", orderDate=\" + orderDate + \", purchaser=\" + purchaser +\n+                \", quantity=\" + quantity + \", productId=\" + productId + '}';\n+    }\n+\n+}\n+```\n+\n+Watch out, in the Postgres DB used the order number column is called\n+ `id`, so the first field in `Order` would look like this:\n+\n+```java\n+@JsonProperty(\"id\")\n+public int orderNumber;\n+```\n+\n+Besides the previous two data classes, `Order` and `Customer`, we also\n+define a combined structure, called `OrdersOfCustomers` which holds data\n+about customers and the orders they have generated and will be stored in\n+the target `IMap`:\n+\n+```java\n+package org.example;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class OrdersOfCustomer implements Serializable {\n+\n+    private final Map<Integer, Order> orders;\n+    private Customer customer;\n+\n+    public OrdersOfCustomer() {\n+        this.customer = null;\n+        this.orders = new HashMap<>();\n+    }\n+\n+    public void setCustomer(Customer customer) {\n+        this.customer = customer;\n+    }\n+\n+    public void deleteOrder(Order order) {\n+        orders.remove(order.getOrderNumber());\n+    }\n+\n+    public void addOrUpdateOrder(Order order) {\n+        orders.put(order.getOrderNumber(), order);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(customer, orders);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        OrdersOfCustomer other = (OrdersOfCustomer) obj;\n+        return Objects.equals(customer, other.customer)\n+                && Objects.equals(orders, other.orders);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"Customer: %s, Orders: %s\", customer, orders);\n+    }\n+}\n+```\n+\n+Careful observers will notice another thing going on, an additional\n+processing stage which handles and fixes event reoreding that might", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNzIwMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r448927202", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Pls. append following config lines to the `config/hazelcast.yaml` file,\n          \n          \n            \n            Please append the following config lines to the `config/hazelcast.yaml` file,", "author": "frant-hartm", "createdAt": "2020-07-02T11:13:34Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've\n+seen how to monitor single database tables and how maintain an\n+up-to-date image of them in memory, as a map.\n+\n+Here we will examine how to make our map hold enriched data, combined\n+(joined, if you will) from multiple tables. Let's say customers and all\n+the orders belonging to them, as one entity.\n+\n+## 1. Install Docker\n+\n+This tutorial uses [Docker](https://www.docker.com/) to simplify the\n+setup of a PostgreSQL database, which you can freely experiment on.\n+\n+1. Follow Docker's [Get Started](https://www.docker.com/get-started)\n+   instructions and install it on your system.\n+2. Test that it works:\n+   * Run `docker version` to check that you have the latest release\n+     installed.\n+   * Run `docker run hello-world` to verify that Docker is pulling\n+     images and running as expected.\n+\n+## 2. Start Database\n+\n+In this tutorial we will provide all code and configs for MySQL, but\n+adapting them to any of the databases covered by the previous tutorials\n+should be pretty straightforward.\n+\n+Exact instructions for starting the supported databases are as follows:\n+\n+* [MySQL](cdc-mysql.md#2-start-mysql-database)\n+* [Postgres](cdc-postgres.md#2-start-postgresql-database).\n+\n+## 3. Start Command Line Client\n+\n+Exact instructions for starting the specific Command Line Client of the\n+supported databases are as follows:\n+\n+* [MySQL](cdc-mysql.md#3-start-mysql-command-line-client)\n+* [Postgres](cdc-postgres.md#3-start-postgresql-command-line-client)\n+\n+## 4. Create a New Java Project\n+\n+The configuration needed differs based on which database will be used.\n+See exact instructions here:\n+\n+* [MySQL](cdc-mysql.md#5-create-a-new-java-project)\n+* [Postgres](cdc-postgres.md#5-create-a-new-java-project)\n+\n+## 5. Define Jet Job\n+\n+Let's write the Jet code for the processing we want to accomplish:\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.Jet;\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.mysql.MySqlCdcSources;\n+import com.hazelcast.jet.config.JobConfig;\n+import com.hazelcast.jet.pipeline.Pipeline;\n+import com.hazelcast.jet.pipeline.Sinks;\n+import com.hazelcast.jet.pipeline.StreamSource;\n+import com.hazelcast.jet.pipeline.StreamStage;\n+\n+public class JetJob {\n+\n+    private static final int MAX_CONCURRENT_OPERATIONS = 1;\n+\n+    public static void main(String[] args) {\n+        StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+            .setDatabaseAddress(\"127.0.0.1\")\n+            .setDatabasePort(3306)\n+            .setDatabaseUser(\"debezium\")\n+            .setDatabasePassword(\"dbz\")\n+            .setClusterName(\"dbserver1\")\n+            .setDatabaseWhitelist(\"inventory\")\n+            .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+            .build();\n+\n+        Pipeline pipeline = Pipeline.create();\n+        StreamStage<ChangeRecord> allRecords = pipeline.readFrom(source)\n+                .withNativeTimestamps(0);\n+\n+        allRecords.filter(r -> r.table().equals(\"customers\"))\n+                .apply(Ordering::fix)\n+                .peek()\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, \"cache\",\n+                        record -> (Integer) record.key().toMap().get(\"id\"),\n+                        CustomerEntryProcessor::new\n+                ));\n+\n+        allRecords.filter(r -> r.table().equals(\"orders\"))\n+                .apply(Ordering::fix)\n+                .peek()\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, \"cache\",\n+                        record -> (Integer) record.value().toMap().get(\"purchaser\"),\n+                        OrderEntryProcessor::new\n+                ));\n+\n+        JobConfig cfg = new JobConfig().setName(\"monitor\");\n+        Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+    }\n+\n+}\n+```\n+\n+If using Postgres, only the source would need to change, like this:\n+\n+```java\n+StreamSource<ChangeRecord> source = PostgresCdcSources.postgres(\"source\")\n+    .setDatabaseAddress(\"127.0.0.1\")\n+    .setDatabasePort(5432)\n+    .setDatabaseUser(\"postgres\")\n+    .setDatabasePassword(\"postgres\")\n+    .setDatabaseName(\"postgres\")\n+    .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+    .build();\n+```\n+\n+As we can see from the pipeline code, our `Sink` is `EntryProcessor`\n+based. The two `EntryProcessors` we use are:\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.map.EntryProcessor;\n+\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class CustomerEntryProcessor implements EntryProcessor<Integer, OrdersOfCustomer, Object> {\n+\n+    private final Customer customer;\n+\n+    public CustomerEntryProcessor(ChangeRecord record) {\n+        try {\n+            this.customer = Operation.DELETE.equals(record.operation()) ? null :\n+                    record.value().toObject(Customer.class);\n+        } catch (ParsingException e) {\n+            throw rethrow(e);\n+        }\n+    }\n+\n+    @Override\n+    public Object process(Map.Entry<Integer, OrdersOfCustomer> entry) {\n+        OrdersOfCustomer value = entry.getValue();\n+        if (customer == null) {\n+            if (value != null) {\n+                value.setCustomer(null);\n+            }\n+        } else {\n+            if (value == null) {\n+                value = new OrdersOfCustomer();\n+            }\n+            value.setCustomer(customer);\n+        }\n+        entry.setValue(value);\n+        return null;\n+    }\n+}\n+```\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.map.EntryProcessor;\n+\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class OrderEntryProcessor implements EntryProcessor<Integer, OrdersOfCustomer, Object> {\n+\n+    private final Operation operation;\n+    private final Order order;\n+\n+    public OrderEntryProcessor(ChangeRecord record) {\n+        try {\n+            this.order = record.value().toObject(Order.class);\n+            this.operation = record.operation();\n+        } catch (ParsingException e) {\n+            throw rethrow(e);\n+        }\n+    }\n+\n+    @Override\n+    public Object process(Map.Entry<Integer, OrdersOfCustomer> entry) {\n+        OrdersOfCustomer value = entry.getValue();\n+        if (Operation.DELETE.equals(operation)) {\n+            if (value != null) {\n+                value.deleteOrder(order);\n+            }\n+        } else {\n+            if (value == null) {\n+                value = new OrdersOfCustomer();\n+            }\n+            value.addOrUpdateOrder(order);\n+        }\n+        entry.setValue(value);\n+        return null;\n+    }\n+}\n+```\n+\n+In them we use a `Customer` and an `Order` for data to object mapping,\n+basically a convenient way of parsing:\n+\n+```java\n+package org.example;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import java.io.Serializable;\n+import java.util.Objects;\n+\n+public class Customer implements Serializable {\n+\n+    @JsonProperty(\"id\")\n+    public int id;\n+\n+    @JsonProperty(\"first_name\")\n+    public String firstName;\n+\n+    @JsonProperty(\"last_name\")\n+    public String lastName;\n+\n+    @JsonProperty(\"email\")\n+    public String email;\n+\n+    Customer() {\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(email, firstName, id, lastName);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        Customer other = (Customer) obj;\n+        return id == other.id\n+                && Objects.equals(firstName, other.firstName)\n+                && Objects.equals(lastName, other.lastName)\n+                && Objects.equals(email, other.email);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Customer {id=\" + id + \", firstName=\" + firstName + \", lastName=\" + lastName + \", email=\" + email + '}';\n+    }\n+}\n+```\n+\n+```java\n+package org.example;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import java.io.Serializable;\n+import java.util.Date;\n+import java.util.Objects;\n+import java.util.concurrent.TimeUnit;\n+\n+public class Order implements Serializable {\n+\n+    @JsonProperty(\"order_number\")\n+    public int orderNumber;\n+\n+    @JsonProperty(\"order_date\")\n+    public Date orderDate;\n+\n+    @JsonProperty(\"purchaser\")\n+    public int purchaser;\n+\n+    @JsonProperty(\"quantity\")\n+    public int quantity;\n+\n+    @JsonProperty(\"product_id\")\n+    public int productId;\n+\n+    Order() {\n+    }\n+\n+    public void setOrderDate(Date orderDate) { //used by object mapping\n+        long days = orderDate.getTime();\n+        this.orderDate = new Date(TimeUnit.DAYS.toMillis(days));\n+    }\n+\n+    public int getOrderNumber() {\n+        return orderNumber;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(orderNumber, orderDate, purchaser, quantity, productId);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        Order other = (Order) obj;\n+        return orderNumber == other.orderNumber\n+                && Objects.equals(orderDate, other.orderDate)\n+                && Objects.equals(purchaser, other.purchaser)\n+                && Objects.equals(quantity, other.quantity)\n+                && Objects.equals(productId, other.productId);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Order {orderNumber=\" + orderNumber + \", orderDate=\" + orderDate + \", purchaser=\" + purchaser +\n+                \", quantity=\" + quantity + \", productId=\" + productId + '}';\n+    }\n+\n+}\n+```\n+\n+Watch out, in the Postgres DB used the order number column is called\n+ `id`, so the first field in `Order` would look like this:\n+\n+```java\n+@JsonProperty(\"id\")\n+public int orderNumber;\n+```\n+\n+Besides the previous two data classes, `Order` and `Customer`, we also\n+define a combined structure, called `OrdersOfCustomers` which holds data\n+about customers and the orders they have generated and will be stored in\n+the target `IMap`:\n+\n+```java\n+package org.example;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class OrdersOfCustomer implements Serializable {\n+\n+    private final Map<Integer, Order> orders;\n+    private Customer customer;\n+\n+    public OrdersOfCustomer() {\n+        this.customer = null;\n+        this.orders = new HashMap<>();\n+    }\n+\n+    public void setCustomer(Customer customer) {\n+        this.customer = customer;\n+    }\n+\n+    public void deleteOrder(Order order) {\n+        orders.remove(order.getOrderNumber());\n+    }\n+\n+    public void addOrUpdateOrder(Order order) {\n+        orders.put(order.getOrderNumber(), order);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(customer, orders);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        OrdersOfCustomer other = (OrdersOfCustomer) obj;\n+        return Objects.equals(customer, other.customer)\n+                && Objects.equals(orders, other.orders);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"Customer: %s, Orders: %s\", customer, orders);\n+    }\n+}\n+```\n+\n+Careful observers will notice another thing going on, an additional\n+processing stage which handles and fixes event reoreding that might\n+happen in our parallel processing pipeline. It's based on non-public\n+classes because future versions of Jet (4.3 most likely) will contain\n+generic solutions for the reordering problem and then this code will\n+no longer be necessary:\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.accumulator.LongAccumulator;\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.RecordPart;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.function.TriFunction;\n+import com.hazelcast.jet.pipeline.StreamStage;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+public class Ordering {\n+\n+    static StreamStage<ChangeRecord> fix(StreamStage<ChangeRecord> input) {\n+        return input\n+                .groupingKey(ChangeRecord::key)\n+                .mapStateful(\n+                        TimeUnit.SECONDS.toMillis(10),\n+                        () -> new LongAccumulator(0),\n+                        (lastSequence, key, record) -> {\n+                            long sequence = ((ChangeRecordImpl) record).getSequenceValue();\n+                            if (lastSequence.get() < sequence) {\n+                                lastSequence.set(sequence);\n+                                return record;\n+                            }\n+                            return null;\n+                        },\n+                        (TriFunction<LongAccumulator, RecordPart, Long, ChangeRecord>) (sequence, recordPart, aLong) -> null);\n+    }\n+\n+}\n+```\n+\n+To make it evident that our pipeline serves the purpose of building an\n+up-to-date cache of \"orders of customer\" data, which can be\n+interrogated at any time let's add one more class. This code can be\n+executed at any time in your IDE and will print the current content of\n+the cache.\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.Jet;\n+import com.hazelcast.jet.JetInstance;\n+\n+public class CacheRead {\n+\n+    public static void main(String[] args) {\n+        JetInstance instance = Jet.newJetClient();\n+\n+        System.out.println(\"Currently there are following customers in the cache:\");\n+        instance.getMap(\"customers\").values().forEach(c -> System.out.println(\"\\t\" + c));\n+\n+        instance.shutdown();\n+    }\n+\n+}\n+```\n+\n+## 6. Package\n+\n+Now that we have all the pieces, we need to submit it to Jet for\n+execution. Since Jet runs on our machine as a standalone cluster in a\n+standalone process we need to give it all the code that we have written.\n+\n+For this reason we create a jar containing everything we need. All we\n+need to do is to run the build command:\n+\n+<!--DOCUSAURUS_CODE_TABS-->\n+\n+<!--Gradle-->\n+\n+```bash\n+gradle build\n+```\n+\n+This will produce a jar file called `cdc-tutorial-1.0-SNAPSHOT.jar`\n+in the `build/libs` folder of our project.\n+\n+<!--Maven-->\n+\n+```bash\n+mvn package\n+```\n+\n+This will produce a jar file called `cdc-tutorial-1.0-SNAPSHOT.jar`\n+in the `target` folder or our project.\n+\n+<!--END_DOCUSAURUS_CODE_TABS-->\n+\n+## 7. Start Hazelcast Jet\n+\n+1. Download Hazelcast Jet\n+\n+```bash\n+wget https://github.com/hazelcast/hazelcast-jet/releases/download/v{jet-version}/hazelcast-jet-{jet-version}.tar.gz\n+tar zxvf hazelcast-jet-{jet-version}.tar.gz && cd hazelcast-jet-{jet-version}\n+```\n+\n+2. Activate the CDC plugin for the database you're using:\n+\n+<!--DOCUSAURUS_CODE_TABS-->\n+\n+<!--MySQL-->\n+\n+```bash\n+mv opt/hazelcast-jet-cdc-debezium-{jet-version}.jar lib; \\\n+mv opt/hazelcast-jet-cdc-mysql-{jet-version}.jar lib\n+```\n+\n+<!--Postgres-->\n+\n+```bash\n+mv opt/hazelcast-jet-cdc-debezium-{jet-version}.jar lib; \\\n+mv opt/hazelcast-jet-cdc-postgres-{jet-version}.jar lib\n+```\n+\n+<!--END_DOCUSAURUS_CODE_TABS-->\n+\n+3. Enable user code deployment:\n+\n+Due to the type of sink we have used in our pipeline we need to make\n+some extra changes in order for the IMDG cluster (which Jet sits\n+on top of) be aware of the custom classes we have defined.\n+\n+Pls. append following config lines to the `config/hazelcast.yaml` file,", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMTY3Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449001676", "bodyText": "should be cdc", "author": "cangencer", "createdAt": "2020-07-02T13:28:46Z", "path": "site/docs/api/sources-sinks.md", "diffHunk": "@@ -950,7 +950,7 @@ p.readFrom(Sources.jdbc(\n \n The JDBC source only works in batching mode, meaning the query is only\n executed once, for streaming changes from the database you can follow the\n-[Change Data Capture tutorial](../tutorials/cdc.md).\n+[Change Data Capture tutorial](../tutorials/cdc-mysql.md).", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQwODUzNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449408537", "bodyText": "Yeah, these are from parallel changes which I didn't notice. Will fix them all.", "author": "jbartok", "createdAt": "2020-07-03T06:55:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMTY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMTk5Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449001996", "bodyText": "should be cdc", "author": "cangencer", "createdAt": "2020-07-02T13:29:14Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've\n+seen how to monitor single database tables and how maintain an\n+up-to-date image of them in memory, as a map.\n+\n+Here we will examine how to make our map hold enriched data, combined\n+(joined, if you will) from multiple tables. Let's say customers and all\n+the orders belonging to them, as one entity.\n+\n+## 1. Install Docker\n+\n+This tutorial uses [Docker](https://www.docker.com/) to simplify the\n+setup of a PostgreSQL database, which you can freely experiment on.\n+\n+1. Follow Docker's [Get Started](https://www.docker.com/get-started)\n+   instructions and install it on your system.\n+2. Test that it works:\n+   * Run `docker version` to check that you have the latest release\n+     installed.\n+   * Run `docker run hello-world` to verify that Docker is pulling\n+     images and running as expected.\n+\n+## 2. Start Database\n+\n+In this tutorial we will provide all code and configs for MySQL, but\n+adapting them to any of the databases covered by the previous tutorials\n+should be pretty straightforward.\n+\n+Exact instructions for starting the supported databases are as follows:\n+\n+* [MySQL](cdc-mysql.md#2-start-mysql-database)", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAwMjMyOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449002329", "bodyText": "shoudl be cdc", "author": "cangencer", "createdAt": "2020-07-02T13:29:43Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,718 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change data capture** refers to the process of **observing changes\n+made to a database** and extracting them in a form usable by other\n+systems, for the purposes of replication, analysis and many more.\n+\n+Change Data Capture is especially important to Jet, because it allows\n+for the **streaming of changes from databases**, which can be\n+efficiently processed by Jet.\n+\n+Implementation of CDC in Jet is based on\n+[Debezium](https://debezium.io/), which is an open source distributed\n+platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc-mysql.md) and [Postgres](cdc-postgres.md) databases we've", "originalCommit": "4db75ddf15cd00081ebb1171a127c68f50065041", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bca571372af627392d9d07fcadddab9b3905804a", "url": "https://github.com/hazelcast/hazelcast-jet/commit/bca571372af627392d9d07fcadddab9b3905804a", "message": "Address review concerns, rewrite parts", "committedDate": "2020-07-03T07:41:44Z", "type": "commit"}, {"oid": "269db395fb3b7a14adc78b1045b1ca16098af72d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/269db395fb3b7a14adc78b1045b1ca16098af72d", "message": "Address review concerns", "committedDate": "2020-07-03T08:53:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ5MzQyMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449493420", "bodyText": "customers -> cache (that's what in the job above)", "author": "frant-hartm", "createdAt": "2020-07-03T09:52:42Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,711 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change Data Capture** (CDC) refers to the process of **observing\n+changes made to a database** and extracting them in a form usable by\n+other systems, for the purposes of replication, analysis and many more.\n+Basically anything that requires keeping multiple heterogeneous\n+datastores in sync.\n+\n+CDC is especially important to Jet, because it makes possible the\n+streaming of changes from databases, in a form efficiently processable\n+by Jet. Jet's implementation is based on [Debezium](https://debezium.io/),\n+which is an open source distributed platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc.md) and [Postgres](cdc-postgres.md) databases, we've seen\n+how to monitor single database tables and how to maintain up-to-date\n+images of those tables in memory, in the form of maps.\n+\n+Here we will examine how to make our map hold enriched data, combined\n+(joined, if you will) from multiple tables. Let's, for example, make\n+each of our enriched data objects hold information about one customer\n+and all the orders belonging to them.\n+\n+## 1. Install Docker\n+\n+This tutorial uses [Docker](https://www.docker.com/) to simplify the\n+setup of databases, which you can freely experiment on.\n+\n+1. Follow Docker's [Get Started](https://www.docker.com/get-started)\n+   instructions and install it on your system.\n+2. Test that it works:\n+   * Run `docker version` to check that you have the latest release\n+     installed.\n+   * Run `docker run hello-world` to verify that Docker is pulling\n+     images and running as expected.\n+\n+## 2. Start Database\n+\n+Exact instructions for starting the supported databases are as follows:\n+\n+* [MySQL](cdc.md#2-start-mysql-database)\n+* [Postgres](cdc-postgres.md#2-start-postgresql-database).\n+\n+## 3. Start Command Line Client\n+\n+Exact instructions for starting the specific command line client of the\n+supported databases are as follows:\n+\n+* [MySQL](cdc.md#3-start-mysql-command-line-client)\n+* [Postgres](cdc-postgres.md#3-start-postgresql-command-line-client)\n+\n+## 4. Create a New Java Project\n+\n+The configuration needed differs based on which database will be used.\n+See exact instructions here:\n+\n+* [MySQL](cdc.md#5-create-a-new-java-project)\n+* [Postgres](cdc-postgres.md#5-create-a-new-java-project)\n+\n+## 5. Define Jet Job\n+\n+Let's write the Jet code for the processing we want to accomplish:\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.Jet;\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.mysql.MySqlCdcSources;\n+import com.hazelcast.jet.config.JobConfig;\n+import com.hazelcast.jet.pipeline.Pipeline;\n+import com.hazelcast.jet.pipeline.Sinks;\n+import com.hazelcast.jet.pipeline.StreamSource;\n+import com.hazelcast.jet.pipeline.StreamStage;\n+\n+public class JetJob {\n+\n+    private static final int MAX_CONCURRENT_OPERATIONS = 1;\n+\n+    public static void main(String[] args) {\n+        StreamSource<ChangeRecord> source = MySqlCdcSources.mysql(\"source\")\n+            .setDatabaseAddress(\"127.0.0.1\")\n+            .setDatabasePort(3306)\n+            .setDatabaseUser(\"debezium\")\n+            .setDatabasePassword(\"dbz\")\n+            .setClusterName(\"dbserver1\")\n+            .setDatabaseWhitelist(\"inventory\")\n+            .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+            .build();\n+\n+        Pipeline pipeline = Pipeline.create();\n+        StreamStage<ChangeRecord> allRecords = pipeline.readFrom(source)\n+                .withNativeTimestamps(0);\n+\n+        allRecords.filter(r -> r.table().equals(\"customers\"))\n+                .apply(Ordering::fix)\n+                .peek()\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, \"cache\",\n+                        record -> (Integer) record.key().toMap().get(\"id\"),\n+                        CustomerEntryProcessor::new\n+                ));\n+\n+        allRecords.filter(r -> r.table().equals(\"orders\"))\n+                .apply(Ordering::fix)\n+                .peek()\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, \"cache\",\n+                        record -> (Integer) record.value().toMap().get(\"purchaser\"),\n+                        OrderEntryProcessor::new\n+                ));\n+\n+        JobConfig cfg = new JobConfig().setName(\"monitor\");\n+        Jet.bootstrappedInstance().newJob(pipeline, cfg);\n+    }\n+\n+}\n+```\n+\n+If using Postgres, only the source would need to change, like this:\n+\n+```java\n+StreamSource<ChangeRecord> source = PostgresCdcSources.postgres(\"source\")\n+    .setDatabaseAddress(\"127.0.0.1\")\n+    .setDatabasePort(5432)\n+    .setDatabaseUser(\"postgres\")\n+    .setDatabasePassword(\"postgres\")\n+    .setDatabaseName(\"postgres\")\n+    .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+    .build();\n+```\n+\n+As we can see from the pipeline code, our `Sink` is `EntryProcessor`\n+based. The two `EntryProcessors` we use are:\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.map.EntryProcessor;\n+\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class CustomerEntryProcessor implements EntryProcessor<Integer, OrdersOfCustomer, Object> {\n+\n+    private final Customer customer;\n+\n+    public CustomerEntryProcessor(ChangeRecord record) {\n+        try {\n+            this.customer = Operation.DELETE.equals(record.operation()) ? null :\n+                    record.value().toObject(Customer.class);\n+        } catch (ParsingException e) {\n+            throw rethrow(e);\n+        }\n+    }\n+\n+    @Override\n+    public Object process(Map.Entry<Integer, OrdersOfCustomer> entry) {\n+        OrdersOfCustomer value = entry.getValue();\n+        if (customer == null) {\n+            if (value != null) {\n+                value.setCustomer(null);\n+            }\n+        } else {\n+            if (value == null) {\n+                value = new OrdersOfCustomer();\n+            }\n+            value.setCustomer(customer);\n+        }\n+        entry.setValue(value);\n+        return null;\n+    }\n+}\n+```\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.map.EntryProcessor;\n+\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class OrderEntryProcessor implements EntryProcessor<Integer, OrdersOfCustomer, Object> {\n+\n+    private final Operation operation;\n+    private final Order order;\n+\n+    public OrderEntryProcessor(ChangeRecord record) {\n+        try {\n+            this.order = record.value().toObject(Order.class);\n+            this.operation = record.operation();\n+        } catch (ParsingException e) {\n+            throw rethrow(e);\n+        }\n+    }\n+\n+    @Override\n+    public Object process(Map.Entry<Integer, OrdersOfCustomer> entry) {\n+        OrdersOfCustomer value = entry.getValue();\n+        if (Operation.DELETE.equals(operation)) {\n+            if (value != null) {\n+                value.deleteOrder(order);\n+            }\n+        } else {\n+            if (value == null) {\n+                value = new OrdersOfCustomer();\n+            }\n+            value.addOrUpdateOrder(order);\n+        }\n+        entry.setValue(value);\n+        return null;\n+    }\n+}\n+```\n+\n+In them we use the `Customer` and the `Order` classes to achieve\n+convenient data parsing with the help of data to object\n+mapping.\n+\n+```java\n+package org.example;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import java.io.Serializable;\n+import java.util.Objects;\n+\n+public class Customer implements Serializable {\n+\n+    @JsonProperty(\"id\")\n+    public int id;\n+\n+    @JsonProperty(\"first_name\")\n+    public String firstName;\n+\n+    @JsonProperty(\"last_name\")\n+    public String lastName;\n+\n+    @JsonProperty(\"email\")\n+    public String email;\n+\n+    Customer() {\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(email, firstName, id, lastName);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        Customer other = (Customer) obj;\n+        return id == other.id\n+                && Objects.equals(firstName, other.firstName)\n+                && Objects.equals(lastName, other.lastName)\n+                && Objects.equals(email, other.email);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Customer {id=\" + id + \", firstName=\" + firstName + \", lastName=\" + lastName + \", email=\" + email + '}';\n+    }\n+}\n+```\n+\n+```java\n+package org.example;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import java.io.Serializable;\n+import java.util.Date;\n+import java.util.Objects;\n+import java.util.concurrent.TimeUnit;\n+\n+public class Order implements Serializable {\n+\n+    @JsonProperty(\"order_number\")\n+    public int orderNumber;\n+\n+    @JsonProperty(\"order_date\")\n+    public Date orderDate;\n+\n+    @JsonProperty(\"purchaser\")\n+    public int purchaser;\n+\n+    @JsonProperty(\"quantity\")\n+    public int quantity;\n+\n+    @JsonProperty(\"product_id\")\n+    public int productId;\n+\n+    Order() {\n+    }\n+\n+    public void setOrderDate(Date orderDate) { //used by object mapping\n+        long days = orderDate.getTime();\n+        this.orderDate = new Date(TimeUnit.DAYS.toMillis(days));\n+    }\n+\n+    public int getOrderNumber() {\n+        return orderNumber;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(orderNumber, orderDate, purchaser, quantity, productId);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        Order other = (Order) obj;\n+        return orderNumber == other.orderNumber\n+                && Objects.equals(orderDate, other.orderDate)\n+                && Objects.equals(purchaser, other.purchaser)\n+                && Objects.equals(quantity, other.quantity)\n+                && Objects.equals(productId, other.productId);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"Order {orderNumber=\" + orderNumber + \", orderDate=\" + orderDate + \", purchaser=\" + purchaser +\n+                \", quantity=\" + quantity + \", productId=\" + productId + '}';\n+    }\n+\n+}\n+```\n+\n+Watch out, in the Postgres database the order number column has a\n+different name, `id`, so the first field in `Order` needs to be changed\n+to:\n+\n+```java\n+@JsonProperty(\"id\")\n+public int orderNumber;\n+```\n+\n+Besides these two data classes we also need to define our enriched\n+structure, called `OrdersOfCustomers`, which will be stored in the\n+target `IMap`:\n+\n+```java\n+package org.example;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+public class OrdersOfCustomer implements Serializable {\n+\n+    private final Map<Integer, Order> orders;\n+    private Customer customer;\n+\n+    public OrdersOfCustomer() {\n+        this.customer = null;\n+        this.orders = new HashMap<>();\n+    }\n+\n+    public void setCustomer(Customer customer) {\n+        this.customer = customer;\n+    }\n+\n+    public void deleteOrder(Order order) {\n+        orders.remove(order.getOrderNumber());\n+    }\n+\n+    public void addOrUpdateOrder(Order order) {\n+        orders.put(order.getOrderNumber(), order);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(customer, orders);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        if (this == obj) {\n+            return true;\n+        }\n+        if (obj == null || getClass() != obj.getClass()) {\n+            return false;\n+        }\n+        OrdersOfCustomer other = (OrdersOfCustomer) obj;\n+        return Objects.equals(customer, other.customer)\n+                && Objects.equals(orders, other.orders);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"Customer: %s, Orders: %s\", customer, orders);\n+    }\n+}\n+```\n+\n+There is also another element in the pipeline, an extra processing stage\n+which handles and fixes event reordering that might happen due to\n+parallel processing. It's based on non-public classes because future\n+versions of Jet (4.3 most likely) will contain generic solutions for\n+the reordering problem and then this code will no longer be necessary:\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.accumulator.LongAccumulator;\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.RecordPart;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.function.TriFunction;\n+import com.hazelcast.jet.pipeline.StreamStage;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+public class Ordering {\n+\n+    static StreamStage<ChangeRecord> fix(StreamStage<ChangeRecord> input) {\n+        return input\n+                .groupingKey(ChangeRecord::key)\n+                .mapStateful(\n+                        TimeUnit.SECONDS.toMillis(10),\n+                        () -> new LongAccumulator(0),\n+                        (lastSequence, key, record) -> {\n+                            long sequence = ((ChangeRecordImpl) record).getSequenceValue();\n+                            if (lastSequence.get() < sequence) {\n+                                lastSequence.set(sequence);\n+                                return record;\n+                            }\n+                            return null;\n+                        },\n+                        (TriFunction<LongAccumulator, RecordPart, Long, ChangeRecord>) (sequence, recordPart, aLong) -> null);\n+    }\n+\n+}\n+```\n+\n+To make it evident that our pipeline serves the purpose of building an\n+up-to-date cache of \"orders of customers\", which can be interrogated at\n+any time, let's add one more class. This code can be executed at will in\n+your IDE and prints the current content of the cache.\n+\n+```java\n+package org.example;\n+\n+import com.hazelcast.jet.Jet;\n+import com.hazelcast.jet.JetInstance;\n+\n+public class CacheRead {\n+\n+    public static void main(String[] args) {\n+        JetInstance instance = Jet.newJetClient();\n+\n+        System.out.println(\"Currently there are following customers in the cache:\");\n+        instance.getMap(\"customers\").values().forEach(c -> System.out.println(\"\\t\" + c));", "originalCommit": "269db395fb3b7a14adc78b1045b1ca16098af72d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTQ5ODA5OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2387#discussion_r449498099", "bodyText": "The linked tutorial says to create cdc-tutorial project.\nWith maven it is fine, there is the artifactId specified.\nWith gradle it is not defined in the build.gradle file but in settings.gradle and the value defaults to the directory name.\nThis should be highlighted, because you refer to the jar later. (I created folder called cdc-join and had to change the user code deployment and submit command).", "author": "frant-hartm", "createdAt": "2020-07-03T10:02:06Z", "path": "site/docs/tutorials/cdc-join.md", "diffHunk": "@@ -0,0 +1,711 @@\n+---\n+title: Join Change Data Capture Records\n+sidebar_label: Join\n+description: How to maintain a joined image of Change Data Capture data from multiple tables.\n+---\n+\n+**Change Data Capture** (CDC) refers to the process of **observing\n+changes made to a database** and extracting them in a form usable by\n+other systems, for the purposes of replication, analysis and many more.\n+Basically anything that requires keeping multiple heterogeneous\n+datastores in sync.\n+\n+CDC is especially important to Jet, because it makes possible the\n+streaming of changes from databases, in a form efficiently processable\n+by Jet. Jet's implementation is based on [Debezium](https://debezium.io/),\n+which is an open source distributed platform for change data capture.\n+\n+In our previous tutorials on how to extract change event data from\n+[MySQL](cdc.md) and [Postgres](cdc-postgres.md) databases, we've seen\n+how to monitor single database tables and how to maintain up-to-date\n+images of those tables in memory, in the form of maps.\n+\n+Here we will examine how to make our map hold enriched data, combined\n+(joined, if you will) from multiple tables. Let's, for example, make\n+each of our enriched data objects hold information about one customer\n+and all the orders belonging to them.\n+\n+## 1. Install Docker\n+\n+This tutorial uses [Docker](https://www.docker.com/) to simplify the\n+setup of databases, which you can freely experiment on.\n+\n+1. Follow Docker's [Get Started](https://www.docker.com/get-started)\n+   instructions and install it on your system.\n+2. Test that it works:\n+   * Run `docker version` to check that you have the latest release\n+     installed.\n+   * Run `docker run hello-world` to verify that Docker is pulling\n+     images and running as expected.\n+\n+## 2. Start Database\n+\n+Exact instructions for starting the supported databases are as follows:\n+\n+* [MySQL](cdc.md#2-start-mysql-database)\n+* [Postgres](cdc-postgres.md#2-start-postgresql-database).\n+\n+## 3. Start Command Line Client\n+\n+Exact instructions for starting the specific command line client of the\n+supported databases are as follows:\n+\n+* [MySQL](cdc.md#3-start-mysql-command-line-client)\n+* [Postgres](cdc-postgres.md#3-start-postgresql-command-line-client)\n+\n+## 4. Create a New Java Project", "originalCommit": "269db395fb3b7a14adc78b1045b1ca16098af72d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7a5f1c5046bc35c2f790fa88570b95cf15a992e6", "url": "https://github.com/hazelcast/hazelcast-jet/commit/7a5f1c5046bc35c2f790fa88570b95cf15a992e6", "message": "Address review concerns", "committedDate": "2020-07-03T11:00:42Z", "type": "commit"}]}