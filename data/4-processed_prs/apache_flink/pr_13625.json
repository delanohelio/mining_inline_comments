{"pr_number": 13625, "pr_title": "[FLINK-19623][table-planner-blink] Introduce ExecEdge to describe information on input edges for ExecNode", "pr_createdAt": "2020-10-14T04:19:16Z", "pr_url": "https://github.com/apache/flink/pull/13625", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUwOTE0OQ==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505509149", "bodyText": "It's better we could use Builder to create an ExecEdge, because all single nodes' priority is always 0, many nodes provide unknown RequiredShuffle, and maybe there are more properties will be added in the future, e.g. source/target node", "author": "godfreyhe", "createdAt": "2020-10-15T12:42:31Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecEdge.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.nodes.exec;\n+\n+/**\n+ * The representation of an edge connecting two {@link ExecNode}.\n+ */\n+public class ExecEdge {\n+\n+\tprivate final RequiredShuffle requiredShuffle;\n+\tprivate final EdgeBehavior edgeBehavior;\n+\t// the priority of this edge read by the target node\n+\t// the smaller the integer, the higher the priority\n+\t// same integer indicates the same priority\n+\tprivate final int priority;\n+\n+\tpublic ExecEdge(RequiredShuffle requiredShuffle, EdgeBehavior edgeBehavior, int priority) {", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUxMDIwNg==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505510206", "bodyText": "require keys is not empty here.", "author": "godfreyhe", "createdAt": "2020-10-15T12:44:05Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecEdge.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.nodes.exec;\n+\n+/**\n+ * The representation of an edge connecting two {@link ExecNode}.\n+ */\n+public class ExecEdge {\n+\n+\tprivate final RequiredShuffle requiredShuffle;\n+\tprivate final EdgeBehavior edgeBehavior;\n+\t// the priority of this edge read by the target node\n+\t// the smaller the integer, the higher the priority\n+\t// same integer indicates the same priority\n+\tprivate final int priority;\n+\n+\tpublic ExecEdge(RequiredShuffle requiredShuffle, EdgeBehavior edgeBehavior, int priority) {\n+\t\tthis.requiredShuffle = requiredShuffle;\n+\t\tthis.edgeBehavior = edgeBehavior;\n+\t\tthis.priority = priority;\n+\t}\n+\n+\tpublic RequiredShuffle getRequiredShuffle() {\n+\t\treturn requiredShuffle;\n+\t}\n+\n+\tpublic EdgeBehavior getEdgeBehavior() {\n+\t\treturn edgeBehavior;\n+\t}\n+\n+\tpublic int getPriority() {\n+\t\treturn priority;\n+\t}\n+\n+\t/**\n+\t * The required shuffle for records when passing this edge.\n+\t */\n+\tpublic static class RequiredShuffle {\n+\n+\t\tprivate final ShuffleType type;\n+\t\tprivate final int[] keys;\n+\n+\t\tprivate RequiredShuffle(ShuffleType type, int[] keys) {\n+\t\t\tthis.type = type;\n+\t\t\tthis.keys = keys;\n+\t\t}\n+\n+\t\tpublic ShuffleType getType() {\n+\t\t\treturn type;\n+\t\t}\n+\n+\t\tpublic int[] getKeys() {\n+\t\t\treturn keys;\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle any() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.ANY, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle hash(int[] keys) {\n+\t\t\tif (keys.length == 0) {", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUxMDQ4Mw==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505510483", "bodyText": "add some comments for the public apis", "author": "godfreyhe", "createdAt": "2020-10-15T12:44:34Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecEdge.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.nodes.exec;\n+\n+/**\n+ * The representation of an edge connecting two {@link ExecNode}.\n+ */\n+public class ExecEdge {\n+\n+\tprivate final RequiredShuffle requiredShuffle;\n+\tprivate final EdgeBehavior edgeBehavior;\n+\t// the priority of this edge read by the target node\n+\t// the smaller the integer, the higher the priority\n+\t// same integer indicates the same priority\n+\tprivate final int priority;\n+\n+\tpublic ExecEdge(RequiredShuffle requiredShuffle, EdgeBehavior edgeBehavior, int priority) {\n+\t\tthis.requiredShuffle = requiredShuffle;\n+\t\tthis.edgeBehavior = edgeBehavior;\n+\t\tthis.priority = priority;\n+\t}\n+\n+\tpublic RequiredShuffle getRequiredShuffle() {\n+\t\treturn requiredShuffle;\n+\t}\n+\n+\tpublic EdgeBehavior getEdgeBehavior() {\n+\t\treturn edgeBehavior;\n+\t}\n+\n+\tpublic int getPriority() {\n+\t\treturn priority;\n+\t}\n+\n+\t/**\n+\t * The required shuffle for records when passing this edge.\n+\t */\n+\tpublic static class RequiredShuffle {\n+\n+\t\tprivate final ShuffleType type;\n+\t\tprivate final int[] keys;\n+\n+\t\tprivate RequiredShuffle(ShuffleType type, int[] keys) {\n+\t\t\tthis.type = type;\n+\t\t\tthis.keys = keys;\n+\t\t}\n+\n+\t\tpublic ShuffleType getType() {\n+\t\t\treturn type;\n+\t\t}\n+\n+\t\tpublic int[] getKeys() {\n+\t\t\treturn keys;\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle any() {", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUxMTIyNg==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505511226", "bodyText": "provide another constructor private RequiredShuffle(ShuffleType type)", "author": "godfreyhe", "createdAt": "2020-10-15T12:45:37Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecEdge.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.nodes.exec;\n+\n+/**\n+ * The representation of an edge connecting two {@link ExecNode}.\n+ */\n+public class ExecEdge {\n+\n+\tprivate final RequiredShuffle requiredShuffle;\n+\tprivate final EdgeBehavior edgeBehavior;\n+\t// the priority of this edge read by the target node\n+\t// the smaller the integer, the higher the priority\n+\t// same integer indicates the same priority\n+\tprivate final int priority;\n+\n+\tpublic ExecEdge(RequiredShuffle requiredShuffle, EdgeBehavior edgeBehavior, int priority) {\n+\t\tthis.requiredShuffle = requiredShuffle;\n+\t\tthis.edgeBehavior = edgeBehavior;\n+\t\tthis.priority = priority;\n+\t}\n+\n+\tpublic RequiredShuffle getRequiredShuffle() {\n+\t\treturn requiredShuffle;\n+\t}\n+\n+\tpublic EdgeBehavior getEdgeBehavior() {\n+\t\treturn edgeBehavior;\n+\t}\n+\n+\tpublic int getPriority() {\n+\t\treturn priority;\n+\t}\n+\n+\t/**\n+\t * The required shuffle for records when passing this edge.\n+\t */\n+\tpublic static class RequiredShuffle {\n+\n+\t\tprivate final ShuffleType type;\n+\t\tprivate final int[] keys;\n+\n+\t\tprivate RequiredShuffle(ShuffleType type, int[] keys) {\n+\t\t\tthis.type = type;\n+\t\t\tthis.keys = keys;\n+\t\t}\n+\n+\t\tpublic ShuffleType getType() {\n+\t\t\treturn type;\n+\t\t}\n+\n+\t\tpublic int[] getKeys() {\n+\t\t\treturn keys;\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle any() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.ANY, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle hash(int[] keys) {\n+\t\t\tif (keys.length == 0) {\n+\t\t\t\treturn new RequiredShuffle(ShuffleType.ANY, keys);\n+\t\t\t} else {\n+\t\t\t\treturn new RequiredShuffle(ShuffleType.HASH, keys);\n+\t\t\t}\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle broadcast() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.BROADCAST, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle singleton() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.SINGLETON, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle unknown() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.UNKNOWN, new int[0]);", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUxMzEzMw==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505513133", "bodyText": "use ExecNode instead of partition to describe the target", "author": "godfreyhe", "createdAt": "2020-10-15T12:48:32Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecEdge.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.nodes.exec;\n+\n+/**\n+ * The representation of an edge connecting two {@link ExecNode}.\n+ */\n+public class ExecEdge {\n+\n+\tprivate final RequiredShuffle requiredShuffle;\n+\tprivate final EdgeBehavior edgeBehavior;\n+\t// the priority of this edge read by the target node\n+\t// the smaller the integer, the higher the priority\n+\t// same integer indicates the same priority\n+\tprivate final int priority;\n+\n+\tpublic ExecEdge(RequiredShuffle requiredShuffle, EdgeBehavior edgeBehavior, int priority) {\n+\t\tthis.requiredShuffle = requiredShuffle;\n+\t\tthis.edgeBehavior = edgeBehavior;\n+\t\tthis.priority = priority;\n+\t}\n+\n+\tpublic RequiredShuffle getRequiredShuffle() {\n+\t\treturn requiredShuffle;\n+\t}\n+\n+\tpublic EdgeBehavior getEdgeBehavior() {\n+\t\treturn edgeBehavior;\n+\t}\n+\n+\tpublic int getPriority() {\n+\t\treturn priority;\n+\t}\n+\n+\t/**\n+\t * The required shuffle for records when passing this edge.\n+\t */\n+\tpublic static class RequiredShuffle {\n+\n+\t\tprivate final ShuffleType type;\n+\t\tprivate final int[] keys;\n+\n+\t\tprivate RequiredShuffle(ShuffleType type, int[] keys) {\n+\t\t\tthis.type = type;\n+\t\t\tthis.keys = keys;\n+\t\t}\n+\n+\t\tpublic ShuffleType getType() {\n+\t\t\treturn type;\n+\t\t}\n+\n+\t\tpublic int[] getKeys() {\n+\t\t\treturn keys;\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle any() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.ANY, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle hash(int[] keys) {\n+\t\t\tif (keys.length == 0) {\n+\t\t\t\treturn new RequiredShuffle(ShuffleType.ANY, keys);\n+\t\t\t} else {\n+\t\t\t\treturn new RequiredShuffle(ShuffleType.HASH, keys);\n+\t\t\t}\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle broadcast() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.BROADCAST, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle singleton() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.SINGLETON, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle unknown() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.UNKNOWN, new int[0]);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Enumeration which describes the shuffle type for records when passing this edge.\n+\t */\n+\tpublic enum ShuffleType {\n+\n+\t\t/**\n+\t\t * Any type of shuffle is OK when passing through this edge.\n+\t\t */\n+\t\tANY,\n+\n+\t\t/**\n+\t\t * Records are shuffle by hash when passing through this edge.\n+\t\t */\n+\t\tHASH,\n+\n+\t\t/**\n+\t\t * Each sub-partition contains full records.", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUxNjM3MQ==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505516371", "bodyText": "add TODO and explain why the RequiredShuffle is unknown.", "author": "godfreyhe", "createdAt": "2020-10-15T12:53:22Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/exec/StreamExecNode.scala", "diffHunk": "@@ -21,7 +21,21 @@ package org.apache.flink.table.planner.plan.nodes.exec\n import org.apache.flink.table.planner.delegation.StreamPlanner\n import org.apache.flink.table.planner.utils.Logging\n \n+import java.util\n+\n /**\n   * Base class for stream ExecNode.\n   */\n-trait StreamExecNode[T] extends ExecNode[StreamPlanner, T] with Logging\n+trait StreamExecNode[T] extends ExecNode[StreamPlanner, T] with Logging {\n+\n+  def getInputEdges: util.List[ExecEdge] = {\n+    val edges = new util.ArrayList[ExecEdge]()\n+    for (_ <- 0 until getInputNodes.size()) {\n+      edges.add(new ExecEdge(\n+        ExecEdge.RequiredShuffle.unknown(),", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUyMzA3OA==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505523078", "bodyText": "END_INPUT ?", "author": "godfreyhe", "createdAt": "2020-10-15T13:03:03Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/batch/BatchExecExchange.scala", "diffHunk": "@@ -117,6 +116,30 @@ class BatchExecExchange(\n   override def getInputNodes: util.List[ExecNode[BatchPlanner, _]] =\n     getInputs.map(_.asInstanceOf[ExecNode[BatchPlanner, _]])\n \n+  override def getInputEdges: util.List[ExecEdge] = {\n+    val tableConfig = FlinkRelOptUtil.getTableConfigFromContext(this)\n+    val shuffleMode = getShuffleMode(tableConfig.getConfiguration)\n+    if (shuffleMode eq ShuffleMode.BATCH) {\n+      List(new ExecEdge(\n+        ExecEdge.RequiredShuffle.unknown(),\n+        ExecEdge.EdgeBehavior.BLOCKING,\n+        0))\n+    } else {\n+      distribution.getType match {\n+        case RelDistribution.Type.RANGE_DISTRIBUTED =>\n+          List(new ExecEdge(\n+            ExecEdge.RequiredShuffle.unknown(),\n+            ExecEdge.EdgeBehavior.BLOCKING,", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUzOTY2OA==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505539668", "bodyText": "should consider leftSorted and rightSorted", "author": "godfreyhe", "createdAt": "2020-10-15T13:25:50Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/batch/BatchExecSortMergeJoin.scala", "diffHunk": "@@ -192,6 +193,11 @@ class BatchExecSortMergeJoin(\n   override def getInputNodes: util.List[ExecNode[BatchPlanner, _]] =\n     getInputs.map(_.asInstanceOf[ExecNode[BatchPlanner, _]])\n \n+  override def getInputEdges: util.List[ExecEdge] =\n+    List(\n+      new ExecEdge(ExecEdge.RequiredShuffle.unknown(), ExecEdge.EdgeBehavior.END_INPUT, 0),", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjA1MzAzMQ==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506053031", "bodyText": "No need. Records are only emitted in the endInput method for sort merge join. See SortMergeJoinOperator.", "author": "tsreaper", "createdAt": "2020-10-16T05:02:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTUzOTY2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTU0MDE3OQ==", "url": "https://github.com/apache/flink/pull/13625#discussion_r505540179", "bodyText": "EdgeDamBehavior ?", "author": "godfreyhe", "createdAt": "2020-10-15T13:26:33Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/ExecEdge.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.nodes.exec;\n+\n+/**\n+ * The representation of an edge connecting two {@link ExecNode}.\n+ */\n+public class ExecEdge {\n+\n+\tprivate final RequiredShuffle requiredShuffle;\n+\tprivate final EdgeBehavior edgeBehavior;\n+\t// the priority of this edge read by the target node\n+\t// the smaller the integer, the higher the priority\n+\t// same integer indicates the same priority\n+\tprivate final int priority;\n+\n+\tpublic ExecEdge(RequiredShuffle requiredShuffle, EdgeBehavior edgeBehavior, int priority) {\n+\t\tthis.requiredShuffle = requiredShuffle;\n+\t\tthis.edgeBehavior = edgeBehavior;\n+\t\tthis.priority = priority;\n+\t}\n+\n+\tpublic RequiredShuffle getRequiredShuffle() {\n+\t\treturn requiredShuffle;\n+\t}\n+\n+\tpublic EdgeBehavior getEdgeBehavior() {\n+\t\treturn edgeBehavior;\n+\t}\n+\n+\tpublic int getPriority() {\n+\t\treturn priority;\n+\t}\n+\n+\t/**\n+\t * The required shuffle for records when passing this edge.\n+\t */\n+\tpublic static class RequiredShuffle {\n+\n+\t\tprivate final ShuffleType type;\n+\t\tprivate final int[] keys;\n+\n+\t\tprivate RequiredShuffle(ShuffleType type, int[] keys) {\n+\t\t\tthis.type = type;\n+\t\t\tthis.keys = keys;\n+\t\t}\n+\n+\t\tpublic ShuffleType getType() {\n+\t\t\treturn type;\n+\t\t}\n+\n+\t\tpublic int[] getKeys() {\n+\t\t\treturn keys;\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle any() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.ANY, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle hash(int[] keys) {\n+\t\t\tif (keys.length == 0) {\n+\t\t\t\treturn new RequiredShuffle(ShuffleType.ANY, keys);\n+\t\t\t} else {\n+\t\t\t\treturn new RequiredShuffle(ShuffleType.HASH, keys);\n+\t\t\t}\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle broadcast() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.BROADCAST, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle singleton() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.SINGLETON, new int[0]);\n+\t\t}\n+\n+\t\tpublic static RequiredShuffle unknown() {\n+\t\t\treturn new RequiredShuffle(ShuffleType.UNKNOWN, new int[0]);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Enumeration which describes the shuffle type for records when passing this edge.\n+\t */\n+\tpublic enum ShuffleType {\n+\n+\t\t/**\n+\t\t * Any type of shuffle is OK when passing through this edge.\n+\t\t */\n+\t\tANY,\n+\n+\t\t/**\n+\t\t * Records are shuffle by hash when passing through this edge.\n+\t\t */\n+\t\tHASH,\n+\n+\t\t/**\n+\t\t * Each sub-partition contains full records.\n+\t\t */\n+\t\tBROADCAST,\n+\n+\t\t/**\n+\t\t * The parallelism of the target node must be 1.\n+\t\t */\n+\t\tSINGLETON,\n+\n+\t\t/**\n+\t\t * Unknown shuffle type, will be filled out in the future.\n+\t\t */\n+\t\tUNKNOWN\n+\t}\n+\n+\t/**\n+\t * Enumeration which describes how an output record from the source node\n+\t * may trigger the output of the target node.\n+\t */\n+\tpublic enum EdgeBehavior {", "originalCommit": "1d3dfd2b49f980db8ac9189ad4bf0d310e19468c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjA1NDYxOQ==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506054619", "bodyText": "DamBehavior seems to be a better name. This is an inner class so we do not need to worry that this class might be confused with the DamBehavior in runtime.", "author": "tsreaper", "createdAt": "2020-10-16T05:08:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTU0MDE3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU0MDIyNQ==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506540225", "bodyText": "create a default ExecEdge instance ?", "author": "godfreyhe", "createdAt": "2020-10-16T15:22:55Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/batch/BatchExecCalcBase.scala", "diffHunk": "@@ -112,11 +111,11 @@ abstract class BatchExecCalcBase(\n \n   //~ ExecNode methods -----------------------------------------------------------\n \n-  override def getDamBehavior = DamBehavior.PIPELINED\n-\n   override def getInputNodes: util.List[ExecNode[BatchPlanner, _]] =\n     List(getInput.asInstanceOf[ExecNode[BatchPlanner, _]])\n \n+  override def getInputEdges: util.List[ExecEdge] = List(ExecEdge.builder().build())", "originalCommit": "4c31824917199ca34801d2bde871c5d1f95d0cc2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU0MjIzMA==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506542230", "bodyText": "we should avoid match specific class here", "author": "godfreyhe", "createdAt": "2020-10-16T15:25:07Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/reuse/DeadlockBreakupProcessor.scala", "diffHunk": "@@ -320,8 +319,9 @@ class DeadlockBreakupProcessor extends DAGProcessor {\n         // should exclude the reused node (at last position in path)\n         while (!hasFullDamNode && idx < inputPath.length - 1) {\n           val node = inputPath(idx)\n-          val nodeDamBehavior = node.asInstanceOf[BatchExecNode[_]].getDamBehavior\n-          hasFullDamNode = if (nodeDamBehavior == DamBehavior.FULL_DAM) {\n+          val atLeastEndInput = node.getInputEdges.forall(\n+            e => e.getDamBehavior.stricterOrEqual(ExecEdge.DamBehavior.END_INPUT))\n+          hasFullDamNode = if (atLeastEndInput) {\n             true\n           } else {\n             node match {", "originalCommit": "4c31824917199ca34801d2bde871c5d1f95d0cc2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjkwMzMyMA==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506903320", "bodyText": "nit: remove unused imports", "author": "godfreyhe", "createdAt": "2020-10-17T09:18:57Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/exec/BatchExecNode.scala", "diffHunk": "@@ -25,11 +25,4 @@ import org.apache.flink.table.planner.utils.Logging\n /**\n   * Base class for batch ExecNode.\n   */\n-trait BatchExecNode[T] extends ExecNode[BatchPlanner, T] with Logging {\n-\n-  /**\n-    * Returns [[DamBehavior]] of this node.\n-    */\n-  def getDamBehavior: DamBehavior\n-\n-}\n+trait BatchExecNode[T] extends ExecNode[BatchPlanner, T] with Logging", "originalCommit": "f26a40dc87e7f977e84f24c5b509b60f2b083d5c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjkwNTcyMg==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506905722", "bodyText": "may have more than two inputs", "author": "godfreyhe", "createdAt": "2020-10-17T09:24:42Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/physical/batch/BatchExecUnion.scala", "diffHunk": "@@ -98,11 +98,11 @@ class BatchExecUnion(\n \n   //~ ExecNode methods -----------------------------------------------------------\n \n-  override def getDamBehavior: DamBehavior = DamBehavior.PIPELINED\n-\n   override def getInputNodes: util.List[ExecNode[BatchPlanner, _]] =\n     getInputs.map(_.asInstanceOf[ExecNode[BatchPlanner, _]])\n \n+  override def getInputEdges: util.List[ExecEdge] = List(ExecEdge.DEFAULT, ExecEdge.DEFAULT)", "originalCommit": "f26a40dc87e7f977e84f24c5b509b60f2b083d5c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjkwNjMxNQ==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506906315", "bodyText": "no build/probe concept here", "author": "godfreyhe", "createdAt": "2020-10-17T09:25:52Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/reuse/DeadlockBreakupProcessor.scala", "diffHunk": "@@ -146,22 +146,33 @@ class DeadlockBreakupProcessor extends DAGProcessor {\n \n   class DeadlockBreakupVisitor(finder: ReuseNodeFinder) extends ExecNodeVisitorImpl {\n \n-    private def rewriteJoin(\n-        join: BatchExecJoinBase,\n-        leftIsBuild: Boolean,\n-        distribution: FlinkRelDistribution): Unit = {\n-      val (buildSideIndex, probeSideIndex) = if (leftIsBuild) (0, 1) else (1, 0)\n-      val buildNode = join.getInputNodes.get(buildSideIndex)\n-      val probeNode = join.getInputNodes.get(probeSideIndex)\n+    private def rewriteTwoInputNode(\n+        node: ExecNode[_, _],\n+        leftPriority: Int,\n+        requiredShuffle: ExecEdge.RequiredShuffle): Unit = {\n+      val (buildSideIndex, probeSideIndex) = if (leftPriority == 0) (0, 1) else (1, 0)\n+      val buildNode = node.getInputNodes.get(buildSideIndex)", "originalCommit": "f26a40dc87e7f977e84f24c5b509b60f2b083d5c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjkwNjg4Mw==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506906883", "bodyText": "the highest priority is always 0? do we have this guarantee?", "author": "godfreyhe", "createdAt": "2020-10-17T09:27:16Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/reuse/DeadlockBreakupProcessor.scala", "diffHunk": "@@ -146,22 +146,33 @@ class DeadlockBreakupProcessor extends DAGProcessor {\n \n   class DeadlockBreakupVisitor(finder: ReuseNodeFinder) extends ExecNodeVisitorImpl {\n \n-    private def rewriteJoin(\n-        join: BatchExecJoinBase,\n-        leftIsBuild: Boolean,\n-        distribution: FlinkRelDistribution): Unit = {\n-      val (buildSideIndex, probeSideIndex) = if (leftIsBuild) (0, 1) else (1, 0)\n-      val buildNode = join.getInputNodes.get(buildSideIndex)\n-      val probeNode = join.getInputNodes.get(probeSideIndex)\n+    private def rewriteTwoInputNode(\n+        node: ExecNode[_, _],\n+        leftPriority: Int,\n+        requiredShuffle: ExecEdge.RequiredShuffle): Unit = {\n+      val (buildSideIndex, probeSideIndex) = if (leftPriority == 0) (0, 1) else (1, 0)", "originalCommit": "f26a40dc87e7f977e84f24c5b509b60f2b083d5c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjkwNzc2NQ==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506907765", "bodyText": "ditto", "author": "godfreyhe", "createdAt": "2020-10-17T09:29:20Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/reuse/DeadlockBreakupProcessor.scala", "diffHunk": "@@ -175,29 +186,32 @@ class DeadlockBreakupProcessor extends DAGProcessor {\n               probeRel,\n               distribution)\n             e.setRequiredShuffleMode(ShuffleMode.BATCH)\n-            // replace join node's input\n-            join.replaceInputNode(probeSideIndex, e)\n+            // replace node's input\n+            node.asInstanceOf[BatchExecNode[_]].replaceInputNode(probeSideIndex, e)\n         }\n       }\n     }\n \n     override def visit(node: ExecNode[_, _]): Unit = {\n       super.visit(node)\n-      node match {\n-        case hashJoin: BatchExecHashJoin =>\n-          val joinInfo = hashJoin.getJoinInfo\n-          val columns = if (hashJoin.leftIsBuild) joinInfo.rightKeys else joinInfo.leftKeys\n-          val distribution = FlinkRelDistribution.hash(columns)\n-          rewriteJoin(hashJoin, hashJoin.leftIsBuild, distribution)\n-        case nestedLoopJoin: BatchExecNestedLoopJoin =>\n-          rewriteJoin(nestedLoopJoin, nestedLoopJoin.leftIsBuild, FlinkRelDistribution.ANY)\n-        case _ => // do nothing\n+      val inputEdges = node.getInputEdges\n+      if (inputEdges.size() == 2) {\n+        val leftPriority = inputEdges.get(0).getPriority\n+        val rightPriority = inputEdges.get(1).getPriority\n+        val requiredShuffle = if (leftPriority == 1) {", "originalCommit": "f26a40dc87e7f977e84f24c5b509b60f2b083d5c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUxMTY0OA==", "url": "https://github.com/apache/flink/pull/13625#discussion_r507511648", "bodyText": "not changed here", "author": "godfreyhe", "createdAt": "2020-10-19T06:53:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjkwNzc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjkwODE3Nw==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506908177", "bodyText": "ditto", "author": "godfreyhe", "createdAt": "2020-10-17T09:30:19Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/reuse/DeadlockBreakupProcessor.scala", "diffHunk": "@@ -320,20 +334,24 @@ class DeadlockBreakupProcessor extends DAGProcessor {\n         // should exclude the reused node (at last position in path)\n         while (!hasFullDamNode && idx < inputPath.length - 1) {\n           val node = inputPath(idx)\n-          val nodeDamBehavior = node.asInstanceOf[BatchExecNode[_]].getDamBehavior\n-          hasFullDamNode = if (nodeDamBehavior == DamBehavior.FULL_DAM) {\n+          val atLeastEndInput = node.getInputEdges.forall(\n+            e => e.getDamBehavior.stricterOrEqual(ExecEdge.DamBehavior.END_INPUT))\n+          hasFullDamNode = if (atLeastEndInput) {\n             true\n           } else {\n-            node match {\n-              case h: BatchExecHashJoin =>\n-                val buildSideIndex = if (h.leftIsBuild) 0 else 1\n-                val buildNode = h.getInputNodes.get(buildSideIndex)\n-                checkJoinBuildSide(buildNode, idx, inputPath)\n-              case n: BatchExecNestedLoopJoin =>\n-                val buildSideIndex = if (n.leftIsBuild) 0 else 1\n-                val buildNode = n.getInputNodes.get(buildSideIndex)\n-                checkJoinBuildSide(buildNode, idx, inputPath)\n-              case _ => false\n+            val inputEdges = node.getInputEdges\n+            if (inputEdges.size() == 2) {\n+              val leftPriority = inputEdges.get(0).getPriority\n+              val rightPriority = inputEdges.get(1).getPriority\n+              if (leftPriority != rightPriority) {\n+                val buildSideIndex = if (leftPriority == 0) 0 else 1", "originalCommit": "f26a40dc87e7f977e84f24c5b509b60f2b083d5c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjkwOTcwNg==", "url": "https://github.com/apache/flink/pull/13625#discussion_r506909706", "bodyText": "nit: can be simplified as getInputNodes.map(_ => ExecEdge.DEFAULT)", "author": "godfreyhe", "createdAt": "2020-10-17T09:34:15Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/exec/StreamExecNode.scala", "diffHunk": "@@ -21,7 +21,19 @@ package org.apache.flink.table.planner.plan.nodes.exec\n import org.apache.flink.table.planner.delegation.StreamPlanner\n import org.apache.flink.table.planner.utils.Logging\n \n+import java.util\n+\n /**\n   * Base class for stream ExecNode.\n   */\n-trait StreamExecNode[T] extends ExecNode[StreamPlanner, T] with Logging\n+trait StreamExecNode[T] extends ExecNode[StreamPlanner, T] with Logging {\n+\n+  def getInputEdges: util.List[ExecEdge] = {\n+    // TODO fill out the required shuffle for each stream exec node\n+    val edges = new util.ArrayList[ExecEdge]()\n+    for (_ <- 0 until getInputNodes.size()) {\n+      edges.add(ExecEdge.DEFAULT)\n+    }\n+    edges", "originalCommit": "f26a40dc87e7f977e84f24c5b509b60f2b083d5c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "27bf96c7efa7327dd35a58aeacfabdd12c33b216", "url": "https://github.com/apache/flink/commit/27bf96c7efa7327dd35a58aeacfabdd12c33b216", "message": "[FLINK-19623][table-planner-blink] Introduce ExecEdge to describe information on input edges for ExecNode", "committedDate": "2020-10-19T03:39:14Z", "type": "commit"}, {"oid": "6012feb56e556606391eb81c2a0bf7c679405f9c", "url": "https://github.com/apache/flink/commit/6012feb56e556606391eb81c2a0bf7c679405f9c", "message": "[fix] Fix scalastyle", "committedDate": "2020-10-19T03:39:14Z", "type": "commit"}, {"oid": "6006a6b99245968721e5f7cc3bd3fa2e78851c2d", "url": "https://github.com/apache/flink/commit/6006a6b99245968721e5f7cc3bd3fa2e78851c2d", "message": "[fix] Fix comments", "committedDate": "2020-10-19T03:39:14Z", "type": "commit"}, {"oid": "890b235a6e83e5d1a8da263b46ee7806e049aa10", "url": "https://github.com/apache/flink/commit/890b235a6e83e5d1a8da263b46ee7806e049aa10", "message": "[fix] Add comments on RequiredShuffle.unknown()", "committedDate": "2020-10-19T03:39:14Z", "type": "commit"}, {"oid": "439f2ce1af9395549218913c1774ce4351160121", "url": "https://github.com/apache/flink/commit/439f2ce1af9395549218913c1774ce4351160121", "message": "[fix] Remove unused import", "committedDate": "2020-10-19T03:39:14Z", "type": "commit"}, {"oid": "f190d98cb57794be7ec0ddf92feb1a32a07e783f", "url": "https://github.com/apache/flink/commit/f190d98cb57794be7ec0ddf92feb1a32a07e783f", "message": "[fix] Fix comments", "committedDate": "2020-10-19T03:39:14Z", "type": "commit"}, {"oid": "741d91fc746bf5a05bf1ddc6f0e88e3fab3fefd2", "url": "https://github.com/apache/flink/commit/741d91fc746bf5a05bf1ddc6f0e88e3fab3fefd2", "message": "[fix] Fix comments and rebase", "committedDate": "2020-10-19T04:44:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUxMjA2Ng==", "url": "https://github.com/apache/flink/pull/13625#discussion_r507512066", "bodyText": "not changed here", "author": "godfreyhe", "createdAt": "2020-10-19T06:54:15Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/reuse/DeadlockBreakupProcessor.scala", "diffHunk": "@@ -296,44 +311,48 @@ class DeadlockBreakupProcessor extends DAGProcessor {\n     * Returns true if all input-paths have barrier node (e.g. agg, sort), otherwise false.\n     */\n   private def hasBarrierNodeInInputPaths(\n-      inputPathsOfProbeSide: List[Array[ExecNode[_, _]]]): Boolean = {\n-    require(inputPathsOfProbeSide.nonEmpty)\n+      inputPathsOfLowerInput: List[Array[ExecNode[_, _]]]): Boolean = {\n+    require(inputPathsOfLowerInput.nonEmpty)\n \n-    /** Return true if the successor of join in the input-path is build node, otherwise false */\n-    def checkJoinBuildSide(\n-        buildNode: ExecNode[_, _],\n-        idxOfJoin: Int,\n+    /** Return true if the successor in the input-path is also in higher input, otherwise false */\n+    def checkHigherInput(\n+        higherNode: ExecNode[_, _],\n+        idx: Int,\n         inputPath: Array[ExecNode[_, _]]): Boolean = {\n-      if (idxOfJoin < inputPath.length - 1) {\n-        val nextNode = inputPath(idxOfJoin + 1)\n-        // next node is build node of hash join\n-        buildNode eq nextNode\n+      if (idx < inputPath.length - 1) {\n+        val nextNode = inputPath(idx + 1)\n+        // next node is higher input\n+        higherNode eq nextNode\n       } else {\n         false\n       }\n     }\n \n-    inputPathsOfProbeSide.forall {\n+    inputPathsOfLowerInput.forall {\n       inputPath =>\n         var idx = 0\n         var hasFullDamNode = false\n         // should exclude the reused node (at last position in path)\n         while (!hasFullDamNode && idx < inputPath.length - 1) {\n           val node = inputPath(idx)\n-          val nodeDamBehavior = node.asInstanceOf[BatchExecNode[_]].getDamBehavior\n-          hasFullDamNode = if (nodeDamBehavior == DamBehavior.FULL_DAM) {\n+          val atLeastEndInput = node.getInputEdges.forall(\n+            e => e.getDamBehavior.stricterOrEqual(ExecEdge.DamBehavior.END_INPUT))\n+          hasFullDamNode = if (atLeastEndInput) {\n             true\n           } else {\n-            node match {\n-              case h: BatchExecHashJoin =>\n-                val buildSideIndex = if (h.leftIsBuild) 0 else 1\n-                val buildNode = h.getInputNodes.get(buildSideIndex)\n-                checkJoinBuildSide(buildNode, idx, inputPath)\n-              case n: BatchExecNestedLoopJoin =>\n-                val buildSideIndex = if (n.leftIsBuild) 0 else 1\n-                val buildNode = n.getInputNodes.get(buildSideIndex)\n-                checkJoinBuildSide(buildNode, idx, inputPath)\n-              case _ => false\n+            val inputEdges = node.getInputEdges\n+            if (inputEdges.size() == 2) {\n+              val leftPriority = inputEdges.get(0).getPriority\n+              val rightPriority = inputEdges.get(1).getPriority\n+              if (leftPriority != rightPriority) {\n+                val higherIndex = if (leftPriority == 0) 0 else 1", "originalCommit": "741d91fc746bf5a05bf1ddc6f0e88e3fab3fefd2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "193e9a611b030c9809eabeb057a31bce9b22b151", "url": "https://github.com/apache/flink/commit/193e9a611b030c9809eabeb057a31bce9b22b151", "message": "[fix] Fix comments", "committedDate": "2020-10-19T07:06:46Z", "type": "commit"}, {"oid": "56fa69f06d5d075aff0ceb8cb721fe41eb3f89ee", "url": "https://github.com/apache/flink/commit/56fa69f06d5d075aff0ceb8cb721fe41eb3f89ee", "message": "[fix] Fix failed tests", "committedDate": "2020-10-19T08:44:00Z", "type": "commit"}]}