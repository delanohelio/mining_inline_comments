{"pr_number": 13140, "pr_title": "[FLINK-18884][python] Add chaining strategy and slot sharing group in\u2026", "pr_createdAt": "2020-08-13T13:13:23Z", "pr_url": "https://github.com/apache/flink/pull/13140", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM3Nzc0Mg==", "url": "https://github.com/apache/flink/pull/13140#discussion_r470377742", "bodyText": "set parallelism on this source ds is useless since the parallelism of from_collection would always be one.", "author": "hequn8128", "createdAt": "2020-08-14T02:37:03Z", "path": "flink-python/pyflink/datastream/tests/test_data_stream.py", "diffHunk": "@@ -322,6 +323,86 @@ def test_keyed_stream_partitioning(self):\n         with self.assertRaises(Exception):\n             keyed_stream.forward()\n \n+    def test_slot_sharing_group(self):\n+        source_operator_name = 'collection source'\n+        map_operator_name = 'map_operator'\n+        slot_sharing_group_1 = 'slot_sharing_group_1'\n+        slot_sharing_group_2 = 'slot_sharing_group_2'\n+        ds_1 = self.env.from_collection([1, 2, 3]).name(source_operator_name)\n+        ds_1.slot_sharing_group(slot_sharing_group_1).map(lambda x: x + 1).set_parallelism(3)\\\n+            .name(map_operator_name).slot_sharing_group(slot_sharing_group_2)\\\n+            .add_sink(self.test_sink)\n+\n+        j_generated_stream_graph = self.env._j_stream_execution_environment \\\n+            .getStreamGraph(\"test start new_chain\", True)\n+\n+        j_stream_nodes = list(j_generated_stream_graph.getStreamNodes().toArray())\n+        for j_stream_node in j_stream_nodes:\n+            if j_stream_node.getOperatorName() == source_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_1)\n+            elif j_stream_node.getOperatorName() == map_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_2)\n+\n+    def test_chaining_strategy(self):\n+        chained_operator_name = \"map_operator_1\"\n+        chained_operator_name_1 = \"map_operator_2\"\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        ds.set_parallelism(2).map(lambda x: x).set_parallelism(2)\\\n+            .name(chained_operator_name).map(lambda x: x).set_parallelism(2)\\\n+            .name(chained_operator_name_1).add_sink(self.test_sink)\n+\n+        def assert_chainable(j_stream_graph, expected_upstream_chainable,\n+                             expected_downstream_chainable):\n+            j_stream_nodes = list(j_stream_graph.getStreamNodes().toArray())\n+            for j_stream_node in j_stream_nodes:\n+                if j_stream_node.getOperatorName() == chained_operator_name:\n+                    JStreamingJobGraphGenerator = get_gateway().jvm \\\n+                        .org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator\n+\n+                    j_in_stream_edge = j_stream_node.getInEdges().get(0)\n+                    upstream_chainable = JStreamingJobGraphGenerator.isChainable(j_in_stream_edge,\n+                                                                                 j_stream_graph)\n+                    self.assertEqual(expected_upstream_chainable, upstream_chainable)\n+\n+                    j_out_stream_edge = j_stream_node.getOutEdges().get(0)\n+                    downstream_chainable = JStreamingJobGraphGenerator.isChainable(\n+                        j_out_stream_edge, j_stream_graph)\n+                    self.assertEqual(expected_downstream_chainable, downstream_chainable)\n+\n+        # The map_operator_1 has the same parallelism with source operator and map_operator_2, and\n+        # ship_strategy for collection source and map_operator_1 is FORWARD, so the map_operator_1\n+        # can be chained with collection source and map_operator_2.\n+        j_generated_stream_graph = self.env._j_stream_execution_environment\\\n+            .getStreamGraph(\"test start new_chain\", True)\n+        assert_chainable(j_generated_stream_graph, True, True)\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        # Start a new chain for map_operator_1\n+        ds.set_parallelism(2).map(lambda x: x).set_parallelism(2) \\", "originalCommit": "95d62f551c4f2215fca8982bddaccde0d0238ef0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM5OTEzNQ==", "url": "https://github.com/apache/flink/pull/13140#discussion_r470399135", "bodyText": "Yes, there should be followed by a new operation.", "author": "shuiqiangchen", "createdAt": "2020-08-14T04:08:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM3Nzc0Mg=="}], "type": "inlineReview"}, {"oid": "135dfe91c0e02ef1ec7c20b956997f9117a4e40f", "url": "https://github.com/apache/flink/commit/135dfe91c0e02ef1ec7c20b956997f9117a4e40f", "message": "[FLINK-18884][python] Add chaining strategy and slot sharing group interfaces for Python DataStream API.", "committedDate": "2020-08-14T03:27:07Z", "type": "commit"}, {"oid": "f8312a9ef18d77d9ca2080133c3cc54714de36ed", "url": "https://github.com/apache/flink/commit/f8312a9ef18d77d9ca2080133c3cc54714de36ed", "message": "[FLINK-18884][python] Resolve spelling errors.", "committedDate": "2020-08-14T03:27:07Z", "type": "commit"}, {"oid": "cc8ddc039efdf3720bfaa29e2bff86df4ea2e346", "url": "https://github.com/apache/flink/commit/cc8ddc039efdf3720bfaa29e2bff86df4ea2e346", "message": "[FLINK-18884][python] fix the bug of from_collection by force it to be non-parallel, optimize test case for chaining strategy.", "committedDate": "2020-08-14T04:07:29Z", "type": "commit"}, {"oid": "cc8ddc039efdf3720bfaa29e2bff86df4ea2e346", "url": "https://github.com/apache/flink/commit/cc8ddc039efdf3720bfaa29e2bff86df4ea2e346", "message": "[FLINK-18884][python] fix the bug of from_collection by force it to be non-parallel, optimize test case for chaining strategy.", "committedDate": "2020-08-14T04:07:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzNjY4OQ==", "url": "https://github.com/apache/flink/pull/13140#discussion_r470436689", "bodyText": "Update comments here.", "author": "hequn8128", "createdAt": "2020-08-14T06:35:16Z", "path": "flink-python/pyflink/datastream/tests/test_data_stream.py", "diffHunk": "@@ -322,6 +322,88 @@ def test_keyed_stream_partitioning(self):\n         with self.assertRaises(Exception):\n             keyed_stream.forward()\n \n+    def test_slot_sharing_group(self):\n+        source_operator_name = 'collection source'\n+        map_operator_name = 'map_operator'\n+        slot_sharing_group_1 = 'slot_sharing_group_1'\n+        slot_sharing_group_2 = 'slot_sharing_group_2'\n+        ds_1 = self.env.from_collection([1, 2, 3]).name(source_operator_name)\n+        ds_1.slot_sharing_group(slot_sharing_group_1).map(lambda x: x + 1).set_parallelism(3)\\\n+            .name(map_operator_name).slot_sharing_group(slot_sharing_group_2)\\\n+            .add_sink(self.test_sink)\n+\n+        j_generated_stream_graph = self.env._j_stream_execution_environment \\\n+            .getStreamGraph(\"test start new_chain\", True)\n+\n+        j_stream_nodes = list(j_generated_stream_graph.getStreamNodes().toArray())\n+        for j_stream_node in j_stream_nodes:\n+            if j_stream_node.getOperatorName() == source_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_1)\n+            elif j_stream_node.getOperatorName() == map_operator_name:\n+                self.assertEqual(j_stream_node.getSlotSharingGroup(), slot_sharing_group_2)\n+\n+    def test_chaining_strategy(self):\n+        chained_operator_name_0 = \"map_operator_0\"\n+        chained_operator_name_1 = \"map_operator_1\"\n+        chained_operator_name_2 = \"map_operator_2\"\n+\n+        ds = self.env.from_collection([1, 2, 3])\n+        ds.map(lambda x: x).set_parallelism(2).name(chained_operator_name_0)\\\n+            .map(lambda x: x).set_parallelism(2).name(chained_operator_name_1)\\\n+            .map(lambda x: x).set_parallelism(2).name(chained_operator_name_2)\\\n+            .add_sink(self.test_sink)\n+\n+        def assert_chainable(j_stream_graph, expected_upstream_chainable,\n+                             expected_downstream_chainable):\n+            j_stream_nodes = list(j_stream_graph.getStreamNodes().toArray())\n+            for j_stream_node in j_stream_nodes:\n+                if j_stream_node.getOperatorName() == chained_operator_name_1:\n+                    JStreamingJobGraphGenerator = get_gateway().jvm \\\n+                        .org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator\n+\n+                    j_in_stream_edge = j_stream_node.getInEdges().get(0)\n+                    upstream_chainable = JStreamingJobGraphGenerator.isChainable(j_in_stream_edge,\n+                                                                                 j_stream_graph)\n+                    self.assertEqual(expected_upstream_chainable, upstream_chainable)\n+\n+                    j_out_stream_edge = j_stream_node.getOutEdges().get(0)\n+                    downstream_chainable = JStreamingJobGraphGenerator.isChainable(\n+                        j_out_stream_edge, j_stream_graph)\n+                    self.assertEqual(expected_downstream_chainable, downstream_chainable)\n+\n+        # The map_operator_1 has the same parallelism with source operator and map_operator_2, and\n+        # ship_strategy for collection source and map_operator_1 is FORWARD, so the map_operator_1\n+        # can be chained with collection source and map_operator_2.", "originalCommit": "cc8ddc039efdf3720bfaa29e2bff86df4ea2e346", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzODQ0OA==", "url": "https://github.com/apache/flink/pull/13140#discussion_r470438448", "bodyText": "Thank you , I will update it.", "author": "shuiqiangchen", "createdAt": "2020-08-14T06:40:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQzNjY4OQ=="}], "type": "inlineReview"}, {"oid": "39d40e77c1c2f6e34070366120a9594fe712548c", "url": "https://github.com/apache/flink/commit/39d40e77c1c2f6e34070366120a9594fe712548c", "message": "[FLINK-18884][python] Update comments.", "committedDate": "2020-08-14T06:42:03Z", "type": "commit"}]}