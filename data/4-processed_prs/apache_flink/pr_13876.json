{"pr_number": 13876, "pr_title": "[FLINK-18382][docs] Translate Kafka SQL connector documentation into Chinese", "pr_createdAt": "2020-11-02T08:31:58Z", "pr_url": "https://github.com/apache/flink/pull/13876", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkxODExMg==", "url": "https://github.com/apache/flink/pull/13876#discussion_r541918112", "bodyText": "It will be better like \"\u4ece\u800c\u4f7f consumer \u80fd\u591f\u63a2\u6d4b\u5339\u914d\u540d\u79f0\u89c4\u5219\u7684 topic \u4e2d\u65b0\u7684 partitions\u3002\"?", "author": "V1ncentzzZ", "createdAt": "2020-12-13T12:44:05Z", "path": "docs/dev/table/connectors/kafka.zh.md", "diffHunk": "@@ -75,185 +72,181 @@ CREATE TABLE kafkaTable (\n </div>\n </div>\n \n-Connector Options\n+\u8fde\u63a5\u5668\u914d\u7f6e\u9879\n ----------------\n \n <table class=\"table table-bordered\">\n     <thead>\n     <tr>\n-      <th class=\"text-left\" style=\"width: 25%\">Option</th>\n-      <th class=\"text-center\" style=\"width: 8%\">Required</th>\n-      <th class=\"text-center\" style=\"width: 7%\">Default</th>\n-      <th class=\"text-center\" style=\"width: 10%\">Type</th>\n-      <th class=\"text-center\" style=\"width: 50%\">Description</th>\n+      <th class=\"text-left\" style=\"width: 25%\">\u9009\u9879</th>\n+      <th class=\"text-center\" style=\"width: 8%\">\u662f\u5426\u5fc5\u9700</th>\n+      <th class=\"text-center\" style=\"width: 7%\">\u9ed8\u8ba4\u503c</th>\n+      <th class=\"text-center\" style=\"width: 10%\">\u7c7b\u578b</th>\n+      <th class=\"text-center\" style=\"width: 50%\">\u63cf\u8ff0</th>\n     </tr>\n     </thead>\n     <tbody>\n     <tr>\n       <td><h5>connector</h5></td>\n-      <td>required</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>\u5fc5\u9700</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>String</td>\n-      <td>Specify what connector to use, for Kafka use: <code>'kafka'</code>.</td>\n+      <td>\u4f7f\u7528\u7684\u8fde\u63a5\u5668, Kafka \u8fde\u63a5\u5668\u4f7f\u7528: <code>'kafka'</code>.</td>\n     </tr>\n     <tr>\n       <td><h5>topic</h5></td>\n-      <td>required for sink, optional for source(use 'topic-pattern' instead if not set)</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>sink \u8868\u5fc5\u9700</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>String</td>\n-      <td>Topic name(s) to read data from when the table is used as source. It also supports topic list for source by separating topic by semicolon like <code>'topic-1;topic-2'</code>. Note, only one of \"topic-pattern\" and \"topic\" can be specified for sources. When the table is used as sink, the topic name is the topic to write data to. Note topic list is not supported for sinks.</td>\n+      <td>\u5f53\u8868\u7528\u4f5c source \u65f6\u8bfb\u53d6\u6570\u636e\u7684 topic \u540d\uff0c\u4ea6\u652f\u6301\u7528\u5206\u53f7\u95f4\u9694\u7684 topic \u5217\u8868\uff0c\u5982 <code>'topic-1;topic-2'</code>\u3002\u6ce8\u610f\u5bf9 source \u8868\u800c\u8a00\uff0c'topic' \u548c 'topic-pattern' \u4e24\u4e2a\u9009\u9879\u53ea\u80fd\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a\u5f53\u8868\u88ab\u7528\u4f5c sink \u65f6\uff0c\u8be5\u914d\u7f6e\u8868\u793a\u5199\u5165\u7684 topic \u540d\u3002\u6ce8\u610f sink \u8868\u4e0d\u652f\u6301 topic \u5217\u8868</td>\n     </tr>\n     <tr>\n       <td><h5>topic-pattern</h5></td>\n-      <td>optional</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>\u53ef\u9009</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>String</td>\n-      <td>The regular expression for a pattern of topic names to read from. All topics with names that match the specified regular expression will be subscribed by the consumer when the job starts running. Note, only one of \"topic-pattern\" and \"topic\" can be specified for sources.</td>\n+      <td>\u5339\u914d\u8bfb\u53d6 topic \u540d\u79f0\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u3002\u5728\u4f5c\u4e1a\u5f00\u59cb\u8fd0\u884c\u65f6\uff0c\u6240\u6709\u5339\u914d\u8be5\u6b63\u5219\u8868\u8fbe\u5f0f\u7684 topic \u90fd\u5c06\u88ab Kafka consumer \u8ba2\u9605\u3002\u6ce8\u610f\u5bf9 source \u8868\u800c\u8a00\uff0c'topic' \u548c 'topic-pattern' \u4e24\u4e2a\u9009\u9879\u53ea\u80fd\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a</td>\n     </tr>\n     <tr>\n       <td><h5>properties.bootstrap.servers</h5></td>\n-      <td>required</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>\u5fc5\u9700</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>String</td>\n-      <td>Comma separated list of Kafka brokers.</td>\n+      <td>\u9017\u53f7\u5206\u9694\u7684 Kafka broker \u5217\u8868</td>\n     </tr>\n     <tr>\n       <td><h5>properties.group.id</h5></td>\n-      <td>required by source</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>source \u8868\u5fc5\u9700</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>String</td>\n-      <td>The id of the consumer group for Kafka source, optional for Kafka sink.</td>\n+      <td>Kafka source \u7684 consumer \u7ec4 ID\uff0c\u5bf9 Kafka sink \u53ef\u9009\u586b</td>\n     </tr>\n     <tr>\n       <td><h5>format</h5></td>\n-      <td>required</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>\u5fc5\u9700</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>String</td>\n-      <td>The format used to deserialize and serialize Kafka messages.\n-      The supported formats are <code>'csv'</code>, <code>'json'</code>, <code>'avro'</code>, <code>'debezium-json'</code> and <code>'canal-json'</code>.\n-      Please refer to <a href=\"{% link dev/table/connectors/formats/index.zh.md %}\">Formats</a> page for more details and more format options.\n+      <td>\u7528\u6765\u5e8f\u5217\u5316\u6216\u53cd\u5e8f\u5217\u5316 Kafka \u6d88\u606f\u7684\u683c\u5f0f\u3002\n+      \u652f\u6301\u7684\u683c\u5f0f\u6709 <code>'csv'</code>\u3001<code>'json'</code>\u3001<code>'avro'</code>\u3001<code>'debezium-json'</code> \u548c <code>'canal-json'</code>\u3002\n+      \u8bf7\u53c2\u9605<a href=\"{% link dev/table/connectors/formats/index.zh.md %}\">\u683c\u5f0f</a>\u9875\u9762\u4ee5\u83b7\u53d6\u66f4\u591a\u5173\u4e8e format \u7684\u7ec6\u8282\u548c\u76f8\u5173\u914d\u7f6e\u9879\u3002\n       </td>\n     </tr>\n     <tr>\n       <td><h5>scan.startup.mode</h5></td>\n-      <td>optional</td>\n+      <td>\u53ef\u9009</td>\n       <td style=\"word-wrap: break-word;\">group-offsets</td>\n       <td>String</td>\n-      <td>Startup mode for Kafka consumer, valid values are <code>'earliest-offset'</code>, <code>'latest-offset'</code>, <code>'group-offsets'</code>, <code>'timestamp'</code> and <code>'specific-offsets'</code>.\n-       See the following <a href=\"#start-reading-position\">Start Reading Position</a> for more details.</td>\n+      <td>Kafka consumer \u7684\u542f\u52a8\u6a21\u5f0f\u3002\u6709\u6548\u7684\u503c\u6709\uff1a<code>'earliest-offset'</code>\u3001<code>'latest-offset'</code>\u3001<code>'group-offsets'</code>\u3001<code>'timestamp'</code> \u548c <code>'specific-offsets'</code>\u3002\n+      \u8bf7\u53c2\u9605\u4e0b\u65b9<a href=\"#start-reading-position\">\u8d77\u59cb\u6d88\u8d39\u4f4d\u70b9</a>\u4e00\u8282\u4ee5\u83b7\u53d6\u66f4\u591a\u7ec6\u8282\u3002</td>\n     </tr>\n     <tr>\n       <td><h5>scan.startup.specific-offsets</h5></td>\n-      <td>optional</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>\u53ef\u9009</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>String</td>\n-      <td>Specify offsets for each partition in case of <code>'specific-offsets'</code> startup mode, e.g. <code>'partition:0,offset:42;partition:1,offset:300'</code>.\n+      <td>\u5728\u4f7f\u7528 <code>'specific-offsets'</code> \u542f\u52a8\u6a21\u5f0f\u65f6\u4e3a\u6bcf\u4e2a partition \u6307\u5b9a\u4f4d\u70b9\uff0c\u4f8b\u5982 <code>'partition:0,offset:42;partition:1,offset:300'</code>\u3002\n       </td>\n     </tr>\n     <tr>\n       <td><h5>scan.startup.timestamp-millis</h5></td>\n-      <td>optional</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>\u53ef\u9009</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>Long</td>\n-      <td>Start from the specified epoch timestamp (milliseconds) used in case of <code>'timestamp'</code> startup mode.</td>\n+      <td>\u5728\u4f7f\u7528 <code>'timestamp'</code> \u542f\u52a8\u6a21\u5f0f\u65f6\u6307\u5b9a\u542f\u52a8\u7684\u65f6\u95f4\u6233\uff08\u6beb\u79d2\u5355\u4f4d\uff09</td>\n     </tr>\n     <tr>\n       <td><h5>scan.topic-partition-discovery.interval</h5></td>\n-      <td>optional</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>\u53ef\u9009</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>Duration</td>\n-      <td>Interval for consumer to discover dynamically created Kafka topics and partitions periodically.</td>\n+      <td>Consumer \u5b9a\u671f\u63a2\u6d4b\u52a8\u6001\u521b\u5efa\u7684 Kafka topic \u548c partition \u7684\u65f6\u95f4\u95f4\u9694</td>\n     </tr>\n     <tr>\n       <td><h5>sink.partitioner</h5></td>\n-      <td>optional</td>\n-      <td style=\"word-wrap: break-word;\">(none)</td>\n+      <td>\u53ef\u9009</td>\n+      <td style=\"word-wrap: break-word;\">(\u65e0)</td>\n       <td>String</td>\n-      <td>Output partitioning from Flink's partitions into Kafka's partitions. Valid values are\n+      <td>Flink partition \u5230 Kafka partition \u7684\u5206\u533a\u6620\u5c04\u5173\u7cfb\uff0c\u6709\u6548\u503c\u6709\uff1a\n       <ul>\n-        <li><code>fixed</code>: each Flink partition ends up in at most one Kafka partition.</li>\n-        <li><code>round-robin</code>: a Flink partition is distributed to Kafka partitions round-robin.</li>\n-        <li>Custom <code>FlinkKafkaPartitioner</code> subclass: e.g. <code>'org.mycompany.MyPartitioner'</code>.</li>\n+        <li><code>fixed</code>: \u6bcf\u4e2a Flink partition \u6700\u7ec8\u5bf9\u5e94\u6700\u591a\u4e00\u4e2a Kafka partition\u3002</li>\n+        <li><code>round-robin</code>: Flink partition \u6309\u8f6e\u5faa (round-robin) \u7684\u6a21\u5f0f\u5bf9\u5e94\u5230 Kafka partition\u3002</li>\n+        <li>\u81ea\u5b9a\u4e49 <code>FlinkKafkaPartitioner</code> \u7684\u5b50\u7c7b: \u4f8b\u5982 <code>'org.mycompany.MyPartitioner'</code>\u3002</li>\n       </ul>\n       </td>\n     </tr>\n     <tr>\n       <td><h5>sink.semantic</h5></td>\n-      <td>optional</td>\n+      <td>\u53ef\u9009</td>\n       <td style=\"word-wrap: break-word;\">at-least-once</td>\n       <td>String</td>\n-      <td>Defines the delivery semantic for the Kafka sink. Valid enumerationns are <code>'at-lease-once'</code>, <code>'exactly-once'</code> and <code>'none'</code>.\n-      See <a href='#consistency-guarantees'>Consistency guarantees</a> for more details. </td>\n+      <td>\u5b9a\u4e49 Kafka sink \u7684\u8bed\u4e49. \u6709\u6548\u503c\u6709 are <code>'at-lease-once'</code>\u3001<code>'exactly-once'</code> \u548c <code>'none'</code>.\n+      \u8bf7\u53c2\u9605<a href='#consistency-guarantees'>\u4e00\u81f4\u6027\u4fdd\u8bc1</a>\u4ee5\u83b7\u53d6\u66f4\u591a\u7ec6\u8282\u3002</td>\n     </tr>\n     </tbody>\n </table>\n \n-Features\n+\u7279\u6027\n ----------------\n-### Topic and Partition Discovery\n+### Topic \u548c Partition \u7684\u63a2\u6d4b\n \n-The config option `topic` and `topic-pattern` specifies the topics or topic pattern to consume for source. The config option `topic` can accept topic list using semicolon separator like 'topic-1;topic-2'.\n-The config option `topic-pattern`  will use regular expression to discover the matched topic. For example, if the `topic-pattern` is `test-topic-[0-9]`, then all topics with names that match the specified regular expression (starting with `test-topic-` and ending with a single digit)) will be subscribed by the consumer when the job starts running.\n+`topic` \u548c `topic-pattern` \u914d\u7f6e\u9879\u51b3\u5b9a\u4e86 source \u6d88\u8d39\u7684 topic \u6216 topic \u7684\u5339\u914d\u89c4\u5219\u3002`topic` \u914d\u7f6e\u9879\u53ef\u63a5\u53d7\u4f7f\u7528\u5206\u53f7\u95f4\u9694\u7684 topic \u5217\u8868\uff0c\u4f8b\u5982 `topic-1;topic-2`\u3002\n+`topic-pattern` \u914d\u7f6e\u9879\u4f7f\u7528\u6b63\u5219\u8868\u8fbe\u5f0f\u6765\u63a2\u6d4b\u5339\u914d\u7684 topic\u3002\u4f8b\u5982 `topic-pattern` \u8bbe\u7f6e\u4e3a `test-topic-[0-9]`\uff0c\u5219\u5728\u4f5c\u4e1a\u542f\u52a8\u65f6\uff0c\u6240\u6709\u5339\u914d\u8be5\u6b63\u5219\u8868\u8fbe\u5f0f\u7684 topic\uff08\u4ee5 `test-topic-` \u5f00\u5934\uff0c\u4ee5\u4e00\u4f4d\u6570\u5b57\u7ed3\u5c3e\uff09\u90fd\u5c06\u88ab consumer \u8ba2\u9605\u3002\n \n-To allow the consumer to discover dynamically created topics after the job started running, set a non-negative value for `scan.topic-partition-discovery.interval`. This allows the consumer to discover partitions of new topics with names that also match the specified pattern.\n+\u4e3a\u5141\u8bb8 consumer \u5728\u4f5c\u4e1a\u542f\u52a8\u4e4b\u540e\u63a2\u6d4b\u5230\u52a8\u6001\u521b\u5efa\u7684 topic\uff0c\u8bf7\u5c06 `scan.topic-partition-discovery.interval` \u914d\u7f6e\u4e3a\u4e00\u4e2a\u975e\u8d1f\u503c\uff0c\u4ece\u800c\u4f7f consumer \u80fd\u591f\u63a2\u6d4b\u5339\u914d\u540d\u79f0\u89c4\u5219\u7684\u65b0 topic \u4e2d\u7684 partition\u3002", "originalCommit": "a6e72cdc72f44909872f7324c62833b7726a44a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTYwMDA4NA==", "url": "https://github.com/apache/flink/pull/13876#discussion_r545600084", "bodyText": "Fixed in the latest commit~", "author": "PatrickRen", "createdAt": "2020-12-18T06:32:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkxODExMg=="}], "type": "inlineReview"}, {"oid": "99bd6ea3177c6b62b2b5c42a70caec5c85cddff0", "url": "https://github.com/apache/flink/commit/99bd6ea3177c6b62b2b5c42a70caec5c85cddff0", "message": "[FLINK-18382][docs] Translate Kafka SQL connector documentation into Chinese", "committedDate": "2020-12-18T06:23:21Z", "type": "commit"}, {"oid": "c02265f594b11adc16aebbb5eb943fc63eee9140", "url": "https://github.com/apache/flink/commit/c02265f594b11adc16aebbb5eb943fc63eee9140", "message": "[hotfix][docs] Fix typo in Kafka SQL connector documentation", "committedDate": "2020-12-18T06:25:07Z", "type": "commit"}, {"oid": "cdcae6f6464fff54bd1040031039d688370d8866", "url": "https://github.com/apache/flink/commit/cdcae6f6464fff54bd1040031039d688370d8866", "message": "[hotfix][docs] Add a Chinese version for sql-connector-download-table.html page", "committedDate": "2020-12-18T06:26:33Z", "type": "commit"}, {"oid": "cdcae6f6464fff54bd1040031039d688370d8866", "url": "https://github.com/apache/flink/commit/cdcae6f6464fff54bd1040031039d688370d8866", "message": "[hotfix][docs] Add a Chinese version for sql-connector-download-table.html page", "committedDate": "2020-12-18T06:26:33Z", "type": "forcePushed"}, {"oid": "5417dad63b1dd60d279a08665f08c3569f52f26e", "url": "https://github.com/apache/flink/commit/5417dad63b1dd60d279a08665f08c3569f52f26e", "message": "[FLINK-18382][docs] Use sql-connector-download-table.zh.html for all Chinese pages and improve expressions in Kafka SQL doc", "committedDate": "2020-12-22T13:34:48Z", "type": "commit"}]}