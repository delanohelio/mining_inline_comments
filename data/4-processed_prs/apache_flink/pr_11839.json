{"pr_number": 11839, "pr_title": "[FLINK-17166][dist] Modify the log4j-console.properties to also output logs into the files for WebUI", "pr_createdAt": "2020-04-21T08:11:56Z", "pr_url": "https://github.com/apache/flink/pull/11839", "timeline": [{"oid": "5a26fbb56d996236c296328a6d673bc01982be5f", "url": "https://github.com/apache/flink/commit/5a26fbb56d996236c296328a6d673bc01982be5f", "message": "[FLINK-17166][dist] Modify the log4j-console.properties to also output logs into the files for WebUI\n\nBy using System.setOut and System.setErr to redirect the PrintStream to log4j logger, we could output the stdout/stderr to console and file at the same time.", "committedDate": "2020-04-21T10:32:07Z", "type": "forcePushed"}, {"oid": "ab5e8324f0ace63d1e5b3f292dd6d517b056fd21", "url": "https://github.com/apache/flink/commit/ab5e8324f0ace63d1e5b3f292dd6d517b056fd21", "message": "[FLINK-17166][dist] Modify the log4j-console.properties to also output logs into the files for WebUI\n\nBy using System.setOut and System.setErr to redirect the PrintStream to log4j logger, we could output the stdout/stderr to console and file at the same time.", "committedDate": "2020-04-21T10:59:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQxNjk3MA==", "url": "https://github.com/apache/flink/pull/11839#discussion_r414416970", "bodyText": "why are we introducing a dedicated .err file? AFAIK no other script has it, why should this one?", "author": "zentol", "createdAt": "2020-04-24T09:05:34Z", "path": "flink-dist/src/main/flink-bin/bin/flink-console.sh", "diffHunk": "@@ -58,7 +58,18 @@ esac\n \n FLINK_TM_CLASSPATH=`constructFlinkClassPath`\n \n-log_setting=(\"-Dlog4j.configuration=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlog4j.configurationFile=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlogback.configurationFile=file:${FLINK_CONF_DIR}/logback-console.xml\")\n+if [ \"$FLINK_IDENT_STRING\" = \"\" ]; then\n+    FLINK_IDENT_STRING=\"$USER\"\n+fi\n+\n+RANDOM_ID=$(echo $RANDOM | tr '[0-9]' '[a-z]')\n+\n+FLINK_LOG_PREFIX=\"${FLINK_LOG_DIR}/flink-${FLINK_IDENT_STRING}-${SERVICE}-${RANDOM_ID}-${HOSTNAME}\"\n+log=\"${FLINK_LOG_PREFIX}.log\"\n+out=\"${FLINK_LOG_PREFIX}.out\"\n+err=\"${FLINK_LOG_PREFIX}.err\"", "originalCommit": "ab5e8324f0ace63d1e5b3f292dd6d517b056fd21", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTE5NjMwMw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r415196303", "bodyText": "Actually, the YARN and K8s deployment always put the stdout to .out file and stderr to .err file. And i think it is better to separate them if we could.", "author": "wangyang0918", "createdAt": "2020-04-26T02:45:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQxNjk3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1OTY1Ng==", "url": "https://github.com/apache/flink/pull/11839#discussion_r415759656", "bodyText": "And i think it is better to separate them if we could.\n\nThat may be so, but the scripts should have a consistent behavior.", "author": "zentol", "createdAt": "2020-04-27T12:13:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQxNjk3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQxODkxMg==", "url": "https://github.com/apache/flink/pull/11839#discussion_r414418912", "bodyText": "this should use the same logic as flink-daemon.sh", "author": "zentol", "createdAt": "2020-04-24T09:08:34Z", "path": "flink-dist/src/main/flink-bin/bin/flink-console.sh", "diffHunk": "@@ -58,7 +58,18 @@ esac\n \n FLINK_TM_CLASSPATH=`constructFlinkClassPath`\n \n-log_setting=(\"-Dlog4j.configuration=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlog4j.configurationFile=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlogback.configurationFile=file:${FLINK_CONF_DIR}/logback-console.xml\")\n+if [ \"$FLINK_IDENT_STRING\" = \"\" ]; then\n+    FLINK_IDENT_STRING=\"$USER\"\n+fi\n+\n+RANDOM_ID=$(echo $RANDOM | tr '[0-9]' '[a-z]')\n+\n+FLINK_LOG_PREFIX=\"${FLINK_LOG_DIR}/flink-${FLINK_IDENT_STRING}-${SERVICE}-${RANDOM_ID}-${HOSTNAME}\"", "originalCommit": "ab5e8324f0ace63d1e5b3f292dd6d517b056fd21", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTE5ODg4Nw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r415198887", "bodyText": "I think the foreground-start is a little different from daemon-start. I will update this part to use an incremental id and try to reuse the logic with flink-daemon.sh.", "author": "wangyang0918", "createdAt": "2020-04-26T03:01:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQxODkxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQyNTY3Ng==", "url": "https://github.com/apache/flink/pull/11839#discussion_r414425676", "bodyText": "change the Logger argument to a Consumer<String>, pass STD_(OUT|ERR)_LOGGER::info as method reference, remove TestingLogger.", "author": "zentol", "createdAt": "2020-04-24T09:18:40Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/util/StdOutErrRedirector.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.util;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.PrintStream;\n+\n+/**\n+ * Redirect std out and std err to logger.\n+ */\n+public class StdOutErrRedirector {\n+\n+\tprivate static final String STD_OUT_FILE_PROPERTY_KEY = \"stdout.file\";\n+\tprivate static final String STD_ERR_FILE_PROPERTY_KEY = \"stderr.file\";\n+\n+\tprivate static final String STD_OUT_LOGGER_NAME = \"StdOutErrRedirector.StdOut\";\n+\tprivate static final String STD_ERR_LOGGER_NAME = \"StdOutErrRedirector.StdErr\";\n+\n+\tprivate static final Logger STD_OUT_LOGGER = LoggerFactory.getLogger(STD_OUT_LOGGER_NAME);\n+\tprivate static final Logger STD_ERR_LOGGER = LoggerFactory.getLogger(STD_ERR_LOGGER_NAME);\n+\n+\tprivate static final ThreadLocal<Boolean> isRedirecting = ThreadLocal.withInitial(() -> false);\n+\n+\t/**\n+\t * Try to redirect stdout and stderr.\n+\t */\n+\tpublic static void redirectStdOutErr() {\n+\t\tif (System.getProperty(STD_OUT_FILE_PROPERTY_KEY) != null) {\n+\t\t\tSystem.setOut(createLoggerProxy(STD_OUT_LOGGER, System.out));\n+\t\t}\n+\n+\t\tif (System.getProperty(STD_ERR_FILE_PROPERTY_KEY) != null) {\n+\t\t\tSystem.setErr(createLoggerProxy(STD_ERR_LOGGER, System.err));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create logger proxy print stream.\n+\t * Do not check null, keep the same behavior with System.out/err.\n+\t *\n+\t * @param originalPrintStream the original print stream\n+\t * @return the proxy print stream\n+\t */\n+\t@VisibleForTesting\n+\tstatic PrintStream createLoggerProxy(final Logger logger, final PrintStream originalPrintStream) {", "originalCommit": "ab5e8324f0ace63d1e5b3f292dd6d517b056fd21", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwMzE0NQ==", "url": "https://github.com/apache/flink/pull/11839#discussion_r415203145", "bodyText": "Nice suggestion. I will fix it.", "author": "wangyang0918", "createdAt": "2020-04-26T03:30:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQyNTY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQzMTg5Nw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r414431897", "bodyText": "use assertThat for consistency with the rest of the file", "author": "zentol", "createdAt": "2020-04-24T09:28:11Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/util/StdOutErrRedirectorTest.java", "diffHunk": "@@ -0,0 +1,456 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.util;\n+\n+import org.apache.flink.util.TestLogger;\n+\n+import org.hamcrest.Matchers;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.Marker;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.UnsupportedEncodingException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.core.testutils.CommonTestUtils.assertThrows;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit test for StdOutErrRedirector.\n+ */\n+public class StdOutErrRedirectorTest extends TestLogger {\n+\n+\tprivate ByteArrayOutputStream byteArrayOutputStream;\n+\tprivate PrintStream originalStream;\n+\n+\t@Before\n+\tpublic void setUp() throws UnsupportedEncodingException {\n+\t\tbyteArrayOutputStream = new ByteArrayOutputStream();\n+\t\toriginalStream = new PrintStream(byteArrayOutputStream, true, \"UTF-8\");\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws IOException {\n+\t\tbyteArrayOutputStream.close();\n+\t\toriginalStream.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testNormalPrint() {\n+\t\tfinal int intMsg = 1234;\n+\t\tfinal String strMsg = \"some message\";\n+\t\tfinal List<String> logContents = new ArrayList<>();\n+\n+\t\tfinal Logger logger = new TestingLogger(\n+\t\t\tmsg -> {\n+\t\t\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(true));\n+\t\t\t\tlogContents.add(msg);\n+\t\t\t}\n+\t\t);\n+\n+\t\tfinal PrintStream proxyStream = StdOutErrRedirector.createLoggerProxy(logger, originalStream);\n+\n+\t\tassertFalse(StdOutErrRedirector.isRedirecting());", "originalCommit": "ab5e8324f0ace63d1e5b3f292dd6d517b056fd21", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2Mjg5MA==", "url": "https://github.com/apache/flink/pull/11839#discussion_r414462890", "bodyText": "the order should be important", "author": "zentol", "createdAt": "2020-04-24T10:17:22Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/util/StdOutErrRedirectorTest.java", "diffHunk": "@@ -0,0 +1,456 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.util;\n+\n+import org.apache.flink.util.TestLogger;\n+\n+import org.hamcrest.Matchers;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.Marker;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.UnsupportedEncodingException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.core.testutils.CommonTestUtils.assertThrows;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit test for StdOutErrRedirector.\n+ */\n+public class StdOutErrRedirectorTest extends TestLogger {\n+\n+\tprivate ByteArrayOutputStream byteArrayOutputStream;\n+\tprivate PrintStream originalStream;\n+\n+\t@Before\n+\tpublic void setUp() throws UnsupportedEncodingException {\n+\t\tbyteArrayOutputStream = new ByteArrayOutputStream();\n+\t\toriginalStream = new PrintStream(byteArrayOutputStream, true, \"UTF-8\");\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws IOException {\n+\t\tbyteArrayOutputStream.close();\n+\t\toriginalStream.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testNormalPrint() {\n+\t\tfinal int intMsg = 1234;\n+\t\tfinal String strMsg = \"some message\";\n+\t\tfinal List<String> logContents = new ArrayList<>();\n+\n+\t\tfinal Logger logger = new TestingLogger(\n+\t\t\tmsg -> {\n+\t\t\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(true));\n+\t\t\t\tlogContents.add(msg);\n+\t\t\t}\n+\t\t);\n+\n+\t\tfinal PrintStream proxyStream = StdOutErrRedirector.createLoggerProxy(logger, originalStream);\n+\n+\t\tassertFalse(StdOutErrRedirector.isRedirecting());\n+\n+\t\tproxyStream.print(intMsg);\n+\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(false));\n+\t\tproxyStream.println(strMsg);\n+\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(false));\n+\n+\t\tassertThat(logContents.size(), is(3));\n+\t\tassertThat(logContents, Matchers.containsInAnyOrder(String.valueOf(intMsg), strMsg, System.lineSeparator()));", "originalCommit": "ab5e8324f0ace63d1e5b3f292dd6d517b056fd21", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQ2NDgwNA==", "url": "https://github.com/apache/flink/pull/11839#discussion_r414464804", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\tproxyStream.print(recursive);\n          \n          \n            \n            \t\t\t\tproxyStream.print(msg);", "author": "zentol", "createdAt": "2020-04-24T10:20:41Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/util/StdOutErrRedirectorTest.java", "diffHunk": "@@ -0,0 +1,456 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.util;\n+\n+import org.apache.flink.util.TestLogger;\n+\n+import org.hamcrest.Matchers;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.Marker;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.UnsupportedEncodingException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Consumer;\n+\n+import static org.apache.flink.core.testutils.CommonTestUtils.assertThrows;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit test for StdOutErrRedirector.\n+ */\n+public class StdOutErrRedirectorTest extends TestLogger {\n+\n+\tprivate ByteArrayOutputStream byteArrayOutputStream;\n+\tprivate PrintStream originalStream;\n+\n+\t@Before\n+\tpublic void setUp() throws UnsupportedEncodingException {\n+\t\tbyteArrayOutputStream = new ByteArrayOutputStream();\n+\t\toriginalStream = new PrintStream(byteArrayOutputStream, true, \"UTF-8\");\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws IOException {\n+\t\tbyteArrayOutputStream.close();\n+\t\toriginalStream.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testNormalPrint() {\n+\t\tfinal int intMsg = 1234;\n+\t\tfinal String strMsg = \"some message\";\n+\t\tfinal List<String> logContents = new ArrayList<>();\n+\n+\t\tfinal Logger logger = new TestingLogger(\n+\t\t\tmsg -> {\n+\t\t\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(true));\n+\t\t\t\tlogContents.add(msg);\n+\t\t\t}\n+\t\t);\n+\n+\t\tfinal PrintStream proxyStream = StdOutErrRedirector.createLoggerProxy(logger, originalStream);\n+\n+\t\tassertFalse(StdOutErrRedirector.isRedirecting());\n+\n+\t\tproxyStream.print(intMsg);\n+\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(false));\n+\t\tproxyStream.println(strMsg);\n+\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(false));\n+\n+\t\tassertThat(logContents.size(), is(3));\n+\t\tassertThat(logContents, Matchers.containsInAnyOrder(String.valueOf(intMsg), strMsg, System.lineSeparator()));\n+\t}\n+\n+\t@Test\n+\tpublic void testRecursivePrint() throws Exception {\n+\t\tfinal String recursive = \"recursive\";\n+\t\tfinal Logger logger = new TestingLogger();\n+\n+\t\tfinal PrintStream proxyStream = StdOutErrRedirector.createLoggerProxy(logger, originalStream);\n+\t\t((TestingLogger) logger).setMsgConsumer(\n+\t\t\tmsg -> {\n+\t\t\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(true));\n+\t\t\t\tproxyStream.print(recursive);", "originalCommit": "ab5e8324f0ace63d1e5b3f292dd6d517b056fd21", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6e097b629bafde50b88d261cd856d624cf6f89c5", "url": "https://github.com/apache/flink/commit/6e097b629bafde50b88d261cd856d624cf6f89c5", "message": "[FLINK-17166][dist] Modify the log4j-console.properties to also output logs into the files for WebUI\n\nBy using System.setOut and System.setErr to redirect the PrintStream to log4j logger, we could output the stdout/stderr to console and file at the same time.", "committedDate": "2020-04-27T02:40:07Z", "type": "forcePushed"}, {"oid": "2ca466db8ef9f2c9ef74cdd830078610dd13506a", "url": "https://github.com/apache/flink/commit/2ca466db8ef9f2c9ef74cdd830078610dd13506a", "message": "[FLINK-17166][dist] Modify the log4j-console.properties to also output logs into the files for WebUI\n\nBy using System.setOut and System.setErr to redirect the PrintStream to log4j logger, we could output the stdout/stderr to console and file at the same time.", "committedDate": "2020-04-27T03:59:59Z", "type": "forcePushed"}, {"oid": "2c1df7529825b6a0af7e57d29febeade36a758b1", "url": "https://github.com/apache/flink/commit/2c1df7529825b6a0af7e57d29febeade36a758b1", "message": "[FLINK-17166][dist] Modify the log4j-console.properties to also output logs into the files for WebUI\n\nBy using System.setOut and System.setErr to redirect the PrintStream to log4j logger, we could output the stdout/stderr to console and file at the same time.", "committedDate": "2020-04-27T05:17:27Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1MTQxNw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r415751417", "bodyText": "use an AtomicReference instead", "author": "zentol", "createdAt": "2020-04-27T11:59:27Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/util/StdOutErrRedirectorTest.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.util;\n+\n+import org.apache.flink.api.java.tuple.Tuple1;\n+import org.apache.flink.util.TestLogger;\n+\n+import org.hamcrest.Matchers;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.UnsupportedEncodingException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static org.apache.flink.core.testutils.CommonTestUtils.assertThrows;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit test for StdOutErrRedirector.\n+ */\n+public class StdOutErrRedirectorTest extends TestLogger {\n+\n+\tprivate ByteArrayOutputStream byteArrayOutputStream;\n+\tprivate PrintStream originalStream;\n+\n+\t@Before\n+\tpublic void setUp() throws UnsupportedEncodingException {\n+\t\tbyteArrayOutputStream = new ByteArrayOutputStream();\n+\t\toriginalStream = new PrintStream(byteArrayOutputStream, true, \"UTF-8\");\n+\t}\n+\n+\t@After\n+\tpublic void tearDown() throws IOException {\n+\t\tbyteArrayOutputStream.close();\n+\t\toriginalStream.close();\n+\t}\n+\n+\t@Test\n+\tpublic void testNormalPrint() {\n+\t\tfinal int intMsg = 1234;\n+\t\tfinal String strMsg = \"some message\";\n+\t\tfinal List<String> logContents = new ArrayList<>();\n+\n+\t\tfinal PrintStream proxyStream = StdOutErrRedirector.createLoggerProxy(\n+\t\t\tmsg -> {\n+\t\t\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(true));\n+\t\t\t\tlogContents.add(msg);\n+\t\t\t},\n+\t\t\toriginalStream);\n+\n+\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(false));\n+\n+\t\tproxyStream.print(intMsg);\n+\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(false));\n+\t\tproxyStream.println(strMsg);\n+\t\tassertThat(StdOutErrRedirector.isRedirecting(), is(false));\n+\n+\t\tassertThat(logContents.size(), is(3));\n+\t\tassertThat(logContents, Matchers.contains(String.valueOf(intMsg), strMsg, System.lineSeparator()));\n+\t}\n+\n+\t@Test\n+\tpublic void testRecursivePrint() throws Exception {\n+\t\tfinal String recursive = \"recursive\";\n+\t\tfinal Tuple1<PrintStream> streamTuple1 = new Tuple1<>();", "originalCommit": "2c1df7529825b6a0af7e57d29febeade36a758b1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1NzUxNw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r415757517", "bodyText": "I see no reason why we should have this in the name.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            FLINK_LOG_PREFIX=\"${FLINK_LOG_DIR}/flink-foreground-${FLINK_IDENT_STRING}-${SERVICE}-${id}-${HOSTNAME}\"\n          \n          \n            \n            FLINK_LOG_PREFIX=\"${FLINK_LOG_DIR}/flink-${FLINK_IDENT_STRING}-${SERVICE}-${id}-${HOSTNAME}\"", "author": "zentol", "createdAt": "2020-04-27T12:09:44Z", "path": "flink-dist/src/main/flink-bin/bin/flink-console.sh", "diffHunk": "@@ -58,7 +58,19 @@ esac\n \n FLINK_TM_CLASSPATH=`constructFlinkClassPath`\n \n-log_setting=(\"-Dlog4j.configuration=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlog4j.configurationFile=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlogback.configurationFile=file:${FLINK_CONF_DIR}/logback-console.xml\")\n+if [ \"$FLINK_IDENT_STRING\" = \"\" ]; then\n+    FLINK_IDENT_STRING=\"$USER\"\n+fi\n+\n+pid=$FLINK_PID_DIR/flink-foreground-$FLINK_IDENT_STRING-$SERVICE.pid\n+id=$(getFlinkDaemonID $pid 0)\n+\n+FLINK_LOG_PREFIX=\"${FLINK_LOG_DIR}/flink-foreground-${FLINK_IDENT_STRING}-${SERVICE}-${id}-${HOSTNAME}\"", "originalCommit": "2c1df7529825b6a0af7e57d29febeade36a758b1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1ODY1MQ==", "url": "https://github.com/apache/flink/pull/11839#discussion_r415758651", "bodyText": "this surely is not a side-effect this method should have", "author": "zentol", "createdAt": "2020-04-27T12:11:28Z", "path": "flink-dist/src/main/flink-bin/bin/config.sh", "diffHunk": "@@ -660,3 +660,39 @@ extractExecutionParams() {\n \n     echo ${execution_config} | sed \"s/$EXECUTION_PREFIX//\"\n }\n+\n+getFlinkDaemonID() {\n+    local pid=$1\n+    local clean_up_when_all_processes_dead=${2:-1}\n+\n+    mkdir -p \"$FLINK_PID_DIR\"\n+\n+    # Log files for daemons are indexed from the process ID's position in the PID\n+    # file. The following lock prevents a race condition during daemon startup\n+    # when multiple daemons read, index, and write to the PID file concurrently.\n+    # The lock is created on the PID directory since a lock file cannot be safely\n+    # removed. The daemon is started with the lock closed and the lock remains\n+    # active in this script until the script exits.\n+    command -v flock >/dev/null 2>&1\n+    if [[ $? -eq 0 ]]; then\n+        exec 200<\"$FLINK_PID_DIR\"\n+        flock 200\n+    fi\n+\n+    # Remove the pid file when all the processes are dead", "originalCommit": "2c1df7529825b6a0af7e57d29febeade36a758b1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTc1OTEzOA==", "url": "https://github.com/apache/flink/pull/11839#discussion_r415759138", "bodyText": "Can we not simplify this?\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                local id=$([ -f \"$pid\" ] && echo $(wc -l < \"$pid\") || echo \"0\")\n          \n          \n            \n                echo $id\n          \n          \n            \n                echo $([ -f \"$pid\" ] && echo $(wc -l < \"$pid\") || echo \"0\")", "author": "zentol", "createdAt": "2020-04-27T12:12:16Z", "path": "flink-dist/src/main/flink-bin/bin/config.sh", "diffHunk": "@@ -660,3 +660,39 @@ extractExecutionParams() {\n \n     echo ${execution_config} | sed \"s/$EXECUTION_PREFIX//\"\n }\n+\n+getFlinkDaemonID() {\n+    local pid=$1\n+    local clean_up_when_all_processes_dead=${2:-1}\n+\n+    mkdir -p \"$FLINK_PID_DIR\"\n+\n+    # Log files for daemons are indexed from the process ID's position in the PID\n+    # file. The following lock prevents a race condition during daemon startup\n+    # when multiple daemons read, index, and write to the PID file concurrently.\n+    # The lock is created on the PID directory since a lock file cannot be safely\n+    # removed. The daemon is started with the lock closed and the lock remains\n+    # active in this script until the script exits.\n+    command -v flock >/dev/null 2>&1\n+    if [[ $? -eq 0 ]]; then\n+        exec 200<\"$FLINK_PID_DIR\"\n+        flock 200\n+    fi\n+\n+    # Remove the pid file when all the processes are dead\n+    if [ -f \"$pid\" ];then\n+        local all_dead=0\n+        while read each_pid; do\n+            kill -0 $each_pid > /dev/null 2>&1\n+            if [[ $? -eq 0 ]] ; then\n+                all_dead=1\n+            fi\n+        done < \"$pid\"\n+        [ $clean_up_when_all_processes_dead -eq 0 -a $all_dead -eq 0 ] && rm $pid\n+    fi\n+\n+    # Ascending ID depending on number of lines in pid file.\n+    # This allows us to start multiple daemon of each type.\n+    local id=$([ -f \"$pid\" ] && echo $(wc -l < \"$pid\") || echo \"0\")\n+    echo $id", "originalCommit": "2c1df7529825b6a0af7e57d29febeade36a758b1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d1a93165bb5e47b2b6b2dd680c404722af7ca039", "url": "https://github.com/apache/flink/commit/d1a93165bb5e47b2b6b2dd680c404722af7ca039", "message": "[FLINK-17166][dist] Modify the log4j-console.properties to also output logs into the files for WebUI", "committedDate": "2020-04-28T05:19:00Z", "type": "forcePushed"}, {"oid": "bcaf191ee0597926ea740092596b34e82592a850", "url": "https://github.com/apache/flink/commit/bcaf191ee0597926ea740092596b34e82592a850", "message": "[FLINK-17166][dist] Modify the flink-console.sh and log configuration to also output logs into the files for WebUI", "committedDate": "2020-05-15T05:52:43Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyMDI2MQ==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425620261", "bodyText": "Why are we re-inventing the wheel and not use the same logic from flink-daemon.sh?\n[ $(wc -l < \"$pid\") -eq 0 ] && rm \"$pid\"\nor\n[ -z $(tail -n 1 \"$pid\") ] && rm \"$pid\"", "author": "zentol", "createdAt": "2020-05-15T07:36:34Z", "path": "flink-dist/src/main/flink-bin/bin/flink-console.sh", "diffHunk": "@@ -58,7 +58,34 @@ esac\n \n FLINK_TM_CLASSPATH=`constructFlinkClassPath`\n \n-log_setting=(\"-Dlog4j.configuration=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlog4j.configurationFile=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlogback.configurationFile=file:${FLINK_CONF_DIR}/logback-console.xml\")\n+if [ \"$FLINK_IDENT_STRING\" = \"\" ]; then\n+    FLINK_IDENT_STRING=\"$USER\"\n+fi\n+\n+pid=$FLINK_PID_DIR/flink-$FLINK_IDENT_STRING-$SERVICE.pid\n+mkdir -p \"$FLINK_PID_DIR\"\n+# The lock needs to be released after use because this script is started foreground\n+command -v flock >/dev/null 2>&1\n+flock_exist=$?\n+if [[ ${flock_exist} -eq 0 ]]; then\n+    exec 200<\"$FLINK_PID_DIR\"\n+    flock 200\n+fi\n+# Remove the pid file when all the processes are dead\n+if [ -f \"$pid\" ];then\n+    all_dead=0", "originalCommit": "bcaf191ee0597926ea740092596b34e82592a850", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYzOTU1MQ==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425639551", "bodyText": "For flink-daemon.sh, it provides the stop and stop-all command so that we could remove the pid file there. However, in flink-console.sh, the script is start with foreground and could be crashed or killed at any time. We may not have chance to remove it. So i put the clean-up logic when starting a new one. Only when all the processes are dead, we could safely delete the pid file.", "author": "wangyang0918", "createdAt": "2020-05-15T08:15:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyMDI2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTcyNzIxOA==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425727218", "bodyText": "Shouldn't this cleanup be done in a trap of some sort? Like on-exit remove the PID of this process from the file, and then maybe delete it if empty?", "author": "zentol", "createdAt": "2020-05-15T11:02:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyMDI2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTc1NDA2Nw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425754067", "bodyText": "It is not easy to be done in a trap because we need to handle all the signals. The scripts also could be killed -9, then it will not have chance to clean-up. So i suggest to do this before start.", "author": "wangyang0918", "createdAt": "2020-05-15T12:01:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyMDI2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyMDc3Nw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425620777", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            flock_exist=$?\n          \n          \n            \n            if [[ ${flock_exist} -eq 0 ]]; then\n          \n          \n            \n            if [[ $? -eq 0 ]]; then\n          \n      \n    \n    \n  \n\nstay consistent with other scripts, so it is more obvious what can be deduplicated later.", "author": "zentol", "createdAt": "2020-05-15T07:37:42Z", "path": "flink-dist/src/main/flink-bin/bin/flink-console.sh", "diffHunk": "@@ -58,7 +58,34 @@ esac\n \n FLINK_TM_CLASSPATH=`constructFlinkClassPath`\n \n-log_setting=(\"-Dlog4j.configuration=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlog4j.configurationFile=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlogback.configurationFile=file:${FLINK_CONF_DIR}/logback-console.xml\")\n+if [ \"$FLINK_IDENT_STRING\" = \"\" ]; then\n+    FLINK_IDENT_STRING=\"$USER\"\n+fi\n+\n+pid=$FLINK_PID_DIR/flink-$FLINK_IDENT_STRING-$SERVICE.pid\n+mkdir -p \"$FLINK_PID_DIR\"\n+# The lock needs to be released after use because this script is started foreground\n+command -v flock >/dev/null 2>&1\n+flock_exist=$?\n+if [[ ${flock_exist} -eq 0 ]]; then", "originalCommit": "bcaf191ee0597926ea740092596b34e82592a850", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTY0MDEwNw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425640107", "bodyText": "The flock_exist will be reused later when to release the lock. So we need a variable to store it.", "author": "wangyang0918", "createdAt": "2020-05-15T08:16:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyMDc3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyNzE3Nw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425627177", "bodyText": "please add a comment for what this does", "author": "zentol", "createdAt": "2020-05-15T07:50:54Z", "path": "flink-dist/src/main/flink-bin/bin/flink-console.sh", "diffHunk": "@@ -70,4 +97,10 @@ if [[ ${JAVA_VERSION} =~ ${IS_NUMBER} ]]; then\n fi\n \n echo \"Starting $SERVICE as a console application on host $HOSTNAME.\"\n+\n+echo $$ >> \"$pid\" 2>/dev/null", "originalCommit": "bcaf191ee0597926ea740092596b34e82592a850", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTY0Njk3Ng==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425646976", "bodyText": "I have added a fixup commit for this comment.", "author": "wangyang0918", "createdAt": "2020-05-15T08:29:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyNzE3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTcyNjc2Mg==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425726762", "bodyText": "so $$ returns the PID of the current process?\n\nand then replace the current program with specified SERVICE in the same process\n\nWith this you mean the exec call? if so, I'd omit it, because it raises more questions than it answers. (most notably due to describing behavior several lines down)", "author": "zentol", "createdAt": "2020-05-15T11:01:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyNzE3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTc1NDQ4Mw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425754483", "bodyText": "Yes, $$ will return the pid of current process. For the exec, i will remove the comments about it.", "author": "wangyang0918", "createdAt": "2020-05-15T12:02:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTYyNzE3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTcyNTU4Mw==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425725583", "bodyText": "add a comment that this checks whether the process is still running", "author": "zentol", "createdAt": "2020-05-15T10:59:00Z", "path": "flink-dist/src/main/flink-bin/bin/flink-console.sh", "diffHunk": "@@ -58,7 +58,34 @@ esac\n \n FLINK_TM_CLASSPATH=`constructFlinkClassPath`\n \n-log_setting=(\"-Dlog4j.configuration=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlog4j.configurationFile=file:${FLINK_CONF_DIR}/log4j-console.properties\" \"-Dlogback.configurationFile=file:${FLINK_CONF_DIR}/logback-console.xml\")\n+if [ \"$FLINK_IDENT_STRING\" = \"\" ]; then\n+    FLINK_IDENT_STRING=\"$USER\"\n+fi\n+\n+pid=$FLINK_PID_DIR/flink-$FLINK_IDENT_STRING-$SERVICE.pid\n+mkdir -p \"$FLINK_PID_DIR\"\n+# The lock needs to be released after use because this script is started foreground\n+command -v flock >/dev/null 2>&1\n+flock_exist=$?\n+if [[ ${flock_exist} -eq 0 ]]; then\n+    exec 200<\"$FLINK_PID_DIR\"\n+    flock 200\n+fi\n+# Remove the pid file when all the processes are dead\n+if [ -f \"$pid\" ];then\n+    all_dead=0\n+    while read each_pid; do\n+        kill -0 $each_pid > /dev/null 2>&1", "originalCommit": "bcaf191ee0597926ea740092596b34e82592a850", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTcyNzc5NA==", "url": "https://github.com/apache/flink/pull/11839#discussion_r425727794", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Release the lock\n          \n          \n            \n            # Release the lock, because the java process runs in the foreground and would block other processes from modifying the pid file", "author": "zentol", "createdAt": "2020-05-15T11:03:50Z", "path": "flink-dist/src/main/flink-bin/bin/flink-console.sh", "diffHunk": "@@ -70,4 +97,10 @@ if [[ ${JAVA_VERSION} =~ ${IS_NUMBER} ]]; then\n fi\n \n echo \"Starting $SERVICE as a console application on host $HOSTNAME.\"\n+\n+echo $$ >> \"$pid\" 2>/dev/null\n+\n+# Release the lock", "originalCommit": "bcaf191ee0597926ea740092596b34e82592a850", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5332adab0695f4ea07eb46d527d7c7e903b7d49c", "url": "https://github.com/apache/flink/commit/5332adab0695f4ea07eb46d527d7c7e903b7d49c", "message": "[FLINK-17166][dist] Modify the flink-console.sh and log configuration to also output logs into the files for WebUI", "committedDate": "2020-05-18T02:23:55Z", "type": "commit"}, {"oid": "78fecb2ae6011cf2f5a0cbe106da98a3a2d8b2b7", "url": "https://github.com/apache/flink/commit/78fecb2ae6011cf2f5a0cbe106da98a3a2d8b2b7", "message": "fixup! Add comments for writing pid", "committedDate": "2020-05-18T02:23:55Z", "type": "commit"}, {"oid": "f8d5b62e81cb5bb3d7fc4488b091e1525f1c85eb", "url": "https://github.com/apache/flink/commit/f8d5b62e81cb5bb3d7fc4488b091e1525f1c85eb", "message": "fixup! address the comments", "committedDate": "2020-05-18T02:23:55Z", "type": "commit"}, {"oid": "de71393ce72505e00313c75d5c43060bb86589f7", "url": "https://github.com/apache/flink/commit/de71393ce72505e00313c75d5c43060bb86589f7", "message": "Update flink-console.sh", "committedDate": "2020-05-18T02:23:55Z", "type": "commit"}, {"oid": "de71393ce72505e00313c75d5c43060bb86589f7", "url": "https://github.com/apache/flink/commit/de71393ce72505e00313c75d5c43060bb86589f7", "message": "Update flink-console.sh", "committedDate": "2020-05-18T02:23:55Z", "type": "forcePushed"}]}