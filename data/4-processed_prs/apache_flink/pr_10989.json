{"pr_number": 10989, "pr_title": "[FLINK-15840][table-planner-blink] ClassCastException is thrown when use tEnv.from for temp/catalog table", "pr_createdAt": "2020-02-01T08:21:14Z", "pr_url": "https://github.com/apache/flink/pull/10989", "timeline": [{"oid": "65c128c991008c1f02ec6cf591a87ebc67cad7f7", "url": "https://github.com/apache/flink/commit/65c128c991008c1f02ec6cf591a87ebc67cad7f7", "message": "[FLINK-15840][table-planner-blink] ClassCastException is thrown when use tEnv.from for temp/catalog table under Blink planner", "committedDate": "2020-02-01T08:18:25Z", "type": "commit"}, {"oid": "9c779b02a840dd3c6ed0968ef3ca2146f7178c6d", "url": "https://github.com/apache/flink/commit/9c779b02a840dd3c6ed0968ef3ca2146f7178c6d", "message": "FIXUP! Solution 1: Obtain ToRexConverterFactory from FlinkContext", "committedDate": "2020-02-02T03:58:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg0MzM5NA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373843394", "bodyText": "\u00a0Would SqlExprToRexConverterFactory be a better name?", "author": "wuchong", "createdAt": "2020-02-02T12:48:32Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/calcite/ToRexConverterFactory.java", "diffHunk": "@@ -18,26 +18,11 @@\n \n package org.apache.flink.table.planner.calcite;\n \n-import org.apache.calcite.plan.RelOptTable;\n import org.apache.calcite.rel.type.RelDataType;\n \n /**\n- * A ToRelContext impl that takes the context variables\n- * used for sql expression transformation.\n+ * Factory to create {@link SqlExprToRexConverter}.\n  */\n-public interface FlinkToRelContext extends RelOptTable.ToRelContext {\n-\n-\t/**\n-\t * Creates a new instance of {@link SqlExprToRexConverter} to convert sql statements\n-\t * to {@link org.apache.calcite.rex.RexNode}.\n-\t *\n-\t * <p>See {@link org.apache.flink.table.planner.plan.schema.FlinkPreparingTableBase#toRel}\n-\t * for details.\n-\t */\n-\tSqlExprToRexConverter createSqlExprToRexConverter(RelDataType tableRowType);\n-\n-\t/**\n-\t * Creates a new instance of {@link FlinkRelBuilder} to build relational expressions.\n-\t */\n-\tFlinkRelBuilder createRelBuilder();\n+public interface ToRexConverterFactory {", "originalCommit": "9c779b02a840dd3c6ed0968ef3ca2146f7178c6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5NTQ4MQ==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373895481", "bodyText": "I thought too long... but is OK.", "author": "JingsongLi", "createdAt": "2020-02-03T01:39:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg0MzM5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg0NjU5NQ==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373846595", "bodyText": "Can we move the prepareWatermarkDDL and prepareComputedColumnDDL to the before stage and give the tables a more readable name, e.g. computed_column_tbl, watermark_tbl? So that the tests doens't need to invoke these methods.", "author": "wuchong", "createdAt": "2020-02-02T13:37:07Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/batch/sql/TableScanTest.scala", "diffHunk": "@@ -68,12 +70,15 @@ class TableScanTest extends TableTestBase {\n          |  'is-bounded' = 'true'\n          |)\n        \"\"\".stripMargin)\n-    util.verifyPlan(\"SELECT * FROM t1\")\n   }\n \n-\n   @Test\n-  def testDDLWithWatermarkComputedColumn(): Unit = {\n+  def testDDLWithComputedColumn(): Unit = {\n+    prepareComputedColumnDDL()\n+    util.verifyPlan(\"SELECT * FROM t1\")\n+  }\n+\n+  private def prepareWatermarkDDL(): Unit = {", "originalCommit": "9c779b02a840dd3c6ed0968ef3ca2146f7178c6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg0NjgxMA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373846810", "bodyText": "Add javadoc to the method.\n  /**\n    * Creates a new instance of {@link SqlExprToRexConverter} to convert SQL expression\n    * to RexNode.\n    */", "author": "wuchong", "createdAt": "2020-02-02T13:40:12Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/calcite/ToRexConverterFactory.java", "diffHunk": "@@ -18,26 +18,11 @@\n \n package org.apache.flink.table.planner.calcite;\n \n-import org.apache.calcite.plan.RelOptTable;\n import org.apache.calcite.rel.type.RelDataType;\n \n /**\n- * A ToRelContext impl that takes the context variables\n- * used for sql expression transformation.\n+ * Factory to create {@link SqlExprToRexConverter}.\n  */\n-public interface FlinkToRelContext extends RelOptTable.ToRelContext {\n-\n-\t/**\n-\t * Creates a new instance of {@link SqlExprToRexConverter} to convert sql statements\n-\t * to {@link org.apache.calcite.rex.RexNode}.\n-\t *\n-\t * <p>See {@link org.apache.flink.table.planner.plan.schema.FlinkPreparingTableBase#toRel}\n-\t * for details.\n-\t */\n-\tSqlExprToRexConverter createSqlExprToRexConverter(RelDataType tableRowType);\n-\n-\t/**\n-\t * Creates a new instance of {@link FlinkRelBuilder} to build relational expressions.\n-\t */\n-\tFlinkRelBuilder createRelBuilder();\n+public interface ToRexConverterFactory {\n+\tSqlExprToRexConverter create(RelDataType tableRowType);", "originalCommit": "9c779b02a840dd3c6ed0968ef3ca2146f7178c6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg0ODMwMA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373848300", "bodyText": "Mutable member field and lazy assignement is not a good practice. I would suggest to make FlinkContextImpl constructor accepts a supplier function to create the SqlExprToRexConverterFactory.\nclass FlinkContextImpl(\n    tableConfig: TableConfig,\n    functionCatalog: FunctionCatalog,\n    catalogManager: CatalogManager,\n    factorySupplier: Supplier[ToRexConverterFactory])\n  extends FlinkContext {\n\n  ...\n\n  override def getToRexConverterFactory: ToRexConverterFactory = factorySupplier.get()\n}\nThen in the PlannerContext, we can instantiate the context early.\n    public PlannerContext(...) {\n       ...\n       this.context = new FlinkContextImpl(\n           tableConfig, \n           functionCatalog, \n           catalogManager, \n           this::createToRexConverterFactory);\n       ...\n    }\n\n    private ToRexConverterFactory createToRexConverterFactory() {\n\t\treturn t -> new SqlExprToRexConverterImpl(createFrameworkConfig(), typeFactory, cluster, t);\n\t}", "author": "wuchong", "createdAt": "2020-02-02T14:00:45Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/delegation/PlannerContext.java", "diffHunk": "@@ -109,6 +109,9 @@ public PlannerContext(\n \t\t\tplanner.addRelTraitDef(traitDef);\n \t\t}\n \t\tthis.cluster = FlinkRelOptClusterFactory.create(planner, new RexBuilder(typeFactory));\n+\n+\t\tthis.context.toRexConverterFactory_$eq(t -> new SqlExprToRexConverterImpl(", "originalCommit": "9c779b02a840dd3c6ed0968ef3ca2146f7178c6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg5ODc5MA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373898790", "bodyText": "It is factory now, we can just remove final of frameworkConfig and cluster.", "author": "JingsongLi", "createdAt": "2020-02-03T02:09:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg0ODMwMA=="}], "type": "inlineReview"}, {"oid": "cad981173bcdee76bb71a4fb8bd7739a94a27db0", "url": "https://github.com/apache/flink/commit/cad981173bcdee76bb71a4fb8bd7739a94a27db0", "message": "Fix comments", "committedDate": "2020-02-03T02:13:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMDI3OA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373900278", "bodyText": "t -> rowType ?", "author": "danny0405", "createdAt": "2020-02-03T02:21:01Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/delegation/PlannerContext.java", "diffHunk": "@@ -95,13 +98,23 @@ public PlannerContext(\n \t\t\tCalciteSchema rootSchema,\n \t\t\tList<RelTraitDef> traitDefs) {\n \t\tthis.tableConfig = tableConfig;\n-\t\tthis.context = new FlinkContextImpl(tableConfig, functionCatalog, catalogManager);\n+\n+\t\tthis.context = new FlinkContextImpl(\n+\t\t\t\ttableConfig,\n+\t\t\t\tfunctionCatalog,\n+\t\t\t\tcatalogManager,\n+\t\t\t\tt -> new SqlExprToRexConverterImpl(\n+\t\t\t\t\t\tcheckNotNull(frameworkConfig),", "originalCommit": "cad981173bcdee76bb71a4fb8bd7739a94a27db0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMDM1OA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373900358", "bodyText": "FlinkContextImpl -> FlinkContext ?", "author": "danny0405", "createdAt": "2020-02-03T02:21:29Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/delegation/PlannerContext.java", "diffHunk": "@@ -80,13 +81,15 @@\n  */\n @Internal\n public class PlannerContext {\n+\n \tprivate final RelDataTypeSystem typeSystem = new FlinkTypeSystem();\n \tprivate final FlinkTypeFactory typeFactory = new FlinkTypeFactory(typeSystem);\n \tprivate final TableConfig tableConfig;\n-\tprivate final RelOptCluster cluster;\n-\tprivate final FlinkContext context;\n+\tprivate final FlinkContextImpl context;\n \tprivate final CalciteSchema rootSchema;", "originalCommit": "cad981173bcdee76bb71a4fb8bd7739a94a27db0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "eb337d645d4278e7da22776f5b7aeef5e43af38c", "url": "https://github.com/apache/flink/commit/eb337d645d4278e7da22776f5b7aeef5e43af38c", "message": "Fix comments", "committedDate": "2020-02-03T02:28:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373902720", "bodyText": "Can these member fields to be final?", "author": "wuchong", "createdAt": "2020-02-03T02:38:37Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/delegation/PlannerContext.java", "diffHunk": "@@ -80,13 +82,15 @@\n  */\n @Internal\n public class PlannerContext {\n+\n \tprivate final RelDataTypeSystem typeSystem = new FlinkTypeSystem();\n \tprivate final FlinkTypeFactory typeFactory = new FlinkTypeFactory(typeSystem);\n \tprivate final TableConfig tableConfig;\n-\tprivate final RelOptCluster cluster;\n \tprivate final FlinkContext context;\n \tprivate final CalciteSchema rootSchema;\n \tprivate final List<RelTraitDef> traitDefs;\n+\tprivate FrameworkConfig frameworkConfig;\n+\tprivate RelOptCluster cluster;", "originalCommit": "eb337d645d4278e7da22776f5b7aeef5e43af38c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMzM4OA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373903388", "bodyText": "There is a factory refer these fields before their initialization. According to the semantics of Java, it needs to be non final.", "author": "JingsongLi", "createdAt": "2020-02-03T02:43:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkxMzY1Mg==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373913652", "bodyText": "We can have a private SqlExprToRexConverter createSqlExprToRexConverter(RelDataType rowType) method and pass this::createSqlExprToRexConverter to the FlinkContextImpl, then these fields can be final.", "author": "wuchong", "createdAt": "2020-02-03T03:57:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkxNDU4NQ==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373914585", "bodyText": "I am not favor of it.\nPass this::createSqlExprToRexConverter to the FlinkContextImpl means we pass an unfinished instance to it. Actually frameworkConfig and cluster is not the real final to FlinkContextImpl, they will become real instance from null.\nSo this feel like bypassing the final rule of Java.", "author": "JingsongLi", "createdAt": "2020-02-03T04:03:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkxNzEwNA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373917104", "bodyText": "The code is a little messy, FrameworkConfig reference the cluster, while the cluster context have a member that needs a FrameworkConfig and the cluster itself ...\nWe may need to re-think if the SqlExprToRexConverter should belong to the cluster context, can we just pass in the FrameworkConfig into the context and constructing the SqlExprToRexConverter when we really need that (i.e. the CatalogSourceTable)?", "author": "danny0405", "createdAt": "2020-02-03T04:22:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkxOTQ4Mg==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373919482", "bodyText": "Hi @danny0405 , The constructor of FrameworkConfig need cluster context.\nContext need a factory which need FrameworkConfig. IMO, relationship like this is very common. That's one of the reasons we need the factory model.\nI admit we can improve it, but if it's a big refactoring, it's unnecessary, because this PR is just an urgent bug fixing.\nOf course, if you have a better and slight improvement plan, you can describe it detailed.\nWhat do you think?", "author": "JingsongLi", "createdAt": "2020-02-03T04:36:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkzODEzNQ==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373938135", "bodyText": "After some research of the code, i found another solution, that is:\n\nModify the FlinkRelBuilder to add a new method scan(Iterable<String> tableNames, ViewExpander viewExpander), then in the method, fetch the RelOptTable first and then do the logic same with TableScanRule\nIn the QueryOperationConverter, use the new scan method to translate the table\nNo other code change is needed\n\nWe do not need to pass the SqlToExprConverter around through the FlinkContext because the it does not belong there, the computed column/watermark translation should happen as early as possible and not in planner rules.", "author": "danny0405", "createdAt": "2020-02-03T06:27:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk0NzI5Ng==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373947296", "bodyText": "Hi @wuchong , Made PlannerContext fields final.", "author": "JingsongLi", "createdAt": "2020-02-03T07:08:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzk0NzUxNQ==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373947515", "bodyText": "After discussing with @danny0405  offline, We can improve this to finish solution#3 in 1.11.", "author": "JingsongLi", "createdAt": "2020-02-03T07:09:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwMjcyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwNjI2OA==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373906268", "bodyText": "Maybe we can inline this code with line 92 ~ 94", "author": "danny0405", "createdAt": "2020-02-03T03:02:09Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/optimize/BatchCommonSubGraphBasedOptimizer.scala", "diffHunk": "@@ -80,12 +81,17 @@ class BatchCommonSubGraphBasedOptimizer(planner: BatchPlanner)\n       .getOrElse(FlinkBatchProgram.buildProgram(config.getConfiguration))\n     Preconditions.checkNotNull(programs)\n \n+    val context = relNode.getCluster.getPlanner.getContext.unwrap(classOf[FlinkContext])\n+", "originalCommit": "eb337d645d4278e7da22776f5b7aeef5e43af38c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwNzI5MQ==", "url": "https://github.com/apache/flink/pull/10989#discussion_r373907291", "bodyText": "Not inline because:\nI think it is better to get all fields from this context instead of getting from planner.\nBatchOptimizeContext should extends previous context.\nNot do it because 1.10.", "author": "JingsongLi", "createdAt": "2020-02-03T03:08:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkwNjI2OA=="}], "type": "inlineReview"}, {"oid": "620d9437f57c76595417f4381fad09ee7859f7f5", "url": "https://github.com/apache/flink/commit/620d9437f57c76595417f4381fad09ee7859f7f5", "message": "Make PlannerContext fields final", "committedDate": "2020-02-03T07:07:18Z", "type": "commit"}]}