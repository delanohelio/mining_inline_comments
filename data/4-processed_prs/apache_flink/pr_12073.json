{"pr_number": 12073, "pr_title": " [FLINK-17735][streaming] Add specialized collecting iterator", "pr_createdAt": "2020-05-11T07:20:41Z", "pr_url": "https://github.com/apache/flink/pull/12073", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwODEzMg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426208132", "bodyText": "rename to jobTerminated", "author": "KurtYoung", "createdAt": "2020-05-17T01:56:47Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTEzNg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209136", "bodyText": "doesn't see any tests relying on this method", "author": "KurtYoung", "createdAt": "2020-05-17T02:16:24Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTIxMw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209213", "bodyText": "init closed variable", "author": "KurtYoung", "createdAt": "2020-05-17T02:17:52Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTIzMw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209233", "bodyText": "add @Nullable", "author": "KurtYoung", "createdAt": "2020-05-17T02:18:19Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTI2Mw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209263", "bodyText": "use another field to save CoordinationRequestGateway, can save some casting in the future", "author": "KurtYoung", "createdAt": "2020-05-17T02:19:18Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIwOTM0MA==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426209340", "bodyText": "how about userVisibleHead", "author": "KurtYoung", "createdAt": "2020-05-17T02:20:24Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDMxMQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210311", "bodyText": "I don't think we should eat this exception, we should throw this out to show something is going wrong", "author": "KurtYoung", "createdAt": "2020-05-17T02:38:25Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;\n+\t\tprivate long userTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\t\t\tthis.lastCheckpointedOffset = 0;\n+\t\t\tthis.userHead = 0;\n+\t\t\tthis.userTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userHead == userTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMTY5Mg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426221692", "bodyText": "I would prefer to throw it out", "author": "KurtYoung", "createdAt": "2020-05-17T06:09:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDMxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDUxOQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210519", "bodyText": "when will responseLastCheckpointedOffset < lastCheckpointedOffset(I can understand when they are equal), and what would you do with this situation?", "author": "KurtYoung", "createdAt": "2020-05-17T02:42:16Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;\n+\t\tprivate long userTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\t\t\tthis.lastCheckpointedOffset = 0;\n+\t\t\tthis.userHead = 0;\n+\t\t\tthis.userTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userHead == userTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tLOG.warn(\"An exception occurs when deserializing query results. Some results might be lost.\", e);\n+\t\t\t\tresults = Collections.emptyList();\n+\t\t\t}\n+\n+\t\t\tif (responseLastCheckpointedOffset > lastCheckpointedOffset) {", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxNjg4OA==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426216888", "bodyText": "It is impossible for responseLastCheckpointedOffset to be smaller than lastCheckpointedOffset, offsets are always non-decreasing.", "author": "tsreaper", "createdAt": "2020-05-17T04:46:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDUxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIxMDYzMQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426210631", "bodyText": "We need some document about these variables and ResultBuffer, I'm quite confused now even if I know the algorithm...", "author": "KurtYoung", "createdAt": "2020-05-17T02:44:32Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,343 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\tprivate JobClient jobClient;\n+\tprivate boolean terminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\t@VisibleForTesting\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.terminated = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (terminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tterminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (terminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\t\tCoordinationRequestGateway gateway = (CoordinationRequestGateway) jobClient;\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\tprivate String version;\n+\t\tprivate long offset;\n+\t\tprivate long lastCheckpointedOffset;\n+\t\tprivate long userHead;", "originalCommit": "ca26d6edd7772ee46d24b05c01952a10887eb3f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "01b3b026dc70c49c81b727cadb53b339bab5fbaf", "url": "https://github.com/apache/flink/commit/01b3b026dc70c49c81b727cadb53b339bab5fbaf", "message": "[FLINK-14807][table] Add specialized collecting iterator to Blink planner", "committedDate": "2020-05-17T05:02:55Z", "type": "commit"}, {"oid": "9874962514e28a3e6ee9e796244cf2a04a84bfbf", "url": "https://github.com/apache/flink/commit/9874962514e28a3e6ee9e796244cf2a04a84bfbf", "message": "[fix] Simplify implementation of collect iterator into a memory-based one and refactor test to use this iterator", "committedDate": "2020-05-17T05:02:55Z", "type": "commit"}, {"oid": "2880b1268705e2e671f17208cc723da6f4ab32bf", "url": "https://github.com/apache/flink/commit/2880b1268705e2e671f17208cc723da6f4ab32bf", "message": "[fix] Fix checkstyle and connection issue in collect sink and coordinator", "committedDate": "2020-05-17T05:02:55Z", "type": "commit"}, {"oid": "e7e982893093d13dd679bc0504d892fdc0fb6b63", "url": "https://github.com/apache/flink/commit/e7e982893093d13dd679bc0504d892fdc0fb6b63", "message": "[fix] Add socket timeout to coordinator", "committedDate": "2020-05-17T05:04:07Z", "type": "commit"}, {"oid": "176a38394a1c0e69167dc151f66959ac84258db5", "url": "https://github.com/apache/flink/commit/176a38394a1c0e69167dc151f66959ac84258db5", "message": "[fix] Change statement order in collect result fetcher for easier understanding", "committedDate": "2020-05-17T05:04:07Z", "type": "commit"}, {"oid": "579236dbe523ccc71e62f4f9becdf0937d3b1bf4", "url": "https://github.com/apache/flink/commit/579236dbe523ccc71e62f4f9becdf0937d3b1bf4", "message": "[fix] Fix kurt's comments", "committedDate": "2020-05-17T05:04:07Z", "type": "commit"}, {"oid": "4ad199a9f0a8db9ce82493af6e180af602774e29", "url": "https://github.com/apache/flink/commit/4ad199a9f0a8db9ce82493af6e180af602774e29", "message": "[fix] Fix checkstyle", "committedDate": "2020-05-17T05:30:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzUxMQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223511", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\tCollectCoordinationResponse<T> response;\n          \n          \n            \n            \t\t\t\ttry {\n          \n          \n            \n            \t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n          \n          \n            \n            \t\t\t\t} catch (Exception e) {\n          \n          \n            \n            \t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n          \n          \n            \n            \t\t\t\t\tsleepBeforeRetry();\n          \n          \n            \n            \t\t\t\t\tcontinue;\n          \n          \n            \n            \t\t\t\t}\n          \n          \n            \n            \t\t\t\tbuffer.dealWithResponse(response);\n          \n          \n            \n            \t\t\t\tlong requestOffset = buffer.offset;\n          \n          \n            \n            \t\t\t\tCollectCoordinationResponse<T> response;\n          \n          \n            \n            \t\t\t\ttry {\n          \n          \n            \n            \t\t\t\t\tresponse = sendRequest(buffer.version, requestOffset);\n          \n          \n            \n            \t\t\t\t} catch (Exception e) {\n          \n          \n            \n            \t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n          \n          \n            \n            \t\t\t\t\tsleepBeforeRetry();\n          \n          \n            \n            \t\t\t\t\tcontinue;\n          \n          \n            \n            \t\t\t\t}\n          \n          \n            \n            \t\t\t\t// the response will contain data (if any) starting exactly from requested offset\n          \n          \n            \n            \t\t\t\tbuffer.dealWithResponse(response, requestOffset);", "author": "KurtYoung", "createdAt": "2020-05-17T06:32:41Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzYwNQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223605", "bodyText": "delete this method", "author": "KurtYoung", "createdAt": "2020-05-17T06:33:30Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzc0MQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426223741", "bodyText": "add a sanity check that responseLastCheckpointedOffset is less than offset.\nand also checks that this buffer still contains data starting from responseLastCheckpointedOffset", "author": "KurtYoung", "createdAt": "2020-05-17T06:35:13Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t}\n+\n+\t\t\t// we first check version in the response to decide whether we should throw away dirty results\n+\t\t\tif (!version.equals(responseVersion)) {\n+\t\t\t\t// sink restarted, we revert back to where the sink tells us\n+\t\t\t\tfor (long i = 0; i < offset - responseLastCheckpointedOffset; i++) {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyOTU5Nw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426229597", "bodyText": "\"less than offset\" should be \"less than or equal to offset\", because sink may have restarted before client fetches more results.", "author": "tsreaper", "createdAt": "2020-05-17T07:46:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyMzc0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDE0Mg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426224142", "bodyText": "what about if responseOffset + results.size() still less than offset, which means you get a fully duplicated data?", "author": "KurtYoung", "createdAt": "2020-05-17T06:40:19Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");\n+\t}\n+\n+\t/**\n+\t * A buffer which encapsulates the logic of dealing with the response from the {@link CollectSinkFunction}.\n+\t * See Java doc of {@link CollectSinkFunction} for explanation of this communication protocol.\n+\t */\n+\tprivate class ResultBuffer {\n+\n+\t\tprivate static final String INIT_VERSION = \"\";\n+\n+\t\tprivate final LinkedList<T> buffer;\n+\t\tprivate final TypeSerializer<T> serializer;\n+\n+\t\t// for detailed explanation of the following 3 variables, see Java doc of CollectSinkFunction\n+\t\t// `version` is to check if the sink restarts\n+\t\tprivate String version;\n+\t\t// `offset` is the offset of the next result we want to fetch\n+\t\tprivate long offset;\n+\n+\t\t// userVisibleHead <= user visible results offset < userVisibleTail\n+\t\tprivate long userVisibleHead;\n+\t\tprivate long userVisibleTail;\n+\n+\t\tprivate ResultBuffer(TypeSerializer<T> serializer) {\n+\t\t\tthis.buffer = new LinkedList<>();\n+\t\t\tthis.serializer = serializer;\n+\n+\t\t\tthis.version = INIT_VERSION;\n+\t\t\tthis.offset = 0;\n+\n+\t\t\tthis.userVisibleHead = 0;\n+\t\t\tthis.userVisibleTail = 0;\n+\t\t}\n+\n+\t\tprivate T next() {\n+\t\t\tif (userVisibleHead == userVisibleTail) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tT ret = buffer.removeFirst();\n+\t\t\tuserVisibleHead++;\n+\n+\t\t\tsanityCheck();\n+\t\t\treturn ret;\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response) {\n+\t\t\tdealWithResponse(response, offset);\n+\t\t}\n+\n+\t\tprivate void dealWithResponse(CollectCoordinationResponse<T> response, long responseOffset) {\n+\t\t\tString responseVersion = response.getVersion();\n+\t\t\tlong responseLastCheckpointedOffset = response.getLastCheckpointedOffset();\n+\t\t\tList<T> results;\n+\t\t\ttry {\n+\t\t\t\tresults = response.getResults(serializer);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new RuntimeException(e);\n+\t\t\t}\n+\n+\t\t\t// we first check version in the response to decide whether we should throw away dirty results\n+\t\t\tif (!version.equals(responseVersion)) {\n+\t\t\t\t// sink restarted, we revert back to where the sink tells us\n+\t\t\t\tfor (long i = 0; i < offset - responseLastCheckpointedOffset; i++) {\n+\t\t\t\t\tbuffer.removeLast();\n+\t\t\t\t}\n+\t\t\t\tversion = responseVersion;\n+\t\t\t\toffset = responseLastCheckpointedOffset;\n+\t\t\t}\n+\n+\t\t\t// we now check if more results can be seen by the user\n+\t\t\tif (responseLastCheckpointedOffset > userVisibleTail) {\n+\t\t\t\t// lastCheckpointedOffset increases, this means that more results have been\n+\t\t\t\t// checkpointed, and we can give these results to the user\n+\t\t\t\tuserVisibleTail = responseLastCheckpointedOffset;\n+\t\t\t}\n+\n+\t\t\tif (!results.isEmpty()) {\n+\t\t\t\t// response contains some data, add them to buffer\n+\t\t\t\tint addStart = (int) (offset - responseOffset);\n+\t\t\t\tList<T> addedResults = results.subList(addStart, results.size());", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNzcxMg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426227712", "bodyText": "This is impossible. Because if this happens then the sink must have restarted, and we must have gone back to the last checkpointed offset. But I'll add a sanity check here.", "author": "tsreaper", "createdAt": "2020-05-17T07:24:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDE0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNDYxNw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426224617", "bodyText": "also check the gateway", "author": "KurtYoung", "createdAt": "2020-05-17T06:46:29Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tif (!isJobTerminated()) {\n+\t\t\tjobClient.cancel();\n+\t\t}\n+\t}\n+\n+\tprivate void sleepBeforeRetry() {\n+\t\tif (retryMillis <= 0) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\t// TODO a more proper retry strategy?\n+\t\t\tThread.sleep(retryMillis);\n+\t\t} catch (InterruptedException e) {\n+\t\t\tLOG.warn(\"Interrupted when sleeping before a retry\", e);\n+\t\t}\n+\t}\n+\n+\tprivate void checkJobClientConfigured() {\n+\t\tPreconditions.checkNotNull(jobClient, \"Job client must be configured before first use.\");", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTAwOQ==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225009", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n          \n          \n            \n            \tprivate Tuple2<Long, CollectCoordinationResponse<T>> getAccumulatorResults() {", "author": "KurtYoung", "createdAt": "2020-05-17T06:51:33Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTY4NA==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225684", "bodyText": "throw IOException istead", "author": "KurtYoung", "createdAt": "2020-05-17T07:00:11Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNTgwMA==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426225800", "bodyText": "should let user know this is a abnormal case, throw an exception?", "author": "KurtYoung", "createdAt": "2020-05-17T07:01:19Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNjIxMw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426226213", "bodyText": "Before we throw any exception, we should also try to cancel the job", "author": "KurtYoung", "createdAt": "2020-05-17T07:06:45Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {\n+\t\t\t\t// still no results, but job is still running, retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tpublic void close() {\n+\t\tif (closed) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\tcancelJob();\n+\t\tclosed = true;\n+\t}\n+\n+\t@Override\n+\tprotected void finalize() throws Throwable {\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\tclose();\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tprivate CollectCoordinationResponse<T> sendRequest(\n+\t\t\tString version,\n+\t\t\tlong offset) throws InterruptedException, ExecutionException {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tOperatorID operatorId = operatorIdFuture.getNow(null);\n+\t\tPreconditions.checkNotNull(operatorId, \"Unknown operator ID. This is a bug.\");\n+\n+\t\tCollectCoordinationRequest request = new CollectCoordinationRequest(version, offset);\n+\t\treturn (CollectCoordinationResponse) gateway.sendCoordinationRequest(operatorId, request).get();\n+\t}\n+\n+\t@Nullable\n+\tprivate Tuple2<Long, CollectCoordinationResponse> getAccumulatorResults() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\tJobExecutionResult executionResult;\n+\t\ttry {\n+\t\t\t// this timeout is sort of hack, see comments in isJobTerminated for explanation\n+\t\t\texecutionResult = jobClient.getJobExecutionResult(getClass().getClassLoader()).get(\n+\t\t\t\tDEFAULT_ACCUMULATOR_GET_MILLIS, TimeUnit.MILLISECONDS);\n+\t\t} catch (InterruptedException | ExecutionException | TimeoutException e) {\n+\t\t\tthrow new RuntimeException(\"Failed to fetch job execution result\", e);\n+\t\t}\n+\n+\t\tArrayList<byte[]> accResults = executionResult.getAccumulatorResult(accumulatorName);\n+\t\tif (accResults == null) {\n+\t\t\t// job terminates abnormally\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\ttry {\n+\t\t\tList<byte[]> serializedResults =\n+\t\t\t\tSerializedListAccumulator.deserializeList(accResults, BytePrimitiveArraySerializer.INSTANCE);\n+\t\t\tbyte[] serializedResult = serializedResults.get(0);\n+\t\t\treturn CollectSinkFunction.deserializeAccumulatorResult(serializedResult);\n+\t\t} catch (ClassNotFoundException | IOException e) {\n+\t\t\t// this is impossible\n+\t\t\tthrow new RuntimeException(\"Failed to deserialize accumulator results\", e);\n+\t\t}\n+\t}\n+\n+\tprivate boolean isJobTerminated() {\n+\t\tcheckJobClientConfigured();\n+\n+\t\ttry {\n+\t\t\tJobStatus status = jobClient.getJobStatus().get();\n+\t\t\treturn status.isGloballyTerminalState();\n+\t\t} catch (Exception e) {\n+\t\t\t// TODO\n+\t\t\t//  This is sort of hack.\n+\t\t\t//  Currently different execution environment will have different behaviors\n+\t\t\t//  when fetching a finished job status.\n+\t\t\t//  For example, standalone session cluster will return a normal FINISHED,\n+\t\t\t//  while mini cluster will throw IllegalStateException,\n+\t\t\t//  and yarn per job will throw ApplicationNotFoundException.\n+\t\t\t//  We have to assume that job has finished in this case.\n+\t\t\t//  Change this when these behaviors are unified.\n+\t\t\tLOG.warn(\"Failed to get job status so we assume that the job has terminated. Some data might be lost.\", e);\n+\t\t\treturn true;\n+\t\t}\n+\t}\n+\n+\tprivate void cancelJob() {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjIyNjY4Ng==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426226686", "bodyText": "change this to do {} while, maybe we can reuse these statements with line 110 - line 117?", "author": "KurtYoung", "createdAt": "2020-05-17T07:12:41Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,359 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\tT res = buffer.next();\n+\t\tif (res != null) {\n+\t\t\t// we still have user-visible results, just use them\n+\t\t\treturn res;\n+\t\t} else if (jobTerminated) {\n+\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// we're going to fetch some more\n+\t\twhile (true) {\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\tTuple2<Long, CollectCoordinationResponse> accResults = getAccumulatorResults();\n+\t\t\t\tif (accResults != null) {\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, buffer.offset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tsleepBeforeRetry();\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\tbuffer.dealWithResponse(response);\n+\t\t\t}\n+\n+\t\t\t// try to return results after fetching\n+\t\t\tres = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// ok, we have results this time\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// still no results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else {", "originalCommit": "4ad199a9f0a8db9ce82493af6e180af602774e29", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "cc45779cd014b587a2fbed2393683ff4fe73a38b", "url": "https://github.com/apache/flink/commit/cc45779cd014b587a2fbed2393683ff4fe73a38b", "message": "[fix] Fix kurt's comments", "committedDate": "2020-05-17T08:21:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI0ODA4Mg==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426248082", "bodyText": "how about throw IOException instead?", "author": "KurtYoung", "createdAt": "2020-05-17T11:08:21Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,358 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\t// this is only an insurance,\n+\t\t// it's the user's responsibility to close the iterator if he does not need it anymore\n+\t\tRuntime.getRuntime().addShutdownHook(new Thread(this::close));\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// this is to avoid sleeping before first try\n+\t\tboolean beforeFirstTry = true;\n+\t\tdo {\n+\t\t\tT res = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// we still have user-visible results, just use them\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else if (!beforeFirstTry) {\n+\t\t\t\t// no results but job is still running, sleep before retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t\tbeforeFirstTry = false;\n+\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\ttry {\n+\t\t\t\t\tTuple2<Long, CollectCoordinationResponse<T>> accResults = getAccumulatorResults();\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(", "originalCommit": "cc45779cd014b587a2fbed2393683ff4fe73a38b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjI0ODE2Nw==", "url": "https://github.com/apache/flink/pull/12073#discussion_r426248167", "bodyText": "ditto", "author": "KurtYoung", "createdAt": "2020-05-17T11:09:23Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectResultFetcher.java", "diffHunk": "@@ -0,0 +1,358 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.api.common.JobExecutionResult;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.api.common.accumulators.SerializedListAccumulator;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.core.execution.JobClient;\n+import org.apache.flink.runtime.jobgraph.OperatorID;\n+import org.apache.flink.runtime.operators.coordination.CoordinationRequestGateway;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * A fetcher which fetches query results from sink and provides exactly-once semantics.\n+ */\n+public class CollectResultFetcher<T> {\n+\n+\tprivate static final int DEFAULT_RETRY_MILLIS = 100;\n+\tprivate static final long DEFAULT_ACCUMULATOR_GET_MILLIS = 10000;\n+\n+\tprivate static final Logger LOG = LoggerFactory.getLogger(CollectResultFetcher.class);\n+\n+\tprivate final CompletableFuture<OperatorID> operatorIdFuture;\n+\tprivate final String accumulatorName;\n+\tprivate final int retryMillis;\n+\n+\tprivate ResultBuffer buffer;\n+\n+\t@Nullable\n+\tprivate JobClient jobClient;\n+\t@Nullable\n+\tprivate CoordinationRequestGateway gateway;\n+\n+\tprivate boolean jobTerminated;\n+\tprivate boolean closed;\n+\n+\tpublic CollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName) {\n+\t\tthis(\n+\t\t\toperatorIdFuture,\n+\t\t\tserializer,\n+\t\t\taccumulatorName,\n+\t\t\tDEFAULT_RETRY_MILLIS);\n+\t}\n+\n+\tCollectResultFetcher(\n+\t\t\tCompletableFuture<OperatorID> operatorIdFuture,\n+\t\t\tTypeSerializer<T> serializer,\n+\t\t\tString accumulatorName,\n+\t\t\tint retryMillis) {\n+\t\tthis.operatorIdFuture = operatorIdFuture;\n+\t\tthis.accumulatorName = accumulatorName;\n+\t\tthis.retryMillis = retryMillis;\n+\n+\t\tthis.buffer = new ResultBuffer(serializer);\n+\n+\t\tthis.jobTerminated = false;\n+\t\tthis.closed = false;\n+\n+\t\t// in case that user neither reads all data nor closes the iterator\n+\t\t// this is only an insurance,\n+\t\t// it's the user's responsibility to close the iterator if he does not need it anymore\n+\t\tRuntime.getRuntime().addShutdownHook(new Thread(this::close));\n+\t}\n+\n+\tpublic void setJobClient(JobClient jobClient) {\n+\t\tPreconditions.checkArgument(\n+\t\t\tjobClient instanceof CoordinationRequestGateway,\n+\t\t\t\"Job client must be a CoordinationRequestGateway. This is a bug.\");\n+\t\tthis.jobClient = jobClient;\n+\t\tthis.gateway = (CoordinationRequestGateway) jobClient;\n+\t}\n+\n+\tpublic T next() {\n+\t\tif (closed) {\n+\t\t\treturn null;\n+\t\t}\n+\n+\t\t// this is to avoid sleeping before first try\n+\t\tboolean beforeFirstTry = true;\n+\t\tdo {\n+\t\t\tT res = buffer.next();\n+\t\t\tif (res != null) {\n+\t\t\t\t// we still have user-visible results, just use them\n+\t\t\t\treturn res;\n+\t\t\t} else if (jobTerminated) {\n+\t\t\t\t// no user-visible results, but job has terminated, we have to return\n+\t\t\t\treturn null;\n+\t\t\t} else if (!beforeFirstTry) {\n+\t\t\t\t// no results but job is still running, sleep before retry\n+\t\t\t\tsleepBeforeRetry();\n+\t\t\t}\n+\t\t\tbeforeFirstTry = false;\n+\n+\t\t\tif (isJobTerminated()) {\n+\t\t\t\t// job terminated, read results from accumulator\n+\t\t\t\tjobTerminated = true;\n+\t\t\t\ttry {\n+\t\t\t\t\tTuple2<Long, CollectCoordinationResponse<T>> accResults = getAccumulatorResults();\n+\t\t\t\t\tbuffer.dealWithResponse(accResults.f1, accResults.f0);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(\n+\t\t\t\t\t\t\"Failed to deal with final accumulator results, final batch of results are lost\", e);\n+\t\t\t\t}\n+\t\t\t\tbuffer.complete();\n+\t\t\t} else {\n+\t\t\t\t// job still running, try to fetch some results\n+\t\t\t\tlong requestOffset = buffer.offset;\n+\t\t\t\tCollectCoordinationResponse<T> response;\n+\t\t\t\ttry {\n+\t\t\t\t\tresponse = sendRequest(buffer.version, requestOffset);\n+\t\t\t\t} catch (Exception e) {\n+\t\t\t\t\tLOG.warn(\"An exception occurs when fetching query results\", e);\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t\t// the response will contain data (if any) starting exactly from requested offset\n+\t\t\t\ttry {\n+\t\t\t\t\tbuffer.dealWithResponse(response, requestOffset);\n+\t\t\t\t} catch (IOException e) {\n+\t\t\t\t\tclose();\n+\t\t\t\t\tthrow new RuntimeException(\"Failed to deal with response from sink\", e);", "originalCommit": "cc45779cd014b587a2fbed2393683ff4fe73a38b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "db16ab869545c73c16e0a3bec6c4482cb3331619", "url": "https://github.com/apache/flink/commit/db16ab869545c73c16e0a3bec6c4482cb3331619", "message": "[fix] Fix kurt's comments", "committedDate": "2020-05-17T11:38:17Z", "type": "commit"}, {"oid": "41d3524e0ba410d80f17f86206191b146d34e460", "url": "https://github.com/apache/flink/commit/41d3524e0ba410d80f17f86206191b146d34e460", "message": "[fix] Remove close insurance as they might throw unwanted exceptions when stopping JVM", "committedDate": "2020-05-17T12:25:23Z", "type": "commit"}]}