{"pr_number": 12138, "pr_title": "[FLINK-16611] [datadog-metrics] Make number of metrics per request configurable", "pr_createdAt": "2020-05-14T00:07:11Z", "pr_url": "https://github.com/apache/flink/pull/12138", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDk1NzYyNg==", "url": "https://github.com/apache/flink/pull/12138#discussion_r424957626", "bodyText": "hmm, I don't really like that we're always sending at least 2 requests, as long as at least one counter and gauge exist.\nUltimately, all we need to do is slice the currently created DSeries, which we could do using ArrayList#subList.\nint fromIndex = 0;\nArrayList<DMetric> series = request.getSeries();\nwhile (fromIndex < series.size()) {\n  int toIndex = Math.Min(currentCount + maxMetricsPerRequestValue, series.size());\n  client.send(series.subList(fromIndex, toIndex));\n  fromIndex = toIndex;\n}\n\nWDYT? We could even wrap this logic into a stateful Consumer that resets the DSeries on each client.send, so we don't have to assemble the full list.", "author": "zentol", "createdAt": "2020-05-14T08:25:12Z", "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "diffHunk": "@@ -157,6 +181,11 @@ private void addGaugesAndUnregisterOnException(DSeries request) {\n \t\t\t\t// Flink uses Gauge to store many types other than Number\n \t\t\t\tg.getMetricValue();\n \t\t\t\trequest.addGauge(g);\n+\t\t\t\t++currentCount;\n+\t\t\t\tif (currentCount % maxMetricsPerRequestValue == 0 || currentCount >= totalGauges) {\n+\t\t\t\t\tclient.send(request);", "originalCommit": "a6af75021894504c6515472be86f1e490ae32e27", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjAxOTQ0Mg==", "url": "https://github.com/apache/flink/pull/12138#discussion_r426019442", "bodyText": "I do like the sublist approach although DatadogHttpClient serializes a DSeries not a List.\nmaybe something like:\nList<DMetric> metrics = new ArrayList();\naddGaugesAndUnregisterOnException(metrics);\nmetrics.addAll(counters.values());\nmetrics.addAll(meters.values());\n\nint fromIndex = 0;\nwhile (fromIndex < metrics.size()) {\n    int toIndex = Math.Min(fromIndex + maxMetricsPerRequestValue, metrics.size());\n    client.send(new DSeries(metrics.subList(fromIndex, toIndex)));\n    fromIndex = toIndex;\n}", "author": "swhelan091", "createdAt": "2020-05-15T20:00:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDk1NzYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM5NDU4MQ==", "url": "https://github.com/apache/flink/pull/12138#discussion_r426394581", "bodyText": "yes, you'D of course have to rap the subList in a DSeries again, requiring a new constructor.", "author": "zentol", "createdAt": "2020-05-18T06:29:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDk1NzYyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxMzA1NQ==", "url": "https://github.com/apache/flink/pull/12138#discussion_r427013055", "bodyText": "One question here. Should ackReport only be called on counters that were successfully emitted to Datadog?", "author": "swhelan091", "createdAt": "2020-05-19T03:43:35Z", "path": "flink-metrics/flink-metrics-datadog/src/main/java/org/apache/flink/metrics/datadog/DatadogHttpReporter.java", "diffHunk": "@@ -137,15 +140,21 @@ public void report() {\n \t\tcounters.values().forEach(request::addCounter);\n \t\tmeters.values().forEach(request::addMeter);\n \n-\t\ttry {\n-\t\t\tclient.send(request);\n-\t\t\tcounters.values().forEach(DCounter::ackReport);\n-\t\t\tLOGGER.debug(\"Reported series with size {}.\", request.getSeries().size());\n-\t\t} catch (SocketTimeoutException e) {\n-\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog because of socket timeout: {}\", e.getMessage());\n-\t\t} catch (Exception e) {\n-\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog.\", e);\n+\t\tint totalMetrics = request.getSeries().size();\n+\t\tint fromIndex = 0;\n+\t\twhile (fromIndex < totalMetrics) {\n+\t\t\tint toIndex = Math.min(fromIndex + maxMetricsPerRequestValue, totalMetrics);\n+\t\t\ttry {\n+\t\t\t\tclient.send(new DSeries(request.getSeries().subList(fromIndex, toIndex)));\n+\t\t\t} catch (SocketTimeoutException e) {\n+\t\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog because of socket timeout: {}\", e.getMessage());\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tLOGGER.warn(\"Failed reporting metrics to Datadog.\", e);\n+\t\t\t}\n+\t\t\tfromIndex = toIndex;\n \t\t}\n+\t\tLOGGER.debug(\"Reported series with size {}.\", totalMetrics);\n+\t\tcounters.values().forEach(DCounter::ackReport);", "originalCommit": "3fa364afeda36c6e3de19804317d7470ecfcbd21", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzIwODEyNA==", "url": "https://github.com/apache/flink/pull/12138#discussion_r427208124", "bodyText": "yes; if an exception occurred for a sublist that contained a counter then we should not ack it.\nAs a quick solution (which is somewhat hacky, but I do want this in 1.11.0), we could add a no-op DMetric#ackReport() method that is overridden by DCounter. You could then ack them in the try section by iterating over the sub DSeries.", "author": "zentol", "createdAt": "2020-05-19T10:49:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAxMzA1NQ=="}], "type": "inlineReview"}, {"oid": "c9bd37ce2064a3cbd1d262adcf7f2a0414b76360", "url": "https://github.com/apache/flink/commit/c9bd37ce2064a3cbd1d262adcf7f2a0414b76360", "message": "[FLINK-16611] [datadog-metrics] Make number of metrics per request configurable", "committedDate": "2020-05-19T15:08:08Z", "type": "commit"}, {"oid": "b68d57306a42552df999c5ba8d3b4b598519b8f7", "url": "https://github.com/apache/flink/commit/b68d57306a42552df999c5ba8d3b4b598519b8f7", "message": "use a sublist to iterate metrics", "committedDate": "2020-05-19T15:08:08Z", "type": "commit"}, {"oid": "637bf0d7481f653c129625f20b95f02a75c5b711", "url": "https://github.com/apache/flink/commit/637bf0d7481f653c129625f20b95f02a75c5b711", "message": "ackReport metrics only if sent successfully", "committedDate": "2020-05-19T15:22:57Z", "type": "forcePushed"}, {"oid": "27d88f5b04869ef3fd68e3fad99dfef3d16856e9", "url": "https://github.com/apache/flink/commit/27d88f5b04869ef3fd68e3fad99dfef3d16856e9", "message": "ackReport metrics only if sent successfully", "committedDate": "2020-05-19T15:24:25Z", "type": "commit"}, {"oid": "27d88f5b04869ef3fd68e3fad99dfef3d16856e9", "url": "https://github.com/apache/flink/commit/27d88f5b04869ef3fd68e3fad99dfef3d16856e9", "message": "ackReport metrics only if sent successfully", "committedDate": "2020-05-19T15:24:25Z", "type": "forcePushed"}, {"oid": "5af9275ab0463841a13c30693df4bbb79de1bb94", "url": "https://github.com/apache/flink/commit/5af9275ab0463841a13c30693df4bbb79de1bb94", "message": "Update DatadogHttpReporter.java", "committedDate": "2020-05-20T09:26:59Z", "type": "commit"}, {"oid": "8e24fc1eaea326825c7667d969005dd242c7ebc0", "url": "https://github.com/apache/flink/commit/8e24fc1eaea326825c7667d969005dd242c7ebc0", "message": "Update DatadogHttpReporter.java", "committedDate": "2020-05-20T09:28:41Z", "type": "commit"}, {"oid": "cfa7085df16698ec5a746648d6e8c723a94dbe07", "url": "https://github.com/apache/flink/commit/cfa7085df16698ec5a746648d6e8c723a94dbe07", "message": "Update DatadogHttpReporter.java", "committedDate": "2020-05-20T09:30:49Z", "type": "commit"}]}