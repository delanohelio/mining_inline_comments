{"pr_number": 11768, "pr_title": "[FLINK-16943][python] Support set the configuration option \"pipeline.jars\" in PyFlink.", "pr_createdAt": "2020-04-16T07:34:10Z", "pr_url": "https://github.com/apache/flink/pull/11768", "timeline": [{"oid": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "url": "https://github.com/apache/flink/commit/a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "message": "[FLINK-16943][python] support add jars in PyFlink.", "committedDate": "2020-04-16T07:25:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ5NjQ3Mg==", "url": "https://github.com/apache/flink/pull/11768#discussion_r409496472", "bodyText": "Rename to _add_pipeline_jars_to_j_env_config", "author": "dianfu", "createdAt": "2020-04-16T11:54:09Z", "path": "flink-python/pyflink/table/table_environment.py", "diffHunk": "@@ -1095,6 +1096,19 @@ def _set_python_executable_for_local_executor(self):\n                 and is_local_deployment(j_config):\n             j_config.setString(jvm.PythonOptions.PYTHON_EXECUTABLE.key(), sys.executable)\n \n+    def _write_pipeline_jars_to_j_env(self):", "originalCommit": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ5Nzk1NA==", "url": "https://github.com/apache/flink/pull/11768#discussion_r409497954", "bodyText": "existing_urls", "author": "dianfu", "createdAt": "2020-04-16T11:56:55Z", "path": "flink-python/pyflink/util/utils.py", "diffHunk": "@@ -98,3 +98,30 @@ def is_local_deployment(j_configuration):\n     JDeploymentOptions = jvm.org.apache.flink.configuration.DeploymentOptions\n     return j_configuration.containsKey(JDeploymentOptions.TARGET.key()) \\\n         and j_configuration.getString(JDeploymentOptions.TARGET.key(), None) == \"local\"\n+\n+\n+def add_jars_to_context_class_loader(jar_urls):\n+    \"\"\"\n+    Add jars to Python gateway server for local compilation and local execution (i.e. minicluster).\n+    There are many component in Flink which won't be added to classpath by default. e.g. Kafka\n+    connector, JDBC connector, CSV format etc. This utility function can be used to hot load the\n+    jars.\n+\n+    :param jar_urls: The list of jar urls.\n+    \"\"\"\n+    gateway = get_gateway()\n+    # validate and normalize\n+    jar_urls = [gateway.jvm.java.net.URL(url).toString() for url in jar_urls]\n+    context_classloader = gateway.jvm.Thread.currentThread().getContextClassLoader()\n+    existed_urls = []", "originalCommit": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUwMzA2OA==", "url": "https://github.com/apache/flink/pull/11768#discussion_r409503068", "bodyText": "third_class_loader -> second_class_loader", "author": "dianfu", "createdAt": "2020-04-16T12:06:16Z", "path": "flink-python/pyflink/table/tests/test_table_environment_api.py", "diffHunk": "@@ -329,6 +334,54 @@ def test_table_environment_with_blink_planner(self):\n \n         self.assert_equals(results, ['2,hi,hello\\n', '3,hello,hello\\n'])\n \n+    def test_set_jars(self):\n+        jar_urls = []\n+        func1_class_name = \"org.apache.flink.table.planner.plan.stream.sql.Func1\"\n+        func2_class_name = \"org.apache.flink.python.util.TestScalarFunction\"\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func1_class_name,\n+            \"flink-table/flink-table-planner-blink/target/flink-table-planner-blink*-tests.jar\"))\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func2_class_name,\n+            \"flink-python/target/flink-python*-tests.jar\"))\n+\n+        # test set the \"pipeline.jars\" multiple times\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        first_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", jar_urls[0])\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        third_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()", "originalCommit": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUxNTQ5MA==", "url": "https://github.com/apache/flink/pull/11768#discussion_r409515490", "bodyText": "Change the error message to The scalar function '%s' should not be able to be loaded.  ?", "author": "dianfu", "createdAt": "2020-04-16T12:28:00Z", "path": "flink-python/pyflink/table/tests/test_table_environment_api.py", "diffHunk": "@@ -329,6 +334,54 @@ def test_table_environment_with_blink_planner(self):\n \n         self.assert_equals(results, ['2,hi,hello\\n', '3,hello,hello\\n'])\n \n+    def test_set_jars(self):\n+        jar_urls = []\n+        func1_class_name = \"org.apache.flink.table.planner.plan.stream.sql.Func1\"\n+        func2_class_name = \"org.apache.flink.python.util.TestScalarFunction\"\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func1_class_name,\n+            \"flink-table/flink-table-planner-blink/target/flink-table-planner-blink*-tests.jar\"))\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func2_class_name,\n+            \"flink-python/target/flink-python*-tests.jar\"))\n+\n+        # test set the \"pipeline.jars\" multiple times\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        first_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", jar_urls[0])\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        third_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.assertEqual(first_class_loader, third_class_loader)\n+\n+        source = self.t_env.from_elements([(1, \"Hi\"), (2, \"Hello\")], [\"a\", \"b\"])\n+        self.t_env.register_java_function(\"func1\", func1_class_name)\n+        self.t_env.register_java_function(\"func2\", func2_class_name)\n+        table_sink = source_sink_utils.TestAppendSink(\n+            [\"a\", \"b\"], [DataTypes.STRING(), DataTypes.STRING()])\n+        self.t_env.register_table_sink(\"sink\", table_sink)\n+        source.select(\"func1(a.cast(int), b), func2(a.cast(int), b)\").insert_into(\"sink\")\n+        self.t_env.execute(\"test\")\n+        actual = source_sink_utils.results()\n+        expected = ['1 and Hi,1 or Hi', '2 and Hello,2 or Hello']\n+        self.assert_equals(actual, expected)\n+\n+    def validate_and_return_unloaded_jar_url(self, func_class_name, jar_filename_pattern):\n+        test_jars = glob.glob(os.path.join(_find_flink_source_root(), jar_filename_pattern))\n+        if not test_jars:\n+            self.fail(\"'%s' is not available. Please compile the test jars first.\"\n+                      % jar_filename_pattern)\n+        try:\n+            self.t_env.register_java_function(\"func\", func_class_name)\n+        except Py4JJavaError:\n+            pass\n+        else:\n+            self.fail(\"The scalar function '%s' should not been loaded before this test case. \"", "originalCommit": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUxNTgzOQ==", "url": "https://github.com/apache/flink/pull/11768#discussion_r409515839", "bodyText": "Split it into two methods to make it more clear?", "author": "dianfu", "createdAt": "2020-04-16T12:28:35Z", "path": "flink-python/pyflink/table/tests/test_table_environment_api.py", "diffHunk": "@@ -329,6 +334,54 @@ def test_table_environment_with_blink_planner(self):\n \n         self.assert_equals(results, ['2,hi,hello\\n', '3,hello,hello\\n'])\n \n+    def test_set_jars(self):\n+        jar_urls = []\n+        func1_class_name = \"org.apache.flink.table.planner.plan.stream.sql.Func1\"\n+        func2_class_name = \"org.apache.flink.python.util.TestScalarFunction\"\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func1_class_name,\n+            \"flink-table/flink-table-planner-blink/target/flink-table-planner-blink*-tests.jar\"))\n+        jar_urls.extend(self.validate_and_return_unloaded_jar_url(\n+            func2_class_name,\n+            \"flink-python/target/flink-python*-tests.jar\"))\n+\n+        # test set the \"pipeline.jars\" multiple times\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        first_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", jar_urls[0])\n+        self.t_env.get_config().get_configuration().set_string(\"pipeline.jars\", \";\".join(jar_urls))\n+        third_class_loader = get_gateway().jvm.Thread.currentThread().getContextClassLoader()\n+\n+        self.assertEqual(first_class_loader, third_class_loader)\n+\n+        source = self.t_env.from_elements([(1, \"Hi\"), (2, \"Hello\")], [\"a\", \"b\"])\n+        self.t_env.register_java_function(\"func1\", func1_class_name)\n+        self.t_env.register_java_function(\"func2\", func2_class_name)\n+        table_sink = source_sink_utils.TestAppendSink(\n+            [\"a\", \"b\"], [DataTypes.STRING(), DataTypes.STRING()])\n+        self.t_env.register_table_sink(\"sink\", table_sink)\n+        source.select(\"func1(a.cast(int), b), func2(a.cast(int), b)\").insert_into(\"sink\")\n+        self.t_env.execute(\"test\")\n+        actual = source_sink_utils.results()\n+        expected = ['1 and Hi,1 or Hi', '2 and Hello,2 or Hello']\n+        self.assert_equals(actual, expected)\n+\n+    def validate_and_return_unloaded_jar_url(self, func_class_name, jar_filename_pattern):", "originalCommit": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUxNzAyMg==", "url": "https://github.com/apache/flink/pull/11768#discussion_r409517022", "bodyText": "What about generating two jars for this test purpose instead of reusing the existing test jars? It would be small and also could avoid potential problems.", "author": "dianfu", "createdAt": "2020-04-16T12:30:32Z", "path": "tools/travis_controller.sh", "diffHunk": "@@ -148,6 +148,8 @@ if [ $STAGE == \"$STAGE_COMPILE\" ]; then\n             ! -path \"$CACHE_FLINK_DIR/flink-dist/target/flink-*-bin/flink-*/opt/flink-python*.jar\" \\\n             ! -path \"$CACHE_FLINK_DIR/flink-connectors/flink-connector-elasticsearch-base/target/flink-*.jar\" \\\n             ! -path \"$CACHE_FLINK_DIR/flink-connectors/flink-connector-kafka-base/target/flink-*.jar\" \\\n+            ! -path \"$CACHE_FLINK_DIR/flink-python/target/flink-python*-tests.jar\" \\", "originalCommit": "a3aa6b6cab6c0a7e0e26c0cf3ef0e38f265e8799", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b796de76daa408c58f6aa13391c93f1a1e88bb57", "url": "https://github.com/apache/flink/commit/b796de76daa408c58f6aa13391c93f1a1e88bb57", "message": "address comments", "committedDate": "2020-04-17T04:50:20Z", "type": "commit"}, {"oid": "01280e72a363ee72180dd385dc95e0013f60650f", "url": "https://github.com/apache/flink/commit/01280e72a363ee72180dd385dc95e0013f60650f", "message": "also support set \"pipeline.classpaths\"", "committedDate": "2020-04-17T11:31:41Z", "type": "commit"}, {"oid": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "url": "https://github.com/apache/flink/commit/375c382d79b0eb32388aa1b6b9c2f365a91344ee", "message": "add documents for add jars.", "committedDate": "2020-04-20T08:02:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgyODE0Ng==", "url": "https://github.com/apache/flink/pull/11768#discussion_r411828146", "bodyText": "What about Java Dependency?", "author": "dianfu", "createdAt": "2020-04-21T02:46:18Z", "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management", "originalCommit": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgyODI2MA==", "url": "https://github.com/apache/flink/pull/11768#discussion_r411828260", "bodyText": "What about Python Dependency?", "author": "dianfu", "createdAt": "2020-04-21T02:46:44Z", "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.\n+table_env.get_config.set_configuration(\"pipeline.jars\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+\n+# Set jar urls in \"pipeline.classpaths\". The jars will be added to the classpath of the cluster.\n+# Users should ensure the urls are accessible on both the local client and the cluster.\n+# NOTE: The supported schemes includes: file,ftp,http,https,jar. \"hdfs\" is not supported by default.\n+table_env.get_config.set_configuration(\"pipeline.classpaths\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+{% endhighlight %}\n+\n+# Python Dependency Management", "originalCommit": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgyODcwMg==", "url": "https://github.com/apache/flink/pull/11768#discussion_r411828702", "bodyText": "Users could also specify the Java dependencies via command line arguments, could we add a link for that?", "author": "dianfu", "createdAt": "2020-04-21T02:48:10Z", "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.", "originalCommit": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgzMTM0Ng==", "url": "https://github.com/apache/flink/pull/11768#discussion_r411831346", "bodyText": "Set jar urls in \"pipeline.jars\". -> Specify a list of jar URLs via \"pipeline.jars\"", "author": "dianfu", "createdAt": "2020-04-21T02:56:08Z", "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.", "originalCommit": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgzMTU2OA==", "url": "https://github.com/apache/flink/pull/11768#discussion_r411831568", "bodyText": "Set jar urls in \"pipeline.classpaths\" ->  Specify a list of jar URLs via \"pipeline.classpaths\"", "author": "dianfu", "createdAt": "2020-04-21T02:56:48Z", "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.\n+table_env.get_config.set_configuration(\"pipeline.jars\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+\n+# Set jar urls in \"pipeline.classpaths\". The jars will be added to the classpath of the cluster.", "originalCommit": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgzMTcxMA==", "url": "https://github.com/apache/flink/pull/11768#discussion_r411831710", "bodyText": "includes -> include", "author": "dianfu", "createdAt": "2020-04-21T02:57:29Z", "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.\n+table_env.get_config.set_configuration(\"pipeline.jars\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+\n+# Set jar urls in \"pipeline.classpaths\". The jars will be added to the classpath of the cluster.\n+# Users should ensure the urls are accessible on both the local client and the cluster.\n+# NOTE: The supported schemes includes: file,ftp,http,https,jar. \"hdfs\" is not supported by default.", "originalCommit": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTgzMzg4NQ==", "url": "https://github.com/apache/flink/pull/11768#discussion_r411833885", "bodyText": "NOTE: Paths must specify a protocol (e.g. file://) and users should ensure that the URLs are accessible on both the client and the cluster.", "author": "dianfu", "createdAt": "2020-04-21T03:04:01Z", "path": "docs/dev/table/python/dependency_management.md", "diffHunk": "@@ -22,7 +22,24 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-If third-party dependencies are used, you can specify the dependencies with the following Python Table APIs or through <a href=\"{{ site.baseurl }}/ops/cli.html#usage\">command line arguments</a> directly when submitting the job.\n+# Java Dependency Management\n+\n+If third-party Java dependencies are used, you can using following code to add jars for your Python job.\n+\n+{% highlight python %}\n+# Set jar urls in \"pipeline.jars\". The jars will be uploaded to the cluster.\n+# NOTE: Only local file urls (start with \"file://\") are supported.\n+table_env.get_config.set_configuration(\"pipeline.jars\", \"file:///my/jar/path/connector.jar;file:///my/jar/path/udf.jar\")\n+\n+# Set jar urls in \"pipeline.classpaths\". The jars will be added to the classpath of the cluster.\n+# Users should ensure the urls are accessible on both the local client and the cluster.\n+# NOTE: The supported schemes includes: file,ftp,http,https,jar. \"hdfs\" is not supported by default.", "originalCommit": "375c382d79b0eb32388aa1b6b9c2f365a91344ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "32989f092938b29018f6a5cec052145289356dcb", "url": "https://github.com/apache/flink/commit/32989f092938b29018f6a5cec052145289356dcb", "message": "address comments", "committedDate": "2020-04-21T06:41:40Z", "type": "commit"}]}