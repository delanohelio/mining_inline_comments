{"pr_number": 13910, "pr_title": "[FLINK-19276][json][connector-kafka] Support reading Debezium metadata", "pr_createdAt": "2020-11-03T17:49:21Z", "pr_url": "https://github.com/apache/flink/pull/13910", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkyMTkyNA==", "url": "https://github.com/apache/flink/pull/13910#discussion_r517921924", "bodyText": "Add VIRTUAL to the metadata (even it is not tested)?", "author": "wuchong", "createdAt": "2020-11-05T09:51:50Z", "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaChangelogTableITCase.java", "diffHunk": "@@ -109,6 +109,7 @@ public void testKafkaDebeziumChangelogSource() throws Exception {\n \t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n \t\tString sourceDDL = String.format(\n \t\t\t\"CREATE TABLE debezium_source (\" +\n+\t\t\t\" origin STRING METADATA FROM 'value.source.table',\" + // test some metadata", "originalCommit": "44e62800be6f0c1ed5b117997212d69f1f7aae85", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5MTI0MA==", "url": "https://github.com/apache/flink/pull/13910#discussion_r517991240", "bodyText": "Add a comment to mention why we must put the format metadata before connector metadata? I think the order can't be switched.", "author": "wuchong", "createdAt": "2020-11-05T11:47:36Z", "path": "flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSource.java", "diffHunk": "@@ -179,13 +183,37 @@ public ScanRuntimeProvider getScanRuntimeProvider(ScanContext context) {\n \t@Override\n \tpublic Map<String, DataType> listReadableMetadata() {\n \t\tfinal Map<String, DataType> metadataMap = new LinkedHashMap<>();\n+\n+\t\t// add value format metadata with prefix", "originalCommit": "44e62800be6f0c1ed5b117997212d69f1f7aae85", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY2MjM4Nw==", "url": "https://github.com/apache/flink/pull/13910#discussion_r518662387", "bodyText": "actually the order doesn't matter here, but I just noticed that the order should be the other way around if format metadata should have higher precedence", "author": "twalthr", "createdAt": "2020-11-06T10:33:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5MTI0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5NDQ0OQ==", "url": "https://github.com/apache/flink/pull/13910#discussion_r517994449", "bodyText": "Could you make this case more complex? For example, declaring 2 format metadata and 2 connector metadata, but only select 1 format metadata and 1 connector metadata. This helps to verify format and connector metadata can work together and the metadata pruning also works.", "author": "wuchong", "createdAt": "2020-11-05T11:53:39Z", "path": "flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaChangelogTableITCase.java", "diffHunk": "@@ -131,7 +133,8 @@ public void testKafkaDebeziumChangelogSource() throws Exception {\n \t\ttEnv.executeSql(sourceDDL);\n \t\ttEnv.executeSql(sinkDDL);\n \t\tTableResult tableResult = tEnv.executeSql(\n-\t\t\t\"INSERT INTO sink SELECT name, SUM(weight) FROM debezium_source GROUP BY name\");\n+\t\t\t\"INSERT INTO sink SELECT FIRST_VALUE(origin), name, SUM(weight) \"\n+\t\t\t\t+ \"FROM debezium_source GROUP BY name\");", "originalCommit": "44e62800be6f0c1ed5b117997212d69f1f7aae85", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcyNDA3Ng==", "url": "https://github.com/apache/flink/pull/13910#discussion_r518724076", "bodyText": "Good suggestion. I found a bug.", "author": "twalthr", "createdAt": "2020-11-06T12:36:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5NDQ0OQ=="}], "type": "inlineReview"}, {"oid": "90a7f3c54a6cb48a381037ed50ba051d130f06bb", "url": "https://github.com/apache/flink/commit/90a7f3c54a6cb48a381037ed50ba051d130f06bb", "message": "Feedback addressed", "committedDate": "2020-11-06T14:33:45Z", "type": "forcePushed"}, {"oid": "fe9313e8a53267a252c3f47b300790accc814ed9", "url": "https://github.com/apache/flink/commit/fe9313e8a53267a252c3f47b300790accc814ed9", "message": "[hotfix][table-common] Improve terminology for data types in formats", "committedDate": "2020-11-07T09:19:32Z", "type": "commit"}, {"oid": "d978a05d6c34fdf80711e4946235105d17137d5e", "url": "https://github.com/apache/flink/commit/d978a05d6c34fdf80711e4946235105d17137d5e", "message": "[hotfix][table-common] Add hashCode/equals to DataTypes.Field", "committedDate": "2020-11-07T09:19:32Z", "type": "commit"}, {"oid": "64b96651579d76c718d67ebf2caca526d402a70e", "url": "https://github.com/apache/flink/commit/64b96651579d76c718d67ebf2caca526d402a70e", "message": "[FLINK-19276][json][connector-kafka] Support reading Debezium metadata\n\nThis exposes metadata for the Debezium JSON format according to FLIP-107.\n\n- Update the Kafka connector to expose format specific metadata.\n- Reconfigure the internal JsonRowDataDeserializationSchema to read additional fields.\n- Let DebeziumJsonDeserializationSchema access and convert those additional fields to metadata columns.\n\nThis closes #13910.", "committedDate": "2020-11-07T09:22:09Z", "type": "commit"}, {"oid": "64b96651579d76c718d67ebf2caca526d402a70e", "url": "https://github.com/apache/flink/commit/64b96651579d76c718d67ebf2caca526d402a70e", "message": "[FLINK-19276][json][connector-kafka] Support reading Debezium metadata\n\nThis exposes metadata for the Debezium JSON format according to FLIP-107.\n\n- Update the Kafka connector to expose format specific metadata.\n- Reconfigure the internal JsonRowDataDeserializationSchema to read additional fields.\n- Let DebeziumJsonDeserializationSchema access and convert those additional fields to metadata columns.\n\nThis closes #13910.", "committedDate": "2020-11-07T09:22:09Z", "type": "forcePushed"}]}