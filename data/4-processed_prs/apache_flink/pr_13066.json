{"pr_number": 13066, "pr_title": "[FLINK-18765][python] Support map() and flat_map() for Python DataStream API.", "pr_createdAt": "2020-08-05T09:25:30Z", "pr_url": "https://github.com/apache/flink/pull/13066", "timeline": [{"oid": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "url": "https://github.com/apache/flink/commit/1379a882e8dd7bcfea2a855847ba672f9fc4047d", "message": "[FLINK-18765][python] Add Beam operation and coders for running python DataStream functions.", "committedDate": "2020-08-05T09:18:34Z", "type": "commit"}, {"oid": "4a3cd4a62873723424a9c9de0e40944b8fc48784", "url": "https://github.com/apache/flink/commit/4a3cd4a62873723424a9c9de0e40944b8fc48784", "message": "[FLINK-18765][python] Add Java Operators to run python DataStream functions.", "committedDate": "2020-08-05T09:19:18Z", "type": "commit"}, {"oid": "91483a7603a0685ecb1351691ca68e75ade50a87", "url": "https://github.com/apache/flink/commit/91483a7603a0685ecb1351691ca68e75ade50a87", "message": "[FLINK-18765][python] Add map/flat_map() interfaces for DataStream.", "committedDate": "2020-08-05T09:20:16Z", "type": "commit"}, {"oid": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "url": "https://github.com/apache/flink/commit/0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "message": "- add conversion for tuple type from proto to coder.", "committedDate": "2020-08-05T09:30:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYxNDM3Nw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465614377", "bodyText": "I think return None is not a good chocie. Maybe you can raise a exception", "author": "HuangXingBo", "createdAt": "2020-08-05T10:01:33Z", "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -332,6 +400,39 @@ def __init__(self, precision, timezone):\n     def get_impl(self):\n         return coder_impl.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n+\n+\n+class PickledBytesCoder(FieldCoder):\n+\n+    def get_impl(self):\n+        return None", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYxNDQ3Ng==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465614476", "bodyText": "ditto", "author": "HuangXingBo", "createdAt": "2020-08-05T10:01:44Z", "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -332,6 +400,39 @@ def __init__(self, precision, timezone):\n     def get_impl(self):\n         return coder_impl.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n+\n+\n+class PickledBytesCoder(FieldCoder):\n+\n+    def get_impl(self):\n+        return None\n+\n+    def get_slow_impl(self):\n+        return coder_impl_slow.PickledBytesCoderImpl()\n+\n+\n+class TupleCoder(FieldCoder):\n+\n+    def __init__(self, field_coders):\n+        self._field_coders = field_coders\n+\n+    def get_slow_impl(self):\n+        return self._create_impl()\n+\n+    def get_impl(self):\n+        return None", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYyMTY1Mw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465621653", "bodyText": "Maybe we can write a more python code:\ntry:\nreturn catch _type_info_name_mappings[field_type_name]\ncatch KeyError:\n# other coder logic", "author": "HuangXingBo", "createdAt": "2020-08-05T10:15:29Z", "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -379,3 +480,40 @@ def from_proto(field_type):\n                             field_type.decimal_info.scale)\n     else:\n         raise ValueError(\"field_type %s is not supported.\" % field_type)\n+\n+\n+# for data stream type information.\n+type_info_name = flink_fn_execution_pb2.TypeInfo\n+_type_info_name_mappings = {\n+    type_info_name.STRING: CharCoder(),\n+    type_info_name.BYTE: TinyIntCoder(),\n+    type_info_name.BOOLEAN: BooleanCoder(),\n+    type_info_name.SHORT: SmallIntCoder(),\n+    type_info_name.INT: IntCoder(),\n+    type_info_name.LONG: BigIntCoder(),\n+    type_info_name.FLOAT: FloatCoder(),\n+    type_info_name.DOUBLE: DoubleCoder(),\n+    type_info_name.CHAR: CharCoder(),\n+    type_info_name.BIG_INT: BigIntCoder(),\n+    type_info_name.BIG_DEC: BasicDecimalCoder(),\n+    type_info_name.SQL_DATE: DateCoder(),\n+    type_info_name.SQL_TIME: TimeCoder(),\n+    type_info_name.SQL_TIMESTAMP: TimeCoder(),\n+    type_info_name.LOCAL_DATE: DateCoder(),\n+    type_info_name.PICKLED_BYTES: PickledBytesCoder()\n+}\n+\n+\n+def from_type_info_proto(field_type):\n+    field_type_name = field_type.type_name\n+    coder = _type_info_name_mappings.get(field_type_name)", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYyMjI4NQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465622285", "bodyText": "I think it is a temporary solution for no-cython coder.Right?", "author": "HuangXingBo", "createdAt": "2020-08-05T10:16:43Z", "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -109,6 +112,10 @@ def __hash__(self):\n \n \n class FieldCoder(ABC):\n+\n+    def get_slow_impl(self):\n+        pass", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYyMjc3MQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465622771", "bodyText": "Use operation_utils . DATA_STREAM_FUNCTION_URN  and Don't import DATA_STREAM_FUNCTION_URN directly.", "author": "HuangXingBo", "createdAt": "2020-08-05T10:17:39Z", "path": "flink-python/pyflink/fn_execution/beam/beam_operations_slow.py", "diffHunk": "@@ -154,6 +167,13 @@ def create_table_function(factory, transform_id, transform_proto, parameter, con\n         factory, transform_proto, consumers, parameter, TableFunctionOperation)\n \n \n+@bundle_processor.BeamTransformFactory.register_urn(\n+    DATA_STREAM_FUNCTION_URN, flink_fn_execution_pb2.UserDefinedDataStreamFunctions)", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY1NjA5Mw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465656093", "bodyText": "Maybe we can use list comprehension", "author": "HuangXingBo", "createdAt": "2020-08-05T11:21:06Z", "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "diffHunk": "@@ -305,6 +368,39 @@ def decode_from_stream(self, in_stream, nested):\n         return value\n \n \n+class BasicDecimalCoderImpl(StreamCoderImpl):\n+\n+    def encode_to_stream(self, value, stream, nested):\n+        bytes_value = str(value).encode(\"utf-8\")\n+        stream.write_bigendian_int32(len(bytes_value))\n+        stream.write(bytes_value, False)\n+\n+    def decode_from_stream(self, stream, nested):\n+        size = stream.read_bigendian_int32()\n+        value = decimal.Decimal(stream.read(size).decode(\"utf-8\"))\n+        return value\n+\n+\n+class TupleCoderImpl(StreamCoderImpl):\n+    def __init__(self, field_coders):\n+        self._field_coders = field_coders\n+        self._field_count = len(field_coders)\n+\n+    def encode_to_stream(self, value, out_stream, nested):\n+        field_coders = self._field_coders\n+        for i in range(self._field_count):\n+            field_coders[i].encode_to_stream(value[i], out_stream, nested)\n+\n+    def decode_from_stream(self, stream, nested):\n+        decoded_list = []\n+        for idx in range(self._field_count):", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY1NzQyNA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465657424", "bodyText": "use typehints.Generator", "author": "HuangXingBo", "createdAt": "2020-08-05T11:24:03Z", "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -209,3 +211,51 @@ def _to_row_type(row_schema):\n \n     def __repr__(self):\n         return 'ArrowCoder[%s]' % self._schema\n+\n+\n+class DataStreamStatelessMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder\n+\n+    def _create_impl(self):\n+        return beam_coder_impl_slow.DataStreamStatelessMapCoderImpl(\n+            self._field_coder.get_slow_impl())\n+\n+    def is_deterministic(self):  # type: () -> bool\n+        return all(c.is_deterministic() for c in self._field_coder)\n+\n+    @Coder.register_urn(FLINK_MAP_FUNCTION_DATA_STREAM_CODER_URN, flink_fn_execution_pb2.TypeInfo)\n+    def _pickled_from_runner_api_parameter(type_info_proto, unused_components, unused_context):\n+        return DataStreamStatelessMapCoder(from_type_info_proto(type_info_proto.field[0].type))\n+\n+    def to_type_hint(self):\n+        pass", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5NDY3Ng==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466794676", "bodyText": "return self._field_coder.to_type_hint ?", "author": "hequn8128", "createdAt": "2020-08-07T03:03:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY1NzQyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY1ODAyOA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465658028", "bodyText": "ditto", "author": "HuangXingBo", "createdAt": "2020-08-05T11:25:15Z", "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -209,3 +211,51 @@ def _to_row_type(row_schema):\n \n     def __repr__(self):\n         return 'ArrowCoder[%s]' % self._schema\n+\n+\n+class DataStreamStatelessMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder\n+\n+    def _create_impl(self):\n+        return beam_coder_impl_slow.DataStreamStatelessMapCoderImpl(\n+            self._field_coder.get_slow_impl())\n+\n+    def is_deterministic(self):  # type: () -> bool\n+        return all(c.is_deterministic() for c in self._field_coder)\n+\n+    @Coder.register_urn(FLINK_MAP_FUNCTION_DATA_STREAM_CODER_URN, flink_fn_execution_pb2.TypeInfo)\n+    def _pickled_from_runner_api_parameter(type_info_proto, unused_components, unused_context):\n+        return DataStreamStatelessMapCoder(from_type_info_proto(type_info_proto.field[0].type))\n+\n+    def to_type_hint(self):\n+        pass\n+\n+    def __repr__(self):\n+        return 'DataStreamStatelessMapCoder[%s]' % repr(self._field_coder)\n+\n+\n+class DataStreamStatelessFlatMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder\n+\n+    def _create_impl(self):\n+        return beam_coder_impl_slow.DataStreamStatelessFlatMapCoderImpl(\n+            self._field_coder.get_impl())\n+\n+    def is_deterministic(self):  # type: () -> bool\n+        return all(c.is_deterministic() for c in self._field_coder)\n+\n+    @Coder.register_urn(FLINK_FLAT_MAP_FUNCTION_DATA_STREAM_CODER_URN,\n+                        flink_fn_execution_pb2.TypeInfo)\n+    def _pickled_from_runner_api_parameter(type_info_proto, unused_components, unused_context):\n+        return DataStreamStatelessFlatMapCoder(DataStreamStatelessMapCoder(\n+            from_type_info_proto(type_info_proto.field[0].type)))\n+\n+    def to_type_hint(self):\n+        pass", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2MDA4NQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465660085", "bodyText": "Why not call the method encode_to_stream of the field_coder? The method of encode will create a temporary buffer.", "author": "HuangXingBo", "createdAt": "2020-08-05T11:29:32Z", "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "diffHunk": "@@ -186,6 +187,68 @@ def __repr__(self):\n         return 'ArrayCoderImpl[%s]' % repr(self._elem_coder)\n \n \n+class PickledBytesCoderImpl(StreamCoderImpl):\n+\n+    def __init__(self):\n+        self.field_coder = BinaryCoderImpl()\n+\n+    def encode_to_stream(self, value, out_stream, nested):\n+        coded_data = pickle.dumps(value)\n+        real_coded_data = self.field_coder.encode(coded_data)", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2NDkxNA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465664914", "bodyText": "Since its filed coder is a certain type, we can use a more specific name", "author": "HuangXingBo", "createdAt": "2020-08-05T11:39:35Z", "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -209,3 +211,51 @@ def _to_row_type(row_schema):\n \n     def __repr__(self):\n         return 'ArrowCoder[%s]' % self._schema\n+\n+\n+class DataStreamStatelessMapCoder(FastCoder):\n+\n+    def __init__(self, field_coder):\n+        self._field_coder = field_coder", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2NjI3NA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465666274", "bodyText": "1.200 is a float, not a Decimal.", "author": "HuangXingBo", "createdAt": "2020-08-05T11:42:31Z", "path": "flink-python/pyflink/fn_execution/tests/test_coders.py", "diffHunk": "@@ -154,6 +154,17 @@ def test_row_coder(self):\n         v = Row(*[None if i % 2 == 0 else i for i in range(field_count)])\n         self.check_coder(coder, v)\n \n+    def test_basic_decimal_coder(self):\n+        basic_dec_coder = BasicDecimalCoder()\n+        value = 1.200", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2NzI1Ng==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465667256", "bodyText": "You should use typehints.Tuple", "author": "HuangXingBo", "createdAt": "2020-08-05T11:44:34Z", "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -332,6 +400,39 @@ def __init__(self, precision, timezone):\n     def get_impl(self):\n         return coder_impl.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n+\n+\n+class PickledBytesCoder(FieldCoder):\n+\n+    def get_impl(self):\n+        return None\n+\n+    def get_slow_impl(self):\n+        return coder_impl_slow.PickledBytesCoderImpl()\n+\n+\n+class TupleCoder(FieldCoder):\n+\n+    def __init__(self, field_coders):\n+        self._field_coders = field_coders\n+\n+    def get_slow_impl(self):\n+        return self._create_impl()\n+\n+    def get_impl(self):\n+        return None\n+\n+    def _create_impl(self):\n+        return coder_impl_slow.TupleCoderImpl([c.get_impl() for c in self._field_coders])\n+\n+    def to_type_hint(self):\n+        return tuple", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2Nzk2MA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465667960", "bodyText": "Maybe it is return coder_impl_slow.TupleCoderImpl([c. get_slow_impl() for c in self._field_coders]) ?", "author": "HuangXingBo", "createdAt": "2020-08-05T11:45:54Z", "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -332,6 +400,39 @@ def __init__(self, precision, timezone):\n     def get_impl(self):\n         return coder_impl.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.LocalZonedTimestampCoderImpl(self.precision, self.timezone)\n+\n+\n+class PickledBytesCoder(FieldCoder):\n+\n+    def get_impl(self):\n+        return None\n+\n+    def get_slow_impl(self):\n+        return coder_impl_slow.PickledBytesCoderImpl()\n+\n+\n+class TupleCoder(FieldCoder):\n+\n+    def __init__(self, field_coders):\n+        self._field_coders = field_coders\n+\n+    def get_slow_impl(self):\n+        return self._create_impl()\n+\n+    def get_impl(self):\n+        return None\n+\n+    def _create_impl(self):\n+        return coder_impl_slow.TupleCoderImpl([c.get_impl() for c in self._field_coders])", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTY2ODk1Nw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465668957", "bodyText": "I think return None is not a good chocie. Maybe you can raise a exception", "author": "HuangXingBo", "createdAt": "2020-08-05T11:47:54Z", "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -271,6 +309,21 @@ def __init__(self, precision, scale):\n     def get_impl(self):\n         return coder_impl.DecimalCoderImpl(self.precision, self.scale)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.DecimalCoderImpl(self.precision, self.scale)\n+\n+\n+class BasicDecimalCoder(FieldCoder):\n+    \"\"\"\n+    Coder for Basic Decimal that no need to have precision and scale specified.\n+    \"\"\"\n+\n+    def get_impl(self):\n+        pass", "originalCommit": "1379a882e8dd7bcfea2a855847ba672f9fc4047d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTYwNzg1MA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r465607850", "bodyText": "Please remove the useless type, e.g., VOID, LOCAL_DATE, etc.", "author": "hequn8128", "createdAt": "2020-08-05T09:49:48Z", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -147,3 +163,50 @@ message Schema {\n \n   repeated Field fields = 1;\n }\n+\n+// A representation of the data type information of a data stream.\n+message TypeInfo {", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA5NzYzMg==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466097632", "bodyText": "Rename to BigDecimalCoder?", "author": "hequn8128", "createdAt": "2020-08-06T01:46:56Z", "path": "flink-python/pyflink/fn_execution/coders.py", "diffHunk": "@@ -271,6 +309,21 @@ def __init__(self, precision, scale):\n     def get_impl(self):\n         return coder_impl.DecimalCoderImpl(self.precision, self.scale)\n \n+    def get_slow_impl(self):\n+        return coder_impl_slow.DecimalCoderImpl(self.precision, self.scale)\n+\n+\n+class BasicDecimalCoder(FieldCoder):", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA5OTIyNQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466099225", "bodyText": "DATA_STREAM_STATELESS_FUNCTION_URN?", "author": "hequn8128", "createdAt": "2020-08-06T01:53:17Z", "path": "flink-python/pyflink/fn_execution/operation_utils.py", "diffHunk": "@@ -20,11 +20,13 @@\n import cloudpickle\n from typing import Any, Tuple, Dict, List\n \n+from pyflink.fn_execution import flink_fn_execution_pb2\n from pyflink.serializers import PickleSerializer\n from pyflink.table.udf import DelegationTableFunction, DelegatingScalarFunction\n \n SCALAR_FUNCTION_URN = \"flink:transform:scalar_function:v1\"\n TABLE_FUNCTION_URN = \"flink:transform:table_function:v1\"\n+DATA_STREAM_FUNCTION_URN = \"flink:transform:datastream_stateless_function:v1\"", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjA5OTQ2MQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466099461", "bodyText": "data stream => DataStream. And for other places.", "author": "hequn8128", "createdAt": "2020-08-06T01:54:09Z", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -52,6 +52,22 @@ message UserDefinedFunctions {\n   bool metric_enabled = 2;\n }\n \n+// User defined data stream function definition.", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMDI1OA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466100258", "bodyText": "maintains", "author": "hequn8128", "createdAt": "2020-08-06T01:57:02Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+/**\n+ * DataStreamPythonFunction maintain the serialized python function and its function type, which will be used in", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMDYyMg==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466100622", "bodyText": "DataStreamPythonFunction => {@link DataStreamPythonFunction}. Same for other places.", "author": "hequn8128", "createdAt": "2020-08-06T01:58:33Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+/**\n+ * DataStreamPythonFunction maintain the serialized python function and its function type, which will be used in", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMDk1NA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466100954", "bodyText": "DataStreamPythonFunctionInfo => {@link DataStreamPythonFunctionInfo}", "author": "hequn8128", "createdAt": "2020-08-06T01:59:53Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunctionInfo.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * DataStreamPythonFunctionInfo holds a PythonFunction and its function type.", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMjE1OQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466102159", "bodyText": "private static final long serialVersionUID = 1L;", "author": "hequn8128", "createdAt": "2020-08-06T02:04:18Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunction.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+/**\n+ * DataStreamPythonFunction maintain the serialized python function and its function type, which will be used in\n+ * DataStreamPythonFunctionRunner.\n+ */\n+public class DataStreamPythonFunction implements PythonFunction {", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMjU3MA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466102570", "bodyText": "We don't need to separate lines here.", "author": "hequn8128", "createdAt": "2020-08-06T02:05:35Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/functions/python/DataStreamPythonFunctionInfo.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.functions.python;\n+\n+import org.apache.flink.table.functions.python.PythonFunction;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * DataStreamPythonFunctionInfo holds a PythonFunction and its function type.\n+ * */\n+public class DataStreamPythonFunctionInfo implements Serializable {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate final PythonFunction pythonFunction;\n+\tprivate final int functionType;\n+\n+\tpublic DataStreamPythonFunctionInfo(PythonFunction pythonFunction,\n+\t\t\t\t\t\t\t\t\t\tint functionType) {", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMjc3NQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466102775", "bodyText": "DataStreamPythonFunctionOperator => {@link DataStreamPythonFunctionOperator}", "author": "hequn8128", "createdAt": "2020-08-06T02:06:23Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,154 @@\n+package org.apache.flink.datastream.runtime.operators.python;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;\n+import org.apache.flink.core.memory.ByteArrayOutputStreamWithPos;\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.datastream.runtime.functions.python.DataStreamPythonFunctionInfo;\n+import org.apache.flink.datastream.runtime.runners.python.beam.BeamDataStreamPythonStatelessFunctionRunner;\n+import org.apache.flink.datastream.runtime.typeutils.python.PythonTypeUtils;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.runtime.util.StreamRecordCollector;\n+\n+import com.google.protobuf.ByteString;\n+\n+import java.util.Map;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * DataStreamPythonFunctionOperator is responsible for launching beam runner which will start a python harness to", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMzA4Nw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466103087", "bodyText": "Please remove these unnecessary variables.", "author": "hequn8128", "createdAt": "2020-08-06T02:07:35Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,154 @@\n+package org.apache.flink.datastream.runtime.operators.python;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.core.memory.ByteArrayInputStreamWithPos;\n+import org.apache.flink.core.memory.ByteArrayOutputStreamWithPos;\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+import org.apache.flink.datastream.runtime.functions.python.DataStreamPythonFunctionInfo;\n+import org.apache.flink.datastream.runtime.runners.python.beam.BeamDataStreamPythonStatelessFunctionRunner;\n+import org.apache.flink.datastream.runtime.typeutils.python.PythonTypeUtils;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.PythonFunctionRunner;\n+import org.apache.flink.streaming.api.operators.python.AbstractPythonFunctionOperator;\n+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;\n+import org.apache.flink.table.functions.python.PythonEnv;\n+import org.apache.flink.table.runtime.util.StreamRecordCollector;\n+\n+import com.google.protobuf.ByteString;\n+\n+import java.util.Map;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * DataStreamPythonFunctionOperator is responsible for launching beam runner which will start a python harness to\n+ * execute user defined python function.\n+ */\n+public class DataStreamPythonStatelessFunctionOperator<IN, OUT> extends AbstractPythonFunctionOperator<IN, OUT> {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\tprivate static final String DATA_STREAM_STATELESS_PYTHON_FUNCTION_URN = \"flink:transform:datastream_stateless_function:v1\";\n+\tprivate static final String DATA_STREAM_MAP_FUNCTION_CODER_URN = \"flink:coder:datastream:map_function:v1\";\n+\tprivate static final String DATA_STREAM_FLAT_MAP_FUNCTION_CODER_URN = \"flink:coder:datastream:flatmap_function:v1\";\n+\n+\n+\tprotected final DataStreamPythonFunctionInfo pythonFunctionInfo;\n+\n+\tprivate final TypeInformation<IN> inputTypeInfo;\n+\n+\tprivate final TypeInformation<OUT> outputTypeInfo;\n+\n+\tprivate final Map<String, String> jobOptions;\n+\n+\tprivate transient TypeSerializer<IN> inputTypeSerializer;\n+\n+\tprivate transient TypeSerializer<OUT> outputTypeSerializer;\n+\n+\tprotected transient LinkedBlockingQueue<byte[]> userDefinedFunctionResultQueue;", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMzQ2MA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466103460", "bodyText": "Add license text for this class. Please check the test failures.", "author": "hequn8128", "createdAt": "2020-08-06T02:08:57Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,154 @@\n+package org.apache.flink.datastream.runtime.operators.python;", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwMzkxNw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466103917", "bodyText": "private static final long serialVersionUID = 1L;", "author": "hequn8128", "createdAt": "2020-08-06T02:10:37Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/runners/python/beam/BeamDataStreamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.runners.python.beam;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.datastream.runtime.typeutils.python.PythonTypeUtils;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.Map;\n+\n+/**\n+ * DataStreamPythonFunctionRunner is responsible for starting a beam python harness to execute user defined python\n+ * function.\n+ */\n+public class BeamDataStreamPythonStatelessFunctionRunner extends BeamPythonStatelessFunctionRunner {", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNDE0Ng==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466104146", "bodyText": "DataStreamPythonFunctionRunner => {@link DataStreamPythonFunctionRunner}", "author": "hequn8128", "createdAt": "2020-08-06T02:11:33Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/runners/python/beam/BeamDataStreamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.runners.python.beam;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.datastream.runtime.typeutils.python.PythonTypeUtils;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.Map;\n+\n+/**\n+ * DataStreamPythonFunctionRunner is responsible for starting a beam python harness to execute user defined python", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNDY3OQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466104679", "bodyText": "We don't have VOID type.", "author": "hequn8128", "createdAt": "2020-08-06T02:13:42Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.typeutils.python;\n+\n+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;\n+import org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.BigIntSerializer;\n+import org.apache.flink.api.common.typeutils.base.BooleanSerializer;\n+import org.apache.flink.api.common.typeutils.base.CharSerializer;\n+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;\n+import org.apache.flink.api.common.typeutils.base.FloatSerializer;\n+import org.apache.flink.api.common.typeutils.base.InstantSerializer;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.ShortSerializer;\n+import org.apache.flink.api.common.typeutils.base.VoidSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n+import org.apache.flink.datastream.typeinfo.python.PickledByteArrayTypeInfo;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A util class for converting the given TypeInformation to other objects.\n+ */\n+public class PythonTypeUtils {\n+\n+\t/**\n+\t * Get coder proto according to the given type information.\n+\t */\n+\tpublic static class TypeInfoToProtoConverter {\n+\n+\t\tpublic static FlinkFnApi.TypeInfo.FieldType getFieldType(TypeInformation typeInformation) {\n+\n+\t\t\tif (typeInformation instanceof BasicTypeInfo) {\n+\t\t\t\treturn buildBasicTypeProto((BasicTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PrimitiveArrayTypeInfo) {\n+\t\t\t\treturn buildPrimitiveArrayTypeProto((PrimitiveArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof RowTypeInfo) {\n+\t\t\t\treturn buildRowTypeProto((RowTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PickledByteArrayTypeInfo) {\n+\t\t\t\treturn buildPickledBytesTypeProto((PickledByteArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof TupleTypeInfo) {\n+\t\t\t\treturn buildTupleTypeProto((TupleTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\tString.format(\"The type information: %s is not supported in PyFlink currently.\",\n+\t\t\t\t\ttypeInformation.toString()));\n+\t\t}\n+\n+\t\tpublic static FlinkFnApi.TypeInfo toTypeInfoProto(FlinkFnApi.TypeInfo.FieldType fieldType) {\n+\t\t\treturn FlinkFnApi.TypeInfo.newBuilder().addField(FlinkFnApi.TypeInfo.Field.newBuilder().setType(fieldType).build()).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildBasicTypeProto(BasicTypeInfo basicTypeInfo) {\n+\n+\t\t\tFlinkFnApi.TypeInfo.TypeName typeName = null;\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BOOLEAN_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BOOLEAN;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BYTE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BYTE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.STRING_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.STRING;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.SHORT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.SHORT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.LONG_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LONG;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.FLOAT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.FLOAT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DOUBLE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.DOUBLE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.CHAR_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.CHAR;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DATE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LOCAL_DATE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.VOID_TYPE_INFO)) {", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNDc2Ng==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466104766", "bodyText": "Don't have INSTANCE type in datastream", "author": "hequn8128", "createdAt": "2020-08-06T02:14:06Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.typeutils.python;\n+\n+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;\n+import org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.BigIntSerializer;\n+import org.apache.flink.api.common.typeutils.base.BooleanSerializer;\n+import org.apache.flink.api.common.typeutils.base.CharSerializer;\n+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;\n+import org.apache.flink.api.common.typeutils.base.FloatSerializer;\n+import org.apache.flink.api.common.typeutils.base.InstantSerializer;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.ShortSerializer;\n+import org.apache.flink.api.common.typeutils.base.VoidSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n+import org.apache.flink.datastream.typeinfo.python.PickledByteArrayTypeInfo;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A util class for converting the given TypeInformation to other objects.\n+ */\n+public class PythonTypeUtils {\n+\n+\t/**\n+\t * Get coder proto according to the given type information.\n+\t */\n+\tpublic static class TypeInfoToProtoConverter {\n+\n+\t\tpublic static FlinkFnApi.TypeInfo.FieldType getFieldType(TypeInformation typeInformation) {\n+\n+\t\t\tif (typeInformation instanceof BasicTypeInfo) {\n+\t\t\t\treturn buildBasicTypeProto((BasicTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PrimitiveArrayTypeInfo) {\n+\t\t\t\treturn buildPrimitiveArrayTypeProto((PrimitiveArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof RowTypeInfo) {\n+\t\t\t\treturn buildRowTypeProto((RowTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PickledByteArrayTypeInfo) {\n+\t\t\t\treturn buildPickledBytesTypeProto((PickledByteArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof TupleTypeInfo) {\n+\t\t\t\treturn buildTupleTypeProto((TupleTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\tString.format(\"The type information: %s is not supported in PyFlink currently.\",\n+\t\t\t\t\ttypeInformation.toString()));\n+\t\t}\n+\n+\t\tpublic static FlinkFnApi.TypeInfo toTypeInfoProto(FlinkFnApi.TypeInfo.FieldType fieldType) {\n+\t\t\treturn FlinkFnApi.TypeInfo.newBuilder().addField(FlinkFnApi.TypeInfo.Field.newBuilder().setType(fieldType).build()).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildBasicTypeProto(BasicTypeInfo basicTypeInfo) {\n+\n+\t\t\tFlinkFnApi.TypeInfo.TypeName typeName = null;\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BOOLEAN_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BOOLEAN;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BYTE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BYTE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.STRING_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.STRING;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.SHORT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.SHORT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.LONG_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LONG;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.FLOAT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.FLOAT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DOUBLE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.DOUBLE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.CHAR_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.CHAR;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DATE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LOCAL_DATE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.VOID_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.VOID;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BIG_INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BIG_INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BIG_DEC_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BIG_DEC;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INSTANT_TYPE_INFO)) {", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNDkwMA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466104900", "bodyText": "Remove void and instance.", "author": "hequn8128", "createdAt": "2020-08-06T02:14:34Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.typeutils.python;\n+\n+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;\n+import org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.BigIntSerializer;\n+import org.apache.flink.api.common.typeutils.base.BooleanSerializer;\n+import org.apache.flink.api.common.typeutils.base.CharSerializer;\n+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;\n+import org.apache.flink.api.common.typeutils.base.FloatSerializer;\n+import org.apache.flink.api.common.typeutils.base.InstantSerializer;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.ShortSerializer;\n+import org.apache.flink.api.common.typeutils.base.VoidSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n+import org.apache.flink.datastream.typeinfo.python.PickledByteArrayTypeInfo;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A util class for converting the given TypeInformation to other objects.\n+ */\n+public class PythonTypeUtils {\n+\n+\t/**\n+\t * Get coder proto according to the given type information.\n+\t */\n+\tpublic static class TypeInfoToProtoConverter {\n+\n+\t\tpublic static FlinkFnApi.TypeInfo.FieldType getFieldType(TypeInformation typeInformation) {\n+\n+\t\t\tif (typeInformation instanceof BasicTypeInfo) {\n+\t\t\t\treturn buildBasicTypeProto((BasicTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PrimitiveArrayTypeInfo) {\n+\t\t\t\treturn buildPrimitiveArrayTypeProto((PrimitiveArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof RowTypeInfo) {\n+\t\t\t\treturn buildRowTypeProto((RowTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof PickledByteArrayTypeInfo) {\n+\t\t\t\treturn buildPickledBytesTypeProto((PickledByteArrayTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tif (typeInformation instanceof TupleTypeInfo) {\n+\t\t\t\treturn buildTupleTypeProto((TupleTypeInfo) typeInformation);\n+\t\t\t}\n+\n+\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\tString.format(\"The type information: %s is not supported in PyFlink currently.\",\n+\t\t\t\t\ttypeInformation.toString()));\n+\t\t}\n+\n+\t\tpublic static FlinkFnApi.TypeInfo toTypeInfoProto(FlinkFnApi.TypeInfo.FieldType fieldType) {\n+\t\t\treturn FlinkFnApi.TypeInfo.newBuilder().addField(FlinkFnApi.TypeInfo.Field.newBuilder().setType(fieldType).build()).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildBasicTypeProto(BasicTypeInfo basicTypeInfo) {\n+\n+\t\t\tFlinkFnApi.TypeInfo.TypeName typeName = null;\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BOOLEAN_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BOOLEAN;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BYTE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BYTE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.STRING_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.STRING;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.SHORT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.SHORT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.LONG_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LONG;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.FLOAT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.FLOAT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DOUBLE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.DOUBLE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.CHAR_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.CHAR;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.DATE_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.LOCAL_DATE;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.VOID_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.VOID;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BIG_INT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BIG_INT;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.BIG_DEC_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.BIG_DEC;\n+\t\t\t}\n+\n+\t\t\tif (basicTypeInfo.equals(BasicTypeInfo.INSTANT_TYPE_INFO)) {\n+\t\t\t\ttypeName = FlinkFnApi.TypeInfo.TypeName.INSTANT;\n+\t\t\t}\n+\n+\t\t\tif (typeName == null) {\n+\t\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\t\tString.format(\"The BasicTypeInfo: %s is not supported in PyFlink currently.\",\n+\t\t\t\t\t\tbasicTypeInfo.toString()));\n+\t\t\t}\n+\n+\t\t\treturn FlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t.setTypeName(typeName).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildPrimitiveArrayTypeProto(\n+\t\t\tPrimitiveArrayTypeInfo primitiveArrayTypeInfo) {\n+\t\t\tFlinkFnApi.TypeInfo.FieldType elementFieldType = null;\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.BOOLEAN_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.BOOLEAN_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.BYTE_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.BYTE_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.SHORT_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.SHORT_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.INT_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.INT_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.LONG_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.LONG_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.FLOAT_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.FLOAT_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.DOUBLE_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.DOUBLE_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (primitiveArrayTypeInfo.equals(PrimitiveArrayTypeInfo.CHAR_PRIMITIVE_ARRAY_TYPE_INFO)) {\n+\t\t\t\telementFieldType = buildBasicTypeProto(BasicTypeInfo.CHAR_TYPE_INFO);\n+\t\t\t}\n+\n+\t\t\tif (elementFieldType == null) {\n+\t\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\t\tString.format(\"The element type of PrimitiveArrayTypeInfo: %s is not supported in PyFlink currently.\"\n+\t\t\t\t\t\t, primitiveArrayTypeInfo.toString()));\n+\t\t\t}\n+\n+\t\t\tFlinkFnApi.TypeInfo.FieldType.Builder builder = FlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t.setTypeName(FlinkFnApi.TypeInfo.TypeName.ARRAY);\n+\t\t\tbuilder.setCollectionElementType(elementFieldType);\n+\t\t\treturn builder.build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildRowTypeProto(RowTypeInfo rowTypeInfo) {\n+\t\t\tFlinkFnApi.TypeInfo.FieldType.Builder builder =\n+\t\t\t\tFlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t\t.setTypeName(FlinkFnApi.TypeInfo.TypeName.ROW);\n+\n+\t\t\tFlinkFnApi.TypeInfo.Builder rowTypeInfoBuilder = FlinkFnApi.TypeInfo.newBuilder();\n+\n+\t\t\tint arity = rowTypeInfo.getArity();\n+\t\t\tfor (int index = 0; index < arity; index++) {\n+\t\t\t\trowTypeInfoBuilder.addField(\n+\t\t\t\t\tFlinkFnApi.TypeInfo.Field.newBuilder()\n+\t\t\t\t\t\t.setName(rowTypeInfo.getFieldNames()[index])\n+\t\t\t\t\t\t.setType(TypeInfoToProtoConverter.getFieldType(rowTypeInfo.getTypeAt(index)))\n+\t\t\t\t\t\t.build());\n+\t\t\t}\n+\t\t\tbuilder.setRowTypeInfo(rowTypeInfoBuilder.build());\n+\t\t\treturn builder.build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildPickledBytesTypeProto(PickledByteArrayTypeInfo pickledByteArrayTypeInfo) {\n+\t\t\treturn FlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t.setTypeName(FlinkFnApi.TypeInfo.TypeName.PICKLED_BYTES).build();\n+\t\t}\n+\n+\t\tprivate static FlinkFnApi.TypeInfo.FieldType buildTupleTypeProto(TupleTypeInfo tupleTypeInfo) {\n+\t\t\tFlinkFnApi.TypeInfo.FieldType.Builder builder =\n+\t\t\t\tFlinkFnApi.TypeInfo.FieldType.newBuilder()\n+\t\t\t\t\t.setTypeName(FlinkFnApi.TypeInfo.TypeName.TUPLE);\n+\n+\t\t\tFlinkFnApi.TypeInfo.Builder tupleTypeInfoBuilder = FlinkFnApi.TypeInfo.newBuilder();\n+\n+\t\t\tint arity = tupleTypeInfo.getArity();\n+\t\t\tfor (int index = 0; index < arity; index++) {\n+\t\t\t\ttupleTypeInfoBuilder.addField(\n+\t\t\t\t\tFlinkFnApi.TypeInfo.Field.newBuilder()\n+\t\t\t\t\t\t.setName(tupleTypeInfo.getFieldNames()[index])\n+\t\t\t\t\t\t.setType(TypeInfoToProtoConverter.getFieldType(tupleTypeInfo.getTypeAt(index)))\n+\t\t\t\t\t\t.build());\n+\t\t\t}\n+\t\t\tbuilder.setTupleTypeInfo(tupleTypeInfoBuilder.build());\n+\t\t\treturn builder.build();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Get serializers according to the given typeInformation.\n+\t */\n+\tpublic static class TypeInfoToSerializerConverter {\n+\t\tprivate static final Map<Class, TypeSerializer> typeInfoToSerialzerMap = new HashMap<>();\n+\n+\t\tstatic {\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.BOOLEAN_TYPE_INFO.getTypeClass(), BooleanSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.INT_TYPE_INFO.getTypeClass(), IntSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.STRING_TYPE_INFO.getTypeClass(), StringSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.SHORT_TYPE_INFO.getTypeClass(), ShortSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.LONG_TYPE_INFO.getTypeClass(), LongSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.FLOAT_TYPE_INFO.getTypeClass(), FloatSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.DOUBLE_TYPE_INFO.getTypeClass(), DoubleSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.CHAR_TYPE_INFO.getTypeClass(), CharSerializer.INSTANCE);\n+\t\t\ttypeInfoToSerialzerMap.put(BasicTypeInfo.DATE_TYPE_INFO.getTypeClass(), DateSerializer.INSTANCE);", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNTAxMg==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466105012", "bodyText": "Add tests for this class.", "author": "hequn8128", "createdAt": "2020-08-06T02:14:55Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/typeutils/python/PythonTypeUtils.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.datastream.runtime.typeutils.python;\n+\n+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;\n+import org.apache.flink.api.common.typeinfo.PrimitiveArrayTypeInfo;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.base.BigIntSerializer;\n+import org.apache.flink.api.common.typeutils.base.BooleanSerializer;\n+import org.apache.flink.api.common.typeutils.base.CharSerializer;\n+import org.apache.flink.api.common.typeutils.base.DoubleSerializer;\n+import org.apache.flink.api.common.typeutils.base.FloatSerializer;\n+import org.apache.flink.api.common.typeutils.base.InstantSerializer;\n+import org.apache.flink.api.common.typeutils.base.IntSerializer;\n+import org.apache.flink.api.common.typeutils.base.LongSerializer;\n+import org.apache.flink.api.common.typeutils.base.ShortSerializer;\n+import org.apache.flink.api.common.typeutils.base.VoidSerializer;\n+import org.apache.flink.api.common.typeutils.base.array.BytePrimitiveArraySerializer;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.api.java.typeutils.RowTypeInfo;\n+import org.apache.flink.api.java.typeutils.TupleTypeInfo;\n+import org.apache.flink.api.java.typeutils.runtime.RowSerializer;\n+import org.apache.flink.api.java.typeutils.runtime.TupleSerializer;\n+import org.apache.flink.datastream.typeinfo.python.PickledByteArrayTypeInfo;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.BigDecSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.DateSerializer;\n+import org.apache.flink.table.runtime.typeutils.serializers.python.StringSerializer;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A util class for converting the given TypeInformation to other objects.\n+ */\n+public class PythonTypeUtils {", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNTU0NA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466105544", "bodyText": "StreamExecutionEnvironment => {@link StreamExecutionEnvironment}", "author": "hequn8128", "createdAt": "2020-08-06T02:16:56Z", "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.python.util;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+\n+/**\n+ * A Util class to get the StreamExecutionEnvironment configuration and merged configuration with environment settings.", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNTY2Ng==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466105666", "bodyText": "{@link StreamExecutionEnvironment#getConfiguration()}", "author": "hequn8128", "createdAt": "2020-08-06T02:17:30Z", "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.python.util;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+\n+/**\n+ * A Util class to get the StreamExecutionEnvironment configuration and merged configuration with environment settings.\n+ */\n+public class PythonConfigUtil {\n+\n+\t/**\n+\t * A static method to get the StreamExecutionEnvironment configuration merged with python dependency management\n+\t * configurations.\n+\t */\n+\tpublic static Configuration getMergedConfig(StreamExecutionEnvironment env) throws InvocationTargetException,\n+\t\tIllegalAccessException, NoSuchMethodException {\n+\t\tConfiguration envConfiguration = getEnvironmentConfig(env);\n+\t\tConfiguration config = PythonDependencyUtils.configurePythonDependencies(env.getCachedFiles(), envConfiguration);\n+\t\treturn config;\n+\t}\n+\n+\t/**\n+\t * Get the private method StreamExecutionEnvironment.getConfiguration() by reflection recursively. Then access the", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNTcxMw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466105713", "bodyText": "Add tests for this class.", "author": "hequn8128", "createdAt": "2020-08-06T02:17:46Z", "path": "flink-python/src/main/java/org/apache/flink/python/util/PythonConfigUtil.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.python.util;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+\n+/**\n+ * A Util class to get the StreamExecutionEnvironment configuration and merged configuration with environment settings.\n+ */\n+public class PythonConfigUtil {", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNjMwMQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466106301", "bodyText": "Recovery the change.", "author": "hequn8128", "createdAt": "2020-08-06T02:19:58Z", "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -53,8 +48,7 @@\n /**\n  * A {@link BeamPythonFunctionRunner} used to execute Python stateless functions.\n  */\n-@Internal", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzA0Nw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107047", "bodyText": "Keep one blank between protected and abstract.", "author": "hequn8128", "createdAt": "2020-08-06T02:22:41Z", "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -170,34 +150,11 @@ public ExecutableStage createExecutableStage() throws Exception {\n \t\t\t.build();\n \t}\n \n-\t/**\n-\t * Gets the proto representation of the input coder.\n-\t */\n-\tprivate RunnerApi.Coder getInputCoderProto() {\n-\t\treturn getRowCoderProto(inputType);\n-\t}\n-\n-\t/**\n-\t * Gets the proto representation of the output coder.\n-\t */\n-\tprivate RunnerApi.Coder getOutputCoderProto() {\n-\t\treturn getRowCoderProto(outputType);\n-\t}\n+\tprotected  abstract byte[] getUserDefinedFunctionsProtoBytes();", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzIzOQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107239", "bodyText": "private static final long serialVersionUID = 1L;", "author": "hequn8128", "createdAt": "2020-08-06T02:23:32Z", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.runners.python.beam;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import java.util.Map;\n+\n+/**\n+ * A {@link BeamPythonFunctionRunner} used to execute Python stateless functions.\n+ */\n+@Internal\n+public class BeamTablePythonStatelessFunctionRunner extends BeamPythonStatelessFunctionRunner {\n+\n+", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzM2Mg==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107362", "bodyText": "BeamTablePythonStatelessFunctionRunner", "author": "hequn8128", "createdAt": "2020-08-06T02:23:57Z", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.runners.python.beam;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import java.util.Map;\n+\n+/**\n+ * A {@link BeamPythonFunctionRunner} used to execute Python stateless functions.", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzY3OQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107679", "bodyText": "PassThroughPythonScalarFunctionRunner", "author": "hequn8128", "createdAt": "2020-08-06T02:24:58Z", "path": "flink-python/src/test/java/org/apache/flink/table/runtime/utils/PassThroughPythonScalarFunctionRunner.java", "diffHunk": "@@ -32,9 +32,9 @@\n import java.util.Map;\n \n /**\n- * A BeamPythonStatelessFunctionRunner runner that just return the input elements as the execution results.\n+ * A BeamTablePythonStatelessFunctionRunner runner that just return the input elements as the execution results.", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEwNzcxNA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466107714", "bodyText": "PassThroughPythonTableFunctionRunner", "author": "hequn8128", "createdAt": "2020-08-06T02:25:06Z", "path": "flink-python/src/test/java/org/apache/flink/table/runtime/utils/PassThroughPythonTableFunctionRunner.java", "diffHunk": "@@ -32,10 +32,10 @@\n import java.util.Map;\n \n /**\n- * A BeamPythonStatelessFunctionRunner that emit each input element in inner join and emit null in\n+ * A BeamTablePythonStatelessFunctionRunner that emit each input element in inner join and emit null in", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjIwNw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112207", "bodyText": "Add type hint.\nfrom typing import Union, Callable\ndef map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None) -> 'DataStream':", "author": "hequn8128", "createdAt": "2020-08-06T02:41:48Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjY0Nw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112647", "bodyText": "The input must be a MapFunction", "author": "hequn8128", "createdAt": "2020-08-06T02:43:25Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input muster be MapFunction or a callable function\")", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjc2Nw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112767", "bodyText": "Add an example in the python docs.", "author": "hequn8128", "createdAt": "2020-08-06T02:43:55Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjg1Mw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112853", "bodyText": "Type hint.", "author": "hequn8128", "createdAt": "2020-08-06T02:44:11Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input muster be MapFunction or a callable function\")\n+        func_name = \"m_map_\" + str(uuid.uuid1())\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(\n+            func_name,\n+            output_type_info.get_java_type_info(),\n+            j_python_data_stream_scalar_function_operator\n+        ))\n+\n+    def flat_map(self, func, type_info=None):", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMjk3NA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466112974", "bodyText": "The input must be a FlatMapFunction", "author": "hequn8128", "createdAt": "2020-08-06T02:44:40Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +167,120 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input muster be MapFunction or a callable function\")\n+        func_name = \"m_map_\" + str(uuid.uuid1())\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(\n+            func_name,\n+            output_type_info.get_java_type_info(),\n+            j_python_data_stream_scalar_function_operator\n+        ))\n+\n+    def flat_map(self, func, type_info=None):\n+        \"\"\"\n+        Applies a FlatMap transformation on a DataStream. The transformation calls a FlatMapFunction\n+        for each element of the DataStream. Each FlatMapFunction call can return any number of\n+        elements including none. The user can also extend RichFlatMapFunction to gain access to\n+        other features provided by the RichFUnction.\n+\n+        :param func: The FlatMapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, FlatMapFunction):\n+            if callable(func):\n+                func = FlatMapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input muster be FlatMapFunction or a callable function\")", "originalCommit": "0bc8a1c9388336bf5eecb6b0e53372c7da00f4f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4ea614633c68f672acca22af3d912c12cde8974c", "url": "https://github.com/apache/flink/commit/4ea614633c68f672acca22af3d912c12cde8974c", "message": "- add fast coders for DataStream stateless functions, resolve part of the review issues.", "committedDate": "2020-08-07T02:28:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5NTQzMw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466795433", "bodyText": "This comment has not been addressed?", "author": "hequn8128", "createdAt": "2020-08-07T03:06:40Z", "path": "flink-python/pyflink/fn_execution/beam/beam_coder_impl_slow.py", "diffHunk": "@@ -186,6 +187,68 @@ def __repr__(self):\n         return 'ArrayCoderImpl[%s]' % repr(self._elem_coder)\n \n \n+class PickledBytesCoderImpl(StreamCoderImpl):\n+\n+    def __init__(self):\n+        self.field_coder = BinaryCoderImpl()\n+\n+    def encode_to_stream(self, value, out_stream, nested):\n+        coded_data = pickle.dumps(value)\n+        real_coded_data = self.field_coder.encode(coded_data)", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5NzEzNA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466797134", "bodyText": "A representation of the Table API Schema", "author": "hequn8128", "createdAt": "2020-08-07T03:13:57Z", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -52,7 +52,23 @@ message UserDefinedFunctions {\n   bool metric_enabled = 2;\n }\n \n-// A representation of the data schema.\n+// User defined DataStream function definition.\n+message UserDefinedDataStreamFunction {\n+  enum FunctionType {\n+    MAP = 0;\n+    FLAT_MAP = 1;\n+  }\n+  FunctionType functionType = 1;\n+  bytes payload = 2;\n+}\n+\n+// A list of user-defined DataStream functions to be executed in a batch.\n+message UserDefinedDataStreamFunctions {\n+  repeated UserDefinedDataStreamFunction udfs = 1;\n+  bool metric_enabled = 2;\n+}\n+\n+// A representation of the DataStream.", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5NzQzOA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466797438", "bodyText": "Please remove the INSTANT type!", "author": "hequn8128", "createdAt": "2020-08-07T03:15:06Z", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -147,3 +163,46 @@ message Schema {\n \n   repeated Field fields = 1;\n }\n+\n+// A representation of the data type information of a DataStream.\n+message TypeInfo {\n+  enum TypeName {\n+    ROW = 0;\n+    STRING = 1;\n+    BYTE = 2;\n+    BOOLEAN = 3;\n+    SHORT = 4;\n+    INT = 5;\n+    LONG = 6;\n+    FLOAT = 7;\n+    DOUBLE = 8;\n+    CHAR = 9;\n+    BIG_INT = 10;\n+    BIG_DEC = 11;\n+    SQL_DATE = 12;\n+    SQL_TIME = 13;\n+    SQL_TIMESTAMP = 14;\n+    INSTANT = 15;", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5ODE4NA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466798184", "bodyText": "A representation of the data type information in DataStream.", "author": "hequn8128", "createdAt": "2020-08-07T03:18:18Z", "path": "flink-python/pyflink/proto/flink-fn-execution.proto", "diffHunk": "@@ -147,3 +163,46 @@ message Schema {\n \n   repeated Field fields = 1;\n }\n+\n+// A representation of the data type information of a DataStream.", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5ODc2MQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466798761", "bodyText": "The comment has not been addressed!\nAdd license text for this class. Please check the test failures", "author": "hequn8128", "createdAt": "2020-08-07T03:20:48Z", "path": "flink-python/src/main/java/org/apache/flink/datastream/runtime/operators/python/DataStreamPythonStatelessFunctionOperator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package org.apache.flink.datastream.runtime.operators.python;", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5OTU1NA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466799554", "bodyText": "The comment has not been addressed!\nKeep one blank between protected and abstract.", "author": "hequn8128", "createdAt": "2020-08-07T03:24:26Z", "path": "flink-python/src/main/java/org/apache/flink/streaming/api/runners/python/beam/BeamPythonStatelessFunctionRunner.java", "diffHunk": "@@ -170,34 +152,11 @@ public ExecutableStage createExecutableStage() throws Exception {\n \t\t\t.build();\n \t}\n \n-\t/**\n-\t * Gets the proto representation of the input coder.\n-\t */\n-\tprivate RunnerApi.Coder getInputCoderProto() {\n-\t\treturn getRowCoderProto(inputType);\n-\t}\n+\tprotected  abstract byte[] getUserDefinedFunctionsProtoBytes();", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc5OTg1OA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466799858", "bodyText": "The comment has not been addressed!\nprivate static final long serialVersionUID = 1L;", "author": "hequn8128", "createdAt": "2020-08-07T03:25:30Z", "path": "flink-python/src/main/java/org/apache/flink/table/runtime/runners/python/beam/BeamTablePythonStatelessFunctionRunner.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.runtime.runners.python.beam;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.fnexecution.v1.FlinkFnApi;\n+import org.apache.flink.python.env.PythonEnvironmentManager;\n+import org.apache.flink.python.metric.FlinkMetricContainer;\n+import org.apache.flink.streaming.api.runners.python.beam.BeamPythonStatelessFunctionRunner;\n+import org.apache.flink.table.runtime.typeutils.PythonTypeUtils;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+\n+import java.util.Map;\n+\n+/**\n+ * A {@link BeamTablePythonStatelessFunctionRunner} used to execute Python stateless functions.\n+ */\n+@Internal\n+public class BeamTablePythonStatelessFunctionRunner extends BeamPythonStatelessFunctionRunner {\n+\n+", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjgwMDM0Mw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466800343", "bodyText": "must be a MapFunction", "author": "hequn8128", "createdAt": "2020-08-07T03:27:35Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +171,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None) \\\n+            -> DataStream:\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be MapFunction or a callable function\")", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjgwMDQxOA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466800418", "bodyText": "a FlatMapFunction", "author": "hequn8128", "createdAt": "2020-08-07T03:27:52Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +171,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None) \\\n+            -> DataStream:\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be MapFunction or a callable function\")\n+        func_name = \"m_map_\" + str(uuid.uuid1())\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(\n+            func_name,\n+            output_type_info.get_java_type_info(),\n+            j_python_data_stream_scalar_function_operator\n+        ))\n+\n+    def flat_map(self, func: Union[Callable, FlatMapFunction], type_info: TypeInformation = None)\\\n+            -> DataStream:\n+        \"\"\"\n+        Applies a FlatMap transformation on a DataStream. The transformation calls a FlatMapFunction\n+        for each element of the DataStream. Each FlatMapFunction call can return any number of\n+        elements including none. The user can also extend RichFlatMapFunction to gain access to\n+        other features provided by the RichFUnction.\n+\n+        :param func: The FlatMapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, FlatMapFunction):\n+            if callable(func):\n+                func = FlatMapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be FlatMapFunction or a callable function\")", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjgwMDk4NQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466800985", "bodyText": "func_name => \"Map\". Keep consistent with Java. Same for flatMap\n        return DataStream(self._j_data_stream.transform(\n            \"Map\",\n            output_type_info.get_java_type_info(),\n            j_python_data_stream_scalar_function_operator\n        ))", "author": "hequn8128", "createdAt": "2020-08-07T03:30:20Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +171,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None) \\\n+            -> DataStream:\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be MapFunction or a callable function\")\n+        func_name = \"m_map_\" + str(uuid.uuid1())\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(", "originalCommit": "4ea614633c68f672acca22af3d912c12cde8974c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5450ead81ef4af74a4f0aa2a25e76a95c39763a1", "url": "https://github.com/apache/flink/commit/5450ead81ef4af74a4f0aa2a25e76a95c39763a1", "message": "- resolve review issues.", "committedDate": "2020-08-07T08:34:02Z", "type": "commit"}, {"oid": "33e5e101da72c7752adc0d8c95cbaf4527312d49", "url": "https://github.com/apache/flink/commit/33e5e101da72c7752adc0d8c95cbaf4527312d49", "message": "- add return type hints for map() and flat_map().", "committedDate": "2020-08-07T08:46:24Z", "type": "commit"}, {"oid": "1744a16bc7b0d5d86df35fae078b68f71bfda1a0", "url": "https://github.com/apache/flink/commit/1744a16bc7b0d5d86df35fae078b68f71bfda1a0", "message": "- resole build error that import google in datastream module.", "committedDate": "2020-08-07T10:37:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkyMTA3MQ==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466921071", "bodyText": "func_name = str(func)\nperform transform with \"Map\"\n\n        func_name = str(func)\n        j_python_data_stream_scalar_function_operator, output_type_info = \\\n            self._get_java_python_function_operator(func,\n                                                    type_info,\n                                                    func_name,\n                                                    flink_fn_execution_pb2\n                                                    .UserDefinedDataStreamFunction.MAP)\n        return DataStream(self._j_data_stream.transform(\n           \"Map\",\n            output_type_info.get_java_type_info(),\n            j_python_data_stream_scalar_function_operator\n        ))", "author": "hequn8128", "createdAt": "2020-08-07T09:12:19Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +169,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be a MapFunction or a callable function\")\n+        func_name = \"Map\"", "originalCommit": "5450ead81ef4af74a4f0aa2a25e76a95c39763a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkyMTUyOA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466921528", "bodyText": "ditto", "author": "hequn8128", "createdAt": "2020-08-07T09:13:20Z", "path": "flink-python/pyflink/datastream/data_stream.py", "diffHunk": "@@ -160,3 +169,122 @@ def set_buffer_timeout(self, timeout_millis: int):\n         \"\"\"\n         self._j_data_stream.setBufferTimeout(timeout_millis)\n         return self\n+\n+    def map(self, func: Union[Callable, MapFunction], type_info: TypeInformation = None):\n+        \"\"\"\n+        Applies a Map transformation on a DataStream. The transformation calls a MapFunction for\n+        each element of the DataStream. Each MapFunction call returns exactly one element. The user\n+        can also extend RichMapFunction to gain access to other features provided by the\n+        RichFunction interface.\n+\n+        Note that If user does not specify the output data type, the output data will be serialized\n+        as pickle primitive byte array.\n+\n+        :param func: The MapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of the MapFunction output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, MapFunction):\n+            if callable(func):\n+                func = MapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be a MapFunction or a callable function\")\n+        func_name = \"Map\"\n+        j_python_data_stream_scalar_function_operator, output_type_info = \\\n+            self._get_java_python_function_operator(func,\n+                                                    type_info,\n+                                                    func_name,\n+                                                    flink_fn_execution_pb2\n+                                                    .UserDefinedDataStreamFunction.MAP)\n+        return DataStream(self._j_data_stream.transform(\n+            func_name,\n+            output_type_info.get_java_type_info(),\n+            j_python_data_stream_scalar_function_operator\n+        ))\n+\n+    def flat_map(self, func: Union[Callable, FlatMapFunction], type_info: TypeInformation = None):\n+        \"\"\"\n+        Applies a FlatMap transformation on a DataStream. The transformation calls a FlatMapFunction\n+        for each element of the DataStream. Each FlatMapFunction call can return any number of\n+        elements including none. The user can also extend RichFlatMapFunction to gain access to\n+        other features provided by the RichFUnction.\n+\n+        :param func: The FlatMapFunction that is called for each element of the DataStream.\n+        :param type_info: The type information of output data.\n+        :return: The transformed DataStream.\n+        \"\"\"\n+        if not isinstance(func, FlatMapFunction):\n+            if callable(func):\n+                func = FlatMapFunctionWrapper(func)\n+            else:\n+                raise TypeError(\"The input must be a FlatMapFunction or a callable function\")\n+        func_name = \"m_flat_map\" + str(uuid.uuid1())", "originalCommit": "5450ead81ef4af74a4f0aa2a25e76a95c39763a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkyMzE3Mw==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466923173", "bodyText": "MapFUnction => MapFunction", "author": "hequn8128", "createdAt": "2020-08-07T09:16:46Z", "path": "flink-python/pyflink/datastream/functions.py", "diffHunk": "@@ -0,0 +1,149 @@\n+################################################################################\n+#  Licensed to the Apache Software Foundation (ASF) under one\n+#  or more contributor license agreements.  See the NOTICE file\n+#  distributed with this work for additional information\n+#  regarding copyright ownership.  The ASF licenses this file\n+#  to you under the Apache License, Version 2.0 (the\n+#  \"License\"); you may not use this file except in compliance\n+#  with the License.  You may obtain a copy of the License at\n+#\n+#      http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#  Unless required by applicable law or agreed to in writing, software\n+#  distributed under the License is distributed on an \"AS IS\" BASIS,\n+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#  See the License for the specific language governing permissions and\n+# limitations under the License.\n+################################################################################\n+\n+import abc\n+\n+from pyflink.java_gateway import get_gateway\n+\n+\n+class Function(abc.ABC):\n+    \"\"\"\n+    The base class for all user-defined functions.\n+    \"\"\"\n+    pass\n+\n+\n+class MapFunction(Function):\n+    \"\"\"\n+    Base class for Map functions. Map functions take elements and transform them, element wise. A\n+    Map function always produces a single result element for each input element. Typical\n+    applications are parsing elements, converting data types, or projecting out fields. Operations\n+    that produce multiple result elements from a single input element can be implemented using the\n+    FlatMapFunction.\n+    The basic syntax for using a MapFUnction is as follows:", "originalCommit": "33e5e101da72c7752adc0d8c95cbaf4527312d49", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkzOTU0NA==", "url": "https://github.com/apache/flink/pull/13066#discussion_r466939544", "bodyText": "remove the unnecessary change", "author": "hequn8128", "createdAt": "2020-08-07T09:49:58Z", "path": "flink-python/pyflink/fn_execution/beam/beam_coders.py", "diffHunk": "@@ -17,6 +17,7 @@\n ################################################################################\n \n import os\n+", "originalCommit": "33e5e101da72c7752adc0d8c95cbaf4527312d49", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e412f8bec1d8dfa0ef317d8b9048b61935f1dfc1", "url": "https://github.com/apache/flink/commit/e412f8bec1d8dfa0ef317d8b9048b61935f1dfc1", "message": "- resolved review issues.", "committedDate": "2020-08-07T11:29:13Z", "type": "commit"}]}