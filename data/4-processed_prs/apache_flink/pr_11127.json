{"pr_number": 11127, "pr_title": "[FLINK-16081][docs] Translate /dev/table/index.zh.md", "pr_createdAt": "2020-02-18T15:36:16Z", "pr_url": "https://github.com/apache/flink/pull/11127", "timeline": [{"oid": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "url": "https://github.com/apache/flink/commit/22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "message": "[FLINK-16081][docs] Translate /dev/table/streaming/index.zh.md", "committedDate": "2020-02-18T15:34:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQwODQxMw==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382408413", "bodyText": "Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API sounds a little weird.\nHow about Table API \u662f\u7528\u4e8e Scala \u548c Java \u8bed\u8a00\u7684\u67e5\u8be2API.", "author": "JingsongLi", "createdAt": "2020-02-21T05:51:45Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -25,41 +25,41 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Apache Flink features two relational APIs - the Table API and SQL - for unified stream and batch processing. The Table API is a language-integrated query API for Scala and Java that allows the composition of queries from relational operators such as selection, filter, and join in a very intuitive way. Flink's SQL support is based on [Apache Calcite](https://calcite.apache.org) which implements the SQL standard. Queries specified in either interface have the same semantics and specify the same result regardless whether the input is a batch input (DataSet) or a stream input (DataStream).\n+Apache Flink \u6709\u4e24\u79cd\u5173\u7cfb\u578b API \u6765\u505a\u6d41\u6279\u7edf\u4e00\u5904\u7406\uff1aTable API \u548c SQL\u3002Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API\uff0c\u5b83\u53ef\u4ee5\u7528\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7ec4\u5408\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49\u5173\u7cfb\u578b\u7b97\u5b50\u3002Flink SQL \u662f\u57fa\u4e8e [Apache Calcite](https://calcite.apache.org) \u6765\u5b9e\u73b0\u7684\u6807\u51c6 SQL\u3002\u8fd9\u4e24\u79cd API \u4e2d\u7684\u67e5\u8be2\u5bf9\u4e8e\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09\u7684\u8f93\u5165\u6709\u76f8\u540c\u7684\u8bed\u4e49\uff0c\u4e5f\u4f1a\u4ea7\u751f\u540c\u6837\u7684\u8ba1\u7b97\u7ed3\u679c\u3002", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQwODkwMA==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382408900", "bodyText": "\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49 -> remove \u4f8b\u5982? It seems there is a \u7b49 to cover this semantic.", "author": "JingsongLi", "createdAt": "2020-02-21T05:54:21Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -25,41 +25,41 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Apache Flink features two relational APIs - the Table API and SQL - for unified stream and batch processing. The Table API is a language-integrated query API for Scala and Java that allows the composition of queries from relational operators such as selection, filter, and join in a very intuitive way. Flink's SQL support is based on [Apache Calcite](https://calcite.apache.org) which implements the SQL standard. Queries specified in either interface have the same semantics and specify the same result regardless whether the input is a batch input (DataSet) or a stream input (DataStream).\n+Apache Flink \u6709\u4e24\u79cd\u5173\u7cfb\u578b API \u6765\u505a\u6d41\u6279\u7edf\u4e00\u5904\u7406\uff1aTable API \u548c SQL\u3002Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API\uff0c\u5b83\u53ef\u4ee5\u7528\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7ec4\u5408\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49\u5173\u7cfb\u578b\u7b97\u5b50\u3002Flink SQL \u662f\u57fa\u4e8e [Apache Calcite](https://calcite.apache.org) \u6765\u5b9e\u73b0\u7684\u6807\u51c6 SQL\u3002\u8fd9\u4e24\u79cd API \u4e2d\u7684\u67e5\u8be2\u5bf9\u4e8e\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09\u7684\u8f93\u5165\u6709\u76f8\u540c\u7684\u8bed\u4e49\uff0c\u4e5f\u4f1a\u4ea7\u751f\u540c\u6837\u7684\u8ba1\u7b97\u7ed3\u679c\u3002", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQwOTI4Nw==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382409287", "bodyText": "\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09 -> add \u548c in middle?", "author": "JingsongLi", "createdAt": "2020-02-21T05:56:19Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -25,41 +25,41 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Apache Flink features two relational APIs - the Table API and SQL - for unified stream and batch processing. The Table API is a language-integrated query API for Scala and Java that allows the composition of queries from relational operators such as selection, filter, and join in a very intuitive way. Flink's SQL support is based on [Apache Calcite](https://calcite.apache.org) which implements the SQL standard. Queries specified in either interface have the same semantics and specify the same result regardless whether the input is a batch input (DataSet) or a stream input (DataStream).\n+Apache Flink \u6709\u4e24\u79cd\u5173\u7cfb\u578b API \u6765\u505a\u6d41\u6279\u7edf\u4e00\u5904\u7406\uff1aTable API \u548c SQL\u3002Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API\uff0c\u5b83\u53ef\u4ee5\u7528\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7ec4\u5408\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49\u5173\u7cfb\u578b\u7b97\u5b50\u3002Flink SQL \u662f\u57fa\u4e8e [Apache Calcite](https://calcite.apache.org) \u6765\u5b9e\u73b0\u7684\u6807\u51c6 SQL\u3002\u8fd9\u4e24\u79cd API \u4e2d\u7684\u67e5\u8be2\u5bf9\u4e8e\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09\u7684\u8f93\u5165\u6709\u76f8\u540c\u7684\u8bed\u4e49\uff0c\u4e5f\u4f1a\u4ea7\u751f\u540c\u6837\u7684\u8ba1\u7b97\u7ed3\u679c\u3002", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQwOTkwNA==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382409904", "bodyText": "Planner\u5927\u5199\u9996\u5b57\u6bcd", "author": "JingsongLi", "createdAt": "2020-02-21T05:59:22Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -25,41 +25,41 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Apache Flink features two relational APIs - the Table API and SQL - for unified stream and batch processing. The Table API is a language-integrated query API for Scala and Java that allows the composition of queries from relational operators such as selection, filter, and join in a very intuitive way. Flink's SQL support is based on [Apache Calcite](https://calcite.apache.org) which implements the SQL standard. Queries specified in either interface have the same semantics and specify the same result regardless whether the input is a batch input (DataSet) or a stream input (DataStream).\n+Apache Flink \u6709\u4e24\u79cd\u5173\u7cfb\u578b API \u6765\u505a\u6d41\u6279\u7edf\u4e00\u5904\u7406\uff1aTable API \u548c SQL\u3002Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API\uff0c\u5b83\u53ef\u4ee5\u7528\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7ec4\u5408\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49\u5173\u7cfb\u578b\u7b97\u5b50\u3002Flink SQL \u662f\u57fa\u4e8e [Apache Calcite](https://calcite.apache.org) \u6765\u5b9e\u73b0\u7684\u6807\u51c6 SQL\u3002\u8fd9\u4e24\u79cd API \u4e2d\u7684\u67e5\u8be2\u5bf9\u4e8e\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09\u7684\u8f93\u5165\u6709\u76f8\u540c\u7684\u8bed\u4e49\uff0c\u4e5f\u4f1a\u4ea7\u751f\u540c\u6837\u7684\u8ba1\u7b97\u7ed3\u679c\u3002\n \n-The Table API and the SQL interfaces are tightly integrated with each other as well as Flink's DataStream and DataSet APIs. You can easily switch between all APIs and libraries which build upon the APIs. For instance, you can extract patterns from a DataStream using the [CEP library]({{ site.baseurl }}/dev/libs/cep.html) and later use the Table API to analyze the patterns, or you might scan, filter, and aggregate a batch table using a SQL query before running a [Gelly graph algorithm]({{ site.baseurl }}/dev/libs/gelly) on the preprocessed data.\n+Table API \u548c SQL \u4e24\u79cd API \u662f\u7d27\u5bc6\u96c6\u6210\u7684\uff0c\u4ee5\u53ca DataStream \u548c DataSet API\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u4e9b API \u4e4b\u95f4\uff0c\u4ee5\u53ca\u4e00\u4e9b\u57fa\u4e8e\u8fd9\u4e9b API \u7684\u5e93\u4e4b\u95f4\u8f7b\u677e\u7684\u5207\u6362\u3002\u6bd4\u5982\uff0c\u4f60\u53ef\u4ee5\u5148\u7528 [CEP]({{ site.baseurl }}/zh/dev/libs/cep.html) \u4ece DataStream \u4e2d\u505a\u6a21\u5f0f\u5339\u914d\uff0c\u7136\u540e\u7528 Table API \u6765\u5206\u6790\u5339\u914d\u7684\u7ed3\u679c\uff1b\u6216\u8005\u4f60\u53ef\u4ee5\u7528 SQL \u6765\u626b\u63cf\u3001\u8fc7\u6ee4\u3001\u805a\u5408\u4e00\u4e2a\u6279\u5f0f\u7684\u8868\uff0c\u7136\u540e\u518d\u8dd1\u4e00\u4e2a [Gelly \u56fe\u7b97\u6cd5]({{ site.baseurl }}/zh/dev/libs/gelly) \u6765\u5904\u7406\u5df2\u7ecf\u9884\u5904\u7406\u597d\u7684\u6570\u636e\u3002\n \n-**Please note that the Table API and SQL are not yet feature complete and are being actively developed. Not all operations are supported by every combination of \\[Table API, SQL\\] and \\[stream, batch\\] input.**\n+**\u6ce8\u610f\uff1aTable API \u548c SQL \u73b0\u5728\u8fd8\u5904\u4e8e\u6d3b\u8dc3\u5f00\u53d1\u9636\u6bb5\uff0c\u8fd8\u6ca1\u6709\u5b8c\u5168\u5b9e\u73b0\u6240\u6709\u7684\u7279\u6027\u3002\u4e0d\u662f\u6240\u6709\u7684 \\[Table API\uff0cSQL\\] \u548c \\[\u6d41\uff0c\u6279\\] \u7684\u7ec4\u5408\u90fd\u662f\u652f\u6301\u7684\u3002**\n \n-Dependency Structure\n+\u4f9d\u8d56\u56fe\n --------------------\n \n-Starting from Flink 1.9, Flink provides two different planner implementations for evaluating Table & SQL API programs: the Blink planner and the old planner that was available before Flink 1.9. Planners are responsible for\n-translating relational operators into an executable, optimized Flink job. Both of the planners come with different optimization rules and runtime classes.\n-They may also differ in the set of supported features.\n+\u4ece1.9\u5f00\u59cb\uff0cFlink \u63d0\u4f9b\u4e86\u4e24\u4e2a table planner \u5b9e\u73b0\u6765\u6267\u884c Table API \u548c SQL \u7a0b\u5e8f\uff1aBlink planner \u548c old planner\uff0cold planner \u57281.9\u4e4b\u524d\u5c31\u5df2\u7ecf\u5b58\u5728\u4e86\u3002\n+planner \u7684\u4f5c\u7528\u4e3b\u8981\u662f\u628a\u5173\u7cfb\u578b\u7684\u64cd\u4f5c\u7ffb\u8bd1\u6210\u53ef\u6267\u884c\u7684\u3001\u7ecf\u8fc7\u4f18\u5316\u7684 Flink job\u3002\u8fd9\u4e24\u4e2a planner \u6240\u4f7f\u7528\u7684\u4f18\u5316\u89c4\u5219\u4ee5\u53ca\u8fd0\u884c\u65f6\u90fd\u4e0d\u4e00\u6837\u3002", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQwOTk5OQ==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382409999", "bodyText": "\u8fd0\u884c\u65f6\u7c7b", "author": "JingsongLi", "createdAt": "2020-02-21T05:59:59Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -25,41 +25,41 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Apache Flink features two relational APIs - the Table API and SQL - for unified stream and batch processing. The Table API is a language-integrated query API for Scala and Java that allows the composition of queries from relational operators such as selection, filter, and join in a very intuitive way. Flink's SQL support is based on [Apache Calcite](https://calcite.apache.org) which implements the SQL standard. Queries specified in either interface have the same semantics and specify the same result regardless whether the input is a batch input (DataSet) or a stream input (DataStream).\n+Apache Flink \u6709\u4e24\u79cd\u5173\u7cfb\u578b API \u6765\u505a\u6d41\u6279\u7edf\u4e00\u5904\u7406\uff1aTable API \u548c SQL\u3002Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API\uff0c\u5b83\u53ef\u4ee5\u7528\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7ec4\u5408\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49\u5173\u7cfb\u578b\u7b97\u5b50\u3002Flink SQL \u662f\u57fa\u4e8e [Apache Calcite](https://calcite.apache.org) \u6765\u5b9e\u73b0\u7684\u6807\u51c6 SQL\u3002\u8fd9\u4e24\u79cd API \u4e2d\u7684\u67e5\u8be2\u5bf9\u4e8e\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09\u7684\u8f93\u5165\u6709\u76f8\u540c\u7684\u8bed\u4e49\uff0c\u4e5f\u4f1a\u4ea7\u751f\u540c\u6837\u7684\u8ba1\u7b97\u7ed3\u679c\u3002\n \n-The Table API and the SQL interfaces are tightly integrated with each other as well as Flink's DataStream and DataSet APIs. You can easily switch between all APIs and libraries which build upon the APIs. For instance, you can extract patterns from a DataStream using the [CEP library]({{ site.baseurl }}/dev/libs/cep.html) and later use the Table API to analyze the patterns, or you might scan, filter, and aggregate a batch table using a SQL query before running a [Gelly graph algorithm]({{ site.baseurl }}/dev/libs/gelly) on the preprocessed data.\n+Table API \u548c SQL \u4e24\u79cd API \u662f\u7d27\u5bc6\u96c6\u6210\u7684\uff0c\u4ee5\u53ca DataStream \u548c DataSet API\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u4e9b API \u4e4b\u95f4\uff0c\u4ee5\u53ca\u4e00\u4e9b\u57fa\u4e8e\u8fd9\u4e9b API \u7684\u5e93\u4e4b\u95f4\u8f7b\u677e\u7684\u5207\u6362\u3002\u6bd4\u5982\uff0c\u4f60\u53ef\u4ee5\u5148\u7528 [CEP]({{ site.baseurl }}/zh/dev/libs/cep.html) \u4ece DataStream \u4e2d\u505a\u6a21\u5f0f\u5339\u914d\uff0c\u7136\u540e\u7528 Table API \u6765\u5206\u6790\u5339\u914d\u7684\u7ed3\u679c\uff1b\u6216\u8005\u4f60\u53ef\u4ee5\u7528 SQL \u6765\u626b\u63cf\u3001\u8fc7\u6ee4\u3001\u805a\u5408\u4e00\u4e2a\u6279\u5f0f\u7684\u8868\uff0c\u7136\u540e\u518d\u8dd1\u4e00\u4e2a [Gelly \u56fe\u7b97\u6cd5]({{ site.baseurl }}/zh/dev/libs/gelly) \u6765\u5904\u7406\u5df2\u7ecf\u9884\u5904\u7406\u597d\u7684\u6570\u636e\u3002\n \n-**Please note that the Table API and SQL are not yet feature complete and are being actively developed. Not all operations are supported by every combination of \\[Table API, SQL\\] and \\[stream, batch\\] input.**\n+**\u6ce8\u610f\uff1aTable API \u548c SQL \u73b0\u5728\u8fd8\u5904\u4e8e\u6d3b\u8dc3\u5f00\u53d1\u9636\u6bb5\uff0c\u8fd8\u6ca1\u6709\u5b8c\u5168\u5b9e\u73b0\u6240\u6709\u7684\u7279\u6027\u3002\u4e0d\u662f\u6240\u6709\u7684 \\[Table API\uff0cSQL\\] \u548c \\[\u6d41\uff0c\u6279\\] \u7684\u7ec4\u5408\u90fd\u662f\u652f\u6301\u7684\u3002**\n \n-Dependency Structure\n+\u4f9d\u8d56\u56fe\n --------------------\n \n-Starting from Flink 1.9, Flink provides two different planner implementations for evaluating Table & SQL API programs: the Blink planner and the old planner that was available before Flink 1.9. Planners are responsible for\n-translating relational operators into an executable, optimized Flink job. Both of the planners come with different optimization rules and runtime classes.\n-They may also differ in the set of supported features.\n+\u4ece1.9\u5f00\u59cb\uff0cFlink \u63d0\u4f9b\u4e86\u4e24\u4e2a table planner \u5b9e\u73b0\u6765\u6267\u884c Table API \u548c SQL \u7a0b\u5e8f\uff1aBlink planner \u548c old planner\uff0cold planner \u57281.9\u4e4b\u524d\u5c31\u5df2\u7ecf\u5b58\u5728\u4e86\u3002\n+planner \u7684\u4f5c\u7528\u4e3b\u8981\u662f\u628a\u5173\u7cfb\u578b\u7684\u64cd\u4f5c\u7ffb\u8bd1\u6210\u53ef\u6267\u884c\u7684\u3001\u7ecf\u8fc7\u4f18\u5316\u7684 Flink job\u3002\u8fd9\u4e24\u4e2a planner \u6240\u4f7f\u7528\u7684\u4f18\u5316\u89c4\u5219\u4ee5\u53ca\u8fd0\u884c\u65f6\u90fd\u4e0d\u4e00\u6837\u3002", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQxMDAzOA==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382410038", "bodyText": "\u5dee\u5f02", "author": "JingsongLi", "createdAt": "2020-02-21T06:00:11Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -25,41 +25,41 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Apache Flink features two relational APIs - the Table API and SQL - for unified stream and batch processing. The Table API is a language-integrated query API for Scala and Java that allows the composition of queries from relational operators such as selection, filter, and join in a very intuitive way. Flink's SQL support is based on [Apache Calcite](https://calcite.apache.org) which implements the SQL standard. Queries specified in either interface have the same semantics and specify the same result regardless whether the input is a batch input (DataSet) or a stream input (DataStream).\n+Apache Flink \u6709\u4e24\u79cd\u5173\u7cfb\u578b API \u6765\u505a\u6d41\u6279\u7edf\u4e00\u5904\u7406\uff1aTable API \u548c SQL\u3002Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API\uff0c\u5b83\u53ef\u4ee5\u7528\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7ec4\u5408\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49\u5173\u7cfb\u578b\u7b97\u5b50\u3002Flink SQL \u662f\u57fa\u4e8e [Apache Calcite](https://calcite.apache.org) \u6765\u5b9e\u73b0\u7684\u6807\u51c6 SQL\u3002\u8fd9\u4e24\u79cd API \u4e2d\u7684\u67e5\u8be2\u5bf9\u4e8e\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09\u7684\u8f93\u5165\u6709\u76f8\u540c\u7684\u8bed\u4e49\uff0c\u4e5f\u4f1a\u4ea7\u751f\u540c\u6837\u7684\u8ba1\u7b97\u7ed3\u679c\u3002\n \n-The Table API and the SQL interfaces are tightly integrated with each other as well as Flink's DataStream and DataSet APIs. You can easily switch between all APIs and libraries which build upon the APIs. For instance, you can extract patterns from a DataStream using the [CEP library]({{ site.baseurl }}/dev/libs/cep.html) and later use the Table API to analyze the patterns, or you might scan, filter, and aggregate a batch table using a SQL query before running a [Gelly graph algorithm]({{ site.baseurl }}/dev/libs/gelly) on the preprocessed data.\n+Table API \u548c SQL \u4e24\u79cd API \u662f\u7d27\u5bc6\u96c6\u6210\u7684\uff0c\u4ee5\u53ca DataStream \u548c DataSet API\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u4e9b API \u4e4b\u95f4\uff0c\u4ee5\u53ca\u4e00\u4e9b\u57fa\u4e8e\u8fd9\u4e9b API \u7684\u5e93\u4e4b\u95f4\u8f7b\u677e\u7684\u5207\u6362\u3002\u6bd4\u5982\uff0c\u4f60\u53ef\u4ee5\u5148\u7528 [CEP]({{ site.baseurl }}/zh/dev/libs/cep.html) \u4ece DataStream \u4e2d\u505a\u6a21\u5f0f\u5339\u914d\uff0c\u7136\u540e\u7528 Table API \u6765\u5206\u6790\u5339\u914d\u7684\u7ed3\u679c\uff1b\u6216\u8005\u4f60\u53ef\u4ee5\u7528 SQL \u6765\u626b\u63cf\u3001\u8fc7\u6ee4\u3001\u805a\u5408\u4e00\u4e2a\u6279\u5f0f\u7684\u8868\uff0c\u7136\u540e\u518d\u8dd1\u4e00\u4e2a [Gelly \u56fe\u7b97\u6cd5]({{ site.baseurl }}/zh/dev/libs/gelly) \u6765\u5904\u7406\u5df2\u7ecf\u9884\u5904\u7406\u597d\u7684\u6570\u636e\u3002\n \n-**Please note that the Table API and SQL are not yet feature complete and are being actively developed. Not all operations are supported by every combination of \\[Table API, SQL\\] and \\[stream, batch\\] input.**\n+**\u6ce8\u610f\uff1aTable API \u548c SQL \u73b0\u5728\u8fd8\u5904\u4e8e\u6d3b\u8dc3\u5f00\u53d1\u9636\u6bb5\uff0c\u8fd8\u6ca1\u6709\u5b8c\u5168\u5b9e\u73b0\u6240\u6709\u7684\u7279\u6027\u3002\u4e0d\u662f\u6240\u6709\u7684 \\[Table API\uff0cSQL\\] \u548c \\[\u6d41\uff0c\u6279\\] \u7684\u7ec4\u5408\u90fd\u662f\u652f\u6301\u7684\u3002**\n \n-Dependency Structure\n+\u4f9d\u8d56\u56fe\n --------------------\n \n-Starting from Flink 1.9, Flink provides two different planner implementations for evaluating Table & SQL API programs: the Blink planner and the old planner that was available before Flink 1.9. Planners are responsible for\n-translating relational operators into an executable, optimized Flink job. Both of the planners come with different optimization rules and runtime classes.\n-They may also differ in the set of supported features.\n+\u4ece1.9\u5f00\u59cb\uff0cFlink \u63d0\u4f9b\u4e86\u4e24\u4e2a table planner \u5b9e\u73b0\u6765\u6267\u884c Table API \u548c SQL \u7a0b\u5e8f\uff1aBlink planner \u548c old planner\uff0cold planner \u57281.9\u4e4b\u524d\u5c31\u5df2\u7ecf\u5b58\u5728\u4e86\u3002\n+planner \u7684\u4f5c\u7528\u4e3b\u8981\u662f\u628a\u5173\u7cfb\u578b\u7684\u64cd\u4f5c\u7ffb\u8bd1\u6210\u53ef\u6267\u884c\u7684\u3001\u7ecf\u8fc7\u4f18\u5316\u7684 Flink job\u3002\u8fd9\u4e24\u4e2a planner \u6240\u4f7f\u7528\u7684\u4f18\u5316\u89c4\u5219\u4ee5\u53ca\u8fd0\u884c\u65f6\u90fd\u4e0d\u4e00\u6837\u3002\n+\u5b83\u4eec\u5728\u652f\u6301\u7684\u529f\u80fd\u4e0a\u4e5f\u6709\u4e9b\u8be7\u5f02\u3002", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQxMDY0Nw==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382410647", "bodyText": "Table \u548c SQL API\uff0c\u4e5f\u652f\u6301 DataStream/DataSet API\uff0c\u597d\u50cf\u4e0d\u662f\u8fd9\u4e2a\u610f\u601d\uff0c\u662fTable/SQL API\u7ed3\u5408DataStream/DataSet\u4e00\u8d77\u7528\u7684\u7528\u6cd5\u3002", "author": "JingsongLi", "createdAt": "2020-02-21T06:02:37Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -25,41 +25,41 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Apache Flink features two relational APIs - the Table API and SQL - for unified stream and batch processing. The Table API is a language-integrated query API for Scala and Java that allows the composition of queries from relational operators such as selection, filter, and join in a very intuitive way. Flink's SQL support is based on [Apache Calcite](https://calcite.apache.org) which implements the SQL standard. Queries specified in either interface have the same semantics and specify the same result regardless whether the input is a batch input (DataSet) or a stream input (DataStream).\n+Apache Flink \u6709\u4e24\u79cd\u5173\u7cfb\u578b API \u6765\u505a\u6d41\u6279\u7edf\u4e00\u5904\u7406\uff1aTable API \u548c SQL\u3002Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API\uff0c\u5b83\u53ef\u4ee5\u7528\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7ec4\u5408\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49\u5173\u7cfb\u578b\u7b97\u5b50\u3002Flink SQL \u662f\u57fa\u4e8e [Apache Calcite](https://calcite.apache.org) \u6765\u5b9e\u73b0\u7684\u6807\u51c6 SQL\u3002\u8fd9\u4e24\u79cd API \u4e2d\u7684\u67e5\u8be2\u5bf9\u4e8e\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09\u7684\u8f93\u5165\u6709\u76f8\u540c\u7684\u8bed\u4e49\uff0c\u4e5f\u4f1a\u4ea7\u751f\u540c\u6837\u7684\u8ba1\u7b97\u7ed3\u679c\u3002\n \n-The Table API and the SQL interfaces are tightly integrated with each other as well as Flink's DataStream and DataSet APIs. You can easily switch between all APIs and libraries which build upon the APIs. For instance, you can extract patterns from a DataStream using the [CEP library]({{ site.baseurl }}/dev/libs/cep.html) and later use the Table API to analyze the patterns, or you might scan, filter, and aggregate a batch table using a SQL query before running a [Gelly graph algorithm]({{ site.baseurl }}/dev/libs/gelly) on the preprocessed data.\n+Table API \u548c SQL \u4e24\u79cd API \u662f\u7d27\u5bc6\u96c6\u6210\u7684\uff0c\u4ee5\u53ca DataStream \u548c DataSet API\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u4e9b API \u4e4b\u95f4\uff0c\u4ee5\u53ca\u4e00\u4e9b\u57fa\u4e8e\u8fd9\u4e9b API \u7684\u5e93\u4e4b\u95f4\u8f7b\u677e\u7684\u5207\u6362\u3002\u6bd4\u5982\uff0c\u4f60\u53ef\u4ee5\u5148\u7528 [CEP]({{ site.baseurl }}/zh/dev/libs/cep.html) \u4ece DataStream \u4e2d\u505a\u6a21\u5f0f\u5339\u914d\uff0c\u7136\u540e\u7528 Table API \u6765\u5206\u6790\u5339\u914d\u7684\u7ed3\u679c\uff1b\u6216\u8005\u4f60\u53ef\u4ee5\u7528 SQL \u6765\u626b\u63cf\u3001\u8fc7\u6ee4\u3001\u805a\u5408\u4e00\u4e2a\u6279\u5f0f\u7684\u8868\uff0c\u7136\u540e\u518d\u8dd1\u4e00\u4e2a [Gelly \u56fe\u7b97\u6cd5]({{ site.baseurl }}/zh/dev/libs/gelly) \u6765\u5904\u7406\u5df2\u7ecf\u9884\u5904\u7406\u597d\u7684\u6570\u636e\u3002\n \n-**Please note that the Table API and SQL are not yet feature complete and are being actively developed. Not all operations are supported by every combination of \\[Table API, SQL\\] and \\[stream, batch\\] input.**\n+**\u6ce8\u610f\uff1aTable API \u548c SQL \u73b0\u5728\u8fd8\u5904\u4e8e\u6d3b\u8dc3\u5f00\u53d1\u9636\u6bb5\uff0c\u8fd8\u6ca1\u6709\u5b8c\u5168\u5b9e\u73b0\u6240\u6709\u7684\u7279\u6027\u3002\u4e0d\u662f\u6240\u6709\u7684 \\[Table API\uff0cSQL\\] \u548c \\[\u6d41\uff0c\u6279\\] \u7684\u7ec4\u5408\u90fd\u662f\u652f\u6301\u7684\u3002**\n \n-Dependency Structure\n+\u4f9d\u8d56\u56fe\n --------------------\n \n-Starting from Flink 1.9, Flink provides two different planner implementations for evaluating Table & SQL API programs: the Blink planner and the old planner that was available before Flink 1.9. Planners are responsible for\n-translating relational operators into an executable, optimized Flink job. Both of the planners come with different optimization rules and runtime classes.\n-They may also differ in the set of supported features.\n+\u4ece1.9\u5f00\u59cb\uff0cFlink \u63d0\u4f9b\u4e86\u4e24\u4e2a table planner \u5b9e\u73b0\u6765\u6267\u884c Table API \u548c SQL \u7a0b\u5e8f\uff1aBlink planner \u548c old planner\uff0cold planner \u57281.9\u4e4b\u524d\u5c31\u5df2\u7ecf\u5b58\u5728\u4e86\u3002\n+planner \u7684\u4f5c\u7528\u4e3b\u8981\u662f\u628a\u5173\u7cfb\u578b\u7684\u64cd\u4f5c\u7ffb\u8bd1\u6210\u53ef\u6267\u884c\u7684\u3001\u7ecf\u8fc7\u4f18\u5316\u7684 Flink job\u3002\u8fd9\u4e24\u4e2a planner \u6240\u4f7f\u7528\u7684\u4f18\u5316\u89c4\u5219\u4ee5\u53ca\u8fd0\u884c\u65f6\u90fd\u4e0d\u4e00\u6837\u3002\n+\u5b83\u4eec\u5728\u652f\u6301\u7684\u529f\u80fd\u4e0a\u4e5f\u6709\u4e9b\u8be7\u5f02\u3002\n \n-<span class=\"label label-danger\">Attention</span> For production use cases, we recommend the old planner that was present before Flink 1.9 for now.\n+<span class=\"label label-danger\">\u6ce8\u610f</span> \u5bf9\u4e8e\u751f\u4ea7\u73af\u5883\uff0c\u6211\u4eec\u5efa\u8bae\u4f7f\u7528\u57281.9\u4e4b\u524d\u5c31\u5df2\u7ecf\u5b58\u5728\u7684 old planner\u3002\n \n-All Table API and SQL components are bundled in the `flink-table` or `flink-table-blink` Maven artifacts.\n+\u6240\u6709\u7684 Table API \u548c SQL \u7684\u4ee3\u7801\u90fd\u5728 `flink-table` \u6216\u8005 `flink-table-blink` Maven artifacts \u4e0b\u3002\n \n-The following dependencies are relevant for most projects:\n+\u4e0b\u9762\u662f\u5404\u4e2a\u4f9d\u8d56\uff1a\n \n-* `flink-table-common`: A common module for extending the table ecosystem by custom functions, formats, etc.\n-* `flink-table-api-java`: The Table & SQL API for pure table programs using the Java programming language (in early development stage, not recommended!).\n-* `flink-table-api-scala`: The Table & SQL API for pure table programs using the Scala programming language (in early development stage, not recommended!).\n-* `flink-table-api-java-bridge`: The Table & SQL API with DataStream/DataSet API support using the Java programming language.\n-* `flink-table-api-scala-bridge`: The Table & SQL API with DataStream/DataSet API support using the Scala programming language.\n-* `flink-table-planner`: The table program planner and runtime. This was the only planner of Flink before the 1.9 release. It is still the recommended one.\n-* `flink-table-planner-blink`: The new Blink planner.\n-* `flink-table-runtime-blink`: The new Blink runtime.\n-* `flink-table-uber`: Packages the API modules above plus the old planner into a distribution for most Table & SQL API use cases. The uber JAR file `flink-table-*.jar` is located in the `/lib` directory of a Flink release by default.\n-* `flink-table-uber-blink`: Packages the API modules above plus the Blink specific modules into a distribution for most Table & SQL API use cases. The uber JAR file `flink-table-blink-*.jar` is located in the `/lib` directory of a Flink release by default.\n+* `flink-table-common`: \u516c\u5171\u6a21\u5757\uff0c\u6bd4\u5982\u81ea\u5b9a\u4e49\u51fd\u6570\u3001\u683c\u5f0f\u7b49\u9700\u8981\u4f9d\u8d56\u7684\u3002\n+* `flink-table-api-java`: Table \u548c SQL API\uff0c\u4f7f\u7528 Java \u8bed\u8a00\u7f16\u5199\u7684\uff0c\u7ed9\u7eaf table \u7a0b\u5e8f\u4f7f\u7528\uff08\u8fd8\u5728\u65e9\u671f\u5f00\u53d1\u9636\u6bb5\uff0c\u4e0d\u5efa\u8bae\u4f7f\u7528\uff09\n+* `flink-table-api-scala`: Table \u548c SQL API\uff0c\u4f7f\u7528 Scala \u8bed\u8a00\u7f16\u5199\u7684\uff0c\u7ed9\u7eaf table \u7a0b\u5e8f\u4f7f\u7528\uff08\u8fd8\u5728\u65e9\u671f\u5f00\u53d1\u9636\u6bb5\uff0c\u4e0d\u5efa\u8bae\u4f7f\u7528\uff09\n+* `flink-table-api-java-bridge`: Table \u548c SQL API\uff0c\u4e5f\u652f\u6301 DataStream/DataSet API\uff0c\u7ed9 Java \u8bed\u8a00\u4f7f\u7528\u3002", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQxMTEwNg==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382411106", "bodyText": "\u6784\u5efa\u4f60\u7684Table API\u548cSQL\u7684\u7a0b\u5e8f\uff1f", "author": "JingsongLi", "createdAt": "2020-02-21T06:04:51Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -25,41 +25,41 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Apache Flink features two relational APIs - the Table API and SQL - for unified stream and batch processing. The Table API is a language-integrated query API for Scala and Java that allows the composition of queries from relational operators such as selection, filter, and join in a very intuitive way. Flink's SQL support is based on [Apache Calcite](https://calcite.apache.org) which implements the SQL standard. Queries specified in either interface have the same semantics and specify the same result regardless whether the input is a batch input (DataSet) or a stream input (DataStream).\n+Apache Flink \u6709\u4e24\u79cd\u5173\u7cfb\u578b API \u6765\u505a\u6d41\u6279\u7edf\u4e00\u5904\u7406\uff1aTable API \u548c SQL\u3002Table API \u662f\u96c6\u6210\u4e8e Java \u548c Scala \u7684\u67e5\u8be2 API\uff0c\u5b83\u53ef\u4ee5\u7528\u4e00\u79cd\u975e\u5e38\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u7ec4\u5408\u4f7f\u7528\u4f8b\u5982\u9009\u53d6\u3001\u8fc7\u6ee4\u3001join \u7b49\u5173\u7cfb\u578b\u7b97\u5b50\u3002Flink SQL \u662f\u57fa\u4e8e [Apache Calcite](https://calcite.apache.org) \u6765\u5b9e\u73b0\u7684\u6807\u51c6 SQL\u3002\u8fd9\u4e24\u79cd API \u4e2d\u7684\u67e5\u8be2\u5bf9\u4e8e\u6279\uff08DataSet\uff09\u6d41\uff08DataStream\uff09\u7684\u8f93\u5165\u6709\u76f8\u540c\u7684\u8bed\u4e49\uff0c\u4e5f\u4f1a\u4ea7\u751f\u540c\u6837\u7684\u8ba1\u7b97\u7ed3\u679c\u3002\n \n-The Table API and the SQL interfaces are tightly integrated with each other as well as Flink's DataStream and DataSet APIs. You can easily switch between all APIs and libraries which build upon the APIs. For instance, you can extract patterns from a DataStream using the [CEP library]({{ site.baseurl }}/dev/libs/cep.html) and later use the Table API to analyze the patterns, or you might scan, filter, and aggregate a batch table using a SQL query before running a [Gelly graph algorithm]({{ site.baseurl }}/dev/libs/gelly) on the preprocessed data.\n+Table API \u548c SQL \u4e24\u79cd API \u662f\u7d27\u5bc6\u96c6\u6210\u7684\uff0c\u4ee5\u53ca DataStream \u548c DataSet API\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u4e9b API \u4e4b\u95f4\uff0c\u4ee5\u53ca\u4e00\u4e9b\u57fa\u4e8e\u8fd9\u4e9b API \u7684\u5e93\u4e4b\u95f4\u8f7b\u677e\u7684\u5207\u6362\u3002\u6bd4\u5982\uff0c\u4f60\u53ef\u4ee5\u5148\u7528 [CEP]({{ site.baseurl }}/zh/dev/libs/cep.html) \u4ece DataStream \u4e2d\u505a\u6a21\u5f0f\u5339\u914d\uff0c\u7136\u540e\u7528 Table API \u6765\u5206\u6790\u5339\u914d\u7684\u7ed3\u679c\uff1b\u6216\u8005\u4f60\u53ef\u4ee5\u7528 SQL \u6765\u626b\u63cf\u3001\u8fc7\u6ee4\u3001\u805a\u5408\u4e00\u4e2a\u6279\u5f0f\u7684\u8868\uff0c\u7136\u540e\u518d\u8dd1\u4e00\u4e2a [Gelly \u56fe\u7b97\u6cd5]({{ site.baseurl }}/zh/dev/libs/gelly) \u6765\u5904\u7406\u5df2\u7ecf\u9884\u5904\u7406\u597d\u7684\u6570\u636e\u3002\n \n-**Please note that the Table API and SQL are not yet feature complete and are being actively developed. Not all operations are supported by every combination of \\[Table API, SQL\\] and \\[stream, batch\\] input.**\n+**\u6ce8\u610f\uff1aTable API \u548c SQL \u73b0\u5728\u8fd8\u5904\u4e8e\u6d3b\u8dc3\u5f00\u53d1\u9636\u6bb5\uff0c\u8fd8\u6ca1\u6709\u5b8c\u5168\u5b9e\u73b0\u6240\u6709\u7684\u7279\u6027\u3002\u4e0d\u662f\u6240\u6709\u7684 \\[Table API\uff0cSQL\\] \u548c \\[\u6d41\uff0c\u6279\\] \u7684\u7ec4\u5408\u90fd\u662f\u652f\u6301\u7684\u3002**\n \n-Dependency Structure\n+\u4f9d\u8d56\u56fe\n --------------------\n \n-Starting from Flink 1.9, Flink provides two different planner implementations for evaluating Table & SQL API programs: the Blink planner and the old planner that was available before Flink 1.9. Planners are responsible for\n-translating relational operators into an executable, optimized Flink job. Both of the planners come with different optimization rules and runtime classes.\n-They may also differ in the set of supported features.\n+\u4ece1.9\u5f00\u59cb\uff0cFlink \u63d0\u4f9b\u4e86\u4e24\u4e2a table planner \u5b9e\u73b0\u6765\u6267\u884c Table API \u548c SQL \u7a0b\u5e8f\uff1aBlink planner \u548c old planner\uff0cold planner \u57281.9\u4e4b\u524d\u5c31\u5df2\u7ecf\u5b58\u5728\u4e86\u3002\n+planner \u7684\u4f5c\u7528\u4e3b\u8981\u662f\u628a\u5173\u7cfb\u578b\u7684\u64cd\u4f5c\u7ffb\u8bd1\u6210\u53ef\u6267\u884c\u7684\u3001\u7ecf\u8fc7\u4f18\u5316\u7684 Flink job\u3002\u8fd9\u4e24\u4e2a planner \u6240\u4f7f\u7528\u7684\u4f18\u5316\u89c4\u5219\u4ee5\u53ca\u8fd0\u884c\u65f6\u90fd\u4e0d\u4e00\u6837\u3002\n+\u5b83\u4eec\u5728\u652f\u6301\u7684\u529f\u80fd\u4e0a\u4e5f\u6709\u4e9b\u8be7\u5f02\u3002\n \n-<span class=\"label label-danger\">Attention</span> For production use cases, we recommend the old planner that was present before Flink 1.9 for now.\n+<span class=\"label label-danger\">\u6ce8\u610f</span> \u5bf9\u4e8e\u751f\u4ea7\u73af\u5883\uff0c\u6211\u4eec\u5efa\u8bae\u4f7f\u7528\u57281.9\u4e4b\u524d\u5c31\u5df2\u7ecf\u5b58\u5728\u7684 old planner\u3002\n \n-All Table API and SQL components are bundled in the `flink-table` or `flink-table-blink` Maven artifacts.\n+\u6240\u6709\u7684 Table API \u548c SQL \u7684\u4ee3\u7801\u90fd\u5728 `flink-table` \u6216\u8005 `flink-table-blink` Maven artifacts \u4e0b\u3002\n \n-The following dependencies are relevant for most projects:\n+\u4e0b\u9762\u662f\u5404\u4e2a\u4f9d\u8d56\uff1a\n \n-* `flink-table-common`: A common module for extending the table ecosystem by custom functions, formats, etc.\n-* `flink-table-api-java`: The Table & SQL API for pure table programs using the Java programming language (in early development stage, not recommended!).\n-* `flink-table-api-scala`: The Table & SQL API for pure table programs using the Scala programming language (in early development stage, not recommended!).\n-* `flink-table-api-java-bridge`: The Table & SQL API with DataStream/DataSet API support using the Java programming language.\n-* `flink-table-api-scala-bridge`: The Table & SQL API with DataStream/DataSet API support using the Scala programming language.\n-* `flink-table-planner`: The table program planner and runtime. This was the only planner of Flink before the 1.9 release. It is still the recommended one.\n-* `flink-table-planner-blink`: The new Blink planner.\n-* `flink-table-runtime-blink`: The new Blink runtime.\n-* `flink-table-uber`: Packages the API modules above plus the old planner into a distribution for most Table & SQL API use cases. The uber JAR file `flink-table-*.jar` is located in the `/lib` directory of a Flink release by default.\n-* `flink-table-uber-blink`: Packages the API modules above plus the Blink specific modules into a distribution for most Table & SQL API use cases. The uber JAR file `flink-table-blink-*.jar` is located in the `/lib` directory of a Flink release by default.\n+* `flink-table-common`: \u516c\u5171\u6a21\u5757\uff0c\u6bd4\u5982\u81ea\u5b9a\u4e49\u51fd\u6570\u3001\u683c\u5f0f\u7b49\u9700\u8981\u4f9d\u8d56\u7684\u3002\n+* `flink-table-api-java`: Table \u548c SQL API\uff0c\u4f7f\u7528 Java \u8bed\u8a00\u7f16\u5199\u7684\uff0c\u7ed9\u7eaf table \u7a0b\u5e8f\u4f7f\u7528\uff08\u8fd8\u5728\u65e9\u671f\u5f00\u53d1\u9636\u6bb5\uff0c\u4e0d\u5efa\u8bae\u4f7f\u7528\uff09\n+* `flink-table-api-scala`: Table \u548c SQL API\uff0c\u4f7f\u7528 Scala \u8bed\u8a00\u7f16\u5199\u7684\uff0c\u7ed9\u7eaf table \u7a0b\u5e8f\u4f7f\u7528\uff08\u8fd8\u5728\u65e9\u671f\u5f00\u53d1\u9636\u6bb5\uff0c\u4e0d\u5efa\u8bae\u4f7f\u7528\uff09\n+* `flink-table-api-java-bridge`: Table \u548c SQL API\uff0c\u4e5f\u652f\u6301 DataStream/DataSet API\uff0c\u7ed9 Java \u8bed\u8a00\u4f7f\u7528\u3002\n+* `flink-table-api-scala-bridge`: Table \u548c SQL API\uff0c\u4e5f\u652f\u6301 DataStream/DataSet API\uff0c\u7ed9 Scala \u8bed\u8a00\u4f7f\u7528\u3002\n+* `flink-table-planner`: table planner \u548c\u8fd0\u884c\u65f6\u3002\u8fd9\u662f\u57281.9\u4e4b\u524d Flink \u7684\u552f\u4e00\u7684 planner\uff0c\u73b0\u5728\u4ecd\u7136\u5efa\u8bae\u4f7f\u7528\u8fd9\u4e2a\u3002\n+* `flink-table-planner-blink`: \u65b0\u7684 Blink planner\u3002\n+* `flink-table-runtime-blink`: \u65b0\u7684 Blink \u8fd0\u884c\u65f6\u3002\n+* `flink-table-uber`: \u628a\u4e0a\u8ff0\u6a21\u5757\u4ee5\u53ca old planner \u6253\u5305\u5230\u4e00\u8d77\uff0c\u53ef\u4ee5\u5728\u5927\u90e8\u5206 Table & SQL API \u573a\u666f\u4e0b\u4f7f\u7528\u3002\u6253\u5305\u5230\u4e00\u8d77\u7684 jar \u6587\u4ef6 `flink-table-*.jar` \u9ed8\u8ba4\u4f1a\u76f4\u63a5\u653e\u5230 Flink \u53d1\u884c\u7248\u7684 `/lib` \u76ee\u5f55\u4e0b\u3002\n+* `flink-table-uber-blink`: \u628a\u4e0a\u8ff0\u6a21\u5757\u4ee5\u53ca Blink planner \u6253\u5305\u5230\u4e00\u8d77\uff0c\u53ef\u4ee5\u5728\u5927\u90e8\u5206 Table & SQL API \u573a\u666f\u4e0b\u4f7f\u7528\u3002\u6253\u5305\u5230\u4e00\u8d77\u7684 jar \u6587\u4ef6 `flink-table-blink-*.jar` \u9ed8\u8ba4\u4f1a\u653e\u5230 Flink \u53d1\u884c\u7248\u7684 `/lib` \u76ee\u5f55\u4e0b\u3002\n \n-See the [common API](common.html) page for more information about how to switch between the old and new Blink planner in table programs.\n+\u5173\u4e8e\u5982\u4f55\u4f7f\u7528 old planner \u4ee5\u53ca Blink planner\uff0c\u53ef\u4ee5\u53c2\u8003[\u516c\u5171 API](common.html)\u3002 \n \n-### Table Program Dependencies\n+### Table \u7a0b\u5e8f\u4f9d\u8d56\n \n-Depending on the target programming language, you need to add the Java or Scala API to a project in order to use the Table API & SQL for defining pipelines:\n+\u53d6\u51b3\u4e8e\u4f60\u4f7f\u7528\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u9009\u62e9 Java \u6216\u8005 Scala API \u6765\u6784\u5efa\u4f60\u7684\u7a0b\u5e8f\uff1a", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjQxMTIzNA==", "url": "https://github.com/apache/flink/pull/11127#discussion_r382411234", "bodyText": "\u6269\u5c55\u4f9d\u8d56\uff1f", "author": "JingsongLi", "createdAt": "2020-02-21T06:05:39Z", "path": "docs/dev/table/index.zh.md", "diffHunk": "@@ -109,9 +108,9 @@ Internally, parts of the table ecosystem are implemented in Scala. Therefore, pl\n </dependency>\n {% endhighlight %}\n \n-### Extension Dependencies\n+### \u6269\u5c55\u6240\u9700\u8981\u7684\u4f9d\u8d56", "originalCommit": "22ee2bb7027f9253a5479e5df4c83e8a4c9809a8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c9aaa06a3c6ba5e7b259668f17c0ed4c9d3e999c", "url": "https://github.com/apache/flink/commit/c9aaa06a3c6ba5e7b259668f17c0ed4c9d3e999c", "message": "address comments", "committedDate": "2020-02-22T04:38:35Z", "type": "commit"}]}