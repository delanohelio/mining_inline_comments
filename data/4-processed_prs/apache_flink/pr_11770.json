{"pr_number": 11770, "pr_title": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy", "pr_createdAt": "2020-04-16T08:53:46Z", "pr_url": "https://github.com/apache/flink/pull/11770", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc0ODQwNg==", "url": "https://github.com/apache/flink/pull/11770#discussion_r409748406", "bodyText": "I would say that such comments are redundant. checkState already implies that it is a sanity check.", "author": "GJL", "createdAt": "2020-04-16T18:01:59Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import org.apache.flink.runtime.execution.ExecutionState;\n+import org.apache.flink.runtime.io.network.partition.ResultPartitionType;\n+import org.apache.flink.runtime.jobgraph.IntermediateDataSetID;\n+import org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID;\n+import org.apache.flink.runtime.scheduler.DeploymentOption;\n+import org.apache.flink.runtime.scheduler.ExecutionVertexDeploymentOption;\n+import org.apache.flink.runtime.scheduler.SchedulerOperations;\n+import org.apache.flink.util.IterableUtils;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link SchedulingStrategy} instance which schedules tasks in granularity of pipelined regions.\n+ */\n+public class PipelinedRegionSchedulingStrategy implements SchedulingStrategy {\n+\n+\tprivate final SchedulerOperations schedulerOperations;\n+\n+\tprivate final SchedulingTopology<?, ?> schedulingTopology;\n+\n+\tprivate final DeploymentOption deploymentOption = new DeploymentOption(false);\n+\n+\t/** Result partitions are correlated if they have the same result id. */\n+\tprivate final Map<IntermediateDataSetID, Set<SchedulingResultPartition<?, ?>>> correlatedResultPartitions = new HashMap<>();\n+\n+\tprivate final Map<IntermediateResultPartitionID, Set<SchedulingPipelinedRegion<?, ?>>> partitionConsumerRegions = new HashMap<>();\n+\n+\tpublic PipelinedRegionSchedulingStrategy(\n+\t\t\tfinal SchedulerOperations schedulerOperations,\n+\t\t\tfinal SchedulingTopology<?, ?> schedulingTopology) {\n+\n+\t\tthis.schedulerOperations = checkNotNull(schedulerOperations);\n+\t\tthis.schedulingTopology = checkNotNull(schedulingTopology);\n+\n+\t\tinit();\n+\t}\n+\n+\tprivate void init() {\n+\t\tfor (SchedulingPipelinedRegion<?, ?> region : schedulingTopology.getAllPipelinedRegions()) {\n+\t\t\tfor (SchedulingResultPartition<?, ?> partition : region.getConsumedResults()) {\n+\t\t\t\t// sanity check", "originalCommit": "2577ed1f1fe568552fcec2a89366ae8dc59911c9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk4MzA5MA==", "url": "https://github.com/apache/flink/pull/11770#discussion_r409983090", "bodyText": "ok. will remove it.", "author": "zhuzhurk", "createdAt": "2020-04-17T04:15:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc0ODQwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1NTEyMw==", "url": "https://github.com/apache/flink/pull/11770#discussion_r409755123", "bodyText": "Is the first line needed? Set#add() returns false if the item was not added.\nAlso, consider using .distinct() since side effects in stream operations are frowned upon:\n\npredicate \u2013 a non-interfering, stateless predicate to apply to each element to determine if it should be included", "author": "GJL", "createdAt": "2020-04-16T18:13:34Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/SchedulingStrategyUtils.java", "diffHunk": "@@ -60,4 +61,18 @@\n \t\t\t\tdeploymentOptionRetriever.apply(executionVertexID)))\n \t\t\t.collect(Collectors.toList());\n \t}\n+\n+\tstatic List<SchedulingPipelinedRegion<?, ?>> sortPipelinedRegionsInTopologicalOrder(\n+\t\t\tfinal SchedulingTopology<?, ?> topology,\n+\t\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> regions) {\n+\n+\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> deduplicator = new HashSet<>();\n+\t\treturn IterableUtils.toStream(topology.getVertices())\n+\t\t\t.map(SchedulingExecutionVertex::getId)\n+\t\t\t.map(topology::getPipelinedRegionOfVertex)\n+\t\t\t.filter(regions::contains)\n+\t\t\t.filter(region -> !deduplicator.contains(region))\n+\t\t\t.filter(deduplicator::add)", "originalCommit": "2577ed1f1fe568552fcec2a89366ae8dc59911c9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk4MjI0NQ==", "url": "https://github.com/apache/flink/pull/11770#discussion_r409982245", "bodyText": "Good idea! Will use distinct().", "author": "zhuzhurk", "createdAt": "2020-04-17T04:12:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1NTEyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1NjMyMw==", "url": "https://github.com/apache/flink/pull/11770#discussion_r409756323", "bodyText": "Maybe checkState for consistency, and drop the // sanity check comment.", "author": "GJL", "createdAt": "2020-04-16T18:15:34Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategy.java", "diffHunk": "@@ -0,0 +1,166 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import org.apache.flink.runtime.execution.ExecutionState;\n+import org.apache.flink.runtime.io.network.partition.ResultPartitionType;\n+import org.apache.flink.runtime.jobgraph.IntermediateDataSetID;\n+import org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID;\n+import org.apache.flink.runtime.scheduler.DeploymentOption;\n+import org.apache.flink.runtime.scheduler.ExecutionVertexDeploymentOption;\n+import org.apache.flink.runtime.scheduler.SchedulerOperations;\n+import org.apache.flink.util.IterableUtils;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+import static org.apache.flink.util.Preconditions.checkState;\n+\n+/**\n+ * {@link SchedulingStrategy} instance which schedules tasks in granularity of pipelined regions.\n+ */\n+public class PipelinedRegionSchedulingStrategy implements SchedulingStrategy {\n+\n+\tprivate final SchedulerOperations schedulerOperations;\n+\n+\tprivate final SchedulingTopology<?, ?> schedulingTopology;\n+\n+\tprivate final DeploymentOption deploymentOption = new DeploymentOption(false);\n+\n+\t/** Result partitions are correlated if they have the same result id. */\n+\tprivate final Map<IntermediateDataSetID, Set<SchedulingResultPartition<?, ?>>> correlatedResultPartitions = new HashMap<>();\n+\n+\tprivate final Map<IntermediateResultPartitionID, Set<SchedulingPipelinedRegion<?, ?>>> partitionConsumerRegions = new HashMap<>();\n+\n+\tpublic PipelinedRegionSchedulingStrategy(\n+\t\t\tfinal SchedulerOperations schedulerOperations,\n+\t\t\tfinal SchedulingTopology<?, ?> schedulingTopology) {\n+\n+\t\tthis.schedulerOperations = checkNotNull(schedulerOperations);\n+\t\tthis.schedulingTopology = checkNotNull(schedulingTopology);\n+\n+\t\tinit();\n+\t}\n+\n+\tprivate void init() {\n+\t\tfor (SchedulingPipelinedRegion<?, ?> region : schedulingTopology.getAllPipelinedRegions()) {\n+\t\t\tfor (SchedulingResultPartition<?, ?> partition : region.getConsumedResults()) {\n+\t\t\t\t// sanity check\n+\t\t\t\tcheckState(partition.getResultType() == ResultPartitionType.BLOCKING);\n+\n+\t\t\t\tpartitionConsumerRegions.computeIfAbsent(partition.getId(), pid -> new HashSet<>()).add(region);\n+\t\t\t\tcorrelatedResultPartitions.computeIfAbsent(partition.getResultId(), rid -> new HashSet<>()).add(partition);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void startScheduling() {\n+\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> sourceRegions = IterableUtils\n+\t\t\t.toStream(schedulingTopology.getAllPipelinedRegions())\n+\t\t\t.filter(region -> !region.getConsumedResults().iterator().hasNext())\n+\t\t\t.collect(Collectors.toSet());\n+\t\tmaybeScheduleRegions(sourceRegions);\n+\t}\n+\n+\t@Override\n+\tpublic void restartTasks(final Set<ExecutionVertexID> verticesToRestart) {\n+\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> regionsToRestart = verticesToRestart.stream()\n+\t\t\t.map(schedulingTopology::getPipelinedRegionOfVertex)\n+\t\t\t.collect(Collectors.toSet());\n+\t\tmaybeScheduleRegions(regionsToRestart);\n+\t}\n+\n+\t@Override\n+\tpublic void onExecutionStateChange(final ExecutionVertexID executionVertexId, final ExecutionState executionState) {\n+\t\tif (executionState == ExecutionState.FINISHED) {\n+\t\t\tfinal Set<SchedulingResultPartition<?, ?>> finishedPartitions = IterableUtils\n+\t\t\t\t.toStream(schedulingTopology.getVertex(executionVertexId).getProducedResults())\n+\t\t\t\t.filter(partition -> partitionConsumerRegions.containsKey(partition.getId()))\n+\t\t\t\t.filter(partition -> partition.getState() == ResultPartitionState.CONSUMABLE)\n+\t\t\t\t.flatMap(partition -> correlatedResultPartitions.get(partition.getResultId()).stream())\n+\t\t\t\t.collect(Collectors.toSet());\n+\n+\t\t\tfinal Set<SchedulingPipelinedRegion<?, ?>> consumerRegions = finishedPartitions.stream()\n+\t\t\t\t.flatMap(partition -> partitionConsumerRegions.get(partition.getId()).stream())\n+\t\t\t\t.collect(Collectors.toSet());\n+\t\t\tmaybeScheduleRegions(consumerRegions);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void onPartitionConsumable(final IntermediateResultPartitionID resultPartitionId) {\n+\t}\n+\n+\tprivate void maybeScheduleRegions(final Set<SchedulingPipelinedRegion<?, ?>> regions) {\n+\t\tfinal List<SchedulingPipelinedRegion<?, ?>> regionsSorted =\n+\t\t\tSchedulingStrategyUtils.sortPipelinedRegionsInTopologicalOrder(schedulingTopology, regions);\n+\t\tfor (SchedulingPipelinedRegion<?, ?> region : regionsSorted) {\n+\t\t\tmaybeScheduleRegion(region);\n+\t\t}\n+\t}\n+\n+\tprivate void maybeScheduleRegion(final SchedulingPipelinedRegion<?, ?> region) {\n+\t\tif (!areRegionInputsAllConsumable(region)) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\t// sanity check\n+\t\tif (!areRegionVerticesAllInCreatedState(region)) {", "originalCommit": "2577ed1f1fe568552fcec2a89366ae8dc59911c9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk4MjQ2MQ==", "url": "https://github.com/apache/flink/pull/11770#discussion_r409982461", "bodyText": "ok.", "author": "zhuzhurk", "createdAt": "2020-04-17T04:12:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1NjMyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1Nzk3Nw==", "url": "https://github.com/apache/flink/pull/11770#discussion_r409757977", "bodyText": "consider hasSize(2)", "author": "GJL", "createdAt": "2020-04-16T18:18:22Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import org.apache.flink.runtime.execution.ExecutionState;\n+import org.apache.flink.runtime.io.network.partition.ResultPartitionType;\n+import org.apache.flink.runtime.scheduler.ExecutionVertexDeploymentOption;\n+import org.apache.flink.util.TestLogger;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit tests for {@link PipelinedRegionSchedulingStrategy}.\n+ */\n+public class PipelinedRegionSchedulingStrategyTest extends TestLogger {\n+\n+\tprivate TestingSchedulerOperations testingSchedulerOperation;\n+\n+\tprivate int parallelism = 2;\n+\n+\tprivate TestingSchedulingTopology testingSchedulingTopology;\n+\n+\tprivate List<TestingSchedulingExecutionVertex> source;\n+\n+\tprivate List<TestingSchedulingExecutionVertex> map;\n+\n+\tprivate List<TestingSchedulingExecutionVertex> sink;\n+\n+\t@Before\n+\tpublic void setUp() {\n+\t\ttestingSchedulerOperation = new TestingSchedulerOperations();\n+\n+\t\tbuildTopology();\n+\t}\n+\n+\tprivate void buildTopology() {\n+\t\ttestingSchedulingTopology = new TestingSchedulingTopology();\n+\n+\t\tsource = testingSchedulingTopology.addExecutionVertices().withParallelism(parallelism).finish();\n+\t\tmap = testingSchedulingTopology.addExecutionVertices().withParallelism(parallelism).finish();\n+\t\tsink =  testingSchedulingTopology.addExecutionVertices().withParallelism(parallelism).finish();\n+\n+\t\ttestingSchedulingTopology.connectPointwise(source, map)\n+\t\t\t.withResultPartitionState(ResultPartitionState.CREATED)\n+\t\t\t.withResultPartitionType(ResultPartitionType.PIPELINED_BOUNDED)\n+\t\t\t.finish();\n+\t\ttestingSchedulingTopology.connectAllToAll(map, sink)\n+\t\t\t.withResultPartitionState(ResultPartitionState.CREATED)\n+\t\t\t.withResultPartitionType(ResultPartitionType.BLOCKING)\n+\t\t\t.finish();\n+\n+\t\ttestingSchedulingTopology.generatePipelinedRegions();\n+\t}\n+\n+\t@Test\n+\tpublic void testStartScheduling() {\n+\t\tstartScheduling(testingSchedulingTopology);\n+\n+\t\tfinal List<List<TestingSchedulingExecutionVertex>> expectedScheduledVertices = new ArrayList<>();\n+\t\texpectedScheduledVertices.add(Arrays.asList(source.get(0), map.get(0)));\n+\t\texpectedScheduledVertices.add(Arrays.asList(source.get(1), map.get(1)));\n+\t\tassertLatestScheduledVerticesAreEqualTo(expectedScheduledVertices);\n+\t}\n+\n+\t@Test\n+\tpublic void testRestartTasks() {\n+\t\tfinal PipelinedRegionSchedulingStrategy schedulingStrategy = startScheduling(testingSchedulingTopology);\n+\n+\t\tfinal Set<ExecutionVertexID> verticesToRestart = Stream.of(source, map, sink)\n+\t\t\t.flatMap(List::stream)\n+\t\t\t.map(TestingSchedulingExecutionVertex::getId)\n+\t\t\t.collect(Collectors.toSet());\n+\n+\t\tschedulingStrategy.restartTasks(verticesToRestart);\n+\n+\t\tfinal List<List<TestingSchedulingExecutionVertex>> expectedScheduledVertices = new ArrayList<>();\n+\t\texpectedScheduledVertices.add(Arrays.asList(source.get(0), map.get(0)));\n+\t\texpectedScheduledVertices.add(Arrays.asList(source.get(1), map.get(1)));\n+\t\tassertLatestScheduledVerticesAreEqualTo(expectedScheduledVertices);\n+\t}\n+\n+\t@Test\n+\tpublic void testNotifyingBlockingResultPartitionProducerFinished() {\n+\t\tfinal PipelinedRegionSchedulingStrategy schedulingStrategy = startScheduling(testingSchedulingTopology);\n+\n+\t\tfinal TestingSchedulingExecutionVertex map1 = map.get(0);\n+\t\tmap1.getProducedResults().iterator().next().setState(ResultPartitionState.CONSUMABLE);\n+\t\tschedulingStrategy.onExecutionStateChange(map1.getId(), ExecutionState.FINISHED);\n+\n+\t\t// sinks' inputs are not all consumable yet so they are not scheduled\n+\t\tassertThat(testingSchedulerOperation.getScheduledVertices().size(), is(2));", "originalCommit": "2577ed1f1fe568552fcec2a89366ae8dc59911c9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTk4MzA0OQ==", "url": "https://github.com/apache/flink/pull/11770#discussion_r409983049", "bodyText": "Ok.", "author": "zhuzhurk", "createdAt": "2020-04-17T04:15:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc1Nzk3Nw=="}], "type": "inlineReview"}, {"oid": "395043eb6bbd4b1dc2dffa1a463ddf7a36401132", "url": "https://github.com/apache/flink/commit/395043eb6bbd4b1dc2dffa1a463ddf7a36401132", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy", "committedDate": "2020-04-17T06:11:11Z", "type": "forcePushed"}, {"oid": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "url": "https://github.com/apache/flink/commit/d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy", "committedDate": "2020-04-19T00:58:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE0ODc5OQ==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411148799", "bodyText": "Consider making this static final or convert to a local variable.", "author": "GJL", "createdAt": "2020-04-20T07:18:15Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/PipelinedRegionSchedulingStrategyTest.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import org.apache.flink.runtime.execution.ExecutionState;\n+import org.apache.flink.runtime.io.network.partition.ResultPartitionType;\n+import org.apache.flink.runtime.scheduler.ExecutionVertexDeploymentOption;\n+import org.apache.flink.util.TestLogger;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit tests for {@link PipelinedRegionSchedulingStrategy}.\n+ */\n+public class PipelinedRegionSchedulingStrategyTest extends TestLogger {\n+\n+\tprivate TestingSchedulerOperations testingSchedulerOperation;\n+\n+\tprivate int parallelism = 2;", "originalCommit": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE3MDkxNg==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411170916", "bodyText": "Ok.", "author": "zhuzhurk", "createdAt": "2020-04-20T07:56:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE0ODc5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1Nzk5OA==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411157998", "bodyText": "Consider wrapping it in Collections.unmodifiableCollection() for immutability or returning a copy. Same in getConsumedResults().", "author": "GJL", "createdAt": "2020-04-20T07:34:43Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/TestingSchedulingPipelinedRegion.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.scheduler.strategy;\n+\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * A simple implementation of {@link SchedulingPipelinedRegion} for testing.\n+ */\n+public class TestingSchedulingPipelinedRegion implements SchedulingPipelinedRegion {\n+\n+\tprivate final Map<ExecutionVertexID, TestingSchedulingExecutionVertex> regionVertices = new HashMap<>();\n+\n+\tprivate final Set<TestingSchedulingResultPartition> consumedPartitions = new HashSet<>();\n+\n+\tpublic TestingSchedulingPipelinedRegion(final Set<TestingSchedulingExecutionVertex> vertices) {\n+\t\tfor (TestingSchedulingExecutionVertex vertex : vertices) {\n+\t\t\tregionVertices.put(vertex.getId(), vertex);\n+\n+\t\t\tfor (TestingSchedulingResultPartition consumedPartition : vertex.getConsumedResults()) {\n+\t\t\t\tif (!vertices.contains(consumedPartition.getProducer())) {\n+\t\t\t\t\tconsumedPartitions.add(consumedPartition);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic Iterable<TestingSchedulingExecutionVertex> getVertices() {\n+\t\treturn regionVertices.values();", "originalCommit": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE3MTc3Ng==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411171776", "bodyText": "Iterable is considered as unmodifiable so I think it's not very needed.", "author": "zhuzhurk", "createdAt": "2020-04-20T07:58:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1Nzk5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE5ODY3Nw==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411198677", "bodyText": "I don't think that's true, see Iterator#remove()", "author": "GJL", "createdAt": "2020-04-20T08:40:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1Nzk5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTIwMTE3Ng==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411201176", "bodyText": "You are right. Will wrap it with Collections.unmodifiableCollection().", "author": "zhuzhurk", "createdAt": "2020-04-20T08:44:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1Nzk5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODk3OA==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411158978", "bodyText": "I think that's the same as new HashSet<>(vertexRegions.values())", "author": "GJL", "createdAt": "2020-04-20T07:36:26Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/TestingSchedulingTopology.java", "diffHunk": "@@ -78,6 +83,31 @@ public TestingSchedulingResultPartition getResultPartition(final IntermediateRes\n \t\treturn resultPartition;\n \t}\n \n+\t@Override\n+\tpublic Iterable<SchedulingPipelinedRegion> getAllPipelinedRegions() {\n+\t\treturn vertexRegions.values().stream().collect(Collectors.toSet());", "originalCommit": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE3Mzk0Mg==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411173942", "bodyText": "Ok. Let's simplify it.", "author": "zhuzhurk", "createdAt": "2020-04-20T08:02:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1ODk3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1OTQ2OA==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411159468", "bodyText": "Consider invoking this method lazily in getAllPipelinedRegions() and getPipelinedRegionOfVertex() instead of relying the client (test) to invoke it.", "author": "GJL", "createdAt": "2020-04-20T07:37:24Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/scheduler/strategy/TestingSchedulingTopology.java", "diffHunk": "@@ -78,6 +83,31 @@ public TestingSchedulingResultPartition getResultPartition(final IntermediateRes\n \t\treturn resultPartition;\n \t}\n \n+\t@Override\n+\tpublic Iterable<SchedulingPipelinedRegion> getAllPipelinedRegions() {\n+\t\treturn vertexRegions.values().stream().collect(Collectors.toSet());\n+\t}\n+\n+\t@Override\n+\tpublic SchedulingPipelinedRegion getPipelinedRegionOfVertex(ExecutionVertexID vertexId) {\n+\t\treturn vertexRegions.get(vertexId);\n+\t}\n+\n+\tvoid generatePipelinedRegions() {", "originalCommit": "d8568c4f9d43b9cd0b9cb47e6f8a9ddd8a57ec1c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE3NzEzMg==", "url": "https://github.com/apache/flink/pull/11770#discussion_r411177132", "bodyText": "Yes that would be better.\nThe only problem is that the regions cannot be refreshed if the topology is changed after invoking getAllPipelinedRegions(). So I will clear the cached regions on any topology changes.", "author": "zhuzhurk", "createdAt": "2020-04-20T08:07:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE1OTQ2OA=="}], "type": "inlineReview"}, {"oid": "17d9f5ed08b877c3157045271e5f6c8a884c5e87", "url": "https://github.com/apache/flink/commit/17d9f5ed08b877c3157045271e5f6c8a884c5e87", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy", "committedDate": "2020-04-20T08:26:23Z", "type": "forcePushed"}, {"oid": "ebbb1587ecd9d0d101a57f1b345c3ee8bc60375c", "url": "https://github.com/apache/flink/commit/ebbb1587ecd9d0d101a57f1b345c3ee8bc60375c", "message": "[FLINK-17014][runtime] TestingSchedulingTopology implements pipelined region getter interfaces", "committedDate": "2020-04-20T08:47:33Z", "type": "commit"}, {"oid": "a47976d0761aeffaf9a656a48b5bdae39f0bd64f", "url": "https://github.com/apache/flink/commit/a47976d0761aeffaf9a656a48b5bdae39f0bd64f", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy", "committedDate": "2020-04-20T08:47:57Z", "type": "commit"}, {"oid": "a47976d0761aeffaf9a656a48b5bdae39f0bd64f", "url": "https://github.com/apache/flink/commit/a47976d0761aeffaf9a656a48b5bdae39f0bd64f", "message": "[FLINK-17014][runtime] Implement PipelinedRegionSchedulingStrategy", "committedDate": "2020-04-20T08:47:57Z", "type": "forcePushed"}]}