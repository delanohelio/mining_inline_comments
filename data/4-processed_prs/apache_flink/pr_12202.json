{"pr_number": 12202, "pr_title": "[FLINK-17791][table][streaming] Support collecting query results under all execution and network environments", "pr_createdAt": "2020-05-17T14:04:14Z", "pr_url": "https://github.com/apache/flink/pull/12202", "timeline": [{"oid": "dc4b338596d9d3dee5dae9b1dfa3bebe1a5d902d", "url": "https://github.com/apache/flink/commit/dc4b338596d9d3dee5dae9b1dfa3bebe1a5d902d", "message": "[FLINK-14807][table] Support collecting query results under all execution and network environments", "committedDate": "2020-05-18T01:59:42Z", "type": "commit"}, {"oid": "171a600b1bac7b86c34dc1f9679ccefc38037adf", "url": "https://github.com/apache/flink/commit/171a600b1bac7b86c34dc1f9679ccefc38037adf", "message": "[fix] Remove execute config options for collect as data stream can also use this collect iterator", "committedDate": "2020-05-18T06:33:16Z", "type": "commit"}, {"oid": "3a44fbe9824e576068a4f172ca5738a7dd5cf9d1", "url": "https://github.com/apache/flink/commit/3a44fbe9824e576068a4f172ca5738a7dd5cf9d1", "message": "[addition] Change implementation of DataStreamUtils#collect to the current implementation", "committedDate": "2020-05-18T06:37:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQxNDc4OA==", "url": "https://github.com/apache/flink/pull/12202#discussion_r426414788", "bodyText": "id is meaningless  here, use \"data stream collect\" ?", "author": "godfreyhe", "createdAt": "2020-05-18T07:19:10Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/datastream/DataStreamUtils.java", "diffHunk": "@@ -47,44 +44,30 @@\n \t * Returns an iterator to iterate over the elements of the DataStream.\n \t * @return The iterator\n \t */\n-\tpublic static <OUT> Iterator<OUT> collect(DataStream<OUT> stream) throws IOException {\n-\n+\tpublic static <OUT> Iterator<OUT> collect(DataStream<OUT> stream) {\n \t\tTypeSerializer<OUT> serializer = stream.getType().createSerializer(\n-\t\t\t\tstream.getExecutionEnvironment().getConfig());\n+\t\t\tstream.getExecutionEnvironment().getConfig());\n+\t\tString id = UUID.randomUUID().toString();\n+\t\tString accumulatorName = \"dataStreamCollect_\" + id;\n \n-\t\tSocketStreamIterator<OUT> iter = new SocketStreamIterator<OUT>(serializer);\n+\t\tCollectSinkOperatorFactory<OUT> factory = new CollectSinkOperatorFactory<>(serializer, accumulatorName);\n+\t\tCollectSinkOperator<OUT> operator = (CollectSinkOperator<OUT>) factory.getOperator();\n+\t\tCollectResultIterator<OUT> iterator = new CollectResultIterator<>(\n+\t\t\toperator.getOperatorIdFuture(), serializer, accumulatorName);\n+\t\tCollectStreamSink<OUT> sink = new CollectStreamSink<>(stream, factory);\n+\t\tsink.name(\"Data stream collect sink\");\n \n-\t\t//Find out what IP of us should be given to CollectSink, that it will be able to connect to\n \t\tStreamExecutionEnvironment env = stream.getExecutionEnvironment();\n-\t\tInetAddress clientAddress;\n-\n-\t\tif (env instanceof RemoteStreamEnvironment) {\n-\t\t\tString host = ((RemoteStreamEnvironment) env).getHost();\n-\t\t\tint port = ((RemoteStreamEnvironment) env).getPort();\n-\t\t\ttry {\n-\t\t\t\tclientAddress = ConnectionUtils.findConnectingAddress(new InetSocketAddress(host, port), 2000, 400);\n-\t\t\t}\n-\t\t\tcatch (Exception e) {\n-\t\t\t\tthrow new IOException(\"Could not determine an suitable network address to \" +\n-\t\t\t\t\t\t\"receive back data from the streaming program.\", e);\n-\t\t\t}\n-\t\t} else if (env instanceof LocalStreamEnvironment) {\n-\t\t\tclientAddress = InetAddress.getLoopbackAddress();\n-\t\t} else {\n-\t\t\ttry {\n-\t\t\t\tclientAddress = InetAddress.getLocalHost();\n-\t\t\t} catch (UnknownHostException e) {\n-\t\t\t\tthrow new IOException(\"Could not determine this machines own local address to \" +\n-\t\t\t\t\t\t\"receive back data from the streaming program.\", e);\n-\t\t\t}\n-\t\t}\n-\n-\t\tDataStreamSink<OUT> sink = stream.addSink(new CollectSink<OUT>(clientAddress, iter.getPort(), serializer));\n-\t\tsink.setParallelism(1); // It would not work if multiple instances would connect to the same port\n+\t\tenv.addOperator(sink.getTransformation());\n \n-\t\t(new CallExecute(env, iter)).start();\n+\t\ttry {\n+\t\t\tJobClient jobClient = env.executeAsync(\"DataStreamCollect_\" + id);", "originalCommit": "3a44fbe9824e576068a4f172ca5738a7dd5cf9d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQxNTc2Ng==", "url": "https://github.com/apache/flink/pull/12202#discussion_r426415766", "bodyText": "CollectStreamSink  is not only used for select query but also for DataStream collect, so make this comment more generic.", "author": "godfreyhe", "createdAt": "2020-05-18T07:21:10Z", "path": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/collect/CollectStreamSink.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.api.operators.collect;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.streaming.api.datastream.DataStream;\n+import org.apache.flink.streaming.api.datastream.DataStreamSink;\n+import org.apache.flink.streaming.api.operators.ChainingStrategy;\n+import org.apache.flink.streaming.api.transformations.SinkTransformation;\n+\n+/**\n+ * A {@link DataStreamSink} which is used to collect query results.", "originalCommit": "3a44fbe9824e576068a4f172ca5738a7dd5cf9d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQxNzAyMg==", "url": "https://github.com/apache/flink/pull/12202#discussion_r426417022", "bodyText": "we can extract the most code of BatchSelectTableSink and StreamSelectTableSink  into a base class (SelectTableSinkBase)", "author": "godfreyhe", "createdAt": "2020-05-18T07:23:40Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/sinks/BatchSelectTableSink.java", "diffHunk": "@@ -49,19 +44,24 @@\n  * once FLINK-14807 is finished, the implementation should be changed.\n  */\n public class BatchSelectTableSink implements StreamTableSink<Row>, SelectTableSink {\n+\n \tprivate final TableSchema tableSchema;\n-\tprivate final String accumulatorName;\n-\tprivate final TypeSerializer<Row> typeSerializer;\n-\tprivate JobClient jobClient;\n+\tprivate final CollectSinkOperatorFactory<Row> factory;\n+\tprivate final CollectResultIterator<Row> iterator;\n \n \t@SuppressWarnings(\"unchecked\")\n \tpublic BatchSelectTableSink(TableSchema tableSchema) {", "originalCommit": "3a44fbe9824e576068a4f172ca5738a7dd5cf9d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3d70dafb893db6a61dcbc1b614349e9164aafeab", "url": "https://github.com/apache/flink/commit/3d70dafb893db6a61dcbc1b614349e9164aafeab", "message": "[fix] Fix godfrey's comments", "committedDate": "2020-05-18T07:28:33Z", "type": "commit"}]}