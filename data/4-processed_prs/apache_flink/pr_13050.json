{"pr_number": 13050, "pr_title": "[FLINK-18750][table] SqlValidatorException thrown when select from a \u2026", "pr_createdAt": "2020-08-03T08:55:02Z", "pr_url": "https://github.com/apache/flink/pull/13050", "timeline": [{"oid": "e274e166aed3ffacc4ac58409aaf3384c937cb66", "url": "https://github.com/apache/flink/commit/e274e166aed3ffacc4ac58409aaf3384c937cb66", "message": "[FLINK-18750][table] SqlValidatorException thrown when select from a view which contains a UDTF call", "committedDate": "2020-08-04T01:48:10Z", "type": "forcePushed"}, {"oid": "128e47f58b081d6273e3c6c57ad0da76c990595f", "url": "https://github.com/apache/flink/commit/128e47f58b081d6273e3c6c57ad0da76c990595f", "message": "Add a component named Expander for sql identifier expanding", "committedDate": "2020-08-06T04:33:02Z", "type": "forcePushed"}, {"oid": "6e9b5b711ca81e18366d521f564b9ed64113bf94", "url": "https://github.com/apache/flink/commit/6e9b5b711ca81e18366d521f564b9ed64113bf94", "message": "Add a component named Expander for sql identifier expanding", "committedDate": "2020-08-06T06:25:32Z", "type": "forcePushed"}, {"oid": "8559c87345749d7a627fd4ae4d4d58141a53639e", "url": "https://github.com/apache/flink/commit/8559c87345749d7a627fd4ae4d4d58141a53639e", "message": "Add a component named Expander for sql identifier expanding", "committedDate": "2020-08-06T08:33:20Z", "type": "forcePushed"}, {"oid": "c44b190d9e1350fa8853fe95b9f0284090f4d0fc", "url": "https://github.com/apache/flink/commit/c44b190d9e1350fa8853fe95b9f0284090f4d0fc", "message": "Add a component named Expander for sql identifier expanding\n\nThe select STAR(*) pattern may still keep the same.", "committedDate": "2020-08-07T07:02:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ3ODczMg==", "url": "https://github.com/apache/flink/pull/13050#discussion_r470478732", "bodyText": "Can we extract the logic from alter view and create view to a common helper method? The code is nearly identical. I am pretty sure we can extract the majority of the logic to a method like:\nCatalogView catalogView = transformToCatalogView(SqlNode query, String comment, List<String> aliases);\n\nRight now we need to modify the code in two different places and the comments differ significantly between the two locations, even though they should be exactly the same.", "author": "dawidwys", "createdAt": "2020-08-14T08:16:51Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/operations/SqlToOperationConverter.java", "diffHunk": "@@ -676,15 +680,20 @@ private Operation convertCreateView(SqlCreateView sqlCreateView) {\n \t\tfinal SqlNode query = sqlCreateView.getQuery();\n \t\tfinal SqlNodeList fieldList = sqlCreateView.getFieldList();\n \n-\t\tSqlNode validateQuery = flinkPlanner.validate(query);\n \t\t// Put the sql string unparse (getQuotedSqlString()) in front of\n \t\t// the node conversion (toQueryOperation()),\n \t\t// because before Calcite 1.22.0, during sql-to-rel conversion, the SqlWindow\n \t\t// bounds state would be mutated as default when they are null (not specified).\n \n \t\t// This bug is fixed in CALCITE-3877 of Calcite 1.23.0.\n \t\tString originalQuery = getQuotedSqlString(query);\n-\t\tString expandedQuery = getQuotedSqlString(validateQuery);\n+\t\tSqlNode validateQuery = flinkPlanner.validate(query);", "originalCommit": "c44b190d9e1350fa8853fe95b9f0284090f4d0fc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ3ODg4NA==", "url": "https://github.com/apache/flink/pull/13050#discussion_r470478884", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * Utility that expand SQL identifiers from a SQL query.\n          \n          \n            \n             * Utility that expands SQL identifiers in a SQL query.", "author": "dawidwys", "createdAt": "2020-08-14T08:17:13Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/utils/Expander.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.utils;\n+\n+import org.apache.flink.table.planner.calcite.FlinkPlannerImpl;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.calcite.sql.SqlIdentifier;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.parser.SqlParser;\n+import org.apache.calcite.sql.parser.SqlParserPos;\n+import org.apache.calcite.sql.util.SqlBasicVisitor;\n+import org.apache.calcite.sql.util.SqlShuttle;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility that expand SQL identifiers from a SQL query.", "originalCommit": "c44b190d9e1350fa8853fe95b9f0284090f4d0fc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUxMTI0NA==", "url": "https://github.com/apache/flink/pull/13050#discussion_r470511244", "bodyText": "nit: inline assignment", "author": "dawidwys", "createdAt": "2020-08-14T09:20:00Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/utils/Expander.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.utils;\n+\n+import org.apache.flink.table.planner.calcite.FlinkPlannerImpl;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.calcite.sql.SqlIdentifier;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.parser.SqlParser;\n+import org.apache.calcite.sql.parser.SqlParserPos;\n+import org.apache.calcite.sql.util.SqlBasicVisitor;\n+import org.apache.calcite.sql.util.SqlShuttle;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility that expand SQL identifiers from a SQL query.\n+ *\n+ * <p>Simple use:\n+ *\n+ * <blockquote><code>\n+ * final String sql =<br>\n+ *     \"select ename from emp where deptno &lt; 10\";<br>\n+ * final Expander.Expanded expanded =<br>\n+ *     Expander.create(planner).expanded(sql);<br>\n+ * print(expanded); // \"select `emp`.`ename` from `catalog`.`db`.`emp` where `emp`.`deptno` &lt; 10\"\n+ * </code></blockquote>\n+ *\n+ * <p>Calling {@link Expanded#toString()} generates a string that is similar to\n+ * SQL where a user has manually converted all identifiers as expanded, and\n+ * which could then be persisted as expanded query of a Catalog view.\n+ *\n+ * <p>For more advanced formatting, use {@link Expanded#substitute(Function)}.\n+ *\n+ * <p>Adjust {@link SqlParser.Config} to use a different parser or parsing options.\n+ */\n+public class Expander {\n+\tprivate final FlinkPlannerImpl planner;\n+\n+\tprivate Expander(FlinkPlannerImpl planner) {\n+\t\tthis.planner = Objects.requireNonNull(planner);\n+\t}\n+\n+\t/** Creates an Expander. **/\n+\tpublic static Expander create(FlinkPlannerImpl planner) {\n+\t\treturn new Expander(planner);\n+\t}\n+\n+\t/** Expands identifiers in a given SQL string, returning a {@link Expanded}. */\n+\tpublic Expanded expanded(String ori) {\n+\t\tfinal Map<SqlParserPos, SqlIdentifier> identifiers = new HashMap<>();\n+\t\tfinal SqlNode oriNode;\n+\t\tfinal SqlNode validated;\n+\t\toriNode = planner.parser().parse(ori);", "originalCommit": "c44b190d9e1350fa8853fe95b9f0284090f4d0fc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUxMTMzMQ==", "url": "https://github.com/apache/flink/pull/13050#discussion_r470511331", "bodyText": "nit: inline assignment", "author": "dawidwys", "createdAt": "2020-08-14T09:20:09Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/utils/Expander.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.utils;\n+\n+import org.apache.flink.table.planner.calcite.FlinkPlannerImpl;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.calcite.sql.SqlIdentifier;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.parser.SqlParser;\n+import org.apache.calcite.sql.parser.SqlParserPos;\n+import org.apache.calcite.sql.util.SqlBasicVisitor;\n+import org.apache.calcite.sql.util.SqlShuttle;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility that expand SQL identifiers from a SQL query.\n+ *\n+ * <p>Simple use:\n+ *\n+ * <blockquote><code>\n+ * final String sql =<br>\n+ *     \"select ename from emp where deptno &lt; 10\";<br>\n+ * final Expander.Expanded expanded =<br>\n+ *     Expander.create(planner).expanded(sql);<br>\n+ * print(expanded); // \"select `emp`.`ename` from `catalog`.`db`.`emp` where `emp`.`deptno` &lt; 10\"\n+ * </code></blockquote>\n+ *\n+ * <p>Calling {@link Expanded#toString()} generates a string that is similar to\n+ * SQL where a user has manually converted all identifiers as expanded, and\n+ * which could then be persisted as expanded query of a Catalog view.\n+ *\n+ * <p>For more advanced formatting, use {@link Expanded#substitute(Function)}.\n+ *\n+ * <p>Adjust {@link SqlParser.Config} to use a different parser or parsing options.\n+ */\n+public class Expander {\n+\tprivate final FlinkPlannerImpl planner;\n+\n+\tprivate Expander(FlinkPlannerImpl planner) {\n+\t\tthis.planner = Objects.requireNonNull(planner);\n+\t}\n+\n+\t/** Creates an Expander. **/\n+\tpublic static Expander create(FlinkPlannerImpl planner) {\n+\t\treturn new Expander(planner);\n+\t}\n+\n+\t/** Expands identifiers in a given SQL string, returning a {@link Expanded}. */\n+\tpublic Expanded expanded(String ori) {\n+\t\tfinal Map<SqlParserPos, SqlIdentifier> identifiers = new HashMap<>();\n+\t\tfinal SqlNode oriNode;\n+\t\tfinal SqlNode validated;\n+\t\toriNode = planner.parser().parse(ori);\n+\t\t// parse again because validation is stateful, that means the node tree was probably\n+\t\t// mutated.\n+\t\tvalidated = planner.validate(planner.parser().parse(ori));", "originalCommit": "c44b190d9e1350fa8853fe95b9f0284090f4d0fc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUyMTEyMg==", "url": "https://github.com/apache/flink/pull/13050#discussion_r470521122", "bodyText": "Shouldn't this be rather:\nif (toReplace == null || id.names.size() >= toReplace.names.size()) {\n\n?", "author": "dawidwys", "createdAt": "2020-08-14T09:39:41Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/utils/Expander.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.utils;\n+\n+import org.apache.flink.table.planner.calcite.FlinkPlannerImpl;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.calcite.sql.SqlIdentifier;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.parser.SqlParser;\n+import org.apache.calcite.sql.parser.SqlParserPos;\n+import org.apache.calcite.sql.util.SqlBasicVisitor;\n+import org.apache.calcite.sql.util.SqlShuttle;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility that expand SQL identifiers from a SQL query.\n+ *\n+ * <p>Simple use:\n+ *\n+ * <blockquote><code>\n+ * final String sql =<br>\n+ *     \"select ename from emp where deptno &lt; 10\";<br>\n+ * final Expander.Expanded expanded =<br>\n+ *     Expander.create(planner).expanded(sql);<br>\n+ * print(expanded); // \"select `emp`.`ename` from `catalog`.`db`.`emp` where `emp`.`deptno` &lt; 10\"\n+ * </code></blockquote>\n+ *\n+ * <p>Calling {@link Expanded#toString()} generates a string that is similar to\n+ * SQL where a user has manually converted all identifiers as expanded, and\n+ * which could then be persisted as expanded query of a Catalog view.\n+ *\n+ * <p>For more advanced formatting, use {@link Expanded#substitute(Function)}.\n+ *\n+ * <p>Adjust {@link SqlParser.Config} to use a different parser or parsing options.\n+ */\n+public class Expander {\n+\tprivate final FlinkPlannerImpl planner;\n+\n+\tprivate Expander(FlinkPlannerImpl planner) {\n+\t\tthis.planner = Objects.requireNonNull(planner);\n+\t}\n+\n+\t/** Creates an Expander. **/\n+\tpublic static Expander create(FlinkPlannerImpl planner) {\n+\t\treturn new Expander(planner);\n+\t}\n+\n+\t/** Expands identifiers in a given SQL string, returning a {@link Expanded}. */\n+\tpublic Expanded expanded(String ori) {\n+\t\tfinal Map<SqlParserPos, SqlIdentifier> identifiers = new HashMap<>();\n+\t\tfinal SqlNode oriNode;\n+\t\tfinal SqlNode validated;\n+\t\toriNode = planner.parser().parse(ori);\n+\t\t// parse again because validation is stateful, that means the node tree was probably\n+\t\t// mutated.\n+\t\tvalidated = planner.validate(planner.parser().parse(ori));\n+\t\tvalidated.accept(new SqlBasicVisitor<Void>() {\n+\t\t\t@Override public Void visit(SqlIdentifier identifier) {\n+\t\t\t\tidentifiers.putIfAbsent(identifier.getParserPosition(), identifier);\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t});\n+\t\treturn new Expanded(planner.config().getParserConfig(), oriNode, identifiers);\n+\t}\n+\n+\t/** Result of expanding. */\n+\tpublic static class Expanded {\n+\t\tpublic final SqlParser.Config parserConf;\n+\t\tpublic final SqlNode oriNode;\n+\t\tpublic final Map<SqlParserPos, SqlIdentifier> identifiersMap;\n+\n+\t\tExpanded(SqlParser.Config parserConf, SqlNode oriNode,\n+\t\t\t\tMap<SqlParserPos, SqlIdentifier> identifiers) {\n+\t\t\tthis.oriNode = oriNode;\n+\t\t\tthis.parserConf = parserConf;\n+\t\t\tthis.identifiersMap = ImmutableMap.copyOf(identifiers);\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic String toString() {\n+\t\t\treturn substitute(SqlNode::toString);\n+\t\t}\n+\n+\t\t/** Returns the SQL string with identifiers replaced according to the\n+\t\t * given unparse function. */\n+\t\tpublic String substitute(Function<SqlNode, String> fn) {\n+\t\t\tfinal SqlShuttle shuttle = new SqlShuttle() {\n+\t\t\t\t@Override\n+\t\t\t\tpublic SqlNode visit(SqlIdentifier id) {\n+\t\t\t\t\tif (id.isStar()) {\n+\t\t\t\t\t\treturn id;\n+\t\t\t\t\t}\n+\t\t\t\t\tfinal SqlIdentifier toReplace = identifiersMap.get(id.getParserPosition());\n+\t\t\t\t\tif (toReplace != null && id.names.size() >= toReplace.names.size()) {", "originalCommit": "c44b190d9e1350fa8853fe95b9f0284090f4d0fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI1NjUxMg==", "url": "https://github.com/apache/flink/pull/13050#discussion_r471256512", "bodyText": "Yes, nice catch ~", "author": "danny0405", "createdAt": "2020-08-17T06:29:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUyMTEyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUyMjQ0MQ==", "url": "https://github.com/apache/flink/pull/13050#discussion_r470522441", "bodyText": "Will it expand function identifiers as well? Can we have a test for that case?", "author": "dawidwys", "createdAt": "2020-08-14T09:42:24Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/utils/Expander.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.utils;\n+\n+import org.apache.flink.table.planner.calcite.FlinkPlannerImpl;\n+\n+import org.apache.flink.shaded.guava18.com.google.common.collect.ImmutableMap;\n+\n+import org.apache.calcite.sql.SqlIdentifier;\n+import org.apache.calcite.sql.SqlNode;\n+import org.apache.calcite.sql.parser.SqlParser;\n+import org.apache.calcite.sql.parser.SqlParserPos;\n+import org.apache.calcite.sql.util.SqlBasicVisitor;\n+import org.apache.calcite.sql.util.SqlShuttle;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * Utility that expand SQL identifiers from a SQL query.\n+ *\n+ * <p>Simple use:\n+ *\n+ * <blockquote><code>\n+ * final String sql =<br>\n+ *     \"select ename from emp where deptno &lt; 10\";<br>\n+ * final Expander.Expanded expanded =<br>\n+ *     Expander.create(planner).expanded(sql);<br>\n+ * print(expanded); // \"select `emp`.`ename` from `catalog`.`db`.`emp` where `emp`.`deptno` &lt; 10\"\n+ * </code></blockquote>\n+ *\n+ * <p>Calling {@link Expanded#toString()} generates a string that is similar to\n+ * SQL where a user has manually converted all identifiers as expanded, and\n+ * which could then be persisted as expanded query of a Catalog view.\n+ *\n+ * <p>For more advanced formatting, use {@link Expanded#substitute(Function)}.\n+ *\n+ * <p>Adjust {@link SqlParser.Config} to use a different parser or parsing options.\n+ */\n+public class Expander {", "originalCommit": "c44b190d9e1350fa8853fe95b9f0284090f4d0fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTI5MjEzOA==", "url": "https://github.com/apache/flink/pull/13050#discussion_r471292138", "bodyText": "I'm afraid we never support expanding functions, i have added a test.", "author": "danny0405", "createdAt": "2020-08-17T07:29:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUyMjQ0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTM1NTM4MQ==", "url": "https://github.com/apache/flink/pull/13050#discussion_r471355381", "bodyText": "The test you added uses a built-in function, which has a single part identifier which does not differ from not expanded one. Are you saying we never expanded identifiers for UDFs?", "author": "dawidwys", "createdAt": "2020-08-17T09:28:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUyMjQ0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg3MjgzMA==", "url": "https://github.com/apache/flink/pull/13050#discussion_r471872830", "bodyText": "The first test also add a UDTF there and it still no expanded.\nI didn't find any evidence that Calcite validator expands the function IDs, the DelegatingScope#fullyQualify expands the table columns, the IdentifierNamespace#validateImpl expands the table name.\nOr did i miss something ?", "author": "danny0405", "createdAt": "2020-08-18T02:11:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUyMjQ0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgxNTExNg==", "url": "https://github.com/apache/flink/pull/13050#discussion_r472815116", "bodyText": "I don't know where it happens but a test like:\n  @Test\n  def testViewExpandingWithUDF(): Unit = {\n    val tableUtil = tableTestUtil(this)\n    val tableEnv = tableUtil.tableEnv\n    tableEnv.createTemporaryFunction(\"func\", classOf[PrimitiveScalarFunction])\n    val createView =\n      \"\"\"\n        |CREATE VIEW tmp_view AS\n        |  SELECT func(1)\n        |\"\"\".stripMargin\n    tableEnv.executeSql(createView)\n    val objectID = ObjectIdentifier.of(tableEnv.getCurrentCatalog,\n      tableEnv.getCurrentDatabase, \"tmp_view\")\n    val view: CatalogBaseTable = tableEnv.getCatalog(objectID.getCatalogName)\n      .get().getTable(objectID.toObjectPath)\n    assertThat(view.asInstanceOf[CatalogView].getExpandedQuery, is(\"SELECT `default_catalog`.`default_database`.`func`(1)\"))\n  }\n\npasses on master and fails with your changes.", "author": "dawidwys", "createdAt": "2020-08-19T07:41:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUyMjQ0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzk3NTY4Mg==", "url": "https://github.com/apache/flink/pull/13050#discussion_r473975682", "bodyText": "Yes, the BridgingSqlFunction did the function id expanding out of the scope of the SqlValidator, so in the code base of this patch, it does not work because BridgingSqlFunction id position was always SqlParserPos.ZERO so it can not match the original identifier.", "author": "danny0405", "createdAt": "2020-08-20T13:31:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDUyMjQ0MQ=="}], "type": "inlineReview"}, {"oid": "bba1b32fd9b7acb3e2ddc4678d4d26c835880e0b", "url": "https://github.com/apache/flink/commit/bba1b32fd9b7acb3e2ddc4678d4d26c835880e0b", "message": "fix comments", "committedDate": "2020-08-17T07:28:15Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTM1NDEyNQ==", "url": "https://github.com/apache/flink/pull/13050#discussion_r471354125", "bodyText": "unrelated change", "author": "dawidwys", "createdAt": "2020-08-17T09:26:38Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/optimize/program/FlinkChainedProgram.scala", "diffHunk": "@@ -62,8 +62,8 @@ class FlinkChainedProgram[OC <: FlinkOptimizeContext]\n         val result = program.optimize(input, context)\n         val end = System.currentTimeMillis()\n \n-        if (LOG.isDebugEnabled) {\n-          LOG.debug(s\"optimize $name cost ${end - start} ms.\\n\" +\n+        if (true) {", "originalCommit": "bba1b32fd9b7acb3e2ddc4678d4d26c835880e0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg3MDQ4OQ==", "url": "https://github.com/apache/flink/pull/13050#discussion_r471870489", "bodyText": "Oops, i committed some test code, fixed.", "author": "danny0405", "createdAt": "2020-08-18T02:02:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTM1NDEyNQ=="}], "type": "inlineReview"}, {"oid": "44ba50fd578d65572ddfea8b09e0e001f9ea530b", "url": "https://github.com/apache/flink/commit/44ba50fd578d65572ddfea8b09e0e001f9ea530b", "message": "fix comments", "committedDate": "2020-08-17T09:38:00Z", "type": "forcePushed"}, {"oid": "0358a12e3524d251396cca950c7403eee205f0d6", "url": "https://github.com/apache/flink/commit/0358a12e3524d251396cca950c7403eee205f0d6", "message": "[FLINK-18750][table] SqlValidatorException thrown when select from a view which contains a UDTF call", "committedDate": "2020-08-18T01:59:43Z", "type": "forcePushed"}, {"oid": "870f73394bfc42e740891a6262e1bfd97efdba56", "url": "https://github.com/apache/flink/commit/870f73394bfc42e740891a6262e1bfd97efdba56", "message": "fix the BridgingSqlFunction expanding", "committedDate": "2020-08-20T14:07:18Z", "type": "forcePushed"}, {"oid": "da58a528949de503a38c69aca6ea4d1e29b2beea", "url": "https://github.com/apache/flink/commit/da58a528949de503a38c69aca6ea4d1e29b2beea", "message": "fix the BridgingSqlFunction expanding", "committedDate": "2020-08-21T01:53:15Z", "type": "forcePushed"}, {"oid": "efe2b4b092cbce31dee74b4261ca7a20904b2000", "url": "https://github.com/apache/flink/commit/efe2b4b092cbce31dee74b4261ca7a20904b2000", "message": "fix the BridgingSqlFunction expanding", "committedDate": "2020-08-21T08:19:28Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM5OTU3Ng==", "url": "https://github.com/apache/flink/pull/13050#discussion_r475399576", "bodyText": "Why did you decide to use a different key for functions? Can't we use the SqlParserPos as well?", "author": "dawidwys", "createdAt": "2020-08-24T07:40:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/utils/Expander.java", "diffHunk": "@@ -70,30 +75,43 @@ public static Expander create(FlinkPlannerImpl planner) {\n \t/** Expands identifiers in a given SQL string, returning a {@link Expanded}. */\n \tpublic Expanded expanded(String ori) {\n \t\tfinal Map<SqlParserPos, SqlIdentifier> identifiers = new HashMap<>();\n+\t\tfinal Map<String, SqlIdentifier> funcNameToId = new HashMap<>();", "originalCommit": "efe2b4b092cbce31dee74b4261ca7a20904b2000", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjA2MzkyNQ==", "url": "https://github.com/apache/flink/pull/13050#discussion_r476063925", "bodyText": "Because the BridgingSqlFunction lost the parser position information. We may need a refactor to BridgingSqlFunction but i don't want to in this PR.", "author": "danny0405", "createdAt": "2020-08-25T02:06:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM5OTU3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwMDY0Mg==", "url": "https://github.com/apache/flink/pull/13050#discussion_r475400642", "bodyText": "Let's not import the PrimitiveScalarFunction. I don't think it makes sense to introduce a cross dependency between the tests. I think it is easy enough to add a simple function in this class.", "author": "dawidwys", "createdAt": "2020-08-24T07:42:27Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/common/ViewsExpandingTest.scala", "diffHunk": "@@ -20,9 +20,12 @@ package org.apache.flink.table.planner.plan.common\n \n import org.apache.flink.api.scala._\n import org.apache.flink.table.api._\n-import org.apache.flink.table.catalog.{CatalogView, CatalogViewImpl, ObjectPath}\n-import org.apache.flink.table.planner.utils.{TableTestBase, TableTestUtil, TableTestUtilBase}\n+import org.apache.flink.table.catalog.{CatalogBaseTable, CatalogView, CatalogViewImpl, ObjectIdentifier, ObjectPath}\n+import org.apache.flink.table.planner.runtime.stream.sql.FunctionITCase.PrimitiveScalarFunction", "originalCommit": "efe2b4b092cbce31dee74b4261ca7a20904b2000", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0aa2e599db47cf035f6d7cf0389e7caa273b5880", "url": "https://github.com/apache/flink/commit/0aa2e599db47cf035f6d7cf0389e7caa273b5880", "message": "[FLINK-18750][table] SqlValidatorException thrown when select from a view which contains a UDTF call", "committedDate": "2020-08-25T02:12:23Z", "type": "commit"}, {"oid": "0aa2e599db47cf035f6d7cf0389e7caa273b5880", "url": "https://github.com/apache/flink/commit/0aa2e599db47cf035f6d7cf0389e7caa273b5880", "message": "[FLINK-18750][table] SqlValidatorException thrown when select from a view which contains a UDTF call", "committedDate": "2020-08-25T02:12:23Z", "type": "forcePushed"}]}