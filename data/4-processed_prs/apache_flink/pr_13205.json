{"pr_number": 13205, "pr_title": "[FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region", "pr_createdAt": "2020-08-20T08:30:41Z", "pr_url": "https://github.com/apache/flink/pull/13205", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIwOTQwMQ==", "url": "https://github.com/apache/flink/pull/13205#discussion_r474209401", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\tfinal int vertexLoopCount = tuple.f1;\n          \n          \n            \n            \t\t\tfinal int vertexOutEdgeIndex = tuple.f1;", "author": "azagrebin", "createdAt": "2020-08-20T19:09:12Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n+\t\tfinal boolean[] onStack = new boolean[numVertex];\n+\t\tfinal AtomicInteger indexCounter = new AtomicInteger(0);\n+\n+\t\tfor (int vertex = 0; vertex < numVertex; vertex++) {\n+\t\t\tif (vertexIndices[vertex] == -1) {\n+\t\t\t\tdfs(vertex, outEdges, vertexIndices, vertexLowLinks, stack, onStack, indexCounter, stronglyConnectedComponents);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn stronglyConnectedComponents;\n+\t}\n+\n+\tprivate static void dfs(\n+\t\t\tfinal int rootVertex,\n+\t\t\tfinal List<List<Integer>> outEdges,\n+\t\t\tfinal int[] vertexIndices,\n+\t\t\tfinal int[] vertexLowLinks,\n+\t\t\tfinal Deque<Integer> stack,\n+\t\t\tfinal boolean[] onStack,\n+\t\t\tfinal AtomicInteger indexCounter,\n+\t\t\tfinal Set<Set<Integer>> stronglyConnectedComponents) {\n+\n+\t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();\n+\t\tloopStack.add(new Tuple2<>(rootVertex, 0));\n+\n+\t\twhile (!loopStack.isEmpty()) {\n+\t\t\tTuple2<Integer, Integer> tuple = loopStack.pollLast();\n+\t\t\tfinal int currentVertex = tuple.f0;\n+\t\t\tfinal int vertexLoopCount = tuple.f1;", "originalCommit": "e11ffec55b9151857069d64c806b47cc98d9679d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMTk0NA==", "url": "https://github.com/apache/flink/pull/13205#discussion_r474211944", "bodyText": "I would add more comments for respective code blocks or maybe even additionally break the loop body into three methods/steps:\nstartTraversingVertex\nfinishTaversingOutEdge\ntraverseOutEdges\ncreateConnectedComponent", "author": "azagrebin", "createdAt": "2020-08-20T19:14:01Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n+\t\tfinal boolean[] onStack = new boolean[numVertex];\n+\t\tfinal AtomicInteger indexCounter = new AtomicInteger(0);\n+\n+\t\tfor (int vertex = 0; vertex < numVertex; vertex++) {\n+\t\t\tif (vertexIndices[vertex] == -1) {\n+\t\t\t\tdfs(vertex, outEdges, vertexIndices, vertexLowLinks, stack, onStack, indexCounter, stronglyConnectedComponents);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn stronglyConnectedComponents;\n+\t}\n+\n+\tprivate static void dfs(\n+\t\t\tfinal int rootVertex,\n+\t\t\tfinal List<List<Integer>> outEdges,\n+\t\t\tfinal int[] vertexIndices,\n+\t\t\tfinal int[] vertexLowLinks,\n+\t\t\tfinal Deque<Integer> stack,\n+\t\t\tfinal boolean[] onStack,\n+\t\t\tfinal AtomicInteger indexCounter,\n+\t\t\tfinal Set<Set<Integer>> stronglyConnectedComponents) {\n+\n+\t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();\n+\t\tloopStack.add(new Tuple2<>(rootVertex, 0));\n+\n+\t\twhile (!loopStack.isEmpty()) {\n+\t\t\tTuple2<Integer, Integer> tuple = loopStack.pollLast();\n+\t\t\tfinal int currentVertex = tuple.f0;\n+\t\t\tfinal int vertexLoopCount = tuple.f1;\n+\n+\t\t\tif (vertexLoopCount == 0) {\n+\t\t\t\tvertexIndices[currentVertex] = indexCounter.get();", "originalCommit": "e11ffec55b9151857069d64c806b47cc98d9679d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMjE4Ng==", "url": "https://github.com/apache/flink/pull/13205#discussion_r474212186", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();\n          \n          \n            \n            \t\tfinal Deque<Tuple2<Integer, Integer>> dfsLoopStack = new ArrayDeque<>();", "author": "azagrebin", "createdAt": "2020-08-20T19:14:28Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n+\t\tfinal boolean[] onStack = new boolean[numVertex];\n+\t\tfinal AtomicInteger indexCounter = new AtomicInteger(0);\n+\n+\t\tfor (int vertex = 0; vertex < numVertex; vertex++) {\n+\t\t\tif (vertexIndices[vertex] == -1) {\n+\t\t\t\tdfs(vertex, outEdges, vertexIndices, vertexLowLinks, stack, onStack, indexCounter, stronglyConnectedComponents);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn stronglyConnectedComponents;\n+\t}\n+\n+\tprivate static void dfs(\n+\t\t\tfinal int rootVertex,\n+\t\t\tfinal List<List<Integer>> outEdges,\n+\t\t\tfinal int[] vertexIndices,\n+\t\t\tfinal int[] vertexLowLinks,\n+\t\t\tfinal Deque<Integer> stack,\n+\t\t\tfinal boolean[] onStack,\n+\t\t\tfinal AtomicInteger indexCounter,\n+\t\t\tfinal Set<Set<Integer>> stronglyConnectedComponents) {\n+\n+\t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();", "originalCommit": "e11ffec55b9151857069d64c806b47cc98d9679d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMjQyMA==", "url": "https://github.com/apache/flink/pull/13205#discussion_r474212420", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n          \n          \n            \n            \t\tfinal Deque<Integer> ccStack = new ArrayDeque<>(numVertex);", "author": "azagrebin", "createdAt": "2020-08-20T19:14:54Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);", "originalCommit": "e11ffec55b9151857069d64c806b47cc98d9679d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM4ODkzNQ==", "url": "https://github.com/apache/flink/pull/13205#discussion_r475388935", "bodyText": "renamed it as visitingStack", "author": "zhuzhurk", "createdAt": "2020-08-24T07:18:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMjQyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIxMzE5OQ==", "url": "https://github.com/apache/flink/pull/13205#discussion_r474213199", "bodyText": "From what I saw before and discussed as code style, we usually put instance methods before static methods.", "author": "azagrebin", "createdAt": "2020-08-20T19:16:21Z", "path": "flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtils.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+\n+import java.util.ArrayDeque;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Utility for computing strongly connected components.\n+ *\n+ * <p>The computation is an implementation of Tarjan's algorithm.\n+ *\n+ * <p>Ref: https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm.\n+ */\n+public final class StronglyConnectedComponentsComputeUtils {\n+\n+\tstatic Set<Set<Integer>> computeStronglyConnectedComponents(final int numVertex, final List<List<Integer>> outEdges) {\n+\t\tfinal Set<Set<Integer>> stronglyConnectedComponents = new HashSet<>();\n+\n+\t\tfinal int[] vertexIndices = new int[numVertex];\n+\t\tArrays.fill(vertexIndices, -1);\n+\n+\t\tfinal int[] vertexLowLinks = new int[numVertex];\n+\t\tfinal Deque<Integer> stack = new ArrayDeque<>(numVertex);\n+\t\tfinal boolean[] onStack = new boolean[numVertex];\n+\t\tfinal AtomicInteger indexCounter = new AtomicInteger(0);\n+\n+\t\tfor (int vertex = 0; vertex < numVertex; vertex++) {\n+\t\t\tif (vertexIndices[vertex] == -1) {\n+\t\t\t\tdfs(vertex, outEdges, vertexIndices, vertexLowLinks, stack, onStack, indexCounter, stronglyConnectedComponents);\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn stronglyConnectedComponents;\n+\t}\n+\n+\tprivate static void dfs(\n+\t\t\tfinal int rootVertex,\n+\t\t\tfinal List<List<Integer>> outEdges,\n+\t\t\tfinal int[] vertexIndices,\n+\t\t\tfinal int[] vertexLowLinks,\n+\t\t\tfinal Deque<Integer> stack,\n+\t\t\tfinal boolean[] onStack,\n+\t\t\tfinal AtomicInteger indexCounter,\n+\t\t\tfinal Set<Set<Integer>> stronglyConnectedComponents) {\n+\n+\t\tfinal Deque<Tuple2<Integer, Integer>> loopStack = new ArrayDeque<>();\n+\t\tloopStack.add(new Tuple2<>(rootVertex, 0));\n+\n+\t\twhile (!loopStack.isEmpty()) {\n+\t\t\tTuple2<Integer, Integer> tuple = loopStack.pollLast();\n+\t\t\tfinal int currentVertex = tuple.f0;\n+\t\t\tfinal int vertexLoopCount = tuple.f1;\n+\n+\t\t\tif (vertexLoopCount == 0) {\n+\t\t\t\tvertexIndices[currentVertex] = indexCounter.get();\n+\t\t\t\tvertexLowLinks[currentVertex] = indexCounter.getAndIncrement();\n+\t\t\t\tstack.add(currentVertex);\n+\t\t\t\tonStack[currentVertex] = true;\n+\t\t\t} else if (vertexLoopCount > 0) {\n+\t\t\t\tfinal int successorVertex = outEdges.get(currentVertex).get(vertexLoopCount - 1);\n+\t\t\t\tvertexLowLinks[currentVertex] = Math.min(vertexLowLinks[currentVertex], vertexLowLinks[successorVertex]);\n+\t\t\t}\n+\n+\t\t\tboolean visitSuccessorVertex = false;\n+\t\t\tfor (int i = vertexLoopCount; i < outEdges.get(currentVertex).size(); i++) {\n+\t\t\t\tfinal int successorVertex = outEdges.get(currentVertex).get(i);\n+\t\t\t\tif (vertexIndices[successorVertex] == -1) {\n+\t\t\t\t\tloopStack.add(new Tuple2<>(currentVertex, i + 1));\n+\t\t\t\t\tloopStack.add(new Tuple2<>(successorVertex, 0));\n+\t\t\t\t\tvisitSuccessorVertex = true;\n+\t\t\t\t\tbreak;\n+\t\t\t\t} else if (onStack[successorVertex]) {\n+\t\t\t\t\tvertexLowLinks[currentVertex] = Math.min(vertexLowLinks[currentVertex], vertexIndices[successorVertex]);\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tif (visitSuccessorVertex) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\tif (vertexLowLinks[currentVertex] == vertexIndices[currentVertex]) {\n+\t\t\t\tfinal Set<Integer> scc = new HashSet<>();\n+\t\t\t\twhile (onStack[currentVertex]) {\n+\t\t\t\t\tfinal int v = stack.pollLast();\n+\t\t\t\t\tonStack[v] = false;\n+\t\t\t\t\tscc.add(v);\n+\n+\t\t\t\t}\n+\t\t\t\tstronglyConnectedComponents.add(scc);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate StronglyConnectedComponentsComputeUtils() {", "originalCommit": "e11ffec55b9151857069d64c806b47cc98d9679d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIyNDA2Nw==", "url": "https://github.com/apache/flink/pull/13205#discussion_r474224067", "bodyText": "Do we need this random test? Is it not covered by separate deterministic cases in other tests?", "author": "azagrebin", "createdAt": "2020-08-20T19:34:52Z", "path": "flink-runtime/src/test/java/org/apache/flink/runtime/executiongraph/failover/flip1/StronglyConnectedComponentsComputeUtilsTest.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.runtime.executiongraph.failover.flip1;\n+\n+import org.apache.flink.util.TestLogger;\n+\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static org.apache.flink.runtime.executiongraph.failover.flip1.StronglyConnectedComponentsComputeUtils.computeStronglyConnectedComponents;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertThat;\n+\n+/**\n+ * Unit tests for {@link StronglyConnectedComponentsComputeUtils}.\n+ */\n+public class StronglyConnectedComponentsComputeUtilsTest extends TestLogger {\n+\n+\t@Test\n+\tpublic void testWithCycles() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tArrays.asList(2, 3),\n+\t\t\tArrays.asList(0),\n+\t\t\tArrays.asList(1),\n+\t\t\tArrays.asList(4),\n+\t\t\tCollections.emptyList());\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(5, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(new HashSet<>(Arrays.asList(0, 1, 2)));\n+\t\texpected.add(Collections.singleton(3));\n+\t\texpected.add(Collections.singleton(4));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testWithMultipleCycles() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tArrays.asList(1),\n+\t\t\tArrays.asList(2),\n+\t\t\tArrays.asList(0),\n+\t\t\tArrays.asList(1, 2, 4),\n+\t\t\tArrays.asList(3, 5),\n+\t\t\tArrays.asList(2, 6),\n+\t\t\tArrays.asList(5),\n+\t\t\tArrays.asList(4, 6, 7));\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(8, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(new HashSet<>(Arrays.asList(0, 1, 2)));\n+\t\texpected.add(new HashSet<>(Arrays.asList(3, 4)));\n+\t\texpected.add(new HashSet<>(Arrays.asList(5, 6)));\n+\t\texpected.add(Collections.singleton(7));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testWithConnectedCycles() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tArrays.asList(1),\n+\t\t\tArrays.asList(2, 4, 5),\n+\t\t\tArrays.asList(3, 6),\n+\t\t\tArrays.asList(2, 7),\n+\t\t\tArrays.asList(0, 5),\n+\t\t\tArrays.asList(6),\n+\t\t\tArrays.asList(5),\n+\t\t\tArrays.asList(3, 6));\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(8, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(new HashSet<>(Arrays.asList(0, 1, 4)));\n+\t\texpected.add(new HashSet<>(Arrays.asList(2, 3, 7)));\n+\t\texpected.add(new HashSet<>(Arrays.asList(5, 6)));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testWithNoEdge() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tCollections.emptyList(),\n+\t\t\tCollections.emptyList(),\n+\t\t\tCollections.emptyList(),\n+\t\t\tCollections.emptyList(),\n+\t\t\tCollections.emptyList());\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(5, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(Collections.singleton(0));\n+\t\texpected.add(Collections.singleton(1));\n+\t\texpected.add(Collections.singleton(2));\n+\t\texpected.add(Collections.singleton(3));\n+\t\texpected.add(Collections.singleton(4));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testWithNoCycle() {\n+\t\tfinal List<List<Integer>> edges = Arrays.asList(\n+\t\t\tArrays.asList(1),\n+\t\t\tArrays.asList(2),\n+\t\t\tArrays.asList(3),\n+\t\t\tArrays.asList(4),\n+\t\t\tCollections.emptyList());\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(5, edges);\n+\n+\t\tfinal Set<Set<Integer>> expected = new HashSet<>();\n+\t\texpected.add(Collections.singleton(0));\n+\t\texpected.add(Collections.singleton(1));\n+\t\texpected.add(Collections.singleton(2));\n+\t\texpected.add(Collections.singleton(3));\n+\t\texpected.add(Collections.singleton(4));\n+\n+\t\tassertThat(result, is(expected));\n+\t}\n+\n+\t@Test\n+\tpublic void testLargeGraph() {\n+\t\tfinal int n = 100000;\n+\t\tfinal List<List<Integer>> edges = new ArrayList<>();\n+\t\tfor (int i = 0; i < n; i++) {\n+\t\t\tedges.add(Collections.singletonList((i + 1) % n));\n+\t\t}\n+\n+\t\tfinal Set<Set<Integer>> result = computeStronglyConnectedComponents(n, edges);\n+\n+\t\tfinal Set<Integer> singleComponent = IntStream.range(0, n).boxed().collect(Collectors.toSet());\n+\n+\t\tassertThat(result, is(Collections.singleton(singleComponent)));\n+\t}\n+\n+\t@Test\n+\tpublic void testArbitraryGraph() {", "originalCommit": "e11ffec55b9151857069d64c806b47cc98d9679d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM5MDA3Mw==", "url": "https://github.com/apache/flink/pull/13205#discussion_r475390073", "bodyText": "I added it to cover any case that I am not aware.\nIt's also fine for me to drop it if you feel like it, since I have already used it to test locally.", "author": "zhuzhurk", "createdAt": "2020-08-24T07:20:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIyNDA2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY4NDA4NQ==", "url": "https://github.com/apache/flink/pull/13205#discussion_r475684085", "bodyText": "My concern was the complexity of the test to maintain in the code base. I think it is good to try this kind of test once but It seems to me that the random tests are usually hard to maintain and it is better to cover with the deterministic cases. I leave it up to you whether to keep it.", "author": "azagrebin", "createdAt": "2020-08-24T15:04:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIyNDA2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTczNDE0Mw==", "url": "https://github.com/apache/flink/pull/13205#discussion_r475734143", "bodyText": "Ok. I will remove it.", "author": "zhuzhurk", "createdAt": "2020-08-24T16:19:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIyNDA2Nw=="}], "type": "inlineReview"}, {"oid": "b6ec9981ff3880e61df71fc37459026dcaafb950", "url": "https://github.com/apache/flink/commit/b6ec9981ff3880e61df71fc37459026dcaafb950", "message": "Fixup! [FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region", "committedDate": "2020-08-24T07:16:56Z", "type": "forcePushed"}, {"oid": "58d0d7f9198d7c336135a3078f9c6cc993a0d358", "url": "https://github.com/apache/flink/commit/58d0d7f9198d7c336135a3078f9c6cc993a0d358", "message": "[hotfix][runtime] Avoid unnecessary map building in PipelinedRegionComputeUtil#buildOneRegionForAllVertices()", "committedDate": "2020-08-24T16:24:38Z", "type": "commit"}, {"oid": "e1b7f9c42197706ca699b57ed587562b05e84dc0", "url": "https://github.com/apache/flink/commit/e1b7f9c42197706ca699b57ed587562b05e84dc0", "message": "[FLINK-17330[runtime] Extract common methods out from PipelinedRegionComputeUtil#computePipelinedRegions()", "committedDate": "2020-08-24T16:24:38Z", "type": "commit"}, {"oid": "8617ce6c0c5e0b4e8ba01aae58b1ef5cff2f02e6", "url": "https://github.com/apache/flink/commit/8617ce6c0c5e0b4e8ba01aae58b1ef5cff2f02e6", "message": "[FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region", "committedDate": "2020-08-24T16:27:31Z", "type": "commit"}, {"oid": "8617ce6c0c5e0b4e8ba01aae58b1ef5cff2f02e6", "url": "https://github.com/apache/flink/commit/8617ce6c0c5e0b4e8ba01aae58b1ef5cff2f02e6", "message": "[FLINK-17330[runtime] Merge cyclic dependent pipelined regions into one region", "committedDate": "2020-08-24T16:27:31Z", "type": "forcePushed"}]}