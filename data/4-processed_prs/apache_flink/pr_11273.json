{"pr_number": 11273, "pr_title": "[FLINK-12814][sql-client] Support tableau result format", "pr_createdAt": "2020-03-01T13:02:12Z", "pr_url": "https://github.com/apache/flink/pull/11273", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjEwNzA5MA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386107090", "bodyText": "2? There is a decimal point.\nlike -123.567", "author": "JingsongLi", "createdAt": "2020-03-01T13:11:37Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();\n+\t}\n+\n+\t/**\n+\t * Try to infer column width based on column types. In streaming case, we will have an\n+\t * endless result set, thus couldn't determine column widths based on column values.\n+\t */\n+\tprivate int[] columnWidthsByType(List<TableColumn> columns, boolean includeChangeflag) {\n+\t\t// fill width with field names first\n+\t\tint[] colWidths  = columns.stream()\n+\t\t\t\t.mapToInt(col -> col.getName().length())\n+\t\t\t\t.toArray();\n+\n+\t\t// determine proper column width based on types\n+\t\tfor (int i = 0; i < columns.size(); ++i) {\n+\t\t\tLogicalType type = columns.get(i).getType().getLogicalType();\n+\t\t\tint len;\n+\t\t\tswitch (type.getTypeRoot()) {\n+\t\t\t\tcase TINYINT:\n+\t\t\t\t\tlen = TinyIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase SMALLINT:\n+\t\t\t\t\tlen = SmallIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase INTEGER:\n+\t\t\t\t\tlen = IntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase BIGINT:\n+\t\t\t\t\tlen = BigIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase DECIMAL:\n+\t\t\t\t\tlen = ((DecimalType) type).getPrecision() + 1; // extra for negative value", "originalCommit": "106c923b64d7246305c1e131bd7bd8ffeb213f87", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIwNTg1Mg==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386205852", "bodyText": "nice catch", "author": "KurtYoung", "createdAt": "2020-03-02T05:43:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjEwNzA5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjEwNzQ1Nw==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386107457", "bodyText": "Actually LocalDateTime.toString is:\n     * <li>{@code uuuu-MM-dd'T'HH:mm}</li>\n     * <li>{@code uuuu-MM-dd'T'HH:mm:ss}</li>\n     * <li>{@code uuuu-MM-dd'T'HH:mm:ss.SSS}</li>\n     * <li>{@code uuuu-MM-dd'T'HH:mm:ss.SSSSSS}</li>\n     * <li>{@code uuuu-MM-dd'T'HH:mm:ss.SSSSSSSSS}</li>\n\nSo maybe we need pad zero for mills,micros,nanos too?", "author": "JingsongLi", "createdAt": "2020-03-01T13:16:52Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();\n+\t}\n+\n+\t/**\n+\t * Try to infer column width based on column types. In streaming case, we will have an\n+\t * endless result set, thus couldn't determine column widths based on column values.\n+\t */\n+\tprivate int[] columnWidthsByType(List<TableColumn> columns, boolean includeChangeflag) {\n+\t\t// fill width with field names first\n+\t\tint[] colWidths  = columns.stream()\n+\t\t\t\t.mapToInt(col -> col.getName().length())\n+\t\t\t\t.toArray();\n+\n+\t\t// determine proper column width based on types\n+\t\tfor (int i = 0; i < columns.size(); ++i) {\n+\t\t\tLogicalType type = columns.get(i).getType().getLogicalType();\n+\t\t\tint len;\n+\t\t\tswitch (type.getTypeRoot()) {\n+\t\t\t\tcase TINYINT:\n+\t\t\t\t\tlen = TinyIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase SMALLINT:\n+\t\t\t\t\tlen = SmallIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase INTEGER:\n+\t\t\t\t\tlen = IntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase BIGINT:\n+\t\t\t\t\tlen = BigIntType.PRECISION + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase DECIMAL:\n+\t\t\t\t\tlen = ((DecimalType) type).getPrecision() + 1; // extra for negative value\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase BOOLEAN:\n+\t\t\t\t\tlen = 5; // \"true\" or \"false\"\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase DATE:\n+\t\t\t\t\tlen = 10; // e.g. 9999-12-31\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase TIME_WITHOUT_TIME_ZONE:\n+\t\t\t\t\tint precision = ((TimeType) type).getPrecision();\n+\t\t\t\t\tlen = precision == 0 ? 8 : precision + 9; // 23:59:59[.999999999]\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase TIMESTAMP_WITHOUT_TIME_ZONE:\n+\t\t\t\t\tprecision = ((TimestampType) type).getPrecision();\n+\t\t\t\t\tlen = precision == 0 ? 19 : precision + 20; // 2020-02-01T23:59:59[.999999999]\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n+\t\t\t\t\tprecision = ((LocalZonedTimestampType) type).getPrecision();\n+\t\t\t\t\tlen = precision == 0 ? 19 : precision + 20; // 2020-02-01T23:59:59[.999999999]", "originalCommit": "106c923b64d7246305c1e131bd7bd8ffeb213f87", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjM3OTA3MA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386379070", "bodyText": "handled both LocalDateTime and java.sql.Timestamp", "author": "KurtYoung", "createdAt": "2020-03-02T13:03:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjEwNzQ1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzNTA5Mw==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386235093", "bodyText": "One more space.", "author": "JingsongLi", "createdAt": "2020-03-02T07:43:01Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();\n+\t}\n+\n+\t/**\n+\t * Try to infer column width based on column types. In streaming case, we will have an\n+\t * endless result set, thus couldn't determine column widths based on column values.\n+\t */\n+\tprivate int[] columnWidthsByType(List<TableColumn> columns, boolean includeChangeflag) {\n+\t\t// fill width with field names first\n+\t\tint[] colWidths  = columns.stream()", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzNzM0MA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386237340", "bodyText": "Use StringUtils.repeat(char) or CliUtils.repeatChar?", "author": "JingsongLi", "createdAt": "2020-03-02T07:50:20Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzNzM3MA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386237370", "bodyText": "Use StringUtils.repeat(char) or CliUtils.repeatChar?", "author": "JingsongLi", "createdAt": "2020-03-02T07:50:25Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzODA2NA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386238064", "bodyText": "Why not put sb.append(\" \"); into if (col.length() <= colWidths[idx]) block, and not use this append.", "author": "JingsongLi", "createdAt": "2020-03-02T07:52:23Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjM4MTA4Mw==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386381083", "bodyText": "could you explain more?", "author": "KurtYoung", "createdAt": "2020-03-02T13:07:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzODA2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njc5OTU3MA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386799570", "bodyText": "Ignore me, misunderstood.", "author": "JingsongLi", "createdAt": "2020-03-03T04:58:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzODA2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzODk3OA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386238978", "bodyText": "Why flush? Flush at final when batch?", "author": "JingsongLi", "createdAt": "2020-03-02T07:55:24Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjM4MjAxMg==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386382012", "bodyText": "just for safe, since this method might be called in different places", "author": "KurtYoung", "createdAt": "2020-03-02T13:09:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjIzODk3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0MDUwOA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386240508", "bodyText": "When includeChangeflag is false?", "author": "JingsongLi", "createdAt": "2020-03-02T08:00:03Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);\n+\t\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate void printBatchResults(List<Row> resultRows) {\n+\t\tList<String[]> rows = new ArrayList<>(resultRows.size() + 1);\n+\n+\t\t// fill field names first\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\trows.add(columns.stream().map(TableColumn::getName).toArray(String[]::new));\n+\t\tresultRows.forEach(row -> rows.add(rowToString(row)));\n+\n+\t\tint[] colWidths = columnWidthsByContent(columns, rows);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print field names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, rows.get(0));\n+\t\tterminal.writer().println(borderline);\n+\n+\t\t// print content\n+\t\trows.subList(1, rows.size()).forEach(row -> printSingleRow(colWidths, row));\n+\t\tif (!resultRows.isEmpty()) {\n+\t\t\tterminal.writer().println(borderline);\n+\t\t}\n+\n+\t\t// print footer\n+\t\tterminal.writer().println(resultRows.size() + \" row in set\");\n+\t\tterminal.flush();\n+\t}\n+\n+\tprivate String genBorderLine(int[] colWidths) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"+\");\n+\t\tfor (int width : colWidths) {\n+\t\t\tsb.append(StringUtils.repeat(\"-\", width + 1));\n+\t\t\tsb.append(\"-+\");\n+\t\t}\n+\t\treturn sb.toString();\n+\t}\n+\n+\tprivate void printSingleRow(int[] colWidths, String[] cols) {\n+\t\tStringBuilder sb = new StringBuilder();\n+\t\tsb.append(\"|\");\n+\t\tint idx = 0;\n+\t\tfor (String col : cols) {\n+\t\t\tsb.append(\" \");\n+\t\t\tif (col.length() <= colWidths[idx]) {\n+\t\t\t\tsb.append(StringUtils.repeat(\" \", colWidths[idx] - col.length()));\n+\t\t\t\tsb.append(col);\n+\t\t\t} else {\n+\t\t\t\tsb.append(col, 0, colWidths[idx] - COLUMN_TRUNCATED_FLAG.length());\n+\t\t\t\tsb.append(COLUMN_TRUNCATED_FLAG);\n+\t\t\t}\n+\t\t\tsb.append(\" |\");\n+\t\t\tidx++;\n+\t\t}\n+\t\tterminal.writer().println(sb.toString());\n+\t\tterminal.flush();\n+\t}\n+\n+\t/**\n+\t * Try to infer column width based on column types. In streaming case, we will have an\n+\t * endless result set, thus couldn't determine column widths based on column values.\n+\t */\n+\tprivate int[] columnWidthsByType(List<TableColumn> columns, boolean includeChangeflag) {", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjM4MjczNQ==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386382735", "bodyText": "right now, no.", "author": "KurtYoung", "createdAt": "2020-03-02T13:10:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0MDUwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0MjY5NQ==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386242695", "bodyText": "try with resource management?", "author": "JingsongLi", "createdAt": "2020-03-02T08:06:50Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliClient.java", "diffHunk": "@@ -512,21 +512,38 @@ private void callSelect(SqlCommandCall cmdCall) {\n \t\t\tprintExecutionException(e);\n \t\t\treturn;\n \t\t}\n-\t\tfinal CliResultView view;\n-\t\tif (resultDesc.isMaterialized()) {\n-\t\t\tview = new CliTableResultView(this, resultDesc);\n+\n+\t\tif (resultDesc.isTableauMode()) {\n+\t\t\tCliTableauResultView tableauResultView = new CliTableauResultView(\n+\t\t\t\t\tterminal, executor, sessionId, resultDesc);\n+\t\t\ttry {", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0NzE3MA==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386247170", "bodyText": "Do we need this? Just field in method is OK?", "author": "JingsongLi", "createdAt": "2020-03-02T08:19:32Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0ODA2Ng==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386248066", "bodyText": "add case PAYLOAD and throw unsupport exception for default?", "author": "JingsongLi", "createdAt": "2020-03-02T08:22:05Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI0ODg4Mg==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386248882", "bodyText": "incrementAndGet?", "author": "JingsongLi", "createdAt": "2020-03-02T08:24:16Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;\n+\n+\tprivate volatile boolean cleanUpQuery;\n+\n+\tpublic CliTableauResultView(\n+\t\t\tfinal Terminal terminal,\n+\t\t\tfinal Executor sqlExecutor,\n+\t\t\tfinal String sessionId,\n+\t\t\tfinal ResultDescriptor resultDescriptor) {\n+\t\tthis.terminal = terminal;\n+\t\tthis.sqlExecutor = sqlExecutor;\n+\t\tthis.sessionId = sessionId;\n+\t\tthis.resultDescriptor = resultDescriptor;\n+\t\tthis.displayResultExecutorService = Executors.newSingleThreadExecutor();\n+\t}\n+\n+\tpublic void displayStreamResults() throws SqlExecutionException {\n+\t\tfinal AtomicInteger receivedRowCount = new AtomicInteger(0);\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tprintStreamResults(receivedRowCount);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated, received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\tpublic void displayBatchResults() throws SqlExecutionException {\n+\t\tFuture<?> resultFuture = displayResultExecutorService.submit(() -> {\n+\t\t\tfinal List<Row> resultRows = waitBatchResults();\n+\t\t\tprintBatchResults(resultRows);\n+\t\t});\n+\n+\t\t// capture CTRL-C\n+\t\tterminal.handle(Terminal.Signal.INT, signal -> {\n+\t\t\tresultFuture.cancel(true);\n+\t\t});\n+\n+\t\tcleanUpQuery = true;\n+\t\ttry {\n+\t\t\tresultFuture.get();\n+\t\t\tcleanUpQuery = false; // job finished successfully\n+\t\t} catch (CancellationException e) {\n+\t\t\tterminal.writer().println(\"Query terminated\");\n+\t\t\tterminal.flush();\n+\t\t} catch (ExecutionException e) {\n+\t\t\tif (e.getCause() instanceof SqlExecutionException) {\n+\t\t\t\tthrow (SqlExecutionException) e.getCause();\n+\t\t\t}\n+\t\t\tthrow new SqlExecutionException(\"unknown exception\", e.getCause());\n+\t\t} catch (InterruptedException e) {\n+\t\t\tthrow new SqlExecutionException(\"Query interrupted\", e);\n+\t\t} finally {\n+\t\t\tcheckAndCleanUpQuery();\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic void close() {\n+\t\tthis.displayResultExecutorService.shutdown();\n+\t}\n+\n+\tprivate void checkAndCleanUpQuery() {\n+\t\tif (cleanUpQuery) {\n+\t\t\ttry {\n+\t\t\t\tsqlExecutor.cancelQuery(sessionId, resultDescriptor.getResultId());\n+\t\t\t} catch (SqlExecutionException e) {\n+\t\t\t\t// ignore further exceptions\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tprivate List<Row> waitBatchResults() {\n+\t\tList<Row> resultRows;\n+\t\t// take snapshot and make all results in one page\n+\t\tdo {\n+\t\t\ttry {\n+\t\t\t\tThread.sleep(50);\n+\t\t\t} catch (InterruptedException e) {\n+\t\t\t\tThread.currentThread().interrupt();\n+\t\t\t}\n+\t\t\tTypedResult<Integer> result = sqlExecutor.snapshotResult(\n+\t\t\t\t\tsessionId,\n+\t\t\t\t\tresultDescriptor.getResultId(),\n+\t\t\t\t\tInteger.MAX_VALUE);\n+\n+\t\t\tif (result.getType() == TypedResult.ResultType.EOS) {\n+\t\t\t\tresultRows = Collections.emptyList();\n+\t\t\t\tbreak;\n+\t\t\t} else if (result.getType() == TypedResult.ResultType.PAYLOAD) {\n+\t\t\t\tresultRows = sqlExecutor.retrieveResultPage(resultDescriptor.getResultId(), 1);\n+\t\t\t\tbreak;\n+\t\t\t} else {\n+\t\t\t\t// result not retrieved yet\n+\t\t\t}\n+\t\t} while (true);\n+\n+\t\treturn resultRows;\n+\t}\n+\n+\tprivate void printStreamResults(AtomicInteger receivedRowCount) {\n+\t\tList<TableColumn> columns = resultDescriptor.getResultSchema().getTableColumns();\n+\t\tString[] fieldNames =\n+\t\t\t\tStream.concat(\n+\t\t\t\t\t\tStream.of(\"+/-\"),\n+\t\t\t\t\t\tcolumns.stream().map(TableColumn::getName)\n+\t\t\t\t).toArray(String[]::new);\n+\n+\t\tint[] colWidths = columnWidthsByType(columns, true);\n+\t\tString borderline = genBorderLine(colWidths);\n+\n+\t\t// print filed names\n+\t\tterminal.writer().println(borderline);\n+\t\tprintSingleRow(colWidths, fieldNames);\n+\t\tterminal.writer().println(borderline);\n+\t\tterminal.flush();\n+\n+\t\twhile (true) {\n+\t\t\tfinal TypedResult<List<Tuple2<Boolean, Row>>> result =\n+\t\t\t\t\tsqlExecutor.retrieveResultChanges(sessionId, resultDescriptor.getResultId());\n+\n+\t\t\tswitch (result.getType()) {\n+\t\t\t\tcase EMPTY:\n+\t\t\t\t\t// do nothing\n+\t\t\t\t\tbreak;\n+\t\t\t\tcase EOS:\n+\t\t\t\t\tif (receivedRowCount.get() > 0) {\n+\t\t\t\t\t\tterminal.writer().println(borderline);\n+\t\t\t\t\t}\n+\t\t\t\t\tterminal.writer().println(\"Received a total of \" + receivedRowCount.get() + \" rows\");\n+\t\t\t\t\tterminal.flush();\n+\t\t\t\t\treturn;\n+\t\t\t\tdefault:\n+\t\t\t\t\tList<Tuple2<Boolean, Row>> changes = result.getPayload();\n+\t\t\t\t\tfor (Tuple2<Boolean, Row> change : changes) {\n+\t\t\t\t\t\tfinal String[] cols = rowToString(change.f1);\n+\t\t\t\t\t\tString[] row = new String[cols.length + 1];\n+\t\t\t\t\t\trow[0] = change.f0 ? \"+\" : \"-\";\n+\t\t\t\t\t\tSystem.arraycopy(cols, 0, row, 1, cols.length);\n+\t\t\t\t\t\tprintSingleRow(colWidths, row);\n+\t\t\t\t\t\treceivedRowCount.addAndGet(1);", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI1MDc5Mg==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386250792", "bodyText": "Why we need a displayResultExecutorService?", "author": "JingsongLi", "createdAt": "2020-03-02T08:28:56Z", "path": "flink-table/flink-sql-client/src/main/java/org/apache/flink/table/client/cli/CliTableauResultView.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.client.cli;\n+\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.client.gateway.Executor;\n+import org.apache.flink.table.client.gateway.ResultDescriptor;\n+import org.apache.flink.table.client.gateway.SqlExecutionException;\n+import org.apache.flink.table.client.gateway.TypedResult;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.SmallIntType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.TinyIntType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.jline.terminal.Terminal;\n+\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Stream;\n+\n+import static org.apache.flink.table.client.cli.CliUtils.rowToString;\n+\n+/**\n+ * Print result in tableau mode.\n+ */\n+public class CliTableauResultView implements Closeable {\n+\n+\tprivate static final int NULL_COLUMN_WIDTH = CliStrings.NULL_COLUMN.length();\n+\tprivate static final int MAX_COLUMN_WIDTH = 30;\n+\tprivate static final int DEFAULT_COLUMN_WIDTH = 20;\n+\tprivate static final String COLUMN_TRUNCATED_FLAG = \"...\";\n+\tprivate static final String CHANGEFLAG_COLUMN_NAME = \"+/-\";\n+\n+\tprivate final Terminal terminal;\n+\tprivate final Executor sqlExecutor;\n+\tprivate final String sessionId;\n+\tprivate final ResultDescriptor resultDescriptor;\n+\tprivate final ExecutorService displayResultExecutorService;", "originalCommit": "87fcf8d5a1309a85519e0a09df0191acd515c15d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjM4NTYzNQ==", "url": "https://github.com/apache/flink/pull/11273#discussion_r386385635", "bodyText": "we need another thread to wait and read job's result, and keep main thread available for cancelling the running job, like using CTRL-C", "author": "KurtYoung", "createdAt": "2020-03-02T13:17:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjI1MDc5Mg=="}], "type": "inlineReview"}, {"oid": "242efcdc3170341c5f8ccef5b29f3317cead3fa3", "url": "https://github.com/apache/flink/commit/242efcdc3170341c5f8ccef5b29f3317cead3fa3", "message": "[FLINK-12814][sql-client] Support a traditional and scrolling view of result (tableau format)\n\nThis closes #11273", "committedDate": "2020-03-03T06:35:15Z", "type": "commit"}, {"oid": "242efcdc3170341c5f8ccef5b29f3317cead3fa3", "url": "https://github.com/apache/flink/commit/242efcdc3170341c5f8ccef5b29f3317cead3fa3", "message": "[FLINK-12814][sql-client] Support a traditional and scrolling view of result (tableau format)\n\nThis closes #11273", "committedDate": "2020-03-03T06:35:15Z", "type": "forcePushed"}]}