{"pr_number": 13789, "pr_title": "[FLINK-19727][table-runtime] Implement ParallelismProvider for sink i\u2026", "pr_createdAt": "2020-10-26T04:22:27Z", "pr_url": "https://github.com/apache/flink/pull/13789", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcxMzk3MA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r511713970", "bodyText": "Actually, this part should be under well discussed.\nFor every changelog mode, from my perspective, should be treated differently. Now I only figured out what should be done in UPSERT MODE or INSERT_ONLY mode.\nWhat shall we do for other changelog modes?\nWDYT?", "author": "shouweikun", "createdAt": "2020-10-26T04:27:57Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +105,33 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        val inputParallelism = inputTransformation.getParallelism\n+        val taskParallelism = env.getParallelism\n+        val parallelism = if (runtimeProvider.isInstanceOf[ParallelismProvider]) runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism.orElse(inputParallelism).intValue()\n+        else inputParallelism\n+\n+        if (implicitly[Ordering[Int]].lteq(parallelism, 0)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism should not be less than zero or equal to zero\")\n+        if (implicitly[Ordering[Int]].gt(parallelism, taskParallelism)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism is larger than the task max parallelism: $taskParallelism\")\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val containedRowKinds = changelogMode.getContainedKinds.toSet\n+        val theFinalInputTransformation = if(inputParallelism == parallelism) inputTransformation //if the parallelism is not changed, do nothing\n+        else (containedRowKinds, primaryKeys.toList) match {\n+        // fixme : if rowKinds only contains  delete, is there somethinng to do with? Currently do nothing.", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MzkwOA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513153908", "bodyText": "Yes, you can just changelogMode  == ChangelogMode.INSERT_ONLY (scala, java should use equals), and do keyBy.", "author": "JingsongLi", "createdAt": "2020-10-28T03:11:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcxMzk3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2OTA3MA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513169070", "bodyText": "@JingsongLi\nI only do keyBy on ChangelogMode which contains update_after, while on other changelogMode I just keep the transformation with do nothing upon it. Is that Proper or not?", "author": "shouweikun", "createdAt": "2020-10-28T04:09:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcxMzk3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcxNjE5Mg==", "url": "https://github.com/apache/flink/pull/13789#discussion_r511716192", "bodyText": "I enumerated all the changelog mode conditions by using Scala match pattern.\nSo that we can esaily modify every condition in its own scope.", "author": "shouweikun", "createdAt": "2020-10-26T04:38:56Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +105,33 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        val inputParallelism = inputTransformation.getParallelism\n+        val taskParallelism = env.getParallelism\n+        val parallelism = if (runtimeProvider.isInstanceOf[ParallelismProvider]) runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism.orElse(inputParallelism).intValue()\n+        else inputParallelism\n+\n+        if (implicitly[Ordering[Int]].lteq(parallelism, 0)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism should not be less than zero or equal to zero\")\n+        if (implicitly[Ordering[Int]].gt(parallelism, taskParallelism)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism is larger than the task max parallelism: $taskParallelism\")\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val containedRowKinds = changelogMode.getContainedKinds.toSet\n+        val theFinalInputTransformation = if(inputParallelism == parallelism) inputTransformation //if the parallelism is not changed, do nothing\n+        else (containedRowKinds, primaryKeys.toList) match {\n+        // fixme : if rowKinds only contains  delete, is there somethinng to do with? Currently do nothing.\n+        case (_, _) if(containedRowKinds == Set(RowKind.DELETE)) => inputTransformation\n+        case (_, _) if(containedRowKinds == Set(RowKind.INSERT)) => inputTransformation\n+        // fixme: for retract mode (insert and delete contains only), is there somethinng to do with? Currently do nothing.\n+        case (_, _) if(containedRowKinds == Set(RowKind.INSERT,RowKind.DELETE)) => inputTransformation\n+        case (_, Nil) if(containedRowKinds.contains(RowKind.UPDATE_AFTER)) => throw new RuntimeException(s\"ChangelogMode contains ${RowKind.UPDATE_AFTER}, but no primaryKeys were found\")\n+        case (_, _) if(containedRowKinds.contains(RowKind.UPDATE_AFTER)) => new DataStream[RowData](env,inputTransformation).keyBy(primaryKeys:_*).getTransformation\n+        case _ => throw new RuntimeException(s\"the changelogMode is: ${containedRowKinds.mkString(\",\")}, which is not supported\")\n+      }\n+", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MTcxMQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513151711", "bodyText": "I think we don't need provide method.\nhttps://flink.apache.org/contributing/code-style-and-quality-java.html#java-optional\nIn Flink code style, it is recommended to use the Optional only in method return values.", "author": "JingsongLi", "createdAt": "2020-10-28T03:03:40Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/connector/sink/SinkFunctionProvider.java", "diffHunk": "@@ -20,19 +20,39 @@\n \n import org.apache.flink.annotation.PublicEvolving;\n import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ParallelismProvider;\n import org.apache.flink.table.data.RowData;\n \n+import java.util.Optional;\n+\n /**\n  * Provider of a {@link SinkFunction} instance as a runtime implementation for {@link DynamicTableSink}.\n  */\n @PublicEvolving\n-public interface SinkFunctionProvider extends DynamicTableSink.SinkRuntimeProvider {\n+public interface SinkFunctionProvider extends DynamicTableSink.SinkRuntimeProvider, ParallelismProvider {\n \n \t/**\n \t * Helper method for creating a static provider.\n \t */\n \tstatic SinkFunctionProvider of(SinkFunction<RowData> sinkFunction) {\n-\t\treturn () -> sinkFunction;\n+\t\treturn of(sinkFunction, Optional.empty());\n+\t}\n+\n+\t/**\n+\t * Helper method for creating a static provider, sink parallelism will be configured if non-empty parallelism is passed in.\n+\t */\n+\tstatic SinkFunctionProvider of(SinkFunction<RowData> sinkFunction, Optional<Integer> parallelism) {", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2NzIxMg==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513167212", "bodyText": "@JingsongLi\nit is recommended to use the Optional only in method return values\ncopy that.\nI think we don't need provide method.\nWell, since SinkFunctionProvider  implements ParallelismProvider as default, as far as I\u2019m concerned, there should be a method passing the parallelism in. Or Is there an better alternative? It\u2018s kind of u to tell me that~", "author": "shouweikun", "createdAt": "2020-10-28T04:02:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MTcxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2OTIwNg==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513169206", "bodyText": "For the user which want to set parallelism, I think it is OK to let them create an implementation class.", "author": "JingsongLi", "createdAt": "2020-10-28T04:10:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MTcxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MTc0MQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513151741", "bodyText": "ditto", "author": "JingsongLi", "createdAt": "2020-10-28T03:03:48Z", "path": "flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java", "diffHunk": "@@ -20,19 +20,39 @@\n \n import org.apache.flink.annotation.PublicEvolving;\n import org.apache.flink.api.common.io.OutputFormat;\n+import org.apache.flink.table.connector.ParallelismProvider;\n import org.apache.flink.table.data.RowData;\n \n+import java.util.Optional;\n+\n /**\n  * Provider of an {@link OutputFormat} instance as a runtime implementation for {@link DynamicTableSink}.\n  */\n @PublicEvolving\n-public interface OutputFormatProvider extends DynamicTableSink.SinkRuntimeProvider {\n+public interface OutputFormatProvider extends DynamicTableSink.SinkRuntimeProvider, ParallelismProvider{\n \n \t/**\n \t * Helper method for creating a static provider.\n \t */\n \tstatic OutputFormatProvider of(OutputFormat<RowData> outputFormat) {\n-\t\treturn () -> outputFormat;\n+\t\treturn of(outputFormat, Optional.empty());\n+\t}\n+\n+\t/**\n+\t * Helper method for creating a static provider, sink parallelism will be configured if non-empty parallelism is passed in.\n+\t */\n+\tstatic OutputFormatProvider of(OutputFormat<RowData> outputFormat, Optional<Integer> parallelism) {", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MjEzNw==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513152137", "bodyText": "TableException", "author": "JingsongLi", "createdAt": "2020-10-28T03:05:15Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -79,6 +84,7 @@ class CommonPhysicalSink (\n     val enforcer = new SinkNotNullEnforcer(notNullEnforcer, notNullFieldIndices, fieldNames)\n \n     runtimeProvider match {\n+      case _: DataStreamSinkProvider with ParallelismProvider => throw new RuntimeException(\"`DataStreamSinkProvider` is not allowed to work with `ParallelismProvider`, please see document of `ParallelismProvider`\")", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MjMwMA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513152300", "bodyText": "not to have too long lines", "author": "JingsongLi", "createdAt": "2020-10-28T03:05:46Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -79,6 +84,7 @@ class CommonPhysicalSink (\n     val enforcer = new SinkNotNullEnforcer(notNullEnforcer, notNullFieldIndices, fieldNames)\n \n     runtimeProvider match {\n+      case _: DataStreamSinkProvider with ParallelismProvider => throw new RuntimeException(\"`DataStreamSinkProvider` is not allowed to work with `ParallelismProvider`, please see document of `ParallelismProvider`\")", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1Mjc5OQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513152799", "bodyText": "env.getMaxParallelism?", "author": "JingsongLi", "createdAt": "2020-10-28T03:07:35Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +105,33 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        val inputParallelism = inputTransformation.getParallelism\n+        val taskParallelism = env.getParallelism", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2NTQwNw==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513165407", "bodyText": "Well,  correct me if i am wrong, getMaxParallelism is the upper bound of parallelism that the task can apply.\ngetParallelism  is the actual parallelism that the task applies", "author": "shouweikun", "createdAt": "2020-10-28T03:54:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1Mjc5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2NTYwOA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513165608", "bodyText": "Since we don\u2018t need to do this according to the conversation below here, it is fine to remove this line.", "author": "shouweikun", "createdAt": "2020-10-28T03:55:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1Mjc5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1Mjg2MQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513152861", "bodyText": "We don't need verify env.getMaxParallelism, DataStream layer will verify it.", "author": "JingsongLi", "createdAt": "2020-10-28T03:07:49Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +105,33 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        val inputParallelism = inputTransformation.getParallelism\n+        val taskParallelism = env.getParallelism\n+        val parallelism = if (runtimeProvider.isInstanceOf[ParallelismProvider]) runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism.orElse(inputParallelism).intValue()\n+        else inputParallelism\n+\n+        if (implicitly[Ordering[Int]].lteq(parallelism, 0)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism should not be less than zero or equal to zero\")\n+        if (implicitly[Ordering[Int]].gt(parallelism, taskParallelism)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism is larger than the task max parallelism: $taskParallelism\")", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1Mjk3Nw==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513152977", "bodyText": "Remove isInstanceOf, it must be", "author": "JingsongLi", "createdAt": "2020-10-28T03:08:23Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +105,33 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        val inputParallelism = inputTransformation.getParallelism\n+        val taskParallelism = env.getParallelism\n+        val parallelism = if (runtimeProvider.isInstanceOf[ParallelismProvider]) runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism.orElse(inputParallelism).intValue()", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2NDE4NQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513164185", "bodyText": "My concern is that once a NEW provider without parallelismProvider is used, exception will be thrown unless we do not check the type", "author": "shouweikun", "createdAt": "2020-10-28T03:50:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1Mjk3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2ODY3Ng==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513168676", "bodyText": "Add a scala assert is enough.", "author": "JingsongLi", "createdAt": "2020-10-28T04:08:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1Mjk3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MzIwNw==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513153207", "bodyText": "Just parallelism <= 0?", "author": "JingsongLi", "createdAt": "2020-10-28T03:09:20Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +105,33 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        val inputParallelism = inputTransformation.getParallelism\n+        val taskParallelism = env.getParallelism\n+        val parallelism = if (runtimeProvider.isInstanceOf[ParallelismProvider]) runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism.orElse(inputParallelism).intValue()\n+        else inputParallelism\n+\n+        if (implicitly[Ordering[Int]].lteq(parallelism, 0)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism should not be less than zero or equal to zero\")", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2MzY2Mg==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513163662", "bodyText": "Sure, btw should TableException also be thrown here instead of RuntimeException?\n@JingsongLi", "author": "shouweikun", "createdAt": "2020-10-28T03:48:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MzIwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE2ODc3Ng==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513168776", "bodyText": "Yes, should always throw TableException", "author": "JingsongLi", "createdAt": "2020-10-28T04:08:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE1MzIwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzE3MjQxMQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513172411", "bodyText": "About how to HASH_DISTRIBUTED, you should take a look to StreamExecExchange", "author": "JingsongLi", "createdAt": "2020-10-28T04:24:06Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +105,33 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        val inputParallelism = inputTransformation.getParallelism\n+        val taskParallelism = env.getParallelism\n+        val parallelism = if (runtimeProvider.isInstanceOf[ParallelismProvider]) runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism.orElse(inputParallelism).intValue()\n+        else inputParallelism\n+\n+        if (implicitly[Ordering[Int]].lteq(parallelism, 0)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism should not be less than zero or equal to zero\")\n+        if (implicitly[Ordering[Int]].gt(parallelism, taskParallelism)) throw new RuntimeException(s\"the configured sink parallelism: $parallelism is larger than the task max parallelism: $taskParallelism\")\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val containedRowKinds = changelogMode.getContainedKinds.toSet\n+        val theFinalInputTransformation = if(inputParallelism == parallelism) inputTransformation //if the parallelism is not changed, do nothing\n+        else (containedRowKinds, primaryKeys.toList) match {\n+        // fixme : if rowKinds only contains  delete, is there somethinng to do with? Currently do nothing.\n+        case (_, _) if(containedRowKinds == Set(RowKind.DELETE)) => inputTransformation\n+        case (_, _) if(containedRowKinds == Set(RowKind.INSERT)) => inputTransformation\n+        // fixme: for retract mode (insert and delete contains only), is there somethinng to do with? Currently do nothing.\n+        case (_, _) if(containedRowKinds == Set(RowKind.INSERT,RowKind.DELETE)) => inputTransformation\n+        case (_, Nil) if(containedRowKinds.contains(RowKind.UPDATE_AFTER)) => throw new RuntimeException(s\"ChangelogMode contains ${RowKind.UPDATE_AFTER}, but no primaryKeys were found\")\n+        case (_, _) if(containedRowKinds.contains(RowKind.UPDATE_AFTER)) => new DataStream[RowData](env,inputTransformation).keyBy(primaryKeys:_*).getTransformation", "originalCommit": "6329930d7acc5d2d4d84e777561e79bd25ac9367", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1NDEzOQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513954139", "bodyText": "Code format: It is ok to include in one line", "author": "JingsongLi", "createdAt": "2020-10-29T04:23:11Z", "path": "flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/OutputFormatProvider.java", "diffHunk": "@@ -20,13 +20,15 @@\n \n import org.apache.flink.annotation.PublicEvolving;\n import org.apache.flink.api.common.io.OutputFormat;\n+import org.apache.flink.table.connector.ParallelismProvider;\n import org.apache.flink.table.data.RowData;\n \n /**\n  * Provider of an {@link OutputFormat} instance as a runtime implementation for {@link DynamicTableSink}.\n  */\n @PublicEvolving\n-public interface OutputFormatProvider extends DynamicTableSink.SinkRuntimeProvider {\n+public interface OutputFormatProvider", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1NDI0Ng==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513954246", "bodyText": "Code format: It is ok to include in one line", "author": "JingsongLi", "createdAt": "2020-10-29T04:23:20Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/connector/sink/SinkFunctionProvider.java", "diffHunk": "@@ -20,13 +20,15 @@\n \n import org.apache.flink.annotation.PublicEvolving;\n import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.table.connector.ParallelismProvider;\n import org.apache.flink.table.data.RowData;\n \n /**\n  * Provider of a {@link SinkFunction} instance as a runtime implementation for {@link DynamicTableSink}.\n  */\n @PublicEvolving\n-public interface SinkFunctionProvider extends DynamicTableSink.SinkRuntimeProvider {\n+public interface SinkFunctionProvider", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1NDY2NQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513954665", "bodyText": "Code format: Better to break line when throw new Table...", "author": "JingsongLi", "createdAt": "2020-10-29T04:24:01Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -79,6 +87,10 @@ class CommonPhysicalSink (\n     val enforcer = new SinkNotNullEnforcer(notNullEnforcer, notNullFieldIndices, fieldNames)\n \n     runtimeProvider match {\n+      case _: DataStreamSinkProvider with ParallelismProvider => throw new TableException(", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1NDkzMg==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513954932", "bodyText": "Code format: Better to fill one line (max 100 chars)", "author": "JingsongLi", "createdAt": "2020-10-29T04:24:30Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -79,6 +87,10 @@ class CommonPhysicalSink (\n     val enforcer = new SinkNotNullEnforcer(notNullEnforcer, notNullFieldIndices, fieldNames)\n \n     runtimeProvider match {\n+      case _: DataStreamSinkProvider with ParallelismProvider => throw new TableException(\n+        \"`DataStreamSinkProvider` is not allowed to \" +", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1NTU0Nw==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513955547", "bodyText": "Code format:\nelse {\n  inputParallelism\n}", "author": "JingsongLi", "createdAt": "2020-10-29T04:25:39Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +111,63 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+              \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider\n+            .asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {\n+            val parallelismPassedIn = parallelismOptional.get().intValue()\n+            if(parallelismPassedIn <= 0) {\n+              throw new TableException(\n+                s\"Table: $tableIdentifier configured sink parallelism: $parallelismPassedIn \" +\n+                  \"should not be less than zero or equal to zero\")\n+            }\n+            parallelismPassedIn\n+          } else inputParallelism", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1NTY4NA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513955684", "bodyText": "Code format:Not break line", "author": "JingsongLi", "createdAt": "2020-10-29T04:25:53Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +111,63 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+              \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider\n+            .asInstanceOf[ParallelismProvider].getParallelism", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1NjI4MQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513956281", "bodyText": "I think it is better to use if else here.", "author": "JingsongLi", "createdAt": "2020-10-29T04:27:00Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +111,63 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+              \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider\n+            .asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {\n+            val parallelismPassedIn = parallelismOptional.get().intValue()\n+            if(parallelismPassedIn <= 0) {\n+              throw new TableException(\n+                s\"Table: $tableIdentifier configured sink parallelism: $parallelismPassedIn \" +\n+                  \"should not be less than zero or equal to zero\")\n+            }\n+            parallelismPassedIn\n+          } else inputParallelism\n+        }\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val theFinalInputTransformation =\n+          (inputParallelism == parallelism,changelogMode, primaryKeys.toList) match {", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1NzI1Mg==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513957252", "bodyText": "Code format: Better to fill one line (max 100 chars)", "author": "JingsongLi", "createdAt": "2020-10-29T04:28:47Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +111,63 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+              \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider\n+            .asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {\n+            val parallelismPassedIn = parallelismOptional.get().intValue()\n+            if(parallelismPassedIn <= 0) {\n+              throw new TableException(\n+                s\"Table: $tableIdentifier configured sink parallelism: $parallelismPassedIn \" +\n+                  \"should not be less than zero or equal to zero\")\n+            }\n+            parallelismPassedIn\n+          } else inputParallelism\n+        }\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val theFinalInputTransformation =\n+          (inputParallelism == parallelism,changelogMode, primaryKeys.toList) match {\n+           // if the inputParallelism equals parallelism, do nothing.\n+          case (true, _, _) => inputTransformation\n+          case (_, _, _) if (changelogMode.containsOnly(RowKind.INSERT)) => inputTransformation\n+          case (_, _, Nil) =>\n+            throw new TableException(\n+            s\"Table: $tableIdentifier configured sink parallelism is: $parallelism, \" +\n+            s\"while the input parallelism is: $inputParallelism. \" +", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1ODEwOA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513958108", "bodyText": "Not break line", "author": "JingsongLi", "createdAt": "2020-10-29T04:30:30Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +111,63 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+              \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider\n+            .asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {\n+            val parallelismPassedIn = parallelismOptional.get().intValue()\n+            if(parallelismPassedIn <= 0) {\n+              throw new TableException(\n+                s\"Table: $tableIdentifier configured sink parallelism: $parallelismPassedIn \" +\n+                  \"should not be less than zero or equal to zero\")\n+            }\n+            parallelismPassedIn\n+          } else inputParallelism\n+        }\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val theFinalInputTransformation =\n+          (inputParallelism == parallelism,changelogMode, primaryKeys.toList) match {\n+           // if the inputParallelism equals parallelism, do nothing.\n+          case (true, _, _) => inputTransformation\n+          case (_, _, _) if (changelogMode.containsOnly(RowKind.INSERT)) => inputTransformation\n+          case (_, _, Nil) =>\n+            throw new TableException(\n+            s\"Table: $tableIdentifier configured sink parallelism is: $parallelism, \" +\n+            s\"while the input parallelism is: $inputParallelism. \" +\n+            s\"Since the changelog mode \" +\n+            s\"contains [${changelogMode.getContainedKinds.toList.mkString(\",\")}], \" +\n+            s\"which is not INSERT_ONLY mode, \" +\n+            s\"primary key is required but no primary key is found\"\n+          )\n+          case (_, _, pks) =>\n+            //key by before sink\n+            //according to [[StreamExecExchange]]\n+            val selector = KeySelectorUtil.getRowDataSelector(\n+              pks.toArray, inputTypeInfo)", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1ODk1MQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513958951", "bodyText": "Why need to check env.getMaxParallelism?", "author": "JingsongLi", "createdAt": "2020-10-29T04:32:09Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +111,63 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+              \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider\n+            .asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {\n+            val parallelismPassedIn = parallelismOptional.get().intValue()\n+            if(parallelismPassedIn <= 0) {\n+              throw new TableException(\n+                s\"Table: $tableIdentifier configured sink parallelism: $parallelismPassedIn \" +\n+                  \"should not be less than zero or equal to zero\")\n+            }\n+            parallelismPassedIn\n+          } else inputParallelism\n+        }\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val theFinalInputTransformation =\n+          (inputParallelism == parallelism,changelogMode, primaryKeys.toList) match {\n+           // if the inputParallelism equals parallelism, do nothing.\n+          case (true, _, _) => inputTransformation\n+          case (_, _, _) if (changelogMode.containsOnly(RowKind.INSERT)) => inputTransformation\n+          case (_, _, Nil) =>\n+            throw new TableException(\n+            s\"Table: $tableIdentifier configured sink parallelism is: $parallelism, \" +\n+            s\"while the input parallelism is: $inputParallelism. \" +\n+            s\"Since the changelog mode \" +\n+            s\"contains [${changelogMode.getContainedKinds.toList.mkString(\",\")}], \" +\n+            s\"which is not INSERT_ONLY mode, \" +\n+            s\"primary key is required but no primary key is found\"\n+          )\n+          case (_, _, pks) =>\n+            //key by before sink\n+            //according to [[StreamExecExchange]]\n+            val selector = KeySelectorUtil.getRowDataSelector(\n+              pks.toArray, inputTypeInfo)\n+            // in case of maxParallelism is negative\n+            val keyGroupNum = env.getMaxParallelism match {", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDAxNzA1MA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r514017050", "bodyText": "Ok, just use DEFAULT_LOWER_BOUND_MAX_PARALLELISM?", "author": "shouweikun", "createdAt": "2020-10-29T06:28:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1ODk1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDAxOTIyOA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r514019228", "bodyText": "Yes", "author": "JingsongLi", "createdAt": "2020-10-29T06:31:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1ODk1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzk1OTM3MQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r513959371", "bodyText": "selector,keyGroupNum => selector, keyGroupNum", "author": "JingsongLi", "createdAt": "2020-10-29T04:32:58Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +111,63 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+              \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider\n+            .asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {\n+            val parallelismPassedIn = parallelismOptional.get().intValue()\n+            if(parallelismPassedIn <= 0) {\n+              throw new TableException(\n+                s\"Table: $tableIdentifier configured sink parallelism: $parallelismPassedIn \" +\n+                  \"should not be less than zero or equal to zero\")\n+            }\n+            parallelismPassedIn\n+          } else inputParallelism\n+        }\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val theFinalInputTransformation =\n+          (inputParallelism == parallelism,changelogMode, primaryKeys.toList) match {\n+           // if the inputParallelism equals parallelism, do nothing.\n+          case (true, _, _) => inputTransformation\n+          case (_, _, _) if (changelogMode.containsOnly(RowKind.INSERT)) => inputTransformation\n+          case (_, _, Nil) =>\n+            throw new TableException(\n+            s\"Table: $tableIdentifier configured sink parallelism is: $parallelism, \" +\n+            s\"while the input parallelism is: $inputParallelism. \" +\n+            s\"Since the changelog mode \" +\n+            s\"contains [${changelogMode.getContainedKinds.toList.mkString(\",\")}], \" +\n+            s\"which is not INSERT_ONLY mode, \" +\n+            s\"primary key is required but no primary key is found\"\n+          )\n+          case (_, _, pks) =>\n+            //key by before sink\n+            //according to [[StreamExecExchange]]\n+            val selector = KeySelectorUtil.getRowDataSelector(\n+              pks.toArray, inputTypeInfo)\n+            // in case of maxParallelism is negative\n+            val keyGroupNum = env.getMaxParallelism match {\n+              case -1 => env.getParallelism\n+              case x if(x > 0) => env.getMaxParallelism\n+              case _ => DEFAULT_LOWER_BOUND_MAX_PARALLELISM\n+            }\n+            val partitioner = new KeyGroupStreamPartitioner(selector,keyGroupNum)", "originalCommit": "a42eba2756d3ebfe1a6a73b58b31c12ff98435fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDA1MzA2Ng==", "url": "https://github.com/apache/flink/pull/13789#discussion_r514053066", "bodyText": "NOTE, code style should be if (.", "author": "JingsongLi", "createdAt": "2020-10-29T07:31:58Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +110,57 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+          \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {", "originalCommit": "5caa50b63ed2b7a172ee9c47aff4ea36e40cbb6b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDA1NDUwNg==", "url": "https://github.com/apache/flink/pull/13789#discussion_r514054506", "bodyText": "if (inputParallelism == parallelism || changelogMode.containsOnly(RowKind.INSERT)) {\n}", "author": "JingsongLi", "createdAt": "2020-10-29T07:35:05Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +110,57 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+          \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {\n+            val parallelismPassedIn = parallelismOptional.get().intValue()\n+            if(parallelismPassedIn <= 0) {\n+              throw new TableException(s\"Table: $tableIdentifier configured sink parallelism: \" +\n+                s\"$parallelismPassedIn should not be less than zero or equal to zero\")\n+            }\n+            parallelismPassedIn\n+          } else {\n+            inputParallelism\n+          }\n+        }\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val theFinalInputTransformation = if (inputParallelism == parallelism) {", "originalCommit": "5caa50b63ed2b7a172ee9c47aff4ea36e40cbb6b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDA1NTUyMQ==", "url": "https://github.com/apache/flink/pull/13789#discussion_r514055521", "bodyText": "if (primaryKeys.isEmpty)?", "author": "JingsongLi", "createdAt": "2020-10-29T07:37:29Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/plan/nodes/common/CommonPhysicalSink.scala", "diffHunk": "@@ -99,11 +110,57 @@ class CommonPhysicalSink (\n \n         val operator = new SinkOperator(env.clean(sinkFunction), rowtimeFieldIndex, enforcer)\n \n+        assert(runtimeProvider.isInstanceOf[ParallelismProvider],\n+          \"runtimeProvider with `ParallelismProvider` implementation is required\")\n+\n+        val inputParallelism = inputTransformation.getParallelism\n+        val parallelism =  {\n+          val parallelismOptional = runtimeProvider.asInstanceOf[ParallelismProvider].getParallelism\n+          if(parallelismOptional.isPresent) {\n+            val parallelismPassedIn = parallelismOptional.get().intValue()\n+            if(parallelismPassedIn <= 0) {\n+              throw new TableException(s\"Table: $tableIdentifier configured sink parallelism: \" +\n+                s\"$parallelismPassedIn should not be less than zero or equal to zero\")\n+            }\n+            parallelismPassedIn\n+          } else {\n+            inputParallelism\n+          }\n+        }\n+\n+        val primaryKeys = TableSchemaUtils.getPrimaryKeyIndices(catalogTable.getSchema)\n+        val theFinalInputTransformation = if (inputParallelism == parallelism) {\n+          // if the inputParallelism is equals to the parallelism, do nothing.\n+          inputTransformation\n+        } else {\n+          (changelogMode, primaryKeys.toList) match {\n+            case (_, _) if (changelogMode.containsOnly(RowKind.INSERT)) => inputTransformation\n+            case (_, Nil) =>", "originalCommit": "5caa50b63ed2b7a172ee9c47aff4ea36e40cbb6b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDA3Nzg2Mw==", "url": "https://github.com/apache/flink/pull/13789#discussion_r514077863", "bodyText": "This line is too long, you can break it.", "author": "JingsongLi", "createdAt": "2020-10-29T08:22:58Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableFactory.java", "diffHunk": "@@ -386,9 +394,11 @@ public DynamicTableSink createDynamicTableSink(Context context) {\n \t\tboolean isInsertOnly = helper.getOptions().get(SINK_INSERT_ONLY);\n \t\tString runtimeSink = helper.getOptions().get(RUNTIME_SINK);\n \t\tint expectedNum = helper.getOptions().get(SINK_EXPECTED_MESSAGES_NUM);\n+\t\tInteger parallelism = helper.getOptions().get(SINK_PARALLELISM);\n \t\tfinal Map<String, DataType> writableMetadata = convertToMetadataMap(\n \t\t\thelper.getOptions().get(WRITABLE_METADATA),\n \t\t\tcontext.getClassLoader());\n+\t\tChangelogMode changelogMode = Optional.ofNullable(helper.getOptions().get(SINK_CHANGELOG_MODE_ENFORCED)).map(m -> parseChangelogMode(m)).orElse(null);", "originalCommit": "8cca8ea8baa8f718138404c4a605f85f9c323723", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDA3Nzk3OA==", "url": "https://github.com/apache/flink/pull/13789#discussion_r514077978", "bodyText": "Don't break line", "author": "JingsongLi", "createdAt": "2020-10-29T08:23:08Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableFactory.java", "diffHunk": "@@ -929,10 +943,13 @@ public String asSummaryString() {\n \t\tprivate DataType consumedDataType;\n \t\tprivate int[] primaryKeyIndices;\n \t\tprivate final String tableName;\n-\t\tprivate final boolean isInsertOnly;\n+\t\tprivate final boolean\n+\t\t\tisInsertOnly;", "originalCommit": "8cca8ea8baa8f718138404c4a605f85f9c323723", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0bfd51270d53b57c1449f560854b2c1d4951a411", "url": "https://github.com/apache/flink/commit/0bfd51270d53b57c1449f560854b2c1d4951a411", "message": "[FLINK-19727][table-runtime] Implement ParallelismProvider for sink in blink planner", "committedDate": "2020-11-02T06:45:26Z", "type": "commit"}, {"oid": "a97796b4cf8d0228ef6b0552c5be81ad75121a6d", "url": "https://github.com/apache/flink/commit/a97796b4cf8d0228ef6b0552c5be81ad75121a6d", "message": "addressing review comments", "committedDate": "2020-11-02T06:45:26Z", "type": "commit"}, {"oid": "7724b91de5d51cbd70b41c4edde0a1f0021bd7e0", "url": "https://github.com/apache/flink/commit/7724b91de5d51cbd70b41c4edde0a1f0021bd7e0", "message": " remove of factory method", "committedDate": "2020-11-02T06:45:26Z", "type": "commit"}, {"oid": "c8b90e46b9982fff464370afb3adf1dad411c37c", "url": "https://github.com/apache/flink/commit/c8b90e46b9982fff464370afb3adf1dad411c37c", "message": "fix checkstyle", "committedDate": "2020-11-02T06:45:26Z", "type": "commit"}, {"oid": "64560c4b5b90cb16b26177b3c71e9064febe9250", "url": "https://github.com/apache/flink/commit/64560c4b5b90cb16b26177b3c71e9064febe9250", "message": "fix checkstyle", "committedDate": "2020-11-02T06:45:26Z", "type": "commit"}, {"oid": "e7cb3eb4668985672c5b41ca734e2029b741f949", "url": "https://github.com/apache/flink/commit/e7cb3eb4668985672c5b41ca734e2029b741f949", "message": "address review comments", "committedDate": "2020-11-02T06:45:27Z", "type": "commit"}, {"oid": "4c11c88ecaea058b37fcbaf13007306c4c4860d5", "url": "https://github.com/apache/flink/commit/4c11c88ecaea058b37fcbaf13007306c4c4860d5", "message": "address comments", "committedDate": "2020-11-02T06:45:27Z", "type": "commit"}, {"oid": "3e5737980ff49e901d90416b7c162a5ee5d2c048", "url": "https://github.com/apache/flink/commit/3e5737980ff49e901d90416b7c162a5ee5d2c048", "message": "address comments", "committedDate": "2020-11-02T06:45:27Z", "type": "commit"}, {"oid": "c5bdf9f9a370250e02e7c21492c15e5547777165", "url": "https://github.com/apache/flink/commit/c5bdf9f9a370250e02e7c21492c15e5547777165", "message": "Minor code style", "committedDate": "2020-11-02T06:47:35Z", "type": "commit"}, {"oid": "c5bdf9f9a370250e02e7c21492c15e5547777165", "url": "https://github.com/apache/flink/commit/c5bdf9f9a370250e02e7c21492c15e5547777165", "message": "Minor code style", "committedDate": "2020-11-02T06:47:35Z", "type": "forcePushed"}]}