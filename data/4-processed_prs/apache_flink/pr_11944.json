{"pr_number": 11944, "pr_title": "[FLINK-17461][formats][json] Support JSON serialization and deseriazation schema for RowData type", "pr_createdAt": "2020-04-29T10:33:40Z", "pr_url": "https://github.com/apache/flink/pull/11944", "timeline": [{"oid": "de28bae2536983745bdf14f1b15b1929d7ff0956", "url": "https://github.com/apache/flink/commit/de28bae2536983745bdf14f1b15b1929d7ff0956", "message": "[FLINK-17461][formats][json] Support JSON serialization and deseriazation schema for RowData type", "committedDate": "2020-04-29T10:33:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI4NDU5NA==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417284594", "bodyText": "Do we really need a builder for this class?", "author": "KurtYoung", "createdAt": "2020-04-29T12:43:32Z", "path": "flink-formats/flink-json/src/main/java/org/apache/flink/formats/json/JsonRowDataDeserializationSchema.java", "diffHunk": "@@ -0,0 +1,492 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.json;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.table.data.DecimalData;\n+import org.apache.flink.table.data.GenericArrayData;\n+import org.apache.flink.table.data.GenericMapData;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.data.TimestampData;\n+import org.apache.flink.table.types.logical.ArrayType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.LogicalTypeFamily;\n+import org.apache.flink.table.types.logical.MapType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.utils.LogicalTypeChecks;\n+import org.apache.flink.table.types.logical.utils.LogicalTypeUtils;\n+\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.JsonNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ArrayNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.TextNode;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.lang.reflect.Array;\n+import java.math.BigDecimal;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.ZoneOffset;\n+import java.time.temporal.TemporalAccessor;\n+import java.time.temporal.TemporalQueries;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+\n+import static java.lang.String.format;\n+import static java.time.format.DateTimeFormatter.ISO_LOCAL_DATE;\n+import static org.apache.flink.formats.json.TimeFormats.RFC3339_TIMESTAMP_FORMAT;\n+import static org.apache.flink.formats.json.TimeFormats.RFC3339_TIME_FORMAT;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Deserialization schema from JSON to Flink Table/SQL internal data structure {@link RowData}.\n+ *\n+ * <p>Deserializes a <code>byte[]</code> message as a JSON object and reads\n+ * the specified fields.\n+ *\n+ * <p>Failures during deserialization are forwarded as wrapped IOExceptions.\n+ */\n+@Internal\n+public class JsonRowDataDeserializationSchema implements DeserializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 8576854315236033439L;\n+\n+\t/** Flag indicating whether to fail if a field is missing. */\n+\tprivate final boolean failOnMissingField;\n+\n+\t/** Flag indicating whether to ignore invalid fields/rows (default: throw an exception). */\n+\tprivate final boolean ignoreParseErrors;\n+\n+\t/** TypeInformation of the produced {@link RowData}. **/\n+\tprivate final TypeInformation<RowData> resultTypeInfo;\n+\n+\t/**\n+\t * Runtime converter that converts {@link JsonNode}s into\n+\t * objects of Flink SQL internal data structures. **/\n+\tprivate final DeserializationRuntimeConverter runtimeConverter;\n+\n+\t/** Object mapper for parsing the JSON. */\n+\tprivate final ObjectMapper objectMapper = new ObjectMapper();\n+\n+\t/**\n+\t * Creates a builder for {@link JsonRowDataDeserializationSchema}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tprivate JsonRowDataDeserializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tTypeInformation<RowData> resultTypeInfo,\n+\t\t\tboolean failOnMissingField,\n+\t\t\tboolean ignoreParseErrors) {\n+\t\tif (ignoreParseErrors && failOnMissingField) {\n+\t\t\tthrow new IllegalArgumentException(\n+\t\t\t\t\"JSON format doesn't support failOnMissingField and ignoreParseErrors are both enabled.\");\n+\t\t}\n+\t\tthis.resultTypeInfo = checkNotNull(resultTypeInfo);\n+\t\tthis.failOnMissingField = failOnMissingField;\n+\t\tthis.ignoreParseErrors = ignoreParseErrors;\n+\t\tthis.runtimeConverter = createRowConverter(checkNotNull(rowType));\n+\t}\n+\n+\t@Override\n+\tpublic RowData deserialize(byte[] message) throws IOException {\n+\t\ttry {\n+\t\t\tfinal JsonNode root = objectMapper.readTree(message);\n+\t\t\treturn (RowData) runtimeConverter.convert(root);\n+\t\t} catch (Throwable t) {\n+\t\t\tif (ignoreParseErrors) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tthrow new IOException(format(\"Failed to deserialize JSON '%s'.\", new String(message)), t);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic boolean isEndOfStream(RowData nextElement) {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic TypeInformation<RowData> getProducedType() {\n+\t\treturn resultTypeInfo;\n+\t}\n+\n+\t// -------------------------------------------------------------------------------------\n+\t// Builder\n+\t// -------------------------------------------------------------------------------------\n+\n+\t/**\n+\t * Builder for {@link JsonRowDataDeserializationSchema}.\n+\t */\n+\tpublic static class Builder {", "originalCommit": "de28bae2536983745bdf14f1b15b1929d7ff0956", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM3NTY5OA==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417375698", "bodyText": "I think we will support more and more options for JSON in the future. A builder is more friendly to evolve without breaking constructors. But I'm also fine to remove builders because this is an @Internal class.", "author": "wuchong", "createdAt": "2020-04-29T14:48:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI4NDU5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI4OTEyNA==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417289124", "bodyText": "add data for type: TINYINT, SMALLINT and  FLOAT.\nAlso please cover the slow path of some special handled data type, like long, double, float", "author": "KurtYoung", "createdAt": "2020-04-29T12:50:58Z", "path": "flink-formats/flink-json/src/test/java/org/apache/flink/formats/json/JsonRowDataSerDeSchemaTest.java", "diffHunk": "@@ -0,0 +1,437 @@\n+package org.apache.flink.formats.json;\n+\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.util.DataFormatConverters;\n+import org.apache.flink.table.runtime.typeutils.RowDataTypeInfo;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ArrayNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode;\n+\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+\n+import java.io.IOException;\n+import java.math.BigDecimal;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ThreadLocalRandom;\n+\n+import static org.apache.flink.table.api.DataTypes.ARRAY;\n+import static org.apache.flink.table.api.DataTypes.BIGINT;\n+import static org.apache.flink.table.api.DataTypes.BOOLEAN;\n+import static org.apache.flink.table.api.DataTypes.BYTES;\n+import static org.apache.flink.table.api.DataTypes.DATE;\n+import static org.apache.flink.table.api.DataTypes.DECIMAL;\n+import static org.apache.flink.table.api.DataTypes.DOUBLE;\n+import static org.apache.flink.table.api.DataTypes.FIELD;\n+import static org.apache.flink.table.api.DataTypes.FLOAT;\n+import static org.apache.flink.table.api.DataTypes.INT;\n+import static org.apache.flink.table.api.DataTypes.MAP;\n+import static org.apache.flink.table.api.DataTypes.ROW;\n+import static org.apache.flink.table.api.DataTypes.STRING;\n+import static org.apache.flink.table.api.DataTypes.TIME;\n+import static org.apache.flink.table.api.DataTypes.TIMESTAMP;\n+import static org.apache.flink.table.types.utils.TypeConversions.fromLogicalToDataType;\n+import static org.junit.Assert.assertEquals;\n+\n+/**\n+ * Tests for {@link JsonRowDataDeserializationSchema} and {@link JsonRowDataSerializationSchema}.\n+ */\n+public class JsonRowDataSerDeSchemaTest {\n+\n+\t@Rule\n+\tpublic ExpectedException thrown = ExpectedException.none();\n+\n+\t@Test\n+\tpublic void testSerDe() throws Exception {\n+\t\tlong id = 1238123899121L;", "originalCommit": "de28bae2536983745bdf14f1b15b1929d7ff0956", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM3NjMzNQ==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417376335", "bodyText": "I added the slow path tests into another test method, because the serde is not bidirectional consistent.", "author": "wuchong", "createdAt": "2020-04-29T14:49:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI4OTEyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI5NDMyNA==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417294324", "bodyText": "If we enable ignoreParseErrors, and key or value is invalid, we will still meet NPE here sine HashMap doesn't allow null values.", "author": "KurtYoung", "createdAt": "2020-04-29T12:59:14Z", "path": "flink-formats/flink-json/src/main/java/org/apache/flink/formats/json/JsonRowDataDeserializationSchema.java", "diffHunk": "@@ -0,0 +1,492 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.json;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.DeserializationSchema;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.table.data.DecimalData;\n+import org.apache.flink.table.data.GenericArrayData;\n+import org.apache.flink.table.data.GenericMapData;\n+import org.apache.flink.table.data.GenericRowData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.StringData;\n+import org.apache.flink.table.data.TimestampData;\n+import org.apache.flink.table.types.logical.ArrayType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.LogicalTypeFamily;\n+import org.apache.flink.table.types.logical.MapType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.utils.LogicalTypeChecks;\n+import org.apache.flink.table.types.logical.utils.LogicalTypeUtils;\n+\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.JsonNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ArrayNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.TextNode;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.lang.reflect.Array;\n+import java.math.BigDecimal;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.ZoneOffset;\n+import java.time.temporal.TemporalAccessor;\n+import java.time.temporal.TemporalQueries;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+\n+import static java.lang.String.format;\n+import static java.time.format.DateTimeFormatter.ISO_LOCAL_DATE;\n+import static org.apache.flink.formats.json.TimeFormats.RFC3339_TIMESTAMP_FORMAT;\n+import static org.apache.flink.formats.json.TimeFormats.RFC3339_TIME_FORMAT;\n+import static org.apache.flink.util.Preconditions.checkNotNull;\n+\n+/**\n+ * Deserialization schema from JSON to Flink Table/SQL internal data structure {@link RowData}.\n+ *\n+ * <p>Deserializes a <code>byte[]</code> message as a JSON object and reads\n+ * the specified fields.\n+ *\n+ * <p>Failures during deserialization are forwarded as wrapped IOExceptions.\n+ */\n+@Internal\n+public class JsonRowDataDeserializationSchema implements DeserializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 8576854315236033439L;\n+\n+\t/** Flag indicating whether to fail if a field is missing. */\n+\tprivate final boolean failOnMissingField;\n+\n+\t/** Flag indicating whether to ignore invalid fields/rows (default: throw an exception). */\n+\tprivate final boolean ignoreParseErrors;\n+\n+\t/** TypeInformation of the produced {@link RowData}. **/\n+\tprivate final TypeInformation<RowData> resultTypeInfo;\n+\n+\t/**\n+\t * Runtime converter that converts {@link JsonNode}s into\n+\t * objects of Flink SQL internal data structures. **/\n+\tprivate final DeserializationRuntimeConverter runtimeConverter;\n+\n+\t/** Object mapper for parsing the JSON. */\n+\tprivate final ObjectMapper objectMapper = new ObjectMapper();\n+\n+\t/**\n+\t * Creates a builder for {@link JsonRowDataDeserializationSchema}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tprivate JsonRowDataDeserializationSchema(\n+\t\t\tRowType rowType,\n+\t\t\tTypeInformation<RowData> resultTypeInfo,\n+\t\t\tboolean failOnMissingField,\n+\t\t\tboolean ignoreParseErrors) {\n+\t\tif (ignoreParseErrors && failOnMissingField) {\n+\t\t\tthrow new IllegalArgumentException(\n+\t\t\t\t\"JSON format doesn't support failOnMissingField and ignoreParseErrors are both enabled.\");\n+\t\t}\n+\t\tthis.resultTypeInfo = checkNotNull(resultTypeInfo);\n+\t\tthis.failOnMissingField = failOnMissingField;\n+\t\tthis.ignoreParseErrors = ignoreParseErrors;\n+\t\tthis.runtimeConverter = createRowConverter(checkNotNull(rowType));\n+\t}\n+\n+\t@Override\n+\tpublic RowData deserialize(byte[] message) throws IOException {\n+\t\ttry {\n+\t\t\tfinal JsonNode root = objectMapper.readTree(message);\n+\t\t\treturn (RowData) runtimeConverter.convert(root);\n+\t\t} catch (Throwable t) {\n+\t\t\tif (ignoreParseErrors) {\n+\t\t\t\treturn null;\n+\t\t\t}\n+\t\t\tthrow new IOException(format(\"Failed to deserialize JSON '%s'.\", new String(message)), t);\n+\t\t}\n+\t}\n+\n+\t@Override\n+\tpublic boolean isEndOfStream(RowData nextElement) {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic TypeInformation<RowData> getProducedType() {\n+\t\treturn resultTypeInfo;\n+\t}\n+\n+\t// -------------------------------------------------------------------------------------\n+\t// Builder\n+\t// -------------------------------------------------------------------------------------\n+\n+\t/**\n+\t * Builder for {@link JsonRowDataDeserializationSchema}.\n+\t */\n+\tpublic static class Builder {\n+\n+\t\tprivate RowType rowType;\n+\t\tprivate TypeInformation<RowData> resultTypeInfo;\n+\t\tprivate boolean failOnMissingField = false;\n+\t\tprivate boolean ignoreParseErrors = false;\n+\n+\t\t/**\n+\t\t * Configures with the {@link RowType} schema information.\n+\t\t */\n+\t\tpublic Builder schema(RowType rowType) {\n+\t\t\tthis.rowType = rowType;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Configures the {@link TypeInformation} of the produced {@link RowData}.\n+\t\t */\n+\t\tpublic Builder resultTypeInfo(TypeInformation<RowData> resultTypeInfo) {\n+\t\t\tthis.resultTypeInfo = resultTypeInfo;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Configures to fail if a JSON field is missing.\n+\t\t *\n+\t\t * <p>By default, a missing field is ignored and the field is set to null.\n+\t\t */\n+\t\tpublic Builder failOnMissingField() {\n+\t\t\tthis.failOnMissingField = true;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Configures to fail when parsing json failed.\n+\t\t *\n+\t\t * <p>By default, an exception will be thrown when parsing json fails.\n+\t\t */\n+\t\tpublic Builder ignoreParseErrors() {\n+\t\t\tthis.ignoreParseErrors = true;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Creates the instance of {@link JsonRowDataDeserializationSchema}.\n+\t\t */\n+\t\tpublic JsonRowDataDeserializationSchema build() {\n+\t\t\treturn new JsonRowDataDeserializationSchema(\n+\t\t\t\trowType,\n+\t\t\t\tresultTypeInfo,\n+\t\t\t\tfailOnMissingField,\n+\t\t\t\tignoreParseErrors);\n+\t\t}\n+\t}\n+\n+\t// -------------------------------------------------------------------------------------\n+\t// Runtime Converters\n+\t// -------------------------------------------------------------------------------------\n+\n+\t/**\n+\t * Runtime converter that converts {@link JsonNode}s into objects of Flink Table & SQL\n+\t * internal data structures.\n+\t */\n+\t@FunctionalInterface\n+\tprivate interface DeserializationRuntimeConverter extends Serializable {\n+\t\tObject convert(JsonNode jsonNode);\n+\t}\n+\n+\t/**\n+\t * Creates a runtime converter which is null safe.\n+\t */\n+\tprivate DeserializationRuntimeConverter createConverter(LogicalType type) {\n+\t\treturn wrapIntoNullableConverter(createNotNullConverter(type));\n+\t}\n+\n+\t/**\n+\t * Creates a runtime converter which assuming input object is not null.\n+\t */\n+\tprivate DeserializationRuntimeConverter createNotNullConverter(LogicalType type) {\n+\t\tswitch (type.getTypeRoot()) {\n+\t\t\tcase NULL:\n+\t\t\t\treturn jsonNode -> null;\n+\t\t\tcase BOOLEAN:\n+\t\t\t\treturn this::convertToBoolean;\n+\t\t\tcase TINYINT:\n+\t\t\t\treturn jsonNode -> Byte.parseByte(jsonNode.asText().trim());\n+\t\t\tcase SMALLINT:\n+\t\t\t\treturn jsonNode -> Short.parseShort(jsonNode.asText().trim());\n+\t\t\tcase INTEGER:\n+\t\t\tcase INTERVAL_YEAR_MONTH:\n+\t\t\t\treturn this::convertToInt;\n+\t\t\tcase BIGINT:\n+\t\t\tcase INTERVAL_DAY_TIME:\n+\t\t\t\treturn this::convertToLong;\n+\t\t\tcase DATE:\n+\t\t\t\treturn this::convertToDate;\n+\t\t\tcase TIME_WITHOUT_TIME_ZONE:\n+\t\t\t\treturn this::convertToTime;\n+\t\t\tcase TIMESTAMP_WITH_TIME_ZONE:\n+\t\t\tcase TIMESTAMP_WITHOUT_TIME_ZONE:\n+\t\t\t\treturn this::convertToTimestamp;\n+\t\t\tcase FLOAT:\n+\t\t\t\treturn this::convertToFloat;\n+\t\t\tcase DOUBLE:\n+\t\t\t\treturn this::convertToDouble;\n+\t\t\tcase CHAR:\n+\t\t\tcase VARCHAR:\n+\t\t\t\treturn this::convertToString;\n+\t\t\tcase BINARY:\n+\t\t\tcase VARBINARY:\n+\t\t\t\treturn this::convertToBytes;\n+\t\t\tcase DECIMAL:\n+\t\t\t\treturn createDecimalConverter((DecimalType) type);\n+\t\t\tcase ARRAY:\n+\t\t\t\treturn createArrayConverter((ArrayType) type);\n+\t\t\tcase MAP:\n+\t\t\tcase MULTISET:\n+\t\t\t\treturn createMapConverter((MapType) type);\n+\t\t\tcase ROW:\n+\t\t\t\treturn createRowConverter((RowType) type);\n+\t\t\tcase RAW:\n+\t\t\tdefault:\n+\t\t\t\tthrow new UnsupportedOperationException(\"Unsupported type: \" + type);\n+\t\t}\n+\t}\n+\n+\tprivate boolean convertToBoolean(JsonNode jsonNode) {\n+\t\tif (jsonNode.isBoolean()) {\n+\t\t\t// avoid redundant toString and parseBoolean, for better performance\n+\t\t\treturn jsonNode.asBoolean();\n+\t\t} else {\n+\t\t\treturn Boolean.parseBoolean(jsonNode.asText().trim());\n+\t\t}\n+\t}\n+\n+\tprivate int convertToInt(JsonNode jsonNode) {\n+\t\tif (jsonNode.canConvertToInt()) {\n+\t\t\t// avoid redundant toString and parseInt, for better performance\n+\t\t\treturn jsonNode.asInt();\n+\t\t} else {\n+\t\t\treturn Integer.parseInt(jsonNode.asText().trim());\n+\t\t}\n+\t}\n+\n+\tprivate long convertToLong(JsonNode jsonNode) {\n+\t\tif (jsonNode.canConvertToLong()) {\n+\t\t\t// avoid redundant toString and parseLong, for better performance\n+\t\t\treturn jsonNode.asLong();\n+\t\t} else {\n+\t\t\treturn Long.parseLong(jsonNode.asText().trim());\n+\t\t}\n+\t}\n+\n+\tprivate double convertToDouble(JsonNode jsonNode) {\n+\t\tif (jsonNode.isDouble()) {\n+\t\t\t// avoid redundant toString and parseDouble, for better performance\n+\t\t\treturn jsonNode.asDouble();\n+\t\t} else {\n+\t\t\treturn Double.parseDouble(jsonNode.asText().trim());\n+\t\t}\n+\t}\n+\n+\tprivate float convertToFloat(JsonNode jsonNode) {\n+\t\tif (jsonNode.isDouble()) {\n+\t\t\t// avoid redundant toString and parseDouble, for better performance\n+\t\t\treturn (float) jsonNode.asDouble();\n+\t\t} else {\n+\t\t\treturn Float.parseFloat(jsonNode.asText().trim());\n+\t\t}\n+\t}\n+\n+\tprivate int convertToDate(JsonNode jsonNode) {\n+\t\tLocalDate date = ISO_LOCAL_DATE.parse(jsonNode.asText()).query(TemporalQueries.localDate());\n+\t\treturn (int) date.toEpochDay();\n+\t}\n+\n+\tprivate int convertToTime(JsonNode jsonNode) {\n+\t\t// according to RFC 3339 every full-time must have a timezone;\n+\t\t// until we have full timezone support, we only support UTC;\n+\t\t// users can parse their time as string as a workaround\n+\t\tTemporalAccessor parsedTime = RFC3339_TIME_FORMAT.parse(jsonNode.asText());\n+\n+\t\tZoneOffset zoneOffset = parsedTime.query(TemporalQueries.offset());\n+\t\tLocalTime localTime = parsedTime.query(TemporalQueries.localTime());\n+\n+\t\tif (zoneOffset != null && zoneOffset.getTotalSeconds() != 0 || localTime.getNano() != 0) {\n+\t\t\tthrow new JsonParseException(\n+\t\t\t\t\"Invalid time format. Only a time in UTC timezone without milliseconds is supported yet.\");\n+\t\t}\n+\n+\t\t// get number of milliseconds of the day\n+\t\treturn localTime.toSecondOfDay() * 1000;\n+\t}\n+\n+\tprivate TimestampData convertToTimestamp(JsonNode jsonNode) {\n+\t\t// according to RFC 3339 every date-time must have a timezone;\n+\t\t// until we have full timezone support, we only support UTC;\n+\t\t// users can parse their time as string as a workaround\n+\t\tTemporalAccessor parsedTimestamp = RFC3339_TIMESTAMP_FORMAT.parse(jsonNode.asText());\n+\n+\t\tZoneOffset zoneOffset = parsedTimestamp.query(TemporalQueries.offset());\n+\n+\t\tif (zoneOffset != null && zoneOffset.getTotalSeconds() != 0) {\n+\t\t\tthrow new JsonParseException(\n+\t\t\t\t\"Invalid timestamp format. Only a timestamp in UTC timezone is supported yet. \" +\n+\t\t\t\t\t\"Format: yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n+\t\t}\n+\n+\t\tLocalTime localTime = parsedTimestamp.query(TemporalQueries.localTime());\n+\t\tLocalDate localDate = parsedTimestamp.query(TemporalQueries.localDate());\n+\n+\t\treturn TimestampData.fromLocalDateTime(LocalDateTime.of(localDate, localTime));\n+\t}\n+\n+\tprivate StringData convertToString(JsonNode jsonNode) {\n+\t\treturn StringData.fromString(jsonNode.asText());\n+\t}\n+\n+\tprivate byte[] convertToBytes(JsonNode jsonNode) {\n+\t\ttry {\n+\t\t\treturn jsonNode.binaryValue();\n+\t\t} catch (IOException e) {\n+\t\t\tthrow new JsonParseException(\"Unable to deserialize byte array.\", e);\n+\t\t}\n+\t}\n+\n+\tprivate DeserializationRuntimeConverter createDecimalConverter(DecimalType decimalType) {\n+\t\tfinal int precision = decimalType.getPrecision();\n+\t\tfinal int scale = decimalType.getScale();\n+\t\treturn jsonNode -> {\n+\t\t\tBigDecimal bigDecimal;\n+\t\t\tif (jsonNode.isBigDecimal()) {\n+\t\t\t\tbigDecimal = jsonNode.decimalValue();\n+\t\t\t} else {\n+\t\t\t\tbigDecimal = new BigDecimal(jsonNode.asText());\n+\t\t\t}\n+\t\t\treturn DecimalData.fromBigDecimal(bigDecimal, precision, scale);\n+\t\t};\n+\t}\n+\n+\tprivate DeserializationRuntimeConverter createArrayConverter(ArrayType arrayType) {\n+\t\tDeserializationRuntimeConverter elementConverter = createConverter(arrayType.getElementType());\n+\t\tfinal Class<?> elementClass = LogicalTypeUtils.toInternalConversionClass(arrayType.getElementType());\n+\t\treturn jsonNode -> {\n+\t\t\tfinal ArrayNode node = (ArrayNode) jsonNode;\n+\t\t\tfinal Object[] array = (Object[]) Array.newInstance(elementClass, node.size());\n+\t\t\tfor (int i = 0; i < node.size(); i++) {\n+\t\t\t\tfinal JsonNode innerNode = node.get(i);\n+\t\t\t\tarray[i] = elementConverter.convert(innerNode);\n+\t\t\t}\n+\t\t\treturn new GenericArrayData(array);\n+\t\t};\n+\t}\n+\n+\tprivate DeserializationRuntimeConverter createMapConverter(MapType mapType) {\n+\t\tLogicalType keyType = mapType.getKeyType();\n+\t\tif (!LogicalTypeChecks.hasFamily(keyType, LogicalTypeFamily.CHARACTER_STRING)) {\n+\t\t\tthrow new UnsupportedOperationException(\n+\t\t\t\t\"JSON format doesn't support non-string as key type of map. \" +\n+\t\t\t\t\"The map type is: \" + mapType.asSummaryString());\n+\t\t}\n+\t\tfinal DeserializationRuntimeConverter keyConverter = createConverter(keyType);\n+\t\tfinal DeserializationRuntimeConverter valueConverter = createConverter(mapType.getValueType());\n+\n+\t\treturn jsonNode -> {\n+\t\t\tIterator<Map.Entry<String, JsonNode>> fields = jsonNode.fields();\n+\t\t\tMap<Object, Object> result = new HashMap<>();\n+\t\t\twhile (fields.hasNext()) {\n+\t\t\t\tMap.Entry<String, JsonNode> entry = fields.next();\n+\t\t\t\tObject key = keyConverter.convert(TextNode.valueOf(entry.getKey()));\n+\t\t\t\tObject value = valueConverter.convert(entry.getValue());\n+\t\t\t\tresult.put(key, value);", "originalCommit": "de28bae2536983745bdf14f1b15b1929d7ff0956", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM3NTk1OA==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417375958", "bodyText": "Java HashMap and SQL MAP allow null keys and null values. I will add a test for this in testSerDeMultiRowsWithNullValues.", "author": "wuchong", "createdAt": "2020-04-29T14:49:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI5NDMyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI5NDUyOA==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417294528", "bodyText": "use a random value?", "author": "KurtYoung", "createdAt": "2020-04-29T12:59:33Z", "path": "flink-formats/flink-json/src/main/java/org/apache/flink/formats/json/JsonRowDataSerializationSchema.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.json;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.SerializationSchema;\n+import org.apache.flink.table.data.ArrayData;\n+import org.apache.flink.table.data.DecimalData;\n+import org.apache.flink.table.data.MapData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.TimestampData;\n+import org.apache.flink.table.types.logical.ArrayType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.LogicalTypeFamily;\n+import org.apache.flink.table.types.logical.MapType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.utils.LogicalTypeChecks;\n+\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.JsonNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ArrayNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode;\n+\n+import java.io.Serializable;\n+import java.math.BigDecimal;\n+import java.time.LocalDate;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+\n+import static java.time.format.DateTimeFormatter.ISO_LOCAL_DATE;\n+import static org.apache.flink.formats.json.TimeFormats.RFC3339_TIMESTAMP_FORMAT;\n+import static org.apache.flink.formats.json.TimeFormats.RFC3339_TIME_FORMAT;\n+\n+/**\n+ * Serialization schema that serializes an object of Flink internal data structure into a JSON bytes.\n+ *\n+ * <p>Serializes the input Flink object into a JSON string and\n+ * converts it into <code>byte[]</code>.\n+ *\n+ * <p>Result <code>byte[]</code> messages can be deserialized using {@link JsonRowDataDeserializationSchema}.\n+ */\n+@Internal\n+public class JsonRowDataSerializationSchema implements SerializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 1L;", "originalCommit": "de28bae2536983745bdf14f1b15b1929d7ff0956", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzM3NTk3MQ==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417375971", "bodyText": "I learned this from Flink Code Style which says:\n\nThe Serial Version UID for new classes should start at 1 and should generally be bumped on every incompatible change to the class according to the Java serialization compatibility definition (i.e: changing the type of a field, or moving the position of a class in the class hierarchy)", "author": "wuchong", "createdAt": "2020-04-29T14:49:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI5NDUyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzcxMTg0MQ==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417711841", "bodyText": "then please also use 1 in the deserialize class", "author": "KurtYoung", "createdAt": "2020-04-30T01:55:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI5NDUyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc4NTE2NA==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417785164", "bodyText": "Good catch!", "author": "wuchong", "createdAt": "2020-04-30T06:35:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI5NDUyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzI5NDg5NA==", "url": "https://github.com/apache/flink/pull/11944#discussion_r417294894", "bodyText": "I think we don't need builder here.", "author": "KurtYoung", "createdAt": "2020-04-29T13:00:07Z", "path": "flink-formats/flink-json/src/main/java/org/apache/flink/formats/json/JsonRowDataSerializationSchema.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.formats.json;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.serialization.SerializationSchema;\n+import org.apache.flink.table.data.ArrayData;\n+import org.apache.flink.table.data.DecimalData;\n+import org.apache.flink.table.data.MapData;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.data.TimestampData;\n+import org.apache.flink.table.types.logical.ArrayType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.LogicalTypeFamily;\n+import org.apache.flink.table.types.logical.MapType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.utils.LogicalTypeChecks;\n+\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.JsonNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ArrayNode;\n+import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode;\n+\n+import java.io.Serializable;\n+import java.math.BigDecimal;\n+import java.time.LocalDate;\n+import java.time.LocalTime;\n+import java.util.Arrays;\n+\n+import static java.time.format.DateTimeFormatter.ISO_LOCAL_DATE;\n+import static org.apache.flink.formats.json.TimeFormats.RFC3339_TIMESTAMP_FORMAT;\n+import static org.apache.flink.formats.json.TimeFormats.RFC3339_TIME_FORMAT;\n+\n+/**\n+ * Serialization schema that serializes an object of Flink internal data structure into a JSON bytes.\n+ *\n+ * <p>Serializes the input Flink object into a JSON string and\n+ * converts it into <code>byte[]</code>.\n+ *\n+ * <p>Result <code>byte[]</code> messages can be deserialized using {@link JsonRowDataDeserializationSchema}.\n+ */\n+@Internal\n+public class JsonRowDataSerializationSchema implements SerializationSchema<RowData> {\n+\tprivate static final long serialVersionUID = 1L;\n+\n+\t/** The converter that converts internal data formats to JsonNode. */\n+\tprivate final SerializationRuntimeConverter runtimeConverter;\n+\n+\t/** Object mapper that is used to create output JSON objects. */\n+\tprivate final ObjectMapper mapper = new ObjectMapper();\n+\n+\t/** Reusable object node. */\n+\tprivate transient ObjectNode node;\n+\n+\t/**\n+\t * Creates a builder for {@link JsonRowDataSerializationSchema}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tprivate JsonRowDataSerializationSchema(RowType rowType) {\n+\t\tthis.runtimeConverter = createConverter(rowType);\n+\t}\n+\n+\t@Override\n+\tpublic byte[] serialize(RowData row) {\n+\t\tif (node == null) {\n+\t\t\tnode = mapper.createObjectNode();\n+\t\t}\n+\n+\t\ttry {\n+\t\t\truntimeConverter.convert(mapper, node, row);\n+\t\t\treturn mapper.writeValueAsBytes(node);\n+\t\t} catch (Throwable t) {\n+\t\t\tthrow new RuntimeException(\"Could not serialize row '\" + row + \"'. \" +\n+\t\t\t\t\"Make sure that the schema matches the input.\", t);\n+\t\t}\n+\t}\n+\n+\t// --------------------------------------------------------------------------------\n+\t// Builder\n+\t// --------------------------------------------------------------------------------\n+\n+\t/**\n+\t * Builder of {@link JsonRowDataSerializationSchema}.\n+\t */\n+\tpublic static class Builder {", "originalCommit": "de28bae2536983745bdf14f1b15b1929d7ff0956", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8afc7b3913e499329d7b71a540c04eb03a42027c", "url": "https://github.com/apache/flink/commit/8afc7b3913e499329d7b71a540c04eb03a42027c", "message": "address review comment", "committedDate": "2020-04-29T14:48:38Z", "type": "commit"}, {"oid": "cf0d25e53c26f764d12a56815869cb100079548b", "url": "https://github.com/apache/flink/commit/cf0d25e53c26f764d12a56815869cb100079548b", "message": "use serialVersionUID = 1L in JsonRowDataDeserializeSchema", "committedDate": "2020-04-30T06:35:45Z", "type": "commit"}]}