{"pr_number": 10932, "pr_title": "[FLINK-15614][docs] Consolidate Hadoop documentation", "pr_createdAt": "2020-01-23T13:43:39Z", "pr_url": "https://github.com/apache/flink/pull/10932", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4MjY5NQ==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372382695", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            In order to use Hadoop features (e.g., YARN, HDFS) it is ncessary to provide Flink with the required Hadoop classes,\n          \n          \n            \n            In order to use Hadoop features (e.g., YARN, HDFS) it is necessary to provide Flink with the required Hadoop classes,", "author": "azagrebin", "createdAt": "2020-01-29T13:32:31Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -38,13 +38,18 @@ Referencing the HDFS configuration in the [Flink configuration]({{ site.baseurl\n \n Another way to provide the Hadoop configuration is to have it on the class path of the Flink process, see more details below.\n \n-## Adding Hadoop Classpaths\n+## Providing Hadoop classes\n \n-The required classes to use Hadoop should be available in the `lib/` folder of the Flink installation\n-(on all machines running Flink) unless Flink is built with [Hadoop shaded dependencies]({{ site.baseurl }}/flinkDev/building.html#pre-bundled-versions).\n+In order to use Hadoop features (e.g., YARN, HDFS) it is ncessary to provide Flink with the required Hadoop classes,", "originalCommit": "fb34b16d701e65ee2edcaa082869af08b4ee0482", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4NTU0Nw==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372385547", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n          \n          \n            \n            For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and put it into", "author": "azagrebin", "createdAt": "2020-01-29T13:38:04Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in", "originalCommit": "fb34b16d701e65ee2edcaa082869af08b4ee0482", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4NjAyNQ==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372386025", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.\n          \n          \n            \n            then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) dependency against this version.", "author": "azagrebin", "createdAt": "2020-01-29T13:39:01Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n+the `/lib` directory of the Flink distribution.\n+\n+If the used Hadoop version is not listed on the download page (possibly due to being a Vendor-specific version),\n+then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.", "originalCommit": "fb34b16d701e65ee2edcaa082869af08b4ee0482", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQ0NDIyNQ==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372444225", "bodyText": "Doesn't make sense to refer to flink-shaded as a whole as a dependency; it's not, only parts of it are.", "author": "zentol", "createdAt": "2020-01-29T15:16:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4NjAyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4NjkzMg==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372386932", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You can find the source for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.\n          \n          \n            \n            You can also find the source code for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.", "author": "azagrebin", "createdAt": "2020-01-29T13:40:45Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n+the `/lib` directory of the Flink distribution.\n+\n+If the used Hadoop version is not listed on the download page (possibly due to being a Vendor-specific version),\n+then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.\n+You can find the source for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.", "originalCommit": "fb34b16d701e65ee2edcaa082869af08b4ee0482", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjgxMzYzMQ==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372813631", "bodyText": "The website is the primary source for the projects source code and hence shouldn't be preceded by \"also\". It would imply that users alternatively may download things from the website.", "author": "zentol", "createdAt": "2020-01-30T08:30:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM4NjkzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5MzE2Mg==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372393162", "bodyText": "Are there no expected dependency clashes in case of just exporting HADOOP_CLASSPATH?\nIn other words, why is the relocation needed for /lib but not for HADOOP_CLASSPATH?\nI also somewhat liked the previous idea of mentioning that the first way should be a recommended way to go and only in case of problems (giving examples) go to the option 2. Is it still the case?", "author": "azagrebin", "createdAt": "2020-01-29T13:52:36Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -38,13 +38,18 @@ Referencing the HDFS configuration in the [Flink configuration]({{ site.baseurl\n \n Another way to provide the Hadoop configuration is to have it on the class path of the Flink process, see more details below.\n \n-## Adding Hadoop Classpaths\n+## Providing Hadoop classes\n \n-The required classes to use Hadoop should be available in the `lib/` folder of the Flink installation\n-(on all machines running Flink) unless Flink is built with [Hadoop shaded dependencies]({{ site.baseurl }}/flinkDev/building.html#pre-bundled-versions).\n+In order to use Hadoop features (e.g., YARN, HDFS) it is ncessary to provide Flink with the required Hadoop classes,\n+as these are not bundled by default.\n \n-If putting the files into the directory is not possible, Flink also respects\n-the `HADOOP_CLASSPATH` environment variable to add Hadoop jar files to the classpath.\n+This can be done in 2 ways:\n+* Adding the Hadoop classpath to Flink", "originalCommit": "fb34b16d701e65ee2edcaa082869af08b4ee0482", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjgxNjU3Mw==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372816573", "bodyText": "Depends on the specific Hadoop distribution. The point is that user should first try the easy way, since building flink-shaded against custom/vendor hadoop versions is a) a pain and b) something we can't test for.", "author": "zentol", "createdAt": "2020-01-30T08:37:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5MzE2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5MzU2OA==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372393568", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            After this step is complete, place the `flink-shaded-hadoop-2-uber` jar in the `/lib` directory of the Flink distribution.\n          \n          \n            \n            After this step is complete, put the `flink-shaded-hadoop-2-uber` jar into the `/lib` directory of the Flink distribution.", "author": "azagrebin", "createdAt": "2020-01-29T13:53:21Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).\n+For these versions it is sufficient to download the corresponding `Pre-bundled Hadoop` component and placing it in\n+the `/lib` directory of the Flink distribution.\n+\n+If the used Hadoop version is not listed on the download page (possibly due to being a Vendor-specific version),\n+then it is necessary to build [flink-shaded](https://github.com/apache/flink-shaded) against this version.\n+You can find the source for this project in the [Additional Components]({{ site.download_url }}#additional-components) section of the download page.\n+\n+<span class=\"label label-info\">Note</span> If you want to build `flink-shaded` against a vendor specific Hadoop version, you first have to configure the\n+vendor-specific maven repository in your local maven setup as described [here](https://maven.apache.org/guides/mini/guide-multiple-repositories.html).\n+\n+Run the following command to build and install `flink-shaded` against your desired Hadoop version (e.g., for version `2.6.5-custom`):\n+\n+{% highlight bash %}\n+mvn clean install -Dhadoop.version=2.6.5-custom\n+{% endhighlight %}\n+\n+After this step is complete, place the `flink-shaded-hadoop-2-uber` jar in the `/lib` directory of the Flink distribution.", "originalCommit": "fb34b16d701e65ee2edcaa082869af08b4ee0482", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5NDI0Mg==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372394242", "bodyText": "I would also suggest to have an expected path to the jar, like target/flink-shaded-hadoop-2-uber.jar for less advanced users.", "author": "azagrebin", "createdAt": "2020-01-29T13:54:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5MzU2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQ0NTEwMg==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372445102", "bodyText": "not reasonably possible since the path contains the shaded-version which is independent of Flink.\nIf someone doesn't know which jar he should take he most likely didn't make it this far into the process anyway.", "author": "zentol", "createdAt": "2020-01-29T15:18:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5MzU2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQwMTI3NA==", "url": "https://github.com/apache/flink/pull/10932#discussion_r372401274", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            These can be found on the [downloads]({{ site.download_url }}).\n          \n          \n            \n            These can be found on the [downloads]({{ site.download_url }}) page in the optional components.", "author": "azagrebin", "createdAt": "2020-01-29T14:07:40Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -66,6 +71,29 @@ in the shell. Note that `hadoop` is the hadoop binary and that `classpath` is an\n \n Putting the Hadoop configuration in the same class path as the Hadoop libraries makes Flink pick up that configuration.\n \n+### Adding Hadoop to /lib\n+\n+The Flink project releases Hadoop distributions for specific versions, that relocate or exclude several dependencies\n+to reduce the risk of dependency clashes.\n+These can be found on the [downloads]({{ site.download_url }}).", "originalCommit": "fb34b16d701e65ee2edcaa082869af08b4ee0482", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY5NjExMw==", "url": "https://github.com/apache/flink/pull/10932#discussion_r374696113", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Option 1) requires very little work and integrates nicely with existing Hadoop setups, and should be the\n          \n          \n            \n            Option 1) requires very little work and integrates nicely with existing Hadoop setups. It should be the", "author": "azagrebin", "createdAt": "2020-02-04T14:19:04Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -38,13 +38,22 @@ Referencing the HDFS configuration in the [Flink configuration]({{ site.baseurl\n \n Another way to provide the Hadoop configuration is to have it on the class path of the Flink process, see more details below.\n \n-## Adding Hadoop Classpaths\n+## Providing Hadoop classes\n \n-The required classes to use Hadoop should be available in the `lib/` folder of the Flink installation\n-(on all machines running Flink) unless Flink is built with [Hadoop shaded dependencies]({{ site.baseurl }}/flinkDev/building.html#pre-bundled-versions).\n+In order to use Hadoop features (e.g., YARN, HDFS) it is necessary to provide Flink with the required Hadoop classes,\n+as these are not bundled by default.\n \n-If putting the files into the directory is not possible, Flink also respects\n-the `HADOOP_CLASSPATH` environment variable to add Hadoop jar files to the classpath.\n+This can be done by \n+1) Adding the Hadoop classpath to Flink\n+2) Putting the required jar files into /lib directory of the Flink distribution\n+Option 1) requires very little work and integrates nicely with existing Hadoop setups, and should be the", "originalCommit": "18362a771aca442dfc07fd646f4bd98724cdd2e6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDY5NjMxNQ==", "url": "https://github.com/apache/flink/pull/10932#discussion_r374696315", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            However, Hadoop has a large dependency footprint, increasing the risk of dependency conflicts occurring.\n          \n          \n            \n            However, Hadoop has a large dependency footprint that increases the risk of dependency conflicts occurring.", "author": "azagrebin", "createdAt": "2020-02-04T14:19:24Z", "path": "docs/ops/deployment/hadoop.md", "diffHunk": "@@ -38,13 +38,22 @@ Referencing the HDFS configuration in the [Flink configuration]({{ site.baseurl\n \n Another way to provide the Hadoop configuration is to have it on the class path of the Flink process, see more details below.\n \n-## Adding Hadoop Classpaths\n+## Providing Hadoop classes\n \n-The required classes to use Hadoop should be available in the `lib/` folder of the Flink installation\n-(on all machines running Flink) unless Flink is built with [Hadoop shaded dependencies]({{ site.baseurl }}/flinkDev/building.html#pre-bundled-versions).\n+In order to use Hadoop features (e.g., YARN, HDFS) it is necessary to provide Flink with the required Hadoop classes,\n+as these are not bundled by default.\n \n-If putting the files into the directory is not possible, Flink also respects\n-the `HADOOP_CLASSPATH` environment variable to add Hadoop jar files to the classpath.\n+This can be done by \n+1) Adding the Hadoop classpath to Flink\n+2) Putting the required jar files into /lib directory of the Flink distribution\n+Option 1) requires very little work and integrates nicely with existing Hadoop setups, and should be the\n+preferred approach.\n+However, Hadoop has a large dependency footprint, increasing the risk of dependency conflicts occurring.", "originalCommit": "18362a771aca442dfc07fd646f4bd98724cdd2e6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d6c08c376ed5bef6011e518ae47ea57cb3754ab6", "url": "https://github.com/apache/flink/commit/d6c08c376ed5bef6011e518ae47ea57cb3754ab6", "message": "[FLINK-15614][docs] Consolidate Hadoop documentation", "committedDate": "2020-02-04T17:09:32Z", "type": "commit"}, {"oid": "d6c08c376ed5bef6011e518ae47ea57cb3754ab6", "url": "https://github.com/apache/flink/commit/d6c08c376ed5bef6011e518ae47ea57cb3754ab6", "message": "[FLINK-15614][docs] Consolidate Hadoop documentation", "committedDate": "2020-02-04T17:09:32Z", "type": "forcePushed"}]}