{"pr_number": 13449, "pr_title": "[FLINK-19282][table sql/planner]Supports watermark push down with Wat\u2026", "pr_createdAt": "2020-09-22T04:41:20Z", "pr_url": "https://github.com/apache/flink/pull/13449", "timeline": [{"oid": "cf69333ccf949c116ede01138e2b01e78c624f2f", "url": "https://github.com/apache/flink/commit/cf69333ccf949c116ede01138e2b01e78c624f2f", "message": "add rule to push WatermarkStrategy into table source scan", "committedDate": "2020-09-24T09:41:21Z", "type": "forcePushed"}, {"oid": "28d25983818d7805f6708b36125a65a493d03aa9", "url": "https://github.com/apache/flink/commit/28d25983818d7805f6708b36125a65a493d03aa9", "message": "add rule and refactor TestValuesTableSource", "committedDate": "2020-09-25T02:53:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIyNDQ2Ng==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497224466", "bodyText": "indent", "author": "godfreyhe", "createdAt": "2020-09-30T03:37:39Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/ExpressionReducer.scala", "diffHunk": "@@ -249,13 +249,15 @@ class ExpressionReducer(\n /**\n   * Constant expression code generator context.\n   */\n-class ConstantCodeGeneratorContext(tableConfig: TableConfig)\n+class ConstantCodeGeneratorContext(\n+  tableConfig: TableConfig,\n+  contextTerm: String = \"parameters\")", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIyNDc3Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497224773", "bodyText": "nit: reorder imports", "author": "godfreyhe", "createdAt": "2020-09-30T03:39:02Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenerator.scala", "diffHunk": "@@ -18,14 +18,16 @@\n \n package org.apache.flink.table.planner.codegen\n \n+import org.apache.calcite.rex.RexNode", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIyNTI3Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497225273", "bodyText": "please use None instead of null in Scala", "author": "godfreyhe", "createdAt": "2020-09-30T03:41:01Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenerator.scala", "diffHunk": "@@ -35,7 +37,8 @@ object WatermarkGeneratorCodeGenerator {\n   def generateWatermarkGenerator(\n       config: TableConfig,\n       inputType: RowType,\n-      watermarkExpr: RexNode): GeneratedWatermarkGenerator = {\n+      watermarkExpr: RexNode,\n+      contextTerm: String = null): GeneratedWatermarkGenerator = {", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIyNjIzNA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497226234", "bodyText": "why we use ConstantCodeGeneratorContext here ? ConstantCodeGeneratorContext is used for constant reducer, we should create a new special CodeGeneratorContext for watermark generator", "author": "godfreyhe", "createdAt": "2020-09-30T03:44:59Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenerator.scala", "diffHunk": "@@ -44,11 +47,33 @@ object WatermarkGeneratorCodeGenerator {\n           \" but is \" + watermarkOutputType)\n     }\n     val funcName = newName(\"WatermarkGenerator\")\n-    val ctx = CodeGeneratorContext(config)\n+    val ctx = if (contextTerm != null) {\n+      new ConstantCodeGeneratorContext(config, contextTerm)", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzNjIxOA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497236218", "bodyText": "reorder imports", "author": "godfreyhe", "createdAt": "2020-09-30T04:28:21Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenTest.scala", "diffHunk": "@@ -32,21 +32,27 @@ import org.apache.flink.table.planner.runtime.utils.JavaUserDefinedScalarFunctio\n import org.apache.flink.table.runtime.generated.WatermarkGenerator\n import org.apache.flink.table.types.logical.{IntType, TimestampType}\n import org.apache.flink.table.utils.CatalogManagerMocks\n-\n import org.apache.calcite.jdbc.CalciteSchemaBuilder.asRootSchema\n import org.apache.calcite.plan.ConventionTraitDef\n import org.apache.calcite.rel.`type`.RelDataType\n import org.junit.Assert.{assertEquals, assertTrue}\n import org.junit.Test\n-\n import java.lang.{Integer => JInt, Long => JLong}\n+import java.util\n import java.util.Collections\n import java.util.function.{Function => JFunction, Supplier => JSupplier}\n \n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzNjMwOQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497236309", "bodyText": "nit: remove the default value", "author": "godfreyhe", "createdAt": "2020-09-30T04:28:45Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenTest.scala", "diffHunk": "@@ -154,7 +199,9 @@ class WatermarkGeneratorCodeGenTest {\n     assertTrue(JavaFunc5.closeCalled)\n   }\n \n-  private def generateWatermarkGenerator(expr: String): WatermarkGenerator = {\n+\n+  private def generateWatermarkGenerator(expr: String,\n+      useDefinedConstructor: Boolean = true): WatermarkGenerator = {", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzNzM1Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497237353", "bodyText": "it's better to add some comments about \"@deprecated\" action", "author": "godfreyhe", "createdAt": "2020-09-30T04:33:26Z", "path": "flink-table/flink-table-api-java-bridge/src/main/java/org/apache/flink/table/connector/source/abilities/PeriodicWatermarkAssignerProvider.java", "diffHunk": "@@ -28,6 +28,7 @@\n  * generating watermarks in {@link ScanTableSource}.\n  */\n @PublicEvolving\n+@Deprecated", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzODAzMg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497238032", "bodyText": "please add some comments to explain the purpose of this rule", "author": "godfreyhe", "createdAt": "2020-09-30T04:36:31Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+/**\n+ * Rule for PushWatermarkIntoTableSourceScan.", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzOTQzNA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497239434", "bodyText": "add static identifier and add serialVersionUID field", "author": "godfreyhe", "createdAt": "2020-09-30T04:42:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+/**\n+ * Rule for PushWatermarkIntoTableSourceScan.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRule extends RelOptRule {\n+\tpublic static final PushWatermarkIntoTableSourceScanRule INSTANCE = new PushWatermarkIntoTableSourceScanRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalTableScan.class, none())),\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tFlinkContext context = (FlinkContext) call.getPlanner().getContext();\n+\t\tTableConfig config = context.getTableConfig();\n+\n+\t\t// generate an inner watermark generator class that allows us to pass FunctionContext and ClassLoader\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tconfig,\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkAssigner.watermarkExpr(),\n+\t\t\t\t\t\t\"context\");\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkAssigner.watermarkExpr());\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\n+\t\tTableSourceTable newTableSourceTable = tableSourceTable.copy(\n+\t\t\t\tnewDynamicTableSource,\n+\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\tnew String[]{digest});\n+\t\tLogicalTableScan newScan = new LogicalTableScan(\n+\t\t\t\tscan.getCluster(), scan.getTraitSet(), scan.getHints(), newTableSourceTable);\n+\n+\t\tcall.transformTo(newScan);\n+\t}\n+\n+\tprivate static class DefaultWatermarkGeneratorSupplier implements WatermarkGeneratorSupplier<RowData> {\n+\t\tprivate final Configuration configuration;\n+\t\tprivate final GeneratedWatermarkGenerator generatedWatermarkGenerator;\n+\n+\t\tpublic DefaultWatermarkGeneratorSupplier(Configuration configuration, GeneratedWatermarkGenerator generatedWatermarkGenerator) {\n+\t\t\tthis.configuration = configuration;\n+\t\t\tthis.generatedWatermarkGenerator = generatedWatermarkGenerator;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic WatermarkGenerator<RowData> createWatermarkGenerator(Context context) {\n+\n+\t\t\tList<Object> references = new ArrayList<>(Arrays.asList(generatedWatermarkGenerator.getReferences()));\n+\t\t\treferences.add(context);\n+\n+\t\t\torg.apache.flink.table.runtime.generated.WatermarkGenerator innerWatermarkGenerator =\n+\t\t\t\t\tnew GeneratedWatermarkGenerator(\n+\t\t\t\t\t\tgeneratedWatermarkGenerator.getClassName(),\n+\t\t\t\t\t\tgeneratedWatermarkGenerator.getCode(),\n+\t\t\t\t\t\treferences.toArray())\n+\t\t\t\t\t\t\t.newInstance(Thread.currentThread().getContextClassLoader());\n+\n+\t\t\ttry {\n+\t\t\t\tinnerWatermarkGenerator.open(configuration);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Fail to instantiate generated watermark generator.\", e);\n+\t\t\t}\n+\t\t\treturn new DefaultWatermarkGenerator(innerWatermarkGenerator);\n+\t\t}\n+\n+\t\tprivate class DefaultWatermarkGenerator implements WatermarkGenerator<RowData> {", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzIzOTgzMQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r497239831", "bodyText": "add serialVersionUID field", "author": "godfreyhe", "createdAt": "2020-09-30T04:43:58Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+/**\n+ * Rule for PushWatermarkIntoTableSourceScan.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRule extends RelOptRule {\n+\tpublic static final PushWatermarkIntoTableSourceScanRule INSTANCE = new PushWatermarkIntoTableSourceScanRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalTableScan.class, none())),\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tFlinkContext context = (FlinkContext) call.getPlanner().getContext();\n+\t\tTableConfig config = context.getTableConfig();\n+\n+\t\t// generate an inner watermark generator class that allows us to pass FunctionContext and ClassLoader\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tconfig,\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkAssigner.watermarkExpr(),\n+\t\t\t\t\t\t\"context\");\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkAssigner.watermarkExpr());\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\n+\t\tTableSourceTable newTableSourceTable = tableSourceTable.copy(\n+\t\t\t\tnewDynamicTableSource,\n+\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\tnew String[]{digest});\n+\t\tLogicalTableScan newScan = new LogicalTableScan(\n+\t\t\t\tscan.getCluster(), scan.getTraitSet(), scan.getHints(), newTableSourceTable);\n+\n+\t\tcall.transformTo(newScan);\n+\t}\n+\n+\tprivate static class DefaultWatermarkGeneratorSupplier implements WatermarkGeneratorSupplier<RowData> {", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwMDI3Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500800277", "bodyText": "nit: use LogicalTableScan.create instead", "author": "godfreyhe", "createdAt": "2020-10-07T07:39:18Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+/**\n+ * Rule for PushWatermarkIntoTableSourceScan.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRule extends RelOptRule {\n+\tpublic static final PushWatermarkIntoTableSourceScanRule INSTANCE = new PushWatermarkIntoTableSourceScanRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalTableScan.class, none())),\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalTableScan scan = call.rel(1);\n+\t\tFlinkContext context = (FlinkContext) call.getPlanner().getContext();\n+\t\tTableConfig config = context.getTableConfig();\n+\n+\t\t// generate an inner watermark generator class that allows us to pass FunctionContext and ClassLoader\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tconfig,\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkAssigner.watermarkExpr(),\n+\t\t\t\t\t\t\"context\");\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkAssigner.watermarkExpr());\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\n+\t\tTableSourceTable newTableSourceTable = tableSourceTable.copy(\n+\t\t\t\tnewDynamicTableSource,\n+\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\tnew String[]{digest});\n+\t\tLogicalTableScan newScan = new LogicalTableScan(", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwMjUwNQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500802505", "bodyText": "please add some comments to explain the purpose of this rule", "author": "godfreyhe", "createdAt": "2020-10-07T07:43:04Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * WatermarkAssignerProjectTransposeRule.\n+ * */\n+public class WatermarkAssignerProjectTransposeRule extends RelOptRule {", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwMzM1OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500803358", "bodyText": "do all input refs in watermark expression are from rowtime field ?", "author": "godfreyhe", "createdAt": "2020-10-07T07:44:37Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * WatermarkAssignerProjectTransposeRule.\n+ * */\n+public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n+\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n+\n+\tpublic WatermarkAssignerProjectTransposeRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalProject.class,\n+\t\t\t\t\t\toperand(LogicalTableScan.class, none()))),\n+\t\t\t\t\"WatermarkAssignerProjectTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalProject project = call.rel(1);\n+\n+\t\tRexNode computedColumn = project.getProjects().get(watermarkAssigner.rowtimeFieldIndex());\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn computedColumn;", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE4MTUzNQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r502181535", "bodyText": "Yes. Currelty, flink doesn't support define computed column on computed column.", "author": "fsk119", "createdAt": "2020-10-09T04:21:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgwMzM1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgxMzkyNA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500813924", "bodyText": "could this rule push watermark into scan directly? then we need not to change the semantic of  LogicalWatermarkAssigner#rowtimeFieldIndex. It's a little strange rowtimeFieldIndex is -1. ( we can extract a base class for PushWatermarkIntoTableSourceScanRule and WatermarkAssignerProjectTransposeRule)", "author": "godfreyhe", "createdAt": "2020-10-07T08:01:58Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/WatermarkAssignerProjectTransposeRule.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * WatermarkAssignerProjectTransposeRule.\n+ * */\n+public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n+\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n+\n+\tpublic WatermarkAssignerProjectTransposeRule() {\n+\t\tsuper(operand(LogicalWatermarkAssigner.class,\n+\t\t\t\toperand(LogicalProject.class,\n+\t\t\t\t\t\toperand(LogicalTableScan.class, none()))),\n+\t\t\t\t\"WatermarkAssignerProjectTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalTableScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tLogicalProject project = call.rel(1);\n+\n+\t\tRexNode computedColumn = project.getProjects().get(watermarkAssigner.rowtimeFieldIndex());\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn computedColumn;\n+\t\t\t}\n+\t\t});\n+\n+\t\t// use -1 to indicate rowtime column is not in scan and watermark generator has to calculate it.\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner =\n+\t\t\t\t(LogicalWatermarkAssigner) watermarkAssigner.copy(watermarkAssigner.getTraitSet(),\n+\t\t\t\tproject.getInput(),\n+\t\t\t\t-1,", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgxNjE4MA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500816180", "bodyText": "give some more meaningful comments", "author": "godfreyhe", "createdAt": "2020-10-07T08:05:48Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java", "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.factories;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.io.CollectionInputFormat;\n+import org.apache.flink.streaming.api.functions.source.FromElementsFunction;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.RuntimeConverter;\n+import org.apache.flink.table.connector.source.AsyncTableFunctionProvider;\n+import org.apache.flink.table.connector.source.InputFormatProvider;\n+import org.apache.flink.table.connector.source.LookupTableSource;\n+import org.apache.flink.table.connector.source.ScanTableSource;\n+import org.apache.flink.table.connector.source.SourceFunctionProvider;\n+import org.apache.flink.table.connector.source.TableFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.functions.AsyncTableFunction;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.InstantiationUtil;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Base class.", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgxODg0Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500818843", "bodyText": "/**\n * \n */", "author": "godfreyhe", "createdAt": "2020-10-07T08:10:10Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/factories/TestValuesTableSourceBase.java", "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.factories;\n+\n+import org.apache.flink.api.common.ExecutionConfig;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.java.io.CollectionInputFormat;\n+import org.apache.flink.streaming.api.functions.source.FromElementsFunction;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.connector.ChangelogMode;\n+import org.apache.flink.table.connector.RuntimeConverter;\n+import org.apache.flink.table.connector.source.AsyncTableFunctionProvider;\n+import org.apache.flink.table.connector.source.InputFormatProvider;\n+import org.apache.flink.table.connector.source.LookupTableSource;\n+import org.apache.flink.table.connector.source.ScanTableSource;\n+import org.apache.flink.table.connector.source.SourceFunctionProvider;\n+import org.apache.flink.table.connector.source.TableFunctionProvider;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.functions.AsyncTableFunction;\n+import org.apache.flink.table.functions.TableFunction;\n+import org.apache.flink.types.Row;\n+import org.apache.flink.util.InstantiationUtil;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Base class.\n+ * */\n+public abstract class TestValuesTableSourceBase implements ScanTableSource, LookupTableSource {\n+\n+\tprotected TableSchema physicalSchema;\n+\tprotected final ChangelogMode changelogMode;\n+\tprotected final boolean bounded;\n+\tprotected final String runtimeSource;\n+\t/* If source table is not partitionable, we will put all data into a emptyMap. */\n+\tprotected Map<Map<String, String>, Collection<Row>> data;\n+\tprotected final boolean isAsync;\n+\tprotected final @Nullable String lookupFunctionClass;\n+\n+\tprotected TestValuesTableSourceBase(\n+\t\t\tTableSchema physicalSchema,\n+\t\t\tChangelogMode changelogMode,\n+\t\t\tboolean bounded,\n+\t\t\tString runtimeSource,\n+\t\t\tMap<Map<String, String>, Collection<Row>> data,\n+\t\t\tboolean isAsync,\n+\t\t\t@Nullable String lookupFunctionClass) {\n+\t\tthis.physicalSchema = physicalSchema;\n+\t\tthis.changelogMode = changelogMode;\n+\t\tthis.bounded = bounded;\n+\t\tthis.runtimeSource = runtimeSource;\n+\t\tthis.data = data;\n+\t\tthis.isAsync = isAsync;\n+\t\tthis.lookupFunctionClass = lookupFunctionClass;\n+\t}\n+\n+\t@Override\n+\tpublic ChangelogMode getChangelogMode() {\n+\t\treturn changelogMode;\n+\t}\n+\n+\t@SuppressWarnings(\"unchecked\")\n+\t@Override\n+\tpublic ScanRuntimeProvider getScanRuntimeProvider(ScanContext runtimeProviderContext) {\n+\t\tTypeSerializer<RowData> serializer = (TypeSerializer<RowData>) runtimeProviderContext\n+\t\t\t\t.createTypeInformation(physicalSchema.toRowDataType())\n+\t\t\t\t.createSerializer(new ExecutionConfig());\n+\t\tDataStructureConverter converter = runtimeProviderContext.createDataStructureConverter(physicalSchema.toRowDataType());\n+\t\tconverter.open(RuntimeConverter.Context.create(TestValuesTableFactory.class.getClassLoader()));\n+\t\tCollection<RowData> values = convertToRowData(converter);\n+\n+\t\tif (runtimeSource.equals(\"SourceFunction\")) {\n+\t\t\ttry {\n+\t\t\t\treturn SourceFunctionProvider.of(\n+\t\t\t\t\t\tnew FromElementsFunction<>(serializer, values),\n+\t\t\t\t\t\tbounded);\n+\t\t\t} catch (IOException e) {\n+\t\t\t\tthrow new TableException(\"Fail to init source function\", e);\n+\t\t\t}\n+\t\t} else if (runtimeSource.equals(\"InputFormat\")) {\n+\t\t\treturn InputFormatProvider.of(new CollectionInputFormat<>(values, serializer));\n+\t\t} else {\n+\t\t\tthrow new IllegalArgumentException(\"Unsupported runtime source class: \" + runtimeSource);\n+\t\t}\n+\t}\n+\n+\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+\t@Override\n+\tpublic LookupRuntimeProvider getLookupRuntimeProvider(LookupContext context) {\n+\t\tif (lookupFunctionClass != null) {\n+\t\t\t// use the specified lookup function\n+\t\t\ttry {\n+\t\t\t\tClass<?> clazz = Class.forName(lookupFunctionClass);\n+\t\t\t\tObject udtf = InstantiationUtil.instantiate(clazz);\n+\t\t\t\tif (udtf instanceof TableFunction) {\n+\t\t\t\t\treturn TableFunctionProvider.of((TableFunction) udtf);\n+\t\t\t\t} else {\n+\t\t\t\t\treturn AsyncTableFunctionProvider.of((AsyncTableFunction) udtf);\n+\t\t\t\t}\n+\t\t\t} catch (ClassNotFoundException e) {\n+\t\t\t\tthrow new IllegalArgumentException(\"Could not instantiate class: \" + lookupFunctionClass);\n+\t\t\t}\n+\t\t}\n+\n+\t\tint[] lookupIndices = Arrays.stream(context.getKeys())\n+\t\t\t\t.mapToInt(k -> k[0])\n+\t\t\t\t.toArray();\n+\t\tMap<Row, List<Row>> mapping = new HashMap<>();\n+\n+\t\tdata.get(Collections.emptyMap()).forEach(record -> {\n+\t\t\tRow key = Row.of(Arrays.stream(lookupIndices)\n+\t\t\t\t\t.mapToObj(record::getField)\n+\t\t\t\t\t.toArray());\n+\t\t\tList<Row> list = mapping.get(key);\n+\t\t\tif (list != null) {\n+\t\t\t\tlist.add(record);\n+\t\t\t} else {\n+\t\t\t\tlist = new ArrayList<>();\n+\t\t\t\tlist.add(record);\n+\t\t\t\tmapping.put(key, list);\n+\t\t\t}\n+\t\t});\n+\t\tif (isAsync) {\n+\t\t\treturn AsyncTableFunctionProvider.of(new TestValuesRuntimeFunctions.AsyncTestValueLookupFunction(mapping));\n+\t\t} else {\n+\t\t\treturn TableFunctionProvider.of(new TestValuesRuntimeFunctions.TestValuesLookupFunction(mapping));\n+\t\t}\n+\t}\n+\n+\tprotected Collection<RowData> convertToRowData(DataStructureConverter converter) {\n+\t\tList<RowData> result = new ArrayList<>();\n+\t\tfor (Row value : handle()) {\n+\t\t\tRowData rowData = (RowData) converter.toInternal(value);\n+\t\t\tif (rowData != null) {\n+\t\t\t\trowData.setRowKind(value.getKind());\n+\t\t\t\tresult.add(rowData);\n+\t\t\t}\n+\t\t}\n+\t\treturn result;\n+\t}\n+\n+\t/*\n+\t* Used by apply method to deal with.\n+\t* */", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgyNjM0Mg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500826342", "bodyText": "it's better to build a specific program that only contains the rules needed for the current test, this could avoid  interference with other rules.", "author": "godfreyhe", "createdAt": "2020-10-07T08:22:05Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule PushWatermarkIntoTableSourceScanRule.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n+\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n+\t\tcalciteConfig.getStreamProgram().get().addLast(\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tWatermarkAssignerProjectTransposeRule.INSTANCE,\n+\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgyODQwMQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500828401", "bodyText": "add some tests about\n\nprojection/filter in select,\nwatermark expression contains two field references", "author": "godfreyhe", "createdAt": "2020-10-07T08:25:13Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule PushWatermarkIntoTableSourceScanRule.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n+\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n+\t\tcalciteConfig.getStreamProgram().get().addLast(\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tWatermarkAssignerProjectTransposeRule.INSTANCE,\n+\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleWatermark() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c timestamp(3),\\n\" +\n+\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleTranspose() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c timestamp(3),\\n\" +\n+\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n+\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleTransposeNotNull() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n+\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n+\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testComputedColumnWithMultipleInputs() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a string,\\n\" +\n+\t\t\t\t\"  b string,\\n\" +\n+\t\t\t\t\"  c as to_timestamp(a, b),\\n\" +\n+\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testTransposeWithRow() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c row<name string, d timestamp(3)>,\" +\n+\t\t\t\t\"  e as c.d,\" +\n+\t\t\t\t\"  watermark for e as e - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testTransposeWithNestedRow() {\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c row<name string, d row<e string, f timestamp(3)>>,\" +\n+\t\t\t\t\"  g as c.d.f,\" +\n+\t\t\t\t\"  watermark for g as g - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testTransposeWithUdf() {\n+\t\tutil.addFunction(\"func1\", new InnerUdf());\n+\t\tString ddl = \"create table MyTable(\" +\n+\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\"  c timestamp(3),\" +\n+\t\t\t\t\"  d as func1(c),\" +\n+\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n+\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\" 'table-source-class' = 'WATERMARK_PUSH_DOWN',\\n\" +\n+\t\t\t\t\" 'bounded' = 'false'\\n\" +\n+\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE3NzcxNw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r502177717", "bodyText": "Please refer to testWatermarkOnComputedColumnWithQuery\nand testWatermarkOnComputedColumnWithMultipleInputs.", "author": "fsk119", "createdAt": "2020-10-09T04:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgyODQwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgzMDY4MA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500830680", "bodyText": "Test for [[PushWatermarkIntoTableSourceScanRule]] and [[WatermarkAssignerProjectTransposeRule]]", "author": "godfreyhe", "createdAt": "2020-10-07T08:28:50Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule PushWatermarkIntoTableSourceScanRule.", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDgzMjM3MA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r500832370", "bodyText": "why parallelism is 1 ?", "author": "godfreyhe", "createdAt": "2020-10-07T08:31:24Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/runtime/stream/sql/SourceWatermarkITCase.scala", "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.runtime.stream.sql\n+\n+import java.sql.Timestamp\n+import java.time.LocalDateTime\n+\n+import org.apache.flink.api.common.eventtime.Watermark\n+import org.apache.flink.api.scala._\n+import org.apache.flink.table.api.bridge.scala._\n+import org.apache.flink.table.data.TimestampData\n+import org.apache.flink.table.planner.factories.TestValuesTableFactory\n+import org.apache.flink.table.planner.plan.rules.logical.PushWatermarkIntoTableSourceScanRuleTest\n+import org.apache.flink.table.planner.runtime.utils.BatchTestBase.row\n+import org.apache.flink.table.planner.runtime.utils.{StreamingTestBase, TestingAppendSink}\n+import org.apache.flink.types.Row\n+import org.junit.Assert.assertEquals\n+import org.junit.{Before, Test}\n+\n+import scala.collection.JavaConverters._\n+\n+class SourceWatermarkITCase extends StreamingTestBase{\n+  @Before\n+  override def before(): Unit = {\n+    super.before()\n+    env.setParallelism(1)", "originalCommit": "25dbaee00978fc3ca2995a4fa7bdb4b88e3c4dc3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "url": "https://github.com/apache/flink/commit/614d1934dd815569b08e7ed0546c0fee1ebcfd18", "message": "[FLINK-19282][planner] Add watermark push down rule for planner", "committedDate": "2020-11-05T10:01:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAwMTQ3Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r503001477", "bodyText": "please update the rule description", "author": "godfreyhe", "createdAt": "2020-10-12T01:55:12Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossProjectRule.java", "diffHunk": "@@ -36,12 +36,13 @@\n import java.util.List;\n \n /**\n- * WatermarkAssignerProjectTransposeRule.\n+ * Planner rule that push {@link LogicalWatermarkAssigner} into a {@link LogicalTableScan}\n+ * which wraps a {@link SupportsWatermarkPushDown} dynamic table source across {@link LogicalProject}.\n  * */\n-public class WatermarkAssignerProjectTransposeRule extends RelOptRule {\n-\tpublic static final WatermarkAssignerProjectTransposeRule INSTANCE = new WatermarkAssignerProjectTransposeRule();\n+public class PushWatermarkIntoTableSourceScanAcrossProjectRule extends PushWatermarkIntoTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossProjectRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossProjectRule();\n \n-\tpublic WatermarkAssignerProjectTransposeRule() {\n+\tpublic PushWatermarkIntoTableSourceScanAcrossProjectRule() {", "originalCommit": "b27010ea244247a724f41ff8f24c68b29d2ad6a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAwNDIzMQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r503004231", "bodyText": "update the comments", "author": "godfreyhe", "createdAt": "2020-10-12T02:09:31Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base Planner rule for {@link PushWatermarkIntoTableSourceScanRule} and {@link PushWatermarkIntoTableSourceScanAcrossProjectRule}.", "originalCommit": "b27010ea244247a724f41ff8f24c68b29d2ad6a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAwNTE1NA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r503005154", "bodyText": "if only TableConfig is used in this method, I suggest to pass TableConfig instead FlinkContext .", "author": "godfreyhe", "createdAt": "2020-10-12T02:14:26Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base Planner rule for {@link PushWatermarkIntoTableSourceScanRule} and {@link PushWatermarkIntoTableSourceScanAcrossProjectRule}.\n+ */\n+public abstract class PushWatermarkIntoTableSourceScanBaseRule extends RelOptRule {\n+\tpublic PushWatermarkIntoTableSourceScanBaseRule(RelOptRuleOperand operand, String description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\tprotected LogicalTableScan getNewScan(LogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, LogicalTableScan scan, FlinkContext context) {", "originalCommit": "b27010ea244247a724f41ff8f24c68b29d2ad6a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAwODIyOA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r503008228", "bodyText": "%s, idletimeout=[%s]", "author": "godfreyhe", "createdAt": "2020-10-12T02:29:28Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rel.logical.LogicalTableScan;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base Planner rule for {@link PushWatermarkIntoTableSourceScanRule} and {@link PushWatermarkIntoTableSourceScanAcrossProjectRule}.\n+ */\n+public abstract class PushWatermarkIntoTableSourceScanBaseRule extends RelOptRule {\n+\tpublic PushWatermarkIntoTableSourceScanBaseRule(RelOptRuleOperand operand, String description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\tprotected LogicalTableScan getNewScan(LogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, LogicalTableScan scan, FlinkContext context) {\n+\t\t// generate an inner watermark generator class that allows us to pass FunctionContext and ClassLoader\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tcontext.getTableConfig(),\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkExpr,\n+\t\t\t\t\t\tOption.apply(\"context\"));\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkExpr);\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());", "originalCommit": "b27010ea244247a724f41ff8f24c68b29d2ad6a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk4NzcwOQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r517987709", "bodyText": "Are there any tests that cover these changes?", "author": "godfreyhe", "createdAt": "2020-11-05T11:41:22Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/operations/MergeTableLikeUtil.java", "diffHunk": "@@ -463,7 +466,19 @@ private void collectPhysicalFieldsTypes(List<SqlNode> derivedColumns) {\n \t\t\t\t\tboolean nullable = type.getNullable() == null ? true : type.getNullable();\n \t\t\t\t\tRelDataType relType = type.deriveType(sqlValidator, nullable);\n \t\t\t\t\t// add field name and field type to physical field list\n-\t\t\t\t\tphysicalFieldNamesToTypes.put(name, relType);\n+\t\t\t\t\tnonComputedFieldNamesToTypes.put(name, relType);\n+\t\t\t\t} else if (derivedColumn instanceof SqlMetadataColumn) {\n+\t\t\t\t\tSqlMetadataColumn metadataColumn = (SqlMetadataColumn) derivedColumn;\n+\t\t\t\t\tString name = metadataColumn.getName().getSimple();\n+\t\t\t\t\tif (columns.containsKey(name)) {\n+\t\t\t\t\t\tthrow new ValidationException(String.format(\n+\t\t\t\t\t\t\t\"A column named '%s' already exists in the base table.\",\n+\t\t\t\t\t\t\tname));\n+\t\t\t\t\t}\n+\t\t\t\t\tRelDataType relType = metadataColumn.getType()\n+\t\t\t\t\t\t\t\t\t\t\t.deriveType(sqlValidator, metadataColumn.getType().getNullable());\n+\t\t\t\t\t// add field name and field type to physical field list\n+\t\t\t\t\tnonComputedFieldNamesToTypes.put(name, relType);", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzM3MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518463371", "bodyText": "Added now", "author": "fsk119", "createdAt": "2020-11-06T01:05:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk4NzcwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5NTIzMw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r517995233", "bodyText": "use a shorter name: WatermarkGeneratorFunctionContext ?", "author": "godfreyhe", "createdAt": "2020-11-05T11:54:50Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenerator.scala", "diffHunk": "@@ -87,3 +119,47 @@ object WatermarkGeneratorCodeGenerator {\n     new GeneratedWatermarkGenerator(funcName, funcCode, ctx.references.toArray)\n   }\n }\n+\n+class WatermarkGeneratorCodeGeneratorContext(\n+  tableConfig: TableConfig,\n+  contextTerm: String = \"parameters\") extends CodeGeneratorContext(tableConfig) {\n+\n+  override def addReusableFunction(\n+      function: UserDefinedFunction,\n+      functionContextClass: Class[_ <: FunctionContext] = classOf[FunctionContext],\n+      runtimeContextTerm: String = null): String = {\n+    super.addReusableFunction(\n+      function, classOf[WatermarkGeneratorCodeGeneratorFunctionContextWrapper], this.contextTerm)\n+  }\n+\n+  override def addReusableConverter(\n+      dataType: DataType,\n+      classLoaderTerm: String = null): String = {\n+    super.addReusableConverter(dataType, \"this.getClass().getClassLoader()\")\n+  }\n+}\n+\n+class WatermarkGeneratorCodeGeneratorFunctionContextWrapper(", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5ODM2Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r517998367", "bodyText": "nit: remove val", "author": "godfreyhe", "createdAt": "2020-11-05T12:00:00Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenTest.scala", "diffHunk": "@@ -36,17 +38,22 @@ import org.apache.flink.table.utils.CatalogManagerMocks\n import org.apache.calcite.jdbc.CalciteSchemaBuilder.asRootSchema\n import org.apache.calcite.plan.ConventionTraitDef\n import org.apache.calcite.rel.`type`.RelDataType\n-import org.junit.Assert.{assertEquals, assertTrue}\n-import org.junit.Test\n \n import java.lang.{Integer => JInt, Long => JLong}\n+import java.util\n import java.util.Collections\n import java.util.function.{Function => JFunction, Supplier => JSupplier}\n \n+import org.junit.Assert.{assertEquals, assertTrue}\n+import org.junit.runner.RunWith\n+import org.junit.runners.Parameterized\n+import org.junit.Test\n+\n /**\n   * Tests the generated [[WatermarkGenerator]] from [[WatermarkGeneratorCodeGenerator]].\n   */\n-class WatermarkGeneratorCodeGenTest {\n+@RunWith(classOf[Parameterized])\n+class WatermarkGeneratorCodeGenTest(val useDefinedConstructor: Boolean) {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5OTc4NA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r517999784", "bodyText": "nit: redundant line", "author": "godfreyhe", "createdAt": "2020-11-05T12:02:23Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenTest.scala", "diffHunk": "@@ -154,7 +200,9 @@ class WatermarkGeneratorCodeGenTest {\n     assertTrue(JavaFunc5.closeCalled)\n   }\n \n-  private def generateWatermarkGenerator(expr: String): WatermarkGenerator = {\n+", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAwMTA3Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518001077", "bodyText": "extract the common code with testLegacyCustomizedWatermark and testCustomizedWatermark  to another method ?", "author": "godfreyhe", "createdAt": "2020-11-05T12:04:59Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/codegen/WatermarkGeneratorCodeGenTest.scala", "diffHunk": "@@ -136,9 +145,46 @@ class WatermarkGeneratorCodeGenTest {\n         \"myFunc\"),\n       new JavaFunc5\n     )\n-    val generator = generateWatermarkGenerator(\"myFunc(ts, `offset`)\")\n-    // mock open and close invoking\n-    generator.setRuntimeContext(new MockStreamingRuntimeContext(false, 1, 1))\n+    val generator = generateWatermarkGenerator(\"myFunc(ts, `offset`)\",\n+      useDefinedConstructor)\n+    if (!useDefinedConstructor) {\n+      // mock open and close invoking\n+      generator.setRuntimeContext(new MockStreamingRuntimeContext(false, 1, 1))\n+    }\n+    generator.open(new Configuration())\n+    val results = data.map(d => generator.currentWatermark(d))\n+    generator.close()\n+    val expected = List(\n+      JLong.valueOf(995L),\n+      null,\n+      null,\n+      JLong.valueOf(4997L),\n+      JLong.valueOf(3990L),\n+      JLong.valueOf(5992L))\n+    assertEquals(expected, results)\n+    assertTrue(JavaFunc5.openCalled)\n+    assertTrue(JavaFunc5.closeCalled)\n+  }\n+\n+  @Test\n+  def testCustomizedWatermark(): Unit = {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAwMzAwOA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518003008", "bodyText": "remove the prefix Flink, it can be simplified as ProjectWatermarkAssignerTransposeRule", "author": "godfreyhe", "createdAt": "2020-11-05T12:08:33Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAwNzIxNw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518007217", "bodyText": "maybe the projection outputs the deduplicate fields, such as: a, a, a, b, b\nyou should push down the used fields in the projection.", "author": "godfreyhe", "createdAt": "2020-11-05T12:16:16Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t/**\n+\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n+\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n+\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n+\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n+\t * count as the input of the {@link LogicalWatermarkAssigner}.\n+\t * */\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\t\t// check RexNode type\n+\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n+\t\tif (!allRef) {\n+\t\t\treturn true;\n+\t\t}\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\t\tif (rowTimeIndexInProject != -1) {\n+\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxMjU4Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518012587", "bodyText": "use project.getCluster().getTypeFactory(), and move it close to the place where it is used", "author": "godfreyhe", "createdAt": "2020-11-05T12:26:21Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t/**\n+\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n+\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n+\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n+\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n+\t * count as the input of the {@link LogicalWatermarkAssigner}.\n+\t * */\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\t\t// check RexNode type\n+\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n+\t\tif (!allRef) {\n+\t\t\treturn true;\n+\t\t}\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\t\tif (rowTimeIndexInProject != -1) {\n+\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\t// whether rowtime field is in the top level projection\n+\t\tRelNode originInput = watermarkAssigner.getInput();\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n+\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\n+\t\t// get projects and data type of the transposed LogicalProject\n+\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxNDA1MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518014051", "bodyText": "originType => rowtimeType", "author": "godfreyhe", "createdAt": "2020-11-05T12:29:03Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t/**\n+\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n+\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n+\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n+\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n+\t * count as the input of the {@link LogicalWatermarkAssigner}.\n+\t * */\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\t\t// check RexNode type\n+\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n+\t\tif (!allRef) {\n+\t\t\treturn true;\n+\t\t}\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\t\tif (rowTimeIndexInProject != -1) {\n+\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\t// whether rowtime field is in the top level projection\n+\t\tRelNode originInput = watermarkAssigner.getInput();\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n+\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\n+\t\t// get projects and data type of the transposed LogicalProject\n+\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n+\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n+\t\tList<String> transposedProjectFieldNames =\n+\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n+\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tint rowTimeIndexInTranposedProject;\n+\t\tif (rowTimeIndexInTopLevelProject == -1) {\n+\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n+\n+\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n+\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n+\t\t}\n+\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n+\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n+\t\t\t\ttransposedProjectFieldNames);\n+\n+\t\t// build the transposed LogicalProjection\n+\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n+\n+\t\t// prepare for rewrite\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n+\t\tif (rowTimeIndexInTopLevelProject == -1) {\n+\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n+\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n+\t\t}\n+\t\t// label by hand\n+\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n+\n+\t\t// build the LogicalWatermarkAssigner\n+\t\tRexBuilder builder = call.builder().getRexBuilder();\n+\t\tRexNode newWatermarkExpr =\n+\t\t\t\tNestedProjectionUtil.rewrite(\n+\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n+\t\t\t\t\t\tnestedSchema,\n+\t\t\t\t\t\tbuilder).get(0);\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n+\t\t\t\twatermarkAssigner.getCluster(),\n+\t\t\t\ttransposedProject,\n+\t\t\t\trowTimeIndexInTranposedProject,\n+\t\t\t\tnewWatermarkExpr);\n+\n+\t\t// build the origin top level LogicalProjection\n+\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n+\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n+\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n+\t\t}\n+\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n+\n+\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n+\t\t\t// drop project if the transformed program merely returns its input\n+\t\t\tcall.transformTo(newWatermarkAssigner);\n+\t\t} else {\n+\t\t\tcall.transformTo(newProject);\n+\t\t}\n+\t}\n+\n+\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n+\t\tfor (int i = 0; i < projects.size(); i++) {\n+\t\t\tRexNode project = projects.get(i);\n+\t\t\tif (project instanceof RexInputRef) {\n+\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n+\t\t\t\t\treturn i;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn -1;\n+\t}\n+\n+\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxNDQxMA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518014410", "bodyText": "return the result directly", "author": "godfreyhe", "createdAt": "2020-11-05T12:29:38Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,178 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. If the top level {@link LogicalProject}\n+ * doesn't need rowtime column that is used by {@link LogicalWatermarkAssigner}, the rule will still keep the top level\n+ * {@link LogicalProject} as a pruner.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final FlinkProjectWatermarkAssignerTransposeRule INSTANCE = new FlinkProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic FlinkProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t/**\n+\t * If the rule has been applied, the projection and filter will be moved to the low level {@link LogicalProject} and\n+\t * the top level {@link LogicalProject} will only works as a pruner if exists. Therefore, only when top level\n+\t * {@link LogicalProject} has calculation or needs to prune columns except for rowtime, the process will apply the rule.\n+\t * In some situations, the query keeps the rowtime info and the top level {@link LogicalProject} has the same field\n+\t * count as the input of the {@link LogicalWatermarkAssigner}.\n+\t * */\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\t\t// check RexNode type\n+\t\tboolean allRef = project.getProjects().stream().allMatch(node -> (node instanceof RexInputRef));\n+\t\tif (!allRef) {\n+\t\t\treturn true;\n+\t\t}\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tint rowTimeIndexInProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\t\tif (rowTimeIndexInProject != -1) {\n+\t\t\treturn project.getRowType().getFieldCount() != watermarkAssigner.getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn (watermarkAssigner.getRowType().getFieldCount() - project.getRowType().getFieldCount()) != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\t// whether rowtime field is in the top level projection\n+\t\tRelNode originInput = watermarkAssigner.getInput();\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tRelDataType originRowTimeType = originInput.getRowType().getFieldList().get(rowTimeIndex).getValue();\n+\t\tint rowTimeIndexInTopLevelProject = indexOfRowtime(project.getProjects(), rowTimeIndex);\n+\n+\t\t// get projects and data type of the transposed LogicalProject\n+\t\tFlinkTypeFactory typeFactory = FlinkTypeFactory.INSTANCE();\n+\t\tList<RexNode> projectsWithRowtime = rewriteRowtimeType(project.getProjects(), rowTimeIndex, originRowTimeType);\n+\t\tList<String> transposedProjectFieldNames =\n+\t\t\t\tproject.getNamedProjects().stream().map(pair -> pair.right).collect(Collectors.toList());\n+\t\tString rowTimeName = originInput.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tint rowTimeIndexInTranposedProject;\n+\t\tif (rowTimeIndexInTopLevelProject == -1) {\n+\t\t\tprojectsWithRowtime.add(new RexInputRef(rowTimeIndex, originRowTimeType));\n+\n+\t\t\trowTimeIndexInTranposedProject = transposedProjectFieldNames.size();\n+\t\t\ttransposedProjectFieldNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\trowTimeIndexInTranposedProject = rowTimeIndexInTopLevelProject;\n+\t\t}\n+\t\tRelDataType transposedProjectType = typeFactory.createStructType(\n+\t\t\t\tprojectsWithRowtime.stream().map(RexNode::getType).collect(Collectors.toList()),\n+\t\t\t\ttransposedProjectFieldNames);\n+\n+\t\t// build the transposed LogicalProjection\n+\t\tLogicalProject transposedProject = project.copy(project.getTraitSet(), originInput, projectsWithRowtime, transposedProjectType);\n+\n+\t\t// prepare for rewrite\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(projectsWithRowtime, originInput.getRowType());\n+\t\tif (rowTimeIndexInTopLevelProject == -1) {\n+\t\t\tNestedColumn rowtimeColumn = NestedProjectionUtil.createNestedColumnLeaf(rowTimeName, rowTimeIndex, originRowTimeType);\n+\t\t\tnestedSchema.columns().put(rowTimeName, rowtimeColumn);\n+\t\t}\n+\t\t// label by hand\n+\t\tnestedSchema.columns().get(rowTimeName).setIndex(rowTimeIndexInTranposedProject);\n+\n+\t\t// build the LogicalWatermarkAssigner\n+\t\tRexBuilder builder = call.builder().getRexBuilder();\n+\t\tRexNode newWatermarkExpr =\n+\t\t\t\tNestedProjectionUtil.rewrite(\n+\t\t\t\t\t\tCollections.singletonList(watermarkAssigner.watermarkExpr()),\n+\t\t\t\t\t\tnestedSchema,\n+\t\t\t\t\t\tbuilder).get(0);\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n+\t\t\t\twatermarkAssigner.getCluster(),\n+\t\t\t\ttransposedProject,\n+\t\t\t\trowTimeIndexInTranposedProject,\n+\t\t\t\tnewWatermarkExpr);\n+\n+\t\t// build the origin top level LogicalProjection\n+\t\tList<RexNode> newProjects = new ArrayList<>(project.getProjects().size());\n+\t\tfor (int i = 0; i < project.getProjects().size(); i++) {\n+\t\t\tnewProjects.add(new RexInputRef(i, project.getProjects().get(i).getType()));\n+\t\t}\n+\t\tLogicalProject newProject = project.copy(project.getTraitSet(), newWatermarkAssigner, newProjects, project.getRowType());\n+\n+\t\tif (ProjectRemoveRule.isTrivial(newProject)) {\n+\t\t\t// drop project if the transformed program merely returns its input\n+\t\t\tcall.transformTo(newWatermarkAssigner);\n+\t\t} else {\n+\t\t\tcall.transformTo(newProject);\n+\t\t}\n+\t}\n+\n+\tprivate static int indexOfRowtime(List<RexNode> projects, int rowTimeIndex) {\n+\t\tfor (int i = 0; i < projects.size(); i++) {\n+\t\t\tRexNode project = projects.get(i);\n+\t\t\tif (project instanceof RexInputRef) {\n+\t\t\t\tif (((RexInputRef) project).getIndex() == rowTimeIndex) {\n+\t\t\t\t\treturn i;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn -1;\n+\t}\n+\n+\tprivate static List<RexNode> rewriteRowtimeType(List<RexNode> projects, int rowTimeIndex, RelDataType originType) {\n+\t\tList<RexNode> projectsWithRowtime = projects.stream().map(node -> node.accept(new RexShuttle(){", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAyNDI2Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518024263", "bodyText": "the test should only involves the required rules", "author": "godfreyhe", "createdAt": "2020-11-05T12:47:04Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test for {@link FlinkProjectWatermarkAssignerTransposeRule}.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAyNTA0MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518025041", "bodyText": "should also consider ddl with computed column and watermark with expression", "author": "godfreyhe", "createdAt": "2020-11-05T12:48:28Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/FlinkProjectWatermarkAssignerTransposeRuleTest.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * Test for {@link FlinkProjectWatermarkAssignerTransposeRule}.\n+ */\n+public class FlinkProjectWatermarkAssignerTransposeRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.DEFAULT_REWRITE());\n+\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n+\t\tcalciteConfig.getStreamProgram().get().addLast(\n+\t\t\t\t\"ProjectWatermarkAssignerTranspose\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(FlinkProjectWatermarkAssignerTransposeRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t}\n+\n+\t@Test\n+\tpublic void simpleTranspose() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE Source(\\n\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n+\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n+\t\t\t\t\t\t\") WITH (\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n+\t\t\t\t\t\t\")\";\n+\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT a, c FROM Source\");\n+\t}\n+\n+\t@Test\n+\tpublic void cannotTranspose() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE Source(\\n\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n+\t\t\t\t\t\t\"WATERMARK FOR c AS c\" +\n+\t\t\t\t\t\t\") WITH (\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false'\\n\" +\n+\t\t\t\t\t\t\")\";\n+\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT b, a FROM Source\");\n+\t}\n+\n+\t@Test\n+\tpublic void transposeWithReorder() {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAyNTk1Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518025957", "bodyText": "the class name can be simplified as PushWatermarkIntoTableSourceScanRuleBase", "author": "godfreyhe", "createdAt": "2020-11-05T12:50:00Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzMjg4MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518032881", "bodyText": "wrap to multiple lines?", "author": "godfreyhe", "createdAt": "2020-11-05T13:01:36Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {\n+\n+\tpublic PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule(RelOptRuleOperand operand,\n+\t\t\tString description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\t/**\n+\t * It uses the input watermark expression to generate the {@link WatermarkGeneratorSupplier}. After the {@link WatermarkStrategy}\n+\t * is pushed into the scan, it will build a new scan. However, when {@link FlinkLogicalWatermarkAssigner} is the parent of the\n+\t * {@link FlinkLogicalTableSourceScan} it should modify the rowtime type to keep the type of plan is consistent. In other cases,\n+\t * it just keep the data type of the scan as same as before and leave the work when rewriting the projection.\n+\t */\n+\tprotected FlinkLogicalTableSourceScan getNewScan(", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0MTE4OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518041188", "bodyText": "return the result directly", "author": "godfreyhe", "createdAt": "2020-11-05T13:15:26Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {\n+\n+\tpublic PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule(RelOptRuleOperand operand,\n+\t\t\tString description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\t/**\n+\t * It uses the input watermark expression to generate the {@link WatermarkGeneratorSupplier}. After the {@link WatermarkStrategy}\n+\t * is pushed into the scan, it will build a new scan. However, when {@link FlinkLogicalWatermarkAssigner} is the parent of the\n+\t * {@link FlinkLogicalTableSourceScan} it should modify the rowtime type to keep the type of plan is consistent. In other cases,\n+\t * it just keep the data type of the scan as same as before and leave the work when rewriting the projection.\n+\t */\n+\tprotected FlinkLogicalTableSourceScan getNewScan(\n+\t\t\tFlinkLogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, FlinkLogicalTableSourceScan scan, FlinkContext context) {\n+\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tcontext.getTableConfig(),\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkExpr,\n+\t\t\t\t\t\tOption.apply(\"context\"));\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkExpr);\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\t\t// scan row type: set rowtime type\n+\t\tTableSourceTable newTableSourceTable;\n+\t\tif (scan.getRowType().equals(watermarkAssigner.getInput().getRowType())) {\n+\t\t\t// without projection or project doesn't project or project doesn't add new computed columns\n+\t\t\tnewTableSourceTable = tableSourceTable.copy(\n+\t\t\t\t\tnewDynamicTableSource,\n+\t\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\t\tnew String[]{digest});\n+\t\t} else {\n+\t\t\t// project exists. make the project's rowtype is consistent with the origin plan.\n+\t\t\tnewTableSourceTable = tableSourceTable.copy(\n+\t\t\t\t\tnewDynamicTableSource,\n+\t\t\t\t\tscan.getRowType(),\n+\t\t\t\t\tnew String[]{digest});\n+\t\t}\n+\n+\t\tFlinkLogicalTableSourceScan newScan = FlinkLogicalTableSourceScan.create(scan.getCluster(),\n+\t\t\t\tnewTableSourceTable);\n+\t\treturn newScan;", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NDQ5OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518044498", "bodyText": "add static", "author": "godfreyhe", "createdAt": "2020-11-05T13:20:40Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {\n+\n+\tpublic PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule(RelOptRuleOperand operand,\n+\t\t\tString description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\t/**\n+\t * It uses the input watermark expression to generate the {@link WatermarkGeneratorSupplier}. After the {@link WatermarkStrategy}\n+\t * is pushed into the scan, it will build a new scan. However, when {@link FlinkLogicalWatermarkAssigner} is the parent of the\n+\t * {@link FlinkLogicalTableSourceScan} it should modify the rowtime type to keep the type of plan is consistent. In other cases,\n+\t * it just keep the data type of the scan as same as before and leave the work when rewriting the projection.\n+\t */\n+\tprotected FlinkLogicalTableSourceScan getNewScan(\n+\t\t\tFlinkLogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, FlinkLogicalTableSourceScan scan, FlinkContext context) {\n+\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tcontext.getTableConfig(),\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkExpr,\n+\t\t\t\t\t\tOption.apply(\"context\"));\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkExpr);\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\t\t// scan row type: set rowtime type\n+\t\tTableSourceTable newTableSourceTable;\n+\t\tif (scan.getRowType().equals(watermarkAssigner.getInput().getRowType())) {\n+\t\t\t// without projection or project doesn't project or project doesn't add new computed columns\n+\t\t\tnewTableSourceTable = tableSourceTable.copy(\n+\t\t\t\t\tnewDynamicTableSource,\n+\t\t\t\t\twatermarkAssigner.getRowType(),\n+\t\t\t\t\tnew String[]{digest});\n+\t\t} else {\n+\t\t\t// project exists. make the project's rowtype is consistent with the origin plan.\n+\t\t\tnewTableSourceTable = tableSourceTable.copy(\n+\t\t\t\t\tnewDynamicTableSource,\n+\t\t\t\t\tscan.getRowType(),\n+\t\t\t\t\tnew String[]{digest});\n+\t\t}\n+\n+\t\tFlinkLogicalTableSourceScan newScan = FlinkLogicalTableSourceScan.create(scan.getCluster(),\n+\t\t\t\tnewTableSourceTable);\n+\t\treturn newScan;\n+\t}\n+\n+\t/**\n+\t * Wrapper of the {@link GeneratedWatermarkGenerator} that is used to create {@link WatermarkGenerator}.\n+\t * The {@link DefaultWatermarkGeneratorSupplier} uses the {@link WatermarkGeneratorSupplier.Context} to init\n+\t * the generated watermark generator.\n+\t */\n+\tprivate static class DefaultWatermarkGeneratorSupplier implements WatermarkGeneratorSupplier<RowData> {\n+\n+\t\tprivate static final long serialVersionUID = 1L;\n+\n+\t\tprivate final Configuration configuration;\n+\t\tprivate final GeneratedWatermarkGenerator generatedWatermarkGenerator;\n+\n+\t\tpublic DefaultWatermarkGeneratorSupplier(Configuration configuration,\n+\t\t\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator) {\n+\t\t\tthis.configuration = configuration;\n+\t\t\tthis.generatedWatermarkGenerator = generatedWatermarkGenerator;\n+\t\t}\n+\n+\t\t@Override\n+\t\tpublic WatermarkGenerator<RowData> createWatermarkGenerator(Context context) {\n+\n+\t\t\tList<Object> references = new ArrayList<>(Arrays.asList(generatedWatermarkGenerator.getReferences()));\n+\t\t\treferences.add(context);\n+\n+\t\t\torg.apache.flink.table.runtime.generated.WatermarkGenerator innerWatermarkGenerator =\n+\t\t\t\t\tnew GeneratedWatermarkGenerator(\n+\t\t\t\t\t\t\tgeneratedWatermarkGenerator.getClassName(),\n+\t\t\t\t\t\t\tgeneratedWatermarkGenerator.getCode(),\n+\t\t\t\t\t\t\treferences.toArray())\n+\t\t\t\t\t\t\t.newInstance(Thread.currentThread().getContextClassLoader());\n+\n+\t\t\ttry {\n+\t\t\t\tinnerWatermarkGenerator.open(configuration);\n+\t\t\t} catch (Exception e) {\n+\t\t\t\tthrow new RuntimeException(\"Fail to instantiate generated watermark generator.\", e);\n+\t\t\t}\n+\t\t\treturn new DefaultWatermarkGeneratorSupplier.DefaultWatermarkGenerator(innerWatermarkGenerator);\n+\t\t}\n+\n+\t\t/**\n+\t\t * Wrapper of the code-generated {@link org.apache.flink.table.runtime.generated.WatermarkGenerator}.\n+\t\t */\n+\t\tprivate class DefaultWatermarkGenerator implements WatermarkGenerator<RowData> {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NTA2Mg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518045062", "bodyText": "PushWatermarkIntoTableSourceScanRule", "author": "godfreyhe", "createdAt": "2020-11-05T13:21:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NTIzNQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518045235", "bodyText": "\"PushWatermarkIntoFlinkTableSourceScan\" -> \"PushWatermarkIntoTableSourceScanRule\"", "author": "godfreyhe", "createdAt": "2020-11-05T13:21:48Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRule.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none())),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScan\");", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NTkyMg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518045922", "bodyText": "PushWatermarkIntoTableSourceScanAcrossCalcRule", "author": "godfreyhe", "createdAt": "2020-11-05T13:22:57Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0Njc4Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518046787", "bodyText": "we can extract a common method into PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule", "author": "godfreyhe", "createdAt": "2020-11-05T13:24:20Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0OTM4Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518049383", "bodyText": "we can expand the local ref first", "author": "godfreyhe", "createdAt": "2020-11-05T13:28:15Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tFlinkLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tFlinkLogicalCalc calc = call.rel(1);\n+\n+\t\tRexProgram originProgram = calc.getProgram();\n+\t\tList<RexLocalRef> projectList = originProgram.getProjectList();", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA1MjkyMg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518052922", "bodyText": "we should only replace the rowtime field ref and other refs should be re-indexed based on TableScan's rowtype.", "author": "godfreyhe", "createdAt": "2020-11-05T13:33:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tFlinkLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tFlinkLogicalCalc calc = call.rel(1);\n+\n+\t\tRexProgram originProgram = calc.getProgram();\n+\t\tList<RexLocalRef> projectList = originProgram.getProjectList();\n+\n+\t\t//get watermark expression\n+\t\tRexNode computedColumn = originProgram.expandLocalRef(projectList.get(watermarkAssigner.rowtimeFieldIndex()));\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3MDY4MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518470681", "bodyText": "The watermark expression only has one input ref. But it's a good idea to make it more robust.", "author": "fsk119", "createdAt": "2020-11-06T01:29:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA1MjkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA1NDMwNg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518054306", "bodyText": "newComputedColumn", "author": "godfreyhe", "createdAt": "2020-11-05T13:35:32Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule extends PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule {\n+\tpublic static final PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\treturn tableSourceTable != null && tableSourceTable.tableSource() instanceof SupportsWatermarkPushDown;\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tFlinkLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tFlinkLogicalCalc calc = call.rel(1);\n+\n+\t\tRexProgram originProgram = calc.getProgram();\n+\t\tList<RexLocalRef> projectList = originProgram.getProjectList();\n+\n+\t\t//get watermark expression\n+\t\tRexNode computedColumn = originProgram.expandLocalRef(projectList.get(watermarkAssigner.rowtimeFieldIndex()));\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\t// replace the input ref with the computed column\n+\t\t\t\treturn computedColumn;\n+\t\t\t}\n+\t\t});\n+\n+\t\t// push watermark assigner into the scan\n+\t\tFlinkLogicalTableSourceScan newScan =\n+\t\t\t\tgetNewScan(watermarkAssigner, newWatermarkExpr, call.rel(2), (FlinkContext) call.getPlanner().getContext());\n+\n+\t\tFlinkTypeFactory typeFactory = (FlinkTypeFactory) watermarkAssigner.getCluster().getTypeFactory();\n+\t\tRexBuilder builder = call.builder().getRexBuilder();\n+\t\t// cast timestamp type to rowtime type.\n+\t\tRexNode newRexNode = builder.makeReinterpretCast(", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MDEwNg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518060106", "bodyText": "add a method parameter determine the condition", "author": "godfreyhe", "createdAt": "2020-11-05T13:44:16Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.Watermark;\n+import org.apache.flink.api.common.eventtime.WatermarkGenerator;\n+import org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier;\n+import org.apache.flink.api.common.eventtime.WatermarkOutput;\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.table.api.config.ExecutionConfigOptions;\n+import org.apache.flink.table.connector.source.DynamicTableSource;\n+import org.apache.flink.table.connector.source.abilities.SupportsWatermarkPushDown;\n+import org.apache.flink.table.data.RowData;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.codegen.WatermarkGeneratorCodeGenerator;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.schema.TableSourceTable;\n+import org.apache.flink.table.runtime.generated.GeneratedWatermarkGenerator;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleOperand;\n+import org.apache.calcite.rex.RexNode;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import scala.Option;\n+\n+/**\n+ * Base rule for interface {@link SupportsWatermarkPushDown}. It offers a util to push the {@link FlinkLogicalWatermarkAssigner}\n+ * into the {@link FlinkLogicalTableSourceScan}.\n+ */\n+public abstract class PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule extends RelOptRule {\n+\n+\tpublic PushWatermarkIntoFlinkLogicalTableSourceScanBaseRule(RelOptRuleOperand operand,\n+\t\t\tString description) {\n+\t\tsuper(operand, description);\n+\t}\n+\n+\t/**\n+\t * It uses the input watermark expression to generate the {@link WatermarkGeneratorSupplier}. After the {@link WatermarkStrategy}\n+\t * is pushed into the scan, it will build a new scan. However, when {@link FlinkLogicalWatermarkAssigner} is the parent of the\n+\t * {@link FlinkLogicalTableSourceScan} it should modify the rowtime type to keep the type of plan is consistent. In other cases,\n+\t * it just keep the data type of the scan as same as before and leave the work when rewriting the projection.\n+\t */\n+\tprotected FlinkLogicalTableSourceScan getNewScan(\n+\t\t\tFlinkLogicalWatermarkAssigner watermarkAssigner, RexNode watermarkExpr, FlinkLogicalTableSourceScan scan, FlinkContext context) {\n+\n+\t\tGeneratedWatermarkGenerator generatedWatermarkGenerator =\n+\t\t\t\tWatermarkGeneratorCodeGenerator.generateWatermarkGenerator(\n+\t\t\t\t\t\tcontext.getTableConfig(),\n+\t\t\t\t\t\tFlinkTypeFactory.toLogicalRowType(scan.getRowType()),\n+\t\t\t\t\t\twatermarkExpr,\n+\t\t\t\t\t\tOption.apply(\"context\"));\n+\t\tConfiguration configuration = context.getTableConfig().getConfiguration();\n+\n+\t\tWatermarkGeneratorSupplier<RowData> supplier = new DefaultWatermarkGeneratorSupplier(configuration, generatedWatermarkGenerator);\n+\t\tString digest = String.format(\"watermark=[%s]\", watermarkExpr);\n+\n+\t\tWatermarkStrategy<RowData> watermarkStrategy = WatermarkStrategy.forGenerator(supplier);\n+\t\tDuration idleTimeout = configuration.get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n+\t\tif (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n+\t\t\twatermarkStrategy.withIdleness(idleTimeout);\n+\t\t\tdigest = String.format(\"%s idletimeout=[%s]\", digest, idleTimeout.toMillis());\n+\t\t}\n+\n+\t\tTableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n+\t\tDynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n+\n+\t\t((SupportsWatermarkPushDown) newDynamicTableSource).applyWatermark(watermarkStrategy);\n+\t\t// scan row type: set rowtime type\n+\t\tTableSourceTable newTableSourceTable;\n+\t\tif (scan.getRowType().equals(watermarkAssigner.getInput().getRowType())) {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MTMxMA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518061310", "bodyText": "UNSUPPORTED_ABILITIES should also be removed", "author": "godfreyhe", "createdAt": "2020-11-05T13:46:03Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/sources/DynamicSourceUtils.java", "diffHunk": "@@ -331,19 +329,6 @@ private static void validateWatermarks(\n \t\t}\n \t}\n \n-\tprivate static void validateAbilities(DynamicTableSource source) {\n-\t\tUNSUPPORTED_ABILITIES.forEach(ability -> {", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2MTkwNw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518061907", "bodyText": "ditto", "author": "godfreyhe", "createdAt": "2020-11-05T13:46:53Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule {@link PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule} and {@link PushWatermarkIntoFlinkTableSourceScanRule}.\n+ * */\n+public class PushWatermarkIntoFlinkTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.LOGICAL_REWRITE());", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2NTgzNA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518065834", "bodyText": "Tests for watermark push down.", "author": "godfreyhe", "createdAt": "2020-11-05T13:52:37Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/planner/plan/stream/sql/SourceWatermarkTest.scala", "diffHunk": "@@ -0,0 +1,182 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.stream.sql\n+\n+import org.apache.flink.table.planner.utils.TableTestBase\n+import org.apache.flink.table.planner.plan.rules.logical._\n+import org.junit.Test\n+\n+/**\n+ * Tests for [[PushWatermarkIntoFlinkTableSourceScanRule]] and\n+ * [[PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule]].", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2NzQwOA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518067408", "bodyText": "why the watermark node can't be pushed down", "author": "godfreyhe", "createdAt": "2020-11-05T13:54:51Z", "path": "flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/SourceWatermarkTest.xml", "diffHunk": "@@ -0,0 +1,152 @@\n+<?xml version=\"1.0\" ?>\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one or more\n+contributor license agreements.  See the NOTICE file distributed with\n+this work for additional information regarding copyright ownership.\n+The ASF licenses this file to you under the Apache License, Version 2.0\n+(the \"License\"); you may not use this file except in compliance with\n+the License.  You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+<Root>\n+  <TestCase name=\"testSimpleWatermark\">\n+    <Resource name=\"sql\">\n+      <![CDATA[select a, c from MyTable]]>\n+    </Resource>\n+    <Resource name=\"planBefore\">\n+      <![CDATA[\n+LogicalProject(a=[$0], c=[$2])\n++- LogicalWatermarkAssigner(rowtime=[c], watermark=[-($2, 5000:INTERVAL SECOND)])\n+   +- LogicalTableScan(table=[[default_catalog, default_database, MyTable]])\n+]]>\n+    </Resource>\n+    <Resource name=\"planAfter\">\n+      <![CDATA[\n+WatermarkAssigner(rowtime=[c], watermark=[-(c, 5000:INTERVAL SECOND)])", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE5MzU2MQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518193561", "bodyText": "Oh! I add the wrong rule into the rule set. It works now.", "author": "fsk119", "createdAt": "2020-11-05T16:39:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2NzQwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2OTQ1OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518069458", "bodyText": "add a test about watermark for d as d - interval '5' second + other timestamp field", "author": "godfreyhe", "createdAt": "2020-11-05T13:57:37Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoFlinkTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.calcite.CalciteConfig;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkStreamProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableConfigUtils;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule {@link PushWatermarkIntoFlinkTableSourceScanAcrossCalcRule} and {@link PushWatermarkIntoFlinkTableSourceScanRule}.\n+ * */\n+public class PushWatermarkIntoFlinkTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tutil.buildStreamProgram(FlinkStreamProgram.LOGICAL_REWRITE());\n+\t\tCalciteConfig calciteConfig = TableConfigUtils.getCalciteConfig(util.tableEnv().getConfig());\n+\t\tcalciteConfig.getStreamProgram().get().addLast(\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tPushWatermarkIntoFlinkTableSourceScanRule.INSTANCE,\n+\t\t\t\t\t\t\t\tPushWatermarkIntoFlinkTableSourceScanAcrossCalcRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleWatermark() {\n+\t\tString ddl =\n+\t\t\t\t\"create table MyTable(\" +\n+\t\t\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\t\t\"  c timestamp(3),\\n\" +\n+\t\t\t\t\t\t\"  watermark for c as c - interval '5' second\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select a, c from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumn() {\n+\t\tString ddl =\n+\t\t\t\t\"create table MyTable(\" +\n+\t\t\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\t\t\"  c timestamp(3),\\n\" +\n+\t\t\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n+\t\t\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumnWithQuery() {\n+\t\tString ddl =\n+\t\t\t\t\"create table MyTable(\" +\n+\t\t\t\t\t\t\"  a int,\\n\" +\n+\t\t\t\t\t\t\"  b bigint,\\n\" +\n+\t\t\t\t\t\t\"  c timestamp(3) not null,\\n\" +\n+\t\t\t\t\t\t\"  d as c + interval '5' second,\\n\" +\n+\t\t\t\t\t\t\"  watermark for d as d - interval '5' second\\n\" +", "originalCommit": "614d1934dd815569b08e7ed0546c0fee1ebcfd18", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE4NzQ5Nw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518187497", "bodyText": "The watermark expression only allows one input reference. The expression mentioned is illegal", "author": "fsk119", "createdAt": "2020-11-05T16:30:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA2OTQ1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU1OTEzMQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518559131", "bodyText": "the projection is not been pushed down ?", "author": "godfreyhe", "createdAt": "2020-11-06T07:07:36Z", "path": "flink-table/flink-table-planner-blink/src/test/resources/org/apache/flink/table/planner/plan/stream/sql/MiniBatchIntervalInferTest.xml", "diffHunk": "@@ -572,7 +556,7 @@ GlobalGroupAggregate(groupBy=[b], select=[b, COUNT(distinct$0 count$0) AS EXPR$1\n       +- Calc(select=[b, a, c])\n          +- MiniBatchAssigner(interval=[1000ms], mode=[ProcTime])\n             +- WatermarkAssigner(rowtime=[rowtime], watermark=[rowtime])\n-               +- Calc(select=[a, b, c, PROCTIME() AS proctime, rowtime])\n+               +- Calc(select=[b, a, c, rowtime])", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU2MzM1NQ==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518563355", "bodyText": "It better rename setIndex to setIndexOfLeafInNewSchema", "author": "godfreyhe", "createdAt": "2020-11-06T07:19:41Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU2OTk4MA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518569980", "bodyText": "builder.project(transposedProjects, usedNames);", "author": "godfreyhe", "createdAt": "2020-11-06T07:37:06Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());\n+\t\t\tcolumn.markLeaf();\n+\n+\t\t\tusedNames.add(column.name());\n+\t\t\ttransposedProjects.add(builder.field(column.indexInOriginSchema()));\n+\t\t}\n+\n+\t\t// get the rowtime field index in the transposed project\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tint indexOfRowTimeInTransposedProject;\n+\t\tif (nestedSchema.columns().get(rowTimeName) == null) {\n+\t\t\t// push the RexInputRef of the rowtime into the list\n+\t\t\tint rowTimeIndexInInput = watermarkAssigner.rowtimeFieldIndex();\n+\t\t\tindexOfRowTimeInTransposedProject = transposedProjects.size();\n+\t\t\ttransposedProjects.add(builder.field(rowTimeIndexInInput));\n+\t\t\tusedNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\t//find rowtime ref in the list and mark the location\n+\t\t\tindexOfRowTimeInTransposedProject = nestedSchema.columns().get(rowTimeName).indexOfLeafInNewSchema();\n+\t\t}\n+\n+\t\t// the rowtime column has no rowtime indicator\n+\t\tLogicalProject transposedProject =", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU3MDA5Mg==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518570092", "bodyText": "builder.watermark(xx)", "author": "godfreyhe", "createdAt": "2020-11-06T07:37:21Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());\n+\t\t\tcolumn.markLeaf();\n+\n+\t\t\tusedNames.add(column.name());\n+\t\t\ttransposedProjects.add(builder.field(column.indexInOriginSchema()));\n+\t\t}\n+\n+\t\t// get the rowtime field index in the transposed project\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tint indexOfRowTimeInTransposedProject;\n+\t\tif (nestedSchema.columns().get(rowTimeName) == null) {\n+\t\t\t// push the RexInputRef of the rowtime into the list\n+\t\t\tint rowTimeIndexInInput = watermarkAssigner.rowtimeFieldIndex();\n+\t\t\tindexOfRowTimeInTransposedProject = transposedProjects.size();\n+\t\t\ttransposedProjects.add(builder.field(rowTimeIndexInInput));\n+\t\t\tusedNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\t//find rowtime ref in the list and mark the location\n+\t\t\tindexOfRowTimeInTransposedProject = nestedSchema.columns().get(rowTimeName).indexOfLeafInNewSchema();\n+\t\t}\n+\n+\t\t// the rowtime column has no rowtime indicator\n+\t\tLogicalProject transposedProject =\n+\t\t\t\tLogicalProject.create(watermarkAssigner.getInput(), project.getHints(), transposedProjects, usedNames);\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn new RexInputRef(indexOfRowTimeInTransposedProject, inputRef.getType());\n+\t\t\t}\n+\t\t});\n+\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU3MDcxMw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518570713", "bodyText": "ditto", "author": "godfreyhe", "createdAt": "2020-11-06T07:39:07Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());\n+\t\t\tcolumn.markLeaf();\n+\n+\t\t\tusedNames.add(column.name());\n+\t\t\ttransposedProjects.add(builder.field(column.indexInOriginSchema()));\n+\t\t}\n+\n+\t\t// get the rowtime field index in the transposed project\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tint indexOfRowTimeInTransposedProject;\n+\t\tif (nestedSchema.columns().get(rowTimeName) == null) {\n+\t\t\t// push the RexInputRef of the rowtime into the list\n+\t\t\tint rowTimeIndexInInput = watermarkAssigner.rowtimeFieldIndex();\n+\t\t\tindexOfRowTimeInTransposedProject = transposedProjects.size();\n+\t\t\ttransposedProjects.add(builder.field(rowTimeIndexInInput));\n+\t\t\tusedNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\t//find rowtime ref in the list and mark the location\n+\t\t\tindexOfRowTimeInTransposedProject = nestedSchema.columns().get(rowTimeName).indexOfLeafInNewSchema();\n+\t\t}\n+\n+\t\t// the rowtime column has no rowtime indicator\n+\t\tLogicalProject transposedProject =\n+\t\t\t\tLogicalProject.create(watermarkAssigner.getInput(), project.getHints(), transposedProjects, usedNames);\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn new RexInputRef(indexOfRowTimeInTransposedProject, inputRef.getType());\n+\t\t\t}\n+\t\t});\n+\n+\t\tLogicalWatermarkAssigner newWatermarkAssigner = LogicalWatermarkAssigner.create(\n+\t\t\t\twatermarkAssigner.getCluster(),\n+\t\t\t\ttransposedProject,\n+\t\t\t\tindexOfRowTimeInTransposedProject,\n+\t\t\t\tnewWatermarkExpr);\n+\n+\t\tList<RexNode> newProjects = NestedProjectionUtil.rewrite(project.getProjects(), nestedSchema, call.builder().getRexBuilder());\n+\t\tLogicalProject newProject = LogicalProject.create(newWatermarkAssigner, project.getHints(), newProjects, project.getRowType());", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU3MjU5NA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518572594", "bodyText": "overwrite the ref only its index equals to the index of rowtime", "author": "godfreyhe", "createdAt": "2020-11-06T07:43:52Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/ProjectWatermarkAssignerTransposeRule.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to you under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.utils.NestedColumn;\n+import org.apache.flink.table.planner.plan.utils.NestedProjectionUtil;\n+import org.apache.flink.table.planner.plan.utils.NestedSchema;\n+\n+import org.apache.calcite.plan.RelOptRule;\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rel.logical.LogicalProject;\n+import org.apache.calcite.rel.rules.ProjectRemoveRule;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.tools.RelBuilder;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+/**\n+ * Transpose between the {@link LogicalWatermarkAssigner} and {@link LogicalProject}. The transposed {@link LogicalProject}\n+ * works like a pruner to prune the unused fields from source. The top level {@link LogicalProject} still has to do the\n+ * calculation, filter and prune the rowtime column if the query doesn't need.\n+ *\n+ * <p>NOTES: Currently the rule doesn't support nested projection push down.\n+ */\n+public class ProjectWatermarkAssignerTransposeRule extends RelOptRule {\n+\n+\tpublic static final ProjectWatermarkAssignerTransposeRule INSTANCE = new ProjectWatermarkAssignerTransposeRule();\n+\n+\tpublic ProjectWatermarkAssignerTransposeRule() {\n+\t\tsuper(operand(LogicalProject.class,\n+\t\t\t\toperand(LogicalWatermarkAssigner.class, any())),\n+\t\t\t\t\"FlinkProjectWatermarkAssignerTransposeRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tint rowTimeIndex = watermarkAssigner.rowtimeFieldIndex();\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(rowTimeIndex);\n+\t\tNestedSchema schema = NestedProjectionUtil.build(project.getProjects(), project.getInput().getRowType());\n+\n+\t\t// The field count difference between the used column in the input and in top level projection is always non-negative.\n+\t\t// At the beginning, the optimization hasn't applied the rule, the input has more columns.\n+\t\t// After the rule is applied, it will always push the used column (including the rowtime) under the watermark assigner.\n+\t\t// Therefore, if the used columns in the input are as same as the input, it doesn't need apply the rule.\n+\n+\t\t// For nested projection, it needs one more check: all top level column in nestedSchema are leaves.\n+\t\tif (schema.columns().containsKey(rowTimeName)) {\n+\t\t\treturn schema.columns().size() != watermarkAssigner.getInput().getRowType().getFieldCount();\n+\t\t} else {\n+\t\t\treturn watermarkAssigner.getInput().getRowType().getFieldCount() - schema.columns().size() != 1;\n+\t\t}\n+\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tLogicalProject project = call.rel(0);\n+\t\tLogicalWatermarkAssigner watermarkAssigner = call.rel(1);\n+\n+\t\tNestedSchema nestedSchema = NestedProjectionUtil.build(project.getProjects(), watermarkAssigner.getRowType());\n+\t\tRelBuilder builder = call.builder().push(watermarkAssigner.getInput());\n+\t\tList<RexInputRef> transposedProjects = new LinkedList<>();\n+\t\tList<String> usedNames = new LinkedList<>();\n+\n+\t\t// TODO: support nested projection push down in transpose\n+\t\t// add the used column RexInputRef and names into list\n+\t\tfor (NestedColumn column: nestedSchema.columns().values()) {\n+\t\t\t// mark by hand\n+\t\t\tcolumn.setIndex(transposedProjects.size());\n+\t\t\tcolumn.markLeaf();\n+\n+\t\t\tusedNames.add(column.name());\n+\t\t\ttransposedProjects.add(builder.field(column.indexInOriginSchema()));\n+\t\t}\n+\n+\t\t// get the rowtime field index in the transposed project\n+\t\tString rowTimeName = watermarkAssigner.getRowType().getFieldNames().get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tint indexOfRowTimeInTransposedProject;\n+\t\tif (nestedSchema.columns().get(rowTimeName) == null) {\n+\t\t\t// push the RexInputRef of the rowtime into the list\n+\t\t\tint rowTimeIndexInInput = watermarkAssigner.rowtimeFieldIndex();\n+\t\t\tindexOfRowTimeInTransposedProject = transposedProjects.size();\n+\t\t\ttransposedProjects.add(builder.field(rowTimeIndexInInput));\n+\t\t\tusedNames.add(rowTimeName);\n+\t\t} else {\n+\t\t\t//find rowtime ref in the list and mark the location\n+\t\t\tindexOfRowTimeInTransposedProject = nestedSchema.columns().get(rowTimeName).indexOfLeafInNewSchema();\n+\t\t}\n+\n+\t\t// the rowtime column has no rowtime indicator\n+\t\tLogicalProject transposedProject =\n+\t\t\t\tLogicalProject.create(watermarkAssigner.getInput(), project.getHints(), transposedProjects, usedNames);\n+\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\treturn new RexInputRef(indexOfRowTimeInTransposedProject, inputRef.getType());\n+\t\t\t}", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU4MDM3OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518580378", "bodyText": "\"PushWatermarkIntoTableSourceScanAcrossCalcRule\"", "author": "godfreyhe", "createdAt": "2020-11-06T08:01:30Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU4MTA1OA==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518581058", "bodyText": "use the element in projectList", "author": "godfreyhe", "createdAt": "2020-11-06T08:03:01Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanAcrossCalcRule.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.api.common.eventtime.WatermarkStrategy;\n+import org.apache.flink.table.planner.calcite.FlinkContext;\n+import org.apache.flink.table.planner.calcite.FlinkTypeFactory;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+\n+import org.apache.calcite.plan.RelOptRuleCall;\n+import org.apache.calcite.rex.RexBuilder;\n+import org.apache.calcite.rex.RexInputRef;\n+import org.apache.calcite.rex.RexLocalRef;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.rex.RexProgram;\n+import org.apache.calcite.rex.RexProgramBuilder;\n+import org.apache.calcite.rex.RexShuttle;\n+import org.apache.calcite.util.Pair;\n+\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Rule to push the {@link FlinkLogicalWatermarkAssigner} across the {@link FlinkLogicalCalc} to the {@link FlinkLogicalTableSourceScan}.\n+ * The rule will first look for the computed column in the {@link FlinkLogicalCalc} and then translate the watermark expression\n+ * and the computed column into a {@link WatermarkStrategy}. With the new scan the rule will build a new {@link FlinkLogicalCalc}.\n+ */\n+public class PushWatermarkIntoTableSourceScanAcrossCalcRule extends PushWatermarkIntoTableSourceScanRuleBase {\n+\tpublic static final PushWatermarkIntoTableSourceScanAcrossCalcRule INSTANCE = new PushWatermarkIntoTableSourceScanAcrossCalcRule();\n+\n+\tpublic PushWatermarkIntoTableSourceScanAcrossCalcRule() {\n+\t\tsuper(operand(FlinkLogicalWatermarkAssigner.class,\n+\t\t\t\toperand(FlinkLogicalCalc.class,\n+\t\t\t\t\t\toperand(FlinkLogicalTableSourceScan.class, none()))),\n+\t\t\t\t\"PushWatermarkIntoFlinkTableSourceScanAcrossProjectRule\");\n+\t}\n+\n+\t@Override\n+\tpublic boolean matches(RelOptRuleCall call) {\n+\t\tFlinkLogicalTableSourceScan scan = call.rel(2);\n+\t\treturn supportsWatermarkPushDown(scan);\n+\t}\n+\n+\t@Override\n+\tpublic void onMatch(RelOptRuleCall call) {\n+\t\tFlinkLogicalWatermarkAssigner watermarkAssigner = call.rel(0);\n+\t\tFlinkLogicalCalc calc = call.rel(1);\n+\n+\t\tRexProgram originProgram = calc.getProgram();\n+\t\tList<RexNode> projectList = originProgram.getProjectList().stream()\n+\t\t\t\t.map(originProgram::expandLocalRef)\n+\t\t\t\t.collect(Collectors.toList());\n+\n+\t\t//get watermark expression\n+\t\tRexNode computedColumn = projectList.get(watermarkAssigner.rowtimeFieldIndex());\n+\t\tRexNode newWatermarkExpr = watermarkAssigner.watermarkExpr().accept(new RexShuttle() {\n+\t\t\t@Override\n+\t\t\tpublic RexNode visitInputRef(RexInputRef inputRef) {\n+\t\t\t\t// replace the input ref of the rowtime with the computed column\n+\t\t\t\tif (inputRef.getIndex() == watermarkAssigner.rowtimeFieldIndex()) {\n+\t\t\t\t\treturn computedColumn;\n+\t\t\t\t} else {\n+\t\t\t\t\treturn inputRef;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t});\n+\n+\t\t// push watermark assigner into the scan\n+\t\tFlinkLogicalTableSourceScan newScan =\n+\t\t\t\tgetNewScan(watermarkAssigner, newWatermarkExpr, call.rel(2), ((FlinkContext) call.getPlanner().getContext()).getTableConfig());\n+\n+\t\tFlinkTypeFactory typeFactory = (FlinkTypeFactory) watermarkAssigner.getCluster().getTypeFactory();\n+\t\tRexBuilder builder = call.builder().getRexBuilder();\n+\t\t// cast timestamp type to rowtime type.\n+\t\tRexNode newComputedColumn = builder.makeReinterpretCast(\n+\t\t\t\ttypeFactory.createRowtimeIndicatorType(computedColumn.getType().isNullable()),\n+\t\t\t\tcomputedColumn,\n+\t\t\t\tnull);\n+\n+\t\t// build new calc program\n+\t\tRexProgramBuilder programBuilder = new RexProgramBuilder(newScan.getRowType(), builder);\n+\n+\t\tfor (int i = 0; i < projectList.size(); i++) {\n+\t\t\tPair<RexLocalRef, String> rexLocalRefStringPair = originProgram.getNamedProjects().get(i);", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU5Nzg0Mw==", "url": "https://github.com/apache/flink/pull/13449#discussion_r518597843", "bodyText": "define this class in JavaUserDefinedScalarFunctions", "author": "godfreyhe", "createdAt": "2020-11-06T08:37:50Z", "path": "flink-table/flink-table-planner-blink/src/test/java/org/apache/flink/table/planner/plan/rules/logical/PushWatermarkIntoTableSourceScanRuleTest.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.table.planner.plan.rules.logical;\n+\n+import org.apache.flink.table.api.TableConfig;\n+import org.apache.flink.table.functions.ScalarFunction;\n+import org.apache.flink.table.planner.plan.nodes.FlinkConventions;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalCalc;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalTableSourceScan;\n+import org.apache.flink.table.planner.plan.nodes.logical.FlinkLogicalWatermarkAssigner;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkChainedProgram;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkHepRuleSetProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.FlinkVolcanoProgramBuilder;\n+import org.apache.flink.table.planner.plan.optimize.program.HEP_RULES_EXECUTION_TYPE;\n+import org.apache.flink.table.planner.plan.optimize.program.StreamOptimizeContext;\n+import org.apache.flink.table.planner.utils.StreamTableTestUtil;\n+import org.apache.flink.table.planner.utils.TableTestBase;\n+\n+import org.apache.calcite.plan.Convention;\n+import org.apache.calcite.plan.hep.HepMatchOrder;\n+import org.apache.calcite.rel.rules.CoreRules;\n+import org.apache.calcite.tools.RuleSets;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+/**\n+ * Test rule {@link PushWatermarkIntoTableSourceScanAcrossCalcRule} and {@link PushWatermarkIntoTableSourceScanRule}.\n+ * */\n+public class PushWatermarkIntoTableSourceScanRuleTest extends TableTestBase {\n+\tprivate StreamTableTestUtil util = streamTestUtil(new TableConfig());\n+\n+\t@Before\n+\tpublic void setup() {\n+\t\tFlinkChainedProgram<StreamOptimizeContext> program = new FlinkChainedProgram<>();\n+\t\tprogram.addLast(\n+\t\t\t\t\"Converter\",\n+\t\t\t\tFlinkVolcanoProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tCoreRules.PROJECT_TO_CALC,\n+\t\t\t\t\t\t\t\tCoreRules.FILTER_TO_CALC,\n+\t\t\t\t\t\t\t\tFlinkLogicalCalc.CONVERTER(),\n+\t\t\t\t\t\t\t\tFlinkLogicalTableSourceScan.CONVERTER(),\n+\t\t\t\t\t\t\t\tFlinkLogicalWatermarkAssigner.CONVERTER()\n+\t\t\t\t\t\t\t\t))\n+\t\t\t\t\t\t.setRequiredOutputTraits(new Convention[] {FlinkConventions.LOGICAL()})\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t\tprogram.addLast(\n+\t\t\t\t\"PushWatermarkIntoTableSourceScanRule\",\n+\t\t\t\tFlinkHepRuleSetProgramBuilder.<StreamOptimizeContext>newBuilder()\n+\t\t\t\t\t\t.setHepRulesExecutionType(HEP_RULES_EXECUTION_TYPE.RULE_SEQUENCE())\n+\t\t\t\t\t\t.setHepMatchOrder(HepMatchOrder.BOTTOM_UP)\n+\t\t\t\t\t\t.add(RuleSets.ofList(\n+\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanRule.INSTANCE,\n+\t\t\t\t\t\t\t\tPushWatermarkIntoTableSourceScanAcrossCalcRule.INSTANCE))\n+\t\t\t\t\t\t.build()\n+\t\t);\n+\t\tutil.replaceStreamProgram(program);\n+\t}\n+\n+\t@Test\n+\tpublic void testSimpleWatermark() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR c AS c - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"select a, c from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumn() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\\n\" +\n+\t\t\t\t\t\t\"  d AS c + INTERVAL '5' SECOND,\\n\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR d AS d - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\" 'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\" 'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\" 'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\" 'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * from MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumnWithQuery() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3) NOT NULL,\\n\" +\n+\t\t\t\t\t\t\"  d AS c + INTERVAL '5' SECOND,\\n\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR d AS d - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT a, b FROM MyTable WHERE d > TO_TIMESTAMP('2020-10-09 12:12:12')\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnComputedColumnWithMultipleInputs() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a STRING,\\n\" +\n+\t\t\t\t\t\t\"  b STRING,\\n\" +\n+\t\t\t\t\t\t\"  c as TO_TIMESTAMP(a, b),\\n\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR c AS c - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * FROM MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnRow() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c ROW<name STRING, d TIMESTAMP(3)>,\" +\n+\t\t\t\t\t\t\"  e AS c.d,\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR e AS e - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * FROM MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkOnNestedRow() {\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c ROW<name STRING, d row<e STRING, f TIMESTAMP(3)>>,\" +\n+\t\t\t\t\t\t\"  g as c.d.f,\" +\n+\t\t\t\t\t\t\"  WATERMARK for g as g - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * FROM MyTable\");\n+\t}\n+\n+\t@Test\n+\tpublic void testWatermarkWithUdf() {\n+\t\tutil.addFunction(\"func1\", new InnerUdf());\n+\t\tString ddl =\n+\t\t\t\t\"CREATE TABLE MyTable(\" +\n+\t\t\t\t\t\t\"  a INT,\\n\" +\n+\t\t\t\t\t\t\"  b BIGINT,\\n\" +\n+\t\t\t\t\t\t\"  c TIMESTAMP(3),\" +\n+\t\t\t\t\t\t\"  d AS func1(c),\" +\n+\t\t\t\t\t\t\"  WATERMARK FOR d AS d - INTERVAL '5' SECOND\\n\" +\n+\t\t\t\t\t\t\") WITH (\\n\" +\n+\t\t\t\t\t\t\"  'connector' = 'values',\\n\" +\n+\t\t\t\t\t\t\"  'enable-watermark-push-down' = 'true',\\n\" +\n+\t\t\t\t\t\t\"  'bounded' = 'false',\\n\" +\n+\t\t\t\t\t\t\"  'disable-lookup' = 'true'\" +\n+\t\t\t\t\t\t\")\";\n+\t\tutil.tableEnv().executeSql(ddl);\n+\t\tutil.verifyPlan(\"SELECT * FROM MyTable\");\n+\t}\n+\n+\t/**\n+\t * Udf for test.\n+\t * */\n+\tpublic static class InnerUdf extends ScalarFunction {", "originalCommit": "15f99c140a47c9d9e41504f3f417ce5d63ecc5af", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6c252f9aeea7ec390706195833a6f5433f71b28c", "url": "https://github.com/apache/flink/commit/6c252f9aeea7ec390706195833a6f5433f71b28c", "message": "[FLINK-19282][planner] Support watermark push down in planner", "committedDate": "2020-11-06T13:24:54Z", "type": "commit"}, {"oid": "6c252f9aeea7ec390706195833a6f5433f71b28c", "url": "https://github.com/apache/flink/commit/6c252f9aeea7ec390706195833a6f5433f71b28c", "message": "[FLINK-19282][planner] Support watermark push down in planner", "committedDate": "2020-11-06T13:24:54Z", "type": "forcePushed"}]}