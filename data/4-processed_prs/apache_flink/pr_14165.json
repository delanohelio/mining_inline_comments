{"pr_number": 14165, "pr_title": "[FLINK-19687][table] Support to get execution plan from StatementSet", "pr_createdAt": "2020-11-23T08:14:31Z", "pr_url": "https://github.com/apache/flink/pull/14165", "timeline": [{"oid": "edc2b48e941b669d03b67d0960f3cca3cde91a2b", "url": "https://github.com/apache/flink/commit/edc2b48e941b669d03b67d0960f3cca3cde91a2b", "message": "[FLINK-19687][table] Support to introduce the execution plan in json format by `StatementSet#explain`", "committedDate": "2020-11-23T08:09:59Z", "type": "commit"}, {"oid": "452c291a21493b2ae4e722de1879b5a94fca9ca9", "url": "https://github.com/apache/flink/commit/452c291a21493b2ae4e722de1879b5a94fca9ca9", "message": "[FLINK-19687][table] Add line separator before streaming execution plan", "committedDate": "2020-11-23T09:03:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzNzU0Ng==", "url": "https://github.com/apache/flink/pull/14165#discussion_r530137546", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t *                     e.g. estimated cost, changelog mode for streaming, execution plan in json format\n          \n          \n            \n            \t *                     e.g. estimated cost, changelog mode for streaming, displaying execution plan in json format", "author": "wuchong", "createdAt": "2020-11-25T06:39:00Z", "path": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/api/StatementSet.java", "diffHunk": "@@ -51,7 +51,7 @@\n \t * all statements and Tables.\n \t *\n \t * @param extraDetails The extra explain details which the explain result should include,\n-\t *                     e.g. estimated cost, changelog mode for streaming\n+\t *                     e.g. estimated cost, changelog mode for streaming, execution plan in json format", "originalCommit": "452c291a21493b2ae4e722de1879b5a94fca9ca9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMTUxMQ==", "url": "https://github.com/apache/flink/pull/14165#discussion_r530731511", "bodyText": "We should also update the docs of TableEnviroment#explainSql() and Planner#explain", "author": "godfreyhe", "createdAt": "2020-11-26T02:01:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzNzU0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg0MzYyMg==", "url": "https://github.com/apache/flink/pull/14165#discussion_r530843622", "bodyText": "@godfreyhe Thanks for your reminder. I will update it.", "author": "V1ncentzzZ", "createdAt": "2020-11-26T08:18:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzNzU0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzODE1Mw==", "url": "https://github.com/apache/flink/pull/14165#discussion_r530138153", "bodyText": "I have discussed with @godfreyhe . We think that we don't need to add a new entry for the \"Streaming Execution Plan\". Because it describes the same plan with \"Physical Execution Plan\", just in different format.\nThus, we suggest to replace the content of \"Physical Execution Plan\" using the json string when ExplainDetail is in JSON_EXECUTION_PLAN.", "author": "wuchong", "createdAt": "2020-11-25T06:40:47Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/delegation/StreamPlanner.scala", "diffHunk": "@@ -129,6 +129,13 @@ class StreamPlanner(\n     sb.append(\"== Physical Execution Plan ==\")\n     sb.append(System.lineSeparator)\n     sb.append(executionPlan)\n+\n+    if (extraDetails.contains(ExplainDetail.JSON_EXECUTION_PLAN)) {\n+      sb.append(System.lineSeparator)\n+      sb.append(\"== Streaming Execution Plan ==\")\n+      sb.append(System.lineSeparator)\n+      sb.append(streamGraph.getStreamingPlanAsJSON)\n+    }", "originalCommit": "452c291a21493b2ae4e722de1879b5a94fca9ca9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDgzNzI5MQ==", "url": "https://github.com/apache/flink/pull/14165#discussion_r530837291", "bodyText": "Okay, I will update it and add some test cases.", "author": "V1ncentzzZ", "createdAt": "2020-11-26T08:06:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDEzODE1Mw=="}], "type": "inlineReview"}, {"oid": "789968fa16af46908bf7094d6b4e391eaf989035", "url": "https://github.com/apache/flink/commit/789968fa16af46908bf7094d6b4e391eaf989035", "message": "[FLINK-19687][table] Modify code comments for `StatementSet#explain`", "committedDate": "2020-11-27T06:48:30Z", "type": "commit"}, {"oid": "c3f61dd588cda6d90b75f65f96f800ecc51aa6fb", "url": "https://github.com/apache/flink/commit/c3f61dd588cda6d90b75f65f96f800ecc51aa6fb", "message": "[FLINK-19687][table] Remove entry `Streaming Execution Plan` and reuse `Physical Execution Plan`", "committedDate": "2020-11-28T04:01:09Z", "type": "commit"}, {"oid": "7c554a8e388693a7f243f211726bbb763dddcb60", "url": "https://github.com/apache/flink/commit/7c554a8e388693a7f243f211726bbb763dddcb60", "message": "[FLINK-19687][table] Add test cases for `StatementSet#explain` and ``(Stream)TableEnvironment#explainSql`", "committedDate": "2020-11-28T04:03:13Z", "type": "commit"}, {"oid": "df3a80a44692c8b13d0026673b463a451d44608d", "url": "https://github.com/apache/flink/commit/df3a80a44692c8b13d0026673b463a451d44608d", "message": "[FLINK-19687][table] Fix scala style error", "committedDate": "2020-11-28T06:19:42Z", "type": "commit"}, {"oid": "5967841ac958d8aa54754ff036045c34241676c7", "url": "https://github.com/apache/flink/commit/5967841ac958d8aa54754ff036045c34241676c7", "message": "[FLINK-19687][table] Add docs for `TableEnvironment#explainSql` and `Planner#explain`", "committedDate": "2020-11-28T09:01:50Z", "type": "commit"}, {"oid": "560977065e15581698d2eec2307cd19a319ee918", "url": "https://github.com/apache/flink/commit/560977065e15581698d2eec2307cd19a319ee918", "message": "[FLINK-19687][table] Fix exception from ci/cd", "committedDate": "2020-11-28T14:32:11Z", "type": "commit"}, {"oid": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd", "url": "https://github.com/apache/flink/commit/c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd", "message": "[FLINK-19687][table] Fix exception from ci/cd", "committedDate": "2020-11-30T02:11:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ==", "url": "https://github.com/apache/flink/pull/14165#discussion_r535873501", "bodyText": "This test case is a unit test, not an integration test, so this test case should be moved to TableEnvironmentTest\nnit: sink1Path and sink2Path are unnecessary", "author": "godfreyhe", "createdAt": "2020-12-04T06:47:54Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentITCase.scala", "diffHunk": "@@ -429,6 +429,26 @@ class TableEnvironmentITCase(tableEnvName: String, isStreaming: Boolean) extends\n     assertLastValues(sink2Path)\n   }\n \n+  @Test\n+  def testExecutionPlanFromStatementSet(): Unit = {\n+    val sink1Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"first\"), Array(STRING)), \"MySink1\")\n+\n+    val sink2Path = TestTableSourceSinks.createCsvTemporarySinkTable(\n+      tEnv, new TableSchema(Array(\"last\"), Array(STRING)), \"MySink2\")\n+\n+    val stmtSet = tEnv.createStatementSet()\n+    stmtSet.addInsert(\"MySink1\", tEnv.sqlQuery(\"select first from MyTable\"))\n+        .addInsertSql(\"insert into MySink2 select last from MyTable\")\n+\n+    val actual = stmtSet.explain(ExplainDetail.JSON_EXECUTION_PLAN)\n+    val expected =\n+      TableTestUtil.readFromResource(\"/explain/testExecutionPlanFromStatementSet.out\")\n+\n+    assertEquals(replaceStreamNodeIdAndParallelism(expected),\n+      replaceStreamNodeIdAndParallelism(actual))", "originalCommit": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0MDQzOQ==", "url": "https://github.com/apache/flink/pull/14165#discussion_r535940439", "bodyText": "You means that move this tests to TableEnvironmentTest  from TableEnvironmentITCase?", "author": "V1ncentzzZ", "createdAt": "2020-12-04T09:01:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1NDIxMA==", "url": "https://github.com/apache/flink/pull/14165#discussion_r535954210", "bodyText": "yes, sorry for the typo word \"removed\"", "author": "godfreyhe", "createdAt": "2020-12-04T09:23:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk3MTUwMg==", "url": "https://github.com/apache/flink/pull/14165#discussion_r535971502", "bodyText": "Okay", "author": "V1ncentzzZ", "createdAt": "2020-12-04T09:49:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3MzUwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ==", "url": "https://github.com/apache/flink/pull/14165#discussion_r535874435", "bodyText": "please also add some test cases for legacy planner", "author": "godfreyhe", "createdAt": "2020-12-04T06:50:30Z", "path": "flink-table/flink-table-planner-blink/src/test/scala/org/apache/flink/table/api/TableEnvironmentTest.scala", "diffHunk": "@@ -103,6 +103,26 @@ class TableEnvironmentTest {\n     assertEquals(TableTestUtil.replaceStageId(expected), TableTestUtil.replaceStageId(actual))\n   }\n \n+  @Test\n+  def testStreamTableEnvironmentExecutionExplain(): Unit = {", "originalCommit": "c5728be97ab3b29a7dc4834b9fb2bbf63a0143dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0MDQ3Ng==", "url": "https://github.com/apache/flink/pull/14165#discussion_r535940476", "bodyText": "Hi @godfreyhe , Sry, How i get legacy planner and add tests for it? Add it to org.apache.flink.table.api.TableEnvironmentTest?", "author": "V1ncentzzZ", "createdAt": "2020-12-04T09:01:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1NTk0Nw==", "url": "https://github.com/apache/flink/pull/14165#discussion_r535955947", "bodyText": "you can add tests into org.apache.flink.table.api.stream.ExplainTest and org.apache.flink.table.api.batch.ExplainTest", "author": "godfreyhe", "createdAt": "2020-12-04T09:26:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk3MTgwNA==", "url": "https://github.com/apache/flink/pull/14165#discussion_r535971804", "bodyText": "Okay", "author": "V1ncentzzZ", "createdAt": "2020-12-04T09:49:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NDQzNQ=="}], "type": "inlineReview"}, {"oid": "61cdd876e27d23952da5c66f6d201c7c7102ad3f", "url": "https://github.com/apache/flink/commit/61cdd876e27d23952da5c66f6d201c7c7102ad3f", "message": "[FLINK-19687][table] Update and add tests", "committedDate": "2020-12-04T15:05:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjUzNTg3NA==", "url": "https://github.com/apache/flink/pull/14165#discussion_r536535874", "bodyText": "A minor concern: the estimated cost maybe unstable, so it's better the value can be normalized to zero or unknown to avoid unstable test.\nbtw, the parallelism value is a key information and the value is determinate except the default parallelism is the number of cpu cores for LocalStreamEnvironment, we can explicitly set the value var setParallelism method", "author": "godfreyhe", "createdAt": "2020-12-05T07:31:59Z", "path": "flink-table/flink-table-planner/src/test/scala/resources/testStatementSetExecutionExplain1.out", "diffHunk": "@@ -0,0 +1,121 @@\n+== Abstract Syntax Tree ==\n+LogicalSink(name=[`default_catalog`.`default_database`.`targetTable`], fields=[d, e])\n+  LogicalProject(first=[$0], id=[$1])\n+    LogicalTableScan(table=[[default_catalog, default_database, sourceTable]])\n+\n+== Optimized Logical Plan ==\n+DataSetSink(name=[`default_catalog`.`default_database`.`targetTable`], fields=[d, e])\n+  BatchTableSourceScan(table=[[default_catalog, default_database, sourceTable]], fields=[first, id], source=[CsvTableSource(read fields: first, id)])\n+\n+== Physical Execution Plan ==\n+{\n+\t\"nodes\": [\n+\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"source\",\n+\t\t\"pact\": \"Data Source\",\n+\t\t\"contents\": \"CsvTableSource(read fields: first, id)\",\n+\t\t\"parallelism\":,\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }\n+\t\t],\n+\t\t\"compiler_hints\": [\n+\t\t\t{ \"name\": \"Output Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Output Cardinality\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Avg. Output Record Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Filter Factor\", \"value\": \"(none)\" }\t\t]\n+\t},\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"pact\",\n+\t\t\"pact\": \"Map\",\n+\t\t\"contents\": \"to: Row\",\n+\t\t\"parallelism\":,\n+\t\t\"predecessors\": [\n+\t\t\t{\"id\": , \"ship_strategy\": \"Forward\", \"exchange_mode\": \"PIPELINED\"}\n+\t\t],\n+\t\t\"driver_strategy\": \"Map\",\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"(unknown)\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }\n+\t\t],\n+\t\t\"compiler_hints\": [\n+\t\t\t{ \"name\": \"Output Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Output Cardinality\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Avg. Output Record Size (bytes)\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Filter Factor\", \"value\": \"(none)\" }\t\t]\n+\t},\n+\t{\n+\t\t\"id\": ,\n+\t\t\"type\": \"sink\",\n+\t\t\"pact\": \"Data Sink\",\n+\t\t\"contents\": \"UnsafeMemoryAppendTableSink(d, e)\",\n+\t\t\"parallelism\":,\n+\t\t\"predecessors\": [\n+\t\t\t{\"id\": , \"ship_strategy\": \"Forward\", \"exchange_mode\": \"PIPELINED\"}\n+\t\t],\n+\t\t\"global_properties\": [\n+\t\t\t{ \"name\": \"Partitioning\", \"value\": \"RANDOM_PARTITIONED\" },\n+\t\t\t{ \"name\": \"Partitioning Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"local_properties\": [\n+\t\t\t{ \"name\": \"Order\", \"value\": \"(none)\" },\n+\t\t\t{ \"name\": \"Grouping\", \"value\": \"not grouped\" },\n+\t\t\t{ \"name\": \"Uniqueness\", \"value\": \"not unique\" }\n+\t\t],\n+\t\t\"estimates\": [\n+\t\t\t{ \"name\": \"Est. Output Size\", \"value\": \"(unknown)\" },\n+\t\t\t{ \"name\": \"Est. Cardinality\", \"value\": \"10.00\" }\t\t],\n+\t\t\"costs\": [\n+\t\t\t{ \"name\": \"Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Disk I/O\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"CPU\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Network\", \"value\": \"0.0\" },\n+\t\t\t{ \"name\": \"Cumulative Disk I/O\", \"value\": \"190.00\" },\n+\t\t\t{ \"name\": \"Cumulative CPU\", \"value\": \"0.0\" }", "originalCommit": "61cdd876e27d23952da5c66f6d201c7c7102ad3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzIwMzAzOA==", "url": "https://github.com/apache/flink/pull/14165#discussion_r537203038", "bodyText": "Done.", "author": "V1ncentzzZ", "createdAt": "2020-12-07T03:16:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjUzNTg3NA=="}], "type": "inlineReview"}, {"oid": "9a54066e688f3de335b646b40b1888be88b41beb", "url": "https://github.com/apache/flink/commit/9a54066e688f3de335b646b40b1888be88b41beb", "message": "[FLINK-19687][table] Update tests", "committedDate": "2020-12-07T03:15:56Z", "type": "commit"}]}