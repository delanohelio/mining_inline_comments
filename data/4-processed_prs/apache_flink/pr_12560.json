{"pr_number": 12560, "pr_title": "[FLINK-18097][history-server] Cleaning job files in history server", "pr_createdAt": "2020-06-09T15:28:12Z", "pr_url": "https://github.com/apache/flink/pull/12560", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5MzU2OQ==", "url": "https://github.com/apache/flink/pull/12560#discussion_r437893569", "bodyText": "nit: can we reuse the variable defined in HistoryServerArchiveFetcher.java?", "author": "dmvk", "createdAt": "2020-06-10T06:44:17Z", "path": "flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java", "diffHunk": "@@ -78,6 +78,7 @@\n \t\t.disable(JsonGenerator.Feature.AUTO_CLOSE_JSON_CONTENT);\n \tprivate static final ObjectMapper OBJECT_MAPPER = new ObjectMapper()\n \t\t.enable(DeserializationFeature.FAIL_ON_MISSING_CREATOR_PROPERTIES);\n+\tprivate static final String JSON_FILE_ENDING = \".json\";", "originalCommit": "3e40dddf2d2559baabc544e1254b942c853dd595", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyMTcwOQ==", "url": "https://github.com/apache/flink/pull/12560#discussion_r437921709", "bodyText": "I guess that wouldn't be problem. There could be even more constants shared between HistoryServerArchiveFetcher and HistoryServerTest to make the code a bit cleaner.", "author": "Draczech", "createdAt": "2020-06-10T07:40:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5MzU2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNjA4Nw==", "url": "https://github.com/apache/flink/pull/12560#discussion_r437936087", "bodyText": "I made the JSON_FILE_ENDING package private to be used in test as well.", "author": "Draczech", "createdAt": "2020-06-10T08:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5MzU2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5NDUwMQ==", "url": "https://github.com/apache/flink/pull/12560#discussion_r437894501", "bodyText": "\ud83d\udc4d", "author": "dmvk", "createdAt": "2020-06-10T06:46:12Z", "path": "flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java", "diffHunk": "@@ -302,18 +289,37 @@ public void run() {\n \n \t\t\tcachedArchives.removeAll(jobsToRemove);\n \t\t\tjobsToRemove.forEach(removedJobID -> {\n-\t\t\t\ttry {\n-\t\t\t\t\tFiles.deleteIfExists(new File(webOverviewDir, removedJobID + JSON_FILE_ENDING).toPath());\n-\t\t\t\t\tFileUtils.deleteDirectory(new File(webJobDir, removedJobID));\n-\t\t\t\t} catch (IOException e) {\n-\t\t\t\t\tLOG.error(\"Failure while removing job overview for job {}.\", removedJobID, e);\n-\t\t\t\t}\n+\t\t\t\tdeleteJobFiles(removedJobID);\n \t\t\t\tdeleteLog.add(new ArchiveEvent(removedJobID, ArchiveEventType.DELETED));\n \t\t\t});\n \n \t\t\treturn deleteLog;\n \t\t}\n \n+\t\tprivate void deleteJobFiles(String jobID) {\n+\t\t\t// Make sure we do not include this job in the overview\n+\t\t\ttry {\n+\t\t\t\tFiles.deleteIfExists(new File(webOverviewDir, jobID + JSON_FILE_ENDING).toPath());\n+\t\t\t} catch (IOException ioe) {\n+\t\t\t\tLOG.warn(\"Could not delete file from overview directory.\", ioe);\n+\t\t\t}\n+\n+\t\t\t// Clean up job files we may have created\n+\t\t\tFile jobDirectory = new File(webJobDir, jobID);\n+\t\t\ttry {\n+\t\t\t\tFileUtils.deleteDirectory(jobDirectory);\n+\t\t\t} catch (IOException ioe) {\n+\t\t\t\tLOG.warn(\"Could not clean up job directory.\", ioe);\n+\t\t\t}\n+\n+\t\t\t// Also clean up job json file in webJobDir\n+\t\t\ttry {\n+\t\t\t\tFiles.deleteIfExists(new File(webJobDir, jobID + JSON_FILE_ENDING).toPath());\n+\t\t\t} catch (IOException ioe) {", "originalCommit": "3e40dddf2d2559baabc544e1254b942c853dd595", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA3MDQ4Mw==", "url": "https://github.com/apache/flink/pull/12560#discussion_r438070483", "bodyText": "This test is written more from a user perspective, and as such I'd prefer if we instead check that /job/<jobId>/overview does (not) return a 404, instead of diving into the nitty-gritty details of how the files are stored on disk.", "author": "zentol", "createdAt": "2020-06-10T12:06:28Z", "path": "flink-runtime-web/src/test/java/org/apache/flink/runtime/webmonitor/history/HistoryServerTest.java", "diffHunk": "@@ -217,11 +219,19 @@ private void runArchiveExpirationTest(boolean cleanupExpiredJobs) throws Excepti\n \t\t\t\t.map(JobID::toString)\n \t\t\t\t.filter(jobId -> jobId.equals(jobIdToDelete))\n \t\t\t\t.count());\n+\t\t\tassertHSFilesExistence(jobIdToDelete, !cleanupExpiredJobs);", "originalCommit": "02f47cea448880d6d2f6185c3086158875818adb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA4NjM2Nw==", "url": "https://github.com/apache/flink/pull/12560#discussion_r438086367", "bodyText": "Well, the purpose of the fix was deleting files. As there haven't been any test for that so far I added them to show that now all files are deleted properly with HS cleaning feature enabled.", "author": "Draczech", "createdAt": "2020-06-10T12:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA3MDQ4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA3MjUyNQ==", "url": "https://github.com/apache/flink/pull/12560#discussion_r438072525", "bodyText": "This changes the log level, which is a bit annoying for the cleanup if a download fails. In that case it is quite likely that we will try to delete something that was never created; for which we shouldn't be logging a warning.", "author": "zentol", "createdAt": "2020-06-10T12:10:25Z", "path": "flink-runtime-web/src/main/java/org/apache/flink/runtime/webmonitor/history/HistoryServerArchiveFetcher.java", "diffHunk": "@@ -302,18 +289,37 @@ public void run() {\n \n \t\t\tcachedArchives.removeAll(jobsToRemove);\n \t\t\tjobsToRemove.forEach(removedJobID -> {\n-\t\t\t\ttry {\n-\t\t\t\t\tFiles.deleteIfExists(new File(webOverviewDir, removedJobID + JSON_FILE_ENDING).toPath());\n-\t\t\t\t\tFileUtils.deleteDirectory(new File(webJobDir, removedJobID));\n-\t\t\t\t} catch (IOException e) {\n-\t\t\t\t\tLOG.error(\"Failure while removing job overview for job {}.\", removedJobID, e);\n-\t\t\t\t}\n+\t\t\t\tdeleteJobFiles(removedJobID);\n \t\t\t\tdeleteLog.add(new ArchiveEvent(removedJobID, ArchiveEventType.DELETED));\n \t\t\t});\n \n \t\t\treturn deleteLog;\n \t\t}\n \n+\t\tprivate void deleteJobFiles(String jobID) {\n+\t\t\t// Make sure we do not include this job in the overview\n+\t\t\ttry {\n+\t\t\t\tFiles.deleteIfExists(new File(webOverviewDir, jobID + JSON_FILE_ENDING).toPath());\n+\t\t\t} catch (IOException ioe) {\n+\t\t\t\tLOG.warn(\"Could not delete file from overview directory.\", ioe);", "originalCommit": "02f47cea448880d6d2f6185c3086158875818adb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA5MzY5NA==", "url": "https://github.com/apache/flink/pull/12560#discussion_r438093694", "bodyText": "For this reason I also changed deleting method to Files.deleteIfExists. So there should be logs only for cases when deleting of actually existing file fails. Also FileUtils.deleteDirectory doesn't do anything in case the directory doesn't exist.\nSo warning is used only if there is an actual problem with deleting existing files. Let me know if it is desired level for such cases.", "author": "Draczech", "createdAt": "2020-06-10T12:47:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA3MjUyNQ=="}], "type": "inlineReview"}, {"oid": "8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "url": "https://github.com/apache/flink/commit/8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "message": "[FLINK-18097][history] Delete all job-related files on expiration", "committedDate": "2020-07-07T19:50:12Z", "type": "commit"}, {"oid": "8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "url": "https://github.com/apache/flink/commit/8e0e2e644ac40574191fe2fc0ef0da237ba9272f", "message": "[FLINK-18097][history] Delete all job-related files on expiration", "committedDate": "2020-07-07T19:50:12Z", "type": "forcePushed"}]}