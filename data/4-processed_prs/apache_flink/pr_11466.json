{"pr_number": 11466, "pr_title": " [FLINK-15400][connectors / elasticsearch] elasticsearch table sink support dynamic index.", "pr_createdAt": "2020-03-20T15:54:38Z", "pr_url": "https://github.com/apache/flink/pull/11466", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDM4MA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396050380", "bodyText": "We can make all these fields final?", "author": "libenchao", "createdAt": "2020-03-22T03:25:49Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.text.SimpleDateFormat;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' the index field comes from any type column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a varchar/timestamp column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link SimpleDateFormat} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\tprivate static final String DEFAULT_FORMAT = \"yyyy-MM-dd\";\n+\n+\tprivate String index;", "originalCommit": "3c4ecce40a8fd1324a797351dc5bc5a0a10adaf7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1NjY5OA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396056698", "bodyText": "+1", "author": "leonardBang", "createdAt": "2020-03-22T05:38:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDM4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDYwNw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396050607", "bodyText": "IIRC, SimpleDateFormat is not a thread safe implementation.", "author": "libenchao", "createdAt": "2020-03-22T03:30:41Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.text.SimpleDateFormat;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' the index field comes from any type column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a varchar/timestamp column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link SimpleDateFormat} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\tprivate static final String DEFAULT_FORMAT = \"yyyy-MM-dd\";\n+\n+\tprivate String index;\n+\tprivate boolean dynamicIndexEnabled;\n+\tprivate boolean dynamicIndexTimeExtractEnabled;\n+\tprivate String dynamicIndexPatternStr;\n+\n+\tprivate int indexFieldPos;\n+\tprivate TypeInformation indexFieldType;\n+\tprivate SimpleDateFormat dateFormat;", "originalCommit": "3c4ecce40a8fd1324a797351dc5bc5a0a10adaf7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDYzNg==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396050636", "bodyText": "Could we also add a private constructor for Builder?", "author": "libenchao", "createdAt": "2020-03-22T03:31:25Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.text.SimpleDateFormat;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' the index field comes from any type column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a varchar/timestamp column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link SimpleDateFormat} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\tprivate static final String DEFAULT_FORMAT = \"yyyy-MM-dd\";\n+\n+\tprivate String index;\n+\tprivate boolean dynamicIndexEnabled;\n+\tprivate boolean dynamicIndexTimeExtractEnabled;\n+\tprivate String dynamicIndexPatternStr;\n+\n+\tprivate int indexFieldPos;\n+\tprivate TypeInformation indexFieldType;\n+\tprivate SimpleDateFormat dateFormat;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\tthis.indexFieldType = extractIndexFieldType(fieldTypes);\n+\t\tthis.dateFormat = extractDateFormat();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {", "originalCommit": "3c4ecce40a8fd1324a797351dc5bc5a0a10adaf7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1NjgzNw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396056837", "bodyText": "why we need private constructor here?", "author": "leonardBang", "createdAt": "2020-03-22T05:41:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDYzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1ODA0Mg==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396058042", "bodyText": "Then we could make sure that only public static Builder builder() could create the Builder, which makes the builder pattern more concise.", "author": "libenchao", "createdAt": "2020-03-22T06:03:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDYzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1OTM5OA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396059398", "bodyText": "got it", "author": "leonardBang", "createdAt": "2020-03-22T06:30:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDYzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDc5Mw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396050793", "bodyText": "Maybe we could do this check in extractIndexFieldType?", "author": "libenchao", "createdAt": "2020-03-22T03:35:31Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.text.SimpleDateFormat;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' the index field comes from any type column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a varchar/timestamp column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link SimpleDateFormat} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\tprivate static final String DEFAULT_FORMAT = \"yyyy-MM-dd\";\n+\n+\tprivate String index;\n+\tprivate boolean dynamicIndexEnabled;\n+\tprivate boolean dynamicIndexTimeExtractEnabled;\n+\tprivate String dynamicIndexPatternStr;\n+\n+\tprivate int indexFieldPos;\n+\tprivate TypeInformation indexFieldType;\n+\tprivate SimpleDateFormat dateFormat;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\tthis.indexFieldType = extractIndexFieldType(fieldTypes);\n+\t\tthis.dateFormat = extractDateFormat();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate String index;\n+\t\tprivate String[] fieldNames;\n+\t\tprivate TypeInformation<?>[] fieldTypes;\n+\n+\t\tpublic Builder index(String index) {\n+\t\t\tthis.index = index;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldNames(String[] fieldNames) {\n+\t\t\tthis.fieldNames = fieldNames;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldTypes(TypeInformation<?>[] fieldTypes) {\n+\t\t\tthis.fieldTypes = fieldTypes;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic IndexFormatter build() {\n+\t\t\treturn new IndexFormatter(index, fieldNames, fieldTypes);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a new builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tpublic boolean isDynamicIndexEnabled() {\n+\t\treturn dynamicIndexEnabled;\n+\t}\n+\n+\t/**\n+\t * Return dynamic index if dynamic index is enabled, else return the static index.\n+\t */\n+\tpublic String getFormattedIndex(Row row) {\n+\t\tif (!isDynamicIndexEnabled()) {\n+\t\t\treturn index;\n+\t\t}\n+\t\tObject indexFiled = row.getField(indexFieldPos);\n+\t\tString indexFiledValueStr = indexFiled.toString();\n+\n+\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\tif (indexFieldType == Types.LONG) {\n+\t\t\t\tindexFiledValueStr = dateFormat.format(new Date((Long) indexFiled));\n+\t\t\t} else if (indexFieldType == Types.SQL_TIMESTAMP) {\n+\t\t\t\tindexFiledValueStr = dateFormat.format((Timestamp) indexFiled);\n+\t\t\t} else if (indexFieldType == Types.SQL_DATE) {\n+\t\t\t\tindexFiledValueStr = dateFormat.format((Date) indexFiled);\n+\t\t\t} else {\n+\t\t\t\tthrow new TableException(String.format(\"Unsupported type '%s' found in Elasticsearch dynamic index column:, \" +", "originalCommit": "3c4ecce40a8fd1324a797351dc5bc5a0a10adaf7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDg5OQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396050899", "bodyText": "We already know indexFieldType, could we do this switch before runtime, like converters in json-format? Then we could avoid this if-else for each record.", "author": "libenchao", "createdAt": "2020-03-22T03:37:45Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.apache.commons.lang3.StringUtils;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.text.SimpleDateFormat;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' the index field comes from any type column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a varchar/timestamp column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link SimpleDateFormat} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\tprivate static final String DEFAULT_FORMAT = \"yyyy-MM-dd\";\n+\n+\tprivate String index;\n+\tprivate boolean dynamicIndexEnabled;\n+\tprivate boolean dynamicIndexTimeExtractEnabled;\n+\tprivate String dynamicIndexPatternStr;\n+\n+\tprivate int indexFieldPos;\n+\tprivate TypeInformation indexFieldType;\n+\tprivate SimpleDateFormat dateFormat;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\tthis.indexFieldType = extractIndexFieldType(fieldTypes);\n+\t\tthis.dateFormat = extractDateFormat();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate String index;\n+\t\tprivate String[] fieldNames;\n+\t\tprivate TypeInformation<?>[] fieldTypes;\n+\n+\t\tpublic Builder index(String index) {\n+\t\t\tthis.index = index;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldNames(String[] fieldNames) {\n+\t\t\tthis.fieldNames = fieldNames;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldTypes(TypeInformation<?>[] fieldTypes) {\n+\t\t\tthis.fieldTypes = fieldTypes;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic IndexFormatter build() {\n+\t\t\treturn new IndexFormatter(index, fieldNames, fieldTypes);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a new builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tpublic boolean isDynamicIndexEnabled() {\n+\t\treturn dynamicIndexEnabled;\n+\t}\n+\n+\t/**\n+\t * Return dynamic index if dynamic index is enabled, else return the static index.\n+\t */\n+\tpublic String getFormattedIndex(Row row) {\n+\t\tif (!isDynamicIndexEnabled()) {\n+\t\t\treturn index;\n+\t\t}\n+\t\tObject indexFiled = row.getField(indexFieldPos);\n+\t\tString indexFiledValueStr = indexFiled.toString();\n+\n+\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\tif (indexFieldType == Types.LONG) {", "originalCommit": "3c4ecce40a8fd1324a797351dc5bc5a0a10adaf7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1NzI1Nw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r396057257", "bodyText": "nice tips", "author": "leonardBang", "createdAt": "2020-03-22T05:50:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjA1MDg5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTAyMDg2MQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399020861", "bodyText": "Please add serialVersionUID .", "author": "wuchong", "createdAt": "2020-03-27T03:52:00Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' is the index field comes from any DataType column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a BIGINT/SQL_TIMESTAMP/SQL_DATE column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link DateTimeFormatter} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE2MjI3MA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399162270", "bodyText": "ok", "author": "leonardBang", "createdAt": "2020-03-27T10:17:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTAyMDg2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTAyODUyNA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399028524", "bodyText": "Suggestion:\n\nrequired: Elasticsearch index. Flink supports both static index and dynamic index.\nIf you want to have a static index, this option value should be a plain string, e.g. 'myusers', all the records will be consistently written into \"myusers\" index.\nIf you want to have a dynamic index, you can use '{field_name}' to reference a field value in the record to dynamically generate a target index. You can also use '{field_name|date_format_string}' to convert a field value of TIMESTAMP/DATE type into the format specified by date_format_string. The date_format_string is compatible with Java's SimpleDateFormat. For example, if the option value is 'myusers-{log_ts|yyyy-MM-dd}', then a record with log_ts field value 2020-03-27 12:25:55 will be written into \"myusers-2020-03-27\" index.", "author": "wuchong", "createdAt": "2020-03-27T04:26:51Z", "path": "docs/dev/table/connect.md", "diffHunk": "@@ -936,7 +936,13 @@ CREATE TABLE MyUserTable (\n   \n   'connector.hosts' = 'http://host_name:9092;http://host_name:9093',  -- required: one or more Elasticsearch hosts to connect to\n \n-  'connector.index' = 'MyUsers',       -- required: Elasticsearch index\n+  'connector.index' = 'myusers',       -- required: Elasticsearch index, Flink support create index based on field\n+                                       -- at runtime dynamically, the index value comes from the dynamic index \n+                                       -- pattern like 'myusers-{log_source}', 'log_source' is a column name of table,\n+                                       -- the dynamicIndex pattern also support format time by Java DateFormatter \n+                                       -- when the column DataType is BIGINT/SQL_TIMESTAMP/SQL_DATE, eg:\n+                                       -- 'myusers-{log_ts|yyyy-MM-dd}', 'log_ts' is a BIGINT/SQL_TIMESTAMP/SQL_DATE column.", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0MTI1Mg==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399041252", "bodyText": "Do we see a big requirement on BIGINT? We should be cautious to convert bigint into timestamp, because it requires a time zone.", "author": "wuchong", "createdAt": "2020-03-27T05:21:04Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' is the index field comes from any DataType column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a BIGINT/SQL_TIMESTAMP/SQL_DATE column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link DateTimeFormatter} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\n+\tprivate final String index;\n+\tprivate final String[] fieldNames;\n+\tprivate final TypeInformation<?>[] fieldTypes;\n+\tprivate final boolean dynamicIndexEnabled;\n+\tprivate final boolean dynamicIndexTimeExtractEnabled;\n+\tprivate final IndexRuntimeConverter indexRuntimeConverter;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.fieldNames = fieldNames;\n+\t\tthis.fieldTypes = fieldTypes;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexRuntimeConverter = createIndexRuntimeConverter();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate String index;\n+\t\tprivate String[] fieldNames;\n+\t\tprivate TypeInformation<?>[] fieldTypes;\n+\n+\t\tprivate Builder() {\n+\t\t\t// private constructor\n+\t\t}\n+\n+\t\tpublic Builder index(String index) {\n+\t\t\tthis.index = index;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldNames(String[] fieldNames) {\n+\t\t\tthis.fieldNames = fieldNames;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldTypes(TypeInformation<?>[] fieldTypes) {\n+\t\t\tthis.fieldTypes = fieldTypes;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic IndexFormatter build() {\n+\t\t\treturn new IndexFormatter(index, fieldNames, fieldTypes);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a new builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tpublic boolean isDynamicIndexEnabled() {\n+\t\treturn dynamicIndexEnabled;\n+\t}\n+\n+\t/**\n+\t * Return dynamic index if dynamic index is enabled, else return the static index.\n+\t */\n+\tpublic String getFormattedIndex(Row row) {\n+\t\treturn indexRuntimeConverter.convert(row);\n+\t}\n+\n+\t/**\n+\t * Check general dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexEnabled() {\n+\t\treturn dynamicIndexPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Check time extract dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexTimeExtractEnabled() {\n+\t\treturn dynamicIndexTimeExtractPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Extract dynamic index pattern string from index pattern string.\n+\t */\n+\tprivate String extractDynamicIndexPatternStr() {\n+\t\tString dynamicIndexPatternStr = null;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tint start = index.indexOf(\"{\");\n+\t\t\tint end = index.lastIndexOf(\"}\");\n+\t\t\tdynamicIndexPatternStr = index.substring(start, end + 1);\n+\t\t}\n+\t\treturn dynamicIndexPatternStr;\n+\t}\n+\n+\t/**\n+\t * Extract index field position in a fieldNames, return the field position.\n+\t */\n+\tprivate int extractIndexFieldPos(String[] fieldNames) {\n+\t\tint pos = 0;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tList<String> fieldList = Arrays.asList(fieldNames);\n+\t\t\tString indexFieldName;\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"|\"));\n+\t\t\t} else {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"}\"));\n+\t\t\t}\n+\t\t\tif (!fieldList.contains(indexFieldName)) {\n+\t\t\t\tthrow new TableException(String.format(\"Unknown column '%s' in index pattern '%s', please check the column name.\",\n+\t\t\t\t\tindexFieldName, index));\n+\t\t\t}\n+\t\t\tpos = fieldList.indexOf(indexFieldName);\n+\t\t}\n+\t\treturn pos;\n+\t}\n+\n+\t/**\n+\t * Extract {@link DateTimeFormatter} by the date format that extracted from index pattern string.\n+\t */\n+\tprivate DateTimeFormatter extractDateFormat() {\n+\t\tString pattern = index.substring(index.indexOf(\"|\") + 1, index.indexOf(\"}\"));\n+\t\treturn DateTimeFormatter.ofPattern(pattern);\n+\t}\n+\n+\t/**\n+\t * Runtime converter that converts the index field to string.\n+\t */\n+\t@FunctionalInterface\n+\tprivate interface IndexRuntimeConverter extends Serializable{\n+\t\tString convert(Row row);\n+\t}\n+\n+\tprivate IndexRuntimeConverter createIndexRuntimeConverter() {\n+\t\tfinal String dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tfinal int indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\t\t// time extract dynamic index pattern\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tfinal TypeInformation<?>indexFieldType = fieldTypes[indexFieldPos];\n+\t\t\t\t// DataTypes.LONG\n+\t\t\t\tif (indexFieldType == Types.LONG) {", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0MTgyMw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399041823", "bodyText": "Add a test for my-index-{local_date|yyyy/MM/dd HH:mm} ?  Does that work?", "author": "wuchong", "createdAt": "2020-03-27T05:23:36Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatterTest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Suite tests for {@link IndexFormatter}.\n+ */\n+public class IndexFormatterTest {\n+\tprivate String[] fieldNames;\n+\tprivate TypeInformation[] fieldTypes;\n+\tprivate List<Row> rows;\n+\n+\t@Before\n+\tpublic void prepareData() {\n+\t\tfieldNames = new String[]{\"id\", \"item\", \"log_ts\", \"log_date\", \"order_timestamp\", \"local_datetime\", \"local_date\", \"note\"};\n+\t\tfieldTypes = new TypeInformation[] {\n+\t\t\tTypes.INT,\n+\t\t\tTypes.STRING,\n+\t\t\tTypes.LONG,\n+\t\t\tTypes.SQL_DATE,\n+\t\t\tTypes.SQL_TIMESTAMP,\n+\t\t\tTypes.LOCAL_DATE_TIME,\n+\t\t\tTypes.LOCAL_DATE,\n+\t\t\tTypes.STRING\n+\t\t};\n+\t\trows = new ArrayList<>();\n+\t\trows.add(Row.of(\n+\t\t\t1,\n+\t\t\t\"apple\",\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-18\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\"),\n+\t\t\tLocalDateTime.of(2020, 3, 18, 12, 12, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 18),\n+\t\t\t\"test1\"));\n+\t\trows.add(Row.of(\n+\t\t\t2,\n+\t\t\t\"peanut\",\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-19\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:21\"),\n+\t\t\tLocalDateTime.of(2020, 3, 19, 12, 22, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 19),\n+\t\t\t\"test2\"));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexEnabled() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_ts|yyyy-MM-dd HH:MM:ss}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertTrue(indexFormatter.isDynamicIndexEnabled());\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"my-index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertFalse(indexFormatter1.isDynamicIndexEnabled());\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTimestamp() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"{order_timestamp|yyyy_MM_dd_HH-ss}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"{order_timestamp|yyyy_MM_dd_HH_mm}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexFormatter1.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDateTime() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"{local_datetime|yyyy_MM_dd_HH-ss}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"{local_datetime|yyyy_MM_dd_HH_mm}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexFormatter1.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLong() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_ts|yyyy-MM-dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"my-index-2020-03-18\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020-03-19\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromDate() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_date|yyyy/MM/dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDate() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{local_date|yyyy/MM/dd}\")", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0MjAwMA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399042000", "bodyText": "Add a test for Time ?", "author": "wuchong", "createdAt": "2020-03-27T05:24:21Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatterTest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Suite tests for {@link IndexFormatter}.\n+ */\n+public class IndexFormatterTest {\n+\tprivate String[] fieldNames;\n+\tprivate TypeInformation[] fieldTypes;\n+\tprivate List<Row> rows;\n+\n+\t@Before\n+\tpublic void prepareData() {\n+\t\tfieldNames = new String[]{\"id\", \"item\", \"log_ts\", \"log_date\", \"order_timestamp\", \"local_datetime\", \"local_date\", \"note\"};\n+\t\tfieldTypes = new TypeInformation[] {\n+\t\t\tTypes.INT,\n+\t\t\tTypes.STRING,\n+\t\t\tTypes.LONG,\n+\t\t\tTypes.SQL_DATE,\n+\t\t\tTypes.SQL_TIMESTAMP,", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0NTAyNg==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399045026", "bodyText": "This sounds like a switch, but not. Maybe isStaticIndex,  isDynamicIndex, isDynamicIndexWithFormat are better.", "author": "wuchong", "createdAt": "2020-03-27T05:37:15Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' is the index field comes from any DataType column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a BIGINT/SQL_TIMESTAMP/SQL_DATE column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link DateTimeFormatter} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\n+\tprivate final String index;\n+\tprivate final String[] fieldNames;\n+\tprivate final TypeInformation<?>[] fieldTypes;\n+\tprivate final boolean dynamicIndexEnabled;\n+\tprivate final boolean dynamicIndexTimeExtractEnabled;\n+\tprivate final IndexRuntimeConverter indexRuntimeConverter;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.fieldNames = fieldNames;\n+\t\tthis.fieldTypes = fieldTypes;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4Mzc4NA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399083784", "bodyText": "Please also check the exception message.", "author": "wuchong", "createdAt": "2020-03-27T07:45:13Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatterTest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Suite tests for {@link IndexFormatter}.\n+ */\n+public class IndexFormatterTest {\n+\tprivate String[] fieldNames;\n+\tprivate TypeInformation[] fieldTypes;\n+\tprivate List<Row> rows;\n+\n+\t@Before\n+\tpublic void prepareData() {\n+\t\tfieldNames = new String[]{\"id\", \"item\", \"log_ts\", \"log_date\", \"order_timestamp\", \"local_datetime\", \"local_date\", \"note\"};\n+\t\tfieldTypes = new TypeInformation[] {\n+\t\t\tTypes.INT,\n+\t\t\tTypes.STRING,\n+\t\t\tTypes.LONG,\n+\t\t\tTypes.SQL_DATE,\n+\t\t\tTypes.SQL_TIMESTAMP,\n+\t\t\tTypes.LOCAL_DATE_TIME,\n+\t\t\tTypes.LOCAL_DATE,\n+\t\t\tTypes.STRING\n+\t\t};\n+\t\trows = new ArrayList<>();\n+\t\trows.add(Row.of(\n+\t\t\t1,\n+\t\t\t\"apple\",\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-18\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\"),\n+\t\t\tLocalDateTime.of(2020, 3, 18, 12, 12, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 18),\n+\t\t\t\"test1\"));\n+\t\trows.add(Row.of(\n+\t\t\t2,\n+\t\t\t\"peanut\",\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-19\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:21\"),\n+\t\t\tLocalDateTime.of(2020, 3, 19, 12, 22, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 19),\n+\t\t\t\"test2\"));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexEnabled() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_ts|yyyy-MM-dd HH:MM:ss}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertTrue(indexFormatter.isDynamicIndexEnabled());\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"my-index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertFalse(indexFormatter1.isDynamicIndexEnabled());\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTimestamp() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"{order_timestamp|yyyy_MM_dd_HH-ss}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"{order_timestamp|yyyy_MM_dd_HH_mm}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexFormatter1.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDateTime() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"{local_datetime|yyyy_MM_dd_HH-ss}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"{local_datetime|yyyy_MM_dd_HH_mm}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexFormatter1.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLong() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_ts|yyyy-MM-dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"my-index-2020-03-18\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020-03-19\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromDate() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_date|yyyy/MM/dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDate() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{local_date|yyyy/MM/dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testGeneralDynamicIndex() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"index_{item}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"index_apple\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"index_peanut\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testStaticIndex() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertFalse(indexFormatter.isDynamicIndexEnabled());\n+\t\tAssert.assertEquals(\"my-index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test(expected = TableException.class)", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4MzgwOQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399083809", "bodyText": "Please also check the exception message.", "author": "wuchong", "createdAt": "2020-03-27T07:45:16Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatterTest.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Suite tests for {@link IndexFormatter}.\n+ */\n+public class IndexFormatterTest {\n+\tprivate String[] fieldNames;\n+\tprivate TypeInformation[] fieldTypes;\n+\tprivate List<Row> rows;\n+\n+\t@Before\n+\tpublic void prepareData() {\n+\t\tfieldNames = new String[]{\"id\", \"item\", \"log_ts\", \"log_date\", \"order_timestamp\", \"local_datetime\", \"local_date\", \"note\"};\n+\t\tfieldTypes = new TypeInformation[] {\n+\t\t\tTypes.INT,\n+\t\t\tTypes.STRING,\n+\t\t\tTypes.LONG,\n+\t\t\tTypes.SQL_DATE,\n+\t\t\tTypes.SQL_TIMESTAMP,\n+\t\t\tTypes.LOCAL_DATE_TIME,\n+\t\t\tTypes.LOCAL_DATE,\n+\t\t\tTypes.STRING\n+\t\t};\n+\t\trows = new ArrayList<>();\n+\t\trows.add(Row.of(\n+\t\t\t1,\n+\t\t\t\"apple\",\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-18\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\"),\n+\t\t\tLocalDateTime.of(2020, 3, 18, 12, 12, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 18),\n+\t\t\t\"test1\"));\n+\t\trows.add(Row.of(\n+\t\t\t2,\n+\t\t\t\"peanut\",\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-19\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:21\"),\n+\t\t\tLocalDateTime.of(2020, 3, 19, 12, 22, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 19),\n+\t\t\t\"test2\"));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexEnabled() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_ts|yyyy-MM-dd HH:MM:ss}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertTrue(indexFormatter.isDynamicIndexEnabled());\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"my-index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertFalse(indexFormatter1.isDynamicIndexEnabled());\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTimestamp() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"{order_timestamp|yyyy_MM_dd_HH-ss}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"{order_timestamp|yyyy_MM_dd_HH_mm}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexFormatter1.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDateTime() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"{local_datetime|yyyy_MM_dd_HH-ss}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tIndexFormatter indexFormatter1 = IndexFormatter.builder()\n+\t\t\t.index(\"{local_datetime|yyyy_MM_dd_HH_mm}_index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexFormatter1.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLong() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_ts|yyyy-MM-dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"my-index-2020-03-18\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020-03-19\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromDate() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{log_date|yyyy/MM/dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDate() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{local_date|yyyy/MM/dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testGeneralDynamicIndex() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"index_{item}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertEquals(\"index_apple\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"index_peanut\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testStaticIndex() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertFalse(indexFormatter.isDynamicIndexEnabled());\n+\t\tAssert.assertEquals(\"my-index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index\", indexFormatter.getFormattedIndex(rows.get(1)));\n+\t}\n+\n+\t@Test(expected = TableException.class)\n+\tpublic void testUnknownField() {\n+\t\tIndexFormatter indexFormatter = IndexFormatter.builder()\n+\t\t\t.index(\"my-index-{unknown_ts|yyyy-MM-dd}\")\n+\t\t\t.fieldNames(fieldNames)\n+\t\t\t.fieldTypes(fieldTypes)\n+\t\t\t.build();\n+\t\tAssert.assertTrue(indexFormatter.isDynamicIndexEnabled());\n+\t\tAssert.assertEquals(\"my-index\", indexFormatter.getFormattedIndex(rows.get(0)));\n+\t}\n+\n+\t@Test(expected = TableException.class)", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NTAwNQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399085005", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\tfinal TypeInformation<?>indexFieldType = fieldTypes[indexFieldPos];\n          \n          \n            \n            \t\t\t\tfinal TypeInformation<?> indexFieldType = fieldTypes[indexFieldPos];", "author": "wuchong", "createdAt": "2020-03-27T07:48:23Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' is the index field comes from any DataType column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a BIGINT/SQL_TIMESTAMP/SQL_DATE column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link DateTimeFormatter} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\n+\tprivate final String index;\n+\tprivate final String[] fieldNames;\n+\tprivate final TypeInformation<?>[] fieldTypes;\n+\tprivate final boolean dynamicIndexEnabled;\n+\tprivate final boolean dynamicIndexTimeExtractEnabled;\n+\tprivate final IndexRuntimeConverter indexRuntimeConverter;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.fieldNames = fieldNames;\n+\t\tthis.fieldTypes = fieldTypes;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexRuntimeConverter = createIndexRuntimeConverter();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate String index;\n+\t\tprivate String[] fieldNames;\n+\t\tprivate TypeInformation<?>[] fieldTypes;\n+\n+\t\tprivate Builder() {\n+\t\t\t// private constructor\n+\t\t}\n+\n+\t\tpublic Builder index(String index) {\n+\t\t\tthis.index = index;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldNames(String[] fieldNames) {\n+\t\t\tthis.fieldNames = fieldNames;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldTypes(TypeInformation<?>[] fieldTypes) {\n+\t\t\tthis.fieldTypes = fieldTypes;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic IndexFormatter build() {\n+\t\t\treturn new IndexFormatter(index, fieldNames, fieldTypes);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a new builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tpublic boolean isDynamicIndexEnabled() {\n+\t\treturn dynamicIndexEnabled;\n+\t}\n+\n+\t/**\n+\t * Return dynamic index if dynamic index is enabled, else return the static index.\n+\t */\n+\tpublic String getFormattedIndex(Row row) {\n+\t\treturn indexRuntimeConverter.convert(row);\n+\t}\n+\n+\t/**\n+\t * Check general dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexEnabled() {\n+\t\treturn dynamicIndexPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Check time extract dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexTimeExtractEnabled() {\n+\t\treturn dynamicIndexTimeExtractPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Extract dynamic index pattern string from index pattern string.\n+\t */\n+\tprivate String extractDynamicIndexPatternStr() {\n+\t\tString dynamicIndexPatternStr = null;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tint start = index.indexOf(\"{\");\n+\t\t\tint end = index.lastIndexOf(\"}\");\n+\t\t\tdynamicIndexPatternStr = index.substring(start, end + 1);\n+\t\t}\n+\t\treturn dynamicIndexPatternStr;\n+\t}\n+\n+\t/**\n+\t * Extract index field position in a fieldNames, return the field position.\n+\t */\n+\tprivate int extractIndexFieldPos(String[] fieldNames) {\n+\t\tint pos = 0;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tList<String> fieldList = Arrays.asList(fieldNames);\n+\t\t\tString indexFieldName;\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"|\"));\n+\t\t\t} else {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"}\"));\n+\t\t\t}\n+\t\t\tif (!fieldList.contains(indexFieldName)) {\n+\t\t\t\tthrow new TableException(String.format(\"Unknown column '%s' in index pattern '%s', please check the column name.\",\n+\t\t\t\t\tindexFieldName, index));\n+\t\t\t}\n+\t\t\tpos = fieldList.indexOf(indexFieldName);\n+\t\t}\n+\t\treturn pos;\n+\t}\n+\n+\t/**\n+\t * Extract {@link DateTimeFormatter} by the date format that extracted from index pattern string.\n+\t */\n+\tprivate DateTimeFormatter extractDateFormat() {\n+\t\tString pattern = index.substring(index.indexOf(\"|\") + 1, index.indexOf(\"}\"));\n+\t\treturn DateTimeFormatter.ofPattern(pattern);\n+\t}\n+\n+\t/**\n+\t * Runtime converter that converts the index field to string.\n+\t */\n+\t@FunctionalInterface\n+\tprivate interface IndexRuntimeConverter extends Serializable{\n+\t\tString convert(Row row);\n+\t}\n+\n+\tprivate IndexRuntimeConverter createIndexRuntimeConverter() {\n+\t\tfinal String dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tfinal int indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\t\t// time extract dynamic index pattern\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tfinal TypeInformation<?>indexFieldType = fieldTypes[indexFieldPos];", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NTQ5MQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399085491", "bodyText": "You don't need to extract the date format for every record.", "author": "wuchong", "createdAt": "2020-03-27T07:49:29Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' is the index field comes from any DataType column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a BIGINT/SQL_TIMESTAMP/SQL_DATE column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link DateTimeFormatter} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\n+\tprivate final String index;\n+\tprivate final String[] fieldNames;\n+\tprivate final TypeInformation<?>[] fieldTypes;\n+\tprivate final boolean dynamicIndexEnabled;\n+\tprivate final boolean dynamicIndexTimeExtractEnabled;\n+\tprivate final IndexRuntimeConverter indexRuntimeConverter;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.fieldNames = fieldNames;\n+\t\tthis.fieldTypes = fieldTypes;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexRuntimeConverter = createIndexRuntimeConverter();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate String index;\n+\t\tprivate String[] fieldNames;\n+\t\tprivate TypeInformation<?>[] fieldTypes;\n+\n+\t\tprivate Builder() {\n+\t\t\t// private constructor\n+\t\t}\n+\n+\t\tpublic Builder index(String index) {\n+\t\t\tthis.index = index;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldNames(String[] fieldNames) {\n+\t\t\tthis.fieldNames = fieldNames;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldTypes(TypeInformation<?>[] fieldTypes) {\n+\t\t\tthis.fieldTypes = fieldTypes;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic IndexFormatter build() {\n+\t\t\treturn new IndexFormatter(index, fieldNames, fieldTypes);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a new builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tpublic boolean isDynamicIndexEnabled() {\n+\t\treturn dynamicIndexEnabled;\n+\t}\n+\n+\t/**\n+\t * Return dynamic index if dynamic index is enabled, else return the static index.\n+\t */\n+\tpublic String getFormattedIndex(Row row) {\n+\t\treturn indexRuntimeConverter.convert(row);\n+\t}\n+\n+\t/**\n+\t * Check general dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexEnabled() {\n+\t\treturn dynamicIndexPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Check time extract dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexTimeExtractEnabled() {\n+\t\treturn dynamicIndexTimeExtractPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Extract dynamic index pattern string from index pattern string.\n+\t */\n+\tprivate String extractDynamicIndexPatternStr() {\n+\t\tString dynamicIndexPatternStr = null;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tint start = index.indexOf(\"{\");\n+\t\t\tint end = index.lastIndexOf(\"}\");\n+\t\t\tdynamicIndexPatternStr = index.substring(start, end + 1);\n+\t\t}\n+\t\treturn dynamicIndexPatternStr;\n+\t}\n+\n+\t/**\n+\t * Extract index field position in a fieldNames, return the field position.\n+\t */\n+\tprivate int extractIndexFieldPos(String[] fieldNames) {\n+\t\tint pos = 0;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tList<String> fieldList = Arrays.asList(fieldNames);\n+\t\t\tString indexFieldName;\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"|\"));\n+\t\t\t} else {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"}\"));\n+\t\t\t}\n+\t\t\tif (!fieldList.contains(indexFieldName)) {\n+\t\t\t\tthrow new TableException(String.format(\"Unknown column '%s' in index pattern '%s', please check the column name.\",\n+\t\t\t\t\tindexFieldName, index));\n+\t\t\t}\n+\t\t\tpos = fieldList.indexOf(indexFieldName);\n+\t\t}\n+\t\treturn pos;\n+\t}\n+\n+\t/**\n+\t * Extract {@link DateTimeFormatter} by the date format that extracted from index pattern string.\n+\t */\n+\tprivate DateTimeFormatter extractDateFormat() {\n+\t\tString pattern = index.substring(index.indexOf(\"|\") + 1, index.indexOf(\"}\"));\n+\t\treturn DateTimeFormatter.ofPattern(pattern);\n+\t}\n+\n+\t/**\n+\t * Runtime converter that converts the index field to string.\n+\t */\n+\t@FunctionalInterface\n+\tprivate interface IndexRuntimeConverter extends Serializable{\n+\t\tString convert(Row row);\n+\t}\n+\n+\tprivate IndexRuntimeConverter createIndexRuntimeConverter() {\n+\t\tfinal String dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tfinal int indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\t\t// time extract dynamic index pattern\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tfinal TypeInformation<?>indexFieldType = fieldTypes[indexFieldPos];\n+\t\t\t\t// DataTypes.LONG\n+\t\t\t\tif (indexFieldType == Types.LONG) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tLong indexFiled = (Long) row.getField(indexFieldPos);\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = LocalDateTime.ofInstant(\n+\t\t\t\t\t\t\tInstant.ofEpochMilli(indexFiled), ZoneId.systemDefault()).format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);\n+\t\t\t\t\t};\n+\t\t\t\t}\n+\t\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\t\telse if (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tString indexFiled = row.getField(indexFieldPos).toString();\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NTk1MA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399085950", "bodyText": "Why converting to string and parse back again?", "author": "wuchong", "createdAt": "2020-03-27T07:50:35Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' is the index field comes from any DataType column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a BIGINT/SQL_TIMESTAMP/SQL_DATE column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link DateTimeFormatter} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\n+\tprivate final String index;\n+\tprivate final String[] fieldNames;\n+\tprivate final TypeInformation<?>[] fieldTypes;\n+\tprivate final boolean dynamicIndexEnabled;\n+\tprivate final boolean dynamicIndexTimeExtractEnabled;\n+\tprivate final IndexRuntimeConverter indexRuntimeConverter;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.fieldNames = fieldNames;\n+\t\tthis.fieldTypes = fieldTypes;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexRuntimeConverter = createIndexRuntimeConverter();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate String index;\n+\t\tprivate String[] fieldNames;\n+\t\tprivate TypeInformation<?>[] fieldTypes;\n+\n+\t\tprivate Builder() {\n+\t\t\t// private constructor\n+\t\t}\n+\n+\t\tpublic Builder index(String index) {\n+\t\t\tthis.index = index;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldNames(String[] fieldNames) {\n+\t\t\tthis.fieldNames = fieldNames;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldTypes(TypeInformation<?>[] fieldTypes) {\n+\t\t\tthis.fieldTypes = fieldTypes;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic IndexFormatter build() {\n+\t\t\treturn new IndexFormatter(index, fieldNames, fieldTypes);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a new builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tpublic boolean isDynamicIndexEnabled() {\n+\t\treturn dynamicIndexEnabled;\n+\t}\n+\n+\t/**\n+\t * Return dynamic index if dynamic index is enabled, else return the static index.\n+\t */\n+\tpublic String getFormattedIndex(Row row) {\n+\t\treturn indexRuntimeConverter.convert(row);\n+\t}\n+\n+\t/**\n+\t * Check general dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexEnabled() {\n+\t\treturn dynamicIndexPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Check time extract dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexTimeExtractEnabled() {\n+\t\treturn dynamicIndexTimeExtractPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Extract dynamic index pattern string from index pattern string.\n+\t */\n+\tprivate String extractDynamicIndexPatternStr() {\n+\t\tString dynamicIndexPatternStr = null;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tint start = index.indexOf(\"{\");\n+\t\t\tint end = index.lastIndexOf(\"}\");\n+\t\t\tdynamicIndexPatternStr = index.substring(start, end + 1);\n+\t\t}\n+\t\treturn dynamicIndexPatternStr;\n+\t}\n+\n+\t/**\n+\t * Extract index field position in a fieldNames, return the field position.\n+\t */\n+\tprivate int extractIndexFieldPos(String[] fieldNames) {\n+\t\tint pos = 0;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tList<String> fieldList = Arrays.asList(fieldNames);\n+\t\t\tString indexFieldName;\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"|\"));\n+\t\t\t} else {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"}\"));\n+\t\t\t}\n+\t\t\tif (!fieldList.contains(indexFieldName)) {\n+\t\t\t\tthrow new TableException(String.format(\"Unknown column '%s' in index pattern '%s', please check the column name.\",\n+\t\t\t\t\tindexFieldName, index));\n+\t\t\t}\n+\t\t\tpos = fieldList.indexOf(indexFieldName);\n+\t\t}\n+\t\treturn pos;\n+\t}\n+\n+\t/**\n+\t * Extract {@link DateTimeFormatter} by the date format that extracted from index pattern string.\n+\t */\n+\tprivate DateTimeFormatter extractDateFormat() {\n+\t\tString pattern = index.substring(index.indexOf(\"|\") + 1, index.indexOf(\"}\"));\n+\t\treturn DateTimeFormatter.ofPattern(pattern);\n+\t}\n+\n+\t/**\n+\t * Runtime converter that converts the index field to string.\n+\t */\n+\t@FunctionalInterface\n+\tprivate interface IndexRuntimeConverter extends Serializable{\n+\t\tString convert(Row row);\n+\t}\n+\n+\tprivate IndexRuntimeConverter createIndexRuntimeConverter() {\n+\t\tfinal String dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tfinal int indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\t\t// time extract dynamic index pattern\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tfinal TypeInformation<?>indexFieldType = fieldTypes[indexFieldPos];\n+\t\t\t\t// DataTypes.LONG\n+\t\t\t\tif (indexFieldType == Types.LONG) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tLong indexFiled = (Long) row.getField(indexFieldPos);\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = LocalDateTime.ofInstant(\n+\t\t\t\t\t\t\tInstant.ofEpochMilli(indexFiled), ZoneId.systemDefault()).format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);\n+\t\t\t\t\t};\n+\t\t\t\t}\n+\t\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\t\telse if (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tString indexFiled = row.getField(indexFieldPos).toString();\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = LocalDateTime.parse(indexFiled).format(dateFormat);", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM0Njc5OQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399346799", "bodyText": "I mean, you don't need to row.getField(indexFieldPos).toString() and LocalDateTime.parse(indexFiled). You can just cast to LocalDateTime (LocalDateTime) row.getField(indexFieldPos).", "author": "wuchong", "createdAt": "2020-03-27T15:26:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NTk1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NjcwMg==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399086702", "bodyText": "Do not use String.replace. It will go through regrex logic which is performance poor. You can simpliy concat the strings.", "author": "wuchong", "createdAt": "2020-03-27T07:52:24Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' is the index field comes from any DataType column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a BIGINT/SQL_TIMESTAMP/SQL_DATE column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link DateTimeFormatter} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\n+\tprivate final String index;\n+\tprivate final String[] fieldNames;\n+\tprivate final TypeInformation<?>[] fieldTypes;\n+\tprivate final boolean dynamicIndexEnabled;\n+\tprivate final boolean dynamicIndexTimeExtractEnabled;\n+\tprivate final IndexRuntimeConverter indexRuntimeConverter;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.fieldNames = fieldNames;\n+\t\tthis.fieldTypes = fieldTypes;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexRuntimeConverter = createIndexRuntimeConverter();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate String index;\n+\t\tprivate String[] fieldNames;\n+\t\tprivate TypeInformation<?>[] fieldTypes;\n+\n+\t\tprivate Builder() {\n+\t\t\t// private constructor\n+\t\t}\n+\n+\t\tpublic Builder index(String index) {\n+\t\t\tthis.index = index;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldNames(String[] fieldNames) {\n+\t\t\tthis.fieldNames = fieldNames;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldTypes(TypeInformation<?>[] fieldTypes) {\n+\t\t\tthis.fieldTypes = fieldTypes;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic IndexFormatter build() {\n+\t\t\treturn new IndexFormatter(index, fieldNames, fieldTypes);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a new builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tpublic boolean isDynamicIndexEnabled() {\n+\t\treturn dynamicIndexEnabled;\n+\t}\n+\n+\t/**\n+\t * Return dynamic index if dynamic index is enabled, else return the static index.\n+\t */\n+\tpublic String getFormattedIndex(Row row) {\n+\t\treturn indexRuntimeConverter.convert(row);\n+\t}\n+\n+\t/**\n+\t * Check general dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexEnabled() {\n+\t\treturn dynamicIndexPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Check time extract dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexTimeExtractEnabled() {\n+\t\treturn dynamicIndexTimeExtractPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Extract dynamic index pattern string from index pattern string.\n+\t */\n+\tprivate String extractDynamicIndexPatternStr() {\n+\t\tString dynamicIndexPatternStr = null;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tint start = index.indexOf(\"{\");\n+\t\t\tint end = index.lastIndexOf(\"}\");\n+\t\t\tdynamicIndexPatternStr = index.substring(start, end + 1);\n+\t\t}\n+\t\treturn dynamicIndexPatternStr;\n+\t}\n+\n+\t/**\n+\t * Extract index field position in a fieldNames, return the field position.\n+\t */\n+\tprivate int extractIndexFieldPos(String[] fieldNames) {\n+\t\tint pos = 0;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tList<String> fieldList = Arrays.asList(fieldNames);\n+\t\t\tString indexFieldName;\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"|\"));\n+\t\t\t} else {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"}\"));\n+\t\t\t}\n+\t\t\tif (!fieldList.contains(indexFieldName)) {\n+\t\t\t\tthrow new TableException(String.format(\"Unknown column '%s' in index pattern '%s', please check the column name.\",\n+\t\t\t\t\tindexFieldName, index));\n+\t\t\t}\n+\t\t\tpos = fieldList.indexOf(indexFieldName);\n+\t\t}\n+\t\treturn pos;\n+\t}\n+\n+\t/**\n+\t * Extract {@link DateTimeFormatter} by the date format that extracted from index pattern string.\n+\t */\n+\tprivate DateTimeFormatter extractDateFormat() {\n+\t\tString pattern = index.substring(index.indexOf(\"|\") + 1, index.indexOf(\"}\"));\n+\t\treturn DateTimeFormatter.ofPattern(pattern);\n+\t}\n+\n+\t/**\n+\t * Runtime converter that converts the index field to string.\n+\t */\n+\t@FunctionalInterface\n+\tprivate interface IndexRuntimeConverter extends Serializable{\n+\t\tString convert(Row row);\n+\t}\n+\n+\tprivate IndexRuntimeConverter createIndexRuntimeConverter() {\n+\t\tfinal String dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tfinal int indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\t\t// time extract dynamic index pattern\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tfinal TypeInformation<?>indexFieldType = fieldTypes[indexFieldPos];\n+\t\t\t\t// DataTypes.LONG\n+\t\t\t\tif (indexFieldType == Types.LONG) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tLong indexFiled = (Long) row.getField(indexFieldPos);\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = LocalDateTime.ofInstant(\n+\t\t\t\t\t\t\tInstant.ofEpochMilli(indexFiled), ZoneId.systemDefault()).format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);\n+\t\t\t\t\t};\n+\t\t\t\t}\n+\t\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\t\telse if (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tString indexFiled = row.getField(indexFieldPos).toString();\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = LocalDateTime.parse(indexFiled).format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA4NzA0Nw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399087047", "bodyText": "Please also consider null fields.", "author": "wuchong", "createdAt": "2020-03-27T07:53:18Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexFormatter.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.ZoneId;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * User can use {@link IndexFormatter} to format index value from index pattern.\n+ *\n+ * <p>If the index is a dynamic index, the index pattern include general pattern like\n+ * 'connector.index'='my-index-{item}' and time extract pattern like 'connector.index'='my-index-{log_ts|yyyy-MM-dd}'.\n+ *\n+ * <p>For general pattern:\n+ * 'item' is the index field comes from any DataType column.\n+ *\n+ * <p>For time extract pattern:\n+ * 'log_ts' is the index field comes from a BIGINT/SQL_TIMESTAMP/SQL_DATE column.\n+ * 'yyyy-MM-dd' is the date format follows the {@link DateTimeFormatter} syntax.\n+ * '{log_ts|yyyy-MM-dd}' is the time extract pattern for index in a dynamic index pattern.\n+ */\n+@Internal\n+public class IndexFormatter implements Serializable {\n+\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\n+\tprivate final String index;\n+\tprivate final String[] fieldNames;\n+\tprivate final TypeInformation<?>[] fieldTypes;\n+\tprivate final boolean dynamicIndexEnabled;\n+\tprivate final boolean dynamicIndexTimeExtractEnabled;\n+\tprivate final IndexRuntimeConverter indexRuntimeConverter;\n+\n+\tIndexFormatter(String index, String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n+\t\tthis.index = index;\n+\t\tthis.fieldNames = fieldNames;\n+\t\tthis.fieldTypes = fieldTypes;\n+\t\tthis.dynamicIndexEnabled = checkDynamicIndexEnabled();\n+\t\tthis.dynamicIndexTimeExtractEnabled = checkDynamicIndexTimeExtractEnabled();\n+\t\tthis.indexRuntimeConverter = createIndexRuntimeConverter();\n+\t}\n+\n+\t/**\n+\t * Builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static class Builder {\n+\t\tprivate String index;\n+\t\tprivate String[] fieldNames;\n+\t\tprivate TypeInformation<?>[] fieldTypes;\n+\n+\t\tprivate Builder() {\n+\t\t\t// private constructor\n+\t\t}\n+\n+\t\tpublic Builder index(String index) {\n+\t\t\tthis.index = index;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldNames(String[] fieldNames) {\n+\t\t\tthis.fieldNames = fieldNames;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic Builder fieldTypes(TypeInformation<?>[] fieldTypes) {\n+\t\t\tthis.fieldTypes = fieldTypes;\n+\t\t\treturn this;\n+\t\t}\n+\n+\t\tpublic IndexFormatter build() {\n+\t\t\treturn new IndexFormatter(index, fieldNames, fieldTypes);\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Creates a new builder for {@link IndexFormatter}.\n+\t */\n+\tpublic static Builder builder() {\n+\t\treturn new Builder();\n+\t}\n+\n+\tpublic boolean isDynamicIndexEnabled() {\n+\t\treturn dynamicIndexEnabled;\n+\t}\n+\n+\t/**\n+\t * Return dynamic index if dynamic index is enabled, else return the static index.\n+\t */\n+\tpublic String getFormattedIndex(Row row) {\n+\t\treturn indexRuntimeConverter.convert(row);\n+\t}\n+\n+\t/**\n+\t * Check general dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexEnabled() {\n+\t\treturn dynamicIndexPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Check time extract dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate boolean checkDynamicIndexTimeExtractEnabled() {\n+\t\treturn dynamicIndexTimeExtractPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Extract dynamic index pattern string from index pattern string.\n+\t */\n+\tprivate String extractDynamicIndexPatternStr() {\n+\t\tString dynamicIndexPatternStr = null;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tint start = index.indexOf(\"{\");\n+\t\t\tint end = index.lastIndexOf(\"}\");\n+\t\t\tdynamicIndexPatternStr = index.substring(start, end + 1);\n+\t\t}\n+\t\treturn dynamicIndexPatternStr;\n+\t}\n+\n+\t/**\n+\t * Extract index field position in a fieldNames, return the field position.\n+\t */\n+\tprivate int extractIndexFieldPos(String[] fieldNames) {\n+\t\tint pos = 0;\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tList<String> fieldList = Arrays.asList(fieldNames);\n+\t\t\tString indexFieldName;\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"|\"));\n+\t\t\t} else {\n+\t\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"}\"));\n+\t\t\t}\n+\t\t\tif (!fieldList.contains(indexFieldName)) {\n+\t\t\t\tthrow new TableException(String.format(\"Unknown column '%s' in index pattern '%s', please check the column name.\",\n+\t\t\t\t\tindexFieldName, index));\n+\t\t\t}\n+\t\t\tpos = fieldList.indexOf(indexFieldName);\n+\t\t}\n+\t\treturn pos;\n+\t}\n+\n+\t/**\n+\t * Extract {@link DateTimeFormatter} by the date format that extracted from index pattern string.\n+\t */\n+\tprivate DateTimeFormatter extractDateFormat() {\n+\t\tString pattern = index.substring(index.indexOf(\"|\") + 1, index.indexOf(\"}\"));\n+\t\treturn DateTimeFormatter.ofPattern(pattern);\n+\t}\n+\n+\t/**\n+\t * Runtime converter that converts the index field to string.\n+\t */\n+\t@FunctionalInterface\n+\tprivate interface IndexRuntimeConverter extends Serializable{\n+\t\tString convert(Row row);\n+\t}\n+\n+\tprivate IndexRuntimeConverter createIndexRuntimeConverter() {\n+\t\tfinal String dynamicIndexPatternStr = extractDynamicIndexPatternStr();\n+\n+\t\tif (dynamicIndexEnabled) {\n+\t\t\tfinal int indexFieldPos = extractIndexFieldPos(fieldNames);\n+\t\t\t// time extract dynamic index pattern\n+\t\t\tif (dynamicIndexTimeExtractEnabled) {\n+\t\t\t\tfinal TypeInformation<?>indexFieldType = fieldTypes[indexFieldPos];\n+\t\t\t\t// DataTypes.LONG\n+\t\t\t\tif (indexFieldType == Types.LONG) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tLong indexFiled = (Long) row.getField(indexFieldPos);\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = LocalDateTime.ofInstant(\n+\t\t\t\t\t\t\tInstant.ofEpochMilli(indexFiled), ZoneId.systemDefault()).format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);\n+\t\t\t\t\t};\n+\t\t\t\t}\n+\t\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\t\telse if (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tString indexFiled = row.getField(indexFieldPos).toString();\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = LocalDateTime.parse(indexFiled).format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);\n+\t\t\t\t\t};\n+\t\t\t\t} else if (indexFieldType == Types.SQL_TIMESTAMP) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tString indexFiled = row.getField(indexFieldPos).toString();\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = Timestamp.valueOf(indexFiled).toLocalDateTime().format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);\n+\t\t\t\t\t};\n+\t\t\t\t}\n+\t\t\t\t// DataTypes.SQL_DATE\n+\t\t\t\telse if (indexFieldType == Types.LOCAL_DATE) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tString indexFiled = row.getField(indexFieldPos).toString();\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = LocalDate.parse(indexFiled).format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);\n+\t\t\t\t\t};\n+\t\t\t\t} else if (indexFieldType == Types.SQL_DATE) {\n+\t\t\t\t\treturn (row) -> {\n+\t\t\t\t\t\tString indexFiled = row.getField(indexFieldPos).toString();\n+\t\t\t\t\t\tDateTimeFormatter dateFormat = extractDateFormat();\n+\t\t\t\t\t\tString indexFiledValueStr = Date.valueOf(indexFiled).toLocalDate().format(dateFormat);\n+\t\t\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiledValueStr);\n+\t\t\t\t\t};\n+\t\t\t\t} else {\n+\t\t\t\t\tthrow new TableException(String.format(\"Unsupported DataType '%s' found in Elasticsearch dynamic index column:, \" +\n+\t\t\t\t\t\t\"extract time-related pattern only support DataType 'BIGINT'\u3001'SQL_TIMESTAMP' and 'SQL_DATE'.\", indexFieldType));\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\t// general dynamic index pattern\n+\t\t\treturn (row) -> {\n+\t\t\t\tObject indexFiled = row.getField(indexFieldPos);\n+\t\t\t\treturn index.replace(dynamicIndexPatternStr, indexFiled.toString());", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA5MDE4NA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399090184", "bodyText": "I would suggest to accept a IndexGenerator interface, not a IndexFormatter.  IndexFormatter is just a factory to create IndexGenerator, even can be called IndexGeneratorFactory.  So that, in the future, DataStream users can also customize their special index generator. But can also use IndexGeneratorFactory in their DataStream jobs.\ninterface IndexGenerator extends Serializable {\n  String generate(Row row);\n}", "author": "wuchong", "createdAt": "2020-03-27T08:00:31Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchUpsertTableSinkBase.java", "diffHunk": "@@ -431,7 +438,8 @@ public ElasticsearchUpsertSinkFunction(\n \t\t\t\tSerializationSchema<Row> serializationSchema,\n \t\t\t\tXContentType contentType,\n \t\t\t\tRequestFactory requestFactory,\n-\t\t\t\tint[] keyFieldIndices) {\n+\t\t\t\tint[] keyFieldIndices,\n+\t\t\t\tIndexFormatter indexFormatter) {", "originalCommit": "ceee7120bc432a4239c092475a96bdf48531559b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE2NDg2MA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r399164860", "bodyText": "Thanks very much for you comments,  I'll update ASAP.", "author": "leonardBang", "createdAt": "2020-03-27T10:21:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA5MDE4NA=="}], "type": "inlineReview"}, {"oid": "14bd87d3ba19a017fa607b688caea5b69c1cbe5d", "url": "https://github.com/apache/flink/commit/14bd87d3ba19a017fa607b688caea5b69c1cbe5d", "message": "[FLINK-15400][connectors / elasticsearch] elasticsearch table sink support dynamic index.", "committedDate": "2020-04-06T03:14:26Z", "type": "commit"}, {"oid": "4088dee9788ab267fc39b5d96825eae69df4d1d3", "url": "https://github.com/apache/flink/commit/4088dee9788ab267fc39b5d96825eae69df4d1d3", "message": "refactor", "committedDate": "2020-04-09T14:09:12Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM3NzQ4Mw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r401377483", "bodyText": "I think we can remove index parameter now, it is never used, and put indexGenerator as the first parameter.", "author": "wuchong", "createdAt": "2020-04-01T06:13:42Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchUpsertTableSinkBase.java", "diffHunk": "@@ -422,6 +427,7 @@ DeleteRequest createDeleteRequest(\n \t\tprivate final XContentType contentType;\n \t\tprivate final RequestFactory requestFactory;\n \t\tprivate final int[] keyFieldIndices;\n+\t\tprivate final IndexGenerator indexGenerator;\n \n \t\tpublic ElasticsearchUpsertSinkFunction(\n \t\t\t\tString index,", "originalCommit": "603d98c3dc229c5c3e5a43f2d748640a55a98680", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNTA4NA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408605084", "bodyText": "Please use ExpectedException to assert exceptions.", "author": "wuchong", "createdAt": "2020-04-15T06:19:41Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/IndexGeneratorTest.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Suite tests for {@link IndexGenerator}.\n+ */\n+public class IndexGeneratorTest {\n+\tprivate TableSchema schema;\n+\tprivate List<Row> rows;\n+\n+\t@Before\n+\tpublic void prepareData() {\n+\t\tString[] fieldNames = new String[] {\"id\", \"item\", \"log_ts\", \"log_date\", \"order_timestamp\", \"log_time\", \"local_datetime\", \"local_date\", \"local_time\", \"note\"};\n+\t\tDataType[] dataTypes = new DataType[] {\n+\t\t\tDataTypes.INT(),\n+\t\t\tDataTypes.STRING(),\n+\t\t\tDataTypes.BIGINT(),\n+\t\t\tDataTypes.DATE().bridgedTo(java.sql.Date.class),\n+\t\t\tDataTypes.TIMESTAMP().bridgedTo(java.sql.Timestamp.class),\n+\t\t\tDataTypes.TIME().bridgedTo(java.sql.Time.class),\n+\t\t\tDataTypes.TIMESTAMP().bridgedTo(java.time.LocalDateTime.class),\n+\t\t\tDataTypes.DATE().bridgedTo(java.time.LocalDate.class),\n+\t\t\tDataTypes.TIME().bridgedTo(java.time.LocalTime.class),\n+\t\t\tDataTypes.STRING()\n+\t\t};\n+\t\tschema = new TableSchema.Builder().fields(fieldNames, dataTypes).build();\n+\n+\t\trows = new ArrayList<>();\n+\t\trows.add(Row.of(\n+\t\t\t1,\n+\t\t\t\"apple\",\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-18\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\"),\n+\t\t\tTime.valueOf(\"12:12:14\"),\n+\t\t\tLocalDateTime.of(2020, 3, 18, 12, 12, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 18),\n+\t\t\tLocalTime.of(12, 13, 14, 2000),\n+\t\t\t\"test1\"));\n+\t\trows.add(Row.of(\n+\t\t\t2,\n+\t\t\t\"peanut\",\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-19\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:21\"),\n+\t\t\tTime.valueOf(\"12:22:21\"),\n+\t\t\tLocalDateTime.of(2020, 3, 19, 12, 22, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 19),\n+\t\t\tLocalTime.of(12, 13, 14, 2000),\n+\t\t\t\"test2\"));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTimestamp() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{order_timestamp|yyyy_MM_dd_HH-ss}_index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexGenerator.generate(rows.get(0)));\n+\t\tIndexGenerator indexGenerator1 = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{order_timestamp|yyyy_MM_dd_HH_mm}_index\", schema);\n+\t\tindexGenerator1.open();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexGenerator1.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDateTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{local_datetime|yyyy_MM_dd_HH-ss}_index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexGenerator.generate(rows.get(0)));\n+\t\tIndexGenerator indexGenerator1 = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{local_datetime|yyyy_MM_dd_HH_mm}_index\", schema);\n+\t\tindexGenerator1.open();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexGenerator1.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromDate() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{log_date|yyyy/MM/dd}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDate() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{local_date|yyyy/MM/dd}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{log_time|HH-mm}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-12-12\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-12-22\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{local_time|HH-mm}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-12-13\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-12-13\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testGeneralDynamicIndex() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"index_{item}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"index_apple\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"index_peanut\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testStaticIndex() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testUnknownField() {\n+\t\tString expectedExceptionMsg = \"Unknown column 'unknown_ts' in index pattern 'my-index-{unknown_ts|yyyy-MM-dd}', please check the column name.\";\n+\t\ttry {\n+\t\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\t\"my-index-{unknown_ts|yyyy-MM-dd}\", schema);\n+\t\t\tindexGenerator.open();\n+\t\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(0)));\n+\t\t} catch (Exception e) {\n+\t\t\tAssert.assertEquals(e.getMessage(), expectedExceptionMsg);", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNTMwNw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408605307", "bodyText": "I think we don't need to assert for this, because it will throw exception? Just indexGenerator.generate(rows.get(0)); is enough?", "author": "wuchong", "createdAt": "2020-04-15T06:20:16Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/IndexGeneratorTest.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Suite tests for {@link IndexGenerator}.\n+ */\n+public class IndexGeneratorTest {\n+\tprivate TableSchema schema;\n+\tprivate List<Row> rows;\n+\n+\t@Before\n+\tpublic void prepareData() {\n+\t\tString[] fieldNames = new String[] {\"id\", \"item\", \"log_ts\", \"log_date\", \"order_timestamp\", \"log_time\", \"local_datetime\", \"local_date\", \"local_time\", \"note\"};\n+\t\tDataType[] dataTypes = new DataType[] {\n+\t\t\tDataTypes.INT(),\n+\t\t\tDataTypes.STRING(),\n+\t\t\tDataTypes.BIGINT(),\n+\t\t\tDataTypes.DATE().bridgedTo(java.sql.Date.class),\n+\t\t\tDataTypes.TIMESTAMP().bridgedTo(java.sql.Timestamp.class),\n+\t\t\tDataTypes.TIME().bridgedTo(java.sql.Time.class),\n+\t\t\tDataTypes.TIMESTAMP().bridgedTo(java.time.LocalDateTime.class),\n+\t\t\tDataTypes.DATE().bridgedTo(java.time.LocalDate.class),\n+\t\t\tDataTypes.TIME().bridgedTo(java.time.LocalTime.class),\n+\t\t\tDataTypes.STRING()\n+\t\t};\n+\t\tschema = new TableSchema.Builder().fields(fieldNames, dataTypes).build();\n+\n+\t\trows = new ArrayList<>();\n+\t\trows.add(Row.of(\n+\t\t\t1,\n+\t\t\t\"apple\",\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-18\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\"),\n+\t\t\tTime.valueOf(\"12:12:14\"),\n+\t\t\tLocalDateTime.of(2020, 3, 18, 12, 12, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 18),\n+\t\t\tLocalTime.of(12, 13, 14, 2000),\n+\t\t\t\"test1\"));\n+\t\trows.add(Row.of(\n+\t\t\t2,\n+\t\t\t\"peanut\",\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-19\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:21\"),\n+\t\t\tTime.valueOf(\"12:22:21\"),\n+\t\t\tLocalDateTime.of(2020, 3, 19, 12, 22, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 19),\n+\t\t\tLocalTime.of(12, 13, 14, 2000),\n+\t\t\t\"test2\"));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTimestamp() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{order_timestamp|yyyy_MM_dd_HH-ss}_index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexGenerator.generate(rows.get(0)));\n+\t\tIndexGenerator indexGenerator1 = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{order_timestamp|yyyy_MM_dd_HH_mm}_index\", schema);\n+\t\tindexGenerator1.open();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexGenerator1.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDateTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{local_datetime|yyyy_MM_dd_HH-ss}_index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexGenerator.generate(rows.get(0)));\n+\t\tIndexGenerator indexGenerator1 = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{local_datetime|yyyy_MM_dd_HH_mm}_index\", schema);\n+\t\tindexGenerator1.open();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexGenerator1.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromDate() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{log_date|yyyy/MM/dd}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDate() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{local_date|yyyy/MM/dd}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{log_time|HH-mm}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-12-12\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-12-22\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{local_time|HH-mm}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-12-13\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-12-13\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testGeneralDynamicIndex() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"index_{item}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"index_apple\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"index_peanut\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testStaticIndex() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testUnknownField() {\n+\t\tString expectedExceptionMsg = \"Unknown column 'unknown_ts' in index pattern 'my-index-{unknown_ts|yyyy-MM-dd}', please check the column name.\";\n+\t\ttry {\n+\t\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\t\"my-index-{unknown_ts|yyyy-MM-dd}\", schema);\n+\t\t\tindexGenerator.open();\n+\t\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(0)));", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNjAyMw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408606023", "bodyText": "Redundent : after column?", "author": "wuchong", "createdAt": "2020-04-15T06:22:14Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/IndexGeneratorTest.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Suite tests for {@link IndexGenerator}.\n+ */\n+public class IndexGeneratorTest {\n+\tprivate TableSchema schema;\n+\tprivate List<Row> rows;\n+\n+\t@Before\n+\tpublic void prepareData() {\n+\t\tString[] fieldNames = new String[] {\"id\", \"item\", \"log_ts\", \"log_date\", \"order_timestamp\", \"log_time\", \"local_datetime\", \"local_date\", \"local_time\", \"note\"};\n+\t\tDataType[] dataTypes = new DataType[] {\n+\t\t\tDataTypes.INT(),\n+\t\t\tDataTypes.STRING(),\n+\t\t\tDataTypes.BIGINT(),\n+\t\t\tDataTypes.DATE().bridgedTo(java.sql.Date.class),\n+\t\t\tDataTypes.TIMESTAMP().bridgedTo(java.sql.Timestamp.class),\n+\t\t\tDataTypes.TIME().bridgedTo(java.sql.Time.class),\n+\t\t\tDataTypes.TIMESTAMP().bridgedTo(java.time.LocalDateTime.class),\n+\t\t\tDataTypes.DATE().bridgedTo(java.time.LocalDate.class),\n+\t\t\tDataTypes.TIME().bridgedTo(java.time.LocalTime.class),\n+\t\t\tDataTypes.STRING()\n+\t\t};\n+\t\tschema = new TableSchema.Builder().fields(fieldNames, dataTypes).build();\n+\n+\t\trows = new ArrayList<>();\n+\t\trows.add(Row.of(\n+\t\t\t1,\n+\t\t\t\"apple\",\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-18\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-18 12:12:14\"),\n+\t\t\tTime.valueOf(\"12:12:14\"),\n+\t\t\tLocalDateTime.of(2020, 3, 18, 12, 12, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 18),\n+\t\t\tLocalTime.of(12, 13, 14, 2000),\n+\t\t\t\"test1\"));\n+\t\trows.add(Row.of(\n+\t\t\t2,\n+\t\t\t\"peanut\",\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:14\").getTime(),\n+\t\t\tDate.valueOf(\"2020-03-19\"),\n+\t\t\tTimestamp.valueOf(\"2020-03-19 12:22:21\"),\n+\t\t\tTime.valueOf(\"12:22:21\"),\n+\t\t\tLocalDateTime.of(2020, 3, 19, 12, 22, 14, 1000),\n+\t\t\tLocalDate.of(2020, 3, 19),\n+\t\t\tLocalTime.of(12, 13, 14, 2000),\n+\t\t\t\"test2\"));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTimestamp() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{order_timestamp|yyyy_MM_dd_HH-ss}_index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexGenerator.generate(rows.get(0)));\n+\t\tIndexGenerator indexGenerator1 = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{order_timestamp|yyyy_MM_dd_HH_mm}_index\", schema);\n+\t\tindexGenerator1.open();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexGenerator1.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDateTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{local_datetime|yyyy_MM_dd_HH-ss}_index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"2020_03_18_12-14_index\", indexGenerator.generate(rows.get(0)));\n+\t\tIndexGenerator indexGenerator1 = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"{local_datetime|yyyy_MM_dd_HH_mm}_index\", schema);\n+\t\tindexGenerator1.open();\n+\t\tAssert.assertEquals(\"2020_03_19_12_22_index\", indexGenerator1.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromDate() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{log_date|yyyy/MM/dd}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalDate() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{local_date|yyyy/MM/dd}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-2020/03/18\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-2020/03/19\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{log_time|HH-mm}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-12-12\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-12-22\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testDynamicIndexFromLocalTime() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index-{local_time|HH-mm}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index-12-13\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index-12-13\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testGeneralDynamicIndex() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"index_{item}\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"index_apple\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"index_peanut\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testStaticIndex() {\n+\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\"my-index\", schema);\n+\t\tindexGenerator.open();\n+\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(0)));\n+\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(1)));\n+\t}\n+\n+\t@Test\n+\tpublic void testUnknownField() {\n+\t\tString expectedExceptionMsg = \"Unknown column 'unknown_ts' in index pattern 'my-index-{unknown_ts|yyyy-MM-dd}', please check the column name.\";\n+\t\ttry {\n+\t\t\tIndexGenerator indexGenerator = IndexGeneratorFactory.createIndexGenerator(\n+\t\t\t\t\"my-index-{unknown_ts|yyyy-MM-dd}\", schema);\n+\t\t\tindexGenerator.open();\n+\t\t\tAssert.assertEquals(\"my-index\", indexGenerator.generate(rows.get(0)));\n+\t\t} catch (Exception e) {\n+\t\t\tAssert.assertEquals(e.getMessage(), expectedExceptionMsg);\n+\t\t}\n+\t}\n+\n+\t@Test\n+\tpublic void testUnSupportedType() {\n+\t\tString expectedExceptionMsg = \"Unsupported DataType 'Integer' found in Elasticsearch dynamic index column:, extract time-related pattern only support DataType 'TIMESTAMP', 'DATE' and 'TIME'.\";", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNjczOQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408606739", "bodyText": "Please add one more test to test the exception when multiple dynamic parameter in the index name, e.g. my-index-{local_date}-{local_time}", "author": "wuchong", "createdAt": "2020-04-15T06:24:03Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/IndexGeneratorTest.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * Suite tests for {@link IndexGenerator}.\n+ */\n+public class IndexGeneratorTest {", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjkwNA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408616904", "bodyText": "We shouldn't add IndexGenerator here. Generating index is the responsibility of ElasticsearchSinkFunction. We can add an default empty open method in ElasticsearchSinkFunction to avoid putting IndexGenerator here.", "author": "wuchong", "createdAt": "2020-04-15T06:49:41Z", "path": "flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/ElasticsearchSink.java", "diffHunk": "@@ -61,15 +63,24 @@\n public class ElasticsearchSink<T> extends ElasticsearchSinkBase<T, RestHighLevelClient> {\n \n \tprivate static final long serialVersionUID = 1L;\n+\tprivate final IndexGenerator indexGenerator;", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMDYxMg==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408620612", "bodyText": "do we still need this field?", "author": "libenchao", "createdAt": "2020-04-15T06:58:07Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchUpsertTableSinkBase.java", "diffHunk": "@@ -422,6 +434,7 @@ DeleteRequest createDeleteRequest(\n \t\tprivate final XContentType contentType;\n \t\tprivate final RequestFactory requestFactory;\n \t\tprivate final int[] keyFieldIndices;\n+\t\tprivate final IndexGenerator indexGenerator;\n \n \t\tpublic ElasticsearchUpsertSinkFunction(\n \t\t\t\tString index,", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMzY5NA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408623694", "bodyText": "typo: indexField", "author": "libenchao", "createdAt": "2020-04-15T07:04:55Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexGeneratorFactory.java", "diffHunk": "@@ -0,0 +1,250 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Factory of {@link IndexGenerator}.\n+ *\n+ * <p>Flink supports both static index and dynamic index.\n+ *\n+ * <p>If you want to have a static index, this option value should be a plain string, e.g. 'myusers',\n+ * all the records will be consistently written into \"myusers\" index.\n+ *\n+ * <p>If you want to have a dynamic index, you can use '{field_name}' to reference a field value in the\n+ * record to dynamically generate a target index. You can also use '{field_name|date_format_string}' to\n+ * convert a field value of TIMESTAMP/DATE/TIME type into the format specified by date_format_string. The\n+ * date_format_string is compatible with {@link java.text.SimpleDateFormat}. For example, if the option\n+ * value is 'myusers_{log_ts|yyyy-MM-dd}', then a record with log_ts field value 2020-03-27 12:25:55 will\n+ * be written into \"myusers-2020-03-27\" index.\n+ */\n+@Internal\n+public class IndexGeneratorFactory {\n+\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\".*\\\\{.+\\\\}.*\");\n+\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\tprivate static final String DEFAULT_DATE_FORMAT = \"yyyy-MM-dd\";\n+\n+\tprivate IndexGeneratorFactory() {}\n+\n+\tpublic static IndexGenerator createIndexGenerator(String index, TableSchema schema) {\n+\t\tfinal boolean isDynamicIndex = checkIsDynamicIndex(index);\n+\t\tif (isDynamicIndex) {\n+\t\t\treturn createRuntimeIndexGenerator(index, schema.getFieldNames(), schema.getFieldDataTypes());\n+\t\t} else {\n+\t\t\treturn new IndexGenerator(index, schema.getFieldNames(), schema.getFieldDataTypes());\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Check general dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate static boolean checkIsDynamicIndex(String index) {\n+\t\treturn dynamicIndexPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Check time extract dynamic index is enabled or not by index pattern.\n+\t */\n+\tprivate static boolean checkIsDynamicIndexWithFormat(String index) {\n+\t\treturn dynamicIndexTimeExtractPattern.matcher(index).matches();\n+\t}\n+\n+\t/**\n+\t * Extract dynamic index pattern string from index pattern string.\n+\t */\n+\tprivate static String extractDynamicIndexPatternStr(String index) {\n+\t\tint start = index.indexOf(\"{\");\n+\t\tint end = index.lastIndexOf(\"}\");\n+\t\treturn index.substring(start, end + 1);\n+\t}\n+\n+\t/**\n+\t * Extract index field position in a fieldNames, return the field position.\n+\t */\n+\tprivate static int extractIndexFieldPos(String index, String[] fieldNames, boolean isDynamicIndexWithFormat) {\n+\t\tList<String> fieldList = Arrays.asList(fieldNames);\n+\t\tString indexFieldName;\n+\t\tif (isDynamicIndexWithFormat) {\n+\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"|\"));\n+\t\t} else {\n+\t\t\tindexFieldName = index.substring(index.indexOf(\"{\") + 1, index.indexOf(\"}\"));\n+\t\t}\n+\t\tif (!fieldList.contains(indexFieldName)) {\n+\t\t\tthrow new TableException(String.format(\"Unknown column '%s' in index pattern '%s', please check the column name.\",\n+\t\t\t\tindexFieldName, index));\n+\t\t}\n+\t\treturn fieldList.indexOf(indexFieldName);\n+\t}\n+\n+\t/**\n+\t * Extract dateTime format by the date format that extracted from index pattern string.\n+\t */\n+\tprivate static String extractDateFormat(String index) {\n+\t\tif (checkIsDynamicIndexWithFormat(index)) {\n+\t\t\treturn index.substring(index.indexOf(\"|\") + 1, index.indexOf(\"}\"));\n+\t\t} else {\n+\t\t\treturn DEFAULT_DATE_FORMAT;\n+\t\t}\n+\t}\n+\n+\tprivate static IndexGenerator createRuntimeIndexGenerator(\n+\t\t\tString index,\n+\t\t\tString[] fieldNames,\n+\t\t\tDataType[] fieldTypes) {\n+\t\tfinal String dynamicIndexPatternStr = extractDynamicIndexPatternStr(index);\n+\t\tfinal String indexPrefix = index.substring(0, index.indexOf(dynamicIndexPatternStr));\n+\t\tfinal String indexSuffix = index.substring(indexPrefix.length() + dynamicIndexPatternStr.length());\n+\n+\t\tfinal boolean isDynamicIndexWithFormat = checkIsDynamicIndexWithFormat(index);\n+\t\tfinal int indexFieldPos = extractIndexFieldPos(index, fieldNames, isDynamicIndexWithFormat);\n+\t\t// time extract dynamic index pattern\n+\t\tif (isDynamicIndexWithFormat) {\n+\t\t\tfinal TypeInformation<?> indexFieldType = TypeConversions.fromDataTypeToLegacyInfo(fieldTypes[indexFieldPos]);\n+\t\t\tfinal String dateTimeFormat = extractDateFormat(index);\n+\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\tif (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\treturn new IndexGenerator(index, fieldNames, fieldTypes) {\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic void open() {\n+\t\t\t\t\t\tthis.dateTimeFormatter = DateTimeFormatter.ofPattern(dateTimeFormat);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDateTime indexFiled = (LocalDateTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFiledValueStr = indexFiled.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFiledValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\telse if (indexFieldType == Types.SQL_TIMESTAMP) {\n+\t\t\t\treturn new IndexGenerator(index, fieldNames, fieldTypes) {\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic void open() {\n+\t\t\t\t\t\tthis.dateTimeFormatter = DateTimeFormatter.ofPattern(dateTimeFormat);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTimestamp indexFiled = (Timestamp) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFiledValueStr = indexFiled.toLocalDateTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFiledValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\t// DataTypes.SQL_DATE\n+\t\t\telse if (indexFieldType == Types.LOCAL_DATE) {\n+\t\t\t\treturn new IndexGenerator(index, fieldNames, fieldTypes) {\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic void open() {\n+\t\t\t\t\t\tthis.dateTimeFormatter = DateTimeFormatter.ofPattern(dateTimeFormat);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDate indexFiled = (LocalDate) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFiledValueStr = indexFiled.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFiledValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_DATE) {\n+\t\t\t\treturn new IndexGenerator(index, fieldNames, fieldTypes) {\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic void open() {\n+\t\t\t\t\t\tthis.dateTimeFormatter = DateTimeFormatter.ofPattern(dateTimeFormat);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tDate indexFiled = (Date) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFiledValueStr = indexFiled.toLocalDate().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFiledValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} // DataTypes.TIME\n+\t\t\telse if (indexFieldType == Types.LOCAL_TIME) {\n+\t\t\t\treturn new IndexGenerator(index, fieldNames, fieldTypes) {\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic void open() {\n+\t\t\t\t\t\tthis.dateTimeFormatter = DateTimeFormatter.ofPattern(dateTimeFormat);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalTime indexFiled = (LocalTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFiledValueStr = indexFiled.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFiledValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_TIME) {\n+\t\t\t\treturn new IndexGenerator(index, fieldNames, fieldTypes) {\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic void open() {\n+\t\t\t\t\t\tthis.dateTimeFormatter = DateTimeFormatter.ofPattern(dateTimeFormat);\n+\t\t\t\t\t}\n+\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTime indexFiled = (Time) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFiledValueStr = indexFiled.toLocalTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFiledValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else {\n+\t\t\t\tthrow new TableException(String.format(\"Unsupported DataType '%s' found in Elasticsearch dynamic index column:, \" +\n+\t\t\t\t\t\"extract time-related pattern only support DataType 'TIMESTAMP', 'DATE' and 'TIME'.\", indexFieldType));\n+\t\t\t}\n+\t\t}\n+\t\t// general dynamic index pattern\n+\t\treturn new IndexGenerator(index, fieldNames, fieldTypes) {\n+\n+\t\t\t@Override\n+\t\t\tpublic String generate(Row row) {\n+\t\t\t\tObject indexFiled = row.getField(indexFieldPos);", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNDYwNw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408624607", "bodyText": "+n for other places.", "author": "libenchao", "createdAt": "2020-04-15T07:06:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMzY5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyOTI3Nw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408629277", "bodyText": "Could we name it DefaultIndexGenerator ?", "author": "libenchao", "createdAt": "2020-04-15T07:16:35Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexGenerator.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.Objects;\n+\n+/**\n+ * IndexGenerator to generate index from {@link Row}.\n+ */\n+@Internal\n+public class IndexGenerator implements Serializable {", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNDIzMA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408634230", "bodyText": "Or have a abstract IndexGenerator and a DefaultIndexGenerator implementation?", "author": "libenchao", "createdAt": "2020-04-15T07:26:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyOTI3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyOTY4NA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408629684", "bodyText": "Maybe we don't need fieldNames and dataTypes?", "author": "libenchao", "createdAt": "2020-04-15T07:17:27Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexGenerator.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.Objects;\n+\n+/**\n+ * IndexGenerator to generate index from {@link Row}.\n+ */\n+@Internal\n+public class IndexGenerator implements Serializable {\n+\n+\tprivate static final long serialVersionUID = 1L;\n+\tprivate final String index;\n+\tprivate final String[] fieldNames;\n+\tprivate final DataType[] dataTypes;", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMzU2NA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408633564", "bodyText": "Does IndexGenerator is a must-have field? If yes, maybe we can just check it is set before build(). or we can create a default one before build()?", "author": "libenchao", "createdAt": "2020-04-15T07:24:42Z", "path": "flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch6/ElasticsearchSink.java", "diffHunk": "@@ -86,6 +97,7 @@ private ElasticsearchSink(\n \t\tprivate Map<String, String> bulkRequestsConfig = new HashMap<>();\n \t\tprivate ActionRequestFailureHandler failureHandler = new NoOpFailureHandler();\n \t\tprivate RestClientFactory restClientFactory = restClientBuilder -> {};\n+\t\tprivate IndexGenerator indexGenerator = new IndexGenerator(null, null, null);", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNDY0Ng==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408634646", "bodyText": "I just realized that, maybe this should be a Public-Evolving api? because DataStream Api also need this?", "author": "libenchao", "createdAt": "2020-04-15T07:26:50Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/IndexGenerator.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.Objects;\n+\n+/**\n+ * IndexGenerator to generate index from {@link Row}.\n+ */\n+@Internal", "originalCommit": "eb912b99fce4721f57ac1318780548f4ec2b2e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODg0NDYzOQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408844639", "bodyText": "I was considering this,  but user can generate index easily in DataStream Api  and no need to care this API, and  Importing a Public-Evolving API should offers a design  doc and be careful, it's should be another topic.", "author": "leonardBang", "createdAt": "2020-04-15T13:33:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNDY0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODg2MzI2Nw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r408863267", "bodyText": "Yes, you are right.", "author": "libenchao", "createdAt": "2020-04-15T13:58:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNDY0Ng=="}], "type": "inlineReview"}, {"oid": "036c29f707d590dbc049bb2adad38da75491194c", "url": "https://github.com/apache/flink/commit/036c29f707d590dbc049bb2adad38da75491194c", "message": "address comments", "committedDate": "2020-04-16T13:55:06Z", "type": "forcePushed"}, {"oid": "c8f8eb3c22bfdd4f82204d281b6f7c5ebbefb769", "url": "https://github.com/apache/flink/commit/c8f8eb3c22bfdd4f82204d281b6f7c5ebbefb769", "message": "address comments", "committedDate": "2020-04-17T01:29:33Z", "type": "commit"}, {"oid": "c8f8eb3c22bfdd4f82204d281b6f7c5ebbefb769", "url": "https://github.com/apache/flink/commit/c8f8eb3c22bfdd4f82204d281b6f7c5ebbefb769", "message": "address comments", "committedDate": "2020-04-17T01:29:33Z", "type": "forcePushed"}, {"oid": "3ca96009fa85a3f2ca057d0eb75bef88be4c54fa", "url": "https://github.com/apache/flink/commit/3ca96009fa85a3f2ca057d0eb75bef88be4c54fa", "message": "add tests", "committedDate": "2020-04-17T04:28:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAyODQ3OA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410028478", "bodyText": "List the supported date types directly here. It's confused to list LOCAL_DATE and DATE.", "author": "wuchong", "createdAt": "2020-04-17T06:59:56Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/index/IndexGeneratorFactory.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch.index;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Factory of {@link IndexGenerator}.\n+ *\n+ * <p>Flink supports both static index and dynamic index.\n+ *\n+ * <p>If you want to have a static index, this option value should be a plain string, e.g. 'myusers',\n+ * all the records will be consistently written into \"myusers\" index.\n+ *\n+ * <p>If you want to have a dynamic index, you can use '{field_name}' to reference a field value in the\n+ * record to dynamically generate a target index. You can also use '{field_name|date_format_string}' to\n+ * convert a field value of TIMESTAMP/DATE/TIME type into the format specified by date_format_string. The\n+ * date_format_string is compatible with {@link java.text.SimpleDateFormat}. For example, if the option\n+ * value is 'myusers_{log_ts|yyyy-MM-dd}', then a record with log_ts field value 2020-03-27 12:25:55 will\n+ * be written into \"myusers-2020-03-27\" index.\n+ */\n+@Internal\n+public class IndexGeneratorFactory {\n+\n+\tprivate IndexGeneratorFactory() {}\n+\n+\tpublic static IndexGenerator createIndexGenerator(String index, TableSchema schema) {\n+\t\tfinal IndexHelper indexHelper = new IndexHelper();\n+\t\tif (indexHelper.checkIsDynamicIndex(index)) {\n+\t\t\treturn createRuntimeIndexGenerator(index, schema.getFieldNames(), schema.getFieldDataTypes(), indexHelper);\n+\t\t} else {\n+\t\t\treturn new DefaultIndexGenerator(index);\n+\t\t}\n+\t}\n+\n+\tprivate static IndexGenerator createRuntimeIndexGenerator(\n+\t\t\tString index,\n+\t\t\tString[] fieldNames,\n+\t\t\tDataType[] fieldTypes,\n+\t\t\tIndexHelper indexHelper) {\n+\t\tfinal String dynamicIndexPatternStr = indexHelper.extractDynamicIndexPatternStr(index);\n+\t\tfinal String indexPrefix = index.substring(0, index.indexOf(dynamicIndexPatternStr));\n+\t\tfinal String indexSuffix = index.substring(indexPrefix.length() + dynamicIndexPatternStr.length());\n+\n+\t\tfinal boolean isDynamicIndexWithFormat = indexHelper.checkIsDynamicIndexWithFormat(index);\n+\t\tfinal int indexFieldPos = indexHelper.extractIndexFieldPos(index, fieldNames, isDynamicIndexWithFormat);\n+\t\tfinal TypeInformation<?> indexFieldType = TypeConversions.fromDataTypeToLegacyInfo(fieldTypes[indexFieldPos]);\n+\n+\t\t// validate index field type\n+\t\tindexHelper.validateIndexFieldType(indexFieldType);\n+\n+\t\t// time extract dynamic index pattern\n+\t\tif (isDynamicIndexWithFormat) {\n+\t\t\tfinal String dateTimeFormat = indexHelper.extractDateFormat(index, indexFieldType);\n+\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\tif (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDateTime indexField = (LocalDateTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\telse if (indexFieldType == Types.SQL_TIMESTAMP) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTimestamp indexField = (Timestamp) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDateTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\t// DataTypes.SQL_DATE\n+\t\t\telse if (indexFieldType == Types.LOCAL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDate indexField = (LocalDate) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tDate indexField = (Date) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDate().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} // DataTypes.TIME\n+\t\t\telse if (indexFieldType == Types.LOCAL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalTime indexField = (LocalTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTime indexField = (Time) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else {\n+\t\t\t\tthrow new TableException(String.format(\"Unsupported type '%s' found in Elasticsearch dynamic index field, \" +\n+\t\t\t\t\t\"time-related pattern only support types are: %s\", indexFieldType, indexHelper.getSupportedDateTypes()));", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAyODY3Nw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410028677", "bodyText": "Why underscore?", "author": "wuchong", "createdAt": "2020-04-17T07:00:23Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/index/IndexGeneratorFactory.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch.index;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Factory of {@link IndexGenerator}.\n+ *\n+ * <p>Flink supports both static index and dynamic index.\n+ *\n+ * <p>If you want to have a static index, this option value should be a plain string, e.g. 'myusers',\n+ * all the records will be consistently written into \"myusers\" index.\n+ *\n+ * <p>If you want to have a dynamic index, you can use '{field_name}' to reference a field value in the\n+ * record to dynamically generate a target index. You can also use '{field_name|date_format_string}' to\n+ * convert a field value of TIMESTAMP/DATE/TIME type into the format specified by date_format_string. The\n+ * date_format_string is compatible with {@link java.text.SimpleDateFormat}. For example, if the option\n+ * value is 'myusers_{log_ts|yyyy-MM-dd}', then a record with log_ts field value 2020-03-27 12:25:55 will\n+ * be written into \"myusers-2020-03-27\" index.\n+ */\n+@Internal\n+public class IndexGeneratorFactory {\n+\n+\tprivate IndexGeneratorFactory() {}\n+\n+\tpublic static IndexGenerator createIndexGenerator(String index, TableSchema schema) {\n+\t\tfinal IndexHelper indexHelper = new IndexHelper();\n+\t\tif (indexHelper.checkIsDynamicIndex(index)) {\n+\t\t\treturn createRuntimeIndexGenerator(index, schema.getFieldNames(), schema.getFieldDataTypes(), indexHelper);\n+\t\t} else {\n+\t\t\treturn new DefaultIndexGenerator(index);\n+\t\t}\n+\t}\n+\n+\tprivate static IndexGenerator createRuntimeIndexGenerator(\n+\t\t\tString index,\n+\t\t\tString[] fieldNames,\n+\t\t\tDataType[] fieldTypes,\n+\t\t\tIndexHelper indexHelper) {\n+\t\tfinal String dynamicIndexPatternStr = indexHelper.extractDynamicIndexPatternStr(index);\n+\t\tfinal String indexPrefix = index.substring(0, index.indexOf(dynamicIndexPatternStr));\n+\t\tfinal String indexSuffix = index.substring(indexPrefix.length() + dynamicIndexPatternStr.length());\n+\n+\t\tfinal boolean isDynamicIndexWithFormat = indexHelper.checkIsDynamicIndexWithFormat(index);\n+\t\tfinal int indexFieldPos = indexHelper.extractIndexFieldPos(index, fieldNames, isDynamicIndexWithFormat);\n+\t\tfinal TypeInformation<?> indexFieldType = TypeConversions.fromDataTypeToLegacyInfo(fieldTypes[indexFieldPos]);\n+\n+\t\t// validate index field type\n+\t\tindexHelper.validateIndexFieldType(indexFieldType);\n+\n+\t\t// time extract dynamic index pattern\n+\t\tif (isDynamicIndexWithFormat) {\n+\t\t\tfinal String dateTimeFormat = indexHelper.extractDateFormat(index, indexFieldType);\n+\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\tif (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDateTime indexField = (LocalDateTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\telse if (indexFieldType == Types.SQL_TIMESTAMP) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTimestamp indexField = (Timestamp) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDateTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\t// DataTypes.SQL_DATE\n+\t\t\telse if (indexFieldType == Types.LOCAL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDate indexField = (LocalDate) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tDate indexField = (Date) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDate().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} // DataTypes.TIME\n+\t\t\telse if (indexFieldType == Types.LOCAL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalTime indexField = (LocalTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTime indexField = (Time) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else {\n+\t\t\t\tthrow new TableException(String.format(\"Unsupported type '%s' found in Elasticsearch dynamic index field, \" +\n+\t\t\t\t\t\"time-related pattern only support types are: %s\", indexFieldType, indexHelper.getSupportedDateTypes()));\n+\t\t\t}\n+\t\t}\n+\t\t// general dynamic index pattern\n+\t\treturn new DefaultIndexGenerator(index) {\n+\n+\t\t\t@Override\n+\t\t\tpublic String generate(Row row) {\n+\t\t\t\tObject indexField = row.getField(indexFieldPos);\n+\t\t\t\treturn indexPrefix.concat(indexField == null ? index : indexField.toString()).concat(indexSuffix);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\t/**\n+\t * Helper class for {@link IndexGeneratorFactory}, this helper can use to validate index field type\n+\t * ans parse index format from pattern.\n+\t */\n+\tprivate static class IndexHelper {\n+\t\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\"\\\\{[^\\\\{\\\\}]+\\\\}?\");\n+\t\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\t\tprivate static final List<TypeInformation> supportedTypes = new ArrayList<>();\n+\t\tprivate static final Map<TypeInformation, String> defaultFormats = new HashMap<>();\n+\n+\t\tstatic {\n+\t\t\t//time related types\n+\t\t\tsupportedTypes.add(Types.LOCAL_DATE_TIME);\n+\t\t\tsupportedTypes.add(Types.SQL_TIMESTAMP);\n+\t\t\tsupportedTypes.add(Types.LOCAL_DATE);\n+\t\t\tsupportedTypes.add(Types.SQL_DATE);\n+\t\t\tsupportedTypes.add(Types.LOCAL_TIME);\n+\t\t\tsupportedTypes.add(Types.SQL_TIME);\n+\t\t\t//general types\n+\t\t\tsupportedTypes.add(Types.STRING);\n+\t\t\tsupportedTypes.add(Types.SHORT);\n+\t\t\tsupportedTypes.add(Types.INT);\n+\t\t\tsupportedTypes.add(Types.LONG);\n+\t\t}\n+\n+\t\tstatic {\n+\t\t\tdefaultFormats.put(Types.LOCAL_DATE_TIME, \"yyyy_MM_dd_HH_mm_ss\");\n+\t\t\tdefaultFormats.put(Types.SQL_TIMESTAMP, \"yyyy_MM_dd_HH_mm_ss\");\n+\t\t\tdefaultFormats.put(Types.LOCAL_DATE, \"yyyy_MM_dd\");\n+\t\t\tdefaultFormats.put(Types.SQL_DATE, \"yyyy_MM_dd\");\n+\t\t\tdefaultFormats.put(Types.LOCAL_TIME, \"HH_mm_ss\");\n+\t\t\tdefaultFormats.put(Types.SQL_TIME, \"HH_mm_ss\");", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDA2OTUwMQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410069501", "bodyText": "hyphen may lead  truncation issue and elasitcsearch recommends underscore in index name   and field name.", "author": "leonardBang", "createdAt": "2020-04-17T08:24:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAyODY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzMTIxMw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410031213", "bodyText": "Why use index when indexField is null? For example, prefix_{my_field}_index, if my_field is null, the generated index will be prefix_prefix_{my_field}_index_index which is confusing.\nShound't we just drop this record if the field is null?", "author": "wuchong", "createdAt": "2020-04-17T07:06:13Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/index/IndexGeneratorFactory.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch.index;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Factory of {@link IndexGenerator}.\n+ *\n+ * <p>Flink supports both static index and dynamic index.\n+ *\n+ * <p>If you want to have a static index, this option value should be a plain string, e.g. 'myusers',\n+ * all the records will be consistently written into \"myusers\" index.\n+ *\n+ * <p>If you want to have a dynamic index, you can use '{field_name}' to reference a field value in the\n+ * record to dynamically generate a target index. You can also use '{field_name|date_format_string}' to\n+ * convert a field value of TIMESTAMP/DATE/TIME type into the format specified by date_format_string. The\n+ * date_format_string is compatible with {@link java.text.SimpleDateFormat}. For example, if the option\n+ * value is 'myusers_{log_ts|yyyy-MM-dd}', then a record with log_ts field value 2020-03-27 12:25:55 will\n+ * be written into \"myusers-2020-03-27\" index.\n+ */\n+@Internal\n+public class IndexGeneratorFactory {\n+\n+\tprivate IndexGeneratorFactory() {}\n+\n+\tpublic static IndexGenerator createIndexGenerator(String index, TableSchema schema) {\n+\t\tfinal IndexHelper indexHelper = new IndexHelper();\n+\t\tif (indexHelper.checkIsDynamicIndex(index)) {\n+\t\t\treturn createRuntimeIndexGenerator(index, schema.getFieldNames(), schema.getFieldDataTypes(), indexHelper);\n+\t\t} else {\n+\t\t\treturn new DefaultIndexGenerator(index);\n+\t\t}\n+\t}\n+\n+\tprivate static IndexGenerator createRuntimeIndexGenerator(\n+\t\t\tString index,\n+\t\t\tString[] fieldNames,\n+\t\t\tDataType[] fieldTypes,\n+\t\t\tIndexHelper indexHelper) {\n+\t\tfinal String dynamicIndexPatternStr = indexHelper.extractDynamicIndexPatternStr(index);\n+\t\tfinal String indexPrefix = index.substring(0, index.indexOf(dynamicIndexPatternStr));\n+\t\tfinal String indexSuffix = index.substring(indexPrefix.length() + dynamicIndexPatternStr.length());\n+\n+\t\tfinal boolean isDynamicIndexWithFormat = indexHelper.checkIsDynamicIndexWithFormat(index);\n+\t\tfinal int indexFieldPos = indexHelper.extractIndexFieldPos(index, fieldNames, isDynamicIndexWithFormat);\n+\t\tfinal TypeInformation<?> indexFieldType = TypeConversions.fromDataTypeToLegacyInfo(fieldTypes[indexFieldPos]);\n+\n+\t\t// validate index field type\n+\t\tindexHelper.validateIndexFieldType(indexFieldType);\n+\n+\t\t// time extract dynamic index pattern\n+\t\tif (isDynamicIndexWithFormat) {\n+\t\t\tfinal String dateTimeFormat = indexHelper.extractDateFormat(index, indexFieldType);\n+\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\tif (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDateTime indexField = (LocalDateTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\telse if (indexFieldType == Types.SQL_TIMESTAMP) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTimestamp indexField = (Timestamp) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDateTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\t// DataTypes.SQL_DATE\n+\t\t\telse if (indexFieldType == Types.LOCAL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDate indexField = (LocalDate) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tDate indexField = (Date) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDate().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} // DataTypes.TIME\n+\t\t\telse if (indexFieldType == Types.LOCAL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalTime indexField = (LocalTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTime indexField = (Time) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else {\n+\t\t\t\tthrow new TableException(String.format(\"Unsupported type '%s' found in Elasticsearch dynamic index field, \" +\n+\t\t\t\t\t\"time-related pattern only support types are: %s\", indexFieldType, indexHelper.getSupportedDateTypes()));\n+\t\t\t}\n+\t\t}\n+\t\t// general dynamic index pattern\n+\t\treturn new DefaultIndexGenerator(index) {\n+\n+\t\t\t@Override\n+\t\t\tpublic String generate(Row row) {\n+\t\t\t\tObject indexField = row.getField(indexFieldPos);\n+\t\t\t\treturn indexPrefix.concat(indexField == null ? index : indexField.toString()).concat(indexSuffix);", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzOTQ4OA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410039488", "bodyText": "prefix_null_index", "author": "wuchong", "createdAt": "2020-04-17T07:24:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzMTIxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzMTY1NQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410031655", "bodyText": "new IndexGenerator {\n\n}\n\nThere is no need to override DefaultIndexGenerator.", "author": "wuchong", "createdAt": "2020-04-17T07:07:08Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/index/IndexGeneratorFactory.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch.index;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Factory of {@link IndexGenerator}.\n+ *\n+ * <p>Flink supports both static index and dynamic index.\n+ *\n+ * <p>If you want to have a static index, this option value should be a plain string, e.g. 'myusers',\n+ * all the records will be consistently written into \"myusers\" index.\n+ *\n+ * <p>If you want to have a dynamic index, you can use '{field_name}' to reference a field value in the\n+ * record to dynamically generate a target index. You can also use '{field_name|date_format_string}' to\n+ * convert a field value of TIMESTAMP/DATE/TIME type into the format specified by date_format_string. The\n+ * date_format_string is compatible with {@link java.text.SimpleDateFormat}. For example, if the option\n+ * value is 'myusers_{log_ts|yyyy-MM-dd}', then a record with log_ts field value 2020-03-27 12:25:55 will\n+ * be written into \"myusers-2020-03-27\" index.\n+ */\n+@Internal\n+public class IndexGeneratorFactory {\n+\n+\tprivate IndexGeneratorFactory() {}\n+\n+\tpublic static IndexGenerator createIndexGenerator(String index, TableSchema schema) {\n+\t\tfinal IndexHelper indexHelper = new IndexHelper();\n+\t\tif (indexHelper.checkIsDynamicIndex(index)) {\n+\t\t\treturn createRuntimeIndexGenerator(index, schema.getFieldNames(), schema.getFieldDataTypes(), indexHelper);\n+\t\t} else {\n+\t\t\treturn new DefaultIndexGenerator(index);\n+\t\t}\n+\t}\n+\n+\tprivate static IndexGenerator createRuntimeIndexGenerator(\n+\t\t\tString index,\n+\t\t\tString[] fieldNames,\n+\t\t\tDataType[] fieldTypes,\n+\t\t\tIndexHelper indexHelper) {\n+\t\tfinal String dynamicIndexPatternStr = indexHelper.extractDynamicIndexPatternStr(index);\n+\t\tfinal String indexPrefix = index.substring(0, index.indexOf(dynamicIndexPatternStr));\n+\t\tfinal String indexSuffix = index.substring(indexPrefix.length() + dynamicIndexPatternStr.length());\n+\n+\t\tfinal boolean isDynamicIndexWithFormat = indexHelper.checkIsDynamicIndexWithFormat(index);\n+\t\tfinal int indexFieldPos = indexHelper.extractIndexFieldPos(index, fieldNames, isDynamicIndexWithFormat);\n+\t\tfinal TypeInformation<?> indexFieldType = TypeConversions.fromDataTypeToLegacyInfo(fieldTypes[indexFieldPos]);\n+\n+\t\t// validate index field type\n+\t\tindexHelper.validateIndexFieldType(indexFieldType);\n+\n+\t\t// time extract dynamic index pattern\n+\t\tif (isDynamicIndexWithFormat) {\n+\t\t\tfinal String dateTimeFormat = indexHelper.extractDateFormat(index, indexFieldType);\n+\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\tif (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDateTime indexField = (LocalDateTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\telse if (indexFieldType == Types.SQL_TIMESTAMP) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTimestamp indexField = (Timestamp) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDateTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\t// DataTypes.SQL_DATE\n+\t\t\telse if (indexFieldType == Types.LOCAL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDate indexField = (LocalDate) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tDate indexField = (Date) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDate().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} // DataTypes.TIME\n+\t\t\telse if (indexFieldType == Types.LOCAL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalTime indexField = (LocalTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTime indexField = (Time) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else {\n+\t\t\t\tthrow new TableException(String.format(\"Unsupported type '%s' found in Elasticsearch dynamic index field, \" +\n+\t\t\t\t\t\"time-related pattern only support types are: %s\", indexFieldType, indexHelper.getSupportedDateTypes()));\n+\t\t\t}\n+\t\t}\n+\t\t// general dynamic index pattern\n+\t\treturn new DefaultIndexGenerator(index) {", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzMTgzMA==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410031830", "bodyText": "Let's call it StaticIndexGenerator.", "author": "wuchong", "createdAt": "2020-04-17T07:07:31Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/index/DefaultIndexGenerator.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch.index;\n+\n+import org.apache.flink.types.Row;\n+\n+/**\n+ * Default IndexGenerator implements.\n+ */\n+public class DefaultIndexGenerator implements IndexGenerator {", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzMjM4Nw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410032387", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t * Generate index for each row dynamically, return the index value by default.\n          \n          \n            \n            \t * Generate index name according the the given row.", "author": "wuchong", "createdAt": "2020-04-17T07:08:33Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/index/IndexGenerator.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch.index;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * Interface to generate index from {@link Row}.\n+ */\n+@Internal\n+public interface IndexGenerator extends Serializable {\n+\n+\t/**\n+\t * Init the dateTimeFormatter if necessary in runtime.\n+\t */\n+\tdefault void open() {}\n+\n+\t/**\n+\t * Generate index for each row dynamically, return the index value by default.", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzMjk0NQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410032945", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t * Init the dateTimeFormatter if necessary in runtime.\n          \n          \n            \n            \t * Initialize the index generator, this will be called only once before {@link #generate(Row)} is called", "author": "wuchong", "createdAt": "2020-04-17T07:09:50Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/index/IndexGenerator.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch.index;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.types.Row;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * Interface to generate index from {@link Row}.\n+ */\n+@Internal\n+public interface IndexGenerator extends Serializable {\n+\n+\t/**\n+\t * Init the dateTimeFormatter if necessary in runtime.", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzMzQ0Nw==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410033447", "bodyText": "Move the open on top of process.", "author": "wuchong", "createdAt": "2020-04-17T07:10:56Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkFunction.java", "diffHunk": "@@ -69,4 +69,9 @@\n \t * @param indexer request indexer that {@code ActionRequest} should be added to\n \t */\n \tvoid process(T element, RuntimeContext ctx, RequestIndexer indexer);\n+\n+\t/**\n+\t *  General-purpose open method.\n+\t */\n+\tdefault void open() {}", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDAzMzcyOQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410033729", "bodyText": "Initialization method for the function. It is called before the actual working process methods.", "author": "wuchong", "createdAt": "2020-04-17T07:11:36Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/ElasticsearchSinkFunction.java", "diffHunk": "@@ -69,4 +69,9 @@\n \t * @param indexer request indexer that {@code ActionRequest} should be added to\n \t */\n \tvoid process(T element, RuntimeContext ctx, RequestIndexer indexer);\n+\n+\t/**\n+\t *  General-purpose open method.", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDA0MDg3OQ==", "url": "https://github.com/apache/flink/pull/11466#discussion_r410040879", "bodyText": "remove", "author": "wuchong", "createdAt": "2020-04-17T07:27:23Z", "path": "flink-connectors/flink-connector-elasticsearch-base/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/index/IndexGeneratorFactory.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.streaming.connectors.elasticsearch.index;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeinfo.TypeInformation;\n+import org.apache.flink.api.common.typeinfo.Types;\n+import org.apache.flink.table.api.TableException;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.types.DataType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n+import org.apache.flink.types.Row;\n+\n+import java.sql.Date;\n+import java.sql.Time;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Factory of {@link IndexGenerator}.\n+ *\n+ * <p>Flink supports both static index and dynamic index.\n+ *\n+ * <p>If you want to have a static index, this option value should be a plain string, e.g. 'myusers',\n+ * all the records will be consistently written into \"myusers\" index.\n+ *\n+ * <p>If you want to have a dynamic index, you can use '{field_name}' to reference a field value in the\n+ * record to dynamically generate a target index. You can also use '{field_name|date_format_string}' to\n+ * convert a field value of TIMESTAMP/DATE/TIME type into the format specified by date_format_string. The\n+ * date_format_string is compatible with {@link java.text.SimpleDateFormat}. For example, if the option\n+ * value is 'myusers_{log_ts|yyyy-MM-dd}', then a record with log_ts field value 2020-03-27 12:25:55 will\n+ * be written into \"myusers-2020-03-27\" index.\n+ */\n+@Internal\n+public class IndexGeneratorFactory {\n+\n+\tprivate IndexGeneratorFactory() {}\n+\n+\tpublic static IndexGenerator createIndexGenerator(String index, TableSchema schema) {\n+\t\tfinal IndexHelper indexHelper = new IndexHelper();\n+\t\tif (indexHelper.checkIsDynamicIndex(index)) {\n+\t\t\treturn createRuntimeIndexGenerator(index, schema.getFieldNames(), schema.getFieldDataTypes(), indexHelper);\n+\t\t} else {\n+\t\t\treturn new DefaultIndexGenerator(index);\n+\t\t}\n+\t}\n+\n+\tprivate static IndexGenerator createRuntimeIndexGenerator(\n+\t\t\tString index,\n+\t\t\tString[] fieldNames,\n+\t\t\tDataType[] fieldTypes,\n+\t\t\tIndexHelper indexHelper) {\n+\t\tfinal String dynamicIndexPatternStr = indexHelper.extractDynamicIndexPatternStr(index);\n+\t\tfinal String indexPrefix = index.substring(0, index.indexOf(dynamicIndexPatternStr));\n+\t\tfinal String indexSuffix = index.substring(indexPrefix.length() + dynamicIndexPatternStr.length());\n+\n+\t\tfinal boolean isDynamicIndexWithFormat = indexHelper.checkIsDynamicIndexWithFormat(index);\n+\t\tfinal int indexFieldPos = indexHelper.extractIndexFieldPos(index, fieldNames, isDynamicIndexWithFormat);\n+\t\tfinal TypeInformation<?> indexFieldType = TypeConversions.fromDataTypeToLegacyInfo(fieldTypes[indexFieldPos]);\n+\n+\t\t// validate index field type\n+\t\tindexHelper.validateIndexFieldType(indexFieldType);\n+\n+\t\t// time extract dynamic index pattern\n+\t\tif (isDynamicIndexWithFormat) {\n+\t\t\tfinal String dateTimeFormat = indexHelper.extractDateFormat(index, indexFieldType);\n+\t\t\t// DataTypes.SQL_TIMESTAMP\n+\t\t\tif (indexFieldType == Types.LOCAL_DATE_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDateTime indexField = (LocalDateTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\telse if (indexFieldType == Types.SQL_TIMESTAMP) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTimestamp indexField = (Timestamp) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDateTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t}\n+\t\t\t// DataTypes.SQL_DATE\n+\t\t\telse if (indexFieldType == Types.LOCAL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalDate indexField = (LocalDate) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_DATE) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tDate indexField = (Date) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalDate().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} // DataTypes.TIME\n+\t\t\telse if (indexFieldType == Types.LOCAL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tLocalTime indexField = (LocalTime) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else if (indexFieldType == Types.SQL_TIME) {\n+\t\t\t\treturn new AbstractTimeIndexGenerator(dateTimeFormat) {\n+\t\t\t\t\t@Override\n+\t\t\t\t\tpublic String generate(Row row) {\n+\t\t\t\t\t\tTime indexField = (Time) row.getField(indexFieldPos);\n+\t\t\t\t\t\tString indexFieldValueStr = indexField.toLocalTime().format(dateTimeFormatter);\n+\t\t\t\t\t\treturn indexPrefix.concat(indexFieldValueStr).concat(indexSuffix);\n+\t\t\t\t\t}\n+\t\t\t\t};\n+\t\t\t} else {\n+\t\t\t\tthrow new TableException(String.format(\"Unsupported type '%s' found in Elasticsearch dynamic index field, \" +\n+\t\t\t\t\t\"time-related pattern only support types are: %s\", indexFieldType, indexHelper.getSupportedDateTypes()));\n+\t\t\t}\n+\t\t}\n+\t\t// general dynamic index pattern\n+\t\treturn new DefaultIndexGenerator(index) {\n+\n+\t\t\t@Override\n+\t\t\tpublic String generate(Row row) {\n+\t\t\t\tObject indexField = row.getField(indexFieldPos);\n+\t\t\t\treturn indexPrefix.concat(indexField == null ? index : indexField.toString()).concat(indexSuffix);\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\t/**\n+\t * Helper class for {@link IndexGeneratorFactory}, this helper can use to validate index field type\n+\t * ans parse index format from pattern.\n+\t */\n+\tprivate static class IndexHelper {\n+\t\tprivate static final Pattern dynamicIndexPattern = Pattern.compile(\"\\\\{[^\\\\{\\\\}]+\\\\}?\");\n+\t\tprivate static final Pattern dynamicIndexTimeExtractPattern = Pattern.compile(\".*\\\\{.+\\\\|.*\\\\}.*\");\n+\t\tprivate static final List<TypeInformation> supportedTypes = new ArrayList<>();\n+\t\tprivate static final Map<TypeInformation, String> defaultFormats = new HashMap<>();\n+\n+\t\tstatic {\n+\t\t\t//time related types\n+\t\t\tsupportedTypes.add(Types.LOCAL_DATE_TIME);\n+\t\t\tsupportedTypes.add(Types.SQL_TIMESTAMP);\n+\t\t\tsupportedTypes.add(Types.LOCAL_DATE);\n+\t\t\tsupportedTypes.add(Types.SQL_DATE);\n+\t\t\tsupportedTypes.add(Types.LOCAL_TIME);\n+\t\t\tsupportedTypes.add(Types.SQL_TIME);\n+\t\t\t//general types\n+\t\t\tsupportedTypes.add(Types.STRING);\n+\t\t\tsupportedTypes.add(Types.SHORT);\n+\t\t\tsupportedTypes.add(Types.INT);\n+\t\t\tsupportedTypes.add(Types.LONG);\n+\t\t}\n+\n+\t\tstatic {\n+\t\t\tdefaultFormats.put(Types.LOCAL_DATE_TIME, \"yyyy_MM_dd_HH_mm_ss\");\n+\t\t\tdefaultFormats.put(Types.SQL_TIMESTAMP, \"yyyy_MM_dd_HH_mm_ss\");\n+\t\t\tdefaultFormats.put(Types.LOCAL_DATE, \"yyyy_MM_dd\");\n+\t\t\tdefaultFormats.put(Types.SQL_DATE, \"yyyy_MM_dd\");\n+\t\t\tdefaultFormats.put(Types.LOCAL_TIME, \"HH_mm_ss\");\n+\t\t\tdefaultFormats.put(Types.SQL_TIME, \"HH_mm_ss\");\n+\t\t}\n+\n+\t\t/**\n+\t\t * Validate the index field Type.\n+\t\t */\n+\t\tvoid validateIndexFieldType(TypeInformation indexTypeInfo) {\n+\t\t\tif (!supportedTypes.contains(indexTypeInfo)) {\n+\t\t\t\tthrow new IllegalArgumentException(String.format(\"Unsupported type %s of index field, \" +\n+\t\t\t\t\t\"Supported types are: %s\", indexTypeInfo, supportedTypes));\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Get the default date format.\n+\t\t */\n+\t\tString getDefaultFormat(TypeInformation indexTypeInfo) {\n+\t\t\treturn defaultFormats.get(indexTypeInfo);\n+\t\t}\n+\n+\t\t/**\n+\t\t * Get the supported date related types.\n+\t\t */\n+\t\tString getSupportedDateTypes() {", "originalCommit": "c015b198415d8077f1782e949036cb07bbaa044c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7999653a0fd426a2edff271a87a5a69f4e1c54dc", "url": "https://github.com/apache/flink/commit/7999653a0fd426a2edff271a87a5a69f4e1c54dc", "message": "address comments", "committedDate": "2020-04-17T08:25:56Z", "type": "commit"}, {"oid": "7999653a0fd426a2edff271a87a5a69f4e1c54dc", "url": "https://github.com/apache/flink/commit/7999653a0fd426a2edff271a87a5a69f4e1c54dc", "message": "address comments", "committedDate": "2020-04-17T08:25:56Z", "type": "forcePushed"}]}