{"pr_number": 10847, "pr_title": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink", "pr_createdAt": "2020-01-13T23:49:10Z", "pr_url": "https://github.com/apache/flink/pull/10847", "timeline": [{"oid": "3e136166db3c3a2325a4014719ca011b4d162a4d", "url": "https://github.com/apache/flink/commit/3e136166db3c3a2325a4014719ca011b4d162a4d", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC", "committedDate": "2020-01-14T07:33:05Z", "type": "forcePushed"}, {"oid": "3c3f7e4329383accb9b940c950321e0c65bdc0b9", "url": "https://github.com/apache/flink/commit/3c3f7e4329383accb9b940c950321e0c65bdc0b9", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC", "committedDate": "2020-01-14T15:00:02Z", "type": "forcePushed"}, {"oid": "c3cffe7d4d81d49b62327a0fca7fc12bb412403c", "url": "https://github.com/apache/flink/commit/c3cffe7d4d81d49b62327a0fca7fc12bb412403c", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC", "committedDate": "2020-01-21T13:17:14Z", "type": "forcePushed"}, {"oid": "21f8b53a2b914b3cfc5f2b284682e168522fedb7", "url": "https://github.com/apache/flink/commit/21f8b53a2b914b3cfc5f2b284682e168522fedb7", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC", "committedDate": "2020-01-23T14:44:30Z", "type": "forcePushed"}, {"oid": "2a7d5e55530eb275ffb276cead3516f3da9623a8", "url": "https://github.com/apache/flink/commit/2a7d5e55530eb275ffb276cead3516f3da9623a8", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC", "committedDate": "2020-01-23T17:30:17Z", "type": "forcePushed"}, {"oid": "f98852fdb3b64d694e4dcfd9510b6b65294f9ea6", "url": "https://github.com/apache/flink/commit/f98852fdb3b64d694e4dcfd9510b6b65294f9ea6", "message": "[FLINK-15578][docs] add streaming API documentation for JDBC", "committedDate": "2020-01-24T14:49:14Z", "type": "forcePushed"}, {"oid": "62eee77afbff0cdabceffeab6e737633af15a4fc", "url": "https://github.com/apache/flink/commit/62eee77afbff0cdabceffeab6e737633af15a4fc", "message": "[FLINK-15578][docs][connectors/jdbc] add streaming API documentation for JDBC", "committedDate": "2020-01-24T20:10:30Z", "type": "forcePushed"}, {"oid": "b2d552291f80b750912f037fc2a64698aa1dc34f", "url": "https://github.com/apache/flink/commit/b2d552291f80b750912f037fc2a64698aa1dc34f", "message": "[FLINK-15578][docs][connectors/jdbc] add streaming API documentation for JDBC", "committedDate": "2020-01-29T13:44:26Z", "type": "forcePushed"}, {"oid": "63956a5e617a61fe592dc6c5bb62e615392f9535", "url": "https://github.com/apache/flink/commit/63956a5e617a61fe592dc6c5bb62e615392f9535", "message": "[FLINK-15578][docs][connectors/jdbc] document exactly once JDBC sink", "committedDate": "2020-01-29T17:12:56Z", "type": "forcePushed"}, {"oid": "b55a17559f8bbd427788152fdc5a2e79e273ad7a", "url": "https://github.com/apache/flink/commit/b55a17559f8bbd427788152fdc5a2e79e273ad7a", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2020-11-29T20:39:44Z", "type": "forcePushed"}, {"oid": "693e48ac1e9cd413f54e7cbc4c46b9ae190ce848", "url": "https://github.com/apache/flink/commit/693e48ac1e9cd413f54e7cbc4c46b9ae190ce848", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2020-11-29T21:20:11Z", "type": "forcePushed"}, {"oid": "b31871fbbbfa073c1f28e591dee7dee95c37a8d8", "url": "https://github.com/apache/flink/commit/b31871fbbbfa073c1f28e591dee7dee95c37a8d8", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2020-11-30T06:40:27Z", "type": "forcePushed"}, {"oid": "46042bff26813c15199ebe6fc9a9d3c1dd4e5860", "url": "https://github.com/apache/flink/commit/46042bff26813c15199ebe6fc9a9d3c1dd4e5860", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2020-11-30T06:41:57Z", "type": "forcePushed"}, {"oid": "1a5d68a1e74c02bb85534ffdde081fcb03d70917", "url": "https://github.com/apache/flink/commit/1a5d68a1e74c02bb85534ffdde081fcb03d70917", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2020-11-30T07:30:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzQ5MTQ3Mg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r537491472", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Since 1.13, Flink JDBC sink supports exactly-once mode. The implementation relies on the JDBC driver support of XA [standard](https://pubs.opengroup.org/onlinepubs/009680699/toc.pdf).\n          \n          \n            \n            Flink also comes with a JDBC sink that supports exactly-once mode. The implementation relies on the JDBC driver support of XA [standard](https://pubs.opengroup.org/onlinepubs/009680699/toc.pdf).", "author": "aljoscha", "createdAt": "2020-12-07T13:06:12Z", "path": "docs/dev/connectors/jdbc.md", "diffHunk": "@@ -65,3 +62,42 @@ env.execute();\n {% endhighlight %}\n \n Please refer to the [API documentation]({{ site.javadocs_baseurl }}/api/java/org/apache/flink/connector/jdbc/JdbcSink.html) for more details.\n+\n+## Exactly-once\n+\n+Since 1.13, Flink JDBC sink supports exactly-once mode. The implementation relies on the JDBC driver support of XA [standard](https://pubs.opengroup.org/onlinepubs/009680699/toc.pdf).", "originalCommit": "1a5d68a1e74c02bb85534ffdde081fcb03d70917", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzQ5MTgxNg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r537491816", "bodyText": "What does \"Semantic\" mean in this class?", "author": "aljoscha", "createdAt": "2020-12-07T13:06:39Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/SemanticXidGenerator.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.RuntimeContext;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.security.SecureRandom;\n+\n+/**\n+ * Generates {@link Xid} from:\n+ * <ol>\n+ *     <li>checkpoint id</li>\n+ *     <li>subtask index</li>\n+ *     <li>4 random bytes to provide uniqueness across other jobs and apps (generated at startup using {@link SecureRandom})</li>\n+ * </ol>\n+ * Each {@link SemanticXidGenerator} instance MUST be used for only one Sink (otherwise Xids could collide).\n+ */\n+@Internal\n+class SemanticXidGenerator implements XidGenerator {", "originalCommit": "1a5d68a1e74c02bb85534ffdde081fcb03d70917", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzU2NDM0Mg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r537564342", "bodyText": "It generates XIDs based on subtask index and checkpoint, as opposed to fully random or sequential transaction IDs for example in Kafka.\nRevisiting this class, I think that RuntimeContextXidGenerator would probably be a better name.\nWDYT?", "author": "rkhachatryan", "createdAt": "2020-12-07T14:48:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzQ5MTgxNg=="}], "type": "inlineReview"}, {"oid": "44c02d892bb4e1393ad45ce69e9624b58278ded4", "url": "https://github.com/apache/flink/commit/44c02d892bb4e1393ad45ce69e9624b58278ded4", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2020-12-28T10:07:51Z", "type": "forcePushed"}, {"oid": "ed4de0e7b5f268c387e0c15d205842936596d943", "url": "https://github.com/apache/flink/commit/ed4de0e7b5f268c387e0c15d205842936596d943", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2020-12-28T14:07:26Z", "type": "forcePushed"}, {"oid": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "url": "https://github.com/apache/flink/commit/23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2020-12-30T17:38:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMjE5OA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550422198", "bodyText": "I think we can use StringUtils.byteToHexString(bytes) here to avoid duplicate implementation.", "author": "wuchong", "createdAt": "2020-12-31T07:56:41Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XidImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.Nonnull;\n+import javax.transaction.xa.Xid;\n+\n+import java.io.Serializable;\n+import java.util.Arrays;\n+import java.util.Objects;\n+\n+/**\n+ * A simple {@link Xid} implementation that stores branch and global transaction identifiers as byte\n+ * arrays.\n+ */\n+@Internal\n+final class XidImpl implements Xid, Serializable {\n+\n+    private final int formatId;\n+    @Nonnull private final byte[] globalTransactionId;\n+    @Nonnull private final byte[] branchQualifier;\n+\n+    XidImpl(int formatId, byte[] globalTransactionId, byte[] branchQualifier) {\n+        Preconditions.checkArgument(globalTransactionId.length <= Xid.MAXGTRIDSIZE);\n+        Preconditions.checkArgument(branchQualifier.length <= Xid.MAXBQUALSIZE);\n+        this.formatId = formatId;\n+        this.globalTransactionId = Arrays.copyOf(globalTransactionId, globalTransactionId.length);\n+        this.branchQualifier = Arrays.copyOf(branchQualifier, branchQualifier.length);\n+    }\n+\n+    @Override\n+    public int getFormatId() {\n+        return formatId;\n+    }\n+\n+    @Override\n+    public byte[] getGlobalTransactionId() {\n+        return globalTransactionId;\n+    }\n+\n+    @Override\n+    public byte[] getBranchQualifier() {\n+        return branchQualifier;\n+    }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+        if (this == o) {\n+            return true;\n+        }\n+        if (!(o instanceof XidImpl)) {\n+            return false;\n+        }\n+        XidImpl xid = (XidImpl) o;\n+        return formatId == xid.formatId\n+                && Arrays.equals(globalTransactionId, xid.globalTransactionId)\n+                && Arrays.equals(branchQualifier, xid.branchQualifier);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        int result = Objects.hash(formatId);\n+        result = 31 * result + Arrays.hashCode(globalTransactionId);\n+        result = 31 * result + Arrays.hashCode(branchQualifier);\n+        return result;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return formatId + \":\" + bytesToHex(globalTransactionId) + \":\" + bytesToHex(branchQualifier);", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMjMxMQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550422311", "bodyText": "Add a serialVersionUID to the class?", "author": "wuchong", "createdAt": "2020-12-31T07:57:18Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XidImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.util.Preconditions;\n+\n+import javax.annotation.Nonnull;\n+import javax.transaction.xa.Xid;\n+\n+import java.io.Serializable;\n+import java.util.Arrays;\n+import java.util.Objects;\n+\n+/**\n+ * A simple {@link Xid} implementation that stores branch and global transaction identifiers as byte\n+ * arrays.\n+ */\n+@Internal\n+final class XidImpl implements Xid, Serializable {", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMjc0MA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550422740", "bodyText": "Condition obj == this covered by subsequent condition obj instanceof XidSerializer, we can remove obj == this here.", "author": "wuchong", "createdAt": "2020-12-31T07:59:48Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XidSerializer.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.SimpleTypeSerializerSnapshot;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+\n+/** {@link Xid} serializer. */\n+@Internal\n+final class XidSerializer extends TypeSerializer<Xid> {\n+\n+    private static final TypeSerializerSnapshot<Xid> SNAPSHOT =\n+            new SimpleTypeSerializerSnapshot<Xid>(XidSerializer::new) {\n+                private static final int VERSION = 1;\n+\n+                @Override\n+                public void writeSnapshot(DataOutputView out) throws IOException {\n+                    super.writeSnapshot(out);\n+                    out.writeInt(VERSION);\n+                }\n+\n+                @Override\n+                public void readSnapshot(int readVersion, DataInputView in, ClassLoader classLoader)\n+                        throws IOException {\n+                    super.readSnapshot(readVersion, in, classLoader);\n+                    in.readInt();\n+                }\n+            };\n+\n+    @Override\n+    public boolean isImmutableType() {\n+        return true;\n+    }\n+\n+    @Override\n+    public TypeSerializer<Xid> duplicate() {\n+        return this;\n+    }\n+\n+    @Override\n+    public Xid createInstance() {\n+        return new XidImpl(0, new byte[0], new byte[0]);\n+    }\n+\n+    @Override\n+    public Xid copy(Xid from) {\n+        return from;\n+    }\n+\n+    @Override\n+    public Xid copy(Xid from, Xid reuse) {\n+        return from;\n+    }\n+\n+    @Override\n+    public int getLength() {\n+        return -1;\n+    }\n+\n+    @Override\n+    public void serialize(Xid xid, DataOutputView target) throws IOException {\n+        target.writeInt(xid.getFormatId());\n+        writeBytesWithSize(target, xid.getGlobalTransactionId());\n+        writeBytesWithSize(target, xid.getBranchQualifier());\n+    }\n+\n+    @Override\n+    public Xid deserialize(DataInputView source) throws IOException {\n+        return new XidImpl(source.readInt(), readBytesWithSize(source), readBytesWithSize(source));\n+    }\n+\n+    private void writeBytesWithSize(DataOutputView target, byte[] bytes) throws IOException {\n+        target.writeByte(bytes.length);\n+        target.write(bytes, 0, bytes.length);\n+    }\n+\n+    private byte[] readBytesWithSize(DataInputView source) throws IOException {\n+        byte len = source.readByte();\n+        byte[] bytes = new byte[len];\n+        source.read(bytes, 0, len);\n+        return bytes;\n+    }\n+\n+    @Override\n+    public Xid deserialize(Xid reuse, DataInputView source) throws IOException {\n+        return deserialize(source);\n+    }\n+\n+    @Override\n+    public void copy(DataInputView source, DataOutputView target) throws IOException {\n+        serialize(deserialize(source), target);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        return obj == this || obj instanceof XidSerializer;", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMjgzNA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550422834", "bodyText": "Better to return this.getClass().hashCode();.", "author": "wuchong", "createdAt": "2020-12-31T08:00:32Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XidSerializer.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.SimpleTypeSerializerSnapshot;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+\n+/** {@link Xid} serializer. */\n+@Internal\n+final class XidSerializer extends TypeSerializer<Xid> {\n+\n+    private static final TypeSerializerSnapshot<Xid> SNAPSHOT =\n+            new SimpleTypeSerializerSnapshot<Xid>(XidSerializer::new) {\n+                private static final int VERSION = 1;\n+\n+                @Override\n+                public void writeSnapshot(DataOutputView out) throws IOException {\n+                    super.writeSnapshot(out);\n+                    out.writeInt(VERSION);\n+                }\n+\n+                @Override\n+                public void readSnapshot(int readVersion, DataInputView in, ClassLoader classLoader)\n+                        throws IOException {\n+                    super.readSnapshot(readVersion, in, classLoader);\n+                    in.readInt();\n+                }\n+            };\n+\n+    @Override\n+    public boolean isImmutableType() {\n+        return true;\n+    }\n+\n+    @Override\n+    public TypeSerializer<Xid> duplicate() {\n+        return this;\n+    }\n+\n+    @Override\n+    public Xid createInstance() {\n+        return new XidImpl(0, new byte[0], new byte[0]);\n+    }\n+\n+    @Override\n+    public Xid copy(Xid from) {\n+        return from;\n+    }\n+\n+    @Override\n+    public Xid copy(Xid from, Xid reuse) {\n+        return from;\n+    }\n+\n+    @Override\n+    public int getLength() {\n+        return -1;\n+    }\n+\n+    @Override\n+    public void serialize(Xid xid, DataOutputView target) throws IOException {\n+        target.writeInt(xid.getFormatId());\n+        writeBytesWithSize(target, xid.getGlobalTransactionId());\n+        writeBytesWithSize(target, xid.getBranchQualifier());\n+    }\n+\n+    @Override\n+    public Xid deserialize(DataInputView source) throws IOException {\n+        return new XidImpl(source.readInt(), readBytesWithSize(source), readBytesWithSize(source));\n+    }\n+\n+    private void writeBytesWithSize(DataOutputView target, byte[] bytes) throws IOException {\n+        target.writeByte(bytes.length);\n+        target.write(bytes, 0, bytes.length);\n+    }\n+\n+    private byte[] readBytesWithSize(DataInputView source) throws IOException {\n+        byte len = source.readByte();\n+        byte[] bytes = new byte[len];\n+        source.read(bytes, 0, len);\n+        return bytes;\n+    }\n+\n+    @Override\n+    public Xid deserialize(Xid reuse, DataInputView source) throws IOException {\n+        return deserialize(source);\n+    }\n+\n+    @Override\n+    public void copy(DataInputView source, DataOutputView target) throws IOException {\n+        serialize(deserialize(source), target);\n+    }\n+\n+    @Override\n+    public boolean equals(Object obj) {\n+        return obj == this || obj instanceof XidSerializer;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return 0;", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMzkwMg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550423902", "bodyText": "Could we add a test scope to this? And move this one and the following one under the <!-- test dependencies -->.", "author": "wuchong", "createdAt": "2020-12-31T08:06:49Z", "path": "flink-connectors/flink-connector-jdbc/pom.xml", "diffHunk": "@@ -55,7 +55,15 @@ under the License.\n \t\t\t<groupId>org.apache.flink</groupId>\n \t\t\t<artifactId>flink-streaming-java_${scala.binary.version}</artifactId>\n \t\t\t<version>${project.version}</version>\n-\t\t\t<scope>provided</scope>\n+\t\t\t<type>test-jar</type>", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMzk3MA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550423970", "bodyText": "I think this is only used for testing, could we change the scope to test?", "author": "wuchong", "createdAt": "2020-12-31T08:07:12Z", "path": "flink-connectors/flink-connector-jdbc/pom.xml", "diffHunk": "@@ -92,6 +100,19 @@ under the License.\n \t\t\t<scope>test</scope>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>javax.transaction</groupId>\n+\t\t\t<artifactId>javax.transaction-api</artifactId>\n+\t\t\t<version>1.3</version>\n+\t\t</dependency>\n+\n+\t\t<dependency>\n+\t\t\t<groupId>com.h2database</groupId>\n+\t\t\t<artifactId>h2</artifactId>\n+\t\t\t<version>1.4.200</version>\n+\t\t\t<scope>compile</scope>", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDIzNTg0Mg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r554235842", "bodyText": "Yes, you're right.", "author": "rkhachatryan", "createdAt": "2021-01-08T22:54:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyMzk3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNDAxMQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550424011", "bodyText": "What classes do we depend on this dependency?", "author": "wuchong", "createdAt": "2020-12-31T08:07:32Z", "path": "flink-connectors/flink-connector-jdbc/pom.xml", "diffHunk": "@@ -92,6 +100,19 @@ under the License.\n \t\t\t<scope>test</scope>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>javax.transaction</groupId>\n+\t\t\t<artifactId>javax.transaction-api</artifactId>\n+\t\t\t<version>1.3</version>", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDIzODUzMg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r554238532", "bodyText": "It isn't needed actually, I removed it. Thanks for pointing out.", "author": "rkhachatryan", "createdAt": "2021-01-08T23:02:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNDAxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNTMxNw==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550425317", "bodyText": "This loses the restored information?", "author": "wuchong", "createdAt": "2020-12-31T08:15:28Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/CheckpointAndXidSerializer.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.SimpleTypeSerializerSnapshot;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+/** {@link CheckpointAndXid} serializer. */\n+@Internal\n+final class CheckpointAndXidSerializer extends TypeSerializer<CheckpointAndXid> {\n+\n+    private static final TypeSerializerSnapshot<CheckpointAndXid> SNAPSHOT =\n+            new SimpleTypeSerializerSnapshot<CheckpointAndXid>(CheckpointAndXidSerializer::new) {\n+                private static final int VERSION = 1;\n+\n+                @Override\n+                public void writeSnapshot(DataOutputView out) throws IOException {\n+                    super.writeSnapshot(out);\n+                    out.writeInt(VERSION);\n+                }\n+\n+                @Override\n+                public void readSnapshot(int readVersion, DataInputView in, ClassLoader classLoader)\n+                        throws IOException {\n+                    super.readSnapshot(readVersion, in, classLoader);\n+                    in.readInt();\n+                }\n+            };\n+\n+    private final TypeSerializer<Xid> xidSerializer = new XidSerializer();\n+\n+    @Override\n+    public boolean isImmutableType() {\n+        return xidSerializer.isImmutableType();\n+    }\n+\n+    @Override\n+    public TypeSerializer<CheckpointAndXid> duplicate() {\n+        return this;\n+    }\n+\n+    @Override\n+    public CheckpointAndXid createInstance() {\n+        return CheckpointAndXid.createRestored(0L, 0, xidSerializer.createInstance());\n+    }\n+\n+    @Override\n+    public CheckpointAndXid copy(CheckpointAndXid from) {\n+        return CheckpointAndXid.createRestored(\n+                from.checkpointId, from.attempts, xidSerializer.copy(from.xid));", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mzk1MDg5NA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r553950894", "bodyText": "Existing restored value is not used because createRestored() always uses true.", "author": "rkhachatryan", "createdAt": "2021-01-08T13:44:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNTMxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNTgzMg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550425832", "bodyText": "Why don't we serialize the restored flag?", "author": "wuchong", "createdAt": "2020-12-31T08:18:02Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/CheckpointAndXidSerializer.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.typeutils.SimpleTypeSerializerSnapshot;\n+import org.apache.flink.api.common.typeutils.TypeSerializer;\n+import org.apache.flink.api.common.typeutils.TypeSerializerSnapshot;\n+import org.apache.flink.core.memory.DataInputView;\n+import org.apache.flink.core.memory.DataOutputView;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+/** {@link CheckpointAndXid} serializer. */\n+@Internal\n+final class CheckpointAndXidSerializer extends TypeSerializer<CheckpointAndXid> {\n+\n+    private static final TypeSerializerSnapshot<CheckpointAndXid> SNAPSHOT =\n+            new SimpleTypeSerializerSnapshot<CheckpointAndXid>(CheckpointAndXidSerializer::new) {\n+                private static final int VERSION = 1;\n+\n+                @Override\n+                public void writeSnapshot(DataOutputView out) throws IOException {\n+                    super.writeSnapshot(out);\n+                    out.writeInt(VERSION);\n+                }\n+\n+                @Override\n+                public void readSnapshot(int readVersion, DataInputView in, ClassLoader classLoader)\n+                        throws IOException {\n+                    super.readSnapshot(readVersion, in, classLoader);\n+                    in.readInt();\n+                }\n+            };\n+\n+    private final TypeSerializer<Xid> xidSerializer = new XidSerializer();\n+\n+    @Override\n+    public boolean isImmutableType() {\n+        return xidSerializer.isImmutableType();\n+    }\n+\n+    @Override\n+    public TypeSerializer<CheckpointAndXid> duplicate() {\n+        return this;\n+    }\n+\n+    @Override\n+    public CheckpointAndXid createInstance() {\n+        return CheckpointAndXid.createRestored(0L, 0, xidSerializer.createInstance());\n+    }\n+\n+    @Override\n+    public CheckpointAndXid copy(CheckpointAndXid from) {\n+        return CheckpointAndXid.createRestored(\n+                from.checkpointId, from.attempts, xidSerializer.copy(from.xid));\n+    }\n+\n+    @Override\n+    public CheckpointAndXid copy(CheckpointAndXid from, CheckpointAndXid reuse) {\n+        return from;\n+    }\n+\n+    @Override\n+    public int getLength() {\n+        return -1;\n+    }\n+\n+    @Override\n+    public void serialize(CheckpointAndXid record, DataOutputView target) throws IOException {\n+        target.writeLong(record.checkpointId);\n+        target.writeInt(record.attempts);", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Mzk1MzY2OA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r553953668", "bodyText": "Because it will forcibly set to true on restore.", "author": "rkhachatryan", "createdAt": "2021-01-08T13:49:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQyNTgzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzMTc1Nw==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550431757", "bodyText": "I think this can be simply supported by calling close() and open() ?", "author": "wuchong", "createdAt": "2020-12-31T08:49:44Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XaFacadeImpl.java", "diffHunk": "@@ -0,0 +1,453 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.util.FlinkRuntimeException;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingRunnable;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import javax.sql.XAConnection;\n+import javax.sql.XADataSource;\n+import javax.transaction.xa.XAException;\n+import javax.transaction.xa.XAResource;\n+import javax.transaction.xa.Xid;\n+\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+import static java.util.Optional.empty;\n+import static java.util.Optional.of;\n+import static javax.transaction.xa.XAException.XAER_NOTA;\n+import static javax.transaction.xa.XAException.XAER_RMFAIL;\n+import static javax.transaction.xa.XAException.XA_HEURCOM;\n+import static javax.transaction.xa.XAException.XA_HEURHAZ;\n+import static javax.transaction.xa.XAException.XA_HEURMIX;\n+import static javax.transaction.xa.XAException.XA_HEURRB;\n+import static javax.transaction.xa.XAException.XA_RBBASE;\n+import static javax.transaction.xa.XAException.XA_RBTIMEOUT;\n+import static javax.transaction.xa.XAException.XA_RBTRANSIENT;\n+import static javax.transaction.xa.XAResource.TMENDRSCAN;\n+import static javax.transaction.xa.XAResource.TMNOFLAGS;\n+import static javax.transaction.xa.XAResource.TMSTARTRSCAN;\n+\n+/** Default {@link XaFacade} implementation. */\n+@NotThreadSafe\n+@Internal\n+class XaFacadeImpl implements XaFacade {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(XaFacadeImpl.class);\n+    private static final Set<Integer> TRANSIENT_ERR_CODES =\n+            new HashSet<>(Arrays.asList(XA_RBTRANSIENT, XAER_RMFAIL));\n+    private static final Set<Integer> HEUR_ERR_CODES =\n+            new HashSet<>(Arrays.asList(XA_HEURRB, XA_HEURCOM, XA_HEURHAZ, XA_HEURMIX));\n+    private static final int MAX_RECOVER_CALLS = 100;\n+\n+    private final Supplier<XADataSource> dataSourceSupplier;\n+    private final Integer timeoutSec;\n+    private transient XAResource xaResource;\n+    private transient Connection connection;\n+    private transient XAConnection xaConnection;\n+\n+    /** @return a non-serializable instance. */\n+    static XaFacadeImpl fromXaDataSource(XADataSource ds) {\n+        return new XaFacadeImpl(() -> ds, empty());\n+    }\n+\n+    XaFacadeImpl(Supplier<XADataSource> dataSourceSupplier, Optional<Integer> timeoutSec) {\n+        this.dataSourceSupplier = Preconditions.checkNotNull(dataSourceSupplier);\n+        this.timeoutSec = timeoutSec.orElse(null);\n+    }\n+\n+    @Override\n+    public void open() throws SQLException, XAException {\n+        Preconditions.checkState(!isOpen(), \"already connected\");\n+        XADataSource ds = dataSourceSupplier.get();\n+        xaConnection = ds.getXAConnection();\n+        xaResource = xaConnection.getXAResource();\n+        if (timeoutSec != null) {\n+            xaResource.setTransactionTimeout(timeoutSec);\n+        }\n+        connection = xaConnection.getConnection();\n+        connection.setReadOnly(false);\n+        connection.setAutoCommit(false);\n+        Preconditions.checkState(!connection.getAutoCommit());\n+    }\n+\n+    @Override\n+    public void close() throws SQLException {\n+        if (connection != null) {\n+            connection.close();\n+            connection = null;\n+        }\n+        if (xaConnection != null) {\n+            xaConnection.close();\n+            xaConnection = null;\n+        }\n+        xaResource = null;\n+    }\n+\n+    @Override\n+    public Connection getConnection() {\n+        Preconditions.checkNotNull(connection);\n+        return connection;\n+    }\n+\n+    @Override\n+    public boolean isConnectionValid() {\n+        return isOpen();\n+    }\n+\n+    @Override\n+    public Connection getOrEstablishConnection() throws SQLException, ClassNotFoundException {\n+        if (!isOpen()) {\n+            try {\n+                open();\n+            } catch (XAException e) {\n+                throw new SQLException(e);\n+            }\n+        }\n+        return connection;\n+    }\n+\n+    @Override\n+    public void closeConnection() {\n+        try {\n+            close();\n+        } catch (SQLException e) {\n+            LOG.warn(\"Connection close failed.\", e);\n+        }\n+    }\n+\n+    @Override\n+    public Connection reestablishConnection() {\n+        throw new UnsupportedOperationException();", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDExMDA3NQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r554110075", "bodyText": "I'm afraid not: a potential ongoing XA transaction should be resumed (or at least aborted).\nThis would require either passing Xid from the outside or storing current Xid in this class. I'd rather avoid both of these options because they either complicate the caller or duplicate Xid tracking.", "author": "rkhachatryan", "createdAt": "2021-01-08T18:12:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzMTc1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzMzM5OQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550433399", "bodyText": "Should use connection.isValid to check the validation?", "author": "wuchong", "createdAt": "2020-12-31T08:58:25Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XaFacadeImpl.java", "diffHunk": "@@ -0,0 +1,453 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.util.FlinkRuntimeException;\n+import org.apache.flink.util.Preconditions;\n+import org.apache.flink.util.function.ThrowingRunnable;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import javax.sql.XAConnection;\n+import javax.sql.XADataSource;\n+import javax.transaction.xa.XAException;\n+import javax.transaction.xa.XAResource;\n+import javax.transaction.xa.Xid;\n+\n+import java.sql.Connection;\n+import java.sql.SQLException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.Callable;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+\n+import static java.util.Optional.empty;\n+import static java.util.Optional.of;\n+import static javax.transaction.xa.XAException.XAER_NOTA;\n+import static javax.transaction.xa.XAException.XAER_RMFAIL;\n+import static javax.transaction.xa.XAException.XA_HEURCOM;\n+import static javax.transaction.xa.XAException.XA_HEURHAZ;\n+import static javax.transaction.xa.XAException.XA_HEURMIX;\n+import static javax.transaction.xa.XAException.XA_HEURRB;\n+import static javax.transaction.xa.XAException.XA_RBBASE;\n+import static javax.transaction.xa.XAException.XA_RBTIMEOUT;\n+import static javax.transaction.xa.XAException.XA_RBTRANSIENT;\n+import static javax.transaction.xa.XAResource.TMENDRSCAN;\n+import static javax.transaction.xa.XAResource.TMNOFLAGS;\n+import static javax.transaction.xa.XAResource.TMSTARTRSCAN;\n+\n+/** Default {@link XaFacade} implementation. */\n+@NotThreadSafe\n+@Internal\n+class XaFacadeImpl implements XaFacade {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(XaFacadeImpl.class);\n+    private static final Set<Integer> TRANSIENT_ERR_CODES =\n+            new HashSet<>(Arrays.asList(XA_RBTRANSIENT, XAER_RMFAIL));\n+    private static final Set<Integer> HEUR_ERR_CODES =\n+            new HashSet<>(Arrays.asList(XA_HEURRB, XA_HEURCOM, XA_HEURHAZ, XA_HEURMIX));\n+    private static final int MAX_RECOVER_CALLS = 100;\n+\n+    private final Supplier<XADataSource> dataSourceSupplier;\n+    private final Integer timeoutSec;\n+    private transient XAResource xaResource;\n+    private transient Connection connection;\n+    private transient XAConnection xaConnection;\n+\n+    /** @return a non-serializable instance. */\n+    static XaFacadeImpl fromXaDataSource(XADataSource ds) {\n+        return new XaFacadeImpl(() -> ds, empty());\n+    }\n+\n+    XaFacadeImpl(Supplier<XADataSource> dataSourceSupplier, Optional<Integer> timeoutSec) {\n+        this.dataSourceSupplier = Preconditions.checkNotNull(dataSourceSupplier);\n+        this.timeoutSec = timeoutSec.orElse(null);\n+    }\n+\n+    @Override\n+    public void open() throws SQLException, XAException {\n+        Preconditions.checkState(!isOpen(), \"already connected\");\n+        XADataSource ds = dataSourceSupplier.get();\n+        xaConnection = ds.getXAConnection();\n+        xaResource = xaConnection.getXAResource();\n+        if (timeoutSec != null) {\n+            xaResource.setTransactionTimeout(timeoutSec);\n+        }\n+        connection = xaConnection.getConnection();\n+        connection.setReadOnly(false);\n+        connection.setAutoCommit(false);\n+        Preconditions.checkState(!connection.getAutoCommit());\n+    }\n+\n+    @Override\n+    public void close() throws SQLException {\n+        if (connection != null) {\n+            connection.close();\n+            connection = null;\n+        }\n+        if (xaConnection != null) {\n+            xaConnection.close();\n+            xaConnection = null;\n+        }\n+        xaResource = null;\n+    }\n+\n+    @Override\n+    public Connection getConnection() {\n+        Preconditions.checkNotNull(connection);\n+        return connection;\n+    }\n+\n+    @Override\n+    public boolean isConnectionValid() {\n+        return isOpen();", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzNTkxNg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550435916", "bodyText": "Add @PublicEvolving annotation?", "author": "wuchong", "createdAt": "2020-12-31T09:11:21Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExactlyOnceOptions.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc;\n+\n+import org.apache.flink.util.Preconditions;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+\n+/**\n+ * JDBC exactly once sink options.\n+ *\n+ * <p><b>maxCommitAttempts</b> - maximum number of commit attempts to make per transaction; must be\n+ * > 0; state size is proportional to the product of max number of in-flight snapshots and this\n+ * number.\n+ *\n+ * <p><b>allowOutOfOrderCommits</b> - If true, all prepared transactions will be attempted to commit\n+ * regardless of any transient failures during this operation. This may lead to inconsistency.\n+ * Default: false.\n+ *\n+ * <p><b>recoveredAndRollback</b> - whether to rollback prepared transactions known to XA RM on\n+ * startup (after committing <b>known</b> transactions, i.e. restored from state).\n+ *\n+ * <p>NOTE that setting this parameter to true may:\n+ *\n+ * <ol>\n+ *   <li>interfere with other subtasks or applications (one subtask rolling back transactions\n+ *       prepared by the other one (and known to it))\n+ *   <li>block when using with some non-MVCC databases, if there are ended-not-prepared transactions\n+ * </ol>\n+ *\n+ * See also {@link org.apache.flink.connector.jdbc.xa.XaFacade#recover()}\n+ */\n+public class JdbcExactlyOnceOptions implements Serializable {", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzOTU5Mg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550439592", "bodyText": "Does the hangingXids have to be a Deque to keep the order? If yes, I'm wondering the state recovery doesn't retain the order.", "author": "wuchong", "createdAt": "2020-12-31T09:29:23Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.\n+ *\n+ * <p>XA uses a two-phase commit protocol, which solves the consistency problem, but leaves the\n+ * following issues:\n+ *\n+ * <ol>\n+ *   <li>transactions may be abandoned, holding resources (e.g. locks, versions of rows)\n+ *   <li>abandoned transactions collide with the new transactions if their IDs repeat after recovery\n+ *   <li>commit requests may be repeated after job recovery, resulting in error responses and job\n+ *       failure\n+ * </ol>\n+ *\n+ * The following table summarizes effects of failures during transaction state transitions and ways\n+ * to mitigate them:\n+ *\n+ * <table border=\"1\" style=\"width:100%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:30%;\">\n+ * <col span=\"1\" style=\"width:40%;\">\n+ * <thead>\n+ * <tr>\n+ * <th>Transition</th>\n+ * <th>Methods</th>\n+ * <th>What happens if transition lost</th>\n+ * <th>Ways to mitigate</th>\n+ * </tr>\n+ * </thead>\n+ * <tbody>\n+ * <tr>\n+ * <td>none &gt; started, started &gt; ended</td>\n+ * <td>open(), snapshotState()</td>\n+ * <td>Database eventually discards these transactions</td>\n+ * <td><ol>\n+ * <li>Use globally unique XIDs</li>\n+ * <li>derive XID from: checkpoint id, subtask id, \"job id\", \"run id\" (see {@link SemanticXidGenerator}).</li>\n+ * </ol></td>\n+ * </tr>\n+ * <tr>\n+ * <td>ended &gt; prepared</td>\n+ * <td>snapshotState()</td>\n+ * <td>Database keeps these transactions prepared forever (\"in-doubt\" state)</td>\n+ * <td>\n+ * <ol>\n+ * <li>store ended transactions in state; rollback on job recovery (still doesn't cover all scenarios)</li>\n+ * <li>call xa_recover() and xa_rollback() on job recovery; disabled by default in order not to affect transactions of other subtasks and apps</li>\n+ * <li>setting transaction timeouts (not supported by most databases)</li>\n+ * <li>manual recovery and rollback</li>\n+ * </ol>\n+ * </td>\n+ * </tr>\n+ * <tr>\n+ * <td>prepared &gt; committed</td>\n+ * <td>open(), notifyCheckpointComplete()</td>\n+ * <td>\n+ * Upon job recovery state contains committed transactions; or JM may notifyCheckpointComplete again after recovery.\n+ * <p>Committing results in {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} error.</p>\n+ * </td>\n+ * <td>\n+ * Distinguish between transactions created during this run and restored from state and ignore {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} for the latter.\n+ * </td>\n+ * </tr>\n+ * </tbody>\n+ * </table>\n+ *\n+ * @since 1.11\n+ */\n+@Internal\n+public class JdbcXaSinkFunction<T> extends AbstractRichFunction\n+        implements CheckpointedFunction, CheckpointListener, SinkFunction<T>, AutoCloseable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(JdbcXaSinkFunction.class);\n+\n+    private final XaFacade xaFacade;\n+    private final XaGroupOps xaGroupOps;\n+    private final XidGenerator xidGenerator;\n+    private final JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format;\n+    private final XaSinkStateHandler stateHandler;\n+    private final JdbcExactlyOnceOptions options;\n+\n+    // checkpoints and the corresponding transactions waiting for completion notification from JM\n+    private transient List<CheckpointAndXid> preparedXids = new ArrayList<>();\n+    // hanging XIDs - used for cleanup\n+    // it's a list to support retries and scaling down\n+    // possible transaction states: active, idle, prepared\n+    // last element is the current xid\n+    private transient Deque<Xid> hangingXids = new LinkedList<>();\n+    private transient Xid currentXid;\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     */\n+    public JdbcXaSinkFunction(\n+            String sql,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            XaFacade xaFacade,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcExactlyOnceOptions options) {\n+        this(\n+                new JdbcBatchingOutputFormat<>(\n+                        xaFacade,\n+                        executionOptions,\n+                        context -> {\n+                            Preconditions.checkState(\n+                                    !context.getExecutionConfig().isObjectReuseEnabled(),\n+                                    \"objects can not be reused with JDBC sink function\");\n+                            return JdbcBatchStatementExecutor.simple(\n+                                    sql, statementBuilder, Function.identity());\n+                        },\n+                        JdbcBatchingOutputFormat.RecordExtractor.identity()),\n+                xaFacade,\n+                XidGenerator.semanticXidGenerator(),\n+                new XaSinkStateHandlerImpl(),\n+                options,\n+                new XaGroupOpsImpl(xaFacade));\n+    }\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param format {@link JdbcBatchingOutputFormat} to write records with\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     * @param xidGenerator {@link XidGenerator} to generate new transaction ids\n+     */\n+    public JdbcXaSinkFunction(\n+            JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format,\n+            XaFacade xaFacade,\n+            XidGenerator xidGenerator,\n+            XaSinkStateHandler stateHandler,\n+            JdbcExactlyOnceOptions options,\n+            XaGroupOps xaGroupOps) {\n+        this.xaFacade = Preconditions.checkNotNull(xaFacade);\n+        this.xidGenerator = Preconditions.checkNotNull(xidGenerator);\n+        this.format = Preconditions.checkNotNull(format);\n+        this.stateHandler = Preconditions.checkNotNull(stateHandler);\n+        this.options = Preconditions.checkNotNull(options);\n+        this.xaGroupOps = xaGroupOps;\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        JdbcXaSinkFunctionState state = stateHandler.load(context);\n+        hangingXids = new LinkedList<>(state.getHanging());", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDEyMTIwMQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r554121201", "bodyText": "Deque is used to keep the current Xid the last; otherwise the order is not important.\n\nthe state recovery doesn't retain the order.\n\nCould you explain what do you mean?", "author": "rkhachatryan", "createdAt": "2021-01-08T18:35:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzOTU5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQzOTcyNQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550439725", "bodyText": "nit: would be better to call this outputFormat to avoid confusing with formats, e.g. csv, json.", "author": "wuchong", "createdAt": "2020-12-31T09:30:07Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.\n+ *\n+ * <p>XA uses a two-phase commit protocol, which solves the consistency problem, but leaves the\n+ * following issues:\n+ *\n+ * <ol>\n+ *   <li>transactions may be abandoned, holding resources (e.g. locks, versions of rows)\n+ *   <li>abandoned transactions collide with the new transactions if their IDs repeat after recovery\n+ *   <li>commit requests may be repeated after job recovery, resulting in error responses and job\n+ *       failure\n+ * </ol>\n+ *\n+ * The following table summarizes effects of failures during transaction state transitions and ways\n+ * to mitigate them:\n+ *\n+ * <table border=\"1\" style=\"width:100%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:30%;\">\n+ * <col span=\"1\" style=\"width:40%;\">\n+ * <thead>\n+ * <tr>\n+ * <th>Transition</th>\n+ * <th>Methods</th>\n+ * <th>What happens if transition lost</th>\n+ * <th>Ways to mitigate</th>\n+ * </tr>\n+ * </thead>\n+ * <tbody>\n+ * <tr>\n+ * <td>none &gt; started, started &gt; ended</td>\n+ * <td>open(), snapshotState()</td>\n+ * <td>Database eventually discards these transactions</td>\n+ * <td><ol>\n+ * <li>Use globally unique XIDs</li>\n+ * <li>derive XID from: checkpoint id, subtask id, \"job id\", \"run id\" (see {@link SemanticXidGenerator}).</li>\n+ * </ol></td>\n+ * </tr>\n+ * <tr>\n+ * <td>ended &gt; prepared</td>\n+ * <td>snapshotState()</td>\n+ * <td>Database keeps these transactions prepared forever (\"in-doubt\" state)</td>\n+ * <td>\n+ * <ol>\n+ * <li>store ended transactions in state; rollback on job recovery (still doesn't cover all scenarios)</li>\n+ * <li>call xa_recover() and xa_rollback() on job recovery; disabled by default in order not to affect transactions of other subtasks and apps</li>\n+ * <li>setting transaction timeouts (not supported by most databases)</li>\n+ * <li>manual recovery and rollback</li>\n+ * </ol>\n+ * </td>\n+ * </tr>\n+ * <tr>\n+ * <td>prepared &gt; committed</td>\n+ * <td>open(), notifyCheckpointComplete()</td>\n+ * <td>\n+ * Upon job recovery state contains committed transactions; or JM may notifyCheckpointComplete again after recovery.\n+ * <p>Committing results in {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} error.</p>\n+ * </td>\n+ * <td>\n+ * Distinguish between transactions created during this run and restored from state and ignore {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} for the latter.\n+ * </td>\n+ * </tr>\n+ * </tbody>\n+ * </table>\n+ *\n+ * @since 1.11\n+ */\n+@Internal\n+public class JdbcXaSinkFunction<T> extends AbstractRichFunction\n+        implements CheckpointedFunction, CheckpointListener, SinkFunction<T>, AutoCloseable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(JdbcXaSinkFunction.class);\n+\n+    private final XaFacade xaFacade;\n+    private final XaGroupOps xaGroupOps;\n+    private final XidGenerator xidGenerator;\n+    private final JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format;", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0NTAzMA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550445030", "bodyText": "Will this break the state consistent that hangingXids.peek() should equal to currentXid?", "author": "wuchong", "createdAt": "2020-12-31T09:55:57Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.\n+ *\n+ * <p>XA uses a two-phase commit protocol, which solves the consistency problem, but leaves the\n+ * following issues:\n+ *\n+ * <ol>\n+ *   <li>transactions may be abandoned, holding resources (e.g. locks, versions of rows)\n+ *   <li>abandoned transactions collide with the new transactions if their IDs repeat after recovery\n+ *   <li>commit requests may be repeated after job recovery, resulting in error responses and job\n+ *       failure\n+ * </ol>\n+ *\n+ * The following table summarizes effects of failures during transaction state transitions and ways\n+ * to mitigate them:\n+ *\n+ * <table border=\"1\" style=\"width:100%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:30%;\">\n+ * <col span=\"1\" style=\"width:40%;\">\n+ * <thead>\n+ * <tr>\n+ * <th>Transition</th>\n+ * <th>Methods</th>\n+ * <th>What happens if transition lost</th>\n+ * <th>Ways to mitigate</th>\n+ * </tr>\n+ * </thead>\n+ * <tbody>\n+ * <tr>\n+ * <td>none &gt; started, started &gt; ended</td>\n+ * <td>open(), snapshotState()</td>\n+ * <td>Database eventually discards these transactions</td>\n+ * <td><ol>\n+ * <li>Use globally unique XIDs</li>\n+ * <li>derive XID from: checkpoint id, subtask id, \"job id\", \"run id\" (see {@link SemanticXidGenerator}).</li>\n+ * </ol></td>\n+ * </tr>\n+ * <tr>\n+ * <td>ended &gt; prepared</td>\n+ * <td>snapshotState()</td>\n+ * <td>Database keeps these transactions prepared forever (\"in-doubt\" state)</td>\n+ * <td>\n+ * <ol>\n+ * <li>store ended transactions in state; rollback on job recovery (still doesn't cover all scenarios)</li>\n+ * <li>call xa_recover() and xa_rollback() on job recovery; disabled by default in order not to affect transactions of other subtasks and apps</li>\n+ * <li>setting transaction timeouts (not supported by most databases)</li>\n+ * <li>manual recovery and rollback</li>\n+ * </ol>\n+ * </td>\n+ * </tr>\n+ * <tr>\n+ * <td>prepared &gt; committed</td>\n+ * <td>open(), notifyCheckpointComplete()</td>\n+ * <td>\n+ * Upon job recovery state contains committed transactions; or JM may notifyCheckpointComplete again after recovery.\n+ * <p>Committing results in {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} error.</p>\n+ * </td>\n+ * <td>\n+ * Distinguish between transactions created during this run and restored from state and ignore {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} for the latter.\n+ * </td>\n+ * </tr>\n+ * </tbody>\n+ * </table>\n+ *\n+ * @since 1.11\n+ */\n+@Internal\n+public class JdbcXaSinkFunction<T> extends AbstractRichFunction\n+        implements CheckpointedFunction, CheckpointListener, SinkFunction<T>, AutoCloseable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(JdbcXaSinkFunction.class);\n+\n+    private final XaFacade xaFacade;\n+    private final XaGroupOps xaGroupOps;\n+    private final XidGenerator xidGenerator;\n+    private final JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format;\n+    private final XaSinkStateHandler stateHandler;\n+    private final JdbcExactlyOnceOptions options;\n+\n+    // checkpoints and the corresponding transactions waiting for completion notification from JM\n+    private transient List<CheckpointAndXid> preparedXids = new ArrayList<>();\n+    // hanging XIDs - used for cleanup\n+    // it's a list to support retries and scaling down\n+    // possible transaction states: active, idle, prepared\n+    // last element is the current xid\n+    private transient Deque<Xid> hangingXids = new LinkedList<>();\n+    private transient Xid currentXid;\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     */\n+    public JdbcXaSinkFunction(\n+            String sql,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            XaFacade xaFacade,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcExactlyOnceOptions options) {\n+        this(\n+                new JdbcBatchingOutputFormat<>(\n+                        xaFacade,\n+                        executionOptions,\n+                        context -> {\n+                            Preconditions.checkState(\n+                                    !context.getExecutionConfig().isObjectReuseEnabled(),\n+                                    \"objects can not be reused with JDBC sink function\");\n+                            return JdbcBatchStatementExecutor.simple(\n+                                    sql, statementBuilder, Function.identity());\n+                        },\n+                        JdbcBatchingOutputFormat.RecordExtractor.identity()),\n+                xaFacade,\n+                XidGenerator.semanticXidGenerator(),\n+                new XaSinkStateHandlerImpl(),\n+                options,\n+                new XaGroupOpsImpl(xaFacade));\n+    }\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param format {@link JdbcBatchingOutputFormat} to write records with\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     * @param xidGenerator {@link XidGenerator} to generate new transaction ids\n+     */\n+    public JdbcXaSinkFunction(\n+            JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format,\n+            XaFacade xaFacade,\n+            XidGenerator xidGenerator,\n+            XaSinkStateHandler stateHandler,\n+            JdbcExactlyOnceOptions options,\n+            XaGroupOps xaGroupOps) {\n+        this.xaFacade = Preconditions.checkNotNull(xaFacade);\n+        this.xidGenerator = Preconditions.checkNotNull(xidGenerator);\n+        this.format = Preconditions.checkNotNull(format);\n+        this.stateHandler = Preconditions.checkNotNull(stateHandler);\n+        this.options = Preconditions.checkNotNull(options);\n+        this.xaGroupOps = xaGroupOps;\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        JdbcXaSinkFunctionState state = stateHandler.load(context);\n+        hangingXids = new LinkedList<>(state.getHanging());\n+        preparedXids = new ArrayList<>(state.getPrepared());\n+        LOG.info(\n+                \"initialized state: prepared xids: {}, hanging xids: {}\",\n+                preparedXids.size(),\n+                hangingXids.size());\n+    }\n+\n+    @Override\n+    public void open(Configuration configuration) throws Exception {\n+        super.open(configuration);\n+        xidGenerator.open();\n+        xaFacade.open();\n+        format.setRuntimeContext(getRuntimeContext());\n+        format.open(\n+                getRuntimeContext().getIndexOfThisSubtask(),\n+                getRuntimeContext().getNumberOfParallelSubtasks());\n+        hangingXids = new LinkedList<>(xaGroupOps.failOrRollback(hangingXids).getForRetry());\n+        commitUpToCheckpoint(Optional.empty());\n+        if (options.isDiscoverAndRollbackOnRecovery()) {\n+            // todo: consider doing recover-rollback later (e.g. after the 1st checkpoint)\n+            // when we are sure that all other subtasks started and committed any of their prepared\n+            // transactions\n+            // this would require to distinguish between this job Xids and other Xids\n+            xaGroupOps.recoverAndRollback();\n+        }\n+        beginTx(0L);\n+    }\n+\n+    @Override\n+    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n+        LOG.debug(\"snapshot state, checkpointId={}\", context.getCheckpointId());\n+        rollbackPreparedFromCheckpoint(context.getCheckpointId());\n+        prepareCurrentTx(context.getCheckpointId());\n+        beginTx(context.getCheckpointId() + 1);\n+        stateHandler.store(of(preparedXids, hangingXids));\n+    }\n+\n+    @Override\n+    public void notifyCheckpointComplete(long checkpointId) {\n+        commitUpToCheckpoint(Optional.of(checkpointId));\n+    }\n+\n+    @Override\n+    public void invoke(T value, Context context) throws IOException {\n+        Preconditions.checkState(currentXid != null, \"current xid must not be null\");\n+        if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"invoke, xid: {}, value: {}\", currentXid, value);\n+        }\n+        format.writeRecord(value);\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+        super.close();\n+        if (currentXid != null && xaFacade.isOpen()) {\n+            try {\n+                LOG.debug(\"remove current transaction before closing, xid={}\", currentXid);\n+                xaFacade.failOrRollback(currentXid);\n+            } catch (Exception e) {\n+                LOG.warn(\"unable to fail/rollback current transaction, xid={}\", currentXid, e);\n+            }\n+        }\n+        xaFacade.close();\n+        xidGenerator.close();\n+        // don't format.close(); as we don't want neither to flush nor to close connection here\n+        currentXid = null;\n+        hangingXids = null;\n+        preparedXids = null;\n+    }\n+\n+    private void prepareCurrentTx(long checkpointId) throws IOException {\n+        Preconditions.checkState(currentXid != null, \"no current xid\");\n+        Preconditions.checkState(\n+                !hangingXids.isEmpty() && hangingXids.peek().equals(currentXid),\n+                \"inconsistent internal state\");\n+        hangingXids.poll();\n+        format.flush();\n+        try {\n+            xaFacade.endAndPrepare(currentXid);\n+            preparedXids.add(CheckpointAndXid.createNew(checkpointId, currentXid));\n+        } catch (EmptyXaTransactionException e) {\n+            LOG.info(\n+                    \"empty XA transaction (skip), xid: {}, checkpoint {}\",\n+                    currentXid,\n+                    checkpointId);\n+        }\n+        currentXid = null;\n+    }\n+\n+    /** @param checkpointId to associate with the new transaction. */\n+    private void beginTx(long checkpointId) {\n+        Preconditions.checkState(currentXid == null, \"currentXid not null\");\n+        currentXid = xidGenerator.generateXid(getRuntimeContext(), checkpointId);\n+        hangingXids.offer(currentXid);\n+        xaFacade.start(currentXid);\n+    }\n+\n+    private void commitUpToCheckpoint(Optional<Long> checkpointInclusive) {\n+        Tuple2<List<CheckpointAndXid>, List<CheckpointAndXid>> splittedXids =\n+                split(preparedXids, checkpointInclusive, true);\n+        if (splittedXids.f0.isEmpty()) {\n+            checkpointInclusive.ifPresent(\n+                    cp -> LOG.warn(\"nothing to commit up to checkpoint: {}\", cp));\n+        } else {\n+            preparedXids = splittedXids.f1;\n+            preparedXids.addAll(\n+                    xaGroupOps\n+                            .commit(\n+                                    splittedXids.f0,\n+                                    options.isAllowOutOfOrderCommits(),\n+                                    options.getMaxCommitAttempts())\n+                            .getForRetry());\n+        }\n+    }\n+\n+    private void rollbackPreparedFromCheckpoint(long fromCheckpointInclusive) {\n+        Tuple2<List<CheckpointAndXid>, List<CheckpointAndXid>> splittedXids =\n+                split(preparedXids, fromCheckpointInclusive, false);\n+        if (splittedXids.f1.isEmpty()) {\n+            return;\n+        }\n+        preparedXids = splittedXids.f0;\n+        LOG.warn(\n+                \"state snapshots have already been taken for checkpoint >= {}, rolling back {} transactions\",\n+                fromCheckpointInclusive,\n+                splittedXids.f1.size());\n+        xaGroupOps\n+                .failOrRollback(\n+                        splittedXids.f1.stream()\n+                                .map(CheckpointAndXid::getXid)\n+                                .collect(Collectors.toList()))\n+                .getForRetry()\n+                .forEach(hangingXids::offerFirst);", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDEyNTc0MA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r554125740", "bodyText": "Yes, you're right!", "author": "rkhachatryan", "createdAt": "2021-01-08T18:44:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0NTAzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0NzczMA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550447730", "bodyText": "Could you add Javadocs on the configuration mehtods about what are the configs used for?", "author": "wuchong", "createdAt": "2020-12-31T10:08:56Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcExactlyOnceOptions.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc;\n+\n+import org.apache.flink.util.Preconditions;\n+\n+import java.io.Serializable;\n+import java.util.Optional;\n+\n+/**\n+ * JDBC exactly once sink options.\n+ *\n+ * <p><b>maxCommitAttempts</b> - maximum number of commit attempts to make per transaction; must be\n+ * > 0; state size is proportional to the product of max number of in-flight snapshots and this\n+ * number.\n+ *\n+ * <p><b>allowOutOfOrderCommits</b> - If true, all prepared transactions will be attempted to commit\n+ * regardless of any transient failures during this operation. This may lead to inconsistency.\n+ * Default: false.\n+ *\n+ * <p><b>recoveredAndRollback</b> - whether to rollback prepared transactions known to XA RM on\n+ * startup (after committing <b>known</b> transactions, i.e. restored from state).\n+ *\n+ * <p>NOTE that setting this parameter to true may:\n+ *\n+ * <ol>\n+ *   <li>interfere with other subtasks or applications (one subtask rolling back transactions\n+ *       prepared by the other one (and known to it))\n+ *   <li>block when using with some non-MVCC databases, if there are ended-not-prepared transactions\n+ * </ol>\n+ *\n+ * See also {@link org.apache.flink.connector.jdbc.xa.XaFacade#recover()}\n+ */\n+public class JdbcExactlyOnceOptions implements Serializable {\n+\n+    private static final boolean DEFAULT_RECOVERED_AND_ROLLBACK = false;\n+    private static final int DEFAULT_MAX_COMMIT_ATTEMPTS = 3;\n+    private static final boolean DEFAULT_ALLOW_OUT_OF_ORDER_COMMITS = false;\n+\n+    private final boolean discoverAndRollbackOnRecovery;\n+    private final int maxCommitAttempts;\n+    private final boolean allowOutOfOrderCommits;\n+    private final Integer timeoutSec;\n+\n+    private JdbcExactlyOnceOptions(\n+            boolean discoverAndRollbackOnRecovery,\n+            int maxCommitAttempts,\n+            boolean allowOutOfOrderCommits,\n+            Optional<Integer> timeoutSec) {\n+        this.discoverAndRollbackOnRecovery = discoverAndRollbackOnRecovery;\n+        this.maxCommitAttempts = maxCommitAttempts;\n+        this.allowOutOfOrderCommits = allowOutOfOrderCommits;\n+        this.timeoutSec = timeoutSec.orElse(null);\n+        Preconditions.checkArgument(this.maxCommitAttempts > 0, \"maxCommitAttempts should be > 0\");\n+    }\n+\n+    public static JdbcExactlyOnceOptions defaults() {\n+        return builder().build();\n+    }\n+\n+    public boolean isDiscoverAndRollbackOnRecovery() {\n+        return discoverAndRollbackOnRecovery;\n+    }\n+\n+    public boolean isAllowOutOfOrderCommits() {\n+        return allowOutOfOrderCommits;\n+    }\n+\n+    public int getMaxCommitAttempts() {\n+        return maxCommitAttempts;\n+    }\n+\n+    public Integer getTimeoutSec() {\n+        return timeoutSec;\n+    }\n+\n+    public static JDBCExactlyOnceOptionsBuilder builder() {\n+        return new JDBCExactlyOnceOptionsBuilder();\n+    }\n+\n+    /** JDBCExactlyOnceOptionsBuilder. */\n+    public static class JDBCExactlyOnceOptionsBuilder {\n+        private boolean recoveredAndRollback = DEFAULT_RECOVERED_AND_ROLLBACK;\n+        private int maxCommitAttempts = DEFAULT_MAX_COMMIT_ATTEMPTS;\n+        private boolean allowOutOfOrderCommits = DEFAULT_ALLOW_OUT_OF_ORDER_COMMITS;\n+        private Optional<Integer> timeoutSec = Optional.empty();\n+\n+        public JDBCExactlyOnceOptionsBuilder withRecoveredAndRollback(", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDEyNjU2Mw==", "url": "https://github.com/apache/flink/pull/10847#discussion_r554126563", "bodyText": "Sure, good point", "author": "rkhachatryan", "createdAt": "2021-01-08T18:46:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0NzczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0ODg4NQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550448885", "bodyText": "I have some questions:\n\nWill this leave some retry Xids in the preparedXids?\nIf the job is failed, will the job restart the checkpoint from checkpoint: 0?\nIf yes, will the retry Xids in the preparedXids not be comitted for a long time?", "author": "wuchong", "createdAt": "2020-12-31T10:15:01Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.\n+ *\n+ * <p>XA uses a two-phase commit protocol, which solves the consistency problem, but leaves the\n+ * following issues:\n+ *\n+ * <ol>\n+ *   <li>transactions may be abandoned, holding resources (e.g. locks, versions of rows)\n+ *   <li>abandoned transactions collide with the new transactions if their IDs repeat after recovery\n+ *   <li>commit requests may be repeated after job recovery, resulting in error responses and job\n+ *       failure\n+ * </ol>\n+ *\n+ * The following table summarizes effects of failures during transaction state transitions and ways\n+ * to mitigate them:\n+ *\n+ * <table border=\"1\" style=\"width:100%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:15%;\">\n+ * <col span=\"1\" style=\"width:30%;\">\n+ * <col span=\"1\" style=\"width:40%;\">\n+ * <thead>\n+ * <tr>\n+ * <th>Transition</th>\n+ * <th>Methods</th>\n+ * <th>What happens if transition lost</th>\n+ * <th>Ways to mitigate</th>\n+ * </tr>\n+ * </thead>\n+ * <tbody>\n+ * <tr>\n+ * <td>none &gt; started, started &gt; ended</td>\n+ * <td>open(), snapshotState()</td>\n+ * <td>Database eventually discards these transactions</td>\n+ * <td><ol>\n+ * <li>Use globally unique XIDs</li>\n+ * <li>derive XID from: checkpoint id, subtask id, \"job id\", \"run id\" (see {@link SemanticXidGenerator}).</li>\n+ * </ol></td>\n+ * </tr>\n+ * <tr>\n+ * <td>ended &gt; prepared</td>\n+ * <td>snapshotState()</td>\n+ * <td>Database keeps these transactions prepared forever (\"in-doubt\" state)</td>\n+ * <td>\n+ * <ol>\n+ * <li>store ended transactions in state; rollback on job recovery (still doesn't cover all scenarios)</li>\n+ * <li>call xa_recover() and xa_rollback() on job recovery; disabled by default in order not to affect transactions of other subtasks and apps</li>\n+ * <li>setting transaction timeouts (not supported by most databases)</li>\n+ * <li>manual recovery and rollback</li>\n+ * </ol>\n+ * </td>\n+ * </tr>\n+ * <tr>\n+ * <td>prepared &gt; committed</td>\n+ * <td>open(), notifyCheckpointComplete()</td>\n+ * <td>\n+ * Upon job recovery state contains committed transactions; or JM may notifyCheckpointComplete again after recovery.\n+ * <p>Committing results in {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} error.</p>\n+ * </td>\n+ * <td>\n+ * Distinguish between transactions created during this run and restored from state and ignore {@link javax.transaction.xa.XAException#XAER_NOTA XAER_NOTA} for the latter.\n+ * </td>\n+ * </tr>\n+ * </tbody>\n+ * </table>\n+ *\n+ * @since 1.11\n+ */\n+@Internal\n+public class JdbcXaSinkFunction<T> extends AbstractRichFunction\n+        implements CheckpointedFunction, CheckpointListener, SinkFunction<T>, AutoCloseable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(JdbcXaSinkFunction.class);\n+\n+    private final XaFacade xaFacade;\n+    private final XaGroupOps xaGroupOps;\n+    private final XidGenerator xidGenerator;\n+    private final JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format;\n+    private final XaSinkStateHandler stateHandler;\n+    private final JdbcExactlyOnceOptions options;\n+\n+    // checkpoints and the corresponding transactions waiting for completion notification from JM\n+    private transient List<CheckpointAndXid> preparedXids = new ArrayList<>();\n+    // hanging XIDs - used for cleanup\n+    // it's a list to support retries and scaling down\n+    // possible transaction states: active, idle, prepared\n+    // last element is the current xid\n+    private transient Deque<Xid> hangingXids = new LinkedList<>();\n+    private transient Xid currentXid;\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     */\n+    public JdbcXaSinkFunction(\n+            String sql,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            XaFacade xaFacade,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcExactlyOnceOptions options) {\n+        this(\n+                new JdbcBatchingOutputFormat<>(\n+                        xaFacade,\n+                        executionOptions,\n+                        context -> {\n+                            Preconditions.checkState(\n+                                    !context.getExecutionConfig().isObjectReuseEnabled(),\n+                                    \"objects can not be reused with JDBC sink function\");\n+                            return JdbcBatchStatementExecutor.simple(\n+                                    sql, statementBuilder, Function.identity());\n+                        },\n+                        JdbcBatchingOutputFormat.RecordExtractor.identity()),\n+                xaFacade,\n+                XidGenerator.semanticXidGenerator(),\n+                new XaSinkStateHandlerImpl(),\n+                options,\n+                new XaGroupOpsImpl(xaFacade));\n+    }\n+\n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param format {@link JdbcBatchingOutputFormat} to write records with\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     * @param xidGenerator {@link XidGenerator} to generate new transaction ids\n+     */\n+    public JdbcXaSinkFunction(\n+            JdbcBatchingOutputFormat<T, T, JdbcBatchStatementExecutor<T>> format,\n+            XaFacade xaFacade,\n+            XidGenerator xidGenerator,\n+            XaSinkStateHandler stateHandler,\n+            JdbcExactlyOnceOptions options,\n+            XaGroupOps xaGroupOps) {\n+        this.xaFacade = Preconditions.checkNotNull(xaFacade);\n+        this.xidGenerator = Preconditions.checkNotNull(xidGenerator);\n+        this.format = Preconditions.checkNotNull(format);\n+        this.stateHandler = Preconditions.checkNotNull(stateHandler);\n+        this.options = Preconditions.checkNotNull(options);\n+        this.xaGroupOps = xaGroupOps;\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        JdbcXaSinkFunctionState state = stateHandler.load(context);\n+        hangingXids = new LinkedList<>(state.getHanging());\n+        preparedXids = new ArrayList<>(state.getPrepared());\n+        LOG.info(\n+                \"initialized state: prepared xids: {}, hanging xids: {}\",\n+                preparedXids.size(),\n+                hangingXids.size());\n+    }\n+\n+    @Override\n+    public void open(Configuration configuration) throws Exception {\n+        super.open(configuration);\n+        xidGenerator.open();\n+        xaFacade.open();\n+        format.setRuntimeContext(getRuntimeContext());\n+        format.open(\n+                getRuntimeContext().getIndexOfThisSubtask(),\n+                getRuntimeContext().getNumberOfParallelSubtasks());\n+        hangingXids = new LinkedList<>(xaGroupOps.failOrRollback(hangingXids).getForRetry());\n+        commitUpToCheckpoint(Optional.empty());", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDE0MjU3OA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r554142578", "bodyText": "Yes, failed Xds will be returned to preparedXids again\nThe job will restart from the latest completed checkpoint if any (decided by CheckpointCoordinator )\nUpon restart, preparedXids will be committed again (or erlier, if a checkpoint completion notification is received before restart)", "author": "rkhachatryan", "createdAt": "2021-01-08T19:19:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ0ODg4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ1MTk2Ng==", "url": "https://github.com/apache/flink/pull/10847#discussion_r550451966", "bodyText": "I'm a little confused about this. Does this mean we can't provide exactly once guarantee across partititons?", "author": "wuchong", "createdAt": "2020-12-31T10:29:52Z", "path": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java", "diffHunk": "@@ -0,0 +1,367 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.annotation.Internal;\n+import org.apache.flink.api.common.functions.AbstractRichFunction;\n+import org.apache.flink.api.common.state.CheckpointListener;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.SinkFunction;\n+import org.apache.flink.util.Preconditions;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.flink.connector.jdbc.xa.JdbcXaSinkFunctionState.of;\n+\n+/**\n+ * JDBC sink function that uses XA transactions to provide exactly once guarantees. That is, if a\n+ * checkpoint succeeds then all records emitted during it are committed in the database, and rolled\n+ * back otherwise.\n+ *\n+ * <p>Each parallel subtask has it's own transactions, independent from other subtasks. Therefore,\n+ * consistency is only guaranteed within partitions.", "originalCommit": "23a55764f7c8fed1d0ef4fce3f9517afbe30c8ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDE0ODEwMQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r554148101", "bodyText": "Let me clarify.\nEach element is sent to the external system exactly once (even across partitions).\nHowever, each partition commits independently (with a potentially big delay because of retries).\nTherefore, the data in the external system may be inconsistent during these periods from the application point of view.\nI believe this is a common behavior of all Flink exatly-once sinks.", "author": "rkhachatryan", "createdAt": "2021-01-08T19:31:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ1MTk2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODE3ODU4Mg==", "url": "https://github.com/apache/flink/pull/10847#discussion_r558178582", "bodyText": "Ah, I see.", "author": "wuchong", "createdAt": "2021-01-15T10:05:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDQ1MTk2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTIwMDg4NA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r559200884", "bodyText": "I think a better and easier way to test serializer is extending SerializerTestBase.", "author": "wuchong", "createdAt": "2021-01-17T15:58:55Z", "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/CheckpointAndXidSerializersTest.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+\n+import org.junit.Test;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+/** XaSerializersTest. */\n+public class CheckpointAndXidSerializersTest {", "originalCommit": "0bc72013bb63f51c7de3909885709de5e56940dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc5MjE4OA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r559792188", "bodyText": "I didn't know about this class, thanks!", "author": "rkhachatryan", "createdAt": "2021-01-18T20:57:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTIwMDg4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTIwMDkzOA==", "url": "https://github.com/apache/flink/pull/10847#discussion_r559200938", "bodyText": "I think a better and easier way to test serializer is extending SerializerTestBase.", "author": "wuchong", "createdAt": "2021-01-17T15:59:09Z", "path": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/XidSerializersTest.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.core.memory.DataInputViewStreamWrapper;\n+import org.apache.flink.core.memory.DataOutputViewStreamWrapper;\n+\n+import org.junit.Test;\n+\n+import javax.transaction.xa.Xid;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+/** XaSerializersTest. */\n+public class XidSerializersTest {", "originalCommit": "0bc72013bb63f51c7de3909885709de5e56940dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTc5MjI0NQ==", "url": "https://github.com/apache/flink/pull/10847#discussion_r559792245", "bodyText": "I didn't know about this class, thanks!", "author": "rkhachatryan", "createdAt": "2021-01-18T20:58:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTIwMDkzOA=="}], "type": "inlineReview"}, {"oid": "e28928f4abbbf2b380db720d6b1dc6d5eeae7b05", "url": "https://github.com/apache/flink/commit/e28928f4abbbf2b380db720d6b1dc6d5eeae7b05", "message": "[hotfix][sink][test] Unignore JdbcITCase", "committedDate": "2021-01-19T07:50:15Z", "type": "commit"}, {"oid": "6f27572110fbc02a1f0ad65260212b621b928dfe", "url": "https://github.com/apache/flink/commit/6f27572110fbc02a1f0ad65260212b621b928dfe", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2021-01-19T07:50:57Z", "type": "commit"}, {"oid": "6f27572110fbc02a1f0ad65260212b621b928dfe", "url": "https://github.com/apache/flink/commit/6f27572110fbc02a1f0ad65260212b621b928dfe", "message": "[FLINK-15578][connectors/jdbc] implement exactly once JDBC sink using JTA (XA)", "committedDate": "2021-01-19T07:50:57Z", "type": "forcePushed"}]}