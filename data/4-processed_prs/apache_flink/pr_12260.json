{"pr_number": 12260, "pr_title": "[FLINK-17189][table-planner] Table with proctime attribute cannot be read from Hive catalog", "pr_createdAt": "2020-05-20T04:05:57Z", "pr_url": "https://github.com/apache/flink/pull/12260", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODUyNDY3MA==", "url": "https://github.com/apache/flink/pull/12260#discussion_r428524670", "bodyText": "Actually proctime(    ) should also work, i'm thinking if we can use the Sqlparser to parse the expr first, if we got one SqlUnresolvedFunction with no operands and its name matches proctime, the we can go ahead.", "author": "danny0405", "createdAt": "2020-05-21T08:44:30Z", "path": "flink-table/flink-table-planner-blink/src/main/scala/org/apache/flink/table/planner/sources/TableSourceUtil.scala", "diffHunk": "@@ -238,6 +250,14 @@ object TableSourceUtil {\n     }\n   }\n \n+  private def containsTimeAttribute(tableSchema: TableSchema): Boolean = {\n+    tableSchema.getWatermarkSpecs.nonEmpty || tableSchema.getTableColumns.exists(isProctime)\n+  }\n+\n+  private def isProctime(column: TableColumn): Boolean = {\n+    toScala(column.getExpr).exists(_.equalsIgnoreCase(\"proctime()\"))\n+  }", "originalCommit": "87d0b478bf38fc74639f8ac2c065e4e6d2fc2156", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODUzNDI2NQ==", "url": "https://github.com/apache/flink/pull/12260#discussion_r428534265", "bodyText": "It is hard to get Sqlparser too. Obtain parser also creates a circular dependency. It is hard to break it.\nI will remove \" \" for checking.", "author": "JingsongLi", "createdAt": "2020-05-21T09:04:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODUyNDY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYwMTIwNA==", "url": "https://github.com/apache/flink/pull/12260#discussion_r428601204", "bodyText": "I think this is error-prone. The string compare is not a general solution, I can come up with some corner cases:\n`proctime()`  // quoted\nproctime // function identifier\n\nI think a more general solution is pass a SqlExprToRexConverterFactory (which can creates a SqlExprToRexConverter to get the correct type of an expression) into the CatalogSchemaTable. I know it's verbose to pass it into CatalogSchemaTable, but I don't find other reasonable ways.", "author": "wuchong", "createdAt": "2020-05-21T11:40:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODUyNDY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYzMDE1OQ==", "url": "https://github.com/apache/flink/pull/12260#discussion_r428630159", "bodyText": "done", "author": "JingsongLi", "createdAt": "2020-05-21T12:48:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODUyNDY3MA=="}], "type": "inlineReview"}, {"oid": "401be6000cf497ea1f598494c70dfbc2fa2fea65", "url": "https://github.com/apache/flink/commit/401be6000cf497ea1f598494c70dfbc2fa2fea65", "message": "Fix comments", "committedDate": "2020-05-21T09:04:57Z", "type": "forcePushed"}, {"oid": "081a62a66ef0a1b687b10e6b41ed8066b0c7992d", "url": "https://github.com/apache/flink/commit/081a62a66ef0a1b687b10e6b41ed8066b0c7992d", "message": "[FLINK-17189][table-planner] Table with processing time attribute can not be read from Hive catalog", "committedDate": "2020-05-25T03:14:33Z", "type": "commit"}, {"oid": "081a62a66ef0a1b687b10e6b41ed8066b0c7992d", "url": "https://github.com/apache/flink/commit/081a62a66ef0a1b687b10e6b41ed8066b0c7992d", "message": "[FLINK-17189][table-planner] Table with processing time attribute can not be read from Hive catalog", "committedDate": "2020-05-25T03:14:33Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcxNjQ2NQ==", "url": "https://github.com/apache/flink/pull/12260#discussion_r429716465", "bodyText": "Could you add a short comment for this field to explain why we need this? The same to CatalogManagerCalciteSchema, CatalogSchemaTable, DatabaseCalciteSchema. For example:\nThe SQL expression converter factory is used to derive correct result type of computed column, because the date type of computed column from catalog table is not trusted.", "author": "wuchong", "createdAt": "2020-05-25T03:21:34Z", "path": "flink-table/flink-table-planner-blink/src/main/java/org/apache/flink/table/planner/catalog/CatalogCalciteSchema.java", "diffHunk": "@@ -42,10 +43,16 @@\n \tprivate final CatalogManager catalogManager;\n \t// Flag that tells if the current planner should work in a batch or streaming mode.\n \tprivate final boolean isStreamingMode;\n+\tprivate final SqlExprToRexConverterFactory converterFactory;", "originalCommit": "081a62a66ef0a1b687b10e6b41ed8066b0c7992d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "cb99a301a3d1625909fbf94e8543e3a7b0726685", "url": "https://github.com/apache/flink/commit/cb99a301a3d1625909fbf94e8543e3a7b0726685", "message": "Fix comments&case", "committedDate": "2020-05-25T05:51:06Z", "type": "commit"}]}