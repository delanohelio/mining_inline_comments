{"pr_number": 11405, "pr_title": "[FLINK-16413]Reduce hive source parallelism when limit push down", "pr_createdAt": "2020-03-14T06:51:13Z", "pr_url": "https://github.com/apache/flink/pull/11405", "timeline": [{"oid": "d0bfd89ac69111dc200232dcd37ce5b954e50977", "url": "https://github.com/apache/flink/commit/d0bfd89ac69111dc200232dcd37ce5b954e50977", "message": "test", "committedDate": "2020-01-21T03:54:03Z", "type": "commit"}, {"oid": "5661cfc7aebe7f3340c88a413fa868c8a34b6b1b", "url": "https://github.com/apache/flink/commit/5661cfc7aebe7f3340c88a413fa868c8a34b6b1b", "message": "Merge branch 'master' of https://github.com/apache/flink", "committedDate": "2020-03-13T05:46:06Z", "type": "commit"}, {"oid": "eb82471fb734d65609504d47e3c37bd5495595eb", "url": "https://github.com/apache/flink/commit/eb82471fb734d65609504d47e3c37bd5495595eb", "message": "Merge branch 'master' of https://github.com/apache/flink", "committedDate": "2020-03-13T14:27:16Z", "type": "commit"}, {"oid": "3f7c411943106addb8d85d19a22b23e5a74bc457", "url": "https://github.com/apache/flink/commit/3f7c411943106addb8d85d19a22b23e5a74bc457", "message": "Merge branch 'master' of https://github.com/apache/flink", "committedDate": "2020-03-14T00:34:18Z", "type": "commit"}, {"oid": "3d425d3af8d4bb20259fb5c60b3b62e4e00161b8", "url": "https://github.com/apache/flink/commit/3d425d3af8d4bb20259fb5c60b3b62e4e00161b8", "message": "Delete HotelOrder2HdfsK8sTest.java", "committedDate": "2020-03-14T00:49:43Z", "type": "commit"}, {"oid": "b196447b93a3c1bdb64fce172c2aea305e16093b", "url": "https://github.com/apache/flink/commit/b196447b93a3c1bdb64fce172c2aea305e16093b", "message": "Reduce hive source parallelism when limit push down", "committedDate": "2020-03-14T06:33:15Z", "type": "commit"}, {"oid": "6bdafe404b708ddd3a50340f8cc961824b1f533f", "url": "https://github.com/apache/flink/commit/6bdafe404b708ddd3a50340f8cc961824b1f533f", "message": "Update pom.xml", "committedDate": "2020-03-16T01:14:55Z", "type": "commit"}, {"oid": "ba40c607250f084c3210b678e82159c479307dff", "url": "https://github.com/apache/flink/commit/ba40c607250f084c3210b678e82159c479307dff", "message": "Update pom.xml", "committedDate": "2020-03-16T01:17:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc0ODc2NQ==", "url": "https://github.com/apache/flink/pull/11405#discussion_r392748765", "bodyText": "Should also affect when not open parallelism infer, modify to:\nint parallelism = flinkConf.get(ExecutionConfigOptions.TABLE_EXEC_RESOURCE_DEFAULT_PARALLELISM);\nif (flinkConf.get(HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM)) {\n    ......\n    parallelism = Math.min(splitNum, max);\n}\nparallelism = limit > 0 ? Math.min(parallelism, (int) limit / 1000) : parallelism;\nparallelism = Math.max(1, parallelism);\nsource.setParallelism(parallelism);", "author": "JingsongLi", "createdAt": "2020-03-16T01:48:57Z", "path": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableSource.java", "diffHunk": "@@ -168,7 +168,9 @@ public boolean isBounded() {\n \t\t\t} catch (IOException e) {\n \t\t\t\tthrow new FlinkHiveException(e);\n \t\t\t}\n-\t\t\tsource.setParallelism(Math.min(Math.max(1, splitNum), max));\n+\t\t\tint parallelism = Math.min(Math.max(1, splitNum), max);", "originalCommit": "b196447b93a3c1bdb64fce172c2aea305e16093b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4NzY0OA==", "url": "https://github.com/apache/flink/pull/11405#discussion_r393387648", "bodyText": "@JingsongLi  Thank you very much for your reply. There are some places that I did not consider carefully. I have modified them according to your suggestions.", "author": "zhangjun0x01", "createdAt": "2020-03-17T00:50:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc0ODc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc1MTQ0Mg==", "url": "https://github.com/apache/flink/pull/11405#discussion_r392751442", "bodyText": "Add this for real test parallelism:\ntEnv.getConfig().getConfiguration().setBoolean(\n\t\t\t\tHiveOptions.TABLE_EXEC_HIVE_FALLBACK_MAPRED_READER, false);\ntEnv.getConfig().getConfiguration().setInteger(\n\t\t\t\tExecutionConfigOptions.TABLE_EXEC_RESOURCE_DEFAULT_PARALLELISM, 2);", "author": "JingsongLi", "createdAt": "2020-03-16T01:58:02Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceTest.java", "diffHunk": "@@ -410,6 +410,32 @@ public void testParallelismSetting() {\n \t\tAssert.assertEquals(2, transformation.getParallelism());\n \t}\n \n+\t@Test\n+\tpublic void testParallelismOnLimitPushDown() {\n+\t\tfinal String catalogName = \"hive\";\n+\t\tfinal String dbName = \"source_db\";\n+\t\tfinal String tblName = \"test_parallelism_limit_pushdown\";\n+\t\thiveShell.execute(\"CREATE TABLE source_db.test_parallelism_limit_pushdown \" +\n+\t\t                  \"(year STRING, value INT) partitioned by (pt int);\");\n+\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n+\t\t             .addRow(new Object[]{\"2014\", 3})\n+\t\t             .addRow(new Object[]{\"2014\", 4})\n+\t\t             .commit(\"pt=0\");\n+\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n+\t\t             .addRow(new Object[]{\"2015\", 2})\n+\t\t             .addRow(new Object[]{\"2015\", 5})\n+\t\t             .commit(\"pt=1\");\n+\t\tTableEnvironment tEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode();", "originalCommit": "b196447b93a3c1bdb64fce172c2aea305e16093b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjc1MTc2OQ==", "url": "https://github.com/apache/flink/pull/11405#discussion_r392751769", "bodyText": "This is limit transformation, should always be 1.\nAssert.assertEquals(1, ((PartitionTransformation) ((OneInputTransformation) transformation).getInput())\n\t\t\t\t.getInput().getParallelism());", "author": "JingsongLi", "createdAt": "2020-03-16T02:00:06Z", "path": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceTest.java", "diffHunk": "@@ -410,6 +410,32 @@ public void testParallelismSetting() {\n \t\tAssert.assertEquals(2, transformation.getParallelism());\n \t}\n \n+\t@Test\n+\tpublic void testParallelismOnLimitPushDown() {\n+\t\tfinal String catalogName = \"hive\";\n+\t\tfinal String dbName = \"source_db\";\n+\t\tfinal String tblName = \"test_parallelism_limit_pushdown\";\n+\t\thiveShell.execute(\"CREATE TABLE source_db.test_parallelism_limit_pushdown \" +\n+\t\t                  \"(year STRING, value INT) partitioned by (pt int);\");\n+\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n+\t\t             .addRow(new Object[]{\"2014\", 3})\n+\t\t             .addRow(new Object[]{\"2014\", 4})\n+\t\t             .commit(\"pt=0\");\n+\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n+\t\t             .addRow(new Object[]{\"2015\", 2})\n+\t\t             .addRow(new Object[]{\"2015\", 5})\n+\t\t             .commit(\"pt=1\");\n+\t\tTableEnvironment tEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode();\n+\t\ttEnv.registerCatalog(catalogName, hiveCatalog);\n+\t\tTable table = tEnv.sqlQuery(\"select * from hive.source_db.test_parallelism_limit_pushdown limit 1\");\n+\t\tPlannerBase planner = (PlannerBase) ((TableEnvironmentImpl) tEnv).getPlanner();\n+\t\tRelNode relNode = planner.optimize(TableTestUtil.toRelNode(table));\n+\t\tExecNode execNode = planner.translateToExecNodePlan(toScala(Collections.singletonList(relNode))).get(0);\n+\t\t@SuppressWarnings(\"unchecked\")\n+\t\tTransformation transformation = execNode.translateToPlan(planner);\n+\t\tAssert.assertEquals(1, transformation.getParallelism());", "originalCommit": "b196447b93a3c1bdb64fce172c2aea305e16093b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7fc8bc0e4c1f9d99e4b4edfcbe7939d23596283d", "url": "https://github.com/apache/flink/commit/7fc8bc0e4c1f9d99e4b4edfcbe7939d23596283d", "message": "Reduce hive source parallelism when limit push down", "committedDate": "2020-03-16T13:48:32Z", "type": "commit"}, {"oid": "4a3d439a9e53fed320efd8220c35f092e64dbbf3", "url": "https://github.com/apache/flink/commit/4a3d439a9e53fed320efd8220c35f092e64dbbf3", "message": "Reduce hive source parallelism when limit push down", "committedDate": "2020-03-16T13:48:32Z", "type": "commit"}, {"oid": "d24333b8d10136ea7ba12a1f2da62cf18fd01d89", "url": "https://github.com/apache/flink/commit/d24333b8d10136ea7ba12a1f2da62cf18fd01d89", "message": "Reduce hive source parallelism when limit push down", "committedDate": "2020-03-16T14:11:58Z", "type": "commit"}]}