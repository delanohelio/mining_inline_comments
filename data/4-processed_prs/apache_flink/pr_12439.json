{"pr_number": 12439, "pr_title": "[FLINK-17776][hive][doc] Add documentation for DDL&DML in hive dialect", "pr_createdAt": "2020-06-02T12:01:47Z", "pr_url": "https://github.com/apache/flink/pull/12439", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyMTA0Ng==", "url": "https://github.com/apache/flink/pull/12439#discussion_r435721046", "bodyText": "You have to choose to use Hive -> You need to switch to Hive dialect", "author": "danny0405", "createdAt": "2020-06-05T06:47:04Z", "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You have to choose to use Hive\n+dialect before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Please also be noted that you can dynamically switch dialect for each", "originalCommit": "723262421f8fbf9a4b86639ef8be6d6651f26bba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyMTIyNg==", "url": "https://github.com/apache/flink/pull/12439#discussion_r435721226", "bodyText": "Please also be noted that -> Also notice that", "author": "danny0405", "createdAt": "2020-06-05T06:47:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyMTA0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyMzA1Nw==", "url": "https://github.com/apache/flink/pull/12439#discussion_r435723057", "bodyText": "You can set dialect for you TableEnvironment with Table API.", "author": "danny0405", "createdAt": "2020-06-05T06:52:39Z", "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You have to choose to use Hive\n+dialect before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Please also be noted that you can dynamically switch dialect for each\n+statement you execute. There's no need to restart a session to use a different dialect.\n+\n+### SQL Client\n+\n+SQL dialect can be specified via the `table.sql-dialect` property. Therefore you can set the initial dialect to use in\n+the `configuration` section of the yaml file for your SQL Client.\n+\n+{% highlight yaml %}\n+\n+execution:\n+  planner: blink\n+  type: batch\n+  result-mode: table\n+\n+configuration:\n+  table.sql-dialect: hive\n+  \n+{% endhighlight %}\n+\n+You can also set the dialect after the SQL Client has launched.\n+\n+{% highlight bash %}\n+\n+Flink SQL> set table.sql-dialect=hive; -- to use hive dialect\n+[INFO] Session property has been set.\n+\n+Flink SQL> set table.sql-dialect=default; -- to use default dialect\n+[INFO] Session property has been set.\n+\n+{% endhighlight %}\n+\n+### Table API\n+\n+With Table API, you can set dialect for you TableEnvironment.\n+", "originalCommit": "723262421f8fbf9a4b86639ef8be6d6651f26bba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNDQ3NQ==", "url": "https://github.com/apache/flink/pull/12439#discussion_r435724475", "bodyText": "The following are some precautions for using using the Hive dialect.", "author": "danny0405", "createdAt": "2020-06-05T06:56:23Z", "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You have to choose to use Hive\n+dialect before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Please also be noted that you can dynamically switch dialect for each\n+statement you execute. There's no need to restart a session to use a different dialect.\n+\n+### SQL Client\n+\n+SQL dialect can be specified via the `table.sql-dialect` property. Therefore you can set the initial dialect to use in\n+the `configuration` section of the yaml file for your SQL Client.\n+\n+{% highlight yaml %}\n+\n+execution:\n+  planner: blink\n+  type: batch\n+  result-mode: table\n+\n+configuration:\n+  table.sql-dialect: hive\n+  \n+{% endhighlight %}\n+\n+You can also set the dialect after the SQL Client has launched.\n+\n+{% highlight bash %}\n+\n+Flink SQL> set table.sql-dialect=hive; -- to use hive dialect\n+[INFO] Session property has been set.\n+\n+Flink SQL> set table.sql-dialect=default; -- to use default dialect\n+[INFO] Session property has been set.\n+\n+{% endhighlight %}\n+\n+### Table API\n+\n+With Table API, you can set dialect for you TableEnvironment.\n+\n+{% highlight java %}\n+\n+EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner()...build();\n+TableEnvironment tableEnv = TableEnvironment.create(settings);\n+// to use hive dialect\n+tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n+// to use default dialect\n+tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n+\n+{% endhighlight %}\n+\n+## DDL\n+\n+This section lists the supported DDLs with the Hive dialect. We'll mainly focus on the syntax\n+here. You can refer to [Hive doc](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL)\n+for the semantics of each DDL statement.\n+\n+### DATABASE\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW DATABASES;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name\n+  [COMMENT database_comment]\n+  [LOCATION fs_path]\n+  [WITH DBPROPERTIES (property_name=property_value, ...)];\n+{% endhighlight %}\n+\n+#### Alter\n+\n+##### Update Properties\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, ...);\n+{% endhighlight %}\n+\n+##### Update Owner\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET OWNER [USER|ROLE] user_or_role;\n+{% endhighlight %}\n+\n+##### Update Location\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET LOCATION fs_path;\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];\n+{% endhighlight %}\n+\n+#### Use\n+\n+{% highlight sql %}\n+USE database_name;\n+{% endhighlight %}\n+\n+### TABLE\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW TABLES;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name\n+  [(col_name data_type [column_constraint] [COMMENT col_comment], ... [table_constraint])]\n+  [COMMENT table_comment]\n+  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]\n+  [\n+    [ROW FORMAT row_format]\n+    [STORED AS file_format]\n+  ]\n+  [LOCATION fs_path]\n+  [TBLPROPERTIES (property_name=property_value, ...)]\n+  \n+row_format:\n+  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]\n+      [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]\n+      [NULL DEFINED AS char]\n+  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, ...)]\n+  \n+file_format:\n+  : SEQUENCEFILE\n+  | TEXTFILE\n+  | RCFILE\n+  | ORC\n+  | PARQUET\n+  | AVRO\n+  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname\n+  \n+column_constraint:\n+  : NOT NULL [[ENABLE|DISABLE] [VALIDATE|NOVALIDATE] [RELY|NORELY]]\n+  \n+table_constraint:\n+  : [CONSTRAINT constraint_name] PRIMARY KEY (col_name, ...) [[ENABLE|DISABLE] [VALIDATE|NOVALIDATE] [RELY|NORELY]]\n+{% endhighlight %}\n+\n+#### Alter\n+\n+##### Rename\n+\n+{% highlight sql %}\n+ALTER TABLE table_name RENAME TO new_table_name;\n+{% endhighlight %}\n+\n+##### Update Properties\n+\n+{% highlight sql %}\n+ALTER TABLE table_name SET TBLPROPERTIES (property_name = property_value, property_name = property_value, ... );\n+{% endhighlight %}\n+\n+##### Update Location\n+\n+{% highlight sql %}\n+ALTER TABLE table_name [PARTITION partition_spec] SET LOCATION fs_path;\n+{% endhighlight %}\n+\n+The `partition_spec`, if present, needs to be a full spec, i.e. has values for all partition columns. And when it's\n+present, the operation will be applied to the corresponding partition instead of the table.\n+\n+##### Update File Format\n+\n+{% highlight sql %}\n+ALTER TABLE table_name [PARTITION partition_spec] SET FILEFORMAT file_format;\n+{% endhighlight %}\n+\n+The `partition_spec`, if present, needs to be a full spec, i.e. has values for all partition columns. And when it's\n+present, the operation will be applied to the corresponding partition instead of the table.\n+\n+##### Update SerDe Properties\n+\n+{% highlight sql %}\n+ALTER TABLE table_name [PARTITION partition_spec] SET SERDE serde_class_name [WITH SERDEPROPERTIES serde_properties];\n+ \n+ALTER TABLE table_name [PARTITION partition_spec] SET SERDEPROPERTIES serde_properties;\n+ \n+serde_properties:\n+  : (property_name = property_value, property_name = property_value, ... )\n+{% endhighlight %}\n+\n+The `partition_spec`, if present, needs to be a full spec, i.e. has values for all partition columns. And when it's\n+present, the operation will be applied to the corresponding partition instead of the table.\n+\n+##### Add Partitions\n+\n+{% highlight sql %}\n+ALTER TABLE table_name ADD [IF NOT EXISTS] (PARTITION partition_spec [LOCATION fs_path])+;\n+{% endhighlight %}\n+\n+##### Drop Partitions\n+\n+{% highlight sql %}\n+ALTER TABLE table_name DROP [IF EXISTS] PARTITION partition_spec[, PARTITION partition_spec, ...];\n+{% endhighlight %}\n+\n+##### Add/Replace Columns\n+\n+{% highlight sql %}\n+ALTER TABLE table_name\n+  ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)\n+  [CASCADE|RESTRICT]\n+{% endhighlight %}\n+\n+##### Change Column\n+\n+{% highlight sql %}\n+ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type\n+  [COMMENT col_comment] [FIRST|AFTER column_name] [CASCADE|RESTRICT];\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP TABLE [IF EXISTS] table_name;\n+{% endhighlight %}\n+\n+### VIEW\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE VIEW [IF NOT EXISTS] view_name [(column_name, ...) ]\n+  [COMMENT view_comment]\n+  [TBLPROPERTIES (property_name = property_value, ...)]\n+  AS SELECT ...;\n+{% endhighlight %}\n+\n+#### Alter\n+\n+##### Rename\n+\n+{% highlight sql %}\n+ALTER VIEW view_name RENAME TO new_view_name;\n+{% endhighlight %}\n+\n+##### Update Properties\n+\n+{% highlight sql %}\n+ALTER VIEW view_name SET TBLPROPERTIES (property_name = property_value, ... );\n+{% endhighlight %}\n+\n+##### Update As Select\n+\n+{% highlight sql %}\n+ALTER VIEW view_name AS select_statement;\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP VIEW [IF EXISTS] view_name;\n+{% endhighlight %}\n+\n+### FUNCTION\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW FUNCTIONS;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE FUNCTION function_name AS class_name;\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP FUNCTION [IF EXISTS] function_name;\n+{% endhighlight %}\n+\n+## DML\n+\n+### INSERT\n+\n+{% highlight sql %}\n+INSERT (INTO|OVERWRITE) [TABLE] table_name [PARTITION partition_spec] SELECT ...;\n+{% endhighlight %}\n+\n+The `partition_spec`, if present, can be either a full spec or partial spec. If the `partition_spec` is a partial\n+spec, the dynamic partition column names can be omitted.\n+\n+## DQL\n+\n+At the moment, Hive dialect supports the same syntax as Flink SQL for DQLs. Refer to\n+[Flink SQL queries]({{ site.baseurl }}/dev/table/sql/queries.html) for more details. And it's recommended to switch to\n+`default` dialect to execute DQLs.\n+\n+## Notice\n+\n+Some things to notice when using the Hive dialect.\n+", "originalCommit": "723262421f8fbf9a4b86639ef8be6d6651f26bba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc1NTgyOA==", "url": "https://github.com/apache/flink/pull/12439#discussion_r435755828", "bodyText": "Can we also give an example for Hive create table ? The syntax template is too complex to understand.", "author": "danny0405", "createdAt": "2020-06-05T08:03:41Z", "path": "docs/dev/table/hive/hive_dialect.md", "diffHunk": "@@ -0,0 +1,347 @@\n+---\n+title: \"Hive Dialect\"\n+nav-parent_id: hive_tableapi\n+nav-pos: 1\n+---\n+<!--\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+  http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing,\n+software distributed under the License is distributed on an\n+\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+KIND, either express or implied.  See the License for the\n+specific language governing permissions and limitations\n+under the License.\n+-->\n+\n+Starting from 1.11.0, Flink allows users to write SQL statements in Hive syntax when Hive dialect\n+is used. By providing compatibility with Hive syntax, we aim to improve the interoperability with\n+Hive and reduce the scenarios when users need to switch between Flink and Hive in order to execute\n+different statements.\n+\n+* This will be replaced by the TOC\n+{:toc}\n+\n+## Use Hive Dialect\n+\n+Flink currently supports two SQL dialects: `default` and `hive`. You need to switch to Hive dialect\n+before you can write in Hive syntax. The following describes how to set dialect with\n+SQL Client and Table API. Also notice that you can dynamically switch dialect for each\n+statement you execute. There's no need to restart a session to use a different dialect.\n+\n+### SQL Client\n+\n+SQL dialect can be specified via the `table.sql-dialect` property. Therefore you can set the initial dialect to use in\n+the `configuration` section of the yaml file for your SQL Client.\n+\n+{% highlight yaml %}\n+\n+execution:\n+  planner: blink\n+  type: batch\n+  result-mode: table\n+\n+configuration:\n+  table.sql-dialect: hive\n+  \n+{% endhighlight %}\n+\n+You can also set the dialect after the SQL Client has launched.\n+\n+{% highlight bash %}\n+\n+Flink SQL> set table.sql-dialect=hive; -- to use hive dialect\n+[INFO] Session property has been set.\n+\n+Flink SQL> set table.sql-dialect=default; -- to use default dialect\n+[INFO] Session property has been set.\n+\n+{% endhighlight %}\n+\n+### Table API\n+\n+You can set dialect for your TableEnvironment with Table API.\n+\n+{% highlight java %}\n+\n+EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner()...build();\n+TableEnvironment tableEnv = TableEnvironment.create(settings);\n+// to use hive dialect\n+tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n+// to use default dialect\n+tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n+\n+{% endhighlight %}\n+\n+## DDL\n+\n+This section lists the supported DDLs with the Hive dialect. We'll mainly focus on the syntax\n+here. You can refer to [Hive doc](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL)\n+for the semantics of each DDL statement.\n+\n+### DATABASE\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW DATABASES;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name\n+  [COMMENT database_comment]\n+  [LOCATION fs_path]\n+  [WITH DBPROPERTIES (property_name=property_value, ...)];\n+{% endhighlight %}\n+\n+#### Alter\n+\n+##### Update Properties\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, ...);\n+{% endhighlight %}\n+\n+##### Update Owner\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET OWNER [USER|ROLE] user_or_role;\n+{% endhighlight %}\n+\n+##### Update Location\n+\n+{% highlight sql %}\n+ALTER (DATABASE|SCHEMA) database_name SET LOCATION fs_path;\n+{% endhighlight %}\n+\n+#### Drop\n+\n+{% highlight sql %}\n+DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];\n+{% endhighlight %}\n+\n+#### Use\n+\n+{% highlight sql %}\n+USE database_name;\n+{% endhighlight %}\n+\n+### TABLE\n+\n+#### Show\n+\n+{% highlight sql %}\n+SHOW TABLES;\n+{% endhighlight %}\n+\n+#### Create\n+\n+{% highlight sql %}\n+CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name\n+  [(col_name data_type [column_constraint] [COMMENT col_comment], ... [table_constraint])]\n+  [COMMENT table_comment]\n+  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]\n+  [\n+    [ROW FORMAT row_format]\n+    [STORED AS file_format]\n+  ]\n+  [LOCATION fs_path]\n+  [TBLPROPERTIES (property_name=property_value, ...)]\n+  \n+row_format:\n+  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]\n+      [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]\n+      [NULL DEFINED AS char]\n+  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, ...)]\n+  \n+file_format:\n+  : SEQUENCEFILE\n+  | TEXTFILE\n+  | RCFILE\n+  | ORC\n+  | PARQUET\n+  | AVRO\n+  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname\n+  \n+column_constraint:\n+  : NOT NULL [[ENABLE|DISABLE] [VALIDATE|NOVALIDATE] [RELY|NORELY]]\n+  \n+table_constraint:\n+  : [CONSTRAINT constraint_name] PRIMARY KEY (col_name, ...) [[ENABLE|DISABLE] [VALIDATE|NOVALIDATE] [RELY|NORELY]]", "originalCommit": "d7de89b8333fd9e073f6a329e2ba641a2d71f26e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTg2MTU4NA==", "url": "https://github.com/apache/flink/pull/12439#discussion_r435861584", "bodyText": "We'll need a lot of examples to cover all the use cases. Besides, since we follow Hive syntax, the examples we add will just be duplicates of what's already in Hive's own doc. So I'd prefer to only list the supported syntax here. Users can always refer to Hive docs for semantics and examples.", "author": "lirui-apache", "createdAt": "2020-06-05T11:32:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc1NTgyOA=="}], "type": "inlineReview"}, {"oid": "efba94b30447bf94addd8fedfdfebd62a3a94bcb", "url": "https://github.com/apache/flink/commit/efba94b30447bf94addd8fedfdfebd62a3a94bcb", "message": "[FLINK-17776][hive][doc] Add documentation for DDL&DML in hive dialect", "committedDate": "2020-06-08T04:55:57Z", "type": "commit"}, {"oid": "5668926fd44843ac0e86920ba69618a13b726039", "url": "https://github.com/apache/flink/commit/5668926fd44843ac0e86920ba69618a13b726039", "message": "update overview page", "committedDate": "2020-06-08T04:55:57Z", "type": "commit"}, {"oid": "24c9e617346fa55fd31b963d98b324271a5fd1b1", "url": "https://github.com/apache/flink/commit/24c9e617346fa55fd31b963d98b324271a5fd1b1", "message": "address comments", "committedDate": "2020-06-08T04:55:57Z", "type": "commit"}, {"oid": "0c4484444c65a12851446dcdf99d962bd02fbd53", "url": "https://github.com/apache/flink/commit/0c4484444c65a12851446dcdf99d962bd02fbd53", "message": "fix typo", "committedDate": "2020-06-08T04:55:58Z", "type": "commit"}, {"oid": "31b991e463168e16cc3400c1df3e06cb28a8a917", "url": "https://github.com/apache/flink/commit/31b991e463168e16cc3400c1df3e06cb28a8a917", "message": "add zh page", "committedDate": "2020-06-08T05:14:58Z", "type": "commit"}, {"oid": "31b991e463168e16cc3400c1df3e06cb28a8a917", "url": "https://github.com/apache/flink/commit/31b991e463168e16cc3400c1df3e06cb28a8a917", "message": "add zh page", "committedDate": "2020-06-08T05:14:58Z", "type": "forcePushed"}]}