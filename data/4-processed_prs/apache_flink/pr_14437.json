{"pr_number": 14437, "pr_title": "[FLINK-20458][docs] translate gettingStarted.zh.md and correct spelling errors in gettingStarted.md", "pr_createdAt": "2020-12-20T14:51:44Z", "pr_url": "https://github.com/apache/flink/pull/14437", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3MjY5OQ==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549072699", "bodyText": "get started quickly with a Flink SQL development environment -> \u5728 Flink SQL \u5f00\u53d1\u73af\u5883\u4e0b\u5feb\u901f\u5165\u95e8", "author": "fsk119", "createdAt": "2020-12-27T06:35:48Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -22,54 +22,54 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Flink SQL makes it simple to develop streaming applications using standard SQL. It is easy to learn Flink if you have ever worked with a database or SQL like system by remaining ANSI-SQL 2011 compliant. This tutorial will help you get started quickly with a Flink SQL development environment. \n+Flink SQL \u4f7f\u5f97\u4f7f\u7528\u6807\u51c6 SQL \u5f00\u53d1\u6d41\u5e94\u7528\u7a0b\u5e8f\u53d8\u7684\u7b80\u5355\u3002\u5982\u679c\u4f60\u66fe\u7ecf\u5728\u5de5\u4f5c\u4e2d\u4f7f\u7528\u8fc7\u517c\u5bb9 ANSI-SQL 2011 \u7684\u6570\u636e\u5e93\u6216\u7c7b\u4f3c\u7684 SQL \u7cfb\u7edf\uff0c\u90a3\u4e48\u5c31\u5f88\u5bb9\u6613\u5b66\u4e60 Flink\u3002\u672c\u6559\u7a0b\u5c06\u5e2e\u52a9\u4f60\u5feb\u901f\u5165\u95e8 Flink SQL \u5f00\u53d1\u73af\u5883\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3Mjg4MA==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549072880", "bodyText": "For experimentation -> \u5bf9\u4e8e\u5b9e\u9a8c\u800c\u8a00", "author": "fsk119", "createdAt": "2020-12-27T06:37:38Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -22,54 +22,54 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Flink SQL makes it simple to develop streaming applications using standard SQL. It is easy to learn Flink if you have ever worked with a database or SQL like system by remaining ANSI-SQL 2011 compliant. This tutorial will help you get started quickly with a Flink SQL development environment. \n+Flink SQL \u4f7f\u5f97\u4f7f\u7528\u6807\u51c6 SQL \u5f00\u53d1\u6d41\u5e94\u7528\u7a0b\u5e8f\u53d8\u7684\u7b80\u5355\u3002\u5982\u679c\u4f60\u66fe\u7ecf\u5728\u5de5\u4f5c\u4e2d\u4f7f\u7528\u8fc7\u517c\u5bb9 ANSI-SQL 2011 \u7684\u6570\u636e\u5e93\u6216\u7c7b\u4f3c\u7684 SQL \u7cfb\u7edf\uff0c\u90a3\u4e48\u5c31\u5f88\u5bb9\u6613\u5b66\u4e60 Flink\u3002\u672c\u6559\u7a0b\u5c06\u5e2e\u52a9\u4f60\u5feb\u901f\u5165\u95e8 Flink SQL \u5f00\u53d1\u73af\u5883\u3002\n  \n * This will be replaced by the TOC\n {:toc}\n \n \n-### Prerequisetes \n+### \u5148\u51b3\u6761\u4ef6\n \n-You only need to have basic knowledge of SQL to follow along. No other programming experience is assumed. \n+\u4f60\u53ea\u9700\u8981\u5177\u5907 SQL \u7684\u57fa\u7840\u77e5\u8bc6\u5373\u53ef\uff0c\u4e0d\u9700\u8981\u5176\u4ed6\u7f16\u7a0b\u7ecf\u9a8c\u3002\n \n-### Installation\n+### \u5b89\u88c5\n \n-There are multiple ways to install Flink. For experimentation, the most common option is to download the binaries and run them locally. You can follow the steps in [local installation]({%link try-flink/local_installation.zh.md %}) to set up an environment for the rest of the tutorial. \n+\u5b89\u88c5 Flink \u6709\u591a\u79cd\u65b9\u5f0f\u3002\u4e3a\u4e86\u5b9e\u9a8c\uff0c\u6700\u5e38\u89c1\u7684\u9009\u62e9\u662f\u4e0b\u8f7d\u4e8c\u8fdb\u5236\u5305\u5e76\u5728\u672c\u5730\u8fd0\u884c\u3002\u4f60\u53ef\u4ee5\u6309\u7167[\u672c\u5730\u6a21\u5f0f\u5b89\u88c5]({% link try-flink/local_installation.zh.md %})\u4e2d\u7684\u6b65\u9aa4\u4e3a\u672c\u6559\u7a0b\u7684\u5269\u4f59\u90e8\u5206\u8bbe\u7f6e\u73af\u5883\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3MzA5Mw==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549073093", "bodyText": "\u8bfb\u8d77\u6765\u4f3c\u4e4e\u4e0d\u592a\u901a\u987a\uff1f \u6216\u8005 \u53e6\u8d77\u4e00\u53e5\uff1a\u901a\u8fc7\u5b83\uff0c\u4f60\u53ef\u4ee5\u76d1\u63a7\u4e0d\u540c\u7684\u4f5c\u4e1a\u3002", "author": "fsk119", "createdAt": "2020-12-27T06:40:29Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -22,54 +22,54 @@ specific language governing permissions and limitations\n under the License.\n -->\n \n-Flink SQL makes it simple to develop streaming applications using standard SQL. It is easy to learn Flink if you have ever worked with a database or SQL like system by remaining ANSI-SQL 2011 compliant. This tutorial will help you get started quickly with a Flink SQL development environment. \n+Flink SQL \u4f7f\u5f97\u4f7f\u7528\u6807\u51c6 SQL \u5f00\u53d1\u6d41\u5e94\u7528\u7a0b\u5e8f\u53d8\u7684\u7b80\u5355\u3002\u5982\u679c\u4f60\u66fe\u7ecf\u5728\u5de5\u4f5c\u4e2d\u4f7f\u7528\u8fc7\u517c\u5bb9 ANSI-SQL 2011 \u7684\u6570\u636e\u5e93\u6216\u7c7b\u4f3c\u7684 SQL \u7cfb\u7edf\uff0c\u90a3\u4e48\u5c31\u5f88\u5bb9\u6613\u5b66\u4e60 Flink\u3002\u672c\u6559\u7a0b\u5c06\u5e2e\u52a9\u4f60\u5feb\u901f\u5165\u95e8 Flink SQL \u5f00\u53d1\u73af\u5883\u3002\n  \n * This will be replaced by the TOC\n {:toc}\n \n \n-### Prerequisetes \n+### \u5148\u51b3\u6761\u4ef6\n \n-You only need to have basic knowledge of SQL to follow along. No other programming experience is assumed. \n+\u4f60\u53ea\u9700\u8981\u5177\u5907 SQL \u7684\u57fa\u7840\u77e5\u8bc6\u5373\u53ef\uff0c\u4e0d\u9700\u8981\u5176\u4ed6\u7f16\u7a0b\u7ecf\u9a8c\u3002\n \n-### Installation\n+### \u5b89\u88c5\n \n-There are multiple ways to install Flink. For experimentation, the most common option is to download the binaries and run them locally. You can follow the steps in [local installation]({%link try-flink/local_installation.zh.md %}) to set up an environment for the rest of the tutorial. \n+\u5b89\u88c5 Flink \u6709\u591a\u79cd\u65b9\u5f0f\u3002\u4e3a\u4e86\u5b9e\u9a8c\uff0c\u6700\u5e38\u89c1\u7684\u9009\u62e9\u662f\u4e0b\u8f7d\u4e8c\u8fdb\u5236\u5305\u5e76\u5728\u672c\u5730\u8fd0\u884c\u3002\u4f60\u53ef\u4ee5\u6309\u7167[\u672c\u5730\u6a21\u5f0f\u5b89\u88c5]({% link try-flink/local_installation.zh.md %})\u4e2d\u7684\u6b65\u9aa4\u4e3a\u672c\u6559\u7a0b\u7684\u5269\u4f59\u90e8\u5206\u8bbe\u7f6e\u73af\u5883\u3002\n \n-Once you're all set, use the following command to start a local cluster from the installation folder:\n+\u5b8c\u6210\u6240\u6709\u8bbe\u7f6e\u540e\uff0c\u5728\u5b89\u88c5\u6587\u4ef6\u5939\u4e2d\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u542f\u52a8\u672c\u5730\u96c6\u7fa4\uff1a\n \n {% highlight bash %}\n ./bin/start-cluster.sh\n {% endhighlight %}\n  \n-Once started, the Flink WebUI on [localhost:8081](localhost:8081) is available locally, from which you can monitor the different jobs.\n+\u542f\u52a8\u5b8c\u6210\u540e\uff0c\u5c31\u53ef\u4ee5\u5728\u672c\u5730\u8bbf\u95ee Flink WebUI [localhost:8081](localhost:8081)\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u5b83\u6765\u76d1\u89c6\u4e0d\u540c\u7684\u4f5c\u4e1a\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3MzMwMw==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549073303", "bodyText": "\u201cFlink \u67e5\u8be2\u5728\u8868\u4e0a\u8fdb\u884c\u64cd\u4f5c\u201d -> \u201cFlink \u67e5\u8be2\u64cd\u4f5c\u662f\u5728\u8868\u4e0a\u8fdb\u884c\u201d\n\u201c\u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u4e0d\u540c\uff0c\u56e0\u4e3a Flink \u4e0d\u5728\u672c\u5730\u7ba1\u7406\u9759\u6001\u6570\u636e\u201c \u4f3c\u4e4e\u4e0d\u592a\u901a\u987a\uff1f \u53bb\u6389\u201c\u56e0\u4e3a\u201d", "author": "fsk119", "createdAt": "2020-12-27T06:43:51Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -79,16 +79,15 @@ SELECT CURRENT_TIMESTAMP;\n \n {% top %}\n \n-## Source Tables\n+## Source \u8868\n \n-As with all SQL engines, Flink queries operate on top of tables. \n-It differs from a traditional database because Flink does not manage data at rest locally; instead, its queries operate continuously over external tables. \n+\u4e0e\u6240\u6709 SQL \u5f15\u64ce\u4e00\u6837\uff0cFlink \u67e5\u8be2\u5728\u8868\u4e0a\u8fdb\u884c\u64cd\u4f5c\u3002\u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u4e0d\u540c\uff0c\u56e0\u4e3a Flink \u4e0d\u5728\u672c\u5730\u7ba1\u7406\u9759\u6001\u6570\u636e\uff1b\u76f8\u53cd\uff0c\u5b83\u7684\u67e5\u8be2\u5728\u5916\u90e8\u8868\u4e0a\u8fde\u7eed\u8fd0\u884c\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3MzUxMQ==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549073511", "bodyText": "pipeline \u5728\u8fd9\u91cc\u5e94\u8be5\u662f\u6d41\u6c34\u7ebf\u7684\u610f\u601d\u3002\n\"Source tables produce rows operated over during the query's execution\" -> Source \u8868\u4ea7\u751f\u5728\u67e5\u8be2\u6267\u884c\u671f\u95f4\u53ef\u4ee5\u88ab\u64cd\u4f5c\u7684\u884c \u3002\n\u201cor any other system that Flink knows how to consume\u201d -> \u6216\u8005 \u4efb\u4f55\u5176\u5b83 Flink \u77e5\u9053\u5982\u4f55\u6d88\u8d39\u7684\u7cfb\u7edf", "author": "fsk119", "createdAt": "2020-12-27T06:46:21Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -79,16 +79,15 @@ SELECT CURRENT_TIMESTAMP;\n \n {% top %}\n \n-## Source Tables\n+## Source \u8868\n \n-As with all SQL engines, Flink queries operate on top of tables. \n-It differs from a traditional database because Flink does not manage data at rest locally; instead, its queries operate continuously over external tables. \n+\u4e0e\u6240\u6709 SQL \u5f15\u64ce\u4e00\u6837\uff0cFlink \u67e5\u8be2\u5728\u8868\u4e0a\u8fdb\u884c\u64cd\u4f5c\u3002\u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u4e0d\u540c\uff0c\u56e0\u4e3a Flink \u4e0d\u5728\u672c\u5730\u7ba1\u7406\u9759\u6001\u6570\u636e\uff1b\u76f8\u53cd\uff0c\u5b83\u7684\u67e5\u8be2\u5728\u5916\u90e8\u8868\u4e0a\u8fde\u7eed\u8fd0\u884c\u3002\n \n-Flink data processing pipelines begin with source tables. Source tables produce rows operated over during the query's execution; they are the tables referenced in the `FROM` clause of a query.  These could be Kafka topics, databases, filesystems, or any other system that Flink knows how to consume. \n+Flink \u6570\u636e\u5904\u7406\u7ba1\u9053\u5f00\u59cb\u4e8e source \u8868\u3002\u5728\u67e5\u8be2\u6267\u884c\u671f\u95f4\uff0csource \u8868\u4ea7\u751f\u64cd\u4f5c\u7684\u884c\uff1b\u5b83\u4eec\u662f\u67e5\u8be2\u65f6 `FROM` \u5b50\u53e5\u4e2d\u5f15\u7528\u7684\u8868\u3002\u8fd9\u4e9b\u8868\u53ef\u80fd\u662f Kafka \u7684 topics\uff0c\u6570\u636e\u5e93\uff0c\u6587\u4ef6\u7cfb\u7edf\uff0c\u6216 Flink \u77e5\u9053\u5982\u4f55\u6d88\u8d39\u7684\u4efb\u4f55\u5176\u4ed6\u7cfb\u7edf\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3NDExOQ==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549074119", "bodyText": "\"pipline\" -> \"\u6d41\u6c34\u7ebf\"", "author": "fsk119", "createdAt": "2020-12-27T06:54:16Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -113,13 +112,13 @@ SELECT * from employee_information WHERE DeptId = 1;\n \n {% top %}\n \n-## Continuous Queries\n+## \u8fde\u7eed\u67e5\u8be2\n \n-While not designed initially with streaming semantics in mind, SQL is a powerful tool for building continuous data pipelines. Where Flink SQL differs from traditional database queries is that is continuously consuming rows as the arrives and produces updates to its results. \n+\u867d\u7136\u6700\u521d\u8bbe\u8ba1\u65f6\u6ca1\u6709\u8003\u8651\u6d41\u8bed\u4e49\uff0c\u4f46 SQL \u662f\u7528\u4e8e\u6784\u5efa\u8fde\u7eed\u6570\u636e\u7ba1\u9053\u7684\u5f3a\u5927\u5de5\u5177\u3002Flink SQL \u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u67e5\u8be2\u7684\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0cFlink SQL \u6301\u7eed\u6d88\u8d39\u5230\u8fbe\u7684\u884c\u5e76\u5bf9\u5176\u7ed3\u679c\u8fdb\u884c\u66f4\u65b0\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3NDIzNw==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549074237", "bodyText": "\u201c\u7ed3\u679c\u4f1a\u751f\u6210\u4e00\u4e2a\u52a8\u6001\u8868\u201d -> \u201c\u5e76\u4f1a\u4ea7\u751f\u4e00\u4e2a\u52a8\u6001\u8868\u4f5c\u4e3a\u7ed3\u679c\u201d", "author": "fsk119", "createdAt": "2020-12-27T06:55:28Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -113,13 +112,13 @@ SELECT * from employee_information WHERE DeptId = 1;\n \n {% top %}\n \n-## Continuous Queries\n+## \u8fde\u7eed\u67e5\u8be2\n \n-While not designed initially with streaming semantics in mind, SQL is a powerful tool for building continuous data pipelines. Where Flink SQL differs from traditional database queries is that is continuously consuming rows as the arrives and produces updates to its results. \n+\u867d\u7136\u6700\u521d\u8bbe\u8ba1\u65f6\u6ca1\u6709\u8003\u8651\u6d41\u8bed\u4e49\uff0c\u4f46 SQL \u662f\u7528\u4e8e\u6784\u5efa\u8fde\u7eed\u6570\u636e\u7ba1\u9053\u7684\u5f3a\u5927\u5de5\u5177\u3002Flink SQL \u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u67e5\u8be2\u7684\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0cFlink SQL \u6301\u7eed\u6d88\u8d39\u5230\u8fbe\u7684\u884c\u5e76\u5bf9\u5176\u7ed3\u679c\u8fdb\u884c\u66f4\u65b0\u3002\n \n-A [continuous query]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries) never terminates and produces a dynamic table as a result. [Dynamic tables]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries) are the core concept of Flink's Table API and SQL support for streaming data. \n+\u4e00\u4e2a[\u8fde\u7eed\u67e5\u8be2]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries)\u6c38\u8fdc\u4e0d\u4f1a\u7ec8\u6b62\uff0c\u7ed3\u679c\u4f1a\u751f\u6210\u4e00\u4e2a\u52a8\u6001\u8868\u3002[\u52a8\u6001\u8868]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries)\u662f Flink \u4e2d Table API \u548c SQL \u5bf9\u6d41\u6570\u636e\u652f\u6301\u7684\u6838\u5fc3\u6982\u5ff5\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3NDYxNw==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549074617", "bodyText": "\u201c\u8fde\u7eed\u5b58\u50a8\u805a\u5408\u7ed3\u679c\u201d -> \u201c\u4e0d\u65ad\u5730\u5b58\u50a8\u805a\u5408\u7684\u7ed3\u679c\u201d \uff1f \u8fd9\u6837\u4f1a\u4e0d\u4f1a\u66f4\u901a\u987a\u70b9\uff1f\n\u201cmaintain\u201d -> \"\u7ef4\u62a4\" \uff1f", "author": "fsk119", "createdAt": "2020-12-27T06:59:23Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -113,13 +112,13 @@ SELECT * from employee_information WHERE DeptId = 1;\n \n {% top %}\n \n-## Continuous Queries\n+## \u8fde\u7eed\u67e5\u8be2\n \n-While not designed initially with streaming semantics in mind, SQL is a powerful tool for building continuous data pipelines. Where Flink SQL differs from traditional database queries is that is continuously consuming rows as the arrives and produces updates to its results. \n+\u867d\u7136\u6700\u521d\u8bbe\u8ba1\u65f6\u6ca1\u6709\u8003\u8651\u6d41\u8bed\u4e49\uff0c\u4f46 SQL \u662f\u7528\u4e8e\u6784\u5efa\u8fde\u7eed\u6570\u636e\u7ba1\u9053\u7684\u5f3a\u5927\u5de5\u5177\u3002Flink SQL \u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u67e5\u8be2\u7684\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0cFlink SQL \u6301\u7eed\u6d88\u8d39\u5230\u8fbe\u7684\u884c\u5e76\u5bf9\u5176\u7ed3\u679c\u8fdb\u884c\u66f4\u65b0\u3002\n \n-A [continuous query]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries) never terminates and produces a dynamic table as a result. [Dynamic tables]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries) are the core concept of Flink's Table API and SQL support for streaming data. \n+\u4e00\u4e2a[\u8fde\u7eed\u67e5\u8be2]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries)\u6c38\u8fdc\u4e0d\u4f1a\u7ec8\u6b62\uff0c\u7ed3\u679c\u4f1a\u751f\u6210\u4e00\u4e2a\u52a8\u6001\u8868\u3002[\u52a8\u6001\u8868]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries)\u662f Flink \u4e2d Table API \u548c SQL \u5bf9\u6d41\u6570\u636e\u652f\u6301\u7684\u6838\u5fc3\u6982\u5ff5\u3002\n \n-Aggregations on continuous streams need to store aggregated results continuously during the execution of the query. For example, suppose you need to count the number of employees for each department from an incoming data stream. The query needs to maintain the most up to date count for each department to output timely results as new rows are processed.\n+\u8fde\u7eed\u6d41\u4e0a\u7684\u805a\u5408\u9700\u8981\u5728\u67e5\u8be2\u6267\u884c\u671f\u95f4\u8fde\u7eed\u5b58\u50a8\u805a\u5408\u7ed3\u679c\u3002\u4f8b\u5982\uff0c\u5047\u8bbe\u4f60\u9700\u8981\u4ece\u4f20\u5165\u7684\u6570\u636e\u6d41\u4e2d\u8ba1\u7b97\u6bcf\u4e2a\u90e8\u95e8\u7684\u5458\u5de5\u4eba\u6570\u3002\u67e5\u8be2\u9700\u8981\u4fdd\u6301\u6bcf\u4e2a\u90e8\u95e8\u6700\u65b0\u7684\u8ba1\u7b97\u603b\u6570\uff0c\u4ee5\u4fbf\u5728\u5904\u7406\u65b0\u884c\u65f6\u53ca\u65f6\u8f93\u51fa\u7ed3\u679c\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3NjMyNg==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549076326", "bodyText": "\u201cFlink has a support for different [connectors] and [formats] that can be used with tables.\u201d -> \"Flink \u652f\u6301 \u4e0d\u540c\u7684 \u8fde\u63a5\u5668\u548c\u683c\u5f0f\u76f8\u7ed3\u5408\u4ee5\u5b9a\u4e49\u8868\u3002\" \u8fd9\u6837\u5b50\u7ffb\u8bd1\u4e0d\u77e5\u9053\u51c6\u4e0d\u51c6\u786e\uff1f\n\"a source table backed by a CSV file\" -> \"\u4ee5 CSV \u6587\u4ef6\u4f5c\u4e3a\u5b58\u50a8\u683c\u5f0f\u7684 source \u8868\"", "author": "fsk119", "createdAt": "2020-12-27T07:20:07Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -79,16 +79,15 @@ SELECT CURRENT_TIMESTAMP;\n \n {% top %}\n \n-## Source Tables\n+## Source \u8868\n \n-As with all SQL engines, Flink queries operate on top of tables. \n-It differs from a traditional database because Flink does not manage data at rest locally; instead, its queries operate continuously over external tables. \n+\u4e0e\u6240\u6709 SQL \u5f15\u64ce\u4e00\u6837\uff0cFlink \u67e5\u8be2\u5728\u8868\u4e0a\u8fdb\u884c\u64cd\u4f5c\u3002\u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u4e0d\u540c\uff0c\u56e0\u4e3a Flink \u4e0d\u5728\u672c\u5730\u7ba1\u7406\u9759\u6001\u6570\u636e\uff1b\u76f8\u53cd\uff0c\u5b83\u7684\u67e5\u8be2\u5728\u5916\u90e8\u8868\u4e0a\u8fde\u7eed\u8fd0\u884c\u3002\n \n-Flink data processing pipelines begin with source tables. Source tables produce rows operated over during the query's execution; they are the tables referenced in the `FROM` clause of a query.  These could be Kafka topics, databases, filesystems, or any other system that Flink knows how to consume. \n+Flink \u6570\u636e\u5904\u7406\u7ba1\u9053\u5f00\u59cb\u4e8e source \u8868\u3002\u5728\u67e5\u8be2\u6267\u884c\u671f\u95f4\uff0csource \u8868\u4ea7\u751f\u64cd\u4f5c\u7684\u884c\uff1b\u5b83\u4eec\u662f\u67e5\u8be2\u65f6 `FROM` \u5b50\u53e5\u4e2d\u5f15\u7528\u7684\u8868\u3002\u8fd9\u4e9b\u8868\u53ef\u80fd\u662f Kafka \u7684 topics\uff0c\u6570\u636e\u5e93\uff0c\u6587\u4ef6\u7cfb\u7edf\uff0c\u6216 Flink \u77e5\u9053\u5982\u4f55\u6d88\u8d39\u7684\u4efb\u4f55\u5176\u4ed6\u7cfb\u7edf\u3002\n \n-Tables can be defined through the SQL client or using environment config file. The SQL client support [SQL DDL commands]({% link dev/table/sql/index.zh.md %}) similar to traditional SQL. Standard SQL DDL is used to [create]({% link dev/table/sql/create.zh.md %}), [alter]({% link dev/table/sql/alter.zh.md %}), [drop]({% link dev/table/sql/drop.zh.md %}) tables. \n+\u53ef\u4ee5\u901a\u8fc7 SQL \u5ba2\u6237\u7aef\u6216\u4f7f\u7528\u73af\u5883\u914d\u7f6e\u6587\u4ef6\u6765\u5b9a\u4e49\u8868\u3002SQL \u5ba2\u6237\u7aef\u652f\u6301\u7c7b\u4f3c\u4e8e\u4f20\u7edf SQL \u7684 [SQL DDL \u547d\u4ee4]({% link dev/table/sql/index.zh.md %})\u3002\u6807\u51c6 SQL DDL \u7528\u4e8e[\u521b\u5efa]({% link dev/table/sql/create.zh.md %})\uff0c[\u4fee\u6539]({% link dev/table/sql/alter.zh.md %})\uff0c[\u5220\u9664]({% link dev/table/sql/drop.zh.md %})\u8868\u3002\n \n-Flink has a support for different [connectors]({% link dev/table/connect.zh.md %}) and [formats]({%link dev/table/connectors/formats/index.zh.md %}) that can be used with tables. Following is an example to define a source table backed by a [CSV file]({%link dev/table/connectors/formats/csv.zh.md %}) with `emp_id`, `name`, `dept_id` as columns in a `CREATE` table statement.\n+Flink \u652f\u6301\u53ef\u4ee5\u4e0e\u8868\u4e00\u8d77\u4f7f\u7528\u7684\u4e0d\u540c[\u8fde\u63a5\u5668]({% link dev/table/connect.zh.md %})\u548c[\u683c\u5f0f]({% link dev/table/connectors/formats/index.zh.md %})\u3002\u4e0b\u9762\u662f\u4e00\u4e2a\u793a\u4f8b\uff0c\u5b9a\u4e49\u4e00\u4e2a[CSV \u6587\u4ef6]({% link dev/table/connectors/formats/csv.zh.md %})\u4f5c\u4e3a source \u8868\uff0c\u5176\u4e2d `emp_id`\uff0c`name`\uff0c`dept_id` \u4f5c\u4e3a `CREATE` \u8868\u8bed\u53e5\u4e2d\u7684\u5217\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3NzE3Mg==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549077172", "bodyText": "\"\u5b58\u50a8\u7ed3\u679c\uff08\u4e3a\u62a5\u8868\u6216\u4eea\u8868\u677f\u63d0\u4f9b\u6570\u636e\u6765\u6e90\uff09\u9700\u8981\u5199\u5230\u53e6\u4e00\u4e2a\u8868\" -> \"\u5b58\u50a8\u7ed3\u679c\uff0c\u4f5c\u4e3a\u62a5\u8868\u6216\u4eea\u8868\u677f\u63d0\u4f9b\u6570\u636e\u6765\u6e90\uff0c\u9700\u8981\u5199\u5230\u53e6\u4e00\u4e2a\u8868\"", "author": "fsk119", "createdAt": "2020-12-27T07:30:21Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -129,11 +128,11 @@ FROM employee_information\n GROUP BY dep_id;\n  {% endhighlight %} \n \n-Such queries are considered _stateful_. Flink's advanced fault-tolerance mechanism will maintain internal state and consistency, so queries always return the correct result, even in the face of hardware failure. \n+\u8fd9\u6837\u7684\u67e5\u8be2\u88ab\u8ba4\u4e3a\u662f _\u6709\u72b6\u6001\u7684_\u3002Flink \u7684\u9ad8\u7ea7\u5bb9\u9519\u673a\u5236\u5c06\u7ef4\u6301\u5185\u90e8\u72b6\u6001\u548c\u4e00\u81f4\u6027\uff0c\u56e0\u6b64\u5373\u4f7f\u9047\u5230\u786c\u4ef6\u6545\u969c\uff0c\u67e5\u8be2\u4e5f\u59cb\u7ec8\u8fd4\u56de\u6b63\u786e\u7ed3\u679c\u3002\n \n-## Sink Tables\n+## Sink \u8868\n \n-When running this query, the SQL client provides output in real-time but in a read-only fashion. Storing results - to power a report or dashboard - requires writing out to another table. This can be achieved using an `INSERT INTO` statement. The table referenced in this clause is known as a sink table. An `INSERT INTO` statement will be submitted as a detached query to the Flink cluster. \n+\u5f53\u8fd0\u884c\u6b64\u67e5\u8be2\u65f6\uff0cSQL \u5ba2\u6237\u7aef\u5b9e\u65f6\u4f46\u662f\u4ee5\u53ea\u8bfb\u65b9\u5f0f\u63d0\u4f9b\u8f93\u51fa\u3002\u5b58\u50a8\u7ed3\u679c\uff08\u4e3a\u62a5\u8868\u6216\u4eea\u8868\u677f\u63d0\u4f9b\u6570\u636e\u6765\u6e90\uff09\u9700\u8981\u5199\u5230\u53e6\u4e00\u4e2a\u8868\u3002\u8fd9\u53ef\u4ee5\u4f7f\u7528 `INSERT INTO` \u8bed\u53e5\u6765\u5b9e\u73b0\u3002\u672c\u8282\u4e2d\u5f15\u7528\u7684\u8868\u79f0\u4e3a sink \u8868\u3002`INSERT INTO` \u8bed\u53e5\u5c06\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u67e5\u8be2\u88ab\u63d0\u4ea4\u5230 Flink \u96c6\u7fa4\u4e2d\u3002", "originalCommit": "8192b4f076bc5e5c62d283ef5ff67d2182a128ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTIzODI2Ng==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549238266", "bodyText": "\u201c\u4f5c\u4e3a\u62a5\u8868\u6216\u4eea\u8868\u677f\u63d0\u4f9b\u6570\u636e\u6765\u6e90\u201d -> \"\u4f5c\u4e3a\u62a5\u8868\u6216\u4eea\u8868\u677f\u7684\u6570\u636e\u6765\u6e90\"   \u7406\u89e3\u60a8\u7684\u610f\u601d\u4e86\uff0c\u8fd9\u91cc\u201c\u63d0\u4f9b\u201d\u6539\u4e3a\u201c\u7684\u201d\u5e94\u8be5\u66f4\u901a\u987a\u4e00\u4e9b\u3002", "author": "jjiey", "createdAt": "2020-12-28T07:04:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTA3NzE3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU2NDU1OQ==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549564559", "bodyText": "Please remove this blank space.", "author": "fsk119", "createdAt": "2020-12-29T04:34:54Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -129,11 +128,11 @@ FROM employee_information\n GROUP BY dep_id;\n  {% endhighlight %} \n \n-Such queries are considered _stateful_. Flink's advanced fault-tolerance mechanism will maintain internal state and consistency, so queries always return the correct result, even in the face of hardware failure. \n+\u8fd9\u6837\u7684\u67e5\u8be2\u88ab\u8ba4\u4e3a\u662f _\u6709\u72b6\u6001\u7684_\u3002Flink \u7684\u9ad8\u7ea7\u5bb9\u9519\u673a\u5236\u5c06\u7ef4\u6301\u5185\u90e8\u72b6\u6001\u548c\u4e00\u81f4\u6027\uff0c\u56e0\u6b64\u5373\u4f7f\u9047\u5230\u786c\u4ef6\u6545\u969c\uff0c\u67e5\u8be2\u4e5f\u59cb\u7ec8\u8fd4\u56de\u6b63\u786e\u7ed3\u679c\u3002\n \n-## Sink Tables\n+## Sink \u8868\n \n-When running this query, the SQL client provides output in real-time but in a read-only fashion. Storing results - to power a report or dashboard - requires writing out to another table. This can be achieved using an `INSERT INTO` statement. The table referenced in this clause is known as a sink table. An `INSERT INTO` statement will be submitted as a detached query to the Flink cluster. \n+\u5f53\u8fd0\u884c\u6b64\u67e5\u8be2\u65f6\uff0cSQL \u5ba2\u6237\u7aef\u5b9e\u65f6\u4f46\u662f\u4ee5\u53ea\u8bfb\u65b9\u5f0f\u63d0\u4f9b\u8f93\u51fa\u3002\u5b58\u50a8\u7ed3\u679c\uff0c\u4f5c\u4e3a\u62a5\u8868\u6216\u4eea\u8868\u677f\u7684\u6570\u636e\u6765\u6e90\uff0c\u9700\u8981\u5199\u5230\u53e6\u4e00\u4e2a\u8868\u3002\u8fd9\u53ef\u4ee5\u4f7f\u7528 `INSERT INTO` \u8bed\u53e5\u6765\u5b9e\u73b0\u3002\u672c\u8282\u4e2d\u5f15\u7528\u7684\u8868\u79f0\u4e3a sink \u8868\u3002`INSERT INTO` \u8bed\u53e5\u5c06\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u67e5\u8be2\u88ab\u63d0\u4ea4\u5230 Flink \u96c6\u7fa4\u4e2d\u3002\n \n  {% highlight sql %}\n  INSERT INTO department_counts", "originalCommit": "c115e3ce78571ad9dfdad6c2ddcd95622b1f2d0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU2NTA0Mg==", "url": "https://github.com/apache/flink/pull/14437#discussion_r549565042", "bodyText": "Please delete empty space before SELECT", "author": "fsk119", "createdAt": "2020-12-29T04:38:00Z", "path": "docs/dev/table/sql/gettingStarted.zh.md", "diffHunk": "@@ -113,13 +112,13 @@ SELECT * from employee_information WHERE DeptId = 1;\n \n {% top %}\n \n-## Continuous Queries\n+## \u8fde\u7eed\u67e5\u8be2\n \n-While not designed initially with streaming semantics in mind, SQL is a powerful tool for building continuous data pipelines. Where Flink SQL differs from traditional database queries is that is continuously consuming rows as the arrives and produces updates to its results. \n+\u867d\u7136\u6700\u521d\u8bbe\u8ba1\u65f6\u6ca1\u6709\u8003\u8651\u6d41\u8bed\u4e49\uff0c\u4f46 SQL \u662f\u7528\u4e8e\u6784\u5efa\u8fde\u7eed\u6570\u636e\u6d41\u6c34\u7ebf\u7684\u5f3a\u5927\u5de5\u5177\u3002Flink SQL \u4e0e\u4f20\u7edf\u6570\u636e\u5e93\u67e5\u8be2\u7684\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0cFlink SQL \u6301\u7eed\u6d88\u8d39\u5230\u8fbe\u7684\u884c\u5e76\u5bf9\u5176\u7ed3\u679c\u8fdb\u884c\u66f4\u65b0\u3002\n \n-A [continuous query]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries) never terminates and produces a dynamic table as a result. [Dynamic tables]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries) are the core concept of Flink's Table API and SQL support for streaming data. \n+\u4e00\u4e2a[\u8fde\u7eed\u67e5\u8be2]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries)\u6c38\u8fdc\u4e0d\u4f1a\u7ec8\u6b62\uff0c\u5e76\u4f1a\u4ea7\u751f\u4e00\u4e2a\u52a8\u6001\u8868\u4f5c\u4e3a\u7ed3\u679c\u3002[\u52a8\u6001\u8868]({% link dev/table/streaming/dynamic_tables.zh.md %}#continuous-queries)\u662f Flink \u4e2d Table API \u548c SQL \u5bf9\u6d41\u6570\u636e\u652f\u6301\u7684\u6838\u5fc3\u6982\u5ff5\u3002\n \n-Aggregations on continuous streams need to store aggregated results continuously during the execution of the query. For example, suppose you need to count the number of employees for each department from an incoming data stream. The query needs to maintain the most up to date count for each department to output timely results as new rows are processed.\n+\u8fde\u7eed\u6d41\u4e0a\u7684\u805a\u5408\u9700\u8981\u5728\u67e5\u8be2\u6267\u884c\u671f\u95f4\u4e0d\u65ad\u5730\u5b58\u50a8\u805a\u5408\u7684\u7ed3\u679c\u3002\u4f8b\u5982\uff0c\u5047\u8bbe\u4f60\u9700\u8981\u4ece\u4f20\u5165\u7684\u6570\u636e\u6d41\u4e2d\u8ba1\u7b97\u6bcf\u4e2a\u90e8\u95e8\u7684\u5458\u5de5\u4eba\u6570\u3002\u67e5\u8be2\u9700\u8981\u7ef4\u62a4\u6bcf\u4e2a\u90e8\u95e8\u6700\u65b0\u7684\u8ba1\u7b97\u603b\u6570\uff0c\u4ee5\u4fbf\u5728\u5904\u7406\u65b0\u884c\u65f6\u53ca\u65f6\u8f93\u51fa\u7ed3\u679c\u3002\n \n  {% highlight sql %}\n  SELECT ", "originalCommit": "c115e3ce78571ad9dfdad6c2ddcd95622b1f2d0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d6d492e6b8b68458c9c17a86e8d732d84363a522", "url": "https://github.com/apache/flink/commit/d6d492e6b8b68458c9c17a86e8d732d84363a522", "message": "[FLINK-20458][docs] remove blank space in \"docs/dev/table/sql/gettingStarted.zh.md\" and \"docs/dev/table/sql/gettingStarted.md\"", "committedDate": "2020-12-29T10:28:37Z", "type": "forcePushed"}, {"oid": "3789fc5ff0255aa3c2149d5aff287dd58c339d02", "url": "https://github.com/apache/flink/commit/3789fc5ff0255aa3c2149d5aff287dd58c339d02", "message": "[FLINK-20458][docs] translate gettingStarted.zh.md and correct spelling errors in gettingStarted.md", "committedDate": "2020-12-29T10:45:09Z", "type": "commit"}, {"oid": "6673016984b60ec4ddcc1f819816ceb873da6668", "url": "https://github.com/apache/flink/commit/6673016984b60ec4ddcc1f819816ceb873da6668", "message": "[FLINK-20458][docs] modify the doc gettingStarted.zh.md according to the review comments", "committedDate": "2020-12-29T10:45:09Z", "type": "commit"}, {"oid": "ab9aa91d53838537f88c453f0e90b6fca22193ed", "url": "https://github.com/apache/flink/commit/ab9aa91d53838537f88c453f0e90b6fca22193ed", "message": "[FLINK-20458][docs] The word 'Source' convert to lowercase 'source'", "committedDate": "2020-12-29T10:45:09Z", "type": "commit"}, {"oid": "ffba56321d5f3ac3070d13ae6df131b107739863", "url": "https://github.com/apache/flink/commit/ffba56321d5f3ac3070d13ae6df131b107739863", "message": "[FLINK-20458][docs] remove blank space in \"docs/dev/table/sql/gettingStarted.zh.md\" and \"docs/dev/table/sql/gettingStarted.md\"", "committedDate": "2020-12-29T10:45:09Z", "type": "commit"}, {"oid": "ffba56321d5f3ac3070d13ae6df131b107739863", "url": "https://github.com/apache/flink/commit/ffba56321d5f3ac3070d13ae6df131b107739863", "message": "[FLINK-20458][docs] remove blank space in \"docs/dev/table/sql/gettingStarted.zh.md\" and \"docs/dev/table/sql/gettingStarted.md\"", "committedDate": "2020-12-29T10:45:09Z", "type": "forcePushed"}]}