{"pr_number": 10820, "pr_title": "[FLINK-15512][statebackend] Refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s)", "pr_createdAt": "2020-01-09T18:44:22Z", "pr_url": "https://github.com/apache/flink/pull/10820", "timeline": [{"oid": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "url": "https://github.com/apache/flink/commit/bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "message": "[FLINK-15512][statebackend] Refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s)\n\nDue to the implemenation of write buffer manager of RocksDB and the issue cannot create stric capacity limit cache, we need to refactor the mechanism to calculate the cache capacity shared among RocksDB instance(s).", "committedDate": "2020-01-09T18:13:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyMzMwNw==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365123307", "bodyText": "Wondering why this description need to be changed, please clarify, thanks.", "author": "carp84", "createdAt": "2020-01-10T08:42:26Z", "path": "docs/_includes/generated/rocks_db_configuration.html", "diffHunk": "@@ -30,7 +30,7 @@\n             <td><h5>state.backend.rocksdb.memory.high-prio-pool-ratio</h5></td>\n             <td style=\"word-wrap: break-word;\">0.1</td>\n             <td>Double</td>\n-            <td>The fraction of cache memory that is reserved for high-priority data like index, filter, and compression dictionary blocks. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.</td>\n+            <td>The fraction of total shared memory that is reserved for high-priority data like index, filter, and compression dictionary blocks. This option only has an effect when 'state.backend.rocksdb.memory.managed' or 'state.backend.rocksdb.memory.fixed-per-slot' are configured.</td>", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTI3NTgxNA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365275814", "bodyText": "Thanks for pointing out, it should not be changed here since the ratio is really used by the cache.", "author": "Myasuka", "createdAt": "2020-01-10T15:03:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyMzMwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyNzU2OQ==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365127569", "bodyText": "Suggest to add a TODO comment here, mentioning that we will change the strictCapacityLimit flag to true after rocksdb#6247 is resolved.", "author": "carp84", "createdAt": "2020-01-10T08:53:15Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,40 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long size, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheSize = calculateActualCacheSize(size, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheSize, highPriorityPoolRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager((long) (writeBufferRatio * size), cache);\n+\t\treturn new RocksDBSharedResources(cache, wbm);\n+\t}\n+\n+\t/**\n+\t * Calculate the actual calculated memory size of cache, which would be shared among rocksDB instance(s).\n+\t * We introduce this method because:\n+\t * a) We cannot create a strict capacity limit cache util FLINK-15532 resolved.\n+\t * b) Regardless of the memory usage of blocks pinned by RocksDB iterators,\n+\t * which is difficult to calculate and only happened when we iterator entries in RocksDBMapState, the overuse of memory is mainly occupied by at most half of the write buffer usage.\n+\t * (see <a href=\"https://github.com/dataArtisans/frocksdb/blob/958f191d3f7276ae59b270f9db8390034d549ee0/include/rocksdb/write_buffer_manager.h#L51\">the flush implementation of write buffer manager</a>).\n+\t * Thus, we have four equations below:\n+\t *   write_buffer_manager_memory = 1.5 * write_buffer_manager_capacity\n+\t *   write_buffer_manager_memory = total_memory_size * write_buffer_ratio\n+\t *   write_buffer_manager_memory + other_part = total_memory_size\n+\t *   write_buffer_manager_capacity + other_part = cache_size\n+\t * And we would deduce the formula: cache_size = 3 * total_memory_size / (3 + write_buffer_ratio)\n+\t *\n+\t * @param totalMemorySize  Total off-heap memory size reserved for RocksDB instance(s).\n+\t * @param writeBufferRatio The ratio of memory size which could be reserved for write buffer manager to control the memory usage.\n+\t * @return The actual calculated memory size.\n+\t */\n+\t@VisibleForTesting\n+\tstatic long calculateActualCacheSize(long totalMemorySize, double writeBufferRatio) {\n+\t\treturn (long) (3 * totalMemorySize / (3 + writeBufferRatio));\n+\t}\n+\n+\t@VisibleForTesting\n+\tstatic Cache createCache(long cacheSize, double highPriorityPoolRatio) {\n+\t\treturn new LRUCache(cacheSize, -1, false, highPriorityPoolRatio);", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTEyNzkyNA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365127924", "bodyText": "Ditto, please revert this change if no rational reason.", "author": "carp84", "createdAt": "2020-01-10T08:54:07Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java", "diffHunk": "@@ -121,7 +121,7 @@\n \t\t.doubleType()\n \t\t.defaultValue(0.1)\n \t\t.withDescription(String.format(\n-\t\t\t\t\"The fraction of cache memory that is reserved for high-priority data like index, filter, and \" +\n+\t\t\t\t\"The fraction of total shared memory that is reserved for high-priority data like index, filter, and \" +", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTIyNjkxMA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365226910", "bodyText": "The WriteBufferManager size should also be calculated with the deduced formula: 2 * total_memory_size * write_buffer_ratio / 3", "author": "carp84", "createdAt": "2020-01-10T13:12:41Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,40 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long size, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheSize = calculateActualCacheSize(size, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheSize, highPriorityPoolRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager((long) (writeBufferRatio * size), cache);", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTIyNzkzMQ==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365227931", "bodyText": "The design of this test seems to be tightly coupled with the implementation, while it's true that we cannot get the actual cache size through RocksDB's JNI (not exposed so reflection couldn't get it, either)", "author": "carp84", "createdAt": "2020-01-10T13:15:42Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java", "diffHunk": "@@ -145,12 +160,34 @@ public void testGetColumnFamilyOptionsWithSharedResources() throws Exception {\n \t\tcontainer.close();\n \t}\n \n+\t@Test\n+\tpublic void testCreateSharedResourcesWithExpectedCapacity() throws Exception {", "originalCommit": "bfc6c4a4f7baa0bec85a9105b96014bb1fa5ce87", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "url": "https://github.com/apache/flink/commit/64d8a9a6821c95f904ca567afd7a056be7f04f3a", "message": "address comments", "committedDate": "2020-01-10T17:25:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTU2NDk2OA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365564968", "bodyText": "I suggest to either remove this test, or also add a verification of write buffer manager size.", "author": "carp84", "createdAt": "2020-01-12T08:11:49Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/test/java/org/apache/flink/contrib/streaming/state/RocksDBResourceContainerTest.java", "diffHunk": "@@ -145,12 +160,34 @@ public void testGetColumnFamilyOptionsWithSharedResources() throws Exception {\n \t\tcontainer.close();\n \t}\n \n+\t@Test\n+\tpublic void testCreateSharedResourcesWithExpectedCapacity() throws Exception {\n+\t\tPowerMockito.spy(RocksDBOperationUtils.class);\n+\t\tfinal AtomicLong actualCacheCapacity = new AtomicLong(0L);\n+\t\t// the `createCache` wrapper is introduced due to PowerMockito cannot mock on native static method easily.\n+\t\tPowerMockito.when(RocksDBOperationUtils.createCache(anyLong(), anyDouble()))\n+\t\t\t.thenAnswer((Answer<LRUCache>) invocation -> {\n+\t\t\t\tObject[] arguments = invocation.getArguments();\n+\t\t\t\tactualCacheCapacity.set((long) arguments[0]);\n+\t\t\t\treturn (LRUCache) invocation.callRealMethod();\n+\t\t\t});\n+\n+\t\tlong totalMemorySize = 2048L;\n+\t\tdouble writeBufferRatio = 0.5;\n+\t\tdouble highPriPoolRatio = 0.1;\n+\t\tcreateSharedResources(totalMemorySize, writeBufferRatio, highPriPoolRatio);\n+\t\tlong expectedCacheCapacity = RocksDBOperationUtils.calculateActualCacheCapacity(totalMemorySize, writeBufferRatio);\n+\t\tassertThat(actualCacheCapacity.get(), is(expectedCacheCapacity));", "originalCommit": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTU2NTAxMA==", "url": "https://github.com/apache/flink/pull/10820#discussion_r365565010", "bodyText": "Minor: the actual calculated memory size -> the actual memory size", "author": "carp84", "createdAt": "2020-01-12T08:12:39Z", "path": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java", "diffHunk": "@@ -213,4 +211,49 @@ public static void addColumnFamilyOptionsToCloseLater(\n \t\t\tthrow new IOException(\"Failed to acquire shared cache resource for RocksDB\", e);\n \t\t}\n \t}\n+\n+\t@VisibleForTesting\n+\tstatic RocksDBSharedResources allocateRocksDBSharedResources(long memorySize, double writeBufferRatio, double highPriorityPoolRatio) {\n+\t\tlong calculatedCacheCapacity = calculateActualCacheCapacity(memorySize, writeBufferRatio);\n+\t\tfinal Cache cache = createCache(calculatedCacheCapacity, highPriorityPoolRatio);\n+\t\tlong writeBufferManagerCapacity = calculateWriteBufferManagerCapacity(memorySize, writeBufferRatio);\n+\t\tfinal WriteBufferManager wbm = new WriteBufferManager(writeBufferManagerCapacity, cache);\n+\t\treturn new RocksDBSharedResources(cache, wbm);\n+\t}\n+\n+\t/**\n+\t * Calculate the actual calculated memory size of cache, which would be shared among rocksDB instance(s).", "originalCommit": "64d8a9a6821c95f904ca567afd7a056be7f04f3a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2d9edb24152bed26f717b6f87725efaa796d64e9", "url": "https://github.com/apache/flink/commit/2d9edb24152bed26f717b6f87725efaa796d64e9", "message": "address comments\n\n1. Add tests for wirte buffer manager\n2. Refactor RocksDBMemoryControllerUtils and its tests", "committedDate": "2020-01-12T12:44:26Z", "type": "commit"}, {"oid": "584b04c3756dfd8723a103b8f1502b4bccf3a6a6", "url": "https://github.com/apache/flink/commit/584b04c3756dfd8723a103b8f1502b4bccf3a6a6", "message": "minor fix on docs", "committedDate": "2020-01-12T12:46:03Z", "type": "commit"}]}