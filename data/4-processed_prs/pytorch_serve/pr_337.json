{"pr_number": 337, "pr_title": "Updated configuration.md for missing config properties", "pr_createdAt": "2020-05-12T15:52:01Z", "pr_url": "https://github.com/pytorch/serve/pull/337", "timeline": [{"oid": "ba630c5b64641eb61bb1a3dce57327c432d9c604", "url": "https://github.com/pytorch/serve/commit/ba630c5b64641eb61bb1a3dce57327c432d9c604", "message": "Updated configuration.md for missing parameters", "committedDate": "2020-05-12T14:35:24Z", "type": "commit"}, {"oid": "acd2269be5d50ea7ee7b839fe31bf7c041671931", "url": "https://github.com/pytorch/serve/commit/acd2269be5d50ea7ee7b839fe31bf7c041671931", "message": "changes TS_MODEL_SNAPSHOT to MODEL_SNAPSHOT\n- removes ambiguity\n- follows naming convention", "committedDate": "2020-05-12T16:06:44Z", "type": "commit"}, {"oid": "d8ca5e1add1334d0c8c51e614c36089ee4436f29", "url": "https://github.com/pytorch/serve/commit/d8ca5e1add1334d0c8c51e614c36089ee4436f29", "message": "Merge branch 'staging_0_1_1' into issue_204", "committedDate": "2020-05-19T05:36:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY1OTQ0OQ==", "url": "https://github.com/pytorch/serve/pull/337#discussion_r427659449", "bodyText": "This works, but their is no server-side exception, fails silently. I have to run curl with verbose output to see the following response code. Maybe we should document this\n< HTTP/1.1 413 Request Entity Too Large\n< content-length: 0\n* HTTP error before end of send, stop sending\n\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `max_request_size` : The maximum allowable request size that the Torchserve accepts.\n          \n          \n            \n            * `max_request_size` : The maximum allowable request size that the Torchserve accepts, in bytes.", "author": "maaquib", "createdAt": "2020-05-19T23:37:20Z", "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.\n+* `model_store` : path of model store directory.\n+* `model_server_home` : Torchserve home directory.\n+* `max_request_size` : The maximum allowable request size that the Torchserve accepts.", "originalCommit": "d8ca5e1add1334d0c8c51e614c36089ee4436f29", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIyNDQ5OA==", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428224498", "bodyText": "Done", "author": "shivamshriwas", "createdAt": "2020-05-20T18:33:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY1OTQ0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY2MDQxOA==", "url": "https://github.com/pytorch/serve/pull/337#discussion_r427660418", "bodyText": "Doesn't seem to be working\n> cat /tmp/serve/config.properties\ndebug=true\nmodel_store=/tmp/model-store\nmodel_server_home=/tmp/model-server-home\nmax_request_size=1000000\nmax_response_size=1\n\n> torchserve --start --ts-config config.properties\n...\nDefault workers per model: 1\nBlacklist Regex: N/A\nMaximum Response Size: 1\nMaximum Request Size: 1000000\n...\n\n> curl -X POST \"http://127.0.0.1:8081/models?url=https://torchserve.s3.amazonaws.com/mar_files/squeezenet1_1.mar\"\n\n> curl -X POST http://0.0.0.0:8080/predictions/squeezenet1_1 -T /tmp/kitten.jpg\n{\n  \"code\": 503,\n  \"type\": \"ServiceUnavailableException\",\n  \"message\": \"No worker is available to serve request: squeezenet1_1\"\n}\n\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.\n          \n          \n            \n            * `debug`: Runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.", "author": "maaquib", "createdAt": "2020-05-19T23:40:35Z", "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.", "originalCommit": "d8ca5e1add1334d0c8c51e614c36089ee4436f29", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIzMDUyMA==", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428230520", "bodyText": "@maaquib Updated debug in config properties as suggested.\nFor detailed description on running to torchserve in debug mode we will be adding\na separate doc file.", "author": "shivamshriwas", "createdAt": "2020-05-20T18:40:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY2MDQxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY2MDQ4Mw==", "url": "https://github.com/pytorch/serve/pull/337#discussion_r427660483", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `model_store` : path of model store directory.\n          \n          \n            \n            * `model_store` : Path of model store directory.", "author": "maaquib", "createdAt": "2020-05-19T23:40:45Z", "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.\n+* `model_store` : path of model store directory.", "originalCommit": "d8ca5e1add1334d0c8c51e614c36089ee4436f29", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIzMDc4Mg==", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428230782", "bodyText": "Done", "author": "shivamshriwas", "createdAt": "2020-05-20T18:40:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY2MDQ4Mw=="}], "type": "inlineReview"}, {"oid": "b3f3db2f5e107e0430c62e4d54cdc63bb051c9e5", "url": "https://github.com/pytorch/serve/commit/b3f3db2f5e107e0430c62e4d54cdc63bb051c9e5", "message": "Merge branch 'staging_0_1_1' into issue_204", "committedDate": "2020-05-20T00:18:00Z", "type": "commit"}, {"oid": "a76474897952f76eab442323232295fa4eda1e46", "url": "https://github.com/pytorch/serve/commit/a76474897952f76eab442323232295fa4eda1e46", "message": "addressed review comments.", "committedDate": "2020-05-20T18:31:27Z", "type": "commit"}, {"oid": "04b0170fad13dc4a5a3396725fa86c626da61b44", "url": "https://github.com/pytorch/serve/commit/04b0170fad13dc4a5a3396725fa86c626da61b44", "message": "Merge branch 'issue_204' of https://github.com/pytorch/serve into issue_204", "committedDate": "2020-05-20T18:31:58Z", "type": "commit"}, {"oid": "e5184ca57995320681446a1284627957968b9968", "url": "https://github.com/pytorch/serve/commit/e5184ca57995320681446a1284627957968b9968", "message": "Merge branch 'staging_0_1_1' of https://github.com/pytorch/serve into issue_204", "committedDate": "2020-05-20T18:32:18Z", "type": "commit"}, {"oid": "a8369dbde5fb6ccee9e1975cfa96d8eb2d8e30d9", "url": "https://github.com/pytorch/serve/commit/a8369dbde5fb6ccee9e1975cfa96d8eb2d8e30d9", "message": "Merge branch 'staging_0_1_1' into issue_204", "committedDate": "2020-05-20T19:32:39Z", "type": "commit"}, {"oid": "888e3b36bd460113488173a4a31da7cae20dac76", "url": "https://github.com/pytorch/serve/commit/888e3b36bd460113488173a4a31da7cae20dac76", "message": "removed debug property", "committedDate": "2020-05-21T10:03:19Z", "type": "commit"}, {"oid": "5b8fe71dc187f6f04d3bfa2c50ea79299bf8f31e", "url": "https://github.com/pytorch/serve/commit/5b8fe71dc187f6f04d3bfa2c50ea79299bf8f31e", "message": "Merge branch 'issue_204' of https://github.com/pytorch/serve into issue_204", "committedDate": "2020-05-21T10:04:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODczNjIwNw==", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428736207", "bodyText": "List down steps", "author": "dhaniram-kshirsagar", "createdAt": "2020-05-21T15:41:33Z", "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,17 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `model_store` : Path of model store directory.\n+* `model_server_home` : Torchserve home directory. \n+* `max_request_size` : The maximum allowable request size that the Torchserve accepts, in bytes. Default: 6553500\n+* `max_response_size` : The maximum buffer size the frontend allocates for a worker response, in bytes. Default: 6553500\n+\n+---\n+**NOTE**\n+\n+Config properties can be set using environment variable only when `enable_envvars_config` is true and ", "originalCommit": "5b8fe71dc187f6f04d3bfa2c50ea79299bf8f31e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc4MjE3NA==", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428782174", "bodyText": "done", "author": "shivamshriwas", "createdAt": "2020-05-21T16:53:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODczNjIwNw=="}], "type": "inlineReview"}, {"oid": "29dfd9375292bf056777073631de867db44f4054", "url": "https://github.com/pytorch/serve/commit/29dfd9375292bf056777073631de867db44f4054", "message": "updated configuration.md", "committedDate": "2020-05-21T16:51:06Z", "type": "commit"}, {"oid": "3456e29503789fc2bfdbf1ab4a118e4495b3b8bf", "url": "https://github.com/pytorch/serve/commit/3456e29503789fc2bfdbf1ab4a118e4495b3b8bf", "message": "Merge branch 'staging_0_1_1' of https://github.com/pytorch/serve into issue_204\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/util/ConfigManager.java", "committedDate": "2020-05-21T18:19:45Z", "type": "commit"}, {"oid": "1af405bd64b95b296460646202b000a6c24250ec", "url": "https://github.com/pytorch/serve/commit/1af405bd64b95b296460646202b000a6c24250ec", "message": "Merge branch 'staging_0_1_1' into issue_204", "committedDate": "2020-05-21T18:37:56Z", "type": "commit"}]}