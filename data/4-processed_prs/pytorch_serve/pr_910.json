{"pr_number": 910, "pr_title": "Modified the readmes for kfserving, wrapper and image transformer", "pr_createdAt": "2020-12-16T16:09:14Z", "pr_url": "https://github.com/pytorch/serve/pull/910", "timeline": [{"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "url": "https://github.com/pytorch/serve/commit/18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "message": "Modified the readmes for kfserving, wrapper and image transformer", "committedDate": "2020-12-16T15:56:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4Nzk3Nw==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544487977", "bodyText": "@abishekchiffon Please change to \"TorchServe supports Captum explanations for eager mode only\"  this is for all models and nothing specific to mnist model", "author": "chauhang", "createdAt": "2020-12-16T17:31:05Z", "path": "examples/image_classifier/mnist/README.md", "diffHunk": "@@ -51,6 +51,8 @@ When a json file is passed as a request format to the curl, Torchserve unwraps t\n \n The explain is called with the following request api http://127.0.0.1:8080/explanations/mnist_explain\n \n+Torchserve supports Captum Explanations for Eager models of mnist only.", "originalCommit": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4ODkxMA==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544488910", "bodyText": "Same comment for other places as well", "author": "chauhang", "createdAt": "2020-12-16T17:32:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4Nzk3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDkzNDAxMw==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544934013", "bodyText": "@chauhang  Changed in all the places.", "author": "abishekchiffon", "createdAt": "2020-12-17T09:22:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4Nzk3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ5MDc5NA==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544490794", "bodyText": "Please change to \"The service_envelope=kfserving setting is needed when deploying models on KFServing\"", "author": "chauhang", "createdAt": "2020-12-16T17:35:10Z", "path": "kubernetes/kfserving/Huggingface_readme.md", "diffHunk": "@@ -14,17 +14,23 @@ This produces all the required files for packaging using a huggingface transform\n The .mar file creation command is as below:\n \n ```\n-torch-model-archiver --model-name BERTSeqClassification --version 1.0 --serialized-file serve/examples/Huggingface_Transformers/Transformer_model/pytorch_model.bin --handler serve/examples/Huggingface_Transformers/Transformer_model/Transformer_handler_generalized.py --source-vocab serve/examples/Huggingface_Transformers/Transformer_model/vocab.txt --extra-files \"Transformer_model/config.json,serve/examples/Huggingface_Transformers/Transformer_model/setup_config.json,serve/examples/Huggingface_Transformers/Transformer_model/index_to_name.json\"\n+torch-model-archiver --model-name BERTSeqClassification --version 1.0 --serialized-file serve/examples/Huggingface_Transformers/Transformer_model/pytorch_model.bin --handler serve/examples/Huggingface_Transformers/Transformer_model/Transformer_handler_generalized.py --extra-files \"serve/examples/Huggingface_Transformers/Transformer_model/vocab.txt,serve/examples/Huggingface_Transformers/Transformer_model/config.json,serve/examples/Huggingface_Transformers/Transformer_model/setup_config.json,serve/examples/Huggingface_Transformers/Transformer_model/index_to_name.json\"\n ```\n \n-## Starting Torchserve\n+## Starting Torchserve for KFServing Predictor\n To serve an Inference Request for Torchserve using the KFServing Spec, follow the below:\n \n * create a config.properties file and specify the details as shown:\n ```\n+inference_address=http://127.0.0.0:8085\n+management_address=http://127.0.0.0:8081\n+number_of_netty_threads=4\n service_envelope=kfserving\n+job_queue_size=10\n+model_store=model-store\n+\n ```\n-The Service Envelope field is mandatory for Torchserve to process the KFServing Input Request Format.\n+The Service Envelope field should be set as kfserving and it is mandatory.", "originalCommit": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDkzNDQzOQ==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544934439", "bodyText": "@chauhang  Changed them in the respective places", "author": "abishekchiffon", "createdAt": "2020-12-17T09:23:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ5MDc5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDUzOTIxNw==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544539217", "bodyText": "Nitpick: Shouldn't this be json?", "author": "fbbradheintz", "createdAt": "2020-12-16T18:47:49Z", "path": "kubernetes/kfserving/Huggingface_readme.md", "diffHunk": "@@ -102,6 +112,20 @@ The Explanation response is as below :\n   ]\n }\n ```\n+\n+KFServing supports Static batching by adding new examples in the instances key of the request:\n+```bash", "originalCommit": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDkzNDcwNg==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544934706", "bodyText": "@fbbradheintz Modified", "author": "abishekchiffon", "createdAt": "2020-12-17T09:23:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDUzOTIxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MTc0NQ==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544541745", "bodyText": "Should this be json?", "author": "fbbradheintz", "createdAt": "2020-12-16T18:51:55Z", "path": "kubernetes/kfserving/README.md", "diffHunk": "@@ -231,7 +237,25 @@ The response is as below :\n   ]\n }\n ```\n-For the request and response of BERT and Text Classifier models, refer the \"Request and Response\" section of section of [BERT Readme file](https://github.com/pytorch/serve/blob/master/kubernetes/kfserving/Huggingface_readme.md) and [Text Classifier Readme file](https://github.com/pytorch/serve/blob/master/kubernetes/kfserving/text_classifier_readme.md). .\n+\n+KFServing supports Static batching by adding new examples in the instances key of the request:\n+\n+```bash", "originalCommit": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDkzNDczNQ==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544934735", "bodyText": "@fbbradheintz Modified", "author": "abishekchiffon", "createdAt": "2020-12-17T09:23:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MTc0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MjQ2NQ==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544542465", "bodyText": "Somewhere, we should add that when performing static batching this way, the user needs to make sure they're using batch size of 1 (even though more than one input instance is specified in the input). Doing otherwise will cause a failure.", "author": "fbbradheintz", "createdAt": "2020-12-16T18:53:00Z", "path": "kubernetes/kfserving/README.md", "diffHunk": "@@ -231,7 +237,25 @@ The response is as below :\n   ]\n }\n ```\n-For the request and response of BERT and Text Classifier models, refer the \"Request and Response\" section of section of [BERT Readme file](https://github.com/pytorch/serve/blob/master/kubernetes/kfserving/Huggingface_readme.md) and [Text Classifier Readme file](https://github.com/pytorch/serve/blob/master/kubernetes/kfserving/text_classifier_readme.md). .\n+\n+KFServing supports Static batching by adding new examples in the instances key of the request:", "originalCommit": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDkzNTMxMA==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544935310", "bodyText": "@fbbradheintz Added it", "author": "abishekchiffon", "createdAt": "2020-12-17T09:24:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MjQ2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MjYzMw==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544542633", "bodyText": "Somewhere, we should add that when performing static batching this way, the user needs to make sure they're using batch size of 1 (even though more than one input instance is specified in the input). Doing otherwise will cause a failure.", "author": "fbbradheintz", "createdAt": "2020-12-16T18:53:16Z", "path": "kubernetes/kfserving/Huggingface_readme.md", "diffHunk": "@@ -102,6 +112,20 @@ The Explanation response is as below :\n   ]\n }\n ```\n+\n+KFServing supports Static batching by adding new examples in the instances key of the request:", "originalCommit": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDkzNTM2MQ==", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544935361", "bodyText": "@fbbradheintz Added it", "author": "abishekchiffon", "createdAt": "2020-12-17T09:24:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MjYzMw=="}], "type": "inlineReview"}, {"oid": "2c8a987c45f44479457fc74e5afbe0fded146d8f", "url": "https://github.com/pytorch/serve/commit/2c8a987c45f44479457fc74e5afbe0fded146d8f", "message": "KFserving readme changes for static batching, image transformer and kfserving wrapper", "committedDate": "2020-12-17T09:21:22Z", "type": "commit"}, {"oid": "205b03ffb3b6aba92852d22c124c2746c2cfaa10", "url": "https://github.com/pytorch/serve/commit/205b03ffb3b6aba92852d22c124c2746c2cfaa10", "message": "Readme changes for kf cluster in end to end document", "committedDate": "2020-12-17T12:58:29Z", "type": "commit"}, {"oid": "03667af29f6b02e75c23f8ab335ae67b348c8612", "url": "https://github.com/pytorch/serve/commit/03667af29f6b02e75c23f8ab335ae67b348c8612", "message": "Merge branch 'master' into kf_readme2", "committedDate": "2020-12-17T23:41:04Z", "type": "commit"}]}