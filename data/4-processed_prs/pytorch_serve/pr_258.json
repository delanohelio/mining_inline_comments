{"pr_number": 258, "pr_title": "added waveglow example", "pr_createdAt": "2020-04-23T17:08:58Z", "pr_url": "https://github.com/pytorch/serve/pull/258", "timeline": [{"oid": "ddc83afb346b7741e1ee1b5698449dae91793e99", "url": "https://github.com/pytorch/serve/commit/ddc83afb346b7741e1ee1b5698449dae91793e99", "message": "added waveglow example", "committedDate": "2020-04-23T16:57:13Z", "type": "commit"}, {"oid": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4", "url": "https://github.com/pytorch/serve/commit/c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4", "message": "Updated readme for waveglow example", "committedDate": "2020-04-24T13:18:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk5MTEzMQ==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r416991131", "bodyText": "This is a problem the first time through. It will start 4 workers by default, all four of which, during init, will try to download some resources to ~/.cache - the problem being that they'll overwrite each others' downloads, resulting in exceptions in the log. The behavior is not 100%, but I find it easiest to repro by starting without the --models arg on start, and using:\ncurl -X POST \"http://localhost:8081/models?initial_workers=4&url=wgsynth.mar\"\n\nThis results in error lines in the log, like:\nRuntimeError: unexpected EOF, expected 12400777 more bytes. The file might be corrupted.\n\nWhich results directly from trying to load files corrupted by download conflicts.", "author": "fbbradheintz", "createdAt": "2020-04-28T23:48:45Z", "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,49 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Download the checkpoint for NVIDIA WaveGlow model :\n+ \n+    ```bash\n+   wget https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth \n+   ```\n+\n+ * Create a torch model archive using the torch-model-archiver utility to archive the above files.\n+ \n+    ```bash\n+    torch-model-archiver --model-name waveglow_synthesizer --version 1.0 --model-file waveglow_model.py --serialized-file nvidia_waveglowpyt_fp32_20190306.pth --handler waveglow_handler.py\n+    ```\n+   \n+ * Register the model on TorchServe using the above model archive file and run digit recognition inference\n+   \n+    ```bash\n+    mkdir model_store\n+    mv waveglow_synthesizer.mar model_store/\n+    torchserve --start --model-store model_store --models waveglow_synthesizer.mar", "originalCommit": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk5NDI0OQ==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r416994249", "bodyText": "NB: https://github.com/nvidia/DeepLearningExamples/archive/torchhub.zip appears to be the problem file.\nOne possible fix: Add a manual download step at the beginning of the example, and include the necessary files in the model archive as --extra-files. The downloaded file, even unzipped, is much smaller than the model weights (I checked).", "author": "fbbradheintz", "createdAt": "2020-04-28T23:58:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk5MTEzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQ3NTI4Ng==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r417475286", "bodyText": "On reflection, we should probably discourage downloading large files as part of handler initialization generally, for this reason and others (e.g., worker startup timeout if a resource is slow to download).", "author": "fbbradheintz", "createdAt": "2020-04-29T17:09:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk5MTEzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTUzNzc2MA==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r419537760", "bodyText": "Done. Also added a create_mar.sh script which does all the work and  generates the waveglow mar file for the user.", "author": "harshbafna", "createdAt": "2020-05-04T15:50:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk5MTEzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU0NTAzNw==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r417545037", "bodyText": "One other item: At the team status meeting today, it was raised that this is not really a complete example, as it stashes the output in a file in /tmp - which does the requester no good if they're on another machine. To make the example truly valuable, it should package the file for download with the HTTP response.", "author": "fbbradheintz", "createdAt": "2020-04-29T19:04:44Z", "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,49 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Download the checkpoint for NVIDIA WaveGlow model :\n+ \n+    ```bash\n+   wget https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth \n+   ```\n+\n+ * Create a torch model archive using the torch-model-archiver utility to archive the above files.\n+ \n+    ```bash\n+    torch-model-archiver --model-name waveglow_synthesizer --version 1.0 --model-file waveglow_model.py --serialized-file nvidia_waveglowpyt_fp32_20190306.pth --handler waveglow_handler.py\n+    ```\n+   \n+ * Register the model on TorchServe using the above model archive file and run digit recognition inference\n+   \n+    ```bash\n+    mkdir model_store\n+    mv waveglow_synthesizer.mar model_store/\n+    torchserve --start --model-store model_store --models waveglow_synthesizer.mar\n+    curl -X POST http://127.0.0.1:8080/predictions/waveglow_synthesizer -T sample_text.txt\n+    ```\n+  * Response :\n+  ```text\n+    [Audio file generated successfully at /tmp/audio.wav]", "originalCommit": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDI4Mjk3MQ==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r420282971", "bodyText": "Done.", "author": "harshbafna", "createdAt": "2020-05-05T17:28:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU0NTAzNw=="}], "type": "inlineReview"}, {"oid": "32871ad4016687a941ad629b231ec469b76ffe7b", "url": "https://github.com/pytorch/serve/commit/32871ad4016687a941ad629b231ec469b76ffe7b", "message": "enhanced example to remove runtime checkpoint download", "committedDate": "2020-05-04T15:45:13Z", "type": "commit"}, {"oid": "321711e8d72234e58c5e138948d5f07b916d4515", "url": "https://github.com/pytorch/serve/commit/321711e8d72234e58c5e138948d5f07b916d4515", "message": "updated handler to return the audio file content instead of dumping it to tmp dir", "committedDate": "2020-05-05T17:27:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE5MDcxOA==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r421190718", "bodyText": "Nice!", "author": "mycpuorg", "createdAt": "2020-05-07T01:44:36Z", "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,37 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Generate the model archive for waveglow speech synthesis model using following command\n+ \n+    ```bash\n+    ./create_mar.sh", "originalCommit": "321711e8d72234e58c5e138948d5f07b916d4515", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e", "url": "https://github.com/pytorch/serve/commit/91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e", "message": "Merge branch 'staging_0_1_1' into issue_60", "committedDate": "2020-05-07T02:58:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r422605786", "bodyText": "@mycpuorg @harshbafna  Please provide steps for how the generated audio file will be downloaded when invoked from a remote machine or invoked by a python client application requesting the inference via the http api calls in the code.\nAlso explain if there are any limits on the size of the text that can be converted to audio. The size of audio file becomes large pretty soon, so the pipe may get broken on trying to download the generated audio file.", "author": "chauhang", "createdAt": "2020-05-10T08:02:45Z", "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,37 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Generate the model archive for waveglow speech synthesis model using following command\n+ \n+    ```bash\n+    ./create_mar.sh\n+    ```\n+   \n+ * Register the model on TorchServe using the above model archive file and run digit recognition inference\n+   \n+    ```bash\n+    mkdir model_store\n+    mv waveglow_synthesizer.mar model_store/\n+    torchserve --start --model-store model_store --models waveglow_synthesizer.mar\n+    curl -X POST http://127.0.0.1:8080/predictions/waveglow_synthesizer -T sample_text.txt -o audio.wav", "originalCommit": "91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY5MTg1MA==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423691850", "bodyText": "@chauhang : We have created this example using the checkpoint files, for tacotron and waveglow model, and the inference code used by following example provided in following PyTorch blog :\nhttps://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\nHowever, this model doesn't work properly for bigger text size as input. I have created following GH issue on NVIDIA/DeeplearningExamples repo : NVIDIA/DeepLearningExamples#497", "author": "harshbafna", "createdAt": "2020-05-12T12:26:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkwNzc0MA==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423907740", "bodyText": "@harshbafna It will be good to add reference to this issue in the example readme", "author": "chauhang", "createdAt": "2020-05-12T17:27:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkwOTAzMQ==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423909031", "bodyText": "@harshbafna What about the steps for downloading the audio file from python client using the TorchServe REST API? Is there any special handling needed?  It will be good to include a small python client code example", "author": "chauhang", "createdAt": "2020-05-12T17:29:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkxMDUyMA==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423910520", "bodyText": "@chauhang\nJust added a sample python snippet in the ReadMe.\nRegarding the issue related to the long text size, I am planning to update the waveglow handler based on the comment provided on the the ticket", "author": "harshbafna", "createdAt": "2020-05-12T17:31:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkxNDA1MQ==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423914051", "bodyText": "Regarding the limits on the size of the text that can be converted to audio :\nApart from the model limitations, the data size in request and response is governed by max_request_size and max_response_size config parameters. The default value for both the parameters is 6553500 bytes.\nThese parameters are not documented in configuration.md and will be taken up as part of fix for #204 ,where we will be updating all the config params and their respective environment variable names.", "author": "harshbafna", "createdAt": "2020-05-12T17:37:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkxNTk5NQ==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423915995", "bodyText": "@chauhang : Please let us know, if we should merge this PR with documentation changes for NVIDIA/DeepLearningExamples#497 and create another ticket for tracking the enhancement of waveglow_handler based on the solution from NVIDIA/DeepLearningExamples#497", "author": "harshbafna", "createdAt": "2020-05-12T17:40:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDQ0MzY4Ng==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r424443686", "bodyText": "@chauhang : Based on the comments on NVIDIA/DeepLearningExamples#497 we will need do additional pre-processing and post-processing in the example's custom handler. Now, this will require good amount of effort to make it work with different sizes of the text and related audio output.\nHence, as you have already indicated we will document this limitation of the waveglow example with reference to above ticket. If required, we can track this enhancement through a different ticket.", "author": "harshbafna", "createdAt": "2020-05-13T13:37:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjE5NDAxMA==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r426194010", "bodyText": "@harshbafna This should be fine. Please describe the current limitation is the doc and then merge the PR", "author": "chauhang", "createdAt": "2020-05-16T21:46:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYxMDM4OQ==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r422610389", "bodyText": "@harshbafna If the torch-model-archiver is not installed, there is no error message thrown, the scripts ends silently without any .mar file. Will be better to throw and error for user in this case", "author": "chauhang", "createdAt": "2020-05-10T08:34:58Z", "path": "examples/text_to_speech_synthesizer/create_mar.sh", "diffHunk": "@@ -0,0 +1,15 @@\n+cd /tmp\n+rm torchhub.zip\n+wget https://github.com/nvidia/DeepLearningExamples/archive/torchhub.zip\n+rm -rf DeepLearningExamples-torchhub\n+unzip torchhub.zip\n+cd -\n+rm tacotron.zip\n+rm -rf PyTorch\n+mkdir -p PyTorch/SpeechSynthesis\n+cp -r /tmp/DeepLearningExamples-torchhub/PyTorch/SpeechSynthesis/* PyTorch/SpeechSynthesis/\n+zip -r tacotron.zip PyTorch\n+wget https://api.ngc.nvidia.com/v2/models/nvidia/tacotron2pyt_fp32/versions/1/files/nvidia_tacotron2pyt_fp32_20190306.pth\n+wget wget https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth\n+torch-model-archiver --model-name waveglow_synthesizer --version 1.0 --model-file waveglow_model.py --serialized-file nvidia_waveglowpyt_fp32_20190306.pth --handler waveglow_handler.py --extra-files tacotron.zip,nvidia_tacotron2pyt_fp32_20190306.pth", "originalCommit": "91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkwOTg3Mg==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423909872", "bodyText": "Done. Added pipefail in the shell script.", "author": "harshbafna", "createdAt": "2020-05-12T17:30:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYxMDM4OQ=="}], "type": "inlineReview"}, {"oid": "451882b2a926e2e5a4c0877e002238668b6824aa", "url": "https://github.com/pytorch/serve/commit/451882b2a926e2e5a4c0877e002238668b6824aa", "message": "Merge branch 'staging_0_1_1' into issue_60", "committedDate": "2020-05-12T10:17:05Z", "type": "commit"}, {"oid": "64eca56cf06157424e79e627e481b2654f8bd5b8", "url": "https://github.com/pytorch/serve/commit/64eca56cf06157424e79e627e481b2654f8bd5b8", "message": "minor change to handler", "committedDate": "2020-05-12T10:25:24Z", "type": "commit"}, {"oid": "ff90b9df5a2785f5039b4eafe40ead451b642993", "url": "https://github.com/pytorch/serve/commit/ff90b9df5a2785f5039b4eafe40ead451b642993", "message": "added pipefail", "committedDate": "2020-05-12T16:54:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkwNjA4OQ==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423906089", "bodyText": "@harshbafna Can you please explain the purpose of this?", "author": "chauhang", "createdAt": "2020-05-12T17:24:14Z", "path": "examples/text_to_speech_synthesizer/waveglow_handler.py", "diffHunk": "@@ -62,6 +62,7 @@ def initialize(self, ctx):\n         waveglow_config = waveglow_checkpoint['config']\n         self.waveglow_model = WaveGlow(**waveglow_config)\n         self.waveglow_model.load_state_dict(waveglow_state_dict)\n+        self.waveglow_model = self.waveglow_model.remove_weightnorm(self.waveglow_model)", "originalCommit": "ff90b9df5a2785f5039b4eafe40ead451b642993", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkwNzQxNw==", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423907417", "bodyText": "@chauhang : This has been taken up from example in : https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/", "author": "harshbafna", "createdAt": "2020-05-12T17:26:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkwNjA4OQ=="}], "type": "inlineReview"}, {"oid": "1e738fd0a72d7472bd36f3cb6410916b7c358811", "url": "https://github.com/pytorch/serve/commit/1e738fd0a72d7472bd36f3cb6410916b7c358811", "message": "added python snippet to run inference", "committedDate": "2020-05-12T17:29:22Z", "type": "commit"}, {"oid": "167bddd8d2286b65c0577a4e566ae0bd7cfa660d", "url": "https://github.com/pytorch/serve/commit/167bddd8d2286b65c0577a4e566ae0bd7cfa660d", "message": "Merge branch 'staging_0_1_1' into issue_60", "committedDate": "2020-05-12T17:40:17Z", "type": "commit"}, {"oid": "5d06f8818a46f8b77b3a8431fbb614cb150102f5", "url": "https://github.com/pytorch/serve/commit/5d06f8818a46f8b77b3a8431fbb614cb150102f5", "message": "updated readme with know issue with the example", "committedDate": "2020-05-14T16:52:23Z", "type": "commit"}, {"oid": "0edafd0aba760270f2e0ae33b3fbd95b259360d4", "url": "https://github.com/pytorch/serve/commit/0edafd0aba760270f2e0ae33b3fbd95b259360d4", "message": "Merge branch 'issue_60' of https://github.com/pytorch/serve into issue_60", "committedDate": "2020-05-14T17:02:50Z", "type": "commit"}, {"oid": "6473178ecd0dbea3e813c505864b0984dfd9dab5", "url": "https://github.com/pytorch/serve/commit/6473178ecd0dbea3e813c505864b0984dfd9dab5", "message": "Merge branch 'staging_0_1_1' into issue_60", "committedDate": "2020-05-18T21:29:02Z", "type": "commit"}]}