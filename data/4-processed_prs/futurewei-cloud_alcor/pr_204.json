{"pr_number": 204, "pr_title": "[Documentation] Proposal of Alcor Integration with Nova", "pr_createdAt": "2020-05-19T08:32:18Z", "pr_url": "https://github.com/futurewei-cloud/alcor/pull/204", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzI1MDUzNA==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r427250534", "bodyText": "@Gzure Actually, this API of VPC manager is internal, only accessible by API gateway or other microservices, but not exposed to Nova or any other clients. Instead, the API gateway is the place where external clients could reach Alcor.\nFor example, we do have a similar API \"/project/{projectId}/network/{vpcId}\", and we could/should make changes there to make all APIs consistent with Nova so that we don't need to make code change to client, ideally.\n\n  \n    \n      alcor/services/api_gateway/src/main/java/com/futurewei/alcor/apigateway/vpc/VpcWebConfiguration.java\n    \n    \n         Line 39\n      in\n      0586423\n    \n    \n    \n    \n\n        \n          \n           .andRoute(GET(\"/project/{projectId}/network/{vpcId}\"), vpcWebHandlers::getVpc)", "author": "xieus", "createdAt": "2020-05-19T12:08:17Z", "path": "docs/design/integration_nova.adoc", "diffHunk": "@@ -20,16 +20,194 @@ We would want to integrate with Nova to support the same set of user operations,\n \n == Review of OpenStack Workflow\n \n+nova call neutron apis\n+|===\n+|Name |method |params |fields |neutron api |alcor status\n+\n+|show_network\n+|get\n+|net_id\n+|provider:physical_network,provider:network_type\n+|/v2.0/networks/{net_id}\n+|/v4/{project_id}/vpcs/{vpcid}", "originalCommit": "f2283f611799f4f1581cffdf46c45ebb860993ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzI1MTQ0Mw==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r427251443", "bodyText": "See multiple rows in this table with the same Name. Does this mean Nova calls Neutron or Alcor in multiple different scenarios, right? Can you specify the scenarios?", "author": "xieus", "createdAt": "2020-05-19T12:10:00Z", "path": "docs/design/integration_nova.adoc", "diffHunk": "@@ -20,16 +20,194 @@ We would want to integrate with Nova to support the same set of user operations,\n \n == Review of OpenStack Workflow\n \n+nova call neutron apis\n+|===\n+|Name |method |params |fields |neutron api |alcor status\n+\n+|show_network\n+|get\n+|net_id\n+|provider:physical_network,provider:network_type\n+|/v2.0/networks/{net_id}\n+|/v4/{project_id}/vpcs/{vpcid}\n+\n+|show_network", "originalCommit": "f2283f611799f4f1581cffdf46c45ebb860993ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzI1MzU2MQ==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r427253561", "bodyText": "Assuming that Alcor APIs is 100% compatible to Neutron, do we still need make changes to Nova? For example, Nova would need to know the server url and port of a new Alcor cluster. It is likely a Nova configuration. Could you list those configuration change as well?", "author": "xieus", "createdAt": "2020-05-19T12:13:34Z", "path": "docs/design/integration_nova.adoc", "diffHunk": "@@ -20,16 +20,194 @@ We would want to integrate with Nova to support the same set of user operations,\n \n == Review of OpenStack Workflow\n \n+nova call neutron apis\n+|===\n+|Name |method |params |fields |neutron api |alcor status\n+\n+|show_network\n+|get\n+|net_id\n+|provider:physical_network,provider:network_type\n+|/v2.0/networks/{net_id}\n+|/v4/{project_id}/vpcs/{vpcid}\n+\n+|show_network\n+|get\n+|net_id\n+|dns_domain\n+|/v2.0/networks/{net_id}\n+|/v4/{project_id}/vpcs/{vpcid}\n+\n+|show_network\n+|get\n+|net_id\n+|segments\n+|/v2.0/networks/{net_id}\n+|/v4/{project_id}/vpcs/{vpcid}\n+\n+|list_network\n+|get\n+|\n+|\n+|/v2.0/networks\n+|/project/{project_id}/vpcs\n+\n+|list_network\n+|get\n+|net_ids\n+|\n+|/v2.0/networks\n+|/project/{project_id}/vpcs\n+\n+|list_network\n+|get\n+|tenant_id: project_id, shared: False\n+|\n+|/v2.0/networks\n+|/project/{project_id}/vpcs(no support)\n+\n+|list_network\n+|get\n+|tenant_id: project_id, shared: False, admin_state_up: True\n+|\n+|/v2.0/networks\n+|/project/{project_id}/vpcs(no support)\n+\n+|list_network\n+|get\n+|shared: True\n+|\n+|/v2.0/networks\n+|/project/{project_id}/vpcs(no support)\n+\n+|list_subnets\n+|get\n+|id: [subnet_id]\n+|\n+|/v2.0/networks\n+|/project/{project_id}/subnets\n+\n+|show_port\n+|get\n+|\n+|binding_profile, network_id\n+|/v2.0/ports/{port_id}\n+|/project/{project_id}/ports/{port_id}\n+\n+|show_port\n+|get\n+|\n+|binding:vnic_type,network_id,binding_profile,resource_request\n+|/v2.0/ports/{port_id}\n+|/project/{project_id}/ports/{port_id}\n+\n+|list_ports\n+|get\n+|network_id: net_id,  device_owner: network_dhcp\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ports(no support)\n+\n+|list_ports\n+|get\n+|device_id: instance.uuid, tenant_id: project_id\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ports(no support)\n+\n+|list_ports\n+|get\n+|network_id: net_id, fixed_ips: ip_addrs\n+|device_id\n+|/v2.0/ports\n+|/project/{project_id}/ports(no support)\n+\n+|create_port\n+|post\n+|port: {device_id: instance.uuid, fixed_ips: fixed_ip, network_id: net_id, admin_state_up: True, tenant_id: project_id, security\u2014\u2014groups:{}}\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ports\n+\n+|update_port\n+|put\n+|port: {device_id: '', device_owner: '', 'binding:host_id': None, 'binding:profile': {}}\n+|\n+|/v2.0/ports/{port_id}\n+|/project/{project_id}/ports/{port_id}\n+\n+|update_port\n+|put\n+|port: {dns_name: ''}\n+|\n+|/v2.0/ports/{port_id}\n+|/project/{project_id}/ports/{port_id}\n+\n+|delete_port\n+|delete\n+|\n+|\n+|/v2.0/ports/{port_id}\n+|/project/{project_id}/ports/{port_id}\n+\n+|list_floatingips\n+|get\n+|fixed_ip_address: fixed_ip, port_id: port_id\n+|\n+|/v2.0/floatingips\n+|\n+\n+|list_floatingips\n+|get\n+|fixed_ip_address: fixed_ip\n+|\n+|/v2.0/floatingips\n+|\n+\n+|show_quota\n+|get\n+|\n+|\n+|/v2.0/quotas/{project_id}\n+|\n+\n+|list_extensions\n+|get\n+|\n+|return example:{'extensions':{{updated: 2017-07-17T10:00:00-00\uff1a00\uff0c name:port_binding_extended, links:[], alias: binding-extended, description: Expose port binding of a virtual port to external application}}}\n+|/v2.0/extensions\n+|\n+|===\n+\n === VM Creation Workflow\n image::images/vm_create.png[\"VM creation workflow\", width=1024, link=\"images/vm_create.png\"]\n \n == Required Changes\n+https://github.com/openstack/python-neutronclient[neutronclient project]\n \n-TBD\n+Nova use python-neutronclient to call neutron apis.Only need to change neutronclient/v2.0/client:Client class.\n \n == Integration Proposal\n \n-TBD\n+There are two ways to integration with nova:", "originalCommit": "f2283f611799f4f1581cffdf46c45ebb860993ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ2MTI1NA==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r428461254", "bodyText": "@Gzure Could you please address the comments based on the discussion in today's open-source meeting? Thank you.", "author": "xieus", "createdAt": "2020-05-21T06:01:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzI1MzU2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzI2NDA4OA==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r427264088", "bodyText": "Neutron 2.0 APIs doesn't need to provide a project id as it generates the project id based on the Authentication token in the X-Auth-Token request header, when Keystone is enabled.\nhttps://docs.openstack.org/api-ref/network/v2/\n\"The Networking API v2.0 uses the OpenStack Identity service as the default authentication service. When Keystone is enabled, users that submit requests to the OpenStack Networking service must provide an authentication token in X-Auth-Token request header. You obtain the token by authenticating to the Keystone endpoint.\nWhen Keystone is enabled, the project_id attribute is not required in create requests because the project ID is derived from the authentication token.\"\n@Gzure We will make changes to API Gateway to support Authentication & Authorization with KeyStone, and support same way how project id is generated based on X-Auth-Token in API Gateway. Can you include details in this design doc as well?", "author": "xieus", "createdAt": "2020-05-19T12:31:25Z", "path": "docs/design/integration_nova.adoc", "diffHunk": "@@ -20,16 +20,194 @@ We would want to integrate with Nova to support the same set of user operations,\n \n == Review of OpenStack Workflow\n \n+nova call neutron apis\n+|===\n+|Name |method |params |fields |neutron api |alcor status\n+\n+|show_network\n+|get\n+|net_id\n+|provider:physical_network,provider:network_type\n+|/v2.0/networks/{net_id}\n+|/v4/{project_id}/vpcs/{vpcid}\n+\n+|show_network\n+|get\n+|net_id\n+|dns_domain\n+|/v2.0/networks/{net_id}", "originalCommit": "f2283f611799f4f1581cffdf46c45ebb860993ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzkxODExMA==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r427918110", "bodyText": "@xieus neutron also verify nova call api by keystone, Do we need add this to alcor?", "author": "Gzure", "createdAt": "2020-05-20T10:53:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzI2NDA4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQ2NTQ5Ng==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r428465496", "bodyText": "@Gzure yes we do. Let me create a new request to track this new feature request. #207", "author": "xieus", "createdAt": "2020-05-21T06:16:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzI2NDA4OA=="}], "type": "inlineReview"}, {"oid": "e11ab4d34a7a71406299417ff0bb3fa64f895c28", "url": "https://github.com/futurewei-cloud/alcor/commit/e11ab4d34a7a71406299417ff0bb3fa64f895c28", "message": "add api use scenarios\nadd new section how nova client identify alcor server url", "committedDate": "2020-06-17T06:31:21Z", "type": "forcePushed"}, {"oid": "06d1c8e081fe6ae42353f096d7e20a92f4a2e36c", "url": "https://github.com/futurewei-cloud/alcor/commit/06d1c8e081fe6ae42353f096d7e20a92f4a2e36c", "message": "merge with master", "committedDate": "2020-06-17T09:27:29Z", "type": "commit"}, {"oid": "06d1c8e081fe6ae42353f096d7e20a92f4a2e36c", "url": "https://github.com/futurewei-cloud/alcor/commit/06d1c8e081fe6ae42353f096d7e20a92f4a2e36c", "message": "merge with master", "committedDate": "2020-06-17T09:27:29Z", "type": "forcePushed"}, {"oid": "0e73d1a1e9cdc7dbdd9414d6128f9b8c7eb841c2", "url": "https://github.com/futurewei-cloud/alcor/commit/0e73d1a1e9cdc7dbdd9414d6128f9b8c7eb841c2", "message": "Shrink the Neutron API table", "committedDate": "2020-06-30T04:20:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODEyMjY5NA==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r448122694", "bodyText": "Besides the API endpoint registration, do we need to consider registering Alcor as one of OpenStack service and register a service user for Alcor for API authentication purpose. Following the current OpenStack service management approach? https://docs.openstack.org/keystone/latest/admin/manage-services.html", "author": "cj-chung", "createdAt": "2020-07-01T05:26:24Z", "path": "docs/modules/ROOT/pages/deploy_related/integration_nova.adoc", "diffHunk": "@@ -21,16 +21,288 @@ We would want to integrate with Nova to support the same set of user operations,\n \n == Review of OpenStack Workflow\n \n+nova create a vm will through four stage.\n+1. check network options is ok\n+2. allocate network resource\n+3. rollback if fail\n+\n+In scenario column on below table, tag by above scenario and features.\n+\n+nova call neutron apis\n+[width=\"100%\",cols=\"1,1,1,1,1,1,1\", options=\"header\"]\n+|====================\n+|Name |Method |Params |Fields |Neutron API |Alcor status |Scenario\n+\n+|show_network\n+|get\n+|net_id\n+|provider: physical_network, provider: network_type\n+|/v2.0/networks/ {net_id}\n+|/project/{projectId}/ vpcs/{vpcId}\n+|stage 1: find a physical network not in multi-segments network\n+\n+|show_network\n+|get\n+|net_id\n+|dns_domain\n+|/v2.0/networks/ {net_id}\n+|/project/{projectId}/ vpcs/{vpcId}\n+|stage 3: get network dns_domain for deallocate network\n+\n+|show_network\n+|get\n+|net_id\n+|segments\n+|/v2.0/networks/ {net_id}\n+|/project/{projectId}/ vpcs/{vpcId}\n+|stage 1: find a first segment that provides a physical network in multi-segments network\n+\n+|list_network\n+|get\n+|net_ids\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ vpcs\n+|stage 1,2: get all request networks\n+\n+|list_network\n+|get\n+|tenant_id: project_id, shared: False\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ vpcs(no support)\n+|stage 1,2: get all tenant user not shared networks if request no networks\n+\n+|list_network\n+|get\n+|tenant_id: project_id, shared: False, admin_state_up: True\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ vpcs(no support)\n+|stage 1,2: get all tenant user not shared networks if request no networks and vm network is auto_allocate\n+\n+|list_network\n+|get\n+|shared: True\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ vpcs(no support)\n+|stage 1,2: get all shared networks for vm create, finals all_networks = available + shared=True\n+\n+|list_subnets\n+|get\n+|id: [subnet_id]\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ subnets\n+|stage 2: get subnet info from port if have request port and port exist\n+\n+|show_port\n+|get\n+|\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 1,2: get request port info, confirm port info is ok for instance\n+\n+|show_port\n+|get\n+|\n+|binding_profile, network_id\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 3: get port info for unbind port\n+\n+|show_port\n+|get\n+|\n+|binding: vnic_type, network_id, binding_profile, resource_request\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 1: retrieve port vNIC info\n+\n+|list_ports\n+|get\n+|device_id: instance.uuid\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ ports(no support)\n+|stage 3: get instance ports for deallocate resources\n+\n+|list_ports\n+|get\n+|device_id: instance.uuid, tenant_id: project_id\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ ports (not support)\n+|stage 2: get ports info for build network resource\n+\n+|list_ports\n+|get\n+|network_id: net_id, device_owner: network:dhcp\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ ports(no support)\n+|stage 2: get dhcp ports info if have request port and port exist in network\n+\n+|list_ports\n+|get\n+|network_id: net_id, fixed_ips: ip_addrs\n+|device_id\n+|/v2.0/ports\n+|/project/{project_id}/ ports(no support)\n+|stage 1: confirm request ip address not in use\n+\n+|create_port\n+|post\n+|port: {device_id: instance.uuid,\n+fixed_ips: {ip_address: fixed_ip},\n+network_id: net_id,\n+admin_state_up: True,\n+tenant_id: project_id,\n+security_groups:{}}\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ ports\n+|stage 2: create port for instance\n+\n+|update_port\n+|put\n+|port: {device_id: '',\n+device_owner: '',\n+'binding:host_id': None,\n+'binding:profile': {},\n+dns_name:''}\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 4: unbind instance port\n+\n+|update_port\n+|put\n+|port: {dns_name: ''}\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 4: reset port dns name\n+\n+|update_port\n+|put\n+|port: {'binding:host_id': host, device_owner: 'compute:zone', 'binding:profile':{} }\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 2: update port binding for instance in build network resource(have request port id and port exist in network)\n+\n+|update_port\n+|put\n+|port: {'binding:host_id': host, device_owner: 'compute:zone', 'binding:profile':{}, 'dns_name': network.dns_domain or instance.hostname, mac_address: mac}\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 2: update port for instance in build network resource\n+\n+|delete_port\n+|delete\n+|\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 3;delete port for instance\n+\n+|list_floatingips\n+|get\n+|fixed_ip_address: fixed_ip, port_id: port_id\n+|\n+|/v2.0/floatingips\n+|\n+|stage 2: get port floatingip if have request port and request port is exist\n+\n+|show_quota\n+|get\n+|\n+|\n+|/v2.0/quotas/ {project_id}\n+|\n+|stage 1: confirm tenant user have enough ports resources\n+\n+|list_extensions\n+|get\n+|\n+|return example: {'extensions': {{'updated': \"2017-07-17T10:00:00-00\uff1a00\",\n+name: port_binding_ extended,\n+links: [],\n+alias: binding-extended,\n+description: \"Expose port binding of a virtual port to external application\"}}}\n+|/v2.0/extensions\n+|\n+|stage 1, 2: get all support extension options\n+\n+|get_auto_allocated_ topology\n+|get\n+|\n+|\n+|/v2.0/auto-allocated-topology/ {project_id}\n+| optional api\n+| stage 2: auto allocate network if no request network and no available network\n+\n+|list_security_ groups\n+|get\n+|tenant_id: project_id\n+|\n+|/v2.0/security-groups\n+|no support\n+| stage 2: process security groups for instance in build network resource\n+|====================\n+\n === VM Creation Workflow\n image::vm_create.png[\"VM creation workflow\", width=1024, link=\"vm_create.png\"]\n \n == Required Changes\n+https://github.com/openstack/python-neutronclient[neutronclient project]\n+\n+Nova use python-neutronclient to call neutron apis.Only need to change neutronclient/v2.0/client:Client class.\n+\n+== How nova client identify alcor server url\n+In openstack, there are a auth server keystone, it can offer server url auth and endpoint catalog.  +\n+https://docs.openstack.org/mitaka/cli-reference/keystone.html[keystone online docs]\n+\n+So alcor need register endpoint in keystone. +\n+Register:\n+\n+$ openstack endpoint create --region RegionOne\n+network public http://<alcor_ip>:<port>\n+\n+$ openstack endpoint create --region RegionOne\n+network internal http://<alcor_ip>:<port>\n+\n+$ openstack endpoint create --region RegionOne\n+network admin http://<alcor_ip>:<port>\n+\n+After register in keystone, nova can get alcor endpoint from keystone. No need to change nova config file.", "originalCommit": "0e73d1a1e9cdc7dbdd9414d6128f9b8c7eb841c2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM3MjQ2NA==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r449372464", "bodyText": "This is a good point @cj-chung @Gzure . In addition to instruction to integrate with Nova, we also need the detailed instruction on integration with other OpenStack component.\n@Gzure we could either list it here or create a separate document. It is your call.", "author": "xieus", "createdAt": "2020-07-03T04:42:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODEyMjY5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM3MTk0OA==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r449371948", "bodyText": "Tried to fix the table width but it is still wider than the page limit. Not a big deal. I would suggest to fix it when you have some extra time.\nhttps://github.com/Gzure/alcor/blob/nova-inti/docs/modules/ROOT/pages/deploy_related/integration_nova.adoc", "author": "xieus", "createdAt": "2020-07-03T04:40:14Z", "path": "docs/modules/ROOT/pages/deploy_related/integration_nova.adoc", "diffHunk": "@@ -21,16 +21,288 @@ We would want to integrate with Nova to support the same set of user operations,\n \n == Review of OpenStack Workflow\n \n+nova create a vm will through four stage.\n+1. check network options is ok\n+2. allocate network resource\n+3. rollback if fail\n+\n+In scenario column on below table, tag by above scenario and features.\n+\n+nova call neutron apis\n+[width=\"100%\",cols=\"1,1,1,1,1,1,1\", options=\"header\"]", "originalCommit": "0e73d1a1e9cdc7dbdd9414d6128f9b8c7eb841c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTM3MjU2NQ==", "url": "https://github.com/futurewei-cloud/alcor/pull/204#discussion_r449372565", "bodyText": "Could you list what we've done during our integration test? Thanks.", "author": "xieus", "createdAt": "2020-07-03T04:43:07Z", "path": "docs/modules/ROOT/pages/deploy_related/integration_nova.adoc", "diffHunk": "@@ -21,16 +21,288 @@ We would want to integrate with Nova to support the same set of user operations,\n \n == Review of OpenStack Workflow\n \n+nova create a vm will through four stage.\n+1. check network options is ok\n+2. allocate network resource\n+3. rollback if fail\n+\n+In scenario column on below table, tag by above scenario and features.\n+\n+nova call neutron apis\n+[width=\"100%\",cols=\"1,1,1,1,1,1,1\", options=\"header\"]\n+|====================\n+|Name |Method |Params |Fields |Neutron API |Alcor status |Scenario\n+\n+|show_network\n+|get\n+|net_id\n+|provider: physical_network, provider: network_type\n+|/v2.0/networks/ {net_id}\n+|/project/{projectId}/ vpcs/{vpcId}\n+|stage 1: find a physical network not in multi-segments network\n+\n+|show_network\n+|get\n+|net_id\n+|dns_domain\n+|/v2.0/networks/ {net_id}\n+|/project/{projectId}/ vpcs/{vpcId}\n+|stage 3: get network dns_domain for deallocate network\n+\n+|show_network\n+|get\n+|net_id\n+|segments\n+|/v2.0/networks/ {net_id}\n+|/project/{projectId}/ vpcs/{vpcId}\n+|stage 1: find a first segment that provides a physical network in multi-segments network\n+\n+|list_network\n+|get\n+|net_ids\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ vpcs\n+|stage 1,2: get all request networks\n+\n+|list_network\n+|get\n+|tenant_id: project_id, shared: False\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ vpcs(no support)\n+|stage 1,2: get all tenant user not shared networks if request no networks\n+\n+|list_network\n+|get\n+|tenant_id: project_id, shared: False, admin_state_up: True\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ vpcs(no support)\n+|stage 1,2: get all tenant user not shared networks if request no networks and vm network is auto_allocate\n+\n+|list_network\n+|get\n+|shared: True\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ vpcs(no support)\n+|stage 1,2: get all shared networks for vm create, finals all_networks = available + shared=True\n+\n+|list_subnets\n+|get\n+|id: [subnet_id]\n+|\n+|/v2.0/networks\n+|/project/{project_id}/ subnets\n+|stage 2: get subnet info from port if have request port and port exist\n+\n+|show_port\n+|get\n+|\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 1,2: get request port info, confirm port info is ok for instance\n+\n+|show_port\n+|get\n+|\n+|binding_profile, network_id\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 3: get port info for unbind port\n+\n+|show_port\n+|get\n+|\n+|binding: vnic_type, network_id, binding_profile, resource_request\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 1: retrieve port vNIC info\n+\n+|list_ports\n+|get\n+|device_id: instance.uuid\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ ports(no support)\n+|stage 3: get instance ports for deallocate resources\n+\n+|list_ports\n+|get\n+|device_id: instance.uuid, tenant_id: project_id\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ ports (not support)\n+|stage 2: get ports info for build network resource\n+\n+|list_ports\n+|get\n+|network_id: net_id, device_owner: network:dhcp\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ ports(no support)\n+|stage 2: get dhcp ports info if have request port and port exist in network\n+\n+|list_ports\n+|get\n+|network_id: net_id, fixed_ips: ip_addrs\n+|device_id\n+|/v2.0/ports\n+|/project/{project_id}/ ports(no support)\n+|stage 1: confirm request ip address not in use\n+\n+|create_port\n+|post\n+|port: {device_id: instance.uuid,\n+fixed_ips: {ip_address: fixed_ip},\n+network_id: net_id,\n+admin_state_up: True,\n+tenant_id: project_id,\n+security_groups:{}}\n+|\n+|/v2.0/ports\n+|/project/{project_id}/ ports\n+|stage 2: create port for instance\n+\n+|update_port\n+|put\n+|port: {device_id: '',\n+device_owner: '',\n+'binding:host_id': None,\n+'binding:profile': {},\n+dns_name:''}\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 4: unbind instance port\n+\n+|update_port\n+|put\n+|port: {dns_name: ''}\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 4: reset port dns name\n+\n+|update_port\n+|put\n+|port: {'binding:host_id': host, device_owner: 'compute:zone', 'binding:profile':{} }\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 2: update port binding for instance in build network resource(have request port id and port exist in network)\n+\n+|update_port\n+|put\n+|port: {'binding:host_id': host, device_owner: 'compute:zone', 'binding:profile':{}, 'dns_name': network.dns_domain or instance.hostname, mac_address: mac}\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 2: update port for instance in build network resource\n+\n+|delete_port\n+|delete\n+|\n+|\n+|/v2.0/ports/ {port_id}\n+|/project/{project_id}/ ports/{port_id}\n+|stage 3;delete port for instance\n+\n+|list_floatingips\n+|get\n+|fixed_ip_address: fixed_ip, port_id: port_id\n+|\n+|/v2.0/floatingips\n+|\n+|stage 2: get port floatingip if have request port and request port is exist\n+\n+|show_quota\n+|get\n+|\n+|\n+|/v2.0/quotas/ {project_id}\n+|\n+|stage 1: confirm tenant user have enough ports resources\n+\n+|list_extensions\n+|get\n+|\n+|return example: {'extensions': {{'updated': \"2017-07-17T10:00:00-00\uff1a00\",\n+name: port_binding_ extended,\n+links: [],\n+alias: binding-extended,\n+description: \"Expose port binding of a virtual port to external application\"}}}\n+|/v2.0/extensions\n+|\n+|stage 1, 2: get all support extension options\n+\n+|get_auto_allocated_ topology\n+|get\n+|\n+|\n+|/v2.0/auto-allocated-topology/ {project_id}\n+| optional api\n+| stage 2: auto allocate network if no request network and no available network\n+\n+|list_security_ groups\n+|get\n+|tenant_id: project_id\n+|\n+|/v2.0/security-groups\n+|no support\n+| stage 2: process security groups for instance in build network resource\n+|====================\n+\n === VM Creation Workflow\n image::vm_create.png[\"VM creation workflow\", width=1024, link=\"vm_create.png\"]\n \n == Required Changes\n+https://github.com/openstack/python-neutronclient[neutronclient project]\n+\n+Nova use python-neutronclient to call neutron apis.Only need to change neutronclient/v2.0/client:Client class.\n+\n+== How nova client identify alcor server url\n+In openstack, there are a auth server keystone, it can offer server url auth and endpoint catalog.  +\n+https://docs.openstack.org/mitaka/cli-reference/keystone.html[keystone online docs]\n+\n+So alcor need register endpoint in keystone. +\n+Register:\n+\n+$ openstack endpoint create --region RegionOne\n+network public http://<alcor_ip>:<port>\n+\n+$ openstack endpoint create --region RegionOne\n+network internal http://<alcor_ip>:<port>\n+\n+$ openstack endpoint create --region RegionOne\n+network admin http://<alcor_ip>:<port>\n+\n+After register in keystone, nova can get alcor endpoint from keystone. No need to change nova config file.\n \n-TBD\n \n == Integration Proposal\n \n-TBD\n+There are two ways to integration with nova:\n+\n+1. Change python-neutronclient to call alcor related api.\n+\n+    advantages:\n+        1)easy to accomplish\n+\n+    disadvantages:\n+        1\uff09hard to maintain, Need change all neutornclient if a new change in alcor api\n+        2\uff09poor compatibility, Need replace all neutronclient when integration with new openstack environment\n+\n+2. Make an adaption layer in alcor to adapt alcor related api to standard neutron api.\n+\n+    advantages:\n+        easy to maintain, all changes is in alcor\n+        strong compatibility, easy to integration with other openstack components and environment\n+\n+    disadvantages:\n+        need to add a new layer to adapt neutron api\n \n == Test Plan\n ", "originalCommit": "0e73d1a1e9cdc7dbdd9414d6128f9b8c7eb841c2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}