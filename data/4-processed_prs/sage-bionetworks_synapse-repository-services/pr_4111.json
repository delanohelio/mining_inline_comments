{"pr_number": 4111, "pr_title": "PLFM-6306: Fix for race condition on replication", "pr_createdAt": "2020-06-25T23:44:08Z", "pr_url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/4111", "timeline": [{"oid": "b50ecf5ef15eeef669bc434c15f562cc50fa1667", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/commit/b50ecf5ef15eeef669bc434c15f562cc50fa1667", "message": "PLFM-6306: Fix for race condition on replication", "committedDate": "2020-06-25T23:43:05Z", "type": "commit"}, {"oid": "8a6899068cf8f541e72910750d4a0d2fdd683a67", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/commit/8a6899068cf8f541e72910750d4a0d2fdd683a67", "message": "PLFM-6306: Dedup data before replication", "committedDate": "2020-06-25T23:43:05Z", "type": "commit"}, {"oid": "0361164fd9f4cbdaa1de3921fd38fcd4f03c18cc", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/commit/0361164fd9f4cbdaa1de3921fd38fcd4f03c18cc", "message": "Note about alias reference with ON DUPLICATE KEY UPDATE", "committedDate": "2020-06-25T23:43:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0ODc4OA==", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/4111#discussion_r446448788", "bodyText": "test with batch of objects with different ids.", "author": "john-hill", "createdAt": "2020-06-26T23:18:33Z", "path": "lib/lib-table-cluster/src/test/java/org/sagebionetworks/table/cluster/TableIndexDAOImplTest.java", "diffHunk": "@@ -1347,6 +1347,57 @@ public void testEntityReplication(){\n \t\tfetched = tableIndexDAO.getObjectData(objectType, 3L);\r\n \t\tassertEquals(file, fetched);\r\n \t}\r\n+\t\r\n+\t/**\r\n+\t * Test for PLFM-6306: The index failed to replicate because the insert was not handling duplicates. When replicating\r\n+\t * we first delete and then insert but with concurrent inserts and with no data it could lead to a race condition where\r\n+\t * a second thread that wasn't blocked by the first delete (since nothing needed to be deleted) tries to insert the same \r\n+\t * record. The solution is to allow updating on duplicate.\r\n+\t */\r\n+\t@Test\r\n+\tpublic void testEntityReplicationWithUpdate(){\r\n+\t\t\r\n+\t\tObjectDataDTO objectData = createObjectDataDTO(2L, EntityType.file, 2);\r\n+\t\t\r\n+\t\t// Add the data to the index once\r\n+\t\ttableIndexDAO.addObjectData(objectType, Collections.singletonList(objectData));\r\n+\t\t\r\n+\t\tObjectDataDTO result = tableIndexDAO.getObjectData(ViewObjectType.ENTITY, objectData.getId());\r\n+\t\r\n+\t\tassertEquals(objectData, result);\r\n+\t\t\r\n+\t\t// Update the data\r\n+\t\tobjectData.setEtag(objectData.getEtag() + \"_updated\");\r\n+\t\tobjectData.getAnnotations().get(0).setValue(\"updated_annotation\");\r\n+\t\t\r\n+\t\t// Re-adding to the index should simply update the object without throwing\r\n+\t\ttableIndexDAO.addObjectData(objectType, Collections.singletonList(objectData));\r\n+\t\t\r\n+\t\t// Makes sure the data was updated\r\n+\t\tresult = tableIndexDAO.getObjectData(ViewObjectType.ENTITY, objectData.getId());\r\n+\t\t\r\n+\t\tassertEquals(objectData, result);\r\n+\t}\r\n+\t\r", "originalCommit": "0361164fd9f4cbdaa1de3921fd38fcd4f03c18cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}