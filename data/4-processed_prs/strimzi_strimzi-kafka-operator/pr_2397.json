{"pr_number": 2397, "pr_title": " [MO] - [system test] -> zookeeper upgrade test with additional check", "pr_createdAt": "2020-01-14T12:53:11Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397", "timeline": [{"oid": "2581ef411d3e1e00a8fd7c0d23ff0ab1776f6d61", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/2581ef411d3e1e00a8fd7c0d23ff0ab1776f6d61", "message": "[MO] - [conflicts] -> rebase\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-18T20:10:23Z", "type": "forcePushed"}, {"oid": "39032bfa459f051bf72900e147996faef3d290f9", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/39032bfa459f051bf72900e147996faef3d290f9", "message": "[MO] - [conflicts] -> rebase\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-19T06:11:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODUxMjM1NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r368512355", "bodyText": "It's not PodReplicasCount it's just ContainerInPodCount, better to use waitForPodsReady() I think or at least name it correctly.", "author": "Frawless", "createdAt": "2020-01-20T12:02:15Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java", "diffHunk": "@@ -166,7 +166,15 @@ public static void waitUntilPodContainersCount(String podNamePrefix, int numberO\n         TestUtils.waitFor(\"Waiting till pod\" + podNamePrefix + \" will have \" + numberOfContainers + \" containers\",\n             Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,\n             () -> kubeClient().listPodsByPrefixInName(podNamePrefix).get(0).getSpec().getContainers().size() == numberOfContainers);\n-        LOGGER.info(\"Waiting till pod {} will have {} containers\", podNamePrefix, numberOfContainers);\n+        LOGGER.info(\"Pod {} has {} containers\", podNamePrefix, numberOfContainers);\n+    }\n+\n+    public static void waitUntilPodReplicasCount(String podNamePrefix, int exceptedPods) {", "originalCommit": "39032bfa459f051bf72900e147996faef3d290f9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODg4NzU3Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r368887577", "bodyText": "You run with 3 replicas, so you should wait for 3 pods (the same below as well).", "author": "scholzj", "createdAt": "2020-01-21T09:22:38Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.Crds;\n+import io.strimzi.api.kafka.model.Kafka;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.BaseST;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.UPGRADE;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(UPGRADE)\n+public class ZookeeperUpgradeST extends BaseST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ZookeeperUpgradeST.class);\n+\n+    public static final String NAMESPACE = \"zookeeper-upgrade-test\";\n+\n+    @Test\n+    void testKafkaClusterUpgrade() throws IOException, InterruptedException {\n+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.parseKafkaVersions();\n+\n+        TestKafkaVersion initialVersion = sortedVersions.get(sortedVersions.size() - 2);\n+        TestKafkaVersion newVersion = sortedVersions.get(sortedVersions.size() - 1);\n+\n+        runVersionChange(initialVersion, newVersion, 3, 3);\n+    }\n+\n+    @Test\n+    void testKafkaClusterDowngrade() throws IOException, InterruptedException {\n+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.parseKafkaVersions();\n+\n+        TestKafkaVersion initialVersion = sortedVersions.get(sortedVersions.size() - 1);\n+        TestKafkaVersion newVersion = sortedVersions.get(sortedVersions.size() - 2);\n+\n+        runVersionChange(initialVersion, newVersion, 3, 3);\n+    }\n+\n+    void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersion, int kafkaReplicas, int zkReplicas) throws InterruptedException {\n+        String logMsgFormat;\n+        if (initialVersion.compareTo(newVersion) < 0) {\n+            // If it is an upgrade test we keep the message format as the lower version number\n+            logMsgFormat = initialVersion.messageVersion();\n+        } else {\n+            // If it is a downgrade then we make sure to use the lower version number for the message format\n+            logMsgFormat = newVersion.messageVersion();\n+        }\n+\n+        LOGGER.info(\"Deploying initial Kafka version (\" + initialVersion.version() + \")\");\n+\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, kafkaReplicas, zkReplicas)\n+                .editSpec()\n+                    .editKafka()\n+                        .withVersion(initialVersion.version())\n+                        .addToConfig(\"log.message.format.version\", logMsgFormat)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        LOGGER.info(\"Deployment of initial Kafka version (\" + initialVersion.version() + \") complete\");\n+\n+        String zkVersionCommand = \"ls libs | grep -Po 'zookeeper-\\\\K\\\\d+.\\\\d+.\\\\d+' | head -1\";\n+        String zkResult = cmdKubeClient().execInPodContainer(KafkaResources.zookeeperPodName(CLUSTER_NAME, 0),\n+                \"zookeeper\", \"/bin/bash\", \"-c\", zkVersionCommand).out().trim();\n+        LOGGER.info(\"Pre-change Zookeeper version query returned: \" + zkResult);\n+\n+        String kafkaVersionCommand = \"ls libs | grep -Po 'kafka_\\\\d+.\\\\d+-\\\\K(\\\\d+.\\\\d+.\\\\d+)(?=.jar)' | head -1\";\n+        String kafkaResult = cmdKubeClient().execInPodContainer(KafkaResources.kafkaPodName(CLUSTER_NAME, 0),\n+                \"kafka\", \"/bin/bash\", \"-c\", kafkaVersionCommand).out().trim();\n+        LOGGER.info(\"Pre-change Kafka version query returned: \" + kafkaResult);\n+\n+        Map<String, String> zkPods = StatefulSetUtils.ssSnapshot(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME));\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating Kafka CR version field to \" + newVersion.version());\n+\n+        // Get the Kafka resource from K8s\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {\n+            kafka.getSpec().getKafka().setVersion(newVersion.version());\n+        });\n+\n+        Kafka retrievedKafka = Crds.kafkaOperation(kubeClient(NAMESPACE).getClient())\n+                .inNamespace(NAMESPACE)\n+                .withName(CLUSTER_NAME)\n+                .get();\n+\n+        // Change the Kafka version for the resource\n+        retrievedKafka.getSpec().getKafka().setVersion(newVersion.version());\n+\n+        // Patch the existing resource with this new version\n+        Crds.kafkaOperation(kubeClient().getClient()).inNamespace(NAMESPACE).withName(CLUSTER_NAME).patch(retrievedKafka);\n+\n+        LOGGER.info(\"Waiting for deployment of new Kafka version (\" + newVersion.version() + \") to complete\");\n+\n+        // Wait for the zk version change roll\n+        zkPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), zkReplicas, zkPods);\n+        LOGGER.info(\"1st Zookeeper roll (image change) is complete\");\n+\n+        // Wait for the kafka broker version change roll\n+        kafkaPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        LOGGER.info(\"Kafka roll (image change) is complete\");\n+\n+        PodUtils.waitUntilPodReplicasCount(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 2);", "originalCommit": "39032bfa459f051bf72900e147996faef3d290f9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODg4ODM2MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r368888360", "bodyText": "This is a bit confusing. The message bellow says Zookeeper roll. But this method seems to check Kafka.", "author": "scholzj", "createdAt": "2020-01-21T09:24:20Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.Crds;\n+import io.strimzi.api.kafka.model.Kafka;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.BaseST;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.UPGRADE;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(UPGRADE)\n+public class ZookeeperUpgradeST extends BaseST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ZookeeperUpgradeST.class);\n+\n+    public static final String NAMESPACE = \"zookeeper-upgrade-test\";\n+\n+    @Test\n+    void testKafkaClusterUpgrade() throws IOException, InterruptedException {\n+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.parseKafkaVersions();\n+\n+        TestKafkaVersion initialVersion = sortedVersions.get(sortedVersions.size() - 2);\n+        TestKafkaVersion newVersion = sortedVersions.get(sortedVersions.size() - 1);\n+\n+        runVersionChange(initialVersion, newVersion, 3, 3);\n+    }\n+\n+    @Test\n+    void testKafkaClusterDowngrade() throws IOException, InterruptedException {\n+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.parseKafkaVersions();\n+\n+        TestKafkaVersion initialVersion = sortedVersions.get(sortedVersions.size() - 1);\n+        TestKafkaVersion newVersion = sortedVersions.get(sortedVersions.size() - 2);\n+\n+        runVersionChange(initialVersion, newVersion, 3, 3);\n+    }\n+\n+    void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersion, int kafkaReplicas, int zkReplicas) throws InterruptedException {\n+        String logMsgFormat;\n+        if (initialVersion.compareTo(newVersion) < 0) {\n+            // If it is an upgrade test we keep the message format as the lower version number\n+            logMsgFormat = initialVersion.messageVersion();\n+        } else {\n+            // If it is a downgrade then we make sure to use the lower version number for the message format\n+            logMsgFormat = newVersion.messageVersion();\n+        }\n+\n+        LOGGER.info(\"Deploying initial Kafka version (\" + initialVersion.version() + \")\");\n+\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, kafkaReplicas, zkReplicas)\n+                .editSpec()\n+                    .editKafka()\n+                        .withVersion(initialVersion.version())\n+                        .addToConfig(\"log.message.format.version\", logMsgFormat)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        LOGGER.info(\"Deployment of initial Kafka version (\" + initialVersion.version() + \") complete\");\n+\n+        String zkVersionCommand = \"ls libs | grep -Po 'zookeeper-\\\\K\\\\d+.\\\\d+.\\\\d+' | head -1\";\n+        String zkResult = cmdKubeClient().execInPodContainer(KafkaResources.zookeeperPodName(CLUSTER_NAME, 0),\n+                \"zookeeper\", \"/bin/bash\", \"-c\", zkVersionCommand).out().trim();\n+        LOGGER.info(\"Pre-change Zookeeper version query returned: \" + zkResult);\n+\n+        String kafkaVersionCommand = \"ls libs | grep -Po 'kafka_\\\\d+.\\\\d+-\\\\K(\\\\d+.\\\\d+.\\\\d+)(?=.jar)' | head -1\";\n+        String kafkaResult = cmdKubeClient().execInPodContainer(KafkaResources.kafkaPodName(CLUSTER_NAME, 0),\n+                \"kafka\", \"/bin/bash\", \"-c\", kafkaVersionCommand).out().trim();\n+        LOGGER.info(\"Pre-change Kafka version query returned: \" + kafkaResult);\n+\n+        Map<String, String> zkPods = StatefulSetUtils.ssSnapshot(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME));\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating Kafka CR version field to \" + newVersion.version());\n+\n+        // Get the Kafka resource from K8s\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {\n+            kafka.getSpec().getKafka().setVersion(newVersion.version());\n+        });\n+\n+        Kafka retrievedKafka = Crds.kafkaOperation(kubeClient(NAMESPACE).getClient())\n+                .inNamespace(NAMESPACE)\n+                .withName(CLUSTER_NAME)\n+                .get();\n+\n+        // Change the Kafka version for the resource\n+        retrievedKafka.getSpec().getKafka().setVersion(newVersion.version());\n+\n+        // Patch the existing resource with this new version\n+        Crds.kafkaOperation(kubeClient().getClient()).inNamespace(NAMESPACE).withName(CLUSTER_NAME).patch(retrievedKafka);\n+\n+        LOGGER.info(\"Waiting for deployment of new Kafka version (\" + newVersion.version() + \") to complete\");\n+\n+        // Wait for the zk version change roll\n+        zkPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), zkReplicas, zkPods);\n+        LOGGER.info(\"1st Zookeeper roll (image change) is complete\");\n+\n+        // Wait for the kafka broker version change roll\n+        kafkaPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        LOGGER.info(\"Kafka roll (image change) is complete\");\n+\n+        PodUtils.waitUntilPodReplicasCount(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 2);\n+\n+        // Wait for the zk rolling update\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        LOGGER.info(\"2nd Kafka roll (update) is complete\");\n+\n+        PodUtils.waitUntilPodReplicasCount(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 2);\n+\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, zkPods);", "originalCommit": "39032bfa459f051bf72900e147996faef3d290f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODkyNDkyMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r368924921", "bodyText": "This does seem confusing. When I designed the original ST the sequence was ZK Roll -> Kafka Roll -> ZK Roll then the update was complete. This seems to be ZK Roll -> Kafka Roll -> ZK Roll -> Kafka Roll -> Kafka Roll? Was the a change introduced by some new Kafka Rolling code? Or are there setup changes that require more rolls?", "author": "tomncooper", "createdAt": "2020-01-21T10:37:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODg4ODM2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODkzNDQ1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r368934451", "bodyText": "I think that between two minor versions there were always 2 Kafka rolling updates. The third one is related to the configuration from file and how is Fabric 8 / Kubernetes seemingly randomly changing the different HereDoc styles in tha patched YAML.", "author": "scholzj", "createdAt": "2020-01-21T10:57:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODg4ODM2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODkzNDc1Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r368934753", "bodyText": "(The third should be solved with the dynamic reconfiguration)", "author": "scholzj", "createdAt": "2020-01-21T10:57:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODg4ODM2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDAyNTAwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r370025003", "bodyText": "I have tested it many times.\n1) Upgrade has following approach - Z roll, K roll, Z roll\n2) Downgrade has - Z roll, K roll, K roll, K roll, K roll\n\nEverything passing. Executed few times.", "author": "see-quick", "createdAt": "2020-01-23T09:59:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODg4ODM2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA0ODExMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r370048112", "bodyText": "You could also just compare the intial and new Kafka versions: if (initialVersion.compareTo(newVersion) > 0)", "author": "tomncooper", "createdAt": "2020-01-23T10:47:34Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.upgrade;\n+\n+import io.strimzi.api.kafka.Crds;\n+import io.strimzi.api.kafka.model.Kafka;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.BaseST;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.StUtils;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.UPGRADE;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(UPGRADE)\n+public class ZookeeperUpgradeST extends BaseST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ZookeeperUpgradeST.class);\n+\n+    public static final String NAMESPACE = \"zookeeper-upgrade-test\";\n+\n+    @Test\n+    void testKafkaClusterUpgrade(TestInfo testinfo) throws IOException, InterruptedException {\n+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.parseKafkaVersions();\n+\n+        TestKafkaVersion initialVersion = sortedVersions.get(sortedVersions.size() - 2);\n+        TestKafkaVersion newVersion = sortedVersions.get(sortedVersions.size() - 1);\n+\n+        runVersionChange(initialVersion, newVersion, 3, 3, testinfo);\n+    }\n+\n+    @Test\n+    void testKafkaClusterDowngrade(TestInfo testInfo) throws IOException, InterruptedException {\n+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.parseKafkaVersions();\n+\n+        TestKafkaVersion initialVersion = sortedVersions.get(sortedVersions.size() - 1);\n+        TestKafkaVersion newVersion = sortedVersions.get(sortedVersions.size() - 2);\n+\n+        runVersionChange(initialVersion, newVersion, 3, 3, testInfo);\n+    }\n+\n+    void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersion, int kafkaReplicas, int zkReplicas, TestInfo testInfo) throws InterruptedException {\n+        String logMsgFormat;\n+        if (initialVersion.compareTo(newVersion) < 0) {\n+            // If it is an upgrade test we keep the message format as the lower version number\n+            logMsgFormat = initialVersion.messageVersion();\n+        } else {\n+            // If it is a downgrade then we make sure to use the lower version number for the message format\n+            logMsgFormat = newVersion.messageVersion();\n+        }\n+\n+        LOGGER.info(\"Deploying initial Kafka version (\" + initialVersion.version() + \")\");\n+\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, kafkaReplicas, zkReplicas)\n+                .editSpec()\n+                    .editKafka()\n+                        .withVersion(initialVersion.version())\n+                        .addToConfig(\"log.message.format.version\", logMsgFormat)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        LOGGER.info(\"Deployment of initial Kafka version (\" + initialVersion.version() + \") complete\");\n+\n+        String zkVersionCommand = \"ls libs | grep -Po 'zookeeper-\\\\K\\\\d+.\\\\d+.\\\\d+' | head -1\";\n+        String zkResult = cmdKubeClient().execInPodContainer(KafkaResources.zookeeperPodName(CLUSTER_NAME, 0),\n+                \"zookeeper\", \"/bin/bash\", \"-c\", zkVersionCommand).out().trim();\n+        LOGGER.info(\"Pre-change Zookeeper version query returned: \" + zkResult);\n+\n+        String kafkaVersionCommand = \"ls libs | grep -Po 'kafka_\\\\d+.\\\\d+-\\\\K(\\\\d+.\\\\d+.\\\\d+)(?=.jar)' | head -1\";\n+        String kafkaResult = cmdKubeClient().execInPodContainer(KafkaResources.kafkaPodName(CLUSTER_NAME, 0),\n+                \"kafka\", \"/bin/bash\", \"-c\", kafkaVersionCommand).out().trim();\n+        LOGGER.info(\"Pre-change Kafka version query returned: \" + kafkaResult);\n+\n+        Map<String, String> zkPods = StatefulSetUtils.ssSnapshot(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME));\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating Kafka CR version field to \" + newVersion.version());\n+\n+        // Get the Kafka resource from K8s\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {\n+            kafka.getSpec().getKafka().setVersion(newVersion.version());\n+        });\n+\n+        Kafka retrievedKafka = Crds.kafkaOperation(kubeClient(NAMESPACE).getClient())\n+                .inNamespace(NAMESPACE)\n+                .withName(CLUSTER_NAME)\n+                .get();\n+\n+        // Change the Kafka version for the resource\n+        retrievedKafka.getSpec().getKafka().setVersion(newVersion.version());\n+\n+        // Patch the existing resource with this new version\n+        Crds.kafkaOperation(kubeClient().getClient()).inNamespace(NAMESPACE).withName(CLUSTER_NAME).patch(retrievedKafka);\n+\n+        LOGGER.info(\"Waiting for deployment of new Kafka version (\" + newVersion.version() + \") to complete\");\n+\n+        // Wait for the zk version change roll\n+        zkPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), zkReplicas, zkPods);\n+        LOGGER.info(\"1st Zookeeper roll (image change) is complete\");\n+\n+        // Wait for the kafka broker version change roll\n+        kafkaPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        LOGGER.info(\"Kafka roll (image change) is complete\");\n+\n+        if (testInfo.getDisplayName().contains(\"Downgrade\")) {", "originalCommit": "845aab5b2b72364dcb4fdd4fd2e6451d17783a0d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA4MzYyMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2397#discussion_r370083623", "bodyText": "Thanks. This Downgrade and Upgrade is maybe little bit more straight looking.", "author": "see-quick", "createdAt": "2020-01-23T12:14:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA0ODExMg=="}], "type": "inlineReview"}, {"oid": "077723889edfd07f0fd8efd08d9be99f8018e584", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/077723889edfd07f0fd8efd08d9be99f8018e584", "message": "[MO] - [system test] -> fix of tests\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-28T09:37:17Z", "type": "forcePushed"}, {"oid": "d4ff394ed25e6b766f8180f0319e11c79b0aab41", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d4ff394ed25e6b766f8180f0319e11c79b0aab41", "message": "[MO] - [system test] -> fix of tests\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-30T10:26:36Z", "type": "forcePushed"}, {"oid": "9b831099333a40787ea7367c519723bcaddc8703", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9b831099333a40787ea7367c519723bcaddc8703", "message": "[MO] - [system test] -> zookeeper upgrade test\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-30T10:29:15Z", "type": "commit"}, {"oid": "775634f128d5eac223597755c4850fb4f17cc103", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/775634f128d5eac223597755c4850fb4f17cc103", "message": "[MO] - [conflicts] -> rebase\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-30T10:29:15Z", "type": "commit"}, {"oid": "562178fd845fbcadfbfa13bc2e82073ff5f5fcff", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/562178fd845fbcadfbfa13bc2e82073ff5f5fcff", "message": "[MO] - [system test] -> fix of tests\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-30T10:32:13Z", "type": "commit"}, {"oid": "562178fd845fbcadfbfa13bc2e82073ff5f5fcff", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/562178fd845fbcadfbfa13bc2e82073ff5f5fcff", "message": "[MO] - [system test] -> fix of tests\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-30T10:32:13Z", "type": "forcePushed"}]}