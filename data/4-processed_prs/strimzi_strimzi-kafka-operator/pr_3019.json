{"pr_number": 3019, "pr_title": "fix: Allow the same secret to hold client auth details and TLS certs", "pr_createdAt": "2020-05-14T11:21:45Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019", "timeline": [{"oid": "ba4c95dd89f9f5a3427bc56725ed8252549363c5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ba4c95dd89f9f5a3427bc56725ed8252549363c5", "message": "fix: Allow the same secret to hold client auth details and TLS certs\n\n - This commit fixes the creation of volumes in the MirrorMaker2,\nMirrorMaker, Connect and Bridge deployments so that the same Kubernetes\nsecret can be used to hold both the TLS certs and authentication\npasswords/certs/keys/tokens. Currently this will fail due to multiple\nvolumes with the same name being created, causing Kubernetes to reject\nthe deployment.\n - Using the same secret to hold multiple TLS/auth values can be\nuseful for those who want keep all their security credentials in one\nplace.\n\nSigned-off-by: Andrew Borley <borley@uk.ibm.com>", "committedDate": "2020-05-14T11:15:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3NjcwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#discussion_r425076708", "bodyText": "This is a useful function, thanks for the addition.", "author": "samuel-hawker", "createdAt": "2020-05-14T11:50:14Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AuthenticationUtils.java", "diffHunk": "@@ -111,37 +111,44 @@ public static void configureClientAuthenticationVolumes(KafkaClientAuthenticatio\n         if (authentication != null) {\n             if (authentication instanceof KafkaClientAuthenticationTls) {\n                 KafkaClientAuthenticationTls tlsAuth = (KafkaClientAuthenticationTls) authentication;\n-\n-                // skipping if a volume with same Secret name was already added\n-                if (!volumeList.stream().anyMatch(v -> v.getName().equals(volumeNamePrefix + tlsAuth.getCertificateAndKey().getSecretName()))) {\n-                    volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + tlsAuth.getCertificateAndKey().getSecretName(), tlsAuth.getCertificateAndKey().getSecretName(), isOpenShift));\n-                }\n+                addNewVolume(volumeList, volumeNamePrefix, tlsAuth.getCertificateAndKey().getSecretName(), isOpenShift);\n             } else if (authentication instanceof KafkaClientAuthenticationPlain) {\n                 KafkaClientAuthenticationPlain passwordAuth = (KafkaClientAuthenticationPlain) authentication;\n-                volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + passwordAuth.getPasswordSecret().getSecretName(), passwordAuth.getPasswordSecret().getSecretName(), isOpenShift));\n+                addNewVolume(volumeList, volumeNamePrefix, passwordAuth.getPasswordSecret().getSecretName(), isOpenShift);\n             } else if (authentication instanceof KafkaClientAuthenticationScramSha512) {\n                 KafkaClientAuthenticationScramSha512 passwordAuth = (KafkaClientAuthenticationScramSha512) authentication;\n-                volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + passwordAuth.getPasswordSecret().getSecretName(), passwordAuth.getPasswordSecret().getSecretName(), isOpenShift));\n+                addNewVolume(volumeList, volumeNamePrefix, passwordAuth.getPasswordSecret().getSecretName(), isOpenShift);\n             } else if (authentication instanceof KafkaClientAuthenticationOAuth) {\n                 KafkaClientAuthenticationOAuth oauth = (KafkaClientAuthenticationOAuth) authentication;\n                 volumeList.addAll(configureOauthCertificateVolumes(oauthVolumeNamePrefix, oauth.getTlsTrustedCertificates(), isOpenShift));\n \n                 if (createOAuthSecretVolumes) {\n                     if (oauth.getClientSecret() != null) {\n-                        volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + oauth.getClientSecret().getSecretName(), oauth.getClientSecret().getSecretName(), isOpenShift));\n+                        addNewVolume(volumeList, volumeNamePrefix, oauth.getClientSecret().getSecretName(), isOpenShift);\n                     }\n                     if (oauth.getAccessToken() != null) {\n-                        volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + oauth.getAccessToken().getSecretName(), oauth.getAccessToken().getSecretName(), isOpenShift));\n+                        addNewVolume(volumeList, volumeNamePrefix, oauth.getAccessToken().getSecretName(), isOpenShift);\n                     }\n                     if (oauth.getRefreshToken() != null) {\n-                        volumeList.add(VolumeUtils.createSecretVolume(volumeNamePrefix + oauth.getRefreshToken().getSecretName(), oauth.getRefreshToken().getSecretName(), isOpenShift));\n+                        addNewVolume(volumeList, volumeNamePrefix, oauth.getRefreshToken().getSecretName(), isOpenShift);\n                     }\n                 }\n             }\n         }\n     }\n \n-        /**\n+    /**\n+     * Creates the Volumes used for authentication of Kafka client based components, checking that the named volume has not already been\n+     * created.\n+     */\n+    private static void addNewVolume(List<Volume> volumeList, String volumeNamePrefix, String secretName, boolean isOpenShift) {", "originalCommit": "ba4c95dd89f9f5a3427bc56725ed8252549363c5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3NzM5MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#discussion_r425077391", "bodyText": "assertThat(AbstractModel.containerEnvVars(containers.get(0)), hasEntry(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_SASL_PASSWORD_FILE, \"my-secret/user1.password\"));\n\nIs minutely more informative if the key is missing, but this is unlikely for this test.", "author": "samuel-hawker", "createdAt": "2020-05-14T11:51:30Z", "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java", "diffHunk": "@@ -387,6 +387,45 @@ public void testGenerateDeploymentWithScramSha512Auth() {\n         assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_SASL_MECHANISM), is(\"scram-sha-512\"));\n     }\n \n+    @Test\n+    public void testGenerateDeploymentWithScramSha512AuthAndTLSSameSecret() {\n+        KafkaConnect resource = new KafkaConnectBuilder(this.resource)\n+            .editSpec()\n+                .editOrNewTls()\n+                    .addToTrustedCertificates(new CertSecretSourceBuilder().withSecretName(\"my-secret\").withCertificate(\"cert.crt\").build())\n+                .endTls()\n+                .withNewKafkaClientAuthenticationScramSha512()\n+                    .withUsername(\"user1\")\n+                    .withNewPasswordSecret()\n+                        .withSecretName(\"my-secret\")\n+                        .withPassword(\"user1.password\")\n+                    .endPasswordSecret()\n+                .endKafkaClientAuthenticationScramSha512()\n+            .endSpec()\n+            .build();\n+        KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(resource, VERSIONS);\n+        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);\n+\n+        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().size(), is(2));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(0).getName(), is(\"kafka-metrics-and-logging\"));\n+        assertThat(dep.getSpec().getTemplate().getSpec().getVolumes().get(1).getName(), is(\"my-secret\"));\n+\n+        List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();\n+\n+        assertThat(containers.get(0).getVolumeMounts().size(), is(3));\n+        assertThat(containers.get(0).getVolumeMounts().get(0).getName(), is(\"kafka-metrics-and-logging\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(0).getMountPath(), is(\"/opt/kafka/custom-config/\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(1).getName(), is(\"my-secret\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(1).getMountPath(), is(KafkaConnectCluster.TLS_CERTS_BASE_VOLUME_MOUNT + \"my-secret\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(2).getName(), is(\"my-secret\"));\n+        assertThat(containers.get(0).getVolumeMounts().get(2).getMountPath(), is(KafkaConnectCluster.PASSWORD_VOLUME_MOUNT + \"my-secret\"));\n+\n+        assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_SASL_PASSWORD_FILE), is(\"my-secret/user1.password\"));", "originalCommit": "ba4c95dd89f9f5a3427bc56725ed8252549363c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTIzNzM4Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#discussion_r425237387", "bodyText": "Yep, looks good. Have updated.", "author": "ajborley", "createdAt": "2020-05-14T15:42:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3NzM5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3ODIyMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#discussion_r425078220", "bodyText": "I do wonder if a small JavaDoc comment expanding on why the test of the same secret is important and how without the deduplication of the volumes it would result in a Kube error", "author": "samuel-hawker", "createdAt": "2020-05-14T11:53:10Z", "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java", "diffHunk": "@@ -413,6 +413,53 @@ public void testGenerateDeploymentWithScramSha512Auth() {\n         assertThat(AbstractModel.containerEnvVars(cont).get(KafkaMirrorMaker2Cluster.ENV_VAR_KAFKA_CONNECT_SASL_MECHANISM), is(\"scram-sha-512\"));\n     }\n \n+    @Test\n+    public void testGenerateDeploymentWithScramSha512AuthAndTLSSameSecret() {", "originalCommit": "ba4c95dd89f9f5a3427bc56725ed8252549363c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTIzNzQ4OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3019#discussion_r425237488", "bodyText": "Javadoc added", "author": "ajborley", "createdAt": "2020-05-14T15:42:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3ODIyMA=="}], "type": "inlineReview"}, {"oid": "cfe1ce9620c517b33675272c0e9fe462f3d6cbac", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/cfe1ce9620c517b33675272c0e9fe462f3d6cbac", "message": "fix: Address review comments\n\n - This commit adds some javadoc about the new tests and switches the\nenv var checks to use `hasEntry` to guard against missing keys.\n\nSigned-off-by: Andrew Borley <borley@uk.ibm.com>", "committedDate": "2020-05-14T15:27:59Z", "type": "commit"}]}