{"pr_number": 3200, "pr_title": "[systemtest][kafkabridge] Remove dependency of external listeners", "pr_createdAt": "2020-06-15T22:41:23Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200", "timeline": [{"oid": "c48ae74f69b25a96df1f89f4ac58322175e1490d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c48ae74f69b25a96df1f89f4ac58322175e1490d", "message": "change string for ingress wait after latest change\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-06-29T12:58:06Z", "type": "forcePushed"}, {"oid": "67405d6de811116ff27875b862ce74c6ceac47a1", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/67405d6de811116ff27875b862ce74c6ceac47a1", "message": "remove bad label\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-06-29T19:20:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcxMDg5MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447710890", "bodyText": "indentation", "author": "ppatierno", "createdAt": "2020-06-30T14:07:08Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java", "diffHunk": "@@ -255,6 +263,42 @@ public static DoneableClusterRoleBinding clusterRoleBinding(ClusterRoleBinding c\n         return kCRBList;\n     }\n \n+    private static Ingress getSystemTestIngressResource(String serviceName, int port) {\n+        IngressBackend backend = new IngressBackend();\n+        backend.setServiceName(serviceName);\n+        backend.setServicePort(new IntOrString(port));\n+\n+        HTTPIngressPath path = new HTTPIngressPath();\n+        path.setPath(\"/\");\n+        path.setBackend(backend);\n+\n+        return new IngressBuilder()\n+            .withNewMetadata()\n+            .withName(serviceName)", "originalCommit": "da430c28cd7f303033b94f4ffc7976627482af5f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcxNDYyNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447714627", "bodyText": "why the choice of makingthe host an explicit parameter while hiding the port (80) inside the method?", "author": "ppatierno", "createdAt": "2020-06-30T14:11:59Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCors.java", "diffHunk": "@@ -59,7 +53,7 @@ void testCorsOriginAllowed(VertxTestContext context) {\n         JsonObject topics = new JsonObject();\n         topics.put(\"topics\", topic);\n \n-        client.request(HttpMethod.OPTIONS, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n+        client.request(HttpMethod.OPTIONS, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")", "originalCommit": "da430c28cd7f303033b94f4ffc7976627482af5f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzczMDQ1Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447730456", "bodyText": "Yeah sorry, I leave that after some try, removed :)", "author": "im-konge", "createdAt": "2020-06-30T14:32:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcxNDYyNw=="}], "type": "inlineReview"}, {"oid": "583a9dca77079f36310b69fa9998bdf5b33334f0", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/583a9dca77079f36310b69fa9998bdf5b33334f0", "message": "comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-06-30T14:50:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NjY5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447746693", "bodyText": "ingress as. a method name would probably suffice, since it is in the system tests, writing system test is redundant.\nSimilarly we are creating a resource and the return type suggests that.\nMight be worth adding a doc comment explaining a few of the config options if they're not clear why they are the way they are.\nI would suggest it be called createIngress but that clashes with the function with the name below.", "author": "samuel-hawker", "createdAt": "2020-06-30T14:52:40Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java", "diffHunk": "@@ -255,6 +263,42 @@ public static DoneableClusterRoleBinding clusterRoleBinding(ClusterRoleBinding c\n         return kCRBList;\n     }\n \n+    private static Ingress getSystemTestIngressResource(String serviceName, int port) {", "originalCommit": "583a9dca77079f36310b69fa9998bdf5b33334f0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzI1NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447747255", "bodyText": "Needs indenting", "author": "samuel-hawker", "createdAt": "2020-06-30T14:53:19Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java", "diffHunk": "@@ -255,6 +263,42 @@ public static DoneableClusterRoleBinding clusterRoleBinding(ClusterRoleBinding c\n         return kCRBList;\n     }\n \n+    private static Ingress getSystemTestIngressResource(String serviceName, int port) {\n+        IngressBackend backend = new IngressBackend();\n+        backend.setServiceName(serviceName);\n+        backend.setServicePort(new IntOrString(port));\n+\n+        HTTPIngressPath path = new HTTPIngressPath();\n+        path.setPath(\"/\");\n+        path.setBackend(backend);\n+\n+        return new IngressBuilder()\n+            .withNewMetadata()\n+                .withName(serviceName)\n+            .endMetadata()\n+            .withNewSpec()\n+            .withRules(new IngressRuleBuilder()", "originalCommit": "583a9dca77079f36310b69fa9998bdf5b33334f0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc1MjAzOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447752039", "bodyText": "testScramShaAuthWithWeirdUsername\nMight be worth testing this with several other names, or perhaps having the name containing more potentially problematic characters?", "author": "samuel-hawker", "createdAt": "2020-06-30T14:59:15Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeExternalListenersST.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.bridge;\n+\n+import io.fabric8.kubernetes.api.model.Service;\n+import io.strimzi.api.kafka.model.CertSecretSource;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpec;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.PasswordSecretSource;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthentication;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n+import io.strimzi.systemtest.utils.specific.BridgeUtils;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(NODEPORT_SUPPORTED)\n+@Tag(EXTERNAL_CLIENTS_USED)\n+class HttpBridgeExternalListenersST extends HttpBridgeBaseST {\n+    private static final String BRIDGE_EXTERNAL_SERVICE = CLUSTER_NAME + \"-bridge-external-service\";\n+\n+    @Test\n+    void testScramShaAuthWithWeirdNamedUser() throws Exception {", "originalCommit": "583a9dca77079f36310b69fa9998bdf5b33334f0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc1NjEyOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447756129", "bodyText": "Which problematic characters do you mean? Like *+/ etc? I don't know if we didn't discussed that with @scholzj, but I can try it :)", "author": "im-konge", "createdAt": "2020-06-30T15:04:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc1MjAzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc4NDQwMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447784401", "bodyText": "I tried some options and it's not working with these special characters, how I said, I think that we had conversation about the naming with @scholzj when we made the tests, so I think we could leave it like this.\nDo you agree @Frawless, @samuel-hawker, @scholzj?", "author": "im-konge", "createdAt": "2020-06-30T15:42:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc1MjAzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc1MjE3MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r447752171", "bodyText": "ditto naming", "author": "samuel-hawker", "createdAt": "2020-06-30T14:59:24Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeExternalListenersST.java", "diffHunk": "@@ -0,0 +1,184 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.bridge;\n+\n+import io.fabric8.kubernetes.api.model.Service;\n+import io.strimzi.api.kafka.model.CertSecretSource;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpec;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.PasswordSecretSource;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthentication;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n+import io.strimzi.systemtest.utils.specific.BridgeUtils;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(NODEPORT_SUPPORTED)\n+@Tag(EXTERNAL_CLIENTS_USED)\n+class HttpBridgeExternalListenersST extends HttpBridgeBaseST {\n+    private static final String BRIDGE_EXTERNAL_SERVICE = CLUSTER_NAME + \"-bridge-external-service\";\n+\n+    @Test\n+    void testScramShaAuthWithWeirdNamedUser() throws Exception {\n+        // Create weird named user with . and more than 64 chars -> SCRAM-SHA\n+        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi\";\n+\n+        // Initialize PasswordSecret to set this as PasswordSecret in Mirror Maker spec\n+        PasswordSecretSource passwordSecret = new PasswordSecretSource();\n+        passwordSecret.setSecretName(weirdUserName);\n+        passwordSecret.setPassword(\"password\");\n+\n+        // Initialize CertSecretSource with certificate and secret names for consumer\n+        CertSecretSource certSecret = new CertSecretSource();\n+        certSecret.setCertificate(\"ca.crt\");\n+        certSecret.setSecretName(KafkaResources.clusterCaCertificateSecretName(CLUSTER_NAME));\n+\n+        KafkaBridgeSpec bridgeSpec = new KafkaBridgeSpecBuilder()\n+            .withNewKafkaClientAuthenticationScramSha512()\n+                .withNewUsername(weirdUserName)\n+                .withPasswordSecret(passwordSecret)\n+            .endKafkaClientAuthenticationScramSha512()\n+            .withNewTls()\n+                .withTrustedCertificates(certSecret)\n+            .endTls()\n+            .build();\n+\n+        testWeirdUsername(weirdUserName, new KafkaListenerAuthenticationScramSha512(), bridgeSpec, SecurityProtocol.SASL_SSL);\n+    }\n+\n+    @Test\n+    void testTlsAuthWithWeirdNamedUser() throws Exception {", "originalCommit": "583a9dca77079f36310b69fa9998bdf5b33334f0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e0850a72a2b76ab0e4c006af31bddad10f8328ef", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e0850a72a2b76ab0e4c006af31bddad10f8328ef", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-07-02T15:19:31Z", "type": "forcePushed"}, {"oid": "b416bc314f10cad2928f663a6fedd8f023da1184", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b416bc314f10cad2928f663a6fedd8f023da1184", "message": "fixup! comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-07-20T10:21:45Z", "type": "forcePushed"}, {"oid": "7a204efdd3e86095a44801b6f926371ab64edd8b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7a204efdd3e86095a44801b6f926371ab64edd8b", "message": "change PR to use example clients\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-07-20T21:05:33Z", "type": "forcePushed"}, {"oid": "a309feece878fbbbadc39f22399fc09bec3f71f5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a309feece878fbbbadc39f22399fc09bec3f71f5", "message": "change PR to use example clients\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-07-28T21:56:57Z", "type": "forcePushed"}, {"oid": "f3b7ae72687114a37658fc8bc47f7c03e5d19230", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f3b7ae72687114a37658fc8bc47f7c03e5d19230", "message": "change --boostrap-server for ver client\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-06T08:53:09Z", "type": "forcePushed"}, {"oid": "6e96a500acd7a2778f6918b2cba22f600b6c643d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6e96a500acd7a2778f6918b2cba22f600b6c643d", "message": "rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-10T09:18:17Z", "type": "forcePushed"}, {"oid": "f9f430604a28a12951b2f65ae1a81d512ea9aab7", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f9f430604a28a12951b2f65ae1a81d512ea9aab7", "message": "fixup! rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-10T10:41:58Z", "type": "forcePushed"}, {"oid": "201c4817b611c7248349111485c480e3cfbedbaf", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/201c4817b611c7248349111485c480e3cfbedbaf", "message": "back to strimzi image\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-10T15:55:17Z", "type": "forcePushed"}, {"oid": "b2556563e992cf9760019c6bb383c7989089cfd5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b2556563e992cf9760019c6bb383c7989089cfd5", "message": "change all http methods to use curl\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-13T19:57:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTEwODc1Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471108753", "bodyText": "Why do we have these tags if we are removing external access?", "author": "scholzj", "createdAt": "2020-08-16T12:44:23Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeAbstractST.java", "diffHunk": "@@ -37,40 +27,18 @@\n @Tag(NODEPORT_SUPPORTED)\n @Tag(EXTERNAL_CLIENTS_USED)", "originalCommit": "b2556563e992cf9760019c6bb383c7989089cfd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE1NjkwNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471156904", "bodyText": "I forgot to remove it, thanks", "author": "im-konge", "createdAt": "2020-08-16T20:49:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTEwODc1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTEwOTU3MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471109570", "bodyText": "I think you should be running this in a separate pod. Not from the bridge pod it self.", "author": "scholzj", "createdAt": "2020-08-16T12:52:19Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCorsST.java", "diffHunk": "@@ -4,129 +4,109 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n import io.strimzi.api.kafka.model.KafkaBridgeHttpCors;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.utils.ClientUtils;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n+import io.strimzi.systemtest.utils.specific.BridgeUtils;\n import io.vertx.core.http.HttpMethod;\n-import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxTestContext;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Test;\n \n-import java.util.Arrays;\n-import java.util.List;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n \n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.hasItem;\n+import static org.hamcrest.Matchers.containsString;\n \n public class HttpBridgeCorsST extends HttpBridgeAbstractST {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeCorsST.class);\n-    public static final String NAMESPACE = \"bridge-cluster-test\";\n-    private static final String CORS_ORIGIN = \"https://strimzi.io\";\n+    private static final String NAMESPACE = \"bridge-cors-cluster-test\";\n \n-    protected static String bridgeExternalService = CLUSTER_NAME + \"-bridge-external-service\";\n-    private static String bridgeHost;\n-    private static int bridgePort;\n+    private static final String ALLOWED_ORIGIN = \"https://strimzi.io\";\n+    private static final String NOT_ALLOWED_ORIGIN = \"https://evil.io\";\n+\n+    private static String podName = \"\";\n \n     @Test\n-    void testCorsOriginAllowed(VertxTestContext context) {\n+    void testCorsOriginAllowed() {\n         final String kafkaBridgeUser = \"bridge-user-example\";\n-        final String topicName = \"topic-simple-receive\";\n         final String groupId = ClientUtils.generateRandomConsumerGroup();\n \n         JsonObject config = new JsonObject();\n         config.put(\"name\", kafkaBridgeUser);\n         config.put(\"format\", \"json\");\n         config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n \n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(topicName);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-\n-        client.request(HttpMethod.OPTIONS, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n-            .putHeader(\"Origin\", CORS_ORIGIN)\n-            .putHeader(\"Access-Control-Request-Method\", \"POST\")\n-            .putHeader(\"Content-length\", String.valueOf(topics.toBuffer().length()))\n-            .putHeader(\"Content-type\", Constants.KAFKA_BRIDGE_JSON)\n-            .sendJsonObject(config, ar -> context.verify(() -> {\n-                assertThat(ar.result().statusCode(), is(200));\n-                assertThat(ar.result().getHeader(\"access-control-allow-origin\"), is(CORS_ORIGIN));\n-                assertThat(ar.result().getHeader(\"access-control-allow-headers\"), is(\"access-control-allow-origin,origin,x-requested-with,content-type,access-control-allow-methods,accept\"));\n-                List<String> list = Arrays.asList(ar.result().getHeader(\"access-control-allow-methods\").split(\",\"));\n-                assertThat(list, hasItem(\"POST\"));\n-                client.request(HttpMethod.POST, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n-                    .putHeader(\"Origin\", CORS_ORIGIN)\n-                    .send(ar2 -> context.verify(() -> {\n-                        assertThat(ar2.result().statusCode(), is(404));\n-                        context.completeNow();\n-                    }));\n-            }));\n+        Map<String, String> additionalHeaders = new HashMap<>();\n+        additionalHeaders.put(\"Origin\", ALLOWED_ORIGIN);\n+        additionalHeaders.put(\"Access-Control-Request-Method\", HttpMethod.POST.toString());\n+\n+        String url = BridgeUtils.DEFAULT_BRIDGE_HOST + \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\";\n+        String headers = BridgeUtils.addHeadersToString(additionalHeaders, Constants.KAFKA_BRIDGE_JSON_JSON, config.toString());\n+        String response = BridgeUtils.executeCurlCommand(HttpMethod.OPTIONS, podName, config.toString(), url, headers);\n+        String allowedHeaders = \"access-control-allow-origin,origin,x-requested-with,content-type,access-control-allow-methods,accept\";\n+\n+        LOGGER.info(\"Checking if response from Bridge is correct\");\n+        assertThat(response, containsString(\"200 OK\"));\n+        assertThat(BridgeUtils.getHeaderValue(\"access-control-allow-origin\", response), is(ALLOWED_ORIGIN));\n+        assertThat(BridgeUtils.getHeaderValue(\"access-control-allow-headers\", response), is(allowedHeaders));\n+        assertThat(BridgeUtils.getHeaderValue(\"access-control-allow-methods\", response), containsString(HttpMethod.POST.toString()));\n+\n+        url = BridgeUtils.DEFAULT_BRIDGE_HOST + \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\";\n+        headers = BridgeUtils.addHeadersToString(Collections.singletonMap(\"Origin\", ALLOWED_ORIGIN));\n+        response = BridgeUtils.executeCurlCommand(HttpMethod.POST, podName, config.toString(), url, headers);\n+\n+        assertThat(response.contains(\"404\"), is(true));\n     }\n \n     @Test\n-    void testCorsForbidden(VertxTestContext context) {\n+    void testCorsForbidden() {\n         final String kafkaBridgeUser = \"bridge-user-example\";\n         final String groupId = ClientUtils.generateRandomConsumerGroup();\n \n-        final String notAllowedOrigin = \"https://evil.io\";\n-\n-        client.request(HttpMethod.OPTIONS, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n-            .putHeader(\"Origin\", notAllowedOrigin)\n-            .putHeader(\"Access-Control-Request-Method\", \"POST\")\n-            .send(ar -> context.verify(() -> {\n-                assertThat(ar.result().statusCode(), is(403));\n-                assertThat(ar.result().statusMessage(), is(\"CORS Rejected - Invalid origin\"));\n-                client.request(HttpMethod.POST, bridgePort, bridgeHost, \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\")\n-                    .putHeader(\"Origin\", notAllowedOrigin)\n-                    .send(ar2 -> context.verify(() -> {\n-                        assertThat(ar2.result().statusCode(), is(403));\n-                        assertThat(ar2.result().statusMessage(), is(\"CORS Rejected - Invalid origin\"));\n-                        context.completeNow();\n-                    }));\n-            }));\n+        Map<String, String> additionalHeaders = new HashMap<>();\n+        additionalHeaders.put(\"Origin\", NOT_ALLOWED_ORIGIN);\n+        additionalHeaders.put(\"Access-Control-Request-Method\", HttpMethod.POST.toString());\n+\n+        String url = BridgeUtils.DEFAULT_BRIDGE_HOST + \"/consumers/\" + groupId + \"/instances/\" + kafkaBridgeUser + \"/subscription\";\n+        String headers = BridgeUtils.addHeadersToString(additionalHeaders);\n+        String response = BridgeUtils.executeCurlCommand(HttpMethod.OPTIONS, podName, url, headers);\n+\n+        LOGGER.info(\"Checking if response from Bridge is correct\");\n+        assertThat(response, containsString(\"403\"));\n+        assertThat(response, containsString(\"CORS Rejected - Invalid origin\"));\n+\n+        additionalHeaders.remove(\"Access-Control-Request-Method\", HttpMethod.POST.toString());\n+        headers = BridgeUtils.addHeadersToString(additionalHeaders);\n+        response = BridgeUtils.executeCurlCommand(HttpMethod.POST, podName, url, headers);\n+\n+        LOGGER.info(\"Checking if response from Bridge is correct\");\n+        assertThat(response, containsString(\"403\"));\n+        assertThat(response, containsString(\"CORS Rejected - Invalid origin\"));\n     }\n \n     @BeforeAll\n-    static void beforeAll() throws InterruptedException {\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n-            .editSpec()\n-                .editKafka()\n-                    .editListeners()\n-                        .withNewKafkaListenerExternalNodePort()\n-                            .withTls(false)\n-                        .endKafkaListenerExternalNodePort()\n-                    .endListeners()\n-                .endKafka()\n-            .endSpec()\n-            .done();\n+    void beforeAll() throws Exception {\n+        deployClusterOperator(NAMESPACE);\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1).done();\n \n         KafkaBridgeResource.kafkaBridgeWithCors(CLUSTER_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME),\n-            1, CORS_ORIGIN, null).done();\n+            1, ALLOWED_ORIGIN, null).done();\n \n         KafkaBridgeHttpCors kafkaBridgeHttpCors = KafkaBridgeResource.kafkaBridgeClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getHttp().getCors();\n         LOGGER.info(\"Bridge with the following CORS settings {}\", kafkaBridgeHttpCors.toString());\n \n-        Service service = KafkaBridgeUtils.createBridgeNodePortService(CLUSTER_NAME, NAMESPACE, bridgeExternalService);\n-        KubernetesResource.createServiceResource(service, NAMESPACE).done();\n-        ServiceUtils.waitForNodePortService(bridgeExternalService);\n-\n-        bridgePort = KafkaBridgeUtils.getBridgeNodePort(NAMESPACE, bridgeExternalService);\n-        bridgeHost = kubeClient(NAMESPACE).getNodeAddress();\n+        podName = kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-bridge\").get(0).getMetadata().getName();", "originalCommit": "b2556563e992cf9760019c6bb383c7989089cfd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE1NjkzNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471156936", "bodyText": "I'm gonna take a look at it :)", "author": "im-konge", "createdAt": "2020-08-16T20:49:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTEwOTU3MA=="}], "type": "inlineReview"}, {"oid": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/94b5a538c0953bf8115691eca3bbf08dfccc4d6c", "message": "change all http methods to use curl\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-17T07:14:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTE1Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471571156", "bodyText": "Kinda strange log, what should it say?", "author": "Frawless", "createdAt": "2020-08-17T15:47:24Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -44,152 +48,181 @@ public static JsonObject generateHttpMessages(int messageCount) {\n         return root;\n     }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static JsonObject sendMessagesHttpRequest(JsonObject records, String topicName, String podName) {\n         LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n-    }\n-\n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n+\n+        url = DEFAULT_BRIDGE_HOST + \"/topics/\" + topicName;\n+        headers = addHeadersToString(Constants.KAFKA_BRIDGE_JSON_JSON, records.toString());\n+        response = executeCurlCommand(HttpMethod.POST, podName, records.toString(), url, headers);\n+\n+        Matcher matcher = ALL_BEFORE_JSON_PATTERN.matcher(response);\n+        JsonObject jsonResponse = new JsonObject(matcher.replaceFirst(\"{\"));\n+\n+        if (response.contains(\"200 OK\")) {\n+            LOGGER.debug(\"Server accepted post\");\n+        } else {\n+            throw new RuntimeException(\"Server didn't accept post: \" + response);\n+        }\n+\n+        return jsonResponse;\n+    }\n+\n+    public static JsonArray receiveMessagesHttpRequest(String podName, String groupID, String name) {\n+        LOGGER.info(\"Trying to receive messages\");\n+        JsonArray jsonResponse = receiveMessages(podName, groupID, name);\n+        if (jsonResponse.size() == 0) {\n+            LOGGER.info(\"Received 0 messages, trying again after subscribing to offset\");\n+            jsonResponse = receiveMessages(podName, groupID, name);\n+        }\n+\n+        return jsonResponse;\n+    }\n+\n+    public static JsonArray receiveMessages(String podName, String groupID, String name) {\n+        LOGGER.info(\"Receiving records from KafkaBridge\");\n+\n+        url = DEFAULT_BRIDGE_HOST + \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000;\n+        headers = addHeadersToString(Collections.singletonMap(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON));\n+        response = executeCurlCommand(HttpMethod.GET, podName, \"\", url, headers);\n+\n+        Matcher matcher = ALL_BEFORE_JSON_ARRAY_PATTERN.matcher(response);\n+        JsonArray jsonResponse = new JsonArray(matcher.replaceFirst(\"[\"));\n+\n+        if (response.contains(\"200 OK\")) {\n+            if (jsonResponse.size() > 0) {\n+                for (int i = 0; i < jsonResponse.size(); i++) {\n+                    JsonObject jsonObject = jsonResponse.getJsonObject(i);\n+                    LOGGER.info(\"JsonResponse: {}\", jsonObject.toString());\n+                    String kafkaTopic = jsonObject.getString(\"topic\");\n+                    int kafkaPartition = jsonObject.getInteger(\"partition\");\n+                    String key = jsonObject.getString(\"key\");\n+                    Object value = jsonObject.getValue(\"value\");\n+                    long offset = jsonObject.getLong(\"offset\");\n+                    LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n                 }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+                LOGGER.info(\"Received {} messages from KafkaBridge\", jsonResponse.size());\n+            } else {\n+                LOGGER.warn(\"Received body 0 messages: {}\", jsonResponse);", "originalCommit": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU4NjM4Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471586383", "bodyText": "already changed -> these methods are useless right now as we are using everywhere example clients...", "author": "im-konge", "createdAt": "2020-08-17T16:11:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTE1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTU1MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471571550", "bodyText": "Maybe add the expected message count to the log?", "author": "Frawless", "createdAt": "2020-08-17T15:47:57Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -44,152 +48,181 @@ public static JsonObject generateHttpMessages(int messageCount) {\n         return root;\n     }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static JsonObject sendMessagesHttpRequest(JsonObject records, String topicName, String podName) {\n         LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n-    }\n-\n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n+\n+        url = DEFAULT_BRIDGE_HOST + \"/topics/\" + topicName;\n+        headers = addHeadersToString(Constants.KAFKA_BRIDGE_JSON_JSON, records.toString());\n+        response = executeCurlCommand(HttpMethod.POST, podName, records.toString(), url, headers);\n+\n+        Matcher matcher = ALL_BEFORE_JSON_PATTERN.matcher(response);\n+        JsonObject jsonResponse = new JsonObject(matcher.replaceFirst(\"{\"));\n+\n+        if (response.contains(\"200 OK\")) {\n+            LOGGER.debug(\"Server accepted post\");\n+        } else {\n+            throw new RuntimeException(\"Server didn't accept post: \" + response);\n+        }\n+\n+        return jsonResponse;\n+    }\n+\n+    public static JsonArray receiveMessagesHttpRequest(String podName, String groupID, String name) {\n+        LOGGER.info(\"Trying to receive messages\");\n+        JsonArray jsonResponse = receiveMessages(podName, groupID, name);\n+        if (jsonResponse.size() == 0) {\n+            LOGGER.info(\"Received 0 messages, trying again after subscribing to offset\");\n+            jsonResponse = receiveMessages(podName, groupID, name);\n+        }\n+\n+        return jsonResponse;\n+    }\n+\n+    public static JsonArray receiveMessages(String podName, String groupID, String name) {\n+        LOGGER.info(\"Receiving records from KafkaBridge\");", "originalCommit": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU4NjQ2Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471586463", "bodyText": "same as above", "author": "im-konge", "createdAt": "2020-08-17T16:11:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTU1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTY3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471571674", "bodyText": "Maybe add expected records count?", "author": "Frawless", "createdAt": "2020-08-17T15:48:08Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -44,152 +48,181 @@ public static JsonObject generateHttpMessages(int messageCount) {\n         return root;\n     }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static JsonObject sendMessagesHttpRequest(JsonObject records, String topicName, String podName) {\n         LOGGER.info(\"Sending records to KafkaBridge\");", "originalCommit": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU4NjYwNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471586605", "bodyText": "same as above", "author": "im-konge", "createdAt": "2020-08-17T16:11:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MTY3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MjI0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471572244", "bodyText": "you should use bridge service address", "author": "Frawless", "createdAt": "2020-08-17T15:48:57Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,31 +4,35 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n+import io.vertx.core.http.HttpMethod;\n import io.vertx.core.json.JsonArray;\n import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n+    public static final Pattern ALL_BEFORE_JSON_PATTERN = Pattern.compile(\"(.*\\\\s)\\\\{\", Pattern.DOTALL);\n+    private static final Pattern ALL_BEFORE_JSON_ARRAY_PATTERN = Pattern.compile(\"(.*\\\\s)\\\\[\", Pattern.DOTALL);\n+\n+    public static final String DEFAULT_BRIDGE_HOST = \"localhost:\" + Constants.HTTP_BRIDGE_DEFAULT_PORT;", "originalCommit": "94b5a538c0953bf8115691eca3bbf08dfccc4d6c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU4Njc4MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r471586780", "bodyText": "already changed", "author": "im-konge", "createdAt": "2020-08-17T16:11:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU3MjI0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA3NjQ1Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472076456", "bodyText": "Change commend ? :)", "author": "see-quick", "createdAt": "2020-08-18T10:26:35Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java", "diffHunk": "@@ -62,7 +62,7 @@ public static void waitForClientSuccess(String jobName, String namespace, int me\n \n     private static long timeoutForClientFinishJob(int messagesCount) {\n         // need to add at least 1-2minutes for finishing the job", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NzY5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472087693", "bodyText": "\ud83d\udc4d", "author": "im-konge", "createdAt": "2020-08-18T10:48:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA3NjQ1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA3NzcwNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472077707", "bodyText": "I would prefer called it buildCurlCommand but it's just  suggestion.", "author": "see-quick", "createdAt": "2020-08-18T10:29:11Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjExOTc5Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472119792", "bodyText": "I have another suggestion, but it's just that. You could also check that data has to be empty when the method is not  PUT or POST.", "author": "ppatierno", "createdAt": "2020-08-18T11:52:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA3NzcwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4MDgyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472080822", "bodyText": "I know that the base idea was good. In a practise if you create method, which has one line to encapsulate some logic. You can end-up having these one-liners with different names but most likely same behaviour. Wouldn't you think that having:\ncmdKubeClient().execInPod(podName, \"/bin/bash\", \"-c\", BridgeUtils.getCurlCommand(httpMethod, url, headers, data)).out().trim();\n\nwill be better?", "author": "see-quick", "createdAt": "2020-08-18T10:35:08Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {\n+        String command = \"curl -X \" + httpMethod.toString() + \" -D - \" + url + \" \" + headers;\n+\n+        if (!data.equals(\"\")) {\n+            command += \" -d \" + \"'\" + data + \"'\";\n         }\n-        JsonObject root = new JsonObject();\n-        root.put(\"records\", records);\n-        return root;\n-    }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+        return command;\n     }\n \n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String url, String headers) {\n+        return executeCurlCommand(httpMethod, podName, \"\", url, headers);\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n-\n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(topics.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n-\n-        for (Map.Entry<String, String> header : additionalHeaders.entrySet()) {\n-            LOGGER.info(\"Adding header {} -> {}\", header.getKey(), header.getValue());\n-            headers.add(header.getKey(), header.getValue());\n-        }\n-\n-        CompletableFuture<Boolean> future = new CompletableFuture<>();\n-\n-        client.post(bridgePort, bridgeHost,  \"/consumers/\" + groupId + \"/instances/\" + name + \"/subscription\")\n-            .putHeaders(headers)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(topics, ar -> {\n-                LOGGER.info(ar.result());\n-\n-                if (ar.succeeded() && ar.result().statusCode() == 204) {\n-                    LOGGER.info(\"Consumer subscribed\");\n-                    future.complete(ar.succeeded());\n-                } else {\n-                    LOGGER.error(\"Cannot subscribe consumer\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String data, String url, String headers) {", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NTExNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472085115", "bodyText": "The point of this test was to send the encrypted (tls) and moreover with support of simple authentication (scram-sha). You have changed to plain communication. Why? I am assuming that you wanted to just test thee scram-sha with plain communication. If this is the case please change the name of the test :)", "author": "see-quick", "createdAt": "2020-08-18T10:43:37Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java", "diffHunk": "@@ -4,225 +4,115 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n-import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.PasswordSecretSource;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n-import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeScramShaST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);\n+    private static final String NAMESPACE = \"bridge-scram-sha-cluster-test\";\n \n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private String kafkaClientsPodName;\n \n     @Test\n-    void testSendSimpleMessageTlsScramSha() throws Exception {\n-        int messageCount = 50;\n+    void testSendSimpleMessageTlsScramSha() {\n         // Create topic\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        JsonObject records = BridgeUtils.generateHttpMessages(messageCount);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, TOPIC_NAME, client);\n-        KafkaBridgeUtils.checkSendResponse(response, messageCount);\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n             .withKafkaUsername(USER_NAME)\n-            .withMessageCount(messageCount)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(kafkaClient.receiveMessagesTls(), is(messageCount));", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4OTM0OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472089349", "bodyText": "My bad! I will change it :) thanks", "author": "im-konge", "createdAt": "2020-08-18T10:52:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NTExNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NjYyMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472086623", "bodyText": "Why do you remove BRIDGE + REGRESSION tag?", "author": "see-quick", "createdAt": "2020-08-18T10:46:47Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java", "diffHunk": "@@ -4,191 +4,102 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4OTE1OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472089159", "bodyText": "It takes all tags from HttpAbstractST, so adding it here is not necessary.", "author": "im-konge", "createdAt": "2020-08-18T10:51:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NjYyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NzYwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472097608", "bodyText": "I wonder if we should keep it in all classes instead of inheriting it. It's a little bit confusing.", "author": "Frawless", "createdAt": "2020-08-18T11:08:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NjYyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjE1NDA5OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472154098", "bodyText": "I'm gonna add it back and remove the inheritance.", "author": "im-konge", "createdAt": "2020-08-18T12:45:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NjYyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MjU4MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472092580", "bodyText": "Does it work with Kafka 2.5.x ?", "author": "Frawless", "createdAt": "2020-08-18T10:58:35Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/ClientArgument.java", "diffHunk": "@@ -23,7 +23,7 @@\n     ASSIGMENT_STRATEGY(\"--assignment-strategy\"),\n \n     // Producer\n-    BROKER_LIST(\"--broker-list\"),\n+    BOOTSTRAP_SERVER(\"--bootstrap-server\"),", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEwMDQwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472100408", "bodyText": "Yes it should, gonna test it on ocp4.x too", "author": "im-konge", "createdAt": "2020-08-18T11:14:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MjU4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjIzNjYwMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472236601", "bodyText": "It works", "author": "im-konge", "createdAt": "2020-08-18T14:23:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MjU4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5Mjk5NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472092995", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (!data.equals(\"\")) {\n          \n          \n            \n                    if (data.isEmpty()) {\n          \n          \n            \n            ``` is maybe better?", "author": "Frawless", "createdAt": "2020-08-18T10:59:28Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {\n+        String command = \"curl -X \" + httpMethod.toString() + \" -D - \" + url + \" \" + headers;\n+\n+        if (!data.equals(\"\")) {", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEwMDQ3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472100474", "bodyText": "but with the ! ofc :D", "author": "see-quick", "createdAt": "2020-08-18T11:15:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5Mjk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MzMxMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472093313", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-08-18T11:00:03Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {\n+        String command = \"curl -X \" + httpMethod.toString() + \" -D - \" + url + \" \" + headers;\n+\n+        if (!data.equals(\"\")) {\n+            command += \" -d \" + \"'\" + data + \"'\";\n         }\n-        JsonObject root = new JsonObject();\n-        root.put(\"records\", records);\n-        return root;\n-    }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+        return command;\n     }\n \n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String url, String headers) {\n+        return executeCurlCommand(httpMethod, podName, \"\", url, headers);\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n-\n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(topics.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n-\n-        for (Map.Entry<String, String> header : additionalHeaders.entrySet()) {\n-            LOGGER.info(\"Adding header {} -> {}\", header.getKey(), header.getValue());\n-            headers.add(header.getKey(), header.getValue());\n-        }\n-\n-        CompletableFuture<Boolean> future = new CompletableFuture<>();\n-\n-        client.post(bridgePort, bridgeHost,  \"/consumers/\" + groupId + \"/instances/\" + name + \"/subscription\")\n-            .putHeaders(headers)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(topics, ar -> {\n-                LOGGER.info(ar.result());\n-\n-                if (ar.succeeded() && ar.result().statusCode() == 204) {\n-                    LOGGER.info(\"Consumer subscribed\");\n-                    future.complete(ar.succeeded());\n-                } else {\n-                    LOGGER.error(\"Cannot subscribe consumer\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String data, String url, String headers) {\n+        return cmdKubeClient().execInPod(podName, \"/bin/bash\", \"-c\", getCurlCommand(httpMethod, url, headers, data)).out().trim();\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        return subscribeHttpConsumer(topics, bridgeHost, bridgePort, groupId, name, client, Collections.emptyMap());\n+    public static String addHeadersToString(Map<String, String> additionalHeaders) {\n+        return addHeadersToString(additionalHeaders, \"\",  \"\");\n     }\n \n-    public static JsonObject createBridgeConsumer(JsonObject config, String bridgeHost, int bridgePort, String groupId,\n-                                                  WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static String addHeadersToString(Map<String, String> additionalHeaders,  String contentType, String content) {\n+        StringBuilder headerString = new StringBuilder();\n \n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(config.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n+        if (!content.equals(\"\")) {", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MzM3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472093373", "bodyText": "same as above", "author": "Frawless", "createdAt": "2020-08-18T11:00:10Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java", "diffHunk": "@@ -4,192 +4,76 @@\n  */\n package io.strimzi.systemtest.utils.specific;\n \n-import io.netty.handler.codec.http.HttpResponseStatus;\n-import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.utils.HttpUtils;\n import io.strimzi.test.TestUtils;\n-import io.vertx.core.MultiMap;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.ext.web.client.HttpResponse;\n-import io.vertx.ext.web.client.WebClient;\n-import io.vertx.ext.web.codec.BodyCodec;\n+import io.vertx.core.http.HttpMethod;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n import java.io.InputStream;\n-import java.util.Collections;\n import java.util.Map;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n \n public class BridgeUtils {\n \n     private static final Logger LOGGER = LogManager.getLogger(HttpUtils.class);\n \n     private BridgeUtils() { }\n \n-    public static JsonObject generateHttpMessages(int messageCount) {\n-        LOGGER.info(\"Creating {} records for KafkaBridge\", messageCount);\n-        JsonArray records = new JsonArray();\n-        JsonObject json = new JsonObject();\n-        for (int i = 0; i < messageCount; i++) {\n-            json.put(\"value\", \"msg_\" + i);\n-            records.add(json);\n+    public static String getCurlCommand(HttpMethod httpMethod, String url, String headers, String data) {\n+        String command = \"curl -X \" + httpMethod.toString() + \" -D - \" + url + \" \" + headers;\n+\n+        if (!data.equals(\"\")) {\n+            command += \" -d \" + \"'\" + data + \"'\";\n         }\n-        JsonObject root = new JsonObject();\n-        root.put(\"records\", records);\n-        return root;\n-    }\n \n-    public static JsonObject sendMessagesHttpRequest(JsonObject records, String bridgeHost, int bridgePort, String topicName, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        LOGGER.info(\"Sending records to KafkaBridge\");\n-        CompletableFuture<JsonObject> future = new CompletableFuture<>();\n-        client.post(bridgePort, bridgeHost, \"/topics/\" + topicName)\n-            .putHeader(\"Content-length\", String.valueOf(records.toBuffer().length()))\n-            .putHeader(\"Content-Type\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(records, ar -> {\n-                if (ar.succeeded()) {\n-                    HttpResponse<JsonObject> response = ar.result();\n-                    if (response.statusCode() == HttpResponseStatus.OK.code()) {\n-                        LOGGER.debug(\"Server accepted post\");\n-                        future.complete(response.body());\n-                    } else {\n-                        LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    }\n-                } else {\n-                    LOGGER.error(\"Server didn't accept post\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+        return command;\n     }\n \n-    public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridgePort, String groupID, String name, WebClient client) throws Exception {\n-        CompletableFuture<JsonArray> future = new CompletableFuture<>();\n-        client.get(bridgePort, bridgeHost, \"/consumers/\" + groupID + \"/instances/\" + name + \"/records?timeout=\" + 1000)\n-            .putHeader(\"Accept\", Constants.KAFKA_BRIDGE_JSON_JSON)\n-            .as(BodyCodec.jsonArray())\n-            .send(ar -> {\n-                if (ar.succeeded() && ar.result().statusCode() == 200) {\n-                    HttpResponse<JsonArray> response = ar.result();\n-                    if (response.body().size() > 0) {\n-                        for (int i = 0; i < response.body().size(); i++) {\n-                            JsonObject jsonResponse = response.body().getJsonObject(i);\n-                            LOGGER.info(\"JsonResponse: {}\", jsonResponse.toString());\n-                            String kafkaTopic = jsonResponse.getString(\"topic\");\n-                            int kafkaPartition = jsonResponse.getInteger(\"partition\");\n-                            String key = jsonResponse.getString(\"key\");\n-                            Object value = jsonResponse.getValue(\"value\");\n-                            long offset = jsonResponse.getLong(\"offset\");\n-                            LOGGER.debug(\"Received msg: topic:{} partition:{} key:{} value:{} offset{}\", kafkaTopic, kafkaPartition, key, value, offset);\n-                        }\n-                        LOGGER.info(\"Received {} messages from KafkaBridge\", response.body().size());\n-                    } else {\n-                        LOGGER.warn(\"Received body 0 messages: {}\", response.body());\n-                    }\n-                    future.complete(response.body());\n-                } else {\n-                    LOGGER.info(\"Cannot consume any messages!\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String url, String headers) {\n+        return executeCurlCommand(httpMethod, podName, \"\", url, headers);\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n-\n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(topics.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n-\n-        for (Map.Entry<String, String> header : additionalHeaders.entrySet()) {\n-            LOGGER.info(\"Adding header {} -> {}\", header.getKey(), header.getValue());\n-            headers.add(header.getKey(), header.getValue());\n-        }\n-\n-        CompletableFuture<Boolean> future = new CompletableFuture<>();\n-\n-        client.post(bridgePort, bridgeHost,  \"/consumers/\" + groupId + \"/instances/\" + name + \"/subscription\")\n-            .putHeaders(headers)\n-            .as(BodyCodec.jsonObject())\n-            .sendJsonObject(topics, ar -> {\n-                LOGGER.info(ar.result());\n-\n-                if (ar.succeeded() && ar.result().statusCode() == 204) {\n-                    LOGGER.info(\"Consumer subscribed\");\n-                    future.complete(ar.succeeded());\n-                } else {\n-                    LOGGER.error(\"Cannot subscribe consumer\", ar.cause());\n-                    future.completeExceptionally(ar.cause());\n-                }\n-            });\n-        return future.get(1, TimeUnit.MINUTES);\n+    public static String executeCurlCommand(HttpMethod httpMethod, String podName, String data, String url, String headers) {\n+        return cmdKubeClient().execInPod(podName, \"/bin/bash\", \"-c\", getCurlCommand(httpMethod, url, headers, data)).out().trim();\n     }\n \n-    public static boolean subscribeHttpConsumer(JsonObject topics, String bridgeHost, int bridgePort, String groupId,\n-                                                String name, WebClient client) throws InterruptedException, ExecutionException, TimeoutException {\n-        return subscribeHttpConsumer(topics, bridgeHost, bridgePort, groupId, name, client, Collections.emptyMap());\n+    public static String addHeadersToString(Map<String, String> additionalHeaders) {\n+        return addHeadersToString(additionalHeaders, \"\",  \"\");\n     }\n \n-    public static JsonObject createBridgeConsumer(JsonObject config, String bridgeHost, int bridgePort, String groupId,\n-                                                  WebClient client, Map<String, String> additionalHeaders) throws InterruptedException, ExecutionException, TimeoutException {\n+    public static String addHeadersToString(Map<String, String> additionalHeaders,  String contentType, String content) {\n+        StringBuilder headerString = new StringBuilder();\n \n-        MultiMap headers = MultiMap.caseInsensitiveMultiMap()\n-            .add(\"Content-length\", String.valueOf(config.toBuffer().length()))\n-            .add(\"Content-type\", Constants.KAFKA_BRIDGE_JSON);\n+        if (!content.equals(\"\")) {\n+            headerString.append(\" -H 'Content-length: \").append(content.length()).append(\"'\");\n+        }\n+\n+        if (!contentType.equals(\"\")) {", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDIwNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472094205", "bodyText": "Wouldn't be better to use KafkaBridgeResources.url() instead just service name?", "author": "Frawless", "createdAt": "2020-08-18T11:01:57Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeAbstractST.java", "diffHunk": "@@ -34,43 +22,19 @@\n @ExtendWith(VertxExtension.class)\n @Tag(BRIDGE)\n @Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n public class HttpBridgeAbstractST extends AbstractST {\n-    private static final Logger LOGGER = LogManager.getLogger(HttpBridgeAbstractST.class);\n-\n-    protected WebClient client;\n-    protected String bridgeExternalService = CLUSTER_NAME + \"-bridge-external-service\";\n+    public static int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    public static String bridgeHost = \"\";\n+    public static String kafkaClientsPodName = \"\";\n+    public static String bridgeServiceName = KafkaBridgeResources.serviceName(CLUSTER_NAME);", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjE3NjU1Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472176553", "bodyText": "For this case I'm gonna add bridgeUrl var to use KafkaBridgeResources.url() method and I will keep bridgeServiceName var for example clients usage.", "author": "im-konge", "createdAt": "2020-08-18T13:09:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDIwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDM3OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472094378", "bodyText": "Why?", "author": "Frawless", "createdAt": "2020-08-18T11:02:17Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java", "diffHunk": "@@ -62,7 +62,7 @@ public static void waitForClientSuccess(String jobName, String namespace, int me\n \n     private static long timeoutForClientFinishJob(int messagesCount) {\n         // need to add at least 1-2minutes for finishing the job\n-        return (long) messagesCount * 1000 + Duration.ofMinutes(2).toMillis();\n+        return (long) messagesCount * 1000 + Duration.ofMinutes(3).toMillis();", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEwMDg3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472100874", "bodyText": "In some cases the job needed one more minute on Jenkins -> on local env two minutes are sufficient ...", "author": "im-konge", "createdAt": "2020-08-18T11:15:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDM3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwMzgwNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472303805", "bodyText": "I wonder why it needs additional time, maybe message count and timeout between messages is not set correctly?", "author": "Frawless", "createdAt": "2020-08-18T15:55:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDM3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxMjk3Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472312976", "bodyText": "I think that 2 minutes will be enough -> I forgot that I added the auto.reset.offset.config: earliest so I'm gonna change it back", "author": "im-konge", "createdAt": "2020-08-18T16:09:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NDM3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NTY0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472095644", "bodyText": "The name is kinda misleading from my POV. IT looks like bridge have external listener here, which is not true.", "author": "Frawless", "createdAt": "2020-08-18T11:04:59Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeExternalListenersST.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.bridge;\n+\n+import io.fabric8.kubernetes.api.model.Service;\n+import io.strimzi.api.kafka.model.CertSecretSource;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpec;\n+import io.strimzi.api.kafka.model.KafkaBridgeSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.PasswordSecretSource;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthentication;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(NODEPORT_SUPPORTED)\n+@Tag(EXTERNAL_CLIENTS_USED)\n+class HttpBridgeExternalListenersST extends HttpBridgeAbstractST {", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEyMTcyOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472121729", "bodyText": "Agree", "author": "ppatierno", "createdAt": "2020-08-18T11:55:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NTY0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NjQ4Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472096486", "bodyText": "Same as Maros mentioned above I guess", "author": "Frawless", "createdAt": "2020-08-18T11:06:39Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java", "diffHunk": "@@ -4,225 +4,115 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n-import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.PasswordSecretSource;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n-import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeScramShaST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);\n+    private static final String NAMESPACE = \"bridge-scram-sha-cluster-test\";\n \n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private String kafkaClientsPodName;\n \n     @Test\n-    void testSendSimpleMessageTlsScramSha() throws Exception {\n-        int messageCount = 50;\n+    void testSendSimpleMessageTlsScramSha() {\n         // Create topic\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        JsonObject records = BridgeUtils.generateHttpMessages(messageCount);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, TOPIC_NAME, client);\n-        KafkaBridgeUtils.checkSendResponse(response, messageCount);\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n             .withKafkaUsername(USER_NAME)\n-            .withMessageCount(messageCount)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(kafkaClient.receiveMessagesTls(), is(messageCount));\n+        assertThat(internalKafkaClient.receiveMessagesPlain(), is(MESSAGE_COUNT));\n     }\n \n     @Test\n-    void testReceiveSimpleMessageTlsScramSha() throws Exception {\n-        // Create topic\n+    void testReceiveSimpleMessageTlsScramSha() {\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withKafkaUsername(USER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .build();\n+        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n \n         // Send messages to Kafka\n-        assertThat(kafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-\n-        String name = \"kafka-consumer-simple-receive\";\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", name);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(name));\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        }\n-\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-    }\n-\n-    @Test\n-    void testScramShaAuthWithWeirdNamedUser() throws Exception {\n-        // Create weird named user with . and more than 64 chars -> SCRAM-SHA\n-        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi\";\n-        // Create user with normal name -> we don't need to set weird name for consumer\n-        String aliceUser = \"alice\";\n-\n-        // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        // Create user\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, weirdUserName).done();\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, aliceUser).done();\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", aliceUser);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(aliceUser));\n-\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .withKafkaUsername(weirdUserName)\n+            .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        assertThat(internalKafkaClient.sendMessagesPlain(), is(MESSAGE_COUNT));", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NjkyNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472096926", "bodyText": "Some new lines/indents?", "author": "Frawless", "createdAt": "2020-08-18T11:07:36Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java", "diffHunk": "@@ -4,225 +4,115 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n-import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.PasswordSecretSource;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n-import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeScramShaST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);\n+    private static final String NAMESPACE = \"bridge-scram-sha-cluster-test\";\n \n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private String kafkaClientsPodName;\n \n     @Test\n-    void testSendSimpleMessageTlsScramSha() throws Exception {\n-        int messageCount = 50;\n+    void testSendSimpleMessageTlsScramSha() {\n         // Create topic\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        JsonObject records = BridgeUtils.generateHttpMessages(messageCount);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, TOPIC_NAME, client);\n-        KafkaBridgeUtils.checkSendResponse(response, messageCount);\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n             .withKafkaUsername(USER_NAME)\n-            .withMessageCount(messageCount)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(kafkaClient.receiveMessagesTls(), is(messageCount));\n+        assertThat(internalKafkaClient.receiveMessagesPlain(), is(MESSAGE_COUNT));\n     }\n \n     @Test\n-    void testReceiveSimpleMessageTlsScramSha() throws Exception {\n-        // Create topic\n+    void testReceiveSimpleMessageTlsScramSha() {\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withKafkaUsername(USER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .build();\n+        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n \n         // Send messages to Kafka\n-        assertThat(kafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-\n-        String name = \"kafka-consumer-simple-receive\";\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", name);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(name));\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        }\n-\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-    }\n-\n-    @Test\n-    void testScramShaAuthWithWeirdNamedUser() throws Exception {\n-        // Create weird named user with . and more than 64 chars -> SCRAM-SHA\n-        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi\";\n-        // Create user with normal name -> we don't need to set weird name for consumer\n-        String aliceUser = \"alice\";\n-\n-        // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        // Create user\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, weirdUserName).done();\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, aliceUser).done();\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", aliceUser);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(aliceUser));\n-\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .withKafkaUsername(weirdUserName)\n+            .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        assertThat(internalKafkaClient.sendMessagesPlain(), is(MESSAGE_COUNT));\n+\n+        ClientUtils.waitForClientSuccess(consumerName, NAMESPACE, MESSAGE_COUNT);\n     }\n \n     @BeforeAll\n-    void setup() throws InterruptedException {\n+    void setup() throws Exception {\n+        deployClusterOperator(NAMESPACE);\n         LOGGER.info(\"Deploy Kafka and KafkaBridge before tests\");\n \n-        KafkaListenerAuthenticationTls auth = new KafkaListenerAuthenticationTls();\n-        KafkaListenerTls listenerTls = new KafkaListenerTls();\n-        listenerTls.setAuth(auth);\n-\n         // Deploy kafka\n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n             .editSpec()\n                 .editKafka()\n                     .withNewListeners()\n-                        .withNewKafkaListenerExternalNodePort()\n-                            .withAuth(new KafkaListenerAuthenticationScramSha512())\n-                        .endKafkaListenerExternalNodePort()\n-                        .withNewTls().withAuth(new KafkaListenerAuthenticationScramSha512()).endTls()\n+                        .withNewPlain().withAuth(new KafkaListenerAuthenticationScramSha512()).endPlain()", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5NzI1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472097251", "bodyText": "Probably same as above? tls -> plain", "author": "Frawless", "createdAt": "2020-08-18T11:08:15Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java", "diffHunk": "@@ -4,225 +4,115 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n-import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.PasswordSecretSource;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.api.kafka.model.listener.KafkaListenerTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n-import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeScramShaST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);\n+    private static final String NAMESPACE = \"bridge-scram-sha-cluster-test\";\n \n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private String kafkaClientsPodName;\n \n     @Test\n-    void testSendSimpleMessageTlsScramSha() throws Exception {\n-        int messageCount = 50;\n+    void testSendSimpleMessageTlsScramSha() {\n         // Create topic\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        JsonObject records = BridgeUtils.generateHttpMessages(messageCount);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, TOPIC_NAME, client);\n-        KafkaBridgeUtils.checkSendResponse(response, messageCount);\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n             .withKafkaUsername(USER_NAME)\n-            .withMessageCount(messageCount)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(kafkaClient.receiveMessagesTls(), is(messageCount));\n+        assertThat(internalKafkaClient.receiveMessagesPlain(), is(MESSAGE_COUNT));\n     }\n \n     @Test\n-    void testReceiveSimpleMessageTlsScramSha() throws Exception {\n-        // Create topic\n+    void testReceiveSimpleMessageTlsScramSha() {\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        BasicExternalKafkaClient kafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withKafkaUsername(USER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .build();\n+        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n \n         // Send messages to Kafka\n-        assertThat(kafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-\n-        String name = \"kafka-consumer-simple-receive\";\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", name);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(name));\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client);\n-        }\n-\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, name, client), is(true));\n-    }\n-\n-    @Test\n-    void testScramShaAuthWithWeirdNamedUser() throws Exception {\n-        // Create weird named user with . and more than 64 chars -> SCRAM-SHA\n-        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd.asdasidioiqweioqiweooioqieioqieoqieooi\";\n-        // Create user with normal name -> we don't need to set weird name for consumer\n-        String aliceUser = \"alice\";\n-\n-        // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        // Create user\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, weirdUserName).done();\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, aliceUser).done();\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", aliceUser);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(aliceUser));\n-\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SASL_SSL)\n-            .withKafkaUsername(weirdUserName)\n+            .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        assertThat(internalKafkaClient.sendMessagesPlain(), is(MESSAGE_COUNT));\n+\n+        ClientUtils.waitForClientSuccess(consumerName, NAMESPACE, MESSAGE_COUNT);\n     }\n \n     @BeforeAll\n-    void setup() throws InterruptedException {\n+    void setup() throws Exception {\n+        deployClusterOperator(NAMESPACE);\n         LOGGER.info(\"Deploy Kafka and KafkaBridge before tests\");\n \n-        KafkaListenerAuthenticationTls auth = new KafkaListenerAuthenticationTls();\n-        KafkaListenerTls listenerTls = new KafkaListenerTls();\n-        listenerTls.setAuth(auth);\n-\n         // Deploy kafka\n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n             .editSpec()\n                 .editKafka()\n                     .withNewListeners()\n-                        .withNewKafkaListenerExternalNodePort()\n-                            .withAuth(new KafkaListenerAuthenticationScramSha512())\n-                        .endKafkaListenerExternalNodePort()\n-                        .withNewTls().withAuth(new KafkaListenerAuthenticationScramSha512()).endTls()\n+                        .withNewPlain().withAuth(new KafkaListenerAuthenticationScramSha512()).endPlain()\n                     .endListeners()\n                 .endKafka()\n             .endSpec().done();\n \n         // Create Kafka user\n-        KafkaUserResource.scramShaUser(CLUSTER_NAME, USER_NAME).done();\n+        KafkaUser scramShaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, USER_NAME).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME, scramShaUser).done();\n+\n+        kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n \n         // Initialize PasswordSecret to set this as PasswordSecret in Mirror Maker spec\n         PasswordSecretSource passwordSecret = new PasswordSecretSource();\n         passwordSecret.setSecretName(USER_NAME);\n         passwordSecret.setPassword(\"password\");\n \n-        // Initialize CertSecretSource with certificate and secret names for consumer\n-        CertSecretSource certSecret = new CertSecretSource();\n-        certSecret.setCertificate(\"ca.crt\");\n-        certSecret.setSecretName(KafkaResources.clusterCaCertificateSecretName(CLUSTER_NAME));\n-\n         // Deploy http bridge\n-        KafkaBridgeResource.kafkaBridge(CLUSTER_NAME, KafkaResources.tlsBootstrapAddress(CLUSTER_NAME), 1)\n+        KafkaBridgeResource.kafkaBridge(CLUSTER_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), 1)", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5ODE5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472098193", "bodyText": "I think format before this changes looks better.", "author": "Frawless", "createdAt": "2020-08-18T11:10:08Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java", "diffHunk": "@@ -4,191 +4,102 @@\n  */\n package io.strimzi.systemtest.bridge;\n \n-import io.fabric8.kubernetes.api.model.Service;\n import io.strimzi.api.kafka.model.CertSecretSource;\n import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaUser;\n import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;\n-import io.strimzi.systemtest.Constants;\n-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;\n-import io.strimzi.systemtest.utils.specific.BridgeUtils;\n-import io.vertx.core.json.JsonArray;\n-import io.vertx.core.json.JsonObject;\n-import io.vertx.junit5.VertxExtension;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n-import org.junit.jupiter.api.extension.ExtendWith;\n-import io.strimzi.systemtest.resources.KubernetesResource;\n-import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n-import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n \n import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n-import static io.strimzi.systemtest.Constants.BRIDGE;\n-import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.CoreMatchers.is;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-@Tag(BRIDGE)\n @Tag(ACCEPTANCE)\n-@Tag(REGRESSION)\n-@Tag(NODEPORT_SUPPORTED)\n-@Tag(EXTERNAL_CLIENTS_USED)\n-@ExtendWith(VertxExtension.class)\n+@Tag(INTERNAL_CLIENTS_USED)\n class HttpBridgeTlsST extends HttpBridgeAbstractST {\n     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);\n-\n-    private String bridgeHost = \"\";\n-    private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;\n+    private static final String NAMESPACE = \"bridge-tls-cluster-test\";\n \n     @Test\n-    void testSendSimpleMessageTls() throws Exception {\n-        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n+    void testSendSimpleMessageTls() {\n         // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n-\n-        JsonObject records = BridgeUtils.generateHttpMessages(MESSAGE_COUNT);\n-        JsonObject response = BridgeUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, topicName, client);\n-        KafkaBridgeUtils.checkSendResponse(response, MESSAGE_COUNT);\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(topicName)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withSecurityProtocol(SecurityProtocol.SSL)\n-            .withKafkaUsername(USER_NAME)\n-            .build();\n+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n \n-        assertThat(basicExternalKafkaClient.receiveMessagesTls(), is(MESSAGE_COUNT));\n-    }\n+        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n+        ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);\n \n-    @Test\n-    void testReceiveSimpleMessageTls() throws Exception {\n-        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();\n-        // Create topic\n-        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n-        KafkaTopicUtils.waitForKafkaTopicCreation(topicName);\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", USER_NAME);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(USER_NAME));\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(topicName);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, USER_NAME, client), is(true));\n-        // Send messages to Kafka\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(topicName)\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n             .withSecurityProtocol(SecurityProtocol.SSL)\n             .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-\n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, USER_NAME, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, USER_NAME, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, USER_NAME, client), is(true));\n+        assertThat(internalKafkaClient.receiveMessagesTls(), is(MESSAGE_COUNT));\n     }\n \n     @Test\n-    void testTlsAuthWithWeirdNamedUser() throws Exception {\n-        // Create weird named user with . and maximum of 64 chars -> TLS\n-        String weirdUserName = \"jjglmahyijoambryleyxjjglmahy.ijoambryleyxjjglmahyijoambryleyxasd\";\n-        // Create user with normal name -> we don't need to set weird name for consumer\n-        String aliceUser = \"alice\";\n-\n-        // Create topic\n+    void testReceiveSimpleMessageTls() {\n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        // Create user\n-        KafkaUserResource.tlsUser(CLUSTER_NAME, weirdUserName).done();\n-        KafkaUserResource.tlsUser(CLUSTER_NAME, aliceUser).done();\n-\n-        JsonObject config = new JsonObject();\n-        config.put(\"name\", aliceUser);\n-        config.put(\"format\", \"json\");\n-        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n-\n-        // Create consumer\n-        JsonObject response = BridgeUtils.createBridgeConsumer(config, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, client);\n-        assertThat(\"Consumer wasn't created correctly\", response.getString(\"instance_id\"), is(aliceUser));\n-\n-        // Create topics json\n-        JsonArray topic = new JsonArray();\n-        topic.add(TOPIC_NAME);\n-        JsonObject topics = new JsonObject();\n-        topics.put(\"topics\", topic);\n \n-        // Subscribe\n-        assertThat(BridgeUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+        // Send messages to Kafka\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n             .withTopicName(TOPIC_NAME)\n             .withNamespaceName(NAMESPACE)\n             .withClusterName(CLUSTER_NAME)\n             .withMessageCount(MESSAGE_COUNT)\n             .withSecurityProtocol(SecurityProtocol.SSL)\n-            .withKafkaUsername(weirdUserName)\n+            .withKafkaUsername(USER_NAME)\n+            .withUsingPodName(kafkaClientsPodName)\n             .build();\n \n-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n-        // Try to consume messages\n-        JsonArray bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        if (bridgeResponse.size() == 0) {\n-            // Real consuming\n-            bridgeResponse = BridgeUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client);\n-        }\n-        assertThat(\"Sent message count is not equal with received message count\", bridgeResponse.size(), is(MESSAGE_COUNT));\n-        // Delete consumer\n-        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, CONSUMER_GROUP_NAME, aliceUser, client), is(true));\n+        assertThat(internalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));\n+\n+        ClientUtils.waitForClientSuccess(consumerName, NAMESPACE, MESSAGE_COUNT);\n     }\n \n     @BeforeAll\n-    void createClassResources() throws InterruptedException {\n+    void createClassResources() throws Exception {\n+        deployClusterOperator(NAMESPACE);\n         LOGGER.info(\"Deploy Kafka and KafkaBridge before tests\");\n \n         // Deploy kafka\n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n             .editSpec()\n                 .editKafka()\n-                    .editListeners()\n-                        .withNewKafkaListenerExternalNodePort()\n-                            .withAuth(new KafkaListenerAuthenticationTls())\n-                        .endKafkaListenerExternalNodePort()\n+                    .withNewListeners()\n+                        .withNewTls().withAuth(new KafkaListenerAuthenticationTls()).endTls()", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5OTU4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472099582", "bodyText": "Why this change is needed?", "author": "Frawless", "createdAt": "2020-08-18T11:13:02Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java", "diffHunk": "@@ -556,7 +551,7 @@ void testProducerConsumerMirrorMakerService() {\n         KafkaClientsResource.consumerWithTracing(KafkaResources.plainBootstrapAddress(kafkaClusterTargetName)).done();\n \n         KafkaMirrorMakerResource.kafkaMirrorMaker(CLUSTER_NAME, kafkaClusterSourceName, kafkaClusterTargetName,\n-            ClientUtils.generateRandomConsumerGroup(), 1, false)\n+                \"my-group\" + new Random().nextInt(Integer.MAX_VALUE), 1, false)", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEwMTMzNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472101337", "bodyText": "Good catch! I think I little bit messed up the rebase", "author": "im-konge", "createdAt": "2020-08-18T11:16:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5OTU4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5OTYxNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472099614", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-08-18T11:13:08Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java", "diffHunk": "@@ -688,7 +683,7 @@ void testProducerConsumerMirrorMakerConnectStreamsService() {\n                 + \"'\" + connectorConfig + \"'\" + \" http://localhost:8083/connectors\");\n \n         KafkaMirrorMakerResource.kafkaMirrorMaker(CLUSTER_NAME, kafkaClusterSourceName, kafkaClusterTargetName,\n-            ClientUtils.generateRandomConsumerGroup(), 1, false)\n+                \"my-group\" + new Random().nextInt(Integer.MAX_VALUE), 1, false)", "originalCommit": "f270223e235e5217f139d39574856fad239816e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEwMTQ4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3200#discussion_r472101482", "bodyText": "Same as above ^^", "author": "im-konge", "createdAt": "2020-08-18T11:17:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5OTYxNA=="}], "type": "inlineReview"}, {"oid": "3882d61f2b7b0d85461e8d5004b5346744720697", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3882d61f2b7b0d85461e8d5004b5346744720697", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-18T14:55:40Z", "type": "forcePushed"}, {"oid": "aff5a736ab785d0066bf356c7935bc8fe5273d59", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/aff5a736ab785d0066bf356c7935bc8fe5273d59", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T14:53:04Z", "type": "forcePushed"}, {"oid": "b036f6da83823b7c9c0033db69dea271da4e86a5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b036f6da83823b7c9c0033db69dea271da4e86a5", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T15:19:24Z", "type": "forcePushed"}, {"oid": "0f12e6327494facb64d6a58f0256e2d0e8102dab", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0f12e6327494facb64d6a58f0256e2d0e8102dab", "message": "remove external listeners and add ingress\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "fab1b130afd5e75b2505f7e5e8f485d2bfc587da", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fab1b130afd5e75b2505f7e5e8f485d2bfc587da", "message": "change string for ingress wait after latest change\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "7e1617cfab1e0d07540a3fc90cb3295703c46041", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7e1617cfab1e0d07540a3fc90cb3295703c46041", "message": "remove bad label\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "f68e40d4b3652a533552b82a716bb230ff61f821", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f68e40d4b3652a533552b82a716bb230ff61f821", "message": "change the debug info\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "d790838a24468b5931e5d0b4f7e15e99965cf0a5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d790838a24468b5931e5d0b4f7e15e99965cf0a5", "message": "new class, some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "85fddd81a46620313f8c96a9e03ae7806e63f990", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/85fddd81a46620313f8c96a9e03ae7806e63f990", "message": "change the bridge spec to be the right one\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "18386c6b4216448fe7519aa3cf940aaac0d90c26", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/18386c6b4216448fe7519aa3cf940aaac0d90c26", "message": "add tag\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "a641612564ef071d1936097d7b08bc26d7282f42", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a641612564ef071d1936097d7b08bc26d7282f42", "message": "add constant for ingress port\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "fee3a8a8fa28c787145712c688a1e430e4fdd723", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fee3a8a8fa28c787145712c688a1e430e4fdd723", "message": "fix indent\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "554f6fcc909e711d5de035cb8cb6328d50748453", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/554f6fcc909e711d5de035cb8cb6328d50748453", "message": "remove unnecessary overloads\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "652efdd0536ac056b3992c48498f8b6d1b20a665", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/652efdd0536ac056b3992c48498f8b6d1b20a665", "message": "add back ports for bridge requests\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "ae5006fadf0d49ec0ee014580d793427a775d8f1", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ae5006fadf0d49ec0ee014580d793427a775d8f1", "message": "comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "0a1914607a72a2604fb6381154bdf285289eeddd", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0a1914607a72a2604fb6381154bdf285289eeddd", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "833954ca3bc5b6e43d61b0ee3eb5baee77a2b18d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/833954ca3bc5b6e43d61b0ee3eb5baee77a2b18d", "message": "fixup! comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "b163fa1cff58912500a6b83967094602d9f1f49b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b163fa1cff58912500a6b83967094602d9f1f49b", "message": "change PR to use example clients\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:47:38Z", "type": "commit"}, {"oid": "807297c4100c70a9969abc6f74b0c9566d0f93b1", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/807297c4100c70a9969abc6f74b0c9566d0f93b1", "message": "change --boostrap-server for ver client\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:48:16Z", "type": "commit"}, {"oid": "3351cad1172f6260d405495e1d84eedc436f3bba", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3351cad1172f6260d405495e1d84eedc436f3bba", "message": "rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:48:17Z", "type": "commit"}, {"oid": "75a530c1d1e1bfeb9852f8d470bca9d7b28a37a8", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/75a530c1d1e1bfeb9852f8d470bca9d7b28a37a8", "message": "fixup! rebase\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:48:17Z", "type": "commit"}, {"oid": "e32b06515afa1df80dd1588c95c616c0921a60d9", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e32b06515afa1df80dd1588c95c616c0921a60d9", "message": "back to strimzi image\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:48:17Z", "type": "commit"}, {"oid": "272f22d7c0cb18e1c0733ad15954e25a731b6cfc", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/272f22d7c0cb18e1c0733ad15954e25a731b6cfc", "message": "do some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:48:52Z", "type": "commit"}, {"oid": "aa7abcb7f2dcfece49b7eb8db62470f98354f807", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/aa7abcb7f2dcfece49b7eb8db62470f98354f807", "message": "fixup! do some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:48:54Z", "type": "commit"}, {"oid": "f7456dfa1c03a5770ebb5ad1466d2224020d013e", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f7456dfa1c03a5770ebb5ad1466d2224020d013e", "message": "fixup! fixup! do some changes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:48:54Z", "type": "commit"}, {"oid": "1ba7a9c64b8956405f341c50fb4aa774e08e2c88", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1ba7a9c64b8956405f341c50fb4aa774e08e2c88", "message": "change all http methods to use curl\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:48:54Z", "type": "commit"}, {"oid": "858f6f994df1efaa9818c1d33e8daa400ee73734", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/858f6f994df1efaa9818c1d33e8daa400ee73734", "message": "comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:50:00Z", "type": "commit"}, {"oid": "8afa9e589cd8ed66f8b407e151d422c7efbe3d0f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/8afa9e589cd8ed66f8b407e151d422c7efbe3d0f", "message": "add NP for ocp4.x\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:50:01Z", "type": "commit"}, {"oid": "6f79d17d328a89890ba87cdf88bec1b253a340f9", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6f79d17d328a89890ba87cdf88bec1b253a340f9", "message": "comments\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:50:01Z", "type": "commit"}, {"oid": "1902d72052fa58ec046564d28b52fb078ff219e3", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1902d72052fa58ec046564d28b52fb078ff219e3", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:50:16Z", "type": "commit"}, {"oid": "1902d72052fa58ec046564d28b52fb078ff219e3", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1902d72052fa58ec046564d28b52fb078ff219e3", "message": "fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T19:50:16Z", "type": "forcePushed"}, {"oid": "9d5eca8597387d3935b1a7b278361a82882aca5a", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9d5eca8597387d3935b1a7b278361a82882aca5a", "message": "fixup! fixes\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-08-19T20:07:36Z", "type": "commit"}]}