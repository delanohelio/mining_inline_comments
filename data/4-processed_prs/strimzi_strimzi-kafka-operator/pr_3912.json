{"pr_number": 3912, "pr_title": "[DOC] consumer configuration tuning", "pr_createdAt": "2020-11-03T13:19:41Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912", "timeline": [{"oid": "6281dcc211318fbd6a843c3df1f323e1d96eafcd", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6281dcc211318fbd6a843c3df1f323e1d96eafcd", "message": "[DOC] consumer configuration tuning\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-11-03T13:17:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NTM0Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r516965343", "bodyText": "Might be handy to mention what is the default.", "author": "scholzj", "createdAt": "2020-11-03T21:27:23Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,253 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.Deserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.Deserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+.Adjusting the ratio of consumers to partitions\n+\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted`", "originalCommit": "6281dcc211318fbd6a843c3df1f323e1d96eafcd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NjA1MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r516966050", "bodyText": "The title and the first sentence seem misleading. I expected this to talk about what to do when the commit call fails. But this is rather what to do when there are no previous offsets. Maybe you could make it a bit clearer?", "author": "scholzj", "createdAt": "2020-11-03T21:29:02Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,253 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.Deserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.Deserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+.Adjusting the ratio of consumers to partitions\n+\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted`\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heatbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.\n+\n+The `session.timeout.ms` property specifies the maximum amount of time in milliseconds a consumer within a consumer group can be out of contact with a broker before being considered inactive and a _rebalancing_ is triggered between the active consumers in the group.\n+When the group rebalances, the partitions are reassigned to the members of the group.\n+\n+The `heatbeat.interval.ms` property specifies the interval in milliseconds between _heartbeat_ checks to the consumer group coordinator to indicate that the consumer is active and connected.\n+The heartbeat interval must be lower, usually by a third, than the session timeout interval.\n+\n+If you set the `session.timeout.ms` property lower, failing consumers are detected earlier, and rebalancing can take place quicker.\n+However, take care not to set the timeout so low that the broker fails to receive a heartbeat in time and triggers an unnecessary rebalance.\n+\n+Decreasing the heartbeat interval reduces the chance of accidental rebalancing, but more frequent heartbeats increases the overhead on broker resources.\n+\n+== Handling uncommitted offsets\n+\n+Use the `auto.offset.reset` property to control how the consumer behaves when offsets are not committed.", "originalCommit": "6281dcc211318fbd6a843c3df1f323e1d96eafcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkyNTAwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r517925008", "bodyText": "Yes. Could be clearer. I've changed to:\n\nUse the auto.offset.reset property to control how a consumer behaves when no offsets have been committed, or a committed offset is no longer valid or deleted.\nSuppose a consumer fails before an offset has been committed. The consumer that then assumes responsibility for consuming the messages will start reading from the reassigned topic partition based on the reset policy. The default value is latest, which starts at the end of the partition, and consequently means some messages are missed. To avoid data loss, but increase the amount of processing, use the earliest value to start at the beginning of the partition.", "author": "PaulRMellor", "createdAt": "2020-11-05T09:56:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NjA1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NjU2OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r516966568", "bodyText": "Might be worth mentioning what happens when you have more consumers than partitions.", "author": "scholzj", "createdAt": "2020-11-03T21:30:03Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,253 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.Deserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.Deserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.", "originalCommit": "6281dcc211318fbd6a843c3df1f323e1d96eafcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE2MTE3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r517161173", "bodyText": "I see it mentioned in the following section Adjusting the ratio of consumers to partitions", "author": "ppatierno", "createdAt": "2020-11-04T08:12:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NjU2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkzNDI4Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r517934287", "bodyText": "I've moved the mention up so that it all sits together", "author": "PaulRMellor", "createdAt": "2020-11-05T10:10:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NjU2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE1ODM0MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r517158341", "bodyText": "why are we putting the Deserielizer interface instead of an actual implementation of it? i.e. StringDeserializer\njust as an example?", "author": "ppatierno", "createdAt": "2020-11-04T08:06:23Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,253 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.Deserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.Deserializer  <3>", "originalCommit": "6281dcc211318fbd6a843c3df1f323e1d96eafcd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkzNTU5Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r517935596", "bodyText": "I've changed both to .StringDeserializer", "author": "PaulRMellor", "createdAt": "2020-11-05T10:13:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE1ODM0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE2NDc1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r517164751", "bodyText": "typo heartbeat.interval.ms", "author": "ppatierno", "createdAt": "2020-11-04T08:19:12Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,253 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.Deserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.Deserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+.Adjusting the ratio of consumers to partitions\n+\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted`\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heatbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.", "originalCommit": "6281dcc211318fbd6a843c3df1f323e1d96eafcd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE2NTQyMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r517165420", "bodyText": "typo heartbeat.interval.ms", "author": "ppatierno", "createdAt": "2020-11-04T08:20:30Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,253 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.Deserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.Deserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+.Adjusting the ratio of consumers to partitions\n+\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted`\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heatbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.\n+\n+The `session.timeout.ms` property specifies the maximum amount of time in milliseconds a consumer within a consumer group can be out of contact with a broker before being considered inactive and a _rebalancing_ is triggered between the active consumers in the group.\n+When the group rebalances, the partitions are reassigned to the members of the group.\n+\n+The `heatbeat.interval.ms` property specifies the interval in milliseconds between _heartbeat_ checks to the consumer group coordinator to indicate that the consumer is active and connected.", "originalCommit": "6281dcc211318fbd6a843c3df1f323e1d96eafcd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzE2NTk5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r517165993", "bodyText": "typo heartbeat.interval.ms", "author": "ppatierno", "createdAt": "2020-11-04T08:21:35Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,253 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.Deserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.Deserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+.Adjusting the ratio of consumers to partitions\n+\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted`\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heatbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.\n+\n+The `session.timeout.ms` property specifies the maximum amount of time in milliseconds a consumer within a consumer group can be out of contact with a broker before being considered inactive and a _rebalancing_ is triggered between the active consumers in the group.\n+When the group rebalances, the partitions are reassigned to the members of the group.\n+\n+The `heatbeat.interval.ms` property specifies the interval in milliseconds between _heartbeat_ checks to the consumer group coordinator to indicate that the consumer is active and connected.\n+The heartbeat interval must be lower, usually by a third, than the session timeout interval.\n+\n+If you set the `session.timeout.ms` property lower, failing consumers are detected earlier, and rebalancing can take place quicker.\n+However, take care not to set the timeout so low that the broker fails to receive a heartbeat in time and triggers an unnecessary rebalance.\n+\n+Decreasing the heartbeat interval reduces the chance of accidental rebalancing, but more frequent heartbeats increases the overhead on broker resources.\n+\n+== Handling uncommitted offsets\n+\n+Use the `auto.offset.reset` property to control how the consumer behaves when offsets are not committed.\n+This could be because the consumer was down for a period.\n+To avoid data loss, but increase the amount of processing, use the `earliest` value to start at the beginning of the partition.\n+The other allowed value is `latest`, which starts at the end of the partition, and consequently means some messages are missed.\n+\n+----\n+# ...\n+heatbeat.interval.ms=3000 <1>", "originalCommit": "6281dcc211318fbd6a843c3df1f323e1d96eafcd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/bc9ff9c96964fae9b7cd34d00404b130d90c783f", "message": "review edits JS, PP\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-11-05T10:27:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIyMjA0OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518222048", "bodyText": "Suggested change:\nA minimum set of configuration properties is required, but you can add or adjust properties to change how producers and consumers interact with Kafka.", "author": "laidan6000", "createdAt": "2020-11-05T17:19:27Z", "path": "documentation/assemblies/managing/assembly-client-config.adoc", "diffHunk": "@@ -9,10 +9,12 @@ Use configuration properties to optimize the performance of Kafka producers and\n \n A minimum set of configuration properties is required.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY3OTk3MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518679970", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n          \n          \n            \n            * The broker does not know if the consumer processed the responses, even when committing offsets to Kafka, because the offsets might be sent to a different broker in the cluster.", "author": "laidan6000", "createdAt": "2020-11-06T11:03:41Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY4MDgyOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518680829", "bodyText": "it's > it is", "author": "laidan6000", "createdAt": "2020-11-06T11:05:13Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY4MTAyMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518681021", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n          \n          \n            \n            If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service because the availability is handled by the loadbalancer.", "author": "laidan6000", "createdAt": "2020-11-06T11:05:37Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY4MzQ1Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518683457", "bodyText": "Would \"subscribed to\" be better than \"interested in\"?", "author": "laidan6000", "createdAt": "2020-11-06T11:10:12Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc5MzcxNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518793715", "bodyText": "Changed to:\nOne of the consumers in the group is elected leader and decides how applicable partitions are assigned to the consumers.", "author": "PaulRMellor", "createdAt": "2020-11-06T14:41:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY4MzQ1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY4NTgyNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518685825", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you want a strict ordering of messages from one topic, use one partition.\n          \n          \n            \n            If you want a strict ordering of messages from one topic, use one partition per consumer.", "author": "laidan6000", "createdAt": "2020-11-06T11:15:06Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY4OTgxMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518689812", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n          \n          \n            \n            The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time.", "author": "laidan6000", "createdAt": "2020-11-06T11:23:19Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY5MDM2OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518690369", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The maximum amount of memory a client can consume is approximately:\n          \n          \n            \n            The approximate maximum amount of memory a client can consume is calculated as follows:", "author": "laidan6000", "createdAt": "2020-11-06T11:24:26Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY5MDgwOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518690809", "bodyText": "Add \"for example\"?", "author": "laidan6000", "createdAt": "2020-11-06T11:25:16Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc5Nzk2MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518797961", "bodyText": "Not sure it needs it.", "author": "PaulRMellor", "createdAt": "2020-11-06T14:47:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY5MDgwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY5NTg2Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518695862", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If this impacts throughput unduly, you can commit less frequently,\n          \n          \n            \n            If this negatively affects throughput, you can commit less frequently,", "author": "laidan6000", "createdAt": "2020-11-06T11:36:13Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY5NjQ0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518696444", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n          \n          \n            \n            Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly-once delivery.", "author": "laidan6000", "createdAt": "2020-11-06T11:37:27Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY5Njk0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518696940", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n          \n          \n            \n            However, this will cause an increase in end-to-end latency, because the consumer will not be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).", "author": "laidan6000", "createdAt": "2020-11-06T11:38:34Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted` (default)\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY5NzAzNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518697035", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <1> Auto commit is set to false to provide more control over committing offsets\n          \n          \n            \n            <1> Auto commit is set to false to provide more control over committing offsets.", "author": "laidan6000", "createdAt": "2020-11-06T11:38:47Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted` (default)\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcwMDE0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518700142", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <2> If no heartbeats are received by the kafka broker before the timeout duration expires, the consumer is removed from the consumer group and a rebalance is initiated.\n          \n          \n            \n            <2> If no heartbeats are received by the Kafka broker before the timeout duration expires, the consumer is removed from the consumer group and a rebalance is initiated.", "author": "laidan6000", "createdAt": "2020-11-06T11:45:22Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted` (default)\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heartbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.\n+\n+The `session.timeout.ms` property specifies the maximum amount of time in milliseconds a consumer within a consumer group can be out of contact with a broker before being considered inactive and a _rebalancing_ is triggered between the active consumers in the group.\n+When the group rebalances, the partitions are reassigned to the members of the group.\n+\n+The `heartbeat.interval.ms` property specifies the interval in milliseconds between _heartbeat_ checks to the consumer group coordinator to indicate that the consumer is active and connected.\n+The heartbeat interval must be lower, usually by a third, than the session timeout interval.\n+\n+If you set the `session.timeout.ms` property lower, failing consumers are detected earlier, and rebalancing can take place quicker.\n+However, take care not to set the timeout so low that the broker fails to receive a heartbeat in time and triggers an unnecessary rebalance.\n+\n+Decreasing the heartbeat interval reduces the chance of accidental rebalancing, but more frequent heartbeats increases the overhead on broker resources.\n+\n+== Managing offset policy\n+\n+Use the `auto.offset.reset` property to control how a consumer behaves when no offsets have been committed,\n+or a committed offset is no longer valid or deleted.\n+\n+Suppose a consumer fails before an offset has been committed.\n+The consumer that then assumes responsibility for consuming the messages will start reading from the reassigned topic partition based on the reset policy.\n+The default value is `latest`, which starts at the end of the partition, and consequently means some messages are missed.\n+To avoid data loss, but increase the amount of processing, use the `earliest` value to start at the beginning of the partition.\n+\n+----\n+# ...\n+heartbeat.interval.ms=3000 <1>\n+session.timeout.ms=10000 <2>\n+auto.offset.reset=earliest <3>\n+# ...\n+----\n+<1> Adjust the heartbeat interval lower according to anticipated rebalances.\n+<2> If no heartbeats are received by the kafka broker before the timeout duration expires, the consumer is removed from the consumer group and a rebalance is initiated.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcwMDQ1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518700451", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If this is the case, you can lower `max.partition.fetch.bytes` or increase `session.timeout.ms`.\n          \n          \n            \n            In this case, you can lower `max.partition.fetch.bytes` or increase `session.timeout.ms`.", "author": "laidan6000", "createdAt": "2020-11-06T11:46:05Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted` (default)\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heartbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.\n+\n+The `session.timeout.ms` property specifies the maximum amount of time in milliseconds a consumer within a consumer group can be out of contact with a broker before being considered inactive and a _rebalancing_ is triggered between the active consumers in the group.\n+When the group rebalances, the partitions are reassigned to the members of the group.\n+\n+The `heartbeat.interval.ms` property specifies the interval in milliseconds between _heartbeat_ checks to the consumer group coordinator to indicate that the consumer is active and connected.\n+The heartbeat interval must be lower, usually by a third, than the session timeout interval.\n+\n+If you set the `session.timeout.ms` property lower, failing consumers are detected earlier, and rebalancing can take place quicker.\n+However, take care not to set the timeout so low that the broker fails to receive a heartbeat in time and triggers an unnecessary rebalance.\n+\n+Decreasing the heartbeat interval reduces the chance of accidental rebalancing, but more frequent heartbeats increases the overhead on broker resources.\n+\n+== Managing offset policy\n+\n+Use the `auto.offset.reset` property to control how a consumer behaves when no offsets have been committed,\n+or a committed offset is no longer valid or deleted.\n+\n+Suppose a consumer fails before an offset has been committed.\n+The consumer that then assumes responsibility for consuming the messages will start reading from the reassigned topic partition based on the reset policy.\n+The default value is `latest`, which starts at the end of the partition, and consequently means some messages are missed.\n+To avoid data loss, but increase the amount of processing, use the `earliest` value to start at the beginning of the partition.\n+\n+----\n+# ...\n+heartbeat.interval.ms=3000 <1>\n+session.timeout.ms=10000 <2>\n+auto.offset.reset=earliest <3>\n+# ...\n+----\n+<1> Adjust the heartbeat interval lower according to anticipated rebalances.\n+<2> If no heartbeats are received by the kafka broker before the timeout duration expires, the consumer is removed from the consumer group and a rebalance is initiated.\n+If the broker configuration has a `group.min.session.timeout.ms` and `group.max.session.timeout.ms`, the session timeout value must be within that range.\n+<3> Set to `earliest` to return to the start of a partition and avoid data loss if offsets were not committed.\n+\n+If the amount of data returned in a single fetch request is large,\n+a timeout might occur before the consumer has processed it.\n+If this is the case, you can lower `max.partition.fetch.bytes` or increase `session.timeout.ms`.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcwMDcxMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518700713", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * The consumers in group to receive their assignments and start fetching\n          \n          \n            \n            * The consumers in the group to receive their assignments and start fetching", "author": "laidan6000", "createdAt": "2020-11-06T11:46:39Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted` (default)\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heartbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.\n+\n+The `session.timeout.ms` property specifies the maximum amount of time in milliseconds a consumer within a consumer group can be out of contact with a broker before being considered inactive and a _rebalancing_ is triggered between the active consumers in the group.\n+When the group rebalances, the partitions are reassigned to the members of the group.\n+\n+The `heartbeat.interval.ms` property specifies the interval in milliseconds between _heartbeat_ checks to the consumer group coordinator to indicate that the consumer is active and connected.\n+The heartbeat interval must be lower, usually by a third, than the session timeout interval.\n+\n+If you set the `session.timeout.ms` property lower, failing consumers are detected earlier, and rebalancing can take place quicker.\n+However, take care not to set the timeout so low that the broker fails to receive a heartbeat in time and triggers an unnecessary rebalance.\n+\n+Decreasing the heartbeat interval reduces the chance of accidental rebalancing, but more frequent heartbeats increases the overhead on broker resources.\n+\n+== Managing offset policy\n+\n+Use the `auto.offset.reset` property to control how a consumer behaves when no offsets have been committed,\n+or a committed offset is no longer valid or deleted.\n+\n+Suppose a consumer fails before an offset has been committed.\n+The consumer that then assumes responsibility for consuming the messages will start reading from the reassigned topic partition based on the reset policy.\n+The default value is `latest`, which starts at the end of the partition, and consequently means some messages are missed.\n+To avoid data loss, but increase the amount of processing, use the `earliest` value to start at the beginning of the partition.\n+\n+----\n+# ...\n+heartbeat.interval.ms=3000 <1>\n+session.timeout.ms=10000 <2>\n+auto.offset.reset=earliest <3>\n+# ...\n+----\n+<1> Adjust the heartbeat interval lower according to anticipated rebalances.\n+<2> If no heartbeats are received by the kafka broker before the timeout duration expires, the consumer is removed from the consumer group and a rebalance is initiated.\n+If the broker configuration has a `group.min.session.timeout.ms` and `group.max.session.timeout.ms`, the session timeout value must be within that range.\n+<3> Set to `earliest` to return to the start of a partition and avoid data loss if offsets were not committed.\n+\n+If the amount of data returned in a single fetch request is large,\n+a timeout might occur before the consumer has processed it.\n+If this is the case, you can lower `max.partition.fetch.bytes` or increase `session.timeout.ms`.\n+\n+== Minimizing the impact of rebalances\n+\n+The rebalancing of a partition between active consumers in a group is the time it takes for:\n+\n+* Consumers to commit their offsets\n+* The new consumer group to be formed\n+* The group leader to assign partitions to group members\n+* The consumers in group to receive their assignments and start fetching", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcwMjgyMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r518702821", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Or you can use the `max.poll.records` property to set a maximum limit on the number of records returned from the consumer buffer, allowing your application to process fewer records within the max.poll.interval.ms limit.\n          \n          \n            \n            Or you can use the `max.poll.records` property to set a maximum limit on the number of records returned from the consumer buffer, allowing your application to process fewer records within the `max.poll.interval.ms` limit.", "author": "laidan6000", "createdAt": "2020-11-06T11:51:02Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service as the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions that the consumers are interested in should be assigned to the consumers.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time,\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is approximately:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this impacts throughput unduly, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted` (default)\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer won\u2019t be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heartbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.\n+\n+The `session.timeout.ms` property specifies the maximum amount of time in milliseconds a consumer within a consumer group can be out of contact with a broker before being considered inactive and a _rebalancing_ is triggered between the active consumers in the group.\n+When the group rebalances, the partitions are reassigned to the members of the group.\n+\n+The `heartbeat.interval.ms` property specifies the interval in milliseconds between _heartbeat_ checks to the consumer group coordinator to indicate that the consumer is active and connected.\n+The heartbeat interval must be lower, usually by a third, than the session timeout interval.\n+\n+If you set the `session.timeout.ms` property lower, failing consumers are detected earlier, and rebalancing can take place quicker.\n+However, take care not to set the timeout so low that the broker fails to receive a heartbeat in time and triggers an unnecessary rebalance.\n+\n+Decreasing the heartbeat interval reduces the chance of accidental rebalancing, but more frequent heartbeats increases the overhead on broker resources.\n+\n+== Managing offset policy\n+\n+Use the `auto.offset.reset` property to control how a consumer behaves when no offsets have been committed,\n+or a committed offset is no longer valid or deleted.\n+\n+Suppose a consumer fails before an offset has been committed.\n+The consumer that then assumes responsibility for consuming the messages will start reading from the reassigned topic partition based on the reset policy.\n+The default value is `latest`, which starts at the end of the partition, and consequently means some messages are missed.\n+To avoid data loss, but increase the amount of processing, use the `earliest` value to start at the beginning of the partition.\n+\n+----\n+# ...\n+heartbeat.interval.ms=3000 <1>\n+session.timeout.ms=10000 <2>\n+auto.offset.reset=earliest <3>\n+# ...\n+----\n+<1> Adjust the heartbeat interval lower according to anticipated rebalances.\n+<2> If no heartbeats are received by the kafka broker before the timeout duration expires, the consumer is removed from the consumer group and a rebalance is initiated.\n+If the broker configuration has a `group.min.session.timeout.ms` and `group.max.session.timeout.ms`, the session timeout value must be within that range.\n+<3> Set to `earliest` to return to the start of a partition and avoid data loss if offsets were not committed.\n+\n+If the amount of data returned in a single fetch request is large,\n+a timeout might occur before the consumer has processed it.\n+If this is the case, you can lower `max.partition.fetch.bytes` or increase `session.timeout.ms`.\n+\n+== Minimizing the impact of rebalances\n+\n+The rebalancing of a partition between active consumers in a group is the time it takes for:\n+\n+* Consumers to commit their offsets\n+* The new consumer group to be formed\n+* The group leader to assign partitions to group members\n+* The consumers in group to receive their assignments and start fetching\n+\n+Clearly, the process increases the downtime of a service, particularly when it happens repeatedly during a rolling restart of a consumer group cluster.\n+\n+In this situation, you can use the concept of _static membership_ to reduce the number of rebalances.\n+Rebalancing assigns topic partitions evenly among consumer group members.\n+Static membership uses persistence so that a consumer instance is recognized during a restart after a session timeout.\n+\n+The consumer group coordinator can identify a new consumer instance using a unique id that is specified using the `group.instance.id` property.\n+During a restart, the consumer is assigned a new member id, but as a static member it continues with the same instance id,\n+and the same assignment of topic partitions is made.\n+\n+If the consumer application does not make a call to poll at least every `max.poll.interval.ms milliseconds`, the consumer is considered to be failed, causing a rebalance.\n+If the application cannot process all the records returned from poll in time, you can avoid a rebalance by using the `max.poll.interval.ms` property to specify the interval in milliseconds between polls for new messages from a consumer.\n+Or you can use the `max.poll.records` property to set a maximum limit on the number of records returned from the consumer buffer, allowing your application to process fewer records within the max.poll.interval.ms limit.", "originalCommit": "bc9ff9c96964fae9b7cd34d00404b130d90c783f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "233e94a3ffff6ad097fdb2e73b89a3c13a1a1e36", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/233e94a3ffff6ad097fdb2e73b89a3c13a1a1e36", "message": "review edits DL\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-11-06T14:52:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE3NjQ0OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r519176449", "bodyText": "The sentence suggests that it is possible to have a consumer without a group, which is not possible if I'm not wrong and according to this\napache/kafka@093e8e7", "author": "OuesFa", "createdAt": "2020-11-07T13:14:26Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka, because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it is not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service because the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.", "originalCommit": "233e94a3ffff6ad097fdb2e73b89a3c13a1a1e36", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE3ODc4Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r519178786", "bodyText": "AFAIK the group.id is not mandatory. You can have a consumer which is not part of any consumer group. You just cannot join a group without the group.id.", "author": "scholzj", "createdAt": "2020-11-07T13:41:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE3NjQ0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTc5OTU4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r519799582", "bodyText": "I've changed the description to make this point clearer.\n\n<5> (Conditional) A group id is required for a consumer to be able to join a consumer group", "author": "PaulRMellor", "createdAt": "2020-11-09T13:10:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE3NjQ0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NTY1Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r519185656", "bodyText": "I think automatic offset commits can provide at least once delivery as well. From the apche kafka docs:\n\nNote: Using automatic offset commits can also give you \"at-least-once\" delivery, but the requirement is that you must consume all data returned from each call to poll(Duration) before any subsequent calls, or before closing the consumer. If you fail to do either of these, it is possible for the committed offset to get ahead of the consumed position, which results in missing records. The advantage of using manual offset control is that you have direct control over when a record is considered \"consumed.\"\n\nReference: https://kafka.apache.org/23/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html", "author": "weeco", "createdAt": "2020-11-07T14:57:35Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,252 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka, because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it is not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service because the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ if the consumer belongs to a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions are assigned to the consumers in the group.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition per consumer.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time.\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is calculated approximately as:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+To minimize the likelihood of data loss or duplication, set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or use `auto.commit.interval.ms=1` to decrease the intervals between commits.", "originalCommit": "233e94a3ffff6ad097fdb2e73b89a3c13a1a1e36", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE5NTA2OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r519195069", "bodyText": "That is true in some cases ... it really depends on how you process these messages (synchronously before the next poll() call or asynchronously).", "author": "scholzj", "createdAt": "2020-11-07T16:43:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NTY1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTgzNDA2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r519834066", "bodyText": "I've expanded a little.\n\nThe auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication. If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost. If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\nAuto-committing can avoid creating duplicates only when all messages are consumed before the next poll to the broker,  or the consumer closes.\nTo minimize the likelihood of data loss or duplication, you can set enable.auto.commit to false and develop your client application to have more control over committing offsets. Or you can use auto.commit.interval.ms=1 to decrease the intervals between commits.", "author": "PaulRMellor", "createdAt": "2020-11-09T13:59:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NTY1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTgzODI2MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r519838261", "bodyText": "@PaulRMellor Your updated version is wrong. Auto-committing can not avoid creating duplicates but you can avoid data loss.", "author": "weeco", "createdAt": "2020-11-09T14:06:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NTY1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg0MDI4NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r519840285", "bodyText": "I think this sentence should sound like this:\nAuto-committing can avoid data loss only when all messages are processed before ...", "author": "scholzj", "createdAt": "2020-11-09T14:09:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTE4NTY1Ng=="}], "type": "inlineReview"}, {"oid": "fe5594803b2d1490093d4334e0836e3f968b2846", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fe5594803b2d1490093d4334e0836e3f968b2846", "message": "review edits JS, MS\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-11-09T15:31:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM4OTQ4MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r520389480", "bodyText": "I think we should suggest to lower it, but not suggest a specific value.", "author": "tombentley", "createdAt": "2020-11-10T08:52:12Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,255 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka, because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it is not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service because the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ for a consumer to be able to join a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions are assigned to the consumers in the group.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition per consumer.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time.\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is calculated approximately as:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+Auto-committing can avoid data loss only when all messages are processed before the next poll to the broker,\n+or the consumer closes.\n+\n+To minimize the likelihood of data loss or duplication, you can set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or you can use `auto.commit.interval.ms=1` to decrease the intervals between commits.", "originalCommit": "fe5594803b2d1490093d4334e0836e3f968b2846", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM5MDcwNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r520390705", "bodyText": "Maybe this deserves its own subsection?", "author": "tombentley", "createdAt": "2020-11-10T08:54:20Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,255 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka, because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it is not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service because the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ for a consumer to be able to join a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions are assigned to the consumers in the group.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition per consumer.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time.\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is calculated approximately as:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+Auto-committing can avoid data loss only when all messages are processed before the next poll to the broker,\n+or the consumer closes.\n+\n+To minimize the likelihood of data loss or duplication, you can set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or you can use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this negatively affects throughput, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly-once delivery.", "originalCommit": "fe5594803b2d1490093d4334e0836e3f968b2846", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ5MDI4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r520490289", "bodyText": "Created a new subsection", "author": "PaulRMellor", "createdAt": "2020-11-10T11:26:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM5MDcwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM5NzYwNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r520397605", "bodyText": "I'm not sure this is really be best example. Better would be:\nYou're deploying a consumer application for the first time and it reads an already existing topic with messages. Because this is the first time this group.id has been used the __consumer_offsets topic won't contain any offset information for this application. Should the new application start processing from the start of the log (thus processing all the existing messages), or the end of the log (thus processing only the messages which are appended from now on)?\nThere are other examples too (e.g. where a previously committed offset gets removed from __consumer_offsets because offsets.retention.minutes has passed without any commits from the (standalone) consumer of member of the consumer group).", "author": "tombentley", "createdAt": "2020-11-10T09:05:17Z", "path": "documentation/modules/managing/con-consumer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,255 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-consumer-config-properties-{context}']\n+= Kafka consumer configuration tuning\n+\n+Use a basic consumer configuration with optional properties that are tailored to specific use cases.\n+\n+When tuning your consumers your primary concern will be ensuring that they cope efficiently with the amount of data ingested.\n+As with the producer tuning, be prepared to make incremental changes until the consumers operate as expected.\n+\n+== Basic consumer configuration\n+\n+Connection and deserializer properties are required for every consumer.\n+Generally, it is good practice to add a client id for tracking.\n+\n+In a consumer configuration, irrespective of any subsequent configuration:\n+\n+* The consumer fetches from a given offset and consumes the messages in order, unless the offset is changed to skip or re-read messages.\n+* The broker does not know if the consumer processed the responses, even when committing offsets to Kafka, because the offsets might be sent to a different broker in the cluster.\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <2>\n+value.deserializer=org.apache.kafka.common.serialization.StringDeserializer  <3>\n+client.id=my-client <4>\n+group.id=my-group-id <5>\n+# ...\n+----\n+<1> (Required) Tells the consumer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The consumer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it is not necessary to provide a list of all the brokers in the cluster.\n+If you are using a loadbalancer service to expose the Kafka cluster, you only need the address for the service because the availability is handled by the loadbalancer.\n+<2> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message keys.\n+<3> (Required) Deserializer to transform the bytes fetched from the Kafka broker into message values.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request. The id can also be used to throttle consumers based on processing time quotas.\n+<5> (Conditional) A group id is _required_ for a consumer to be able to join a consumer group.\n+\n+Consumer groups are used to share a typically large data stream generated by multiple producers from a given topic.\n+Consumers are grouped using a `group.id`, allowing messages to be spread across the members.\n+\n+== Scaling data consumption using consumer groups\n+\n+Consumer groups share a typically large data stream generated by one or multiple producers from a given topic.\n+Consumers with the same `group.id` property are in the same group.\n+One of the consumers in the group is elected leader and decides how the partitions are assigned to the consumers in the group.\n+Each partition can only be assigned to a single consumer.\n+\n+If you do not already have as many consumers as partitions,\n+you can scale data consumption by adding more consumer instances with the same `group.id`.\n+Adding more consumers to a group than there are partitions will not help throughput,\n+but it does mean that there are consumers on standby should one stop functioning.\n+If you can meet throughput goals with fewer consumers, you save on resources.\n+\n+Consumers within the same consumer group send offset commits and heartbeats to the same broker.\n+So the greater the number of consumers in the group, the higher the request load on the broker.\n+\n+----\n+# ...\n+group.id=my-group-id <1>\n+# ...\n+----\n+<1> Add a consumer to a consumer group using a group id.\n+\n+== Message ordering guarantees\n+\n+Kafka brokers receive fetch requests from consumers that ask the broker to send messages from a list of topics, partitions and offset positions.\n+\n+A consumer observes messages in a single partition in the same order that they were committed to the broker,\n+which means that Kafka *only* provides ordering guarantees for messages in a single partition.\n+Conversely, if a consumer is consuming messages from multiple partitions, the order of messages in different partitions as observed by the consumer does not necessarily reflect the order in which they were sent.\n+\n+If you want a strict ordering of messages from one topic, use one partition per consumer.\n+\n+== Optimizing throughput and latency\n+\n+Control the number of messages returned when your client application calls `KafkaConsumer.poll()`.\n+\n+Use the `fetch.max.wait.ms` and `fetch.min.bytes` properties to increase the minimum amount of data fetched by the consumer from the Kafka broker.\n+Time-based batching is configured using `fetch.max.wait.ms`, and size-based batching is configured using `fetch.min.bytes`.\n+\n+If CPU utilization in the consumer or broker is high, it might be because there are too many requests from the consumer.\n+You can adjust `fetch.max.wait.ms` and `fetch.min.bytes` properties higher so that there are fewer requests and messages are delivered in bigger batches.\n+By adjusting higher, throughput is improved with some cost to latency.\n+You can also adjust higher if the amount of data being produced is low.\n+\n+For example, if you set `fetch.max.wait.ms` to 500ms and `fetch.min.bytes` to 16384 bytes,\n+when Kafka receives a fetch request from the consumer it will respond when the first of either threshold is reached.\n+\n+Conversely, you can adjust the `fetch.max.wait.ms` and `fetch.min.bytes` properties lower to improve end-to-end latency.\n+\n+----\n+# ...\n+fetch.max.wait.ms=500 <1>\n+fetch.min.bytes=16384 <2>\n+# ...\n+----\n+<1> The maximum time in milliseconds the broker will wait before completing fetch requests.\n+The default is `500` milliseconds.\n+<2> If a minimum batch size in bytes is used, a request is sent when the minimum is reached, or messages have been queued for longer than `fetch.max.wait.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+\n+.Lowering latency by increasing the fetch request size\n+\n+Use the `fetch.max.bytes` and `max.partition.fetch.bytes` properties to increase the maximum amount of data fetched by the consumer from the Kafka broker.\n+\n+The `fetch.max.bytes` property sets a maximum limit in bytes on the amount of data fetched from the broker at one time.\n+\n+The `max.partition.fetch.bytes` sets a maximum limit in bytes on how much data is returned for each partition,\n+which must always be larger than the number of bytes set in the broker or topic configuration for `max.message.bytes`.\n+\n+The maximum amount of memory a client can consume is calculated approximately as:\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+_NUMBER-OF-BROKERS_ * fetch.max.bytes and _NUMBER-OF-PARTITIONS_ * max.partition.fetch.bytes\n+----\n+\n+If memory usage can accommodate it, you can increase the values of these two properties.\n+By allowing more data in each request, latency is improved as there are fewer fetch requests.\n+\n+----\n+# ...\n+fetch.max.bytes=52428800 <1>\n+max.partition.fetch.bytes=1048576 <2>\n+# ...\n+----\n+<1> The maximum amount of data in bytes returned for a fetch request.\n+<2> The maximum amount of data in bytes returned for each partition.\n+\n+== Avoiding data loss or duplication when committing offsets\n+\n+The Kafka _auto-commit mechanism_ allows a consumer to commit the offsets of messages automatically.\n+If enabled, the consumer will commit offsets received from polling the broker at 5000ms intervals.\n+\n+The auto-commit mechanism is convenient, but it introduces a risk of data loss and duplication.\n+If a consumer has fetched and transformed a number of messages, but the system crashes with processed messages in the consumer buffer when performing an auto-commit, that data is lost.\n+If the system crashes after processing the messages, but before performing the auto-commit, the data is duplicated on another consumer instance after rebalancing.\n+\n+Auto-committing can avoid data loss only when all messages are processed before the next poll to the broker,\n+or the consumer closes.\n+\n+To minimize the likelihood of data loss or duplication, you can set `enable.auto.commit` to `false` and develop your client application to have more control over committing offsets.\n+Or you can use `auto.commit.interval.ms=1` to decrease the intervals between commits.\n+\n+By setting to `enable.auto.commit` to `false`, you can commit offsets after *all* processing has been performed and the message has been consumed.\n+For example, you can set up your application to call the Kafka `commitSync` and `commitAsync` commit APIs.\n+\n+The `commitSync` API commits the offsets in a message batch returned from polling.\n+You call the API when you are finished processing all the messages in the batch.\n+If you use the `commitSync` API, the application will not poll for new messages until the last offset in the batch is committed.\n+If this negatively affects throughput, you can commit less frequently,\n+or you can use the `commitAsync` API.\n+The `commitAsync` API does not wait for the broker to respond to a commit request,\n+but risks creating more duplicates when rebalancing.\n+A common approach is to combine both commit APIs in an application, with the `commitSync` API used just before shutting the consumer down or rebalancing to make sure the final commit is successful.\n+\n+Also, consider using transactional ids and having idempotence enabled (`enable.idempotence=true`) on the producer side to guarantee exactly-once delivery.\n+On the consumer side, you can then use the `isolation.level` property to control how transactional messages are read by the consumer.\n+\n+The `isolation.level` property has two valid values:\n+\n+* `read_committed`\n+* `read_uncommitted` (default)\n+\n+Use `read_committed` to ensure that only transactional messages that have been committed are read by the consumer.\n+However, this will cause an increase in end-to-end latency, because the consumer will not be able to return a message until the brokers have written the transaction markers that record the result of the transaction (_committed_ or _aborted_).\n+\n+----\n+# ...\n+enable.auto.commit=false <1>\n+isolation.level=read_committed <2>\n+# ...\n+----\n+<1> Auto commit is set to false to provide more control over committing offsets.\n+<2> Set to `read_committed` so that only committed messages are read by the consumer.\n+\n+== Recovering from failure to avoid data loss\n+\n+Use the `session.timeout.ms` and `heartbeat.interval.ms` properties to configure the time taken to check and recover from consumer failure within a consumer group.\n+\n+The `session.timeout.ms` property specifies the maximum amount of time in milliseconds a consumer within a consumer group can be out of contact with a broker before being considered inactive and a _rebalancing_ is triggered between the active consumers in the group.\n+When the group rebalances, the partitions are reassigned to the members of the group.\n+\n+The `heartbeat.interval.ms` property specifies the interval in milliseconds between _heartbeat_ checks to the consumer group coordinator to indicate that the consumer is active and connected.\n+The heartbeat interval must be lower, usually by a third, than the session timeout interval.\n+\n+If you set the `session.timeout.ms` property lower, failing consumers are detected earlier, and rebalancing can take place quicker.\n+However, take care not to set the timeout so low that the broker fails to receive a heartbeat in time and triggers an unnecessary rebalance.\n+\n+Decreasing the heartbeat interval reduces the chance of accidental rebalancing, but more frequent heartbeats increases the overhead on broker resources.\n+\n+== Managing offset policy\n+\n+Use the `auto.offset.reset` property to control how a consumer behaves when no offsets have been committed,\n+or a committed offset is no longer valid or deleted.\n+\n+Suppose a consumer fails before an offset has been committed.\n+The consumer that then assumes responsibility for consuming the messages will start reading from the reassigned topic partition based on the reset policy.", "originalCommit": "fe5594803b2d1490093d4334e0836e3f968b2846", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDYyODI2MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3912#discussion_r520628260", "bodyText": "I've changed to the two suggestions", "author": "PaulRMellor", "createdAt": "2020-11-10T14:59:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM5NzYwNQ=="}], "type": "inlineReview"}, {"oid": "da4094187040f28d1843aabfdcb6600c829a3ec7", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/da4094187040f28d1843aabfdcb6600c829a3ec7", "message": "review edits TB\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-11-10T15:00:30Z", "type": "commit"}]}