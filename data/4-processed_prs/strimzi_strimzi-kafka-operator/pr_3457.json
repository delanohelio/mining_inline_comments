{"pr_number": 3457, "pr_title": "[DOC] Managing Strimzi: Tuning producer configuration", "pr_createdAt": "2020-08-05T12:51:28Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457", "timeline": [{"oid": "e3bed0ace8562c56898b2a5714971040a9b22e35", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e3bed0ace8562c56898b2a5714971040a9b22e35", "message": "[DOC] Managing Strimzi: Tuning client configuration\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-08-05T12:27:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTE2MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r465999161", "bodyText": "Any reason why we picked these two for the minimal configuration? I would maybe leave these out?", "author": "scholzj", "createdAt": "2020-08-05T20:57:16Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM5NDk0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466394944", "bodyText": "You're right that they're not strictly required, but there's also a balance to be struck between strict minimality and recommending particular configs because of their general usefulness/applicability. Maybe we shouldn't call it a \"minimal configuration\", but rather a \"basic/initial/starting point configuration\".", "author": "tombentley", "createdAt": "2020-08-06T13:02:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTE2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTczNzQ0OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469737449", "bodyText": "I changed to Basic producer configuration", "author": "PaulRMellor", "createdAt": "2020-08-13T06:59:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTE2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTgyMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r465999823", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <3> Set to `all`.\n          \n          \n            \n            <3> Set `acks` to `all`.", "author": "scholzj", "createdAt": "2020-08-05T20:58:35Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.\n+<3> Set to `all`.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTk5NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r465999995", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <1> Set to `true`.\n          \n          \n            \n            <1> Enable idempotent producer", "author": "scholzj", "createdAt": "2020-08-05T20:58:54Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM5MDU1MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469390550", "bodyText": "Set to true to enable the idempotent producer.", "author": "PaulRMellor", "createdAt": "2020-08-12T16:33:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwMTE4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466001182", "bodyText": "I don't think makes sense ... setting in-flight messages to 1 will slow down the producer. So it does not fit for me with the If the performance cost is too great. Maybe something like If performance is not the main priority or something like that?", "author": "scholzj", "createdAt": "2020-08-05T21:01:17Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.\n+<3> Set to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If the performance cost is too great, and you are not using `acks=all`,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwMzY3MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466403671", "bodyText": "TBH I think this sentence is really part of the following section on ordered without idempotency.", "author": "tombentley", "createdAt": "2020-08-06T13:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwMTE4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgwMTI0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469801242", "bodyText": "Yes, it's related to the next example.\nI've changed to:\nIf you are not using acks=all and idempotency because of the performance cost, set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.", "author": "PaulRMellor", "createdAt": "2020-08-13T08:55:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwMTE4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NTU1NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466185555", "bodyText": "using the plural sounds strange to me .. \"message keys\" and \"message values\" ... it seems that a Kafka message has more than one key and more than one value which is not the case.", "author": "ppatierno", "createdAt": "2020-08-06T06:57:25Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM5NTcwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466395703", "bodyText": "\"...transform each message's value to bytes...\" perhaps?", "author": "tombentley", "createdAt": "2020-08-06T13:03:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NTU1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgxMzAxNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469813017", "bodyText": "Changed to the key of each message and the value of each message", "author": "PaulRMellor", "createdAt": "2020-08-13T09:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NTU1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NzM3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466187374", "bodyText": "This is the opposite of the statement that is always mentioned when you talk about messages order in Kafka.\nI guess you are saying that based on retries and inflight requests (so retries > 0 and inflight > 1 can drive to change the order) but I think that we should be clear about that otherwise we can confuse people reading since the beginning. Maybe we could say \"The order of messages can be guaranteed at partition level only\" or something like that @tombentley wdyt?", "author": "ppatierno", "createdAt": "2020-08-06T07:01:38Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM5MzE2NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466393165", "bodyText": "I think the problem is in \"always mentioned when you talk about messages order in Kafka\". The fact is that Kafka can provide a message ordering guarantee if it's configured to, but by default it does not. So where those statements about message ordering exist in these docs we should fix them to be clearer (and we can now link to the section which describes how to configure for an ordering guarantee).\nIn any case I don't think this is confusing as it stands because we do way \"In this minimal configuration\".", "author": "tombentley", "createdAt": "2020-08-06T12:59:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NzM3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ3MjYwMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466472601", "bodyText": "I agree on the fact that the statement is wrong but I still think that \"The order of messages can be guaranteed at partition level only\" much better than saying \"is not guaranteed\" or at least we should add that it's not guaranteed if not configured in the proper way. I thought that my \"can be\" could open the possibility and the understanding that it can be guaranteed if configured to do so.\nBtw it's not just about our doc ... maybe every developer in the world having a Kafka presentation slides deck should change his slides at this point (me included).", "author": "ppatierno", "createdAt": "2020-08-06T14:54:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NzM3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgxNzkzMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469817933", "bodyText": "I think the section is clear that this is referring to the basic config. That is, before we look at the config that adds the guarantees", "author": "PaulRMellor", "createdAt": "2020-08-13T09:23:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NzM3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzI1NjEyMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r477256120", "bodyText": "Ok, so ... \"In this basic configuration\" ...should be the key. I really hope that other readers will pay more attention than me :-)", "author": "ppatierno", "createdAt": "2020-08-26T12:19:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4NzM3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5MzkyMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466193920", "bodyText": "5 is already the default", "author": "ppatierno", "createdAt": "2020-08-06T07:15:25Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwMjc2Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466402767", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <2> Specify the number of allowed in-flight requests to a maximum of 5.\n          \n          \n            \n            <2> With idempotent delivery the number of in-flight requests may be greater than 1 while still providing the message ordering guarantee.", "author": "tombentley", "createdAt": "2020-08-06T13:14:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5MzkyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NDMzNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466194335", "bodyText": "Disable idempotent producer", "author": "ppatierno", "createdAt": "2020-08-06T07:16:18Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.\n+<3> Set to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If the performance cost is too great, and you are not using `acks=all`,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.\n+Otherwise, a situation is possible where _Message-A_ fails only to succeed after _Message-B_ was already written to the broker.\n+\n+.Ordered delivery without idempotency\n+----\n+# ...\n+enable.idempotence=false <1>\n+max.in.flight.requests.per.connection=1 <2>\n+retries=2147483647\n+# ...\n+----\n+<1> Set to `false`.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM5MjY5Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469392697", "bodyText": "Set to false to disable the idempotent producer.", "author": "PaulRMellor", "createdAt": "2020-08-12T16:36:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NDMzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NzM4MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466197380", "bodyText": "in the above example, I don't think we are explaining well the balance between linger time and batch size. I mean, with above example, the message will be sent immediately because linger is 0, right?\nIf we want to explain better, maybe we should see linger to 100 ms for example and saying that messages are sent when 100 ms are reached without filling the batch size completely, or if you fill the entire batch size in less than 100 ms. @tombentley wdyt?", "author": "ppatierno", "createdAt": "2020-08-06T07:22:21Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.\n+<3> Set to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If the performance cost is too great, and you are not using `acks=all`,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.\n+Otherwise, a situation is possible where _Message-A_ fails only to succeed after _Message-B_ was already written to the broker.\n+\n+.Ordered delivery without idempotency\n+----\n+# ...\n+enable.idempotence=false <1>\n+max.in.flight.requests.per.connection=1 <2>\n+retries=2147483647\n+# ...\n+----\n+<1> Set to `false`.\n+<2> Set the number of in-flight requests to exactly `1`.\n+\n+== Reliability guarantees\n+\n+Idempotence is useful for exactly once writes from a single partition.\n+Transactions, when used with idempotence, allow exactly once writes across multiple partitions.\n+\n+Transactions guarantee that messages using the same transactional ID are produced once,\n+and either _all_ are successfully written to the log or _none_ of them are.\n+\n+----\n+# ...\n+enable.idempotence=true\n+max.in.flight.requests.per.connection=5\n+acks=all\n+retries=2147483647\n+transactional.id=_UNIQUE-ID_ <1>\n+transaction.timeout.ms=900000 <2>\n+# ...\n+----\n+<1> Specify a unique transactional ID.\n+<2> Set the maximum allowed time for transactions in milliseconds before a timeout error is returned.\n+The default is `900000` or 15 minutes.\n+\n+The choice of `transactional.id` is important in order that the transational guarantee is maintained.\n+Each transactional id should be used for a unique set of topic partitions.\n+For example, this can be achieved using an external mapping of topic partition names to transactional ids,\n+or by computing the transactional id from the topic partition names using a function that avoids collisions.\n+\n+== Optimizing throughput and latency\n+\n+Usually, the requirement of a system is to satisfy a particular throughput target for a proportion of messages within a given latency.\n+For example, targeting 500,000 messages per second with 95% of messages being acknowledged within 2 seconds.\n+\n+It\u2019s likely that the messaging semantics (message ordering and durability) of your producer are defined by the requirements for your application.\n+For instance, it\u2019s possible that you don\u2019t have the option of using `acks=0` or `acks=1` without breaking some important property or guarantee provided by your application.\n+\n+Broker restarts have a significant impact on high percentile statistics.\n+For example, over a long period the 99th percentile latency is dominated by behavior around broker restarts.\n+This is worth considering when designing benchmarks or comparing performance numbers from benchmarking with performance numbers seen in production.\n+\n+Depending on your objective, Kafka offers a number of configuration parameters and techniques for tuning producer performance for throughput and latency.\n+\n+Message batching (`linger.ms` and `batch.size`)::\n+Message batching delays sending messages in the hope that more messages destined for the same broker will be sent,\n+allowing them to be batched into a single produce request.\n+Batching is a compromise between higher latency in return for higher throughput.\n+Time-based batching is configured using `linger.ms`, and size-based batching is configured using `batch.size`.\n+\n+Compression (`compression.type`)::\n+Message compression adds latency in the producer (CPU time spent compressing the messages),\n+but makes requests (and potentially disk writes) smaller, which can increase throughput.\n+Whether compression is worthwhile, and the best compression to use, will depend on the messages being sent.\n+Compression happens on the thread which calls `KafkaProducer.send()`,\n+so if the latency of this method matters for your application you should consider using more threads.\n+\n+Pipelining (`max.in.flight.requests.per.connection`)::\n+Pipelining means sending more requests before the response to a previous request has been received.\n+In general more pipelining means better throughput, up to a threshold at which other effects,\n+such as worse batching, start to counteract the effect on throughput.\n+\n+.Lowering latency\n+\n+Producers scaled to produce a high rate of requests might cause queues in the Kafka cluster and increase latency.\n+\n+Use a buffer and add a small delay to reduce the number of requests to topics from producers that are not contributing a large number of messages.\n+You can set the delay in conjunction with a maximum batch size, so the delay only applies if the batch size is not reached earlier.\n+\n+NOTE: If the system fails, there is a risk of unsent data in the buffer being lost.\n+\n+----\n+# ...\n+linger.ms=0 <1>\n+batch.size=16384 <2>\n+buffer.memory=33554432 <3>\n+# ...\n+----\n+<1> The `linger` property adds a delay in milliseconds so that larger batches of messages are accumulated and sent in a request. The defaullt is `0'.`\n+<2> If a maximum `batch.size` in bytes is used, a request is sent when the maximum is reached, or messages have been queued for longer than `linger.ms` (whichever comes sooner).", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQxMDA0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466410040", "bodyText": "Well, it's not quite that simple, because the producer also uses piggy-backing. IOW it might send messages before the batch is full or the linger is expired if it's sending a Produce request to the relevant broker anyway. But there's no need to mention that detail here, I'm only telling you so you know. I think you're right though @ppatierno, using a linger.ms > 0 would mean it makes a bit more sense.", "author": "tombentley", "createdAt": "2020-08-06T13:25:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NzM4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUzMjQyMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466532421", "bodyText": "sorry @tombentley AFAIK piggy-backing could mean delaying when talking about packet transmission not anticipating as you are describing. So what do you mean by piggy-backing in this case?", "author": "ppatierno", "createdAt": "2020-08-06T16:22:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NzM4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU4NDA3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466584073", "bodyText": "We're sending some messages batches to a broker anyway, so we may as well add some partially full batch destined for the same broker. In a way it's not unrelated to the acknowledgement case you describe. In that case an ack is delayed so that we can ack two or more data frames with a single ack frame. TBH, I don't know how standardised my usage is here.", "author": "tombentley", "createdAt": "2020-08-06T17:49:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NzM4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYxNzU1OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466617558", "bodyText": "Thanks for sharing this! ... but I see two possible different behaviors.\n\nMore partitions belong to the same broker. One batch for a partition is full and it's ready to be sent but ... the producer sends even the batches for other partitions belonging to the same broker even if they are not totally filled. In this case, we are anticipating acks.\nMore partitions belong to the same broker. One batch for a partition is full and it's ready to be sent but ... producer waits for the other batches belonging to the other partitions (but still on the same broker) to be filled before sending all of them. In this case, we are delaying acks.\n\nWhat is the right one in the Kafka producer?", "author": "ppatierno", "createdAt": "2020-08-06T18:50:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NzM4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgyMDU1NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469820554", "bodyText": "I changed the example to linger.ms=100\nAnd we leave out the idea of piggy-backing here?", "author": "PaulRMellor", "createdAt": "2020-08-13T09:27:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NzM4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzI1Nzg5MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r477257891", "bodyText": "I would leave it out, anyway it's not still clear how piggy-backing works in the producer.", "author": "ppatierno", "createdAt": "2020-08-26T12:22:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE5NzM4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM5OTA2OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466399068", "bodyText": "The broker might be configured to compress messages differently or not at all (https://kafka.apache.org/documentation.html#compression.type)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n          \n          \n            \n            <5> (Optional) The codec for compressing messages, which are sent and may be stored in compressed format and then decompressed when reaching a consumer.", "author": "tombentley", "createdAt": "2020-08-06T13:09:11Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM5OTQxMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466399412", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n          \n          \n            \n            Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression could be prohibitive.", "author": "tombentley", "createdAt": "2020-08-06T13:09:43Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM5OTk4Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466399987", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n          \n          \n            \n            <1> Specifying `acks=all` forces a partition leader to replicate messages to a certain number of followers before", "author": "tombentley", "createdAt": "2020-08-06T13:10:36Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwMTY0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466401642", "bodyText": "I guess we should reword this...\nThe number of brokers which need to have appended the messages to their logs before the acknowledgement is sent to the producer is determined by the topic's `min.insync.replicas` configuration.\n\nI think that carries on more naturally from the text in the callout.", "author": "tombentley", "createdAt": "2020-08-06T13:13:12Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgzOTc2NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469839765", "bodyText": "Better", "author": "PaulRMellor", "createdAt": "2020-08-13T10:01:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwMTY0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwMzk5Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466403997", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Idempotence is useful for exactly once writes from a single partition.\n          \n          \n            \n            Idempotence is useful for exactly once writes to a single partition.", "author": "tombentley", "createdAt": "2020-08-06T13:16:47Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.\n+<3> Set to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If the performance cost is too great, and you are not using `acks=all`,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.\n+Otherwise, a situation is possible where _Message-A_ fails only to succeed after _Message-B_ was already written to the broker.\n+\n+.Ordered delivery without idempotency\n+----\n+# ...\n+enable.idempotence=false <1>\n+max.in.flight.requests.per.connection=1 <2>\n+retries=2147483647\n+# ...\n+----\n+<1> Set to `false`.\n+<2> Set the number of in-flight requests to exactly `1`.\n+\n+== Reliability guarantees\n+\n+Idempotence is useful for exactly once writes from a single partition.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQxOTA3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466419073", "bodyText": "I think if we're going to talk about buffer.memory and the possibility of send() blocking because the accumulator is full then we need to explain how it works in a bit more detail.\nAlso I don't think the NOTE is helpful, because you can't assume anything until you've received the acknowledgement. So we should add something in the durability section about that. It's certainly not something which is specific to low latency.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Producers scaled to produce a high rate of requests might cause queues in the Kafka cluster and increase latency.\n          \n          \n            \n            \n          \n          \n            \n            Use a buffer and add a small delay to reduce the number of requests to topics from producers that are not contributing a large number of messages.\n          \n          \n            \n            You can set the delay in conjunction with a maximum batch size, so the delay only applies if the batch size is not reached earlier.\n          \n          \n            \n            \n          \n          \n            \n            NOTE: If the system fails, there is a risk of unsent data in the buffer being lost.\n          \n          \n            \n            When your application calls `KafkaProducer.send()` the messages are:\n          \n          \n            \n            \n          \n          \n            \n            * processed by any interceptors\n          \n          \n            \n            * Serialized\n          \n          \n            \n            * Assigned to a partition\n          \n          \n            \n            * Compressed\n          \n          \n            \n            * Added to a batch of messages in a per-partition queue\n          \n          \n            \n            \n          \n          \n            \n            at which point the `send()` method returns. So the amount of time for which `send()` blocks is determined by:\n          \n          \n            \n            \n          \n          \n            \n            * The time spent in the interceptors, serializers and partitioner\n          \n          \n            \n            * The compression algorithm used\n          \n          \n            \n            * The time spent waiting for a buffer to use for compression.\n          \n          \n            \n            \n          \n          \n            \n            Batches in the queue will remain there until:\n          \n          \n            \n            \n          \n          \n            \n            * the batch is full (according to `batch.size`)\n          \n          \n            \n            * or at least `linger.ms` has passed\n          \n          \n            \n            * or the sender is about to send message batches for other partitions to the same broker, and it's possible to add this batch too.\n          \n          \n            \n            * or the producer is being flushed or closed", "author": "tombentley", "createdAt": "2020-08-06T13:39:27Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.\n+<3> Set to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If the performance cost is too great, and you are not using `acks=all`,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.\n+Otherwise, a situation is possible where _Message-A_ fails only to succeed after _Message-B_ was already written to the broker.\n+\n+.Ordered delivery without idempotency\n+----\n+# ...\n+enable.idempotence=false <1>\n+max.in.flight.requests.per.connection=1 <2>\n+retries=2147483647\n+# ...\n+----\n+<1> Set to `false`.\n+<2> Set the number of in-flight requests to exactly `1`.\n+\n+== Reliability guarantees\n+\n+Idempotence is useful for exactly once writes from a single partition.\n+Transactions, when used with idempotence, allow exactly once writes across multiple partitions.\n+\n+Transactions guarantee that messages using the same transactional ID are produced once,\n+and either _all_ are successfully written to the log or _none_ of them are.\n+\n+----\n+# ...\n+enable.idempotence=true\n+max.in.flight.requests.per.connection=5\n+acks=all\n+retries=2147483647\n+transactional.id=_UNIQUE-ID_ <1>\n+transaction.timeout.ms=900000 <2>\n+# ...\n+----\n+<1> Specify a unique transactional ID.\n+<2> Set the maximum allowed time for transactions in milliseconds before a timeout error is returned.\n+The default is `900000` or 15 minutes.\n+\n+The choice of `transactional.id` is important in order that the transational guarantee is maintained.\n+Each transactional id should be used for a unique set of topic partitions.\n+For example, this can be achieved using an external mapping of topic partition names to transactional ids,\n+or by computing the transactional id from the topic partition names using a function that avoids collisions.\n+\n+== Optimizing throughput and latency\n+\n+Usually, the requirement of a system is to satisfy a particular throughput target for a proportion of messages within a given latency.\n+For example, targeting 500,000 messages per second with 95% of messages being acknowledged within 2 seconds.\n+\n+It\u2019s likely that the messaging semantics (message ordering and durability) of your producer are defined by the requirements for your application.\n+For instance, it\u2019s possible that you don\u2019t have the option of using `acks=0` or `acks=1` without breaking some important property or guarantee provided by your application.\n+\n+Broker restarts have a significant impact on high percentile statistics.\n+For example, over a long period the 99th percentile latency is dominated by behavior around broker restarts.\n+This is worth considering when designing benchmarks or comparing performance numbers from benchmarking with performance numbers seen in production.\n+\n+Depending on your objective, Kafka offers a number of configuration parameters and techniques for tuning producer performance for throughput and latency.\n+\n+Message batching (`linger.ms` and `batch.size`)::\n+Message batching delays sending messages in the hope that more messages destined for the same broker will be sent,\n+allowing them to be batched into a single produce request.\n+Batching is a compromise between higher latency in return for higher throughput.\n+Time-based batching is configured using `linger.ms`, and size-based batching is configured using `batch.size`.\n+\n+Compression (`compression.type`)::\n+Message compression adds latency in the producer (CPU time spent compressing the messages),\n+but makes requests (and potentially disk writes) smaller, which can increase throughput.\n+Whether compression is worthwhile, and the best compression to use, will depend on the messages being sent.\n+Compression happens on the thread which calls `KafkaProducer.send()`,\n+so if the latency of this method matters for your application you should consider using more threads.\n+\n+Pipelining (`max.in.flight.requests.per.connection`)::\n+Pipelining means sending more requests before the response to a previous request has been received.\n+In general more pipelining means better throughput, up to a threshold at which other effects,\n+such as worse batching, start to counteract the effect on throughput.\n+\n+.Lowering latency\n+\n+Producers scaled to produce a high rate of requests might cause queues in the Kafka cluster and increase latency.\n+\n+Use a buffer and add a small delay to reduce the number of requests to topics from producers that are not contributing a large number of messages.\n+You can set the delay in conjunction with a maximum batch size, so the delay only applies if the batch size is not reached earlier.\n+\n+NOTE: If the system fails, there is a risk of unsent data in the buffer being lost.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUzNDM0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466534340", "bodyText": "While I think this description could be useful to people who don't know and would like to know how a producer works internally, I am also thinking that we are providing too many details about Kafka in the Strimzi documentation that is more about deploying/handling Kafka not maybe ... using it?", "author": "ppatierno", "createdAt": "2020-08-06T16:26:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQxOTA3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg1Mjc3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469852773", "bodyText": "I've added but it seems a bit disconnected with the config that comes after. I've joined by adding Look at the configuration for batching and buffering to mitigate the impact of send() blocking on latency. after this new section for now", "author": "PaulRMellor", "createdAt": "2020-08-13T10:25:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQxOTA3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg1NzkzNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469857934", "bodyText": "I've moved the note under durability as a placeholder", "author": "PaulRMellor", "createdAt": "2020-08-13T10:35:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQxOTA3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQyMjU0Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466422547", "bodyText": "This isn't really correct. If you call send() with some topic/partition which the producer don't already know about then it will make a metadata request immedaitely to find out. It's true that that adds to the send latency, but in general lowering metadata.max.age.ms won't help because that's only used to refresh the cache when it's not been updated for a while. IOW, it won't help with sending messages to a new topic, it will help with discovering that there's a new partition of an existing topic which we were already sending to (and thus changing how messages get partitioned). I think we should drop metadata.max.age.ms from this section.", "author": "tombentley", "createdAt": "2020-08-06T13:44:33Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.\n+<3> Set to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If the performance cost is too great, and you are not using `acks=all`,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.\n+Otherwise, a situation is possible where _Message-A_ fails only to succeed after _Message-B_ was already written to the broker.\n+\n+.Ordered delivery without idempotency\n+----\n+# ...\n+enable.idempotence=false <1>\n+max.in.flight.requests.per.connection=1 <2>\n+retries=2147483647\n+# ...\n+----\n+<1> Set to `false`.\n+<2> Set the number of in-flight requests to exactly `1`.\n+\n+== Reliability guarantees\n+\n+Idempotence is useful for exactly once writes from a single partition.\n+Transactions, when used with idempotence, allow exactly once writes across multiple partitions.\n+\n+Transactions guarantee that messages using the same transactional ID are produced once,\n+and either _all_ are successfully written to the log or _none_ of them are.\n+\n+----\n+# ...\n+enable.idempotence=true\n+max.in.flight.requests.per.connection=5\n+acks=all\n+retries=2147483647\n+transactional.id=_UNIQUE-ID_ <1>\n+transaction.timeout.ms=900000 <2>\n+# ...\n+----\n+<1> Specify a unique transactional ID.\n+<2> Set the maximum allowed time for transactions in milliseconds before a timeout error is returned.\n+The default is `900000` or 15 minutes.\n+\n+The choice of `transactional.id` is important in order that the transational guarantee is maintained.\n+Each transactional id should be used for a unique set of topic partitions.\n+For example, this can be achieved using an external mapping of topic partition names to transactional ids,\n+or by computing the transactional id from the topic partition names using a function that avoids collisions.\n+\n+== Optimizing throughput and latency\n+\n+Usually, the requirement of a system is to satisfy a particular throughput target for a proportion of messages within a given latency.\n+For example, targeting 500,000 messages per second with 95% of messages being acknowledged within 2 seconds.\n+\n+It\u2019s likely that the messaging semantics (message ordering and durability) of your producer are defined by the requirements for your application.\n+For instance, it\u2019s possible that you don\u2019t have the option of using `acks=0` or `acks=1` without breaking some important property or guarantee provided by your application.\n+\n+Broker restarts have a significant impact on high percentile statistics.\n+For example, over a long period the 99th percentile latency is dominated by behavior around broker restarts.\n+This is worth considering when designing benchmarks or comparing performance numbers from benchmarking with performance numbers seen in production.\n+\n+Depending on your objective, Kafka offers a number of configuration parameters and techniques for tuning producer performance for throughput and latency.\n+\n+Message batching (`linger.ms` and `batch.size`)::\n+Message batching delays sending messages in the hope that more messages destined for the same broker will be sent,\n+allowing them to be batched into a single produce request.\n+Batching is a compromise between higher latency in return for higher throughput.\n+Time-based batching is configured using `linger.ms`, and size-based batching is configured using `batch.size`.\n+\n+Compression (`compression.type`)::\n+Message compression adds latency in the producer (CPU time spent compressing the messages),\n+but makes requests (and potentially disk writes) smaller, which can increase throughput.\n+Whether compression is worthwhile, and the best compression to use, will depend on the messages being sent.\n+Compression happens on the thread which calls `KafkaProducer.send()`,\n+so if the latency of this method matters for your application you should consider using more threads.\n+\n+Pipelining (`max.in.flight.requests.per.connection`)::\n+Pipelining means sending more requests before the response to a previous request has been received.\n+In general more pipelining means better throughput, up to a threshold at which other effects,\n+such as worse batching, start to counteract the effect on throughput.\n+\n+.Lowering latency\n+\n+Producers scaled to produce a high rate of requests might cause queues in the Kafka cluster and increase latency.\n+\n+Use a buffer and add a small delay to reduce the number of requests to topics from producers that are not contributing a large number of messages.\n+You can set the delay in conjunction with a maximum batch size, so the delay only applies if the batch size is not reached earlier.\n+\n+NOTE: If the system fails, there is a risk of unsent data in the buffer being lost.\n+\n+----\n+# ...\n+linger.ms=0 <1>\n+batch.size=16384 <2>\n+buffer.memory=33554432 <3>\n+# ...\n+----\n+<1> The `linger` property adds a delay in milliseconds so that larger batches of messages are accumulated and sent in a request. The defaullt is `0'.`\n+<2> If a maximum `batch.size` in bytes is used, a request is sent when the maximum is reached, or messages have been queued for longer than `linger.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+<3> The buffer size must be at least as big as the batch size, and be able to accommodate buffering, compression and in-flight requests.\n+\n+.Increasing throughput\n+\n+Improve throughput of your message requests by adjusting the maximum time to wait before a message is delivered and completes a send request.\n+If you have a large number of topics to write to, you can also lower the time it takes to pick up topic metadata changes and reduce the time to discover new brokers or partitions.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg1NjM2NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469856364", "bodyText": "Removed from the intro and example", "author": "PaulRMellor", "createdAt": "2020-08-13T10:32:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQyMjU0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQyMzI4NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r466423284", "bodyText": "Usually called \"semantic partitioning\", and worthy of its own documentation.", "author": "tombentley", "createdAt": "2020-08-06T13:45:34Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,203 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a minimum producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Minimum producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this minimal configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the message keys to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform message values to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression is prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to all followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+In addition to using `acks=all`, you must configure the topics receiving the messages to have more than one in-sync replica.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true`.\n+<2> Specify the number of allowed in-flight requests to a maximum of 5.\n+<3> Set to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If the performance cost is too great, and you are not using `acks=all`,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.\n+Otherwise, a situation is possible where _Message-A_ fails only to succeed after _Message-B_ was already written to the broker.\n+\n+.Ordered delivery without idempotency\n+----\n+# ...\n+enable.idempotence=false <1>\n+max.in.flight.requests.per.connection=1 <2>\n+retries=2147483647\n+# ...\n+----\n+<1> Set to `false`.\n+<2> Set the number of in-flight requests to exactly `1`.\n+\n+== Reliability guarantees\n+\n+Idempotence is useful for exactly once writes from a single partition.\n+Transactions, when used with idempotence, allow exactly once writes across multiple partitions.\n+\n+Transactions guarantee that messages using the same transactional ID are produced once,\n+and either _all_ are successfully written to the log or _none_ of them are.\n+\n+----\n+# ...\n+enable.idempotence=true\n+max.in.flight.requests.per.connection=5\n+acks=all\n+retries=2147483647\n+transactional.id=_UNIQUE-ID_ <1>\n+transaction.timeout.ms=900000 <2>\n+# ...\n+----\n+<1> Specify a unique transactional ID.\n+<2> Set the maximum allowed time for transactions in milliseconds before a timeout error is returned.\n+The default is `900000` or 15 minutes.\n+\n+The choice of `transactional.id` is important in order that the transational guarantee is maintained.\n+Each transactional id should be used for a unique set of topic partitions.\n+For example, this can be achieved using an external mapping of topic partition names to transactional ids,\n+or by computing the transactional id from the topic partition names using a function that avoids collisions.\n+\n+== Optimizing throughput and latency\n+\n+Usually, the requirement of a system is to satisfy a particular throughput target for a proportion of messages within a given latency.\n+For example, targeting 500,000 messages per second with 95% of messages being acknowledged within 2 seconds.\n+\n+It\u2019s likely that the messaging semantics (message ordering and durability) of your producer are defined by the requirements for your application.\n+For instance, it\u2019s possible that you don\u2019t have the option of using `acks=0` or `acks=1` without breaking some important property or guarantee provided by your application.\n+\n+Broker restarts have a significant impact on high percentile statistics.\n+For example, over a long period the 99th percentile latency is dominated by behavior around broker restarts.\n+This is worth considering when designing benchmarks or comparing performance numbers from benchmarking with performance numbers seen in production.\n+\n+Depending on your objective, Kafka offers a number of configuration parameters and techniques for tuning producer performance for throughput and latency.\n+\n+Message batching (`linger.ms` and `batch.size`)::\n+Message batching delays sending messages in the hope that more messages destined for the same broker will be sent,\n+allowing them to be batched into a single produce request.\n+Batching is a compromise between higher latency in return for higher throughput.\n+Time-based batching is configured using `linger.ms`, and size-based batching is configured using `batch.size`.\n+\n+Compression (`compression.type`)::\n+Message compression adds latency in the producer (CPU time spent compressing the messages),\n+but makes requests (and potentially disk writes) smaller, which can increase throughput.\n+Whether compression is worthwhile, and the best compression to use, will depend on the messages being sent.\n+Compression happens on the thread which calls `KafkaProducer.send()`,\n+so if the latency of this method matters for your application you should consider using more threads.\n+\n+Pipelining (`max.in.flight.requests.per.connection`)::\n+Pipelining means sending more requests before the response to a previous request has been received.\n+In general more pipelining means better throughput, up to a threshold at which other effects,\n+such as worse batching, start to counteract the effect on throughput.\n+\n+.Lowering latency\n+\n+Producers scaled to produce a high rate of requests might cause queues in the Kafka cluster and increase latency.\n+\n+Use a buffer and add a small delay to reduce the number of requests to topics from producers that are not contributing a large number of messages.\n+You can set the delay in conjunction with a maximum batch size, so the delay only applies if the batch size is not reached earlier.\n+\n+NOTE: If the system fails, there is a risk of unsent data in the buffer being lost.\n+\n+----\n+# ...\n+linger.ms=0 <1>\n+batch.size=16384 <2>\n+buffer.memory=33554432 <3>\n+# ...\n+----\n+<1> The `linger` property adds a delay in milliseconds so that larger batches of messages are accumulated and sent in a request. The defaullt is `0'.`\n+<2> If a maximum `batch.size` in bytes is used, a request is sent when the maximum is reached, or messages have been queued for longer than `linger.ms` (whichever comes sooner).\n+Adding the delay allows batches to accumulate messages up to the batch size.\n+<3> The buffer size must be at least as big as the batch size, and be able to accommodate buffering, compression and in-flight requests.\n+\n+.Increasing throughput\n+\n+Improve throughput of your message requests by adjusting the maximum time to wait before a message is delivered and completes a send request.\n+If you have a large number of topics to write to, you can also lower the time it takes to pick up topic metadata changes and reduce the time to discover new brokers or partitions.\n+\n+You can also direct messages to a specified partition by writing a custom partitioner to replace the default.", "originalCommit": "e3bed0ace8562c56898b2a5714971040a9b22e35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg1NjY0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r469856644", "bodyText": "Another time :-)", "author": "PaulRMellor", "createdAt": "2020-08-13T10:32:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQyMzI4NA=="}], "type": "inlineReview"}, {"oid": "ebd4e2dbfe89792026871fd03fb82f9c37954565", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ebd4e2dbfe89792026871fd03fb82f9c37954565", "message": "review edits TB, PP\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-08-13T10:38:49Z", "type": "commit"}, {"oid": "426990021c62bac03f6236d0b0195248e823f20d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/426990021c62bac03f6236d0b0195248e823f20d", "message": "build fix\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-08-25T10:02:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTk3MTQ4NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r481971484", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            and either _all_ are successfully written to the log or _none_ of them are.\n          \n          \n            \n            and either _all_ are successfully written to the respective logs or _none_ of them are.", "author": "tombentley", "createdAt": "2020-09-02T10:39:10Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,219 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a basic producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Basic producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this basic configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the key of each message to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform the value of each message to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and might be stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression could be prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to a certain number of followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+The number of brokers which need to have appended the messages to their logs before the acknowledgment is sent to the producer is determined by the topic's `min.insync.replicas` configuration.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+NOTE: If the system fails, there is a risk of unsent data in the buffer being lost.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true` to enable the idempotent producer.\n+<2> With idempotent delivery the number of in-flight requests may be greater than 1 while still providing the message ordering guarantee. The default is 5 in-flight requests.\n+<3> Set `acks` to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If you are not using `acks=all` and idempotency because of the performance cost,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.\n+Otherwise, a situation is possible where _Message-A_ fails only to succeed after _Message-B_ was already written to the broker.\n+\n+.Ordered delivery without idempotency\n+----\n+# ...\n+enable.idempotence=false <1>\n+max.in.flight.requests.per.connection=1 <2>\n+retries=2147483647\n+# ...\n+----\n+<1> Set to `false` to disable the idempotent producer.\n+<2> Set the number of in-flight requests to exactly `1`.\n+\n+== Reliability guarantees\n+\n+Idempotence is useful for exactly once writes to a single partition.\n+Transactions, when used with idempotence, allow exactly once writes across multiple partitions.\n+\n+Transactions guarantee that messages using the same transactional ID are produced once,\n+and either _all_ are successfully written to the log or _none_ of them are.", "originalCommit": "426990021c62bac03f6236d0b0195248e823f20d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTk3MzYwNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3457#discussion_r481973604", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <1> The `linger` property adds a delay in milliseconds so that larger batches of messages are accumulated and sent in a request. The defaullt is `0'.`\n          \n          \n            \n            <1> The `linger` property adds a delay in milliseconds so that larger batches of messages are accumulated and sent in a request. The default is `0'.`", "author": "tombentley", "createdAt": "2020-09-02T10:42:51Z", "path": "documentation/modules/managing/con-producer-config-properties.adoc", "diffHunk": "@@ -0,0 +1,219 @@\n+// This module is included in the following files:\n+//\n+// assembly-client-config.adoc\n+\n+[id='con-producer-config-properties-{context}']\n+= Kafka producer configuration tuning\n+\n+Use a basic producer configuration with optional properties that are tailored to specific uses cases.\n+\n+Adjusting your configuration to maximize throughput might increase latency or vice versa.\n+You will need to experiment and tune your producer configuration to get the balance you need.\n+\n+== Basic producer configuration\n+\n+Connection and serializer properties are required for every producer.\n+Generally, it is good practice to add a client id for tracking,\n+and use compression on the producer to reduce batch sizes in requests.\n+\n+In this basic configuration:\n+\n+* The order of messages in a partition is not guaranteed\n+* The acknowledgment of messages reaching the broker does not guarantee durability\n+\n+[source,shell,subs=\"+quotes,attributes\"]\n+----\n+# ...\n+bootstrap.servers=localhost:9092 <1>\n+key.serializer=org.apache.kafka.common.serialization.StringSerializer <2>\n+value.serializer=org.apache.kafka.common.serialization.StringSerializer <3>\n+client.id=my-client <4>\n+compression.type=gzip <5>\n+# ...\n+----\n+<1> (Required) Tells the producer to connect to a Kafka cluster using a _host:port_ bootstrap server address for a Kafka broker.\n+The producer uses the address to discover and connect to all brokers in the cluster.\n+Use a comma-separated list to specify two or three addresses in case a server is down, but it\u2019s not necessary to provide a list of all the brokers in the cluster.\n+<2> (Required) Serializer to transform the key of each message to bytes prior to them being sent to a broker.\n+<3> (Required) Serializer to transform the value of each message to bytes prior to them being sent to a broker.\n+<4> (Optional) The logical name for the client, which is used in logs and metrics to identify the source of a request.\n+<5> (Optional) The codec for compressing messages, which are sent and might be stored in compressed format and then decompressed when reaching a consumer.\n+Compression is useful for improving throughput and reducing the load on storage, but might not be suitable for low latency applications where the cost of compression or decompression could be prohibitive.\n+\n+== Data durability\n+\n+You can apply greater data durability, to minimize the likelihood that messages are lost, using message delivery acknowledgments.\n+\n+----\n+# ...\n+acks=all <1>\n+# ...\n+----\n+\n+<1> Specifying `acks=all` forces a partition leader to replicate messages to a certain number of followers before\n+acknowledging that the message request was successfully received.\n+Because of the additional checks, `acks=all` increases the latency between the producer sending a message and receiving acknowledgment.\n+\n+The number of brokers which need to have appended the messages to their logs before the acknowledgment is sent to the producer is determined by the topic's `min.insync.replicas` configuration.\n+A typical starting point is to have a topic replication factor of 3, with two in-sync replicas on other brokers.\n+In this configuration, the producer can continue unaffected if a single broker is unavailable.\n+If a second broker becomes unavailable, the producer won\u2019t receive acknowledgments and won\u2019t be able to produce more messages.\n+\n+.Topic configuration to support `acks=all`\n+----\n+# ...\n+min.insync.replicas=2 <1>\n+# ...\n+----\n+<1> Use `2` in-sync replicas. The default is `1`.\n+\n+NOTE: If the system fails, there is a risk of unsent data in the buffer being lost.\n+\n+== Ordered delivery\n+\n+Idempotent producers avoid duplicates as messages are delivered exactly once.\n+IDs and sequence numbers are assigned to messages to ensure the order of delivery, even in the event of failure.\n+If you are using `acks=all` for data consistency, enabling idempotency makes sense for ordered delivery.\n+\n+.Ordered delivery with idempotency\n+----\n+# ...\n+enable.idempotence=true <1>\n+max.in.flight.requests.per.connection=5 <2>\n+acks=all <3>\n+retries=2147483647 <4>\n+# ...\n+----\n+<1> Set to `true` to enable the idempotent producer.\n+<2> With idempotent delivery the number of in-flight requests may be greater than 1 while still providing the message ordering guarantee. The default is 5 in-flight requests.\n+<3> Set `acks` to `all`.\n+<4> Set the number of attempts to resend a failed message request.\n+\n+If you are not using `acks=all` and idempotency because of the performance cost,\n+set the number of in-flight (unacknowledged) requests to 1 to preserve ordering.\n+Otherwise, a situation is possible where _Message-A_ fails only to succeed after _Message-B_ was already written to the broker.\n+\n+.Ordered delivery without idempotency\n+----\n+# ...\n+enable.idempotence=false <1>\n+max.in.flight.requests.per.connection=1 <2>\n+retries=2147483647\n+# ...\n+----\n+<1> Set to `false` to disable the idempotent producer.\n+<2> Set the number of in-flight requests to exactly `1`.\n+\n+== Reliability guarantees\n+\n+Idempotence is useful for exactly once writes to a single partition.\n+Transactions, when used with idempotence, allow exactly once writes across multiple partitions.\n+\n+Transactions guarantee that messages using the same transactional ID are produced once,\n+and either _all_ are successfully written to the log or _none_ of them are.\n+\n+----\n+# ...\n+enable.idempotence=true\n+max.in.flight.requests.per.connection=5\n+acks=all\n+retries=2147483647\n+transactional.id=_UNIQUE-ID_ <1>\n+transaction.timeout.ms=900000 <2>\n+# ...\n+----\n+<1> Specify a unique transactional ID.\n+<2> Set the maximum allowed time for transactions in milliseconds before a timeout error is returned.\n+The default is `900000` or 15 minutes.\n+\n+The choice of `transactional.id` is important in order that the transational guarantee is maintained.\n+Each transactional id should be used for a unique set of topic partitions.\n+For example, this can be achieved using an external mapping of topic partition names to transactional ids,\n+or by computing the transactional id from the topic partition names using a function that avoids collisions.\n+\n+== Optimizing throughput and latency\n+\n+Usually, the requirement of a system is to satisfy a particular throughput target for a proportion of messages within a given latency.\n+For example, targeting 500,000 messages per second with 95% of messages being acknowledged within 2 seconds.\n+\n+It\u2019s likely that the messaging semantics (message ordering and durability) of your producer are defined by the requirements for your application.\n+For instance, it\u2019s possible that you don\u2019t have the option of using `acks=0` or `acks=1` without breaking some important property or guarantee provided by your application.\n+\n+Broker restarts have a significant impact on high percentile statistics.\n+For example, over a long period the 99th percentile latency is dominated by behavior around broker restarts.\n+This is worth considering when designing benchmarks or comparing performance numbers from benchmarking with performance numbers seen in production.\n+\n+Depending on your objective, Kafka offers a number of configuration parameters and techniques for tuning producer performance for throughput and latency.\n+\n+Message batching (`linger.ms` and `batch.size`)::\n+Message batching delays sending messages in the hope that more messages destined for the same broker will be sent,\n+allowing them to be batched into a single produce request.\n+Batching is a compromise between higher latency in return for higher throughput.\n+Time-based batching is configured using `linger.ms`, and size-based batching is configured using `batch.size`.\n+\n+Compression (`compression.type`)::\n+Message compression adds latency in the producer (CPU time spent compressing the messages),\n+but makes requests (and potentially disk writes) smaller, which can increase throughput.\n+Whether compression is worthwhile, and the best compression to use, will depend on the messages being sent.\n+Compression happens on the thread which calls `KafkaProducer.send()`,\n+so if the latency of this method matters for your application you should consider using more threads.\n+\n+Pipelining (`max.in.flight.requests.per.connection`)::\n+Pipelining means sending more requests before the response to a previous request has been received.\n+In general more pipelining means better throughput, up to a threshold at which other effects,\n+such as worse batching, start to counteract the effect on throughput.\n+\n+.Lowering latency\n+\n+When your application calls `KafkaProducer.send()` the messages are:\n+\n+* Processed by any interceptors\n+* Serialized\n+* Assigned to a partition\n+* Compressed\n+* Added to a batch of messages in a per-partition queue\n+\n+At which point the `send()` method returns.\n+So the time `send()` is blocked is determined by:\n+\n+* The time spent in the interceptors, serializers and partitioner\n+* The compression algorithm used\n+* The time spent waiting for a buffer to use for compression\n+\n+Batches will remain in the queue until one of the following occurs:\n+\n+* The batch is full (according to `batch.size`)\n+* The delay introduced by `linger.ms` has passed\n+* The sender is about to send message batches for other partitions to the same broker, and it is possible to add this batch too\n+* The producer is being flushed or closed\n+\n+Look at the configuration for batching and buffering to mitigate the impact of `send()` blocking on latency.\n+\n+----\n+# ...\n+linger.ms=100 <1>\n+batch.size=16384 <2>\n+buffer.memory=33554432 <3>\n+# ...\n+----\n+<1> The `linger` property adds a delay in milliseconds so that larger batches of messages are accumulated and sent in a request. The defaullt is `0'.`", "originalCommit": "426990021c62bac03f6236d0b0195248e823f20d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1f1e5efbdaddc8a85230fe5385166e26de31d47d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1f1e5efbdaddc8a85230fe5385166e26de31d47d", "message": "review edits TB\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-09-03T10:43:44Z", "type": "commit"}, {"oid": "f48e35b073d2b2b1ecb9ca699764cec222a8b1e4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f48e35b073d2b2b1ecb9ca699764cec222a8b1e4", "message": "minor edit\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-09-03T10:54:46Z", "type": "commit"}, {"oid": "738569fa73d35eaeee3869d9abf5f62dd7097f0f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/738569fa73d35eaeee3869d9abf5f62dd7097f0f", "message": "merge conflict fix\n\nSigned-off-by: prmellor <pmellor@redhat.com>", "committedDate": "2020-09-03T12:54:38Z", "type": "commit"}]}