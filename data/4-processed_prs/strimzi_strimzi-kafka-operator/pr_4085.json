{"pr_number": 4085, "pr_title": "[systemtest] Tests for NetworkPolicy enhancements", "pr_createdAt": "2020-12-10T13:19:34Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085", "timeline": [{"oid": "31c1332c767545562a711daae44938dd617e52b1", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/31c1332c767545562a711daae44938dd617e52b1", "message": "add tests for np enhancements, create ST for NPs etc.\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-12-10T13:12:40Z", "type": "commit"}, {"oid": "74ccf5ef8950e77eed6543f9eb49feb468db6a60", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/74ccf5ef8950e77eed6543f9eb49feb468db6a60", "message": "Jakub's comment\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-12-10T19:06:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MTQ3Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540441476", "bodyText": "Correct me if I am wrong, but you should ut there an assertion, that the install type is bundle. Same for the second test. Otherwise, it will be executed in other install types as well.", "author": "Frawless", "createdAt": "2020-12-10T19:33:25Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java", "diffHunk": "@@ -0,0 +1,334 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.fabric8.kubernetes.api.model.EnvVar;\n+import io.fabric8.kubernetes.api.model.EnvVarBuilder;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;\n+import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.resources.operator.BundleResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import io.strimzi.systemtest.utils.specific.MetricsUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(NETWORKPOLICIES_SUPPORTED)\n+public class NetworkPoliciesST extends AbstractST {\n+    public static final String NAMESPACE = \"np-cluster-test\";\n+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithPlainListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelForPlain = new HashMap<>();\n+        matchLabelForPlain.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                            .withPort(9092)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(false)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelForPlain)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+                .withNewKafkaExporter()\n+                .endKafkaExporter()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesPlain(),\n+            internalKafkaClient.receiveMessagesPlain()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(false, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is not able to exchange messages\", deniedKafkaClientsPodName);\n+        assertThrows(AssertionError.class, () ->  {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesPlain(),\n+                newInternalKafkaClient.receiveMessagesPlain()\n+            );\n+        });\n+\n+        LOGGER.info(\"Check metrics exported by Kafka Exporter\");\n+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(CLUSTER_NAME);\n+        assertThat(\"Kafka Exporter metrics should be non-empty\", kafkaExporterMetricsData.size() > 0);\n+        for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {\n+            assertThat(\"Value from collected metric should be non-empty\", !entry.getValue().isEmpty());\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_consumergroup_current_offset\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic0 + \"\\\"} 1\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic1 + \"\\\"} 1\"));\n+        }\n+    }\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithTlsListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelsForTls = new HashMap<>();\n+        matchLabelsForTls.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+                            .withPort(9093)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(true)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelsForTls)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaClientsResource.deployKafkaClients(true, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesTls(),\n+            internalKafkaClient.receiveMessagesTls()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(true, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .withConsumerGroupName(ClientUtils.generateRandomConsumerGroup())\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is  not able to exchange messages\", deniedKafkaClientsPodName);\n+\n+        assertThrows(AssertionError.class, () -> {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesTls(),\n+                newInternalKafkaClient.receiveMessagesTls()\n+            );\n+        });\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInSameNamespaceAsOperand() {", "originalCommit": "74ccf5ef8950e77eed6543f9eb49feb468db6a60", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0ODYwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540448608", "bodyText": "The whole ST is \"tagged\" with NETWORKPOLICIES_SUPPORTED and these tests are not run for Olm and Helm. But maybe it will be better to add some other check.\nOr ... @scholzj do we want to run these tests for Helm and OLM too?", "author": "im-konge", "createdAt": "2020-12-10T19:45:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MTQ3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ2MzI5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540463293", "bodyText": "But you should add this assumption as well because CO will be installed via yaml bundle always.", "author": "Frawless", "createdAt": "2020-12-10T20:09:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MTQ3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MjA3Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540442072", "bodyText": "Just a question: shouldn't we check some specific value in NP? Just asking.", "author": "Frawless", "createdAt": "2020-12-10T19:34:22Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java", "diffHunk": "@@ -0,0 +1,334 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.fabric8.kubernetes.api.model.EnvVar;\n+import io.fabric8.kubernetes.api.model.EnvVarBuilder;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;\n+import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.resources.operator.BundleResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import io.strimzi.systemtest.utils.specific.MetricsUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(NETWORKPOLICIES_SUPPORTED)\n+public class NetworkPoliciesST extends AbstractST {\n+    public static final String NAMESPACE = \"np-cluster-test\";\n+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithPlainListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelForPlain = new HashMap<>();\n+        matchLabelForPlain.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                            .withPort(9092)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(false)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelForPlain)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+                .withNewKafkaExporter()\n+                .endKafkaExporter()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesPlain(),\n+            internalKafkaClient.receiveMessagesPlain()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(false, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is not able to exchange messages\", deniedKafkaClientsPodName);\n+        assertThrows(AssertionError.class, () ->  {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesPlain(),\n+                newInternalKafkaClient.receiveMessagesPlain()\n+            );\n+        });\n+\n+        LOGGER.info(\"Check metrics exported by Kafka Exporter\");\n+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(CLUSTER_NAME);\n+        assertThat(\"Kafka Exporter metrics should be non-empty\", kafkaExporterMetricsData.size() > 0);\n+        for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {\n+            assertThat(\"Value from collected metric should be non-empty\", !entry.getValue().isEmpty());\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_consumergroup_current_offset\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic0 + \"\\\"} 1\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic1 + \"\\\"} 1\"));\n+        }\n+    }\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithTlsListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelsForTls = new HashMap<>();\n+        matchLabelsForTls.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+                            .withPort(9093)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(true)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelsForTls)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaClientsResource.deployKafkaClients(true, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesTls(),\n+            internalKafkaClient.receiveMessagesTls()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(true, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .withConsumerGroupName(ClientUtils.generateRandomConsumerGroup())\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is  not able to exchange messages\", deniedKafkaClientsPodName);\n+\n+        assertThrows(AssertionError.class, () -> {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesTls(),\n+                newInternalKafkaClient.receiveMessagesTls()\n+            );\n+        });\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInSameNamespaceAsOperand() {\n+        EnvVar operatorNamespaceEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE\")\n+            .withValue(NAMESPACE)\n+            .build();\n+\n+        prepareEnvForOperator(NAMESPACE);\n+        applyRoleBindings(NAMESPACE);\n+        // 060-Deployment\n+        BundleResource.clusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT)\n+            .editOrNewSpec()\n+                .editOrNewTemplate()\n+                    .editOrNewSpec()\n+                        .editContainer(0)\n+                            .addToEnv(operatorNamespaceEnv)\n+                        .endContainer()\n+                    .endSpec()\n+                .endTemplate()\n+            .endSpec()\n+            .done();\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3).done();\n+\n+        checkNetworkPoliciesInNamespace(NAMESPACE);\n+\n+        changeKafkaConfigurationAndCheckObservedGeneration(NAMESPACE);\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInDifferentNamespaceThanOperand() {\n+        String secondNamespace = \"second-\" + NAMESPACE;\n+\n+        Map<String, String> labels = new HashMap<>();\n+        labels.put(\"my-label\", \"my-value\");\n+\n+        EnvVar operatorLabelsEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE_LABELS\")\n+            .withValue(labels.toString().replaceAll(\"\\\\{|}\", \"\"))\n+            .build();\n+\n+        cluster.createNamespace(secondNamespace);\n+\n+        prepareEnvForOperator(NAMESPACE, Arrays.asList(NAMESPACE, secondNamespace));\n+\n+        // Apply role bindings in CO namespace\n+        applyRoleBindings(NAMESPACE);\n+\n+        // Create ClusterRoleBindings that grant cluster-wide access to all OpenShift projects\n+        List<ClusterRoleBinding> clusterRoleBindingList = KubernetesResource.clusterRoleBindingsForAllNamespaces(NAMESPACE);\n+        clusterRoleBindingList.forEach(clusterRoleBinding ->\n+            KubernetesResource.clusterRoleBinding(clusterRoleBinding, NAMESPACE));\n+        // 060-Deployment\n+        BundleResource.clusterOperator(\"*\", Constants.CO_OPERATION_TIMEOUT_DEFAULT)\n+            .editOrNewSpec()\n+                .editOrNewTemplate()\n+                    .editOrNewSpec()\n+                        .editContainer(0)\n+                            .addToEnv(operatorLabelsEnv)\n+                        .endContainer()\n+                    .endSpec()\n+                .endTemplate()\n+            .endSpec()\n+            .done();\n+\n+        kubeClient().getClient().namespaces().withName(NAMESPACE).edit()\n+            .editMetadata()\n+                .addToLabels(labels)\n+            .endMetadata()\n+            .done();\n+\n+        cluster.setNamespace(secondNamespace);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editMetadata()\n+                .addToLabels(labels)\n+            .endMetadata()\n+            .done();\n+\n+        checkNetworkPoliciesInNamespace(secondNamespace);\n+\n+        changeKafkaConfigurationAndCheckObservedGeneration(secondNamespace);\n+    }\n+\n+    void checkNetworkPoliciesInNamespace(String namespace) {\n+        List<NetworkPolicy> networkPolicyList = new ArrayList<>(kubeClient().getClient().network().networkPolicies().inNamespace(namespace).list().getItems());\n+\n+        String networkPolicyPrefix = CLUSTER_NAME + \"-network-policy\";\n+\n+        assertNotNull(networkPolicyList.stream().filter(networkPolicy ->  networkPolicy.getMetadata().getName().contains(networkPolicyPrefix + \"-kafka\")).findFirst());\n+        assertNotNull(networkPolicyList.stream().filter(networkPolicy ->  networkPolicy.getMetadata().getName().contains(networkPolicyPrefix + \"-zookeeper\")).findFirst());", "originalCommit": "74ccf5ef8950e77eed6543f9eb49feb468db6a60", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0NzU1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540447551", "bodyText": "Maybe I'm wrong but I don't think that we need to check some values in NP.. because you only need to know that NP for Kafka and Zookeeper are created, the values inside are tested in some UT maybe..", "author": "im-konge", "createdAt": "2020-12-10T19:43:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MjA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MzEyNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540443125", "bodyText": "Why this check is needed", "author": "Frawless", "createdAt": "2020-12-10T19:36:11Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java", "diffHunk": "@@ -0,0 +1,334 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.fabric8.kubernetes.api.model.EnvVar;\n+import io.fabric8.kubernetes.api.model.EnvVarBuilder;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;\n+import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.resources.operator.BundleResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import io.strimzi.systemtest.utils.specific.MetricsUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(NETWORKPOLICIES_SUPPORTED)\n+public class NetworkPoliciesST extends AbstractST {\n+    public static final String NAMESPACE = \"np-cluster-test\";\n+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithPlainListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelForPlain = new HashMap<>();\n+        matchLabelForPlain.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                            .withPort(9092)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(false)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelForPlain)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+                .withNewKafkaExporter()\n+                .endKafkaExporter()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesPlain(),\n+            internalKafkaClient.receiveMessagesPlain()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(false, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is not able to exchange messages\", deniedKafkaClientsPodName);\n+        assertThrows(AssertionError.class, () ->  {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesPlain(),\n+                newInternalKafkaClient.receiveMessagesPlain()\n+            );\n+        });\n+\n+        LOGGER.info(\"Check metrics exported by Kafka Exporter\");\n+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(CLUSTER_NAME);\n+        assertThat(\"Kafka Exporter metrics should be non-empty\", kafkaExporterMetricsData.size() > 0);\n+        for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {\n+            assertThat(\"Value from collected metric should be non-empty\", !entry.getValue().isEmpty());\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_consumergroup_current_offset\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic0 + \"\\\"} 1\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic1 + \"\\\"} 1\"));\n+        }\n+    }\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithTlsListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelsForTls = new HashMap<>();\n+        matchLabelsForTls.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+                            .withPort(9093)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(true)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelsForTls)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaClientsResource.deployKafkaClients(true, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesTls(),\n+            internalKafkaClient.receiveMessagesTls()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(true, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .withConsumerGroupName(ClientUtils.generateRandomConsumerGroup())\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is  not able to exchange messages\", deniedKafkaClientsPodName);\n+\n+        assertThrows(AssertionError.class, () -> {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesTls(),\n+                newInternalKafkaClient.receiveMessagesTls()\n+            );\n+        });\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInSameNamespaceAsOperand() {\n+        EnvVar operatorNamespaceEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE\")\n+            .withValue(NAMESPACE)\n+            .build();\n+\n+        prepareEnvForOperator(NAMESPACE);\n+        applyRoleBindings(NAMESPACE);\n+        // 060-Deployment\n+        BundleResource.clusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT)\n+            .editOrNewSpec()\n+                .editOrNewTemplate()\n+                    .editOrNewSpec()\n+                        .editContainer(0)\n+                            .addToEnv(operatorNamespaceEnv)\n+                        .endContainer()\n+                    .endSpec()\n+                .endTemplate()\n+            .endSpec()\n+            .done();\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3).done();\n+\n+        checkNetworkPoliciesInNamespace(NAMESPACE);\n+\n+        changeKafkaConfigurationAndCheckObservedGeneration(NAMESPACE);\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInDifferentNamespaceThanOperand() {\n+        String secondNamespace = \"second-\" + NAMESPACE;\n+\n+        Map<String, String> labels = new HashMap<>();\n+        labels.put(\"my-label\", \"my-value\");\n+\n+        EnvVar operatorLabelsEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE_LABELS\")\n+            .withValue(labels.toString().replaceAll(\"\\\\{|}\", \"\"))\n+            .build();\n+\n+        cluster.createNamespace(secondNamespace);\n+\n+        prepareEnvForOperator(NAMESPACE, Arrays.asList(NAMESPACE, secondNamespace));\n+\n+        // Apply role bindings in CO namespace\n+        applyRoleBindings(NAMESPACE);\n+\n+        // Create ClusterRoleBindings that grant cluster-wide access to all OpenShift projects\n+        List<ClusterRoleBinding> clusterRoleBindingList = KubernetesResource.clusterRoleBindingsForAllNamespaces(NAMESPACE);\n+        clusterRoleBindingList.forEach(clusterRoleBinding ->\n+            KubernetesResource.clusterRoleBinding(clusterRoleBinding, NAMESPACE));\n+        // 060-Deployment\n+        BundleResource.clusterOperator(\"*\", Constants.CO_OPERATION_TIMEOUT_DEFAULT)\n+            .editOrNewSpec()\n+                .editOrNewTemplate()\n+                    .editOrNewSpec()\n+                        .editContainer(0)\n+                            .addToEnv(operatorLabelsEnv)\n+                        .endContainer()\n+                    .endSpec()\n+                .endTemplate()\n+            .endSpec()\n+            .done();\n+\n+        kubeClient().getClient().namespaces().withName(NAMESPACE).edit()\n+            .editMetadata()\n+                .addToLabels(labels)\n+            .endMetadata()\n+            .done();\n+\n+        cluster.setNamespace(secondNamespace);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editMetadata()\n+                .addToLabels(labels)\n+            .endMetadata()\n+            .done();\n+\n+        checkNetworkPoliciesInNamespace(secondNamespace);\n+\n+        changeKafkaConfigurationAndCheckObservedGeneration(secondNamespace);\n+    }\n+\n+    void checkNetworkPoliciesInNamespace(String namespace) {\n+        List<NetworkPolicy> networkPolicyList = new ArrayList<>(kubeClient().getClient().network().networkPolicies().inNamespace(namespace).list().getItems());\n+\n+        String networkPolicyPrefix = CLUSTER_NAME + \"-network-policy\";\n+\n+        assertNotNull(networkPolicyList.stream().filter(networkPolicy ->  networkPolicy.getMetadata().getName().contains(networkPolicyPrefix + \"-kafka\")).findFirst());\n+        assertNotNull(networkPolicyList.stream().filter(networkPolicy ->  networkPolicy.getMetadata().getName().contains(networkPolicyPrefix + \"-zookeeper\")).findFirst());\n+    }\n+\n+    void changeKafkaConfigurationAndCheckObservedGeneration(String namespace) {", "originalCommit": "74ccf5ef8950e77eed6543f9eb49feb468db6a60", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0OTc4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540449789", "bodyText": "When you don't have created NP for Kafka, you cannot do requests on Kafka API. If I'm correct, the dynamic configuration is changed through the Kafka API, so these checks will ensure us the config is applied and NP are working. (the observed generation is higher after these changes)", "author": "im-konge", "createdAt": "2020-12-10T19:47:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MzEyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ2Mzc4Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540463787", "bodyText": "Ok thanks :)", "author": "Frawless", "createdAt": "2020-12-10T20:10:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0MzEyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0OTYzNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540549637", "bodyText": "It is configured in the installation files (\n  \n    \n      strimzi-kafka-operator/install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml\n    \n    \n         Line 87\n      in\n      e1e1035\n    \n    \n    \n    \n\n        \n          \n           - name: STRIMZI_OPERATOR_NAMESPACE \n        \n    \n  \n\n) ... why do you need to configure it again your self here? Isn't that unnecessary? I think you deploy using these files ...", "author": "scholzj", "createdAt": "2020-12-10T22:38:50Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java", "diffHunk": "@@ -0,0 +1,334 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.fabric8.kubernetes.api.model.EnvVar;\n+import io.fabric8.kubernetes.api.model.EnvVarBuilder;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;\n+import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;\n+import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;\n+import io.strimzi.api.kafka.model.KafkaUser;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.resources.operator.BundleResource;\n+import io.strimzi.systemtest.utils.ClientUtils;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import io.strimzi.systemtest.utils.specific.MetricsUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(NETWORKPOLICIES_SUPPORTED)\n+public class NetworkPoliciesST extends AbstractST {\n+    public static final String NAMESPACE = \"np-cluster-test\";\n+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithPlainListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelForPlain = new HashMap<>();\n+        matchLabelForPlain.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                            .withPort(9092)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(false)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelForPlain)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+                .withNewKafkaExporter()\n+                .endKafkaExporter()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesPlain(),\n+            internalKafkaClient.receiveMessagesPlain()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(false, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is not able to exchange messages\", deniedKafkaClientsPodName);\n+        assertThrows(AssertionError.class, () ->  {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesPlain(),\n+                newInternalKafkaClient.receiveMessagesPlain()\n+            );\n+        });\n+\n+        LOGGER.info(\"Check metrics exported by Kafka Exporter\");\n+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(CLUSTER_NAME);\n+        assertThat(\"Kafka Exporter metrics should be non-empty\", kafkaExporterMetricsData.size() > 0);\n+        for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {\n+            assertThat(\"Value from collected metric should be non-empty\", !entry.getValue().isEmpty());\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_consumergroup_current_offset\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic0 + \"\\\"} 1\"));\n+            assertThat(\"Metrics doesn't contain specific values\", entry.getValue().contains(\"kafka_topic_partitions{topic=\\\"\" + topic1 + \"\\\"} 1\"));\n+        }\n+    }\n+\n+    @Test\n+    @Tag(INTERNAL_CLIENTS_USED)\n+    void testNetworkPoliciesWithTlsListener() {\n+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);\n+\n+        String allowedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-allow\";\n+        String deniedKafkaClientsName = CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS + \"-deny\";\n+        Map<String, String> matchLabelsForTls = new HashMap<>();\n+        matchLabelsForTls.put(\"app\", allowedKafkaClientsName);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .addNewGenericKafkaListener()\n+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+                            .withPort(9093)\n+                            .withType(KafkaListenerType.INTERNAL)\n+                            .withTls(true)\n+                            .withNewKafkaListenerAuthenticationScramSha512Auth()\n+                            .endKafkaListenerAuthenticationScramSha512Auth()\n+                            .withNetworkPolicyPeers(\n+                                new NetworkPolicyPeerBuilder()\n+                                    .withNewPodSelector()\n+                                    .withMatchLabels(matchLabelsForTls)\n+                                    .endPodSelector()\n+                                    .build())\n+                        .endGenericKafkaListener()\n+                    .endListeners()\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String topic0 = \"topic-example-0\";\n+        String topic1 = \"topic-example-1\";\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic0).done();\n+        KafkaTopicResource.topic(CLUSTER_NAME, topic1).done();\n+\n+        String userName = \"user-example\";\n+        KafkaUser kafkaUser = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();\n+\n+        KafkaClientsResource.deployKafkaClients(true, allowedKafkaClientsName, kafkaUser).done();\n+\n+        String allowedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(allowedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Verifying that {} pod is able to exchange messages\", allowedKafkaClientsPodName);\n+\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+            .withUsingPodName(allowedKafkaClientsPodName)\n+            .withTopicName(topic0)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(userName)\n+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)\n+            .build();\n+\n+        internalKafkaClient.checkProducedAndConsumedMessages(\n+            internalKafkaClient.sendMessagesTls(),\n+            internalKafkaClient.receiveMessagesTls()\n+        );\n+\n+        KafkaClientsResource.deployKafkaClients(true, deniedKafkaClientsName, kafkaUser).done();\n+\n+        String deniedKafkaClientsPodName = kubeClient().listPodsByPrefixInName(deniedKafkaClientsName).get(0).getMetadata().getName();\n+\n+        InternalKafkaClient newInternalKafkaClient = internalKafkaClient.toBuilder()\n+            .withUsingPodName(deniedKafkaClientsPodName)\n+            .withTopicName(topic1)\n+            .withConsumerGroupName(ClientUtils.generateRandomConsumerGroup())\n+            .build();\n+\n+        LOGGER.info(\"Verifying that {} pod is  not able to exchange messages\", deniedKafkaClientsPodName);\n+\n+        assertThrows(AssertionError.class, () -> {\n+            newInternalKafkaClient.checkProducedAndConsumedMessages(\n+                newInternalKafkaClient.sendMessagesTls(),\n+                newInternalKafkaClient.receiveMessagesTls()\n+            );\n+        });\n+    }\n+\n+    @Test\n+    void testNPWhenOperatorIsInSameNamespaceAsOperand() {\n+        EnvVar operatorNamespaceEnv = new EnvVarBuilder()\n+            .withName(\"STRIMZI_OPERATOR_NAMESPACE\")\n+            .withValue(NAMESPACE)\n+            .build();", "originalCommit": "74ccf5ef8950e77eed6543f9eb49feb468db6a60", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU1MzIwNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/4085#discussion_r540553206", "bodyText": "Yep, good point, thanks", "author": "im-konge", "createdAt": "2020-12-10T22:45:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0OTYzNw=="}], "type": "inlineReview"}, {"oid": "b46b0448f5b16679515f0f1b9ff76553ee352b0c", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b46b0448f5b16679515f0f1b9ff76553ee352b0c", "message": "Jakub's comment vol.2\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>", "committedDate": "2020-12-11T12:18:24Z", "type": "commit"}]}