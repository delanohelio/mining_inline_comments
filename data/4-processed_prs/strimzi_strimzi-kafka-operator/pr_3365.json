{"pr_number": 3365, "pr_title": "FIX(Readme) TESTING.md various docs updates", "pr_createdAt": "2020-07-22T17:12:09Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3OTY4OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r458979688", "bodyText": "BaseST no longer exists.", "author": "Frawless", "createdAt": "2020-07-22T17:58:04Z", "path": "development-docs/TESTING.md", "diffHunk": "@@ -90,18 +91,18 @@ Cluster Operator setup example:\n     }\n ```\n \n-##### Exercise\n-In this phase you specify all the steps which you need to cover some functionality. \n-If you didn't create the Kafka cluster you should do so at the begging of test using the test method resources instance of `Resources` inherited from `BaseST`.\n+### Exercise\n+In this phase you specify all steps which you need to execute to cover some specific functionality.\n+If you didn't create the Kafka cluster you should do so at the beginning of the test using a test method resources instance of `Resources` inherited from `BaseST`.", "originalCommit": "1c6e15d58bcbbf76c3cb4bcf4e0d51e296a48688", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk5MDM4NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r458990384", "bodyText": "fixed BaseST -> AbstractST", "author": "michalxo", "createdAt": "2020-07-22T18:16:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk3OTY4OA=="}], "type": "inlineReview"}, {"oid": "6e54babaed5269b98bc1899fa4d244c8dd3a04e6", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6e54babaed5269b98bc1899fa4d244c8dd3a04e6", "message": "FIX(Readme) TESTING.md various docs updates\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-07-22T18:15:54Z", "type": "forcePushed"}, {"oid": "29fcb6b282f7d5d7fbb0f767358580cab1c761e6", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/29fcb6b282f7d5d7fbb0f767358580cab1c761e6", "message": "FIX(Readme) TESTING.md various docs updates\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-07-22T18:17:19Z", "type": "commit"}, {"oid": "29fcb6b282f7d5d7fbb0f767358580cab1c761e6", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/29fcb6b282f7d5d7fbb0f767358580cab1c761e6", "message": "FIX(Readme) TESTING.md various docs updates\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-07-22T18:17:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAwNTcwNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r459005707", "bodyText": "I don't thin this is valid now. We use two stacks and you can everywhere use static methods from \"resources\" classes (like KafkaResources.class) and ResourceManager.classwill handle the rest. This approach in TESTING.md is quite old and I thing I just forgot to remove it.", "author": "Frawless", "createdAt": "2020-07-22T18:42:38Z", "path": "development-docs/TESTING.md", "diffHunk": "@@ -90,19 +91,19 @@ Cluster Operator setup example:\n     }\n ```\n \n-##### Exercise\n-In this phase you specify all the steps which you need to cover some functionality. \n-If you didn't create the Kafka cluster you should do so at the begging of test using the test method resources instance of `Resources` inherited from `BaseST`.\n+### Exercise\n+In this phase you specify all steps which you need to execute to cover some specific functionality.\n+If you didn't create the Kafka cluster you should do so at the beginning of the test using a test method resources instance of `Resources` inherited from `AbstractST`.", "originalCommit": "29fcb6b282f7d5d7fbb0f767358580cab1c761e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIzNDYyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r459234622", "bodyText": "ok I am removing this line 96.", "author": "michalxo", "createdAt": "2020-07-23T06:18:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTAwNTcwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA0MDYwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r459040608", "bodyText": "Just typo from the past.\nor [CodeReady Contaners](https://github.com/code-ready/crc) -> Containers", "author": "im-konge", "createdAt": "2020-07-22T19:45:18Z", "path": "development-docs/TESTING.md", "diffHunk": "@@ -18,11 +18,11 @@ For more information about build process see [Dev guide document](DEV_GUIDE.md).\n \n <!-- /TOC -->\n \n-## Pre-requisites \n+## Pre-requisites\n \n-To run any system tests you need a Kubernetes or Openshift cluster available in your active kubernetes context. \n-You can use [minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/), [minishift](https://www.okd.io/minishift/), [oc cluster up](https://github.com/openshift/origin) or [CodeReady Contaners](https://github.com/code-ready/crc) to have access to a cluster on your local machine. \n-You can also access a remote cluster on any machine you want, but make sure your active kubernetes context points to it. \n+To run any system tests you need a Kubernetes or Openshift cluster available in your active kubernetes context.\n+You can use [minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/), [minishift](https://www.okd.io/minishift/), [oc cluster up](https://github.com/openshift/origin) or [CodeReady Contaners](https://github.com/code-ready/crc) to have access to a cluster on your local machine.", "originalCommit": "29fcb6b282f7d5d7fbb0f767358580cab1c761e6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1MDI5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r459050293", "bodyText": "Just thinking - do we really want almost same sentence so many times? It's the third time until this line when I see this - ... resource lifecycle implementation will ... and deletion of resources at the end of tests.\nDo we want this so many times in our docu? It's just idea.", "author": "im-konge", "createdAt": "2020-07-22T20:03:28Z", "path": "development-docs/TESTING.md", "diffHunk": "@@ -32,50 +32,51 @@ The next requirement is to have built the `systemtest` package dependencies, whi\n * crd-generator\n * api\n \n-You can achieve that with `mvn clean install -DskipTests` or `mvn clean install -am -pl systemtest -DskipTests` commands. \n-The dependencies are needed because we use methods from the `test` package and strimzi model from `api` package. \n+You can achieve that with `mvn clean install -DskipTests` or `mvn clean install -am -pl systemtest -DskipTests` commands.\n+These dependencies are needed because we use methods from the `test` package and strimzi model from `api` package.\n \n-## Package Structure \n+## Package Structure\n \n-Systemtest package is divided into `main` and `test` as usuall. \n-In `main` you can find all support classes, which are used in the tests. \n-Modules worth mentioning are:\n+Systemtest package is divided into `main` and `test` as usual.\n+In `main` you can find all support classes, which are used in the tests.\n+\n+Notable modules:\n \n * **annotations** \u2014 we have our own `@OpenShiftOnly` annotation, which checks if the current cluster is Openshift or not. Any other annotations should be stored here.\n * **clients** \u2014 client implementations used in tests.\n * **matchers** \u2014 contains our matcher implementation for checking cluster operator logs. For more info see [Cluster Operator log check](#cluster-operator-log-check).\n * **utils** \u2014 a lot of actions are the same for most of the tests, and we share them through utils class and static methods. You can find here most of the useful methods.\n-* **resources** \u2014 heart of the systemtest package. In classes from this package, you can find all methods needed for deploy Strimzi, Kafka, Kafka Connect, Kafka Bridge, Kafka Mirror Maker and all other useful resources. \n-The current mechanism will ensure that all resources created within these classesurce deleto will be deleted after tests.\n+* **resources** \u2014 heart of the systemtest package. You can find here all methods needed for deploying Strimzi, Kafka, Kafka Connect, Kafka Bridge, Kafka Mirror Maker and other resources.\n+The current lifecycle mechanism will ensure that all resources created within these classes will be deleted after finished tests.\n \n-And classes: \n+Notable classes:\n \n-* **Environment** \u2014 singleton class, which loads the test environment variables (see following section), which are used in the tests.\n-* **Constants** \u2014 simple interface holding all constants used in the tests. \n-* **resources/ResourceManager** - singleton class which store info about deployed resources and take care about proper resource deletion.  \n+* **Environment** \u2014 singleton class, which loads the test environment variables (see following section), which are used in tests.\n+* **Constants** \u2014 simple interface holding all constants used in tests.\n+* **resources/ResourceManager** - singleton class which stores data about deployed resources and takes care of proper resource deletion.\n \n ## Test Phases\n \n-In general, we have classic test phases: setup, exercise, test, teardown.\n+In general, we use classic test phases: `setup`, `exercise`, `test` and `teardown`.\n \n-#### Setup\n+### Setup\n \n-In this phase we do the following things:\n+In this phase we perform:\n \n * Create namespace(s)\n * Deploy the Strimzi Cluster operator\n-* Deploy a Kafka cluster or other components (optional)\n+* Deploy the Kafka cluster and/or other components (optional)\n \n-The reason why the last point is optional is because we have some test cases where you want to have a different kafka configuration for each test scenario so creation of the Kafka cluster and other resources is done in the test phase.\n+The reason why the last point is optional, is because we have some test cases where you want to have a different kafka configuration for each test scenario, so creation of the Kafka cluster and other resources is done in the test phase.\n \n-We create resources in Kubernetes cluster via classes in `resources` package, which allows you to deploy all components and, if needed, change them from their default configuration using a builder. \n-Currently, we have two stacks, which are stored in `ResourceManager` singleton instance \u2014 one for whole test class resources and one for test method resources.\n-You can create resources anywhere you want, and our implementation will take care about put resource on top of one stack and delete them at the end of test method/class.\n+We create resources in Kubernetes cluster via classes in `resources` package, which allows you to deploy all components and, if needed, change them from their default configuration using a builder.\n+Currently, we have two stacks, which are stored in `ResourceManager` singleton instance \u2014 one for all test class resources and one for test method resources.\n+You can create resources anywhere you want. Our resource lifecycle implementation will handle insertion of the resource on top of stack and deletion at the end of the test method/class.", "originalCommit": "29fcb6b282f7d5d7fbb0f767358580cab1c761e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIzMzk4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r459233989", "bodyText": "I think I can simplify it on lines  49-50. Let me have a look at it.", "author": "michalxo", "createdAt": "2020-07-23T06:16:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1MDI5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1NTA3Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r459055072", "bodyText": "Can you please change the testKafkaAndZookeeperScaleUpScaleDown to testCustomAndUpdatedValues? This test is no longer part of the KafkaST and if someone will try it, he will see some errors and maybe he will think that he is doing something wrong. Thanks \ud83d\ude04", "author": "im-konge", "createdAt": "2020-07-22T20:12:29Z", "path": "development-docs/TESTING.md", "diffHunk": "@@ -144,125 +145,124 @@ You need to use the `groups` system property in order to execute a group of syst\n `-Dgroups=acceptance,regression` \u2014 to execute many test groups\n `-Dgroups=all` \u2014 to execute all test groups\n \n-If `-Dgroups` system property isn't defined, all tests without an explicitly declared test group will be executed. \n+If `-Dgroups` system property isn't defined, all tests without an explicitly declared test group will be executed.\n The following table shows currently used tags:\n \n-| Name            | Description                                                                        |\n-| :-------------: | :--------------------------------------------------------------------------------: |\n-| travis          | Marks tests executed on Travis                                                     |\n-| acceptance      | Acceptance tests, which guarantee, that basic functionality of Strimzi is working. |\n-| regression      | Regression tests, which contains all non-flaky tests.                              |\n-| upgrade         | Upgrade tests for specific versions of the Strimzi.                                |\n-| flaky           | Execute all flaky tests (tests, which are failing from time to time)               |\n-| nodeport        | Execute tests which use external lister of type nodeport                           |\n-| loadbalancer    | Execute tests which use external lister of type loadbalancer                       |\n-| bridge          | Execute tests which use Kafka Bridge                                               |\n-| specific        | Specific tests, which cannot be easily added to other categories                   |\n-| networkpolicies | Execute tests which use Kafka with Network Policies                                |\n-| tracing         | Execute tests for Tracing                                                          |\n-| prometheus      | Execute tests for Kafka with Prometheus                                            |\n-| oauth           | Execute tests which use OAuth                                                      |\n-| helm            | Execute tests which use Helm for deploy cluster operator                           |\n-| olm             | Execute tests which use OLM for deploy cluster operator                            |\n-| connectoroperator  | Execute tests which deploy KafkaConnector resource                              |\n-| connect         | Execute tests which deploy KafkaConnect resource                                   |\n-| connects2i      | Execute tests which deploy KafkaConnectS2I resource                                |\n-| mirrormaker     | Execute tests which deploy KafkaMirrorMaker resource                               |\n-| mirrormaker2    | Execute tests which deploy KafkaMirrorMaker2 resource                              |\n+| Name               | Description                                                                        |\n+| :----------------: | :--------------------------------------------------------------------------------: |\n+| travis             | Marks tests executed on Travis                                                     |\n+| acceptance         | Acceptance tests, which guarantee, that basic functionality of Strimzi is working. |\n+| regression         | Regression tests, which contains all non-flaky tests.                              |\n+| upgrade            | Upgrade tests for specific versions of the Strimzi.                                |\n+| flaky              | Execute all flaky tests (tests, which are failing from time to time)               |\n+| nodeport           | Execute tests which use external lister of type nodeport                           |\n+| loadbalancer       | Execute tests which use external lister of type loadbalancer                       |\n+| bridge             | Execute tests which use Kafka Bridge                                               |\n+| specific           | Specific tests, which cannot be easily added to other categories                   |\n+| networkpolicies    | Execute tests which use Kafka with Network Policies                                |\n+| tracing            | Execute tests for Tracing                                                          |\n+| prometheus         | Execute tests for Kafka with Prometheus                                            |\n+| oauth              | Execute tests which use OAuth                                                      |\n+| helm               | Execute tests which use Helm for deploy cluster operator                           |\n+| olm                | Execute tests which use OLM for deploy cluster operator                            |\n+| connectoroperator  | Execute tests which deploy KafkaConnector resource                                 |\n+| connect            | Execute tests which deploy KafkaConnect resource                                   |\n+| connects2i         | Execute tests which deploy KafkaConnectS2I resource                                |\n+| mirrormaker        | Execute tests which deploy KafkaMirrorMaker resource                               |\n+| mirrormaker2       | Execute tests which deploy KafkaMirrorMaker2 resource                              |\n | conneccomponents   | Execute tests which deploy KafkaConnect, KafkaConnectS2I, KafkaMirrorMaker2, KafkaConnector resources |\n-| internalclients | Execute tests which use internal (from pod) kafka clients in tests                 |\n-| externalclients | Execute tests which use external (from code) kafka clients in tests                |\n+| internalclients    | Execute tests which use internal (from pod) kafka clients in tests                 |\n+| externalclients    | Execute tests which use external (from code) kafka clients in tests                |\n \n-If your Kubernetes cluster doesn't support, for example, Network Policies or NodePort services, you can easily skip those tests with `-DexcludeGroups=networkpolicies,nodeport`.\n+If your Kubernetes cluster doesn't support for example, Network Policies or NodePort services, you can easily skip those tests with `-DexcludeGroups=networkpolicies,nodeport`.\n \n There is also a mvn profile for most of the groups, but we suggest to use profile with id `all` (default) and then include or exclude specific groups.\n \n All available test groups are listed in [Constants](systemtest/src/main/java/io/strimzi/systemtest/Constants.java) class.\n \n ## Environment variables\n \n-We can configure our system tests with several environment variables, which are loaded before test execution. \n-All environment variables can be seen in [Environment](systemtest/src/main/java/io/strimzi/systemtest/Environment.java) class:\n-\n-| Name                      | Description                                                                          | Default                                          |\n-| :-----------------------: | :----------------------------------------------------------------------------------: | :----------------------------------------------: |\n-| DOCKER_ORG                | Specify the organization/repo containing the image used in system tests                           | strimzi                                          |\n-| DOCKER_TAG                | Specify the image tags used in system tests                                              | latest                                           |\n-| DOCKER_REGISTRY           | Specify the docker registry used in system tests                                         | docker.io                                        |\n-| TEST_CLIENT_IMAGE         | Specify the test client image used in system tests                                       | docker.io/strimzi/test-client:latest-kafka-2.3.0 |\n-| BRIDGE_IMAGE              | Specify the kafka bridge image used in system tests                                      | docker.io/strimzi/kafka-bridge:latest            |\n-| TEST_LOG_DIR              | Directory for storing logs collected during the tests                                  | ../systemtest/target/logs/                       |\n-| ST_KAFKA_VERSION          | Kafka version used in images during the system tests                                 | 2.3.0                                            |\n-| STRIMZI_DEFAULT_LOG_LEVEL | Log level for the cluster operator                                                       | DEBUG                                            |\n-| KUBERNETES_DOMAIN         | Cluster domain                                                                       | .nip.io                                          |\n-| TEST_CLUSTER_CONTEXT      | Context which will be used to reach the cluster*                                     | currently active kubernetes context              |\n-| TEST_CLUSTER_USER         | Default user which will be used for command line admin operations                    | developer                                        |\n-| SKIP_TEARDOWN             | Variable for skip teardown phase for more debug if needed                            | false                                            |\n-| OPERATOR_IMAGE_PULL_POLICY   | Image Pull Policy for Operator image                                              | Always                                           |\n-| COMPONENTS_IMAGE_PULL_POLICY | Image Pull Policy for Kafka, Bridge, etc.                                         | IfNotPresent                                     |\n-| STRIMZI_TEST_LOG_LEVEL    | Log level for system tests                                                           | INFO                                             |\n-| OLM_OPERATOR_NAME         | Operator name in manifests CSV                                                       | strimzi                                             |\n-| OLM_SOURCE_NAME           | CatalogSource name which contains desired operator                                   | strimzi-source                                     |\n-| OLM_APP_BUNDLE_PREFIX     | CSV bundle name                                                                      | strimzi                                             |\n-| OLM_OPERATOR_VERSION      | Version of the operator which will be installed                                      | v0.16.2                                             |\n-| DEFAULT_TO_DENY_NETWORK_POLICIES | Determines how will be network policies set - to deny-all (true) or allow-all (false)    | true                                            |\n-| STRIMZI_EXEC_MAX_LOG_OUTPUT_CHARACTERS | Set maximum count of characters printed from [Executor](test/src/main/java/io/strimzi/test/executor/Exec.java) stdout and stderr | 20000   |\n-| CLUSTER_OPERATOR_INSTALL_TYPE | Specify how the CO will be deployed. `OLM` option will install operator via OLM, you just need to set other `OLM` env variables.    | bundle  |\n+System tests can be configured by several environment variables, which are loaded before test execution.\n+All environment variables are defined in [Environment](systemtest/src/main/java/io/strimzi/systemtest/Environment.java) class:\n+\n+| Name                                   | Description                                                                              | Default                                          |\n+| :------------------------------------: | :--------------------------------------------------------------------------------------: | :----------------------------------------------: |\n+| DOCKER_ORG                             | Specify the organization/repo containing the image used in system tests                  | strimzi                                          |\n+| DOCKER_TAG                             | Specify the image tags used in system tests                                              | latest                                           |\n+| DOCKER_REGISTRY                        | Specify the docker registry used in system tests                                         | docker.io                                        |\n+| TEST_CLIENT_IMAGE                      | Specify the test client image used in system tests                                       | docker.io/strimzi/test-client:latest-kafka-2.3.0 |\n+| BRIDGE_IMAGE                           | Specify the kafka bridge image used in system tests                                      | docker.io/strimzi/kafka-bridge:latest            |\n+| TEST_LOG_DIR                           | Directory for storing logs collected during the tests                                    | ../systemtest/target/logs/                       |\n+| ST_KAFKA_VERSION                       | Kafka version used in images during the system tests                                     | 2.3.0                                            |\n+| STRIMZI_DEFAULT_LOG_LEVEL              | Log level for the cluster operator                                                       | DEBUG                                            |\n+| KUBERNETES_DOMAIN                      | Cluster domain                                                                           | .nip.io                                          |\n+| TEST_CLUSTER_CONTEXT                   | Context which will be used to reach the cluster*                                         | currently active kubernetes context              |\n+| TEST_CLUSTER_USER                      | Default user which will be used for command line admin operations                        | developer                                        |\n+| SKIP_TEARDOWN                          | Variable for skip teardown phase for more debug if needed                                | false                                            |\n+| OPERATOR_IMAGE_PULL_POLICY             | Image Pull Policy for Operator image                                                     | Always                                           |\n+| COMPONENTS_IMAGE_PULL_POLICY           | Image Pull Policy for Kafka, Bridge, etc.                                                | IfNotPresent                                     |\n+| STRIMZI_TEST_LOG_LEVEL                 | Log level for system tests                                                               | INFO                                             |\n+| OLM_OPERATOR_NAME                      | Operator name in manifests CSV                                                           | strimzi                                          |\n+| OLM_SOURCE_NAME                        | CatalogSource name which contains desired operator                                       | strimzi-source                                   |\n+| OLM_APP_BUNDLE_PREFIX                  | CSV bundle name                                                                          | strimzi                                          |\n+| OLM_OPERATOR_VERSION                   | Version of the operator which will be installed                                          | v0.16.2                                          |\n+| DEFAULT_TO_DENY_NETWORK_POLICIES       | Determines how will be network policies set - to deny-all (true) or allow-all (false)    | true                                             |\n+| STRIMZI_EXEC_MAX_LOG_OUTPUT_CHARACTERS | Set maximum count of characters printed from [Executor](test/src/main/java/io/strimzi/test/executor/Exec.java) stdout and stderr | 20000    |\n+| CLUSTER_OPERATOR_INSTALL_TYPE          | Specify how the CO will be deployed. `OLM` option will install operator via OLM, you just need to set other `OLM` env variables. | bundle   |\n \n If you want to use your own images with a different tag or from a different repository, you can use `DOCKER_REGISTRY`, `DOCKER_ORG` and `DOCKER_TAG` environment variables.\n \n-`KUBERNETES_DOMAIN` should be specified only in case you are using specific configuration in your kubernetes cluster.\n+`KUBERNETES_DOMAIN` should be specified only in case, when you are using specific configuration in your kubernetes cluster.\n \n ##### Specific Kafka version\n \n-To set custom Kafka version in system tests you need to set environment variable `ST_KAFKA_VERSION` to one of the values in [kafka-versions](kafka-versions.yaml).\n+To set custom Kafka version in system tests you need to set the environment variable `ST_KAFKA_VERSION` to one of the values in [kafka-versions](kafka-versions.yaml).\n \n ##### Cluster Operator Log level\n \n To set the log level of Strimzi for system tests you need to set the environment variable `STRIMZI_DEFAULT_LOG_LEVEL` with one of the following values: `ERROR`, `WARNING`, `INFO`, `DEBUG`, `TRACE`.\n \n ## Use Remote Cluster\n \n-The integration and system tests are run against a cluster specified in the environment variable `TEST_CLUSTER_CONTEXT`. \n-If this variable is not set, the kubernetes client will use the currently active context. \n+The integration and system tests are ran against a cluster specified in the environment variable `TEST_CLUSTER_CONTEXT`.\n+If this variable is unset, the kubernetes client will use the currently active context.\n Otherwise, it will use the context from kubeconfig with a name specified by the `TEST_CLUSTER_CONTEXT` variable.\n \n-For example command `TEST_CLUSTER_CONTEXT=remote-cluster ./systemtest/scripts/run_tests.sh` will execute tests with cluster context `remote-cluster`. \n+For example, command `TEST_CLUSTER_CONTEXT=remote-cluster ./systemtest/scripts/run_tests.sh` will execute tests with cluster context `remote-cluster`.\n However, since system tests use command line `Executor` for some actions, make sure that you are using context from `TEST_CLUSTER_CONTEXT`.\n \n-System tests uses admin user for some actions. \n+System tests uses admin user for some actions.\n You can specify the admin user using variable `TEST_CLUSTER_ADMIN` (by default it uses `developer` because `system:admin` cannot be used over remote connections).\n \n ## Helper script\n \n-The `./systemtest/scripts/run_tests.sh` script can be used to run the `systemtests` using the same configuration as used in the travis build. \n+The `./systemtest/scripts/run_tests.sh` script can be used to run the `systemtests` using the same configuration as used in the travis build.\n You can use this script to easily run the `systemtests` project.\n \n Pass additional parameters to `mvn` by populating the `EXTRA_ARGS` env var.\n \n     EXTRA_ARGS=\"-Dfoo=bar\" ./systemtest/scripts/run_tests.sh\n-    \n+\n ## Running single test class\n \n-Use the `verify` build goal and provide a `-Dit.test=TestClassName[#testMethodName]` system property. \n+Use the `verify` build goal and provide `-Dit.test=TestClassName[#testMethodName]` system property.\n \n     mvn verify -pl systemtest -Dit.test=KafkaST#testKafkaAndZookeeperScaleUpScaleDown", "originalCommit": "29fcb6b282f7d5d7fbb0f767358580cab1c761e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIzNDg1Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3365#discussion_r459234852", "bodyText": "Done.", "author": "michalxo", "createdAt": "2020-07-23T06:19:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA1NTA3Mg=="}], "type": "inlineReview"}, {"oid": "ca127e38b56196f12443cb03cf5cade804c7b451", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ca127e38b56196f12443cb03cf5cade804c7b451", "message": "fixup! FIX(Readme) TESTING.md various docs updates\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-07-23T06:45:59Z", "type": "commit"}, {"oid": "ca127e38b56196f12443cb03cf5cade804c7b451", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ca127e38b56196f12443cb03cf5cade804c7b451", "message": "fixup! FIX(Readme) TESTING.md various docs updates\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-07-23T06:45:59Z", "type": "forcePushed"}]}