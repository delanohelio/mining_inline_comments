{"pr_number": 3873, "pr_title": "FIX(Tests) testRackAware (no external clients) & new testRackAwareConnect", "pr_createdAt": "2020-10-26T07:16:14Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTgwNzM5Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r511807396", "bodyText": "Why is this in any way relevant only to this ST? Also, sleeping for the whole reconciliation interval could be waste of time. You should check periodically with some small backoff for example to make sure you don't waste time on it.", "author": "scholzj", "createdAt": "2020-10-26T09:05:17Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,6 +100,15 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n+        LOGGER.info(\"Waiting for reconciliation to happen. \" +\n+                \"Giving some time to DNS/load balancer to propagate kafka address.\" +\n+                \"Sleeping for {}ms\", Constants.RECONCILIATION_INTERVAL);\n+        try {\n+            Thread.sleep(Constants.RECONCILIATION_INTERVAL);\n+        } catch (InterruptedException e) {\n+            e.printStackTrace();\n+        }", "originalCommit": "ef35a4e7393c0d91afbdeb2f94c3c95d3435e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzI2NTMyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r513265322", "bodyText": "Removed with LB and External clients usage.", "author": "michalxo", "createdAt": "2020-10-28T08:41:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTgwNzM5Ng=="}], "type": "inlineReview"}, {"oid": "e6907c23439339e2b9636c0eb7d73da2f3bafc79", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e6907c23439339e2b9636c0eb7d73da2f3bafc79", "message": "FIX(Tests) TestRackAware do not use load balance w/ ext clients\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-10-26T15:05:44Z", "type": "forcePushed"}, {"oid": "14a3b390216fae011b06b50920aa3a692238c448", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/14a3b390216fae011b06b50920aa3a692238c448", "message": "NEW(Tests) testRackAwareConnect\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-04T10:45:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMyMDM0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517320340", "bodyText": "I guess ideally you should also deploy some connector and send some messages to verify it is all working and is connected.", "author": "scholzj", "createdAt": "2020-11-04T12:51:13Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ0MDA1OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517440059", "bodyText": "#3917", "author": "git175", "createdAt": "2020-11-04T15:45:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMyMDM0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwNzc4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517407782", "bodyText": "You should add REGRESSION tag here", "author": "Frawless", "createdAt": "2020-11-04T15:01:27Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -56,8 +69,6 @@\n     public static final String NAMESPACE = \"specific-cluster-test\";\n \n     @Test\n-    @Tag(LOADBALANCER_SUPPORTED)\n-    @Tag(EXTERNAL_CLIENTS_USED)\n     void testRackAware() {", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwNzg5NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517407894", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-11-04T15:01:36Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwODE4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517408189", "bodyText": "Indent", "author": "Frawless", "createdAt": "2020-11-04T15:02:00Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                .endKafka()\n+                .endSpec().done();", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwODI3NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517408275", "bodyText": "Indent", "author": "Frawless", "createdAt": "2020-11-04T15:02:09Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                .withNewRack()\n+                .withTopologyKey(wrongRackKey)\n+                .endRack()\n+                .endSpec()\n+                .build());", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwODU0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517408542", "bodyText": "indent", "author": "Frawless", "createdAt": "2020-11-04T15:02:24Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                .withNewRack()\n+                .withTopologyKey(wrongRackKey)\n+                .endRack()\n+                .endSpec()\n+                .build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));\n+        KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();\n+        PodUtils.deletePodWithWait(connectWrongPodName);\n+\n+        LOGGER.info(\"Deploy KafkaConnect with correct rack-aware topology key: {}\", rackKey);\n+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 2)\n+                .editSpec()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .endSpec()\n+                .done();", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQxMzMzNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517413337", "bodyText": "Wouldn't be better to check KC status instead of pod status which is set by kubernetes? If there is something useful of course.", "author": "Frawless", "createdAt": "2020-11-04T15:09:07Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                .withNewRack()\n+                .withTopologyKey(wrongRackKey)\n+                .endRack()\n+                .endSpec()\n+                .build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQxNzkwNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517417907", "bodyText": "I will check it out. Thanks for pointer.", "author": "michalxo", "createdAt": "2020-11-04T15:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQxMzMzNw=="}], "type": "inlineReview"}, {"oid": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9f647c40ef0258e15da6770dcf79def95bfd7ea0", "message": "fixup! FIX(Tests) TestRackAware do not use load balance w/ ext clients\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-05T08:08:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEwOTIxMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518109211", "bodyText": "Didn't you had some waitFor methods which can do this in a more efficient way?", "author": "scholzj", "createdAt": "2020-11-05T14:50:39Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +109,120 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnect() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));", "originalCommit": "872a420efbc02018f9b12b676dab17786d08ca09", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMDEzMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518110132", "bodyText": "I wonder if we do really want to have the error text hardcoded. It is often different with Kubernetes versions and makes the test lass portable and future-proof.", "author": "scholzj", "createdAt": "2020-11-05T14:51:47Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +109,120 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnect() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));", "originalCommit": "872a420efbc02018f9b12b676dab17786d08ca09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyMTUwMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518121502", "bodyText": "Yeah, I was thinking the same if it should be regexp or this line should be completely omitted.\nI will remove it for KISS.", "author": "michalxo", "createdAt": "2020-11-05T15:06:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMDEzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518111126", "bodyText": "Maybe if you already start with a wrong rack, you could also just change the Connect CR and see that it recovers instead of deleting it?", "author": "scholzj", "createdAt": "2020-11-05T14:53:04Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +109,120 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnect() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));\n+        KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();\n+        PodUtils.deletePodWithWait(connectWrongPodName);", "originalCommit": "872a420efbc02018f9b12b676dab17786d08ca09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExNDg5Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518114897", "bodyText": "I was thinking about it while writing this test. After your suggestion, I think that probably it should be a different test.\nOr even better this test split into two.\n\nPositive case (second portion of test)\nNegative case (incorrect rack-key) with happy-ending (edit pf CR as you suggest)\n\nWDYT @Frawless @scholzj", "author": "michalxo", "createdAt": "2020-11-05T14:57:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyMzI0OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518123249", "bodyText": "Sounds good to me.", "author": "scholzj", "createdAt": "2020-11-05T15:09:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyNjU0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518126542", "bodyText": "Ye, sounds reasonable. What about recovery from the wrong rack? Isn't it something which could be useful for KafkaRoller coverage?", "author": "Frawless", "createdAt": "2020-11-05T15:13:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkzNTUxMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r526935512", "bodyText": "What do you mean by recovery from wrong rack? @Frawless - Is this question targeted at me or @scholzj ?\nI added both tests now into PR. Locally they are passing, but I think they will fail in this PR's as we will miss rack-key label on nodes...", "author": "michalxo", "createdAt": "2020-11-19T14:37:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkzOTYyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r526939622", "bodyText": "You deploy it with the wrong one => check it fails => fix it to the correct one in the CR => check that the operator recovers from it and fixes it.", "author": "scholzj", "createdAt": "2020-11-19T14:42:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjk1MjMxOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r526952318", "bodyText": "Yup, that's what I did I believe in testRackAwareConnectWrongDeployment :-)", "author": "michalxo", "createdAt": "2020-11-19T14:58:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}], "type": "inlineReview"}, {"oid": "a34467fbdc216c9256041ddf74b46f844d33915f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a34467fbdc216c9256041ddf74b46f844d33915f", "message": "FIX(Tests) testRackAware added wait for DNS propagation of kafka to load balancer\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-19T14:34:41Z", "type": "commit"}, {"oid": "0338dc6395c2383c906130b1ffba861c852633af", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0338dc6395c2383c906130b1ffba861c852633af", "message": "FIX(Tests) TestRackAware do not use load balance w/ ext clients\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-19T14:34:42Z", "type": "commit"}, {"oid": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "message": "fixup! NEW(Tests) testRackAwareConnect\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-19T14:34:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNTc5OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527025799", "bodyText": "It's not a test", "author": "Frawless", "createdAt": "2020-11-19T16:31:26Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -78,4 +80,33 @@ public static void waitForKafkaConnectConfigChange(String propertyKey, String pr\n             });\n         LOGGER.info(\"Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n     }\n+\n+    /**\n+     * Test sending and receiving messages through file sink connector (using Kafka Connect).", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNTk1OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527025958", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-11-19T16:31:38Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -78,4 +80,33 @@ public static void waitForKafkaConnectConfigChange(String propertyKey, String pr\n             });\n         LOGGER.info(\"Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n     }\n+\n+    /**\n+     * Test sending and receiving messages through file sink connector (using Kafka Connect).\n+     * @param connectPodName kafkaConnect pod name\n+     * @param topicName topic to be used\n+     * @param kafkaClientsPodName kafkaClients pod name\n+     * @param namespace namespace name\n+     * @param clusterName cluster name\n+     */\n+    public static void sendReceiveMessagesThroughConnect(String connectPodName, String topicName, String kafkaClientsPodName, String namespace, String clusterName) {\n+        LOGGER.info(\"Test sending and receiving messages through KafkaConnect\");", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzQ4Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527027486", "bodyText": "Move it to some utils class? You basically wait until KC is not ready, I don't see any specific message in status. Also, the test will wait 5 minutes until deployment will timeout. WOuldn't be enough just to wait for the pending, wait for the next reconciliation, check if the pod is still pending, and then proceed?", "author": "Frawless", "createdAt": "2020-11-19T16:33:43Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MTE4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527091189", "bodyText": "Makes sense to move it to KCUtils.waitUntilCondition(Reason, Type). Good idea.\nActually it will wait only 1min as long CO_OPERATION_TIMEOUT_SHORT = Duration.ofSeconds(30).toMillis(); *2", "author": "michalxo", "createdAt": "2020-11-19T18:03:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzQ4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIxNjc2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527216766", "bodyText": "I see. Anyway, move it is still a good idea :)", "author": "Frawless", "createdAt": "2020-11-19T21:37:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzQ4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzgwNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527027805", "bodyText": "Why do you assert something, which is verified a few lines above?", "author": "Frawless", "createdAt": "2020-11-19T16:34:12Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MTcyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527091722", "bodyText": "Thanks, left-over from previous test case (work).", "author": "michalxo", "createdAt": "2020-11-19T18:04:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyODU2MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527028561", "bodyText": "maybe put rack key into the log as well?", "author": "Frawless", "createdAt": "2020-11-19T16:35:06Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> {\n+            kafkaConnect.getSpec().setRack(new Rack(rackKey));\n+        });\n+        KafkaConnectUtils.waitForConnectReady(CLUSTER_NAME);\n+        LOGGER.info(\"KafkaConnect is ready with changed rack key.\");", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527029839", "bodyText": "isn't it by default applied for each KC which we create during tests?", "author": "Frawless", "createdAt": "2020-11-19T16:36:51Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> {\n+            kafkaConnect.getSpec().setRack(new Rack(rackKey));\n+        });\n+        KafkaConnectUtils.waitForConnectReady(CLUSTER_NAME);\n+        LOGGER.info(\"KafkaConnect is ready with changed rack key.\");\n+        LOGGER.info(\"Verify KafkaConnect rack key update\");\n+        kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        assertThat(kc.getSpec().getRack().getTopologyKey(), is(rackKey));\n+\n+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {\n+            KubernetesResource.allowNetworkPolicySettingsForResource(kc, KafkaConnectResources.deploymentName(kc.getMetadata().getName()));\n+        }", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MjgwNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527092804", "bodyText": "No, as I am not using specifically KafkaConnectResource.deployKafkaConnect() method. @im-konge also mentioned me this today.", "author": "michalxo", "createdAt": "2020-11-19T18:06:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIxOTY3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527219673", "bodyText": "I don't say you have to change it in this PR, but maybe we should think about applying the NP in kafkaConnectWithoutWait as we do in deployKafkaConnect", "author": "Frawless", "createdAt": "2020-11-19T21:40:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyMTcwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527221703", "bodyText": "Yes, but I thought that you will add it to the KafkaConnectResource.kafkaConnectWithoutWait() method. I don't think that having it directly in a test is a good idea. But ... there comes another problem -> you have to create KafkaClients pod before creating the KafkaConnect, so you'll have to add it to all tests where the Connect is deployed via the withoutWait method.", "author": "im-konge", "createdAt": "2020-11-19T21:43:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyMzU0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527223544", "bodyText": "Ye, maybe we should think more about it and solve it a little bit differently to avoid the situation with clients", "author": "Frawless", "createdAt": "2020-11-19T21:47:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNDQ4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527224482", "bodyText": "And you are using this if more than once ... so ... what about to create some different method, which will create the NP and then deploy the Connect without wait? To not add unnecessary Clients pods to other testcases?", "author": "im-konge", "createdAt": "2020-11-19T21:48:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAzMDA4NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527030084", "bodyText": "indent", "author": "Frawless", "createdAt": "2020-11-19T16:37:09Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAzMjA1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527032051", "bodyText": "Same as I mentioned above", "author": "Frawless", "createdAt": "2020-11-19T16:39:44Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> {\n+            kafkaConnect.getSpec().setRack(new Rack(rackKey));\n+        });\n+        KafkaConnectUtils.waitForConnectReady(CLUSTER_NAME);\n+        LOGGER.info(\"KafkaConnect is ready with changed rack key.\");\n+        LOGGER.info(\"Verify KafkaConnect rack key update\");\n+        kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        assertThat(kc.getSpec().getRack().getTopologyKey(), is(rackKey));\n+\n+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {\n+            KubernetesResource.allowNetworkPolicySettingsForResource(kc, KafkaConnectResources.deploymentName(kc.getMetadata().getName()));\n+        }\n+        List<String> kcPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        KafkaConnectUtils.sendReceiveMessagesThroughConnect(kcPods.get(0), TOPIC_NAME, kafkaClientsPodName, NAMESPACE, CLUSTER_NAME);\n+    }\n+\n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    public void testRackAwareConnectCorrectDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String rackKey = \"rack-key\";\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with correct rack-aware topology key: {}\", rackKey);\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(rackKey)\n+                    .endRack()\n+                    .addToConfig(\"key.converter.schemas.enable\", false)\n+                    .addToConfig(\"value.converter.schemas.enable\", false)\n+                    .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                    .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().done();\n+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {\n+            KubernetesResource.allowNetworkPolicySettingsForResource(kc, KafkaConnectResources.deploymentName(kc.getMetadata().getName()));\n+        }", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNTUwNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527225506", "bodyText": "How about to add INTERNAL_CLIENTS_USED as well?", "author": "im-konge", "createdAt": "2020-11-19T21:50:25Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -56,8 +75,7 @@\n     public static final String NAMESPACE = \"specific-cluster-test\";\n \n     @Test\n-    @Tag(LOADBALANCER_SUPPORTED)\n-    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(REGRESSION)\n     void testRackAware() {", "originalCommit": "9b9af81b61d1cf33d87366ab643d8b8c09e4fcd2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNzY3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527227674", "bodyText": "Same also for the second test", "author": "im-konge", "createdAt": "2020-11-19T21:54:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNTUwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNjEyMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527226120", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n          \n          \n            \n                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n          \n          \n            \n            ``` ?", "author": "im-konge", "createdAt": "2020-11-19T21:51:31Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,147 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();", "originalCommit": "9b9af81b61d1cf33d87366ab643d8b8c09e4fcd2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "message": "NEW(Tests) testRackAwareConnect\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-26T11:04:53Z", "type": "commit"}, {"oid": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "message": "NEW(Tests) testRackAwareConnect\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-26T11:04:53Z", "type": "forcePushed"}]}