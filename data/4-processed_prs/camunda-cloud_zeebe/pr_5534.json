{"pr_number": 5534, "pr_title": "Write an Zeebe upgrade guide", "pr_createdAt": "2020-10-08T07:28:22Z", "pr_url": "https://github.com/camunda-cloud/zeebe/pull/5534", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzExNzYzOA==", "url": "https://github.com/camunda-cloud/zeebe/pull/5534#discussion_r503117638", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The following procedure describes how upgrade a broker. If the cluster contains multiple brokers then these steps can be done for all brokers in parallel. Standalone gateways should be upgrade after all brokers in the cluster are upgrade to avoid mismatches in the protocol version.\n          \n          \n            \n            The following procedure describes how to upgrade a broker. If the cluster contains multiple brokers then these steps can be done for all brokers in parallel. Standalone gateways should be upgraded after all brokers in the cluster are upgraded to avoid mismatches in the protocol version.", "author": "deepthidevaki", "createdAt": "2020-10-12T08:18:07Z", "path": "docs/src/operations/upgrade.md", "diffHunk": "@@ -0,0 +1,152 @@\n+# Upgrade Zeebe\n+\n+This section describes how to upgrade Zeebe to a new version.\n+\n+> **Important:** Currently, we are facing an issue that can corrupt the data when upgrading to a new version. The issue affects the reprocessing (i.e. rehydrating the data from the records on the log stream) and can be omitted by restoring the data from a snapshot. Please follow the recommended procedure to minimize the risk of losing data.\n+\n+## Upgrade Procedure\n+\n+The following procedure describes how upgrade a broker. If the cluster contains multiple brokers then these steps can be done for all brokers in parallel. Standalone gateways should be upgrade after all brokers in the cluster are upgrade to avoid mismatches in the protocol version.", "originalCommit": "aef80dd7a8e1cfd1460ec1680def4f07d5c08117", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzExOTcwMA==", "url": "https://github.com/camunda-cloud/zeebe/pull/5534#discussion_r503119700", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            > Because of current issue, it is not recommended performing a rolling upgrade. Please follow the upgrade procedure instead.\n          \n          \n            \n            > Because of current issue, it is not recommended to perform a rolling upgrade. Please follow the upgrade procedure instead.", "author": "deepthidevaki", "createdAt": "2020-10-12T08:21:28Z", "path": "docs/src/operations/upgrade.md", "diffHunk": "@@ -0,0 +1,152 @@\n+# Upgrade Zeebe\n+\n+This section describes how to upgrade Zeebe to a new version.\n+\n+> **Important:** Currently, we are facing an issue that can corrupt the data when upgrading to a new version. The issue affects the reprocessing (i.e. rehydrating the data from the records on the log stream) and can be omitted by restoring the data from a snapshot. Please follow the recommended procedure to minimize the risk of losing data.\n+\n+## Upgrade Procedure\n+\n+The following procedure describes how upgrade a broker. If the cluster contains multiple brokers then these steps can be done for all brokers in parallel. Standalone gateways should be upgrade after all brokers in the cluster are upgrade to avoid mismatches in the protocol version.\n+\n+Note that this procedure results in a downtime of the whole cluster. Currently, a rolling upgrade is not recommended to avoid that an upgraded broker do reprocessing and is affected by the issue.\n+\n+> TODO: describe how to perform the upgrade on Kubernetes/Helm\n+\n+### Preparing the Upgrade\n+\n+#### From broker version < 24.4\n+\n+1. Stop the workflow processing\n+    * Close all job workers\n+    * Interrupt the incoming connections to avoid user commands\n+1. Wait until a snapshot is created for all partitions\n+    * By default, a snapshot is created every 15 minutes\n+    * Verify that a snapshot is created by looking at the [Metric](/operations/metrics.md) `zeebe_snapshot_count` on the leader and the followers\n+    * Note that no snapshot is created if no processing happened since the last snapshot\n+1. Make a backup of the `data` folder\n+\n+#### From broker version >= 24.4\n+\n+The [Partitions Admin Endpoint](#partitions-admin-endpoint) can be used to query the status of the partitions and perform operations for the upgrade.\n+\n+1. Stop the workflow processing and trigger a snapshot creation\n+    * Call the `prepareUpgrade` operation on the partitions endpoint\n+    * Query the status of the partitions until the following conditions are met for all partitions:\n+        * `processedPositionInSnapshot` is equal to `processedPosition`\n+        * all followers (role: `FOLLOWER`) have the same `snapshotId` as the leader (role: `LEADER`)\n+1. Make a backup of the `data` folder\n+\n+### Performing the Upgrade\n+\n+1. Shut down the broker\n+1. Replace the `/bin` and `/lib` folders with the versions of the new distribution\n+1. Start up the broker\n+\n+### Verifying the Upgrade\n+\n+The upgrade is successful if the following conditions are met:\n+\n+* the broker is ready (see [Ready Check](/operations/health.md#ready-check))\n+* the broker is healthy (see [Health Check](/operations/health.md#health-check))\n+* all partitions are healthy (see the [Metric](/operations/metrics.md#metrics-related-to-health) `zeebe_health`)\n+* the stream processors of the partition leaders are in the phase `PROCESSING` (see [Partitions Admin Endpoint](#partitions-admin-endpoint))\n+\n+If the upgrade failed because of a known issue then a partition change its status to unhealthy, and the log output may contain the following error message:\n+\n+<details>\n+  <summary>Sample Upgrade Error Message</summary>\n+  <p>\n+\n+```\n+Unexpected error on recovery happens.\n+io.zeebe.engine.processor.InconsistentReprocessingException: Reprocessing issue detected!\n+  Restore the data from a backup and follow the recommended upgrade procedure. [cause:\n+  \"The key of the record on the log stream doesn't match to the record from reprocessing.\",\n+  log-stream-record: {\"partitionId\":1,\"value\":{\"version\":1,\"bpmnProcessId\":\"parallel-tasks\",\n+  \"workflowKey\":2251799813685249,\"parentElementInstanceKey\":-1,\"parentWorkflowInstanceKey\":-1,\n+  \"bpmnElementType\":\"PARALLEL_GATEWAY\",\"flowScopeKey\":2251799813685251,\n+  \"elementId\":\"ExclusiveGateway_0tkgnd5\",\"workflowInstanceKey\":2251799813685251},\n+  \"key\":2251799813685256,\"sourceRecordPosition\":4294997784,\"valueType\":\"WORKFLOW_INSTANCE\",\n+  \"timestamp\":1601025180728,\"recordType\":\"EVENT\",\"intent\":\"ELEMENT_ACTIVATING\",\n+  \"rejectionType\":\"NULL_VAL\",\"rejectionReason\":\"\",\"position\":4294998112},\n+  reprocessing-record: {key=2251799813685255, sourceRecordPosition=4294997784,\n+  intent=WorkflowInstanceIntent:ELEMENT_ACTIVATING, recordType=EVENT}]\n+```\n+\n+  </p>\n+</details>\n+\n+In this case, the broker should be rolled back to the previous version and the backup should be restored. Ensure that the upgrade was prepared correctly. If it is still unclear why it was not successful then please contact the Zeebe team and ask for guidance.\n+\n+\n+## Rolling Upgrade\n+\n+Zeebe is designed to allow a rolling upgrade of a cluster. The brokers can be upgrade one after each other. The other brokers in the cluster continue processing until the whole upgrade is done.\n+\n+1. Upgrade the first broker and wait until it is ready again\n+1. Continue with the next broker until all brokers are upgraded\n+1. Upgrade the standalone gateways\n+\n+> Because of current issue, it is not recommended performing a rolling upgrade. Please follow the upgrade procedure instead.", "originalCommit": "aef80dd7a8e1cfd1460ec1680def4f07d5c08117", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzE1MDk3NA==", "url": "https://github.com/camunda-cloud/zeebe/pull/5534#discussion_r503150974", "bodyText": "Should we move this section to the beginning? Mention that this is usual way to upgrade - but because of the current issue follow the following upgrade procedure temporarily.", "author": "deepthidevaki", "createdAt": "2020-10-12T09:10:33Z", "path": "docs/src/operations/upgrade.md", "diffHunk": "@@ -0,0 +1,152 @@\n+# Upgrade Zeebe\n+\n+This section describes how to upgrade Zeebe to a new version.\n+\n+> **Important:** Currently, we are facing an issue that can corrupt the data when upgrading to a new version. The issue affects the reprocessing (i.e. rehydrating the data from the records on the log stream) and can be omitted by restoring the data from a snapshot. Please follow the recommended procedure to minimize the risk of losing data.\n+\n+## Upgrade Procedure\n+\n+The following procedure describes how upgrade a broker. If the cluster contains multiple brokers then these steps can be done for all brokers in parallel. Standalone gateways should be upgrade after all brokers in the cluster are upgrade to avoid mismatches in the protocol version.\n+\n+Note that this procedure results in a downtime of the whole cluster. Currently, a rolling upgrade is not recommended to avoid that an upgraded broker do reprocessing and is affected by the issue.\n+\n+> TODO: describe how to perform the upgrade on Kubernetes/Helm\n+\n+### Preparing the Upgrade\n+\n+#### From broker version < 24.4\n+\n+1. Stop the workflow processing\n+    * Close all job workers\n+    * Interrupt the incoming connections to avoid user commands\n+1. Wait until a snapshot is created for all partitions\n+    * By default, a snapshot is created every 15 minutes\n+    * Verify that a snapshot is created by looking at the [Metric](/operations/metrics.md) `zeebe_snapshot_count` on the leader and the followers\n+    * Note that no snapshot is created if no processing happened since the last snapshot\n+1. Make a backup of the `data` folder\n+\n+#### From broker version >= 24.4\n+\n+The [Partitions Admin Endpoint](#partitions-admin-endpoint) can be used to query the status of the partitions and perform operations for the upgrade.\n+\n+1. Stop the workflow processing and trigger a snapshot creation\n+    * Call the `prepareUpgrade` operation on the partitions endpoint\n+    * Query the status of the partitions until the following conditions are met for all partitions:\n+        * `processedPositionInSnapshot` is equal to `processedPosition`\n+        * all followers (role: `FOLLOWER`) have the same `snapshotId` as the leader (role: `LEADER`)\n+1. Make a backup of the `data` folder\n+\n+### Performing the Upgrade\n+\n+1. Shut down the broker\n+1. Replace the `/bin` and `/lib` folders with the versions of the new distribution\n+1. Start up the broker\n+\n+### Verifying the Upgrade\n+\n+The upgrade is successful if the following conditions are met:\n+\n+* the broker is ready (see [Ready Check](/operations/health.md#ready-check))\n+* the broker is healthy (see [Health Check](/operations/health.md#health-check))\n+* all partitions are healthy (see the [Metric](/operations/metrics.md#metrics-related-to-health) `zeebe_health`)\n+* the stream processors of the partition leaders are in the phase `PROCESSING` (see [Partitions Admin Endpoint](#partitions-admin-endpoint))\n+\n+If the upgrade failed because of a known issue then a partition change its status to unhealthy, and the log output may contain the following error message:\n+\n+<details>\n+  <summary>Sample Upgrade Error Message</summary>\n+  <p>\n+\n+```\n+Unexpected error on recovery happens.\n+io.zeebe.engine.processor.InconsistentReprocessingException: Reprocessing issue detected!\n+  Restore the data from a backup and follow the recommended upgrade procedure. [cause:\n+  \"The key of the record on the log stream doesn't match to the record from reprocessing.\",\n+  log-stream-record: {\"partitionId\":1,\"value\":{\"version\":1,\"bpmnProcessId\":\"parallel-tasks\",\n+  \"workflowKey\":2251799813685249,\"parentElementInstanceKey\":-1,\"parentWorkflowInstanceKey\":-1,\n+  \"bpmnElementType\":\"PARALLEL_GATEWAY\",\"flowScopeKey\":2251799813685251,\n+  \"elementId\":\"ExclusiveGateway_0tkgnd5\",\"workflowInstanceKey\":2251799813685251},\n+  \"key\":2251799813685256,\"sourceRecordPosition\":4294997784,\"valueType\":\"WORKFLOW_INSTANCE\",\n+  \"timestamp\":1601025180728,\"recordType\":\"EVENT\",\"intent\":\"ELEMENT_ACTIVATING\",\n+  \"rejectionType\":\"NULL_VAL\",\"rejectionReason\":\"\",\"position\":4294998112},\n+  reprocessing-record: {key=2251799813685255, sourceRecordPosition=4294997784,\n+  intent=WorkflowInstanceIntent:ELEMENT_ACTIVATING, recordType=EVENT}]\n+```\n+\n+  </p>\n+</details>\n+\n+In this case, the broker should be rolled back to the previous version and the backup should be restored. Ensure that the upgrade was prepared correctly. If it is still unclear why it was not successful then please contact the Zeebe team and ask for guidance.\n+\n+\n+## Rolling Upgrade", "originalCommit": "aef80dd7a8e1cfd1460ec1680def4f07d5c08117", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzE1MjY4NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/5534#discussion_r503152685", "bodyText": "In 0.23.7 the endpoint is http://{zeebe-broker}:{zeebe.broker.network.monitoringApi.port}/partitions and cannot be disabled.", "author": "deepthidevaki", "createdAt": "2020-10-12T09:13:20Z", "path": "docs/src/operations/upgrade.md", "diffHunk": "@@ -0,0 +1,152 @@\n+# Upgrade Zeebe\n+\n+This section describes how to upgrade Zeebe to a new version.\n+\n+> **Important:** Currently, we are facing an issue that can corrupt the data when upgrading to a new version. The issue affects the reprocessing (i.e. rehydrating the data from the records on the log stream) and can be omitted by restoring the data from a snapshot. Please follow the recommended procedure to minimize the risk of losing data.\n+\n+## Upgrade Procedure\n+\n+The following procedure describes how upgrade a broker. If the cluster contains multiple brokers then these steps can be done for all brokers in parallel. Standalone gateways should be upgrade after all brokers in the cluster are upgrade to avoid mismatches in the protocol version.\n+\n+Note that this procedure results in a downtime of the whole cluster. Currently, a rolling upgrade is not recommended to avoid that an upgraded broker do reprocessing and is affected by the issue.\n+\n+> TODO: describe how to perform the upgrade on Kubernetes/Helm\n+\n+### Preparing the Upgrade\n+\n+#### From broker version < 24.4\n+\n+1. Stop the workflow processing\n+    * Close all job workers\n+    * Interrupt the incoming connections to avoid user commands\n+1. Wait until a snapshot is created for all partitions\n+    * By default, a snapshot is created every 15 minutes\n+    * Verify that a snapshot is created by looking at the [Metric](/operations/metrics.md) `zeebe_snapshot_count` on the leader and the followers\n+    * Note that no snapshot is created if no processing happened since the last snapshot\n+1. Make a backup of the `data` folder\n+\n+#### From broker version >= 24.4\n+\n+The [Partitions Admin Endpoint](#partitions-admin-endpoint) can be used to query the status of the partitions and perform operations for the upgrade.\n+\n+1. Stop the workflow processing and trigger a snapshot creation\n+    * Call the `prepareUpgrade` operation on the partitions endpoint\n+    * Query the status of the partitions until the following conditions are met for all partitions:\n+        * `processedPositionInSnapshot` is equal to `processedPosition`\n+        * all followers (role: `FOLLOWER`) have the same `snapshotId` as the leader (role: `LEADER`)\n+1. Make a backup of the `data` folder\n+\n+### Performing the Upgrade\n+\n+1. Shut down the broker\n+1. Replace the `/bin` and `/lib` folders with the versions of the new distribution\n+1. Start up the broker\n+\n+### Verifying the Upgrade\n+\n+The upgrade is successful if the following conditions are met:\n+\n+* the broker is ready (see [Ready Check](/operations/health.md#ready-check))\n+* the broker is healthy (see [Health Check](/operations/health.md#health-check))\n+* all partitions are healthy (see the [Metric](/operations/metrics.md#metrics-related-to-health) `zeebe_health`)\n+* the stream processors of the partition leaders are in the phase `PROCESSING` (see [Partitions Admin Endpoint](#partitions-admin-endpoint))\n+\n+If the upgrade failed because of a known issue then a partition change its status to unhealthy, and the log output may contain the following error message:\n+\n+<details>\n+  <summary>Sample Upgrade Error Message</summary>\n+  <p>\n+\n+```\n+Unexpected error on recovery happens.\n+io.zeebe.engine.processor.InconsistentReprocessingException: Reprocessing issue detected!\n+  Restore the data from a backup and follow the recommended upgrade procedure. [cause:\n+  \"The key of the record on the log stream doesn't match to the record from reprocessing.\",\n+  log-stream-record: {\"partitionId\":1,\"value\":{\"version\":1,\"bpmnProcessId\":\"parallel-tasks\",\n+  \"workflowKey\":2251799813685249,\"parentElementInstanceKey\":-1,\"parentWorkflowInstanceKey\":-1,\n+  \"bpmnElementType\":\"PARALLEL_GATEWAY\",\"flowScopeKey\":2251799813685251,\n+  \"elementId\":\"ExclusiveGateway_0tkgnd5\",\"workflowInstanceKey\":2251799813685251},\n+  \"key\":2251799813685256,\"sourceRecordPosition\":4294997784,\"valueType\":\"WORKFLOW_INSTANCE\",\n+  \"timestamp\":1601025180728,\"recordType\":\"EVENT\",\"intent\":\"ELEMENT_ACTIVATING\",\n+  \"rejectionType\":\"NULL_VAL\",\"rejectionReason\":\"\",\"position\":4294998112},\n+  reprocessing-record: {key=2251799813685255, sourceRecordPosition=4294997784,\n+  intent=WorkflowInstanceIntent:ELEMENT_ACTIVATING, recordType=EVENT}]\n+```\n+\n+  </p>\n+</details>\n+\n+In this case, the broker should be rolled back to the previous version and the backup should be restored. Ensure that the upgrade was prepared correctly. If it is still unclear why it was not successful then please contact the Zeebe team and ask for guidance.\n+\n+\n+## Rolling Upgrade\n+\n+Zeebe is designed to allow a rolling upgrade of a cluster. The brokers can be upgrade one after each other. The other brokers in the cluster continue processing until the whole upgrade is done.\n+\n+1. Upgrade the first broker and wait until it is ready again\n+1. Continue with the next broker until all brokers are upgraded\n+1. Upgrade the standalone gateways\n+\n+> Because of current issue, it is not recommended performing a rolling upgrade. Please follow the upgrade procedure instead.\n+\n+## Partitions Admin Endpoint\n+\n+This endpoint allows querying the status of the partitions and performing operations to prepare an upgrade.\n+\n+It is available under `http://{zeebe-broker}:{zeebe.broker.network.monitoringApi.port}/actuator/partitions` (default port: `9600`).", "originalCommit": "aef80dd7a8e1cfd1460ec1680def4f07d5c08117", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzE1MzUzMw==", "url": "https://github.com/camunda-cloud/zeebe/pull/5534#discussion_r503153533", "bodyText": "Can we link to a specific issue here?", "author": "deepthidevaki", "createdAt": "2020-10-12T09:14:45Z", "path": "docs/src/operations/upgrade.md", "diffHunk": "@@ -0,0 +1,152 @@\n+# Upgrade Zeebe\n+\n+This section describes how to upgrade Zeebe to a new version.\n+\n+> **Important:** Currently, we are facing an issue that can corrupt the data when upgrading to a new version. The issue affects the reprocessing (i.e. rehydrating the data from the records on the log stream) and can be omitted by restoring the data from a snapshot. Please follow the recommended procedure to minimize the risk of losing data.", "originalCommit": "aef80dd7a8e1cfd1460ec1680def4f07d5c08117", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2NzY3Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/5534#discussion_r503667672", "bodyText": "You're not the first one asking this \ud83d\ude05 We have no explicit issue yet. I'll create one and link it here.", "author": "saig0", "createdAt": "2020-10-13T05:00:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzE1MzUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzg4NzM4Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/5534#discussion_r503887387", "bodyText": "So, here is the issue: #5581", "author": "saig0", "createdAt": "2020-10-13T11:51:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzE1MzUzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzE1NTE1Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/5534#discussion_r503155157", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Zeebe is designed to allow a rolling upgrade of a cluster. The brokers can be upgrade one after each other. The other brokers in the cluster continue processing until the whole upgrade is done.\n          \n          \n            \n            Zeebe is designed to allow a rolling upgrade of a cluster. The brokers can be upgrade one after the other. The other brokers in the cluster continue processing until the whole upgrade is done.", "author": "deepthidevaki", "createdAt": "2020-10-12T09:17:11Z", "path": "docs/src/operations/upgrade.md", "diffHunk": "@@ -0,0 +1,152 @@\n+# Upgrade Zeebe\n+\n+This section describes how to upgrade Zeebe to a new version.\n+\n+> **Important:** Currently, we are facing an issue that can corrupt the data when upgrading to a new version. The issue affects the reprocessing (i.e. rehydrating the data from the records on the log stream) and can be omitted by restoring the data from a snapshot. Please follow the recommended procedure to minimize the risk of losing data.\n+\n+## Upgrade Procedure\n+\n+The following procedure describes how upgrade a broker. If the cluster contains multiple brokers then these steps can be done for all brokers in parallel. Standalone gateways should be upgrade after all brokers in the cluster are upgrade to avoid mismatches in the protocol version.\n+\n+Note that this procedure results in a downtime of the whole cluster. Currently, a rolling upgrade is not recommended to avoid that an upgraded broker do reprocessing and is affected by the issue.\n+\n+> TODO: describe how to perform the upgrade on Kubernetes/Helm\n+\n+### Preparing the Upgrade\n+\n+#### From broker version < 24.4\n+\n+1. Stop the workflow processing\n+    * Close all job workers\n+    * Interrupt the incoming connections to avoid user commands\n+1. Wait until a snapshot is created for all partitions\n+    * By default, a snapshot is created every 15 minutes\n+    * Verify that a snapshot is created by looking at the [Metric](/operations/metrics.md) `zeebe_snapshot_count` on the leader and the followers\n+    * Note that no snapshot is created if no processing happened since the last snapshot\n+1. Make a backup of the `data` folder\n+\n+#### From broker version >= 24.4\n+\n+The [Partitions Admin Endpoint](#partitions-admin-endpoint) can be used to query the status of the partitions and perform operations for the upgrade.\n+\n+1. Stop the workflow processing and trigger a snapshot creation\n+    * Call the `prepareUpgrade` operation on the partitions endpoint\n+    * Query the status of the partitions until the following conditions are met for all partitions:\n+        * `processedPositionInSnapshot` is equal to `processedPosition`\n+        * all followers (role: `FOLLOWER`) have the same `snapshotId` as the leader (role: `LEADER`)\n+1. Make a backup of the `data` folder\n+\n+### Performing the Upgrade\n+\n+1. Shut down the broker\n+1. Replace the `/bin` and `/lib` folders with the versions of the new distribution\n+1. Start up the broker\n+\n+### Verifying the Upgrade\n+\n+The upgrade is successful if the following conditions are met:\n+\n+* the broker is ready (see [Ready Check](/operations/health.md#ready-check))\n+* the broker is healthy (see [Health Check](/operations/health.md#health-check))\n+* all partitions are healthy (see the [Metric](/operations/metrics.md#metrics-related-to-health) `zeebe_health`)\n+* the stream processors of the partition leaders are in the phase `PROCESSING` (see [Partitions Admin Endpoint](#partitions-admin-endpoint))\n+\n+If the upgrade failed because of a known issue then a partition change its status to unhealthy, and the log output may contain the following error message:\n+\n+<details>\n+  <summary>Sample Upgrade Error Message</summary>\n+  <p>\n+\n+```\n+Unexpected error on recovery happens.\n+io.zeebe.engine.processor.InconsistentReprocessingException: Reprocessing issue detected!\n+  Restore the data from a backup and follow the recommended upgrade procedure. [cause:\n+  \"The key of the record on the log stream doesn't match to the record from reprocessing.\",\n+  log-stream-record: {\"partitionId\":1,\"value\":{\"version\":1,\"bpmnProcessId\":\"parallel-tasks\",\n+  \"workflowKey\":2251799813685249,\"parentElementInstanceKey\":-1,\"parentWorkflowInstanceKey\":-1,\n+  \"bpmnElementType\":\"PARALLEL_GATEWAY\",\"flowScopeKey\":2251799813685251,\n+  \"elementId\":\"ExclusiveGateway_0tkgnd5\",\"workflowInstanceKey\":2251799813685251},\n+  \"key\":2251799813685256,\"sourceRecordPosition\":4294997784,\"valueType\":\"WORKFLOW_INSTANCE\",\n+  \"timestamp\":1601025180728,\"recordType\":\"EVENT\",\"intent\":\"ELEMENT_ACTIVATING\",\n+  \"rejectionType\":\"NULL_VAL\",\"rejectionReason\":\"\",\"position\":4294998112},\n+  reprocessing-record: {key=2251799813685255, sourceRecordPosition=4294997784,\n+  intent=WorkflowInstanceIntent:ELEMENT_ACTIVATING, recordType=EVENT}]\n+```\n+\n+  </p>\n+</details>\n+\n+In this case, the broker should be rolled back to the previous version and the backup should be restored. Ensure that the upgrade was prepared correctly. If it is still unclear why it was not successful then please contact the Zeebe team and ask for guidance.\n+\n+\n+## Rolling Upgrade\n+\n+Zeebe is designed to allow a rolling upgrade of a cluster. The brokers can be upgrade one after each other. The other brokers in the cluster continue processing until the whole upgrade is done.", "originalCommit": "aef80dd7a8e1cfd1460ec1680def4f07d5c08117", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "53017c35bd45b6c75a88baa6a2c253a47c3f9375", "url": "https://github.com/camunda-cloud/zeebe/commit/53017c35bd45b6c75a88baa6a2c253a47c3f9375", "message": "docs(operations): add the upgrade guide\n\n* add a new section that describe how to upgrade Zeebe", "committedDate": "2020-10-14T04:32:21Z", "type": "commit"}, {"oid": "53017c35bd45b6c75a88baa6a2c253a47c3f9375", "url": "https://github.com/camunda-cloud/zeebe/commit/53017c35bd45b6c75a88baa6a2c253a47c3f9375", "message": "docs(operations): add the upgrade guide\n\n* add a new section that describe how to upgrade Zeebe", "committedDate": "2020-10-14T04:32:21Z", "type": "forcePushed"}]}