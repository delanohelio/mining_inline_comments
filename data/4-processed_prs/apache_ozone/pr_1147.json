{"pr_number": 1147, "pr_title": "HDDS-3892. Datanode initialization is too slow when there are thousan\u2026", "pr_createdAt": "2020-06-29T08:30:20Z", "pr_url": "https://github.com/apache/ozone/pull/1147", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg4MDQxNg==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r446880416", "bodyText": "What happens to the ReferenceCountedDB instance created at line 140 if we return here?\nDo we need to call db.cleanup() on the newly created instance, and if we don't could this potentially leak db objects? I note that the remove() call in ContainerCache calls db.cleanup when removing the entry, which makes we suspect this is important.\nIf we do need to call cleanup() on it, we can probably capture the return value inside the lock and then call cleanup() from outside the lock and then return?", "author": "sodonnel", "createdAt": "2020-06-29T09:45:20Z", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/utils/ContainerCache.java", "diffHunk": "@@ -117,28 +117,47 @@ public ReferenceCountedDB getDB(long containerID, String containerDBType,\n       throws IOException {\n     Preconditions.checkState(containerID >= 0,\n         \"Container ID cannot be negative.\");\n+    ReferenceCountedDB db;\n     lock.lock();\n     try {\n-      ReferenceCountedDB db = (ReferenceCountedDB) this.get(containerDBPath);\n-\n-      if (db == null) {\n-        MetadataStore metadataStore =\n-            MetadataStoreBuilder.newBuilder()\n-            .setDbFile(new File(containerDBPath))\n-            .setCreateIfMissing(false)\n-            .setConf(conf)\n-            .setDBType(containerDBType)\n-            .build();\n-        db = new ReferenceCountedDB(metadataStore, containerDBPath);\n-        this.put(containerDBPath, db);\n+      db = (ReferenceCountedDB) this.get(containerDBPath);\n+      if (db != null) {\n+        db.incrementReference();\n+        return db;\n       }\n-      // increment the reference before returning the object\n-      db.incrementReference();\n-      return db;\n+    } finally {\n+      lock.unlock();\n+    }\n+\n+    try {\n+      MetadataStore metadataStore =\n+          MetadataStoreBuilder.newBuilder()\n+              .setDbFile(new File(containerDBPath))\n+              .setCreateIfMissing(false)\n+              .setConf(conf)\n+              .setDBType(containerDBType)\n+              .build();\n+      db = new ReferenceCountedDB(metadataStore, containerDBPath);\n     } catch (Exception e) {\n       LOG.error(\"Error opening DB. Container:{} ContainerPath:{}\",\n           containerID, containerDBPath, e);\n       throw e;\n+    }\n+\n+    lock.lock();\n+    try {\n+      ReferenceCountedDB currentDB =\n+          (ReferenceCountedDB) this.get(containerDBPath);\n+      if (currentDB != null) {\n+        // increment the reference before returning the object\n+        currentDB.incrementReference();\n+        return currentDB;", "originalCommit": "eba15e24fc61c66d65d82723c24cf201b77f9593", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk1OTY5OQ==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r446959699", "bodyText": "Thanks for the review. You're right.  The new DB instance should be explicitely closed in this case.", "author": "ChenSammi", "createdAt": "2020-06-29T13:12:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg4MDQxNg=="}], "type": "inlineReview"}, {"oid": "95836d2443ea4774becc7f2003e3ea49239780d2", "url": "https://github.com/apache/ozone/commit/95836d2443ea4774becc7f2003e3ea49239780d2", "message": "HDDS-3892. Datanode initialization is too slow when there are thousands of containers per volume.", "committedDate": "2020-07-03T10:04:52Z", "type": "commit"}, {"oid": "9dda984a9c1a588fc2d8a55a61c7a74b01e62be8", "url": "https://github.com/apache/ozone/commit/9dda984a9c1a588fc2d8a55a61c7a74b01e62be8", "message": "release db resource", "committedDate": "2020-07-03T10:04:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDE4Mjk1OQ==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r450182959", "bodyText": "I see one issue with this approach.\nIf the database is already opened, and if we try to open again we will get this error.\nI think, with this change, we will throw an exception if we try to open the database again an already existing one.\njava.io.IOException: Failed init RocksDB, db path : /Users/bviswanadham/workspace/hadoop-ozone/hadoop-hdds/container-service/target/test-dir/xCkBnsLVrc/cont1, exception :org.rocksdb.RocksDBException lock : /Users/bviswanadham/workspace/hadoop-ozone/hadoop-hdds/container-service/target/test-dir/xCkBnsLVrc/cont1/LOCK: No locks available\n\n@bharatviswa504 , I get your point. It's an issue, but not introduced by this patch. It's a currenlty existing issue and we need to carefully think about how to fix it with a new JIRA.\n\n@ChenSammi can you please clarify why you think it's an existing issue?  It seems to me that calling build() outside of the lock introduces this problem.\nIf I understand correctly, the performance issue is due to using a single lock for all containers.  Instead of moving the expensive part outside of the lock, how about using a separate lock per containerDBPath?", "author": "adoroszlai", "createdAt": "2020-07-06T12:22:12Z", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/utils/ContainerCache.java", "diffHunk": "@@ -117,28 +117,49 @@ public ReferenceCountedDB getDB(long containerID, String containerDBType,\n       throws IOException {\n     Preconditions.checkState(containerID >= 0,\n         \"Container ID cannot be negative.\");\n+    ReferenceCountedDB db;\n     lock.lock();\n     try {\n-      ReferenceCountedDB db = (ReferenceCountedDB) this.get(containerDBPath);\n-\n-      if (db == null) {\n-        MetadataStore metadataStore =\n-            MetadataStoreBuilder.newBuilder()\n-            .setDbFile(new File(containerDBPath))\n-            .setCreateIfMissing(false)\n-            .setConf(conf)\n-            .setDBType(containerDBType)\n-            .build();\n-        db = new ReferenceCountedDB(metadataStore, containerDBPath);\n-        this.put(containerDBPath, db);\n+      db = (ReferenceCountedDB) this.get(containerDBPath);\n+      if (db != null) {\n+        db.incrementReference();\n+        return db;\n       }\n-      // increment the reference before returning the object\n-      db.incrementReference();\n-      return db;\n+    } finally {\n+      lock.unlock();\n+    }\n+\n+    try {\n+      MetadataStore metadataStore =\n+          MetadataStoreBuilder.newBuilder()\n+              .setDbFile(new File(containerDBPath))\n+              .setCreateIfMissing(false)\n+              .setConf(conf)\n+              .setDBType(containerDBType)\n+              .build();", "originalCommit": "ee4df7996d0071e32b0e057b775d36a07fe0bc38", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTQwODI1MQ==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r451408251", "bodyText": "@adoroszlai, OK, I get the point now.  During the datanode initialization phase, actually there is no change a DB will be opened concurrently.  But since this function is also used in late phase, there is possibility to trigger the exception.", "author": "ChenSammi", "createdAt": "2020-07-08T09:27:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDE4Mjk1OQ=="}], "type": "inlineReview"}, {"oid": "5dd9a0fda5f345f6e71d3fa0cdec07e4e1f197c4", "url": "https://github.com/apache/ozone/commit/5dd9a0fda5f345f6e71d3fa0cdec07e4e1f197c4", "message": "address concurrent rocksdb open case", "committedDate": "2020-07-09T09:56:05Z", "type": "commit"}, {"oid": "5dd9a0fda5f345f6e71d3fa0cdec07e4e1f197c4", "url": "https://github.com/apache/ozone/commit/5dd9a0fda5f345f6e71d3fa0cdec07e4e1f197c4", "message": "address concurrent rocksdb open case", "committedDate": "2020-07-09T09:56:05Z", "type": "forcePushed"}, {"oid": "15ec4d3c266dc13f5ce9d1b847a93119c73d389f", "url": "https://github.com/apache/ozone/commit/15ec4d3c266dc13f5ce9d1b847a93119c73d389f", "message": "fix checkstyle", "committedDate": "2020-07-09T11:28:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0Nzg4OQ==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r454947889", "bodyText": "If I understand correctly, you have created a boolean to either lock or not lock in this method. In the DN initialization logic, you pass false here to avoid locking, as the same container will not be initialized by multiple threads at once.\nI am still not sure this is safe, specifically the line:\nthis.put(containerDBPath, db);\n\nContainerCache is an instance of LRUCache and the JavaDoc says:\n\nNote that LRUMap is not synchronized and is not thread-safe.\nIf you wish to use this map from multiple threads concurrently, you must use\nappropriate synchronization.\n\nTherefore I think you must lock around access and writes to the LRU Cache.\nI also worry about removing locking completely incase someone passes \"false\" mistakenly to this method in the future.\n@adoroszlai Earlier suggested using a lock per container path. We might be able to use a Guava Striped lock here with something like 256 buckets.\nCould we do something like:\n  public ReferenceCountedDB getDB(long containerID, String containerDBType,\n                             String containerDBPath, ConfigurationSource conf)\n      throws IOException {\n    Preconditions.checkState(containerID >= 0,\n        \"Container ID cannot be negative.\");\n    ReferenceCountedDB db = null;\n    Lock slock = stripedLock.get(containerDBPath);\n    slock.lock();\n    try {\n      lock.lock();\n      try {\n        db = (ReferenceCountedDB) this.get(containerDBPath);\n      } finally {\n        lock.unlock();\n      }\n      if (db == null) {\n        MetadataStore metadataStore =\n            MetadataStoreBuilder.newBuilder()\n                .setDbFile(new File(containerDBPath))\n                .setCreateIfMissing(false)\n                .setConf(conf)\n                .setDBType(containerDBType)\n                .build();\n        db = new ReferenceCountedDB(metadataStore, containerDBPath);\n        addDB(containerDBPath, db);\n      }\n      db.incrementReference();\n      return db;\n    } catch (Exception e) {\n      LOG.error(\"Error opening DB. Container:{} ContainerPath:{}\",\n          containerID, containerDBPath, e);\n      throw e;\n    } finally {\n      slock.unlock();\n    }\n  }\n\nWe still have the global lock to protect the ContainerCache structure, but we now have a stripped lock to ensure that the same ContainerPath cannot be initialized at the same time.\nI am not sure if we need to worry about another thread calling addDB and adding another instances of the same DB to the cache. Perhaps not a DN initialization time, but at runtime. If that is the case, we would need to add back the logic you had before, where you take the global lock again, and then test to see if an entry for the DB has been added to the cache, and if so close the new instance and return the cached one.", "author": "sodonnel", "createdAt": "2020-07-15T10:21:23Z", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/utils/ContainerCache.java", "diffHunk": "@@ -113,22 +113,41 @@ protected boolean removeLRU(LinkEntry entry) {\n    * @return ReferenceCountedDB.\n    */\n   public ReferenceCountedDB getDB(long containerID, String containerDBType,\n-                             String containerDBPath, ConfigurationSource conf)\n+      String containerDBPath, ConfigurationSource conf)\n+      throws IOException {\n+    return getDB(containerID, containerDBType, containerDBPath, conf, true);\n+  }\n+  /**\n+   * Returns a DB handle if available, create the handler otherwise.\n+   *\n+   * @param containerID - ID of the container.\n+   * @param containerDBType - DB type of the container.\n+   * @param containerDBPath - DB path of the container.\n+   * @param acquireLock - false only for one-time ContainerReader execution\n+   *                    during datanode initialization. Don't set it to false\n+   *                    in other cases.\n+   * @param conf - Hadoop Configuration.\n+   * @return ReferenceCountedDB.\n+   */\n+  public ReferenceCountedDB getDB(long containerID, String containerDBType,\n+      String containerDBPath, ConfigurationSource conf, boolean acquireLock)\n       throws IOException {\n     Preconditions.checkState(containerID >= 0,\n         \"Container ID cannot be negative.\");\n-    lock.lock();\n+    ReferenceCountedDB db;\n+    if (acquireLock) {\n+      lock.lock();\n+    }\n     try {\n-      ReferenceCountedDB db = (ReferenceCountedDB) this.get(containerDBPath);\n-\n+      db = (ReferenceCountedDB) this.get(containerDBPath);\n       if (db == null) {\n         MetadataStore metadataStore =\n             MetadataStoreBuilder.newBuilder()\n-            .setDbFile(new File(containerDBPath))\n-            .setCreateIfMissing(false)\n-            .setConf(conf)\n-            .setDBType(containerDBType)\n-            .build();\n+                .setDbFile(new File(containerDBPath))\n+                .setCreateIfMissing(false)\n+                .setConf(conf)\n+                .setDBType(containerDBType)\n+                .build();\n         db = new ReferenceCountedDB(metadataStore, containerDBPath);\n         this.put(containerDBPath, db);", "originalCommit": "15ec4d3c266dc13f5ce9d1b847a93119c73d389f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk1NzEyMQ==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r454957121", "bodyText": "Thinking about this some more, it might be safest to wrap addDB and removeDB with the strippedLock too, as that way we ensure only one DB instance can be initialized and added to the map at any given time.\n@adoroszlai might have some better idea than me on this too?", "author": "sodonnel", "createdAt": "2020-07-15T10:38:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0Nzg4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ4MDA0NQ==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r455480045", "bodyText": "Thanks @sodonnel , I will take a look at the StrippedLock.", "author": "ChenSammi", "createdAt": "2020-07-16T02:58:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk0Nzg4OQ=="}], "type": "inlineReview"}, {"oid": "20b694ad0d6155df0eb9b5091ed3d6caef85ab37", "url": "https://github.com/apache/ozone/commit/20b694ad0d6155df0eb9b5091ed3d6caef85ab37", "message": "Revert \"fix checkstyle\"\n\nThis reverts commit 15ec4d3c266dc13f5ce9d1b847a93119c73d389f.", "committedDate": "2020-07-16T12:22:31Z", "type": "commit"}, {"oid": "fa37b9f398aa089cb023d813c5a6aebd4ac2d6ad", "url": "https://github.com/apache/ozone/commit/fa37b9f398aa089cb023d813c5a6aebd4ac2d6ad", "message": "Revert \"address concurrent rocksdb open case\"\n\nThis reverts commit 5dd9a0fda5f345f6e71d3fa0cdec07e4e1f197c4.", "committedDate": "2020-07-16T12:22:42Z", "type": "commit"}, {"oid": "71b4571af9985d47c0d2ec5859ed5c7f6f7a4892", "url": "https://github.com/apache/ozone/commit/71b4571af9985d47c0d2ec5859ed5c7f6f7a4892", "message": "Use striped lock", "committedDate": "2020-07-17T02:52:23Z", "type": "commit"}, {"oid": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "url": "https://github.com/apache/ozone/commit/b4060aa590e4e5f7c8a40070e64177abab5ad274", "message": "checkstyle", "committedDate": "2020-07-17T03:48:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM3MjQyMg==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456372422", "bodyText": "This cleanup() call may be expensive, and ideally it should be outside the lock. However, I think it will be very rare where you hit this scenario and therefore I think the logic is OK as it is now.", "author": "sodonnel", "createdAt": "2020-07-17T10:58:39Z", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/utils/ContainerCache.java", "diffHunk": "@@ -117,30 +119,57 @@ public ReferenceCountedDB getDB(long containerID, String containerDBType,\n       throws IOException {\n     Preconditions.checkState(containerID >= 0,\n         \"Container ID cannot be negative.\");\n-    lock.lock();\n+    ReferenceCountedDB db;\n+    Lock containerLock = rocksDBLock.get(containerDBPath);\n+    containerLock.lock();\n     try {\n-      ReferenceCountedDB db = (ReferenceCountedDB) this.get(containerDBPath);\n+      lock.lock();\n+      try {\n+        db = (ReferenceCountedDB) this.get(containerDBPath);\n+        if (db != null) {\n+          db.incrementReference();\n+          return db;\n+        }\n+      } finally {\n+        lock.unlock();\n+      }\n \n-      if (db == null) {\n+      try {\n         MetadataStore metadataStore =\n             MetadataStoreBuilder.newBuilder()\n-            .setDbFile(new File(containerDBPath))\n-            .setCreateIfMissing(false)\n-            .setConf(conf)\n-            .setDBType(containerDBType)\n-            .build();\n+                .setDbFile(new File(containerDBPath))\n+                .setCreateIfMissing(false)\n+                .setConf(conf)\n+                .setDBType(containerDBType)\n+                .build();\n         db = new ReferenceCountedDB(metadataStore, containerDBPath);\n-        this.put(containerDBPath, db);\n+      } catch (Exception e) {\n+        LOG.error(\"Error opening DB. Container:{} ContainerPath:{}\",\n+            containerID, containerDBPath, e);\n+        throw e;\n+      }\n+\n+      lock.lock();\n+      try {\n+        ReferenceCountedDB currentDB =\n+            (ReferenceCountedDB) this.get(containerDBPath);\n+        if (currentDB != null) {\n+          // increment the reference before returning the object\n+          currentDB.incrementReference();\n+          // clean the db created in previous step\n+          db.cleanup();", "originalCommit": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM5ODUzOA==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456398538", "bodyText": "OK.", "author": "ChenSammi", "createdAt": "2020-07-17T12:02:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjM3MjQyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ1NjMxMg==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456456312", "bodyText": "Would be nice to make the number of stripes configurable (later).", "author": "adoroszlai", "createdAt": "2020-07-17T13:52:35Z", "path": "hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/utils/ContainerCache.java", "diffHunk": "@@ -43,6 +44,7 @@\n   private final Lock lock = new ReentrantLock();\n   private static ContainerCache cache;\n   private static final float LOAD_FACTOR = 0.75f;\n+  private final Striped<Lock> rocksDBLock = Striped.lazyWeakLock(1024);", "originalCommit": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ1NzU2OA==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456457568", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Assert.assertTrue(cache.size() == 0);\n          \n          \n            \n                Assert.assertEquals(0, cache.size());", "author": "adoroszlai", "createdAt": "2020-07-17T13:54:48Z", "path": "hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/TestContainerCache.java", "diffHunk": "@@ -63,6 +70,8 @@ public void testContainerCacheEviction() throws Exception {\n     conf.setInt(OzoneConfigKeys.OZONE_CONTAINER_CACHE_SIZE, 2);\n \n     ContainerCache cache = ContainerCache.getInstance(conf);\n+    cache.clear();\n+    Assert.assertTrue(cache.size() == 0);", "originalCommit": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ1Nzc0Mw==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456457743", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Assert.assertTrue(cache.size() == 0);\n          \n          \n            \n                Assert.assertEquals(0, cache.size());", "author": "adoroszlai", "createdAt": "2020-07-17T13:55:02Z", "path": "hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/TestContainerCache.java", "diffHunk": "@@ -123,4 +132,47 @@ public void testContainerCacheEviction() throws Exception {\n     thrown.expect(IllegalArgumentException.class);\n     db5.close();\n   }\n+\n+  @Test\n+  public void testConcurrentDBGet() throws Exception {\n+    File root = new File(testRoot);\n+    root.mkdirs();\n+    root.deleteOnExit();\n+\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(OzoneConfigKeys.OZONE_CONTAINER_CACHE_SIZE, 2);\n+    ContainerCache cache = ContainerCache.getInstance(conf);\n+    cache.clear();\n+    Assert.assertTrue(cache.size() == 0);", "originalCommit": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ1Nzg0NQ==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456457845", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Assert.assertTrue(cache.size() == 1);\n          \n          \n            \n                Assert.assertEquals(1, cache.size());", "author": "adoroszlai", "createdAt": "2020-07-17T13:55:12Z", "path": "hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/TestContainerCache.java", "diffHunk": "@@ -123,4 +132,47 @@ public void testContainerCacheEviction() throws Exception {\n     thrown.expect(IllegalArgumentException.class);\n     db5.close();\n   }\n+\n+  @Test\n+  public void testConcurrentDBGet() throws Exception {\n+    File root = new File(testRoot);\n+    root.mkdirs();\n+    root.deleteOnExit();\n+\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(OzoneConfigKeys.OZONE_CONTAINER_CACHE_SIZE, 2);\n+    ContainerCache cache = ContainerCache.getInstance(conf);\n+    cache.clear();\n+    Assert.assertTrue(cache.size() == 0);\n+    File containerDir = new File(root, \"cont1\");\n+    createContainerDB(conf, containerDir);\n+    ExecutorService executorService = Executors.newFixedThreadPool(2);\n+    Runnable task = () -> {\n+      try {\n+        ReferenceCountedDB db1 = cache.getDB(1, \"RocksDB\",\n+            containerDir.getPath(), conf);\n+        Assert.assertTrue(db1 != null);\n+      } catch (IOException e) {\n+        Assert.fail(\"Should get the DB instance\");\n+      }\n+    };\n+    List<Future> futureList = new ArrayList<>();\n+    futureList.add(executorService.submit(task));\n+    futureList.add(executorService.submit(task));\n+    for (Future future: futureList) {\n+      try {\n+        future.get();\n+      } catch (InterruptedException| ExecutionException e) {\n+        Assert.fail(\"Should get the DB instance\");\n+      }\n+    }\n+\n+    ReferenceCountedDB db = cache.getDB(1, \"RocksDB\",\n+        containerDir.getPath(), conf);\n+    db.close();\n+    db.close();\n+    db.close();\n+    Assert.assertTrue(cache.size() == 1);", "originalCommit": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ1ODQ4NA==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456458484", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Assert.assertTrue(db1 != null);\n          \n          \n            \n                    Assert.assertNotNull(db1);", "author": "adoroszlai", "createdAt": "2020-07-17T13:56:13Z", "path": "hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/TestContainerCache.java", "diffHunk": "@@ -123,4 +132,47 @@ public void testContainerCacheEviction() throws Exception {\n     thrown.expect(IllegalArgumentException.class);\n     db5.close();\n   }\n+\n+  @Test\n+  public void testConcurrentDBGet() throws Exception {\n+    File root = new File(testRoot);\n+    root.mkdirs();\n+    root.deleteOnExit();\n+\n+    OzoneConfiguration conf = new OzoneConfiguration();\n+    conf.setInt(OzoneConfigKeys.OZONE_CONTAINER_CACHE_SIZE, 2);\n+    ContainerCache cache = ContainerCache.getInstance(conf);\n+    cache.clear();\n+    Assert.assertTrue(cache.size() == 0);\n+    File containerDir = new File(root, \"cont1\");\n+    createContainerDB(conf, containerDir);\n+    ExecutorService executorService = Executors.newFixedThreadPool(2);\n+    Runnable task = () -> {\n+      try {\n+        ReferenceCountedDB db1 = cache.getDB(1, \"RocksDB\",\n+            containerDir.getPath(), conf);\n+        Assert.assertTrue(db1 != null);", "originalCommit": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ1ODg1Ng==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456458856", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Assert.assertTrue(\n          \n          \n            \n                    containerSet.getContainerMap().entrySet().size() == containerCount);\n          \n          \n            \n                Assert.assertEquals(containerCount,\n          \n          \n            \n                    containerSet.getContainerMap().entrySet().size());", "author": "adoroszlai", "createdAt": "2020-07-17T13:56:49Z", "path": "hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/ozoneimpl/TestContainerReader.java", "diffHunk": "@@ -219,4 +220,68 @@ public void testContainerReader() throws Exception {\n           keyValueContainerData.getNumPendingDeletionBlocks());\n     }\n   }\n+\n+  @Test\n+  public void testMultipleContainerReader() throws Exception {\n+    final int volumeNum = 10;\n+    StringBuffer datanodeDirs = new StringBuffer();\n+    File[] volumeDirs = new File[volumeNum];\n+    for (int i = 0; i < volumeNum; i++) {\n+      volumeDirs[i] = tempDir.newFolder();\n+      datanodeDirs = datanodeDirs.append(volumeDirs[i]).append(\",\");\n+    }\n+    conf.set(ScmConfigKeys.HDDS_DATANODE_DIR_KEY,\n+        datanodeDirs.toString());\n+    MutableVolumeSet volumeSets =\n+        new MutableVolumeSet(datanodeId.toString(), conf);\n+    ContainerCache cache = ContainerCache.getInstance(conf);\n+    cache.clear();\n+\n+    RoundRobinVolumeChoosingPolicy policy =\n+        new RoundRobinVolumeChoosingPolicy();\n+\n+    final int containerCount = 100;\n+    blockCount = containerCount;\n+    for (int i = 0; i < containerCount; i++) {\n+      KeyValueContainerData keyValueContainerData =\n+          new KeyValueContainerData(i, ChunkLayOutVersion.FILE_PER_BLOCK,\n+              (long) StorageUnit.GB.toBytes(5), UUID.randomUUID().toString(),\n+              datanodeId.toString());\n+\n+      KeyValueContainer keyValueContainer =\n+          new KeyValueContainer(keyValueContainerData,\n+              conf);\n+      keyValueContainer.create(volumeSets, policy, scmId);\n+\n+      List<Long> blkNames;\n+      if (i % 2 == 0) {\n+        blkNames = addBlocks(keyValueContainer, true);\n+        markBlocksForDelete(keyValueContainer, true, blkNames, i);\n+      } else {\n+        blkNames = addBlocks(keyValueContainer, false);\n+        markBlocksForDelete(keyValueContainer, false, blkNames, i);\n+      }\n+    }\n+\n+    List<HddsVolume> hddsVolumes = volumeSets.getVolumesList();\n+    ContainerReader[] containerReaders = new ContainerReader[volumeNum];\n+    Thread[] threads = new Thread[volumeNum];\n+    for (int i = 0; i < volumeNum; i++) {\n+      containerReaders[i] = new ContainerReader(volumeSets,\n+          hddsVolumes.get(i), containerSet, conf);\n+      threads[i] = new Thread(containerReaders[i]);\n+    }\n+    long startTime = System.currentTimeMillis();\n+    for (int i = 0; i < volumeNum; i++) {\n+      threads[i].start();\n+    }\n+    for (int i = 0; i < volumeNum; i++) {\n+      threads[i].join();\n+    }\n+    System.out.println(\"Open \" + volumeNum + \" Volume with \" + containerCount +\n+        \" costs \" + (System.currentTimeMillis() - startTime) / 1000 + \"s\");\n+    Assert.assertTrue(\n+        containerSet.getContainerMap().entrySet().size() == containerCount);", "originalCommit": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjQ1ODk5OA==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r456458998", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Assert.assertTrue(cache.size() == containerCount);\n          \n          \n            \n                Assert.assertEquals(containerCount, cache.size());", "author": "adoroszlai", "createdAt": "2020-07-17T13:57:05Z", "path": "hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/ozoneimpl/TestContainerReader.java", "diffHunk": "@@ -219,4 +220,68 @@ public void testContainerReader() throws Exception {\n           keyValueContainerData.getNumPendingDeletionBlocks());\n     }\n   }\n+\n+  @Test\n+  public void testMultipleContainerReader() throws Exception {\n+    final int volumeNum = 10;\n+    StringBuffer datanodeDirs = new StringBuffer();\n+    File[] volumeDirs = new File[volumeNum];\n+    for (int i = 0; i < volumeNum; i++) {\n+      volumeDirs[i] = tempDir.newFolder();\n+      datanodeDirs = datanodeDirs.append(volumeDirs[i]).append(\",\");\n+    }\n+    conf.set(ScmConfigKeys.HDDS_DATANODE_DIR_KEY,\n+        datanodeDirs.toString());\n+    MutableVolumeSet volumeSets =\n+        new MutableVolumeSet(datanodeId.toString(), conf);\n+    ContainerCache cache = ContainerCache.getInstance(conf);\n+    cache.clear();\n+\n+    RoundRobinVolumeChoosingPolicy policy =\n+        new RoundRobinVolumeChoosingPolicy();\n+\n+    final int containerCount = 100;\n+    blockCount = containerCount;\n+    for (int i = 0; i < containerCount; i++) {\n+      KeyValueContainerData keyValueContainerData =\n+          new KeyValueContainerData(i, ChunkLayOutVersion.FILE_PER_BLOCK,\n+              (long) StorageUnit.GB.toBytes(5), UUID.randomUUID().toString(),\n+              datanodeId.toString());\n+\n+      KeyValueContainer keyValueContainer =\n+          new KeyValueContainer(keyValueContainerData,\n+              conf);\n+      keyValueContainer.create(volumeSets, policy, scmId);\n+\n+      List<Long> blkNames;\n+      if (i % 2 == 0) {\n+        blkNames = addBlocks(keyValueContainer, true);\n+        markBlocksForDelete(keyValueContainer, true, blkNames, i);\n+      } else {\n+        blkNames = addBlocks(keyValueContainer, false);\n+        markBlocksForDelete(keyValueContainer, false, blkNames, i);\n+      }\n+    }\n+\n+    List<HddsVolume> hddsVolumes = volumeSets.getVolumesList();\n+    ContainerReader[] containerReaders = new ContainerReader[volumeNum];\n+    Thread[] threads = new Thread[volumeNum];\n+    for (int i = 0; i < volumeNum; i++) {\n+      containerReaders[i] = new ContainerReader(volumeSets,\n+          hddsVolumes.get(i), containerSet, conf);\n+      threads[i] = new Thread(containerReaders[i]);\n+    }\n+    long startTime = System.currentTimeMillis();\n+    for (int i = 0; i < volumeNum; i++) {\n+      threads[i].start();\n+    }\n+    for (int i = 0; i < volumeNum; i++) {\n+      threads[i].join();\n+    }\n+    System.out.println(\"Open \" + volumeNum + \" Volume with \" + containerCount +\n+        \" costs \" + (System.currentTimeMillis() - startTime) / 1000 + \"s\");\n+    Assert.assertTrue(\n+        containerSet.getContainerMap().entrySet().size() == containerCount);\n+    Assert.assertTrue(cache.size() == containerCount);", "originalCommit": "b4060aa590e4e5f7c8a40070e64177abab5ad274", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f86391b2c2d2b0b4de18162b88ceb14f97b3b6de", "url": "https://github.com/apache/ozone/commit/f86391b2c2d2b0b4de18162b88ceb14f97b3b6de", "message": "address comments", "committedDate": "2020-07-20T06:54:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEyNTkwNQ==", "url": "https://github.com/apache/ozone/pull/1147#discussion_r457125905", "bodyText": "Note minor typo: strips -> stripes, but I'm fine with both.", "author": "adoroszlai", "createdAt": "2020-07-20T07:22:32Z", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/OzoneConfigKeys.java", "diffHunk": "@@ -104,6 +104,9 @@\n   public static final String OZONE_CONTAINER_CACHE_SIZE =\n       \"ozone.container.cache.size\";\n   public static final int OZONE_CONTAINER_CACHE_DEFAULT = 1024;\n+  public static final String OZONE_CONTAINER_CACHE_LOCK_STRIPS =\n+      \"ozone.container.cache.lock.strips\";\n+  public static final int OZONE_CONTAINER_CACHE_LOCK_STRIPS_DEFAULT = 1024;", "originalCommit": "f86391b2c2d2b0b4de18162b88ceb14f97b3b6de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b53da4da747f419ededba258bdd39bc09fb16c51", "url": "https://github.com/apache/ozone/commit/b53da4da747f419ededba258bdd39bc09fb16c51", "message": "change strip to stripe", "committedDate": "2020-07-21T08:38:03Z", "type": "commit"}, {"oid": "2c9f550852446bc7d64bbac79c26f39bca7da61f", "url": "https://github.com/apache/ozone/commit/2c9f550852446bc7d64bbac79c26f39bca7da61f", "message": "add ozone.container.cache.lock.stripes in ozone-default.xml", "committedDate": "2020-07-21T12:43:01Z", "type": "commit"}]}