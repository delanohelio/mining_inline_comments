{"pr_number": 1484, "pr_title": "HDDS-4322. Add integration tests for Decommission and resolve issues detected by the tests.", "pr_createdAt": "2020-10-07T20:21:44Z", "pr_url": "https://github.com/apache/ozone/pull/1484", "timeline": [{"oid": "3acaf9c373864540b47077beb104234ac44eb533", "url": "https://github.com/apache/ozone/commit/3acaf9c373864540b47077beb104234ac44eb533", "message": "Add integration tests to prove datanodes can be decommissioned successfully", "committedDate": "2020-10-07T20:09:30Z", "type": "commit"}, {"oid": "cdd5c9723bbc6f170fd39944ce052673cb6fb89b", "url": "https://github.com/apache/ozone/commit/cdd5c9723bbc6f170fd39944ce052673cb6fb89b", "message": "Fixed checkstyle issues", "committedDate": "2020-10-07T20:52:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQxOTEyMw==", "url": "https://github.com/apache/ozone/pull/1484#discussion_r502419123", "bodyText": "Do we need it on info level? What is the expected frequency of this message?\nI can create a decom insight point to make it easier to see this message, if it's required for debugging...", "author": "elek", "createdAt": "2020-10-09T13:15:42Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/node/DatanodeAdminMonitorImpl.java", "diffHunk": "@@ -294,6 +294,9 @@ private boolean checkContainersReplicatedOnNode(DatanodeDetails dn)\n             \"in containerManager\", cid, dn);\n       }\n     }\n+    LOG.info(\"{} has {} sufficientlyReplicated, {} underReplicated and {} \" +", "originalCommit": "cdd5c9723bbc6f170fd39944ce052673cb6fb89b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ0NDI4MQ==", "url": "https://github.com/apache/ozone/pull/1484#discussion_r502444281", "bodyText": "That message would be printed for each decommissioned or maintenance node for each run of the replication monitor. The default now is 30 seconds, but that is probably too short, and we will need to change that default to something longer, maybe a minute or two.\nI think it is useful to have this information in the logs from a supportability perspective. It lets us see the progress of decommission, whether a node appears to be stuck, etc, and a few messages per minute only when nodes are decommissioning is not excessively noisy.", "author": "sodonnel", "createdAt": "2020-10-09T13:55:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQxOTEyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ0NTMxNA==", "url": "https://github.com/apache/ozone/pull/1484#discussion_r502445314", "bodyText": "These fields had been missed from the DatanodeDetails builder object, so when the DN reported back its \"persisted state\" the DN was always IN_SERVICE. Adding this change fixed that problem and allowed the state to be returned correctly.", "author": "sodonnel", "createdAt": "2020-10-09T13:57:08Z", "path": "hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/protocol/DatanodeDetails.java", "diffHunk": "@@ -476,6 +476,9 @@ public Builder setDatanodeDetails(DatanodeDetails details) {\n       this.setupTime = details.getSetupTime();\n       this.revision = details.getRevision();\n       this.buildDate = details.getBuildDate();\n+      this.persistedOpState = details.getPersistedOpState();\n+      this.persistedOpStateExpiryEpochSec =\n+          details.getPersistedOpStateExpiryEpochSec();\n       return this;", "originalCommit": "cdd5c9723bbc6f170fd39944ce052673cb6fb89b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ0Njk2Mg==", "url": "https://github.com/apache/ozone/pull/1484#discussion_r502446962", "bodyText": "If a DN is DECOMMISSIONING, and then SCM is restarted, SCM will forget all about the decommission nodes. Then the nodes will re-register with SCM and report they are DECOMMISSIONING. If the node is DECOMMISSIONING rather than DECOMMISSIONED, we need to get it back into the decommission workflow. This NewNodeHandler is invoked for a new registration of a Node, so this change continues the decom process.", "author": "sodonnel", "createdAt": "2020-10-09T13:59:31Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/node/NewNodeHandler.java", "diffHunk": "@@ -20,27 +20,49 @@\n \n import org.apache.hadoop.hdds.conf.ConfigurationSource;\n import org.apache.hadoop.hdds.protocol.DatanodeDetails;\n+import org.apache.hadoop.hdds.protocol.proto.HddsProtos;\n+import org.apache.hadoop.hdds.scm.node.states.NodeNotFoundException;\n import org.apache.hadoop.hdds.scm.pipeline.PipelineManager;\n import org.apache.hadoop.hdds.server.events.EventHandler;\n import org.apache.hadoop.hdds.server.events.EventPublisher;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n /**\n  * Handles New Node event.\n  */\n public class NewNodeHandler implements EventHandler<DatanodeDetails> {\n \n   private final PipelineManager pipelineManager;\n+  private final NodeDecommissionManager decommissionManager;\n   private final ConfigurationSource conf;\n+  private static final Logger LOG =\n+      LoggerFactory.getLogger(NewNodeHandler.class);\n \n   public NewNodeHandler(PipelineManager pipelineManager,\n+      NodeDecommissionManager decommissionManager,\n       ConfigurationSource conf) {\n     this.pipelineManager = pipelineManager;\n+    this.decommissionManager = decommissionManager;\n     this.conf = conf;\n   }\n \n   @Override\n   public void onMessage(DatanodeDetails datanodeDetails,\n       EventPublisher publisher) {\n     pipelineManager.triggerPipelineCreation();\n+    HddsProtos.NodeOperationalState opState\n+        = datanodeDetails.getPersistedOpState();\n+    if (datanodeDetails.getPersistedOpState()\n+        != HddsProtos.NodeOperationalState.IN_SERVICE) {\n+      try {\n+        decommissionManager.continueAdminForNode(datanodeDetails);\n+      } catch (NodeNotFoundException e) {\n+        // Should not happen, as the node has just registered to call this event\n+        // handler.\n+        LOG.warn(\"NodeNotFound when adding the node to the decommissionManager\",\n+            e);\n+      }\n+    }\n   }", "originalCommit": "cdd5c9723bbc6f170fd39944ce052673cb6fb89b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ0NzM0NQ==", "url": "https://github.com/apache/ozone/pull/1484#discussion_r502447345", "bodyText": "This facilitates nodes re-joining the workflow - will be called from NewNodeHandler.", "author": "sodonnel", "createdAt": "2020-10-09T14:00:09Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/node/NodeDecommissionManager.java", "diffHunk": "@@ -233,6 +233,22 @@ public synchronized void decommissionNodes(List nodes)\n     }\n   }\n \n+  /**\n+   * If a SCM is restarted, then upon re-registration the datanode will already\n+   * be in DECOMMISSIONING or ENTERING_MAINTENANCE state. In that case, it\n+   * needs to be added back into the monitor to track its progress.\n+   * @param dn Datanode to add back to tracking.\n+   * @throws NodeNotFoundException\n+   */\n+  public synchronized void continueAdminForNode(DatanodeDetails dn)\n+      throws NodeNotFoundException {\n+    NodeOperationalState opState = getNodeStatus(dn).getOperationalState();\n+    if (opState == NodeOperationalState.DECOMMISSIONING\n+        || opState == NodeOperationalState.ENTERING_MAINTENANCE) {\n+      monitor.startMonitoring(dn, 0);\n+    }\n+  }\n+", "originalCommit": "cdd5c9723bbc6f170fd39944ce052673cb6fb89b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ0OTExOQ==", "url": "https://github.com/apache/ozone/pull/1484#discussion_r502449119", "bodyText": "This code was lifted out of SCMNodeManager as it fits better here. The NodeStatus is now set as part of registration and before any events are triggered (eg PipelineCreation). Before there was a race condition, where the NodeStatus was IN_SERVICE and pipeline creation could be triggered. Then the state was quickly changed to DECOMMISSIONED etc.", "author": "sodonnel", "createdAt": "2020-10-09T14:02:30Z", "path": "hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/node/NodeStateManager.java", "diffHunk": "@@ -239,11 +239,32 @@ private void initializeStateMachines() {\n    */\n   public void addNode(DatanodeDetails datanodeDetails)\n       throws NodeAlreadyExistsException {\n-    nodeStateMap.addNode(datanodeDetails, new NodeStatus(\n-        NodeOperationalState.IN_SERVICE, nodeHealthSM.getInitialState()));\n+    NodeStatus newNodeStatus = newNodeStatus(datanodeDetails);\n+    nodeStateMap.addNode(datanodeDetails, newNodeStatus);\n     eventPublisher.fireEvent(SCMEvents.NEW_NODE, datanodeDetails);\n   }\n \n+  /**\n+   * When a node registers with SCM, the operational state stored on the\n+   * datanode is the source of truth. Therefore, if the datanode reports\n+   * anything other than IN_SERVICE on registration, the state in SCM should be\n+   * updated to reflect the datanode state.\n+   * @param dn DatanodeDetails reported by the datanode\n+   */\n+  private NodeStatus newNodeStatus(DatanodeDetails dn) {\n+    HddsProtos.NodeOperationalState dnOpState = dn.getPersistedOpState();\n+    if (dnOpState != NodeOperationalState.IN_SERVICE) {\n+      LOG.info(\"Updating nodeOperationalState on registration as the \" +\n+              \"datanode has a persisted state of {} and expiry of {}\",\n+          dnOpState, dn.getPersistedOpStateExpiryEpochSec());\n+      return new NodeStatus(dnOpState, nodeHealthSM.getInitialState(),\n+          dn.getPersistedOpStateExpiryEpochSec());\n+    } else {\n+      return new NodeStatus(\n+          NodeOperationalState.IN_SERVICE, nodeHealthSM.getInitialState());\n+    }\n+  }\n+\n   /**", "originalCommit": "cdd5c9723bbc6f170fd39944ce052673cb6fb89b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}