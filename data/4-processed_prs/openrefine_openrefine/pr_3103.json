{"pr_number": 3103, "pr_title": "Docs > Transforming data", "pr_createdAt": "2020-08-20T16:43:41Z", "pr_url": "https://github.com/OpenRefine/OpenRefine/pull/3103", "timeline": [{"oid": "f66b9d385a4aa1318576592f54a4f540daf7141f", "url": "https://github.com/OpenRefine/OpenRefine/commit/f66b9d385a4aa1318576592f54a4f540daf7141f", "message": "Docs > Transforming data\n\nCell editing page is up first. Ignore the \"overview\" page for now.", "committedDate": "2020-08-20T16:43:07Z", "type": "commit"}, {"oid": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "url": "https://github.com/OpenRefine/OpenRefine/commit/0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "message": "Add column-editing page", "committedDate": "2020-08-24T16:01:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgxMzM2Nw==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475813367", "bodyText": "ASCII is too techie and description is too English-centric. \"sort\" is simpler than reorganize.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            **Fingerprinting** is the least likely to produce false positives, so it\u2019s a good place to start. It does the same kind of data-cleaning behind the scenes that you might think to do manually: fix whitespace into single spaces, put all uppercase letters into lowercase, discard punctuation, convert special characters to their ASCII equivalent, split all strings (words) and reorganize them alphabetically (so \u201cZhenyi, Wang\u201d becomes \u201cWang Zhenyi\u201d). This makes comparing those types of name values very easy.\n          \n          \n            \n            **Fingerprinting** is the least likely to produce false positives, so it\u2019s a good place to start. It does the same kind of data-cleaning behind the scenes that you might think to do manually: fix whitespace into single spaces, put all uppercase letters into lowercase, discard punctuation, remove diacritics (e.g. accents) from characters, split all strings (words) and sort them alphabetically (so \u201cZhenyi, Wang\u201d becomes \u201cWang Zhenyi\u201d). This makes comparing those types of name values very easy.", "author": "tfmorris", "createdAt": "2020-08-24T18:29:37Z", "path": "docs/docs/manual/cellediting.md", "diffHunk": "@@ -0,0 +1,162 @@\n+---\n+id: cellediting\n+title: Cell editing\n+sidebar_label: Cell editing\n+---\n+## Overview\n+\n+OpenRefine offers a number of features to edit and improve the contents of cells automatically and efficiently. \n+\n+One way of doing this is editing through a [text facet](facets#text-facet). Once you have created a facet on a column, hover over the displayed results in the sidebar. Click on the small \u201cedit\u201d button that appears to the right of the facet, and type in a new value. This will apply to all the cells in the facet. \n+\n+## Transform\n+\n+Select \u201cEdit cells\u201d > \u201cTransforms\u201d to open up an expressions window. From here, you can apply [expressions](expressions) to your data. The simplest examples are GREL functions such as `toUppercase` or `toLowercase`, used in expressions as `toUppercase(value)` or `toLowercase(value)`. In all of these cases, `value` is the value in each cell in the selected column. \n+\n+Use the preview to ensure your data is being transformed correctly. \n+\n+You can also switch to the \u201cHistory\u201d tab inside the expressions window to reuse expressions you\u2019ve already attempted in this project, whether they have been undone or not. \n+\n+OpenRefine offers you some frequently-used transformations in the next menu option, \u201cCommon transforms.\u201d For more custom transforms, read up on [expressions](expressions). \n+\n+## Common transforms\n+\n+### Trim leading and trailing whitespace\n+\n+Often cell contents that should be identical, and look identical, are different because of space or line-break characters that are invisible to users. This function will get rid of any characters that sit before or after visible text characters.\n+\n+### Collapse consecutive whitespace\n+\n+You may also find that some text cells contain what look like spaces but are actually tabs, or contain multiple spaces in a row. This function will remove all space characters that sit in sequence and replace them with a single space. \n+\n+### Unescape HTML \n+\n+Your data may come from an HTML-formatted source that expresses some characters through references (such as \"&amp;nbsp;\" for a space, or \"%u0107\" for a \u0107) instead of the actual Unicode characters. You can use the \u201cunescape HTML entities\u201d transform to look for these codes and replace them with the characters they represent. \n+\n+### Replace smart quotes with ASCII\n+\n+Smart quotes (or curly quotes) recognize whether they come at the beginning or end of a string, and will generate an \u201copen\u201d quote (\u201c) and a \u201cclose\u201d quote (\u201d). These characters are not ASCII-compliant (though they are UTF8-compliant) so you can use this tranform to replace them with a straight double quote character (\") instead. \n+\n+### Case transforms\n+\n+You can transform an entire column of text into UPPERCASE, lowercase, or Title Case using these three options. This can be useful if you are planning to do textual analysis and wish to avoid case-sensitivity (which many functions are) causing problems in your analysis. \n+\n+### Data-type transforms\n+\n+As detailed in [Data types](exploring#data-types), OpenRefine recognizes seven data types: string, number, boolean, date, array, error, and null. When you use these transforms, OpenRefine will check to see if the given values can be converted, then both transform the data in the cells (such as \u201c3\u201d as a text string to \u201c3\u201d as a number) and convert the data type on each successfully transformed cell. Cells that cannot be transformed will output the original value and maintain their original data type. \n+\n+For example, the following column of strings on the left will transform into the values on the right:\n+\n+|Input|>|Output|\n+|---|---|---|\n+|23/12/2019|>|2019-12-23T00:00:00Z|\n+|14-10-2015|>|2015-10-14T00:00:00Z|\n+|2012 02 16|>|2012-02-16T00:00:00Z|\n+|August 2nd 1964|>|1964-08-02T00:00:00Z|\n+|today|>|today|\n+|never|>|never|\n+\n+This is based on OpenRefine\u2019s ability to recognize dates with the [`toDate()` function](expressions#dates). \n+\n+Clicking the \u201ctoday\u201d cell and editing its data type manually will convert \u201ctoday\u201d into a value such as \u201c2020-08-14T00:00:00Z\u201d. Attempting the same data-type change on \u201cnever\u201d will give you an error message and refuse to proceed.  \n+\n+Because these common transforms do not offer the ability to output an error instead of the original cell contents, be careful to look for unconverted and untransformed values. You will see a yellow alert at the top of screen that will tell you how many cells were converted - if this number does not match your current row set, you will need to look for and manually correct the remaining cells. \n+\n+You can also convert cells into null values or empty strings. This can be useful if you wish to, for example, erase duplicates that you have identified and are analyzing as a subset. \n+\n+## Fill down and blank down\n+\n+Fill down and blank down are two functions most frequently used when encountering data organized into [records](exploring#row-types-rows-vs-records) - that is, multiple rows associated with one specific entity. \n+\n+If you receive information in rows mode and want to convert it to records mode, the easiest way is to sort your first column by the value that you want to use as a unique records key, then blank down all the duplicates in that column. OpenRefine will retain the first unique value and erase the rest. Then you can switch from \u201cShow as rows\u201d to \u201cShow as records\u201d and OpenRefine will convert the data based on the remaining values in the first column. Be careful that your data is sorted properly before you begin blanking down - not just the first column but other columns you may want to have in a certain order. For example, you may have multiple identical entries in the first column, one with a value in the second column and one with an empty cell in the second column. In this case you want the value to come first, so that you can clean up empty rows later, once you blank down. \n+\n+If, conversely, you\u2019ve received data with empty cells because it was already in something akin to records mode, you can fill down information to the rest of the rows. This will duplicate whatever value exists in the topmost cell with a value: if the first row in the record is blank, it will take information from the next cell, or the cell after that, until it finds a value. The blank cells above this will remain blank.\n+\n+## Split multi-valued cells\n+\n+Splitting cells with more than one value in them is a common way to get your data from single rows into multi-row records. Survey data, for example, frequently allows respondents to \u201cSelect all that apply,\u201d or an inventory list might have items filed under more than one category. \n+\n+You can split a column based on any character or series of characters you input, such as a semi-colon (;) or a slash (/). The default is a comma. Splitting based on a separator will remove the separator characters, so you may wish to include a space with your separator (; ) if it exists in your data.\n+\n+You can use [expressions](expressions) to design the point at which a cell should split itself into two or more rows. This can be used to identify special characters or create more advanced evaluations. You can split on a line-break by entering `\\n` and checking the \u201cregular expression\u201d checkbox. \n+\n+This can be useful if the split is not straightforward: say, if a capital letter indicates the beginning of a new string, or if you need to _not_ always split on a character that appears in both the strings and as a separator. Remember that this will remove all the matching characters. \n+\n+You can also split based on the lengths of the strings you expect to find. This can be useful if you have predictable data in the cells: for example, a 10-digit phone number, followed by a space, followed by another 10-digit phone number. Any characters past the explicit length you\u2019ve specified will be discarded: if you split by \u201c11, 10\u201d any characters that may come after the 21st character will disappear. If some cells only have one phone number, you will end up with blank rows. \n+\n+If you have data that should be split into multiple columns instead of multiple rows, see [split into several columns(columnediting#split-into-several-columns). \n+\n+## Join multi-valued cells\n+\n+Joining will reverse the \u201csplit multi-valued cells\u201d operation, or join up information from multiple rows into one row. All the strings will be compressed into the topmost cell in the record, in the order they appear. A window will appear where you can set the separator; the default is a comma and a space (, ). This separator is optional. \n+\n+## Cluster and edit\n+\n+Creating a facet on a column is a great way to look for inconsistencies in your data; clustering is a great way to fix those inconsistencies. Clustering uses a variety of comparison methods to find text entries that are similar but not exact, then shares those results with you so that you can merge the cells that should match. Where editing a single cell or text facet at a time can be time-consuming and difficult, clustering is quick and streamlined. \n+\n+Clustering always requires the user to approve each suggested edit - it will display values it thinks are variations on the same thing, and you can select which version to keep and apply across all those matching cells (or type in your own version). OpenRefine will do a number of cleanup operations behind the scenes, in memory, in order to do its analysis, but only the merges you approve will modify your data. \n+\n+You can start the process in two ways: using the dropdown menu on your column, select \u201cEdit cells\u201d > \u201cCluster and edit\u2026\u201d or create a text facet and then press the \u201cCluster\u201d button that appears in the facet box. \n+\n+![A screenshot of the Clustering window.](/img/cluster.png)\n+\n+The clustering pop-up window will take a small amount of time to analyze your column, and then make some suggestions based on the clustering method currently active. \n+\n+For each cluster identified, you can pick one of the existing values to apply to all cells, or manually type in a new value in the text box. And, of course, you can choose not to cluster them at all. OpenRefine will keep analyzing every time you make a change, with \u201cMerge selected & re-cluster,\u201d and you can work through all the methods this way. \n+\n+You can also export the currently identified clusters as a JSON file, or close the window with or without applying your changes. You can also use the histograms on the right to narrow down to, for example, clusters with lots of matching rows, or clusters of long or short values. \n+\n+### Clustering methods\n+\n+You don\u2019t need to understand the details behind each clustering method to apply them successfully to your data. The order in which these methods are presented in the interface and on this page is the order we recommend - starting with the most strict rules and moving to the most lax, which require more human supervision to apply correctly. \n+\n+The clustering pop-up window offers you a variety of clustering methods:\n+\n+*   key collision\n+    *   fingerprint\n+    *   ngram-fingerprint\n+    *   metaphone3\n+    *   cologne-phonetic\n+    *   Daitch-Mokotoff\n+    *   Beider-Morse\n+*   nearest neighbor\n+    *   levenshtein\n+    *   ppm\n+\n+**Key collisions** are very fast and can process millions of cells in seconds:\n+\n+**Fingerprinting** is the least likely to produce false positives, so it\u2019s a good place to start. It does the same kind of data-cleaning behind the scenes that you might think to do manually: fix whitespace into single spaces, put all uppercase letters into lowercase, discard punctuation, convert special characters to their ASCII equivalent, split all strings (words) and reorganize them alphabetically (so \u201cZhenyi, Wang\u201d becomes \u201cWang Zhenyi\u201d). This makes comparing those types of name values very easy.", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg4NTg0MA==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475885840", "bodyText": "I'm not sure \"diacritics\" is much better than \"ASCII\" but you're right; I'll work on it.", "author": "allanaaa", "createdAt": "2020-08-24T20:50:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgxMzM2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgxODkzNg==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475818936", "bodyText": "Is \"gram\" a word? I've never run across it, so it's certainly not commonly used. The n-grams are de-duped after sorting, which is an important aspect of this, that doesn't come through clearly. A well chosen simple example using bigrams might be the easiest way to make it obvious what's going on e.g. \"banana\" -> ba an na an na -> anbana.", "author": "tfmorris", "createdAt": "2020-08-24T18:39:58Z", "path": "docs/docs/manual/cellediting.md", "diffHunk": "@@ -0,0 +1,162 @@\n+---\n+id: cellediting\n+title: Cell editing\n+sidebar_label: Cell editing\n+---\n+## Overview\n+\n+OpenRefine offers a number of features to edit and improve the contents of cells automatically and efficiently. \n+\n+One way of doing this is editing through a [text facet](facets#text-facet). Once you have created a facet on a column, hover over the displayed results in the sidebar. Click on the small \u201cedit\u201d button that appears to the right of the facet, and type in a new value. This will apply to all the cells in the facet. \n+\n+## Transform\n+\n+Select \u201cEdit cells\u201d > \u201cTransforms\u201d to open up an expressions window. From here, you can apply [expressions](expressions) to your data. The simplest examples are GREL functions such as `toUppercase` or `toLowercase`, used in expressions as `toUppercase(value)` or `toLowercase(value)`. In all of these cases, `value` is the value in each cell in the selected column. \n+\n+Use the preview to ensure your data is being transformed correctly. \n+\n+You can also switch to the \u201cHistory\u201d tab inside the expressions window to reuse expressions you\u2019ve already attempted in this project, whether they have been undone or not. \n+\n+OpenRefine offers you some frequently-used transformations in the next menu option, \u201cCommon transforms.\u201d For more custom transforms, read up on [expressions](expressions). \n+\n+## Common transforms\n+\n+### Trim leading and trailing whitespace\n+\n+Often cell contents that should be identical, and look identical, are different because of space or line-break characters that are invisible to users. This function will get rid of any characters that sit before or after visible text characters.\n+\n+### Collapse consecutive whitespace\n+\n+You may also find that some text cells contain what look like spaces but are actually tabs, or contain multiple spaces in a row. This function will remove all space characters that sit in sequence and replace them with a single space. \n+\n+### Unescape HTML \n+\n+Your data may come from an HTML-formatted source that expresses some characters through references (such as \"&amp;nbsp;\" for a space, or \"%u0107\" for a \u0107) instead of the actual Unicode characters. You can use the \u201cunescape HTML entities\u201d transform to look for these codes and replace them with the characters they represent. \n+\n+### Replace smart quotes with ASCII\n+\n+Smart quotes (or curly quotes) recognize whether they come at the beginning or end of a string, and will generate an \u201copen\u201d quote (\u201c) and a \u201cclose\u201d quote (\u201d). These characters are not ASCII-compliant (though they are UTF8-compliant) so you can use this tranform to replace them with a straight double quote character (\") instead. \n+\n+### Case transforms\n+\n+You can transform an entire column of text into UPPERCASE, lowercase, or Title Case using these three options. This can be useful if you are planning to do textual analysis and wish to avoid case-sensitivity (which many functions are) causing problems in your analysis. \n+\n+### Data-type transforms\n+\n+As detailed in [Data types](exploring#data-types), OpenRefine recognizes seven data types: string, number, boolean, date, array, error, and null. When you use these transforms, OpenRefine will check to see if the given values can be converted, then both transform the data in the cells (such as \u201c3\u201d as a text string to \u201c3\u201d as a number) and convert the data type on each successfully transformed cell. Cells that cannot be transformed will output the original value and maintain their original data type. \n+\n+For example, the following column of strings on the left will transform into the values on the right:\n+\n+|Input|>|Output|\n+|---|---|---|\n+|23/12/2019|>|2019-12-23T00:00:00Z|\n+|14-10-2015|>|2015-10-14T00:00:00Z|\n+|2012 02 16|>|2012-02-16T00:00:00Z|\n+|August 2nd 1964|>|1964-08-02T00:00:00Z|\n+|today|>|today|\n+|never|>|never|\n+\n+This is based on OpenRefine\u2019s ability to recognize dates with the [`toDate()` function](expressions#dates). \n+\n+Clicking the \u201ctoday\u201d cell and editing its data type manually will convert \u201ctoday\u201d into a value such as \u201c2020-08-14T00:00:00Z\u201d. Attempting the same data-type change on \u201cnever\u201d will give you an error message and refuse to proceed.  \n+\n+Because these common transforms do not offer the ability to output an error instead of the original cell contents, be careful to look for unconverted and untransformed values. You will see a yellow alert at the top of screen that will tell you how many cells were converted - if this number does not match your current row set, you will need to look for and manually correct the remaining cells. \n+\n+You can also convert cells into null values or empty strings. This can be useful if you wish to, for example, erase duplicates that you have identified and are analyzing as a subset. \n+\n+## Fill down and blank down\n+\n+Fill down and blank down are two functions most frequently used when encountering data organized into [records](exploring#row-types-rows-vs-records) - that is, multiple rows associated with one specific entity. \n+\n+If you receive information in rows mode and want to convert it to records mode, the easiest way is to sort your first column by the value that you want to use as a unique records key, then blank down all the duplicates in that column. OpenRefine will retain the first unique value and erase the rest. Then you can switch from \u201cShow as rows\u201d to \u201cShow as records\u201d and OpenRefine will convert the data based on the remaining values in the first column. Be careful that your data is sorted properly before you begin blanking down - not just the first column but other columns you may want to have in a certain order. For example, you may have multiple identical entries in the first column, one with a value in the second column and one with an empty cell in the second column. In this case you want the value to come first, so that you can clean up empty rows later, once you blank down. \n+\n+If, conversely, you\u2019ve received data with empty cells because it was already in something akin to records mode, you can fill down information to the rest of the rows. This will duplicate whatever value exists in the topmost cell with a value: if the first row in the record is blank, it will take information from the next cell, or the cell after that, until it finds a value. The blank cells above this will remain blank.\n+\n+## Split multi-valued cells\n+\n+Splitting cells with more than one value in them is a common way to get your data from single rows into multi-row records. Survey data, for example, frequently allows respondents to \u201cSelect all that apply,\u201d or an inventory list might have items filed under more than one category. \n+\n+You can split a column based on any character or series of characters you input, such as a semi-colon (;) or a slash (/). The default is a comma. Splitting based on a separator will remove the separator characters, so you may wish to include a space with your separator (; ) if it exists in your data.\n+\n+You can use [expressions](expressions) to design the point at which a cell should split itself into two or more rows. This can be used to identify special characters or create more advanced evaluations. You can split on a line-break by entering `\\n` and checking the \u201cregular expression\u201d checkbox. \n+\n+This can be useful if the split is not straightforward: say, if a capital letter indicates the beginning of a new string, or if you need to _not_ always split on a character that appears in both the strings and as a separator. Remember that this will remove all the matching characters. \n+\n+You can also split based on the lengths of the strings you expect to find. This can be useful if you have predictable data in the cells: for example, a 10-digit phone number, followed by a space, followed by another 10-digit phone number. Any characters past the explicit length you\u2019ve specified will be discarded: if you split by \u201c11, 10\u201d any characters that may come after the 21st character will disappear. If some cells only have one phone number, you will end up with blank rows. \n+\n+If you have data that should be split into multiple columns instead of multiple rows, see [split into several columns(columnediting#split-into-several-columns). \n+\n+## Join multi-valued cells\n+\n+Joining will reverse the \u201csplit multi-valued cells\u201d operation, or join up information from multiple rows into one row. All the strings will be compressed into the topmost cell in the record, in the order they appear. A window will appear where you can set the separator; the default is a comma and a space (, ). This separator is optional. \n+\n+## Cluster and edit\n+\n+Creating a facet on a column is a great way to look for inconsistencies in your data; clustering is a great way to fix those inconsistencies. Clustering uses a variety of comparison methods to find text entries that are similar but not exact, then shares those results with you so that you can merge the cells that should match. Where editing a single cell or text facet at a time can be time-consuming and difficult, clustering is quick and streamlined. \n+\n+Clustering always requires the user to approve each suggested edit - it will display values it thinks are variations on the same thing, and you can select which version to keep and apply across all those matching cells (or type in your own version). OpenRefine will do a number of cleanup operations behind the scenes, in memory, in order to do its analysis, but only the merges you approve will modify your data. \n+\n+You can start the process in two ways: using the dropdown menu on your column, select \u201cEdit cells\u201d > \u201cCluster and edit\u2026\u201d or create a text facet and then press the \u201cCluster\u201d button that appears in the facet box. \n+\n+![A screenshot of the Clustering window.](/img/cluster.png)\n+\n+The clustering pop-up window will take a small amount of time to analyze your column, and then make some suggestions based on the clustering method currently active. \n+\n+For each cluster identified, you can pick one of the existing values to apply to all cells, or manually type in a new value in the text box. And, of course, you can choose not to cluster them at all. OpenRefine will keep analyzing every time you make a change, with \u201cMerge selected & re-cluster,\u201d and you can work through all the methods this way. \n+\n+You can also export the currently identified clusters as a JSON file, or close the window with or without applying your changes. You can also use the histograms on the right to narrow down to, for example, clusters with lots of matching rows, or clusters of long or short values. \n+\n+### Clustering methods\n+\n+You don\u2019t need to understand the details behind each clustering method to apply them successfully to your data. The order in which these methods are presented in the interface and on this page is the order we recommend - starting with the most strict rules and moving to the most lax, which require more human supervision to apply correctly. \n+\n+The clustering pop-up window offers you a variety of clustering methods:\n+\n+*   key collision\n+    *   fingerprint\n+    *   ngram-fingerprint\n+    *   metaphone3\n+    *   cologne-phonetic\n+    *   Daitch-Mokotoff\n+    *   Beider-Morse\n+*   nearest neighbor\n+    *   levenshtein\n+    *   ppm\n+\n+**Key collisions** are very fast and can process millions of cells in seconds:\n+\n+**Fingerprinting** is the least likely to produce false positives, so it\u2019s a good place to start. It does the same kind of data-cleaning behind the scenes that you might think to do manually: fix whitespace into single spaces, put all uppercase letters into lowercase, discard punctuation, convert special characters to their ASCII equivalent, split all strings (words) and reorganize them alphabetically (so \u201cZhenyi, Wang\u201d becomes \u201cWang Zhenyi\u201d). This makes comparing those types of name values very easy.\n+\n+**N-gram fingerprinting** allows you to set the _n_ value to whatever number you\u2019d like, and will create n-grams of _n_ size (after doing some cleaning), alphabetize them, then join them back together into a _fingerprint_. For example, a 1-gram fingerprint will simply organize all the letters in the cell into alphabetical order - by creating grams with one character length. A 2-gram fingerprint will find all the two-character grams, remove duplicates, alphabetize them, and join them back together. This can help match cells that have typos, or incorrect spaces (such as matching \u201clookout\u201d and \u201clook out,\u201d which fingerprinting itself won\u2019t identify). The higher the _n_ value, the fewer clusters will be identified. With 1-grams, keep an eye out for mismatched values that are near-anagrams of each other (such as \u201cWellington\u201d and \u201cElgin Town\u201d). ", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg4ODcwNw==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475888707", "bodyText": "No, it appears to be just a word in my head!\nNew version:\n\nN-gram fingerprinting allows you to set the n value to whatever number you\u2019d like, and will create n-grams of n size (after doing some cleaning), alphabetize them, then join them back together into a fingerprint. For example, a 1-gram fingerprint will simply organize all the letters in the cell into alphabetical order - by creating segments one character in length. A 2-gram fingerprint will find all the two-character segments, remove duplicates, alphabetize them, and join them back together (for example, \u201cbanana\u201d generates \u201cba an na an na,\u201d which becomes \u201canbana\u201d). This can help match cells that have typos, or incorrect spaces (such as matching \u201clookout\u201d and \u201clook out,\u201d which fingerprinting itself won\u2019t identify). The higher the n value, the fewer clusters will be identified. With 1-grams, keep an eye out for mismatched values that are near-anagrams of each other (such as \u201cWellington\u201d and \u201cElgin Town\u201d).", "author": "allanaaa", "createdAt": "2020-08-24T20:55:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgxODkzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyNzg1Mg==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475827852", "bodyText": "They are slower because they have to do pairwise comparisons of all strings in a given block which causes the time to be proportional to the square of the number of entries in a block.\nThe tradeoff is that smaller blocks increase the likelihood that two similar strings will be in different blocks and never compared against each other, while bigger blocks run slower (MUCH slower for large blocks because of the N^2 behavior).", "author": "tfmorris", "createdAt": "2020-08-24T18:56:22Z", "path": "docs/docs/manual/cellediting.md", "diffHunk": "@@ -0,0 +1,162 @@\n+---\n+id: cellediting\n+title: Cell editing\n+sidebar_label: Cell editing\n+---\n+## Overview\n+\n+OpenRefine offers a number of features to edit and improve the contents of cells automatically and efficiently. \n+\n+One way of doing this is editing through a [text facet](facets#text-facet). Once you have created a facet on a column, hover over the displayed results in the sidebar. Click on the small \u201cedit\u201d button that appears to the right of the facet, and type in a new value. This will apply to all the cells in the facet. \n+\n+## Transform\n+\n+Select \u201cEdit cells\u201d > \u201cTransforms\u201d to open up an expressions window. From here, you can apply [expressions](expressions) to your data. The simplest examples are GREL functions such as `toUppercase` or `toLowercase`, used in expressions as `toUppercase(value)` or `toLowercase(value)`. In all of these cases, `value` is the value in each cell in the selected column. \n+\n+Use the preview to ensure your data is being transformed correctly. \n+\n+You can also switch to the \u201cHistory\u201d tab inside the expressions window to reuse expressions you\u2019ve already attempted in this project, whether they have been undone or not. \n+\n+OpenRefine offers you some frequently-used transformations in the next menu option, \u201cCommon transforms.\u201d For more custom transforms, read up on [expressions](expressions). \n+\n+## Common transforms\n+\n+### Trim leading and trailing whitespace\n+\n+Often cell contents that should be identical, and look identical, are different because of space or line-break characters that are invisible to users. This function will get rid of any characters that sit before or after visible text characters.\n+\n+### Collapse consecutive whitespace\n+\n+You may also find that some text cells contain what look like spaces but are actually tabs, or contain multiple spaces in a row. This function will remove all space characters that sit in sequence and replace them with a single space. \n+\n+### Unescape HTML \n+\n+Your data may come from an HTML-formatted source that expresses some characters through references (such as \"&amp;nbsp;\" for a space, or \"%u0107\" for a \u0107) instead of the actual Unicode characters. You can use the \u201cunescape HTML entities\u201d transform to look for these codes and replace them with the characters they represent. \n+\n+### Replace smart quotes with ASCII\n+\n+Smart quotes (or curly quotes) recognize whether they come at the beginning or end of a string, and will generate an \u201copen\u201d quote (\u201c) and a \u201cclose\u201d quote (\u201d). These characters are not ASCII-compliant (though they are UTF8-compliant) so you can use this tranform to replace them with a straight double quote character (\") instead. \n+\n+### Case transforms\n+\n+You can transform an entire column of text into UPPERCASE, lowercase, or Title Case using these three options. This can be useful if you are planning to do textual analysis and wish to avoid case-sensitivity (which many functions are) causing problems in your analysis. \n+\n+### Data-type transforms\n+\n+As detailed in [Data types](exploring#data-types), OpenRefine recognizes seven data types: string, number, boolean, date, array, error, and null. When you use these transforms, OpenRefine will check to see if the given values can be converted, then both transform the data in the cells (such as \u201c3\u201d as a text string to \u201c3\u201d as a number) and convert the data type on each successfully transformed cell. Cells that cannot be transformed will output the original value and maintain their original data type. \n+\n+For example, the following column of strings on the left will transform into the values on the right:\n+\n+|Input|>|Output|\n+|---|---|---|\n+|23/12/2019|>|2019-12-23T00:00:00Z|\n+|14-10-2015|>|2015-10-14T00:00:00Z|\n+|2012 02 16|>|2012-02-16T00:00:00Z|\n+|August 2nd 1964|>|1964-08-02T00:00:00Z|\n+|today|>|today|\n+|never|>|never|\n+\n+This is based on OpenRefine\u2019s ability to recognize dates with the [`toDate()` function](expressions#dates). \n+\n+Clicking the \u201ctoday\u201d cell and editing its data type manually will convert \u201ctoday\u201d into a value such as \u201c2020-08-14T00:00:00Z\u201d. Attempting the same data-type change on \u201cnever\u201d will give you an error message and refuse to proceed.  \n+\n+Because these common transforms do not offer the ability to output an error instead of the original cell contents, be careful to look for unconverted and untransformed values. You will see a yellow alert at the top of screen that will tell you how many cells were converted - if this number does not match your current row set, you will need to look for and manually correct the remaining cells. \n+\n+You can also convert cells into null values or empty strings. This can be useful if you wish to, for example, erase duplicates that you have identified and are analyzing as a subset. \n+\n+## Fill down and blank down\n+\n+Fill down and blank down are two functions most frequently used when encountering data organized into [records](exploring#row-types-rows-vs-records) - that is, multiple rows associated with one specific entity. \n+\n+If you receive information in rows mode and want to convert it to records mode, the easiest way is to sort your first column by the value that you want to use as a unique records key, then blank down all the duplicates in that column. OpenRefine will retain the first unique value and erase the rest. Then you can switch from \u201cShow as rows\u201d to \u201cShow as records\u201d and OpenRefine will convert the data based on the remaining values in the first column. Be careful that your data is sorted properly before you begin blanking down - not just the first column but other columns you may want to have in a certain order. For example, you may have multiple identical entries in the first column, one with a value in the second column and one with an empty cell in the second column. In this case you want the value to come first, so that you can clean up empty rows later, once you blank down. \n+\n+If, conversely, you\u2019ve received data with empty cells because it was already in something akin to records mode, you can fill down information to the rest of the rows. This will duplicate whatever value exists in the topmost cell with a value: if the first row in the record is blank, it will take information from the next cell, or the cell after that, until it finds a value. The blank cells above this will remain blank.\n+\n+## Split multi-valued cells\n+\n+Splitting cells with more than one value in them is a common way to get your data from single rows into multi-row records. Survey data, for example, frequently allows respondents to \u201cSelect all that apply,\u201d or an inventory list might have items filed under more than one category. \n+\n+You can split a column based on any character or series of characters you input, such as a semi-colon (;) or a slash (/). The default is a comma. Splitting based on a separator will remove the separator characters, so you may wish to include a space with your separator (; ) if it exists in your data.\n+\n+You can use [expressions](expressions) to design the point at which a cell should split itself into two or more rows. This can be used to identify special characters or create more advanced evaluations. You can split on a line-break by entering `\\n` and checking the \u201cregular expression\u201d checkbox. \n+\n+This can be useful if the split is not straightforward: say, if a capital letter indicates the beginning of a new string, or if you need to _not_ always split on a character that appears in both the strings and as a separator. Remember that this will remove all the matching characters. \n+\n+You can also split based on the lengths of the strings you expect to find. This can be useful if you have predictable data in the cells: for example, a 10-digit phone number, followed by a space, followed by another 10-digit phone number. Any characters past the explicit length you\u2019ve specified will be discarded: if you split by \u201c11, 10\u201d any characters that may come after the 21st character will disappear. If some cells only have one phone number, you will end up with blank rows. \n+\n+If you have data that should be split into multiple columns instead of multiple rows, see [split into several columns(columnediting#split-into-several-columns). \n+\n+## Join multi-valued cells\n+\n+Joining will reverse the \u201csplit multi-valued cells\u201d operation, or join up information from multiple rows into one row. All the strings will be compressed into the topmost cell in the record, in the order they appear. A window will appear where you can set the separator; the default is a comma and a space (, ). This separator is optional. \n+\n+## Cluster and edit\n+\n+Creating a facet on a column is a great way to look for inconsistencies in your data; clustering is a great way to fix those inconsistencies. Clustering uses a variety of comparison methods to find text entries that are similar but not exact, then shares those results with you so that you can merge the cells that should match. Where editing a single cell or text facet at a time can be time-consuming and difficult, clustering is quick and streamlined. \n+\n+Clustering always requires the user to approve each suggested edit - it will display values it thinks are variations on the same thing, and you can select which version to keep and apply across all those matching cells (or type in your own version). OpenRefine will do a number of cleanup operations behind the scenes, in memory, in order to do its analysis, but only the merges you approve will modify your data. \n+\n+You can start the process in two ways: using the dropdown menu on your column, select \u201cEdit cells\u201d > \u201cCluster and edit\u2026\u201d or create a text facet and then press the \u201cCluster\u201d button that appears in the facet box. \n+\n+![A screenshot of the Clustering window.](/img/cluster.png)\n+\n+The clustering pop-up window will take a small amount of time to analyze your column, and then make some suggestions based on the clustering method currently active. \n+\n+For each cluster identified, you can pick one of the existing values to apply to all cells, or manually type in a new value in the text box. And, of course, you can choose not to cluster them at all. OpenRefine will keep analyzing every time you make a change, with \u201cMerge selected & re-cluster,\u201d and you can work through all the methods this way. \n+\n+You can also export the currently identified clusters as a JSON file, or close the window with or without applying your changes. You can also use the histograms on the right to narrow down to, for example, clusters with lots of matching rows, or clusters of long or short values. \n+\n+### Clustering methods\n+\n+You don\u2019t need to understand the details behind each clustering method to apply them successfully to your data. The order in which these methods are presented in the interface and on this page is the order we recommend - starting with the most strict rules and moving to the most lax, which require more human supervision to apply correctly. \n+\n+The clustering pop-up window offers you a variety of clustering methods:\n+\n+*   key collision\n+    *   fingerprint\n+    *   ngram-fingerprint\n+    *   metaphone3\n+    *   cologne-phonetic\n+    *   Daitch-Mokotoff\n+    *   Beider-Morse\n+*   nearest neighbor\n+    *   levenshtein\n+    *   ppm\n+\n+**Key collisions** are very fast and can process millions of cells in seconds:\n+\n+**Fingerprinting** is the least likely to produce false positives, so it\u2019s a good place to start. It does the same kind of data-cleaning behind the scenes that you might think to do manually: fix whitespace into single spaces, put all uppercase letters into lowercase, discard punctuation, convert special characters to their ASCII equivalent, split all strings (words) and reorganize them alphabetically (so \u201cZhenyi, Wang\u201d becomes \u201cWang Zhenyi\u201d). This makes comparing those types of name values very easy.\n+\n+**N-gram fingerprinting** allows you to set the _n_ value to whatever number you\u2019d like, and will create n-grams of _n_ size (after doing some cleaning), alphabetize them, then join them back together into a _fingerprint_. For example, a 1-gram fingerprint will simply organize all the letters in the cell into alphabetical order - by creating grams with one character length. A 2-gram fingerprint will find all the two-character grams, remove duplicates, alphabetize them, and join them back together. This can help match cells that have typos, or incorrect spaces (such as matching \u201clookout\u201d and \u201clook out,\u201d which fingerprinting itself won\u2019t identify). The higher the _n_ value, the fewer clusters will be identified. With 1-grams, keep an eye out for mismatched values that are near-anagrams of each other (such as \u201cWellington\u201d and \u201cElgin Town\u201d). \n+\n+The next four methods are phonetic algorithsm: they know whether two letters sound the same when pronounced out loud, and assess text values based on that (such as knowing that a word with an \u201cS\u201d might be a mistype of a word with a \u201cZ\u201d).  They are great for spotting mistakes made by not knowing the spelling of a word or name after only hearing it spoken aloud. \n+\n+**Metaphone3 fingerprinting** is an English-language phonetic algorithm. For example, \"Reuben Gevorkiantz\" and \"Ruben Gevorkyants\" share the same phonetic fingerprint in English.\n+\n+**Cologne fingerprinting** is another phonetic algorithm, but for German pronunciation. \n+\n+**Daitch-Mokotoff** is a phonetic algorithm for Slavic and Yiddish words, especially names. **Baider-Morse** is a version of Daitch-Mokotoff that is slightly more strict. \n+\n+Regardless of the language of your data, applying each of them might find different potential matches: for example, Metaphone clusters \u201cCornwall\u201d and \u201cCorn Hill\u201d and \u201cGreen Hill,\u201d while Cologne clusters \u201cGreenvale\u201d and \u201cGranville\u201d and \u201cCornwall\u201d and \u201cGreen Wall.\u201d \n+\n+**Nearest neighbor **clustering methods are slower than key collision methods. They allow the user to set a radius - a threshold for matching or not matching. OpenRefine uses a \u201cblocking\u201d method first, which sorts values based on whether they have a certain amount of similarity (the default is \u201c6\u201d for a six-character string of identical characters) and then runs the nearest-neighbor operations on those sorted groups. We recommend setting the block number to at least three, and then increasing it if you need to be more strict (for example, if every value with \u201criver\u201d is being matched, you should increase it to 6 or more). Increasing the radius will make the matches more lax, as bigger differences will be clustered:", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODkwNw==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475828907", "bodyText": "These \"operations\" are usually called \"edits.\"\nSomething to consider might be linking to Wikipedia for more detail on standard algorithms and terms like this.", "author": "tfmorris", "createdAt": "2020-08-24T18:58:23Z", "path": "docs/docs/manual/cellediting.md", "diffHunk": "@@ -0,0 +1,162 @@\n+---\n+id: cellediting\n+title: Cell editing\n+sidebar_label: Cell editing\n+---\n+## Overview\n+\n+OpenRefine offers a number of features to edit and improve the contents of cells automatically and efficiently. \n+\n+One way of doing this is editing through a [text facet](facets#text-facet). Once you have created a facet on a column, hover over the displayed results in the sidebar. Click on the small \u201cedit\u201d button that appears to the right of the facet, and type in a new value. This will apply to all the cells in the facet. \n+\n+## Transform\n+\n+Select \u201cEdit cells\u201d > \u201cTransforms\u201d to open up an expressions window. From here, you can apply [expressions](expressions) to your data. The simplest examples are GREL functions such as `toUppercase` or `toLowercase`, used in expressions as `toUppercase(value)` or `toLowercase(value)`. In all of these cases, `value` is the value in each cell in the selected column. \n+\n+Use the preview to ensure your data is being transformed correctly. \n+\n+You can also switch to the \u201cHistory\u201d tab inside the expressions window to reuse expressions you\u2019ve already attempted in this project, whether they have been undone or not. \n+\n+OpenRefine offers you some frequently-used transformations in the next menu option, \u201cCommon transforms.\u201d For more custom transforms, read up on [expressions](expressions). \n+\n+## Common transforms\n+\n+### Trim leading and trailing whitespace\n+\n+Often cell contents that should be identical, and look identical, are different because of space or line-break characters that are invisible to users. This function will get rid of any characters that sit before or after visible text characters.\n+\n+### Collapse consecutive whitespace\n+\n+You may also find that some text cells contain what look like spaces but are actually tabs, or contain multiple spaces in a row. This function will remove all space characters that sit in sequence and replace them with a single space. \n+\n+### Unescape HTML \n+\n+Your data may come from an HTML-formatted source that expresses some characters through references (such as \"&amp;nbsp;\" for a space, or \"%u0107\" for a \u0107) instead of the actual Unicode characters. You can use the \u201cunescape HTML entities\u201d transform to look for these codes and replace them with the characters they represent. \n+\n+### Replace smart quotes with ASCII\n+\n+Smart quotes (or curly quotes) recognize whether they come at the beginning or end of a string, and will generate an \u201copen\u201d quote (\u201c) and a \u201cclose\u201d quote (\u201d). These characters are not ASCII-compliant (though they are UTF8-compliant) so you can use this tranform to replace them with a straight double quote character (\") instead. \n+\n+### Case transforms\n+\n+You can transform an entire column of text into UPPERCASE, lowercase, or Title Case using these three options. This can be useful if you are planning to do textual analysis and wish to avoid case-sensitivity (which many functions are) causing problems in your analysis. \n+\n+### Data-type transforms\n+\n+As detailed in [Data types](exploring#data-types), OpenRefine recognizes seven data types: string, number, boolean, date, array, error, and null. When you use these transforms, OpenRefine will check to see if the given values can be converted, then both transform the data in the cells (such as \u201c3\u201d as a text string to \u201c3\u201d as a number) and convert the data type on each successfully transformed cell. Cells that cannot be transformed will output the original value and maintain their original data type. \n+\n+For example, the following column of strings on the left will transform into the values on the right:\n+\n+|Input|>|Output|\n+|---|---|---|\n+|23/12/2019|>|2019-12-23T00:00:00Z|\n+|14-10-2015|>|2015-10-14T00:00:00Z|\n+|2012 02 16|>|2012-02-16T00:00:00Z|\n+|August 2nd 1964|>|1964-08-02T00:00:00Z|\n+|today|>|today|\n+|never|>|never|\n+\n+This is based on OpenRefine\u2019s ability to recognize dates with the [`toDate()` function](expressions#dates). \n+\n+Clicking the \u201ctoday\u201d cell and editing its data type manually will convert \u201ctoday\u201d into a value such as \u201c2020-08-14T00:00:00Z\u201d. Attempting the same data-type change on \u201cnever\u201d will give you an error message and refuse to proceed.  \n+\n+Because these common transforms do not offer the ability to output an error instead of the original cell contents, be careful to look for unconverted and untransformed values. You will see a yellow alert at the top of screen that will tell you how many cells were converted - if this number does not match your current row set, you will need to look for and manually correct the remaining cells. \n+\n+You can also convert cells into null values or empty strings. This can be useful if you wish to, for example, erase duplicates that you have identified and are analyzing as a subset. \n+\n+## Fill down and blank down\n+\n+Fill down and blank down are two functions most frequently used when encountering data organized into [records](exploring#row-types-rows-vs-records) - that is, multiple rows associated with one specific entity. \n+\n+If you receive information in rows mode and want to convert it to records mode, the easiest way is to sort your first column by the value that you want to use as a unique records key, then blank down all the duplicates in that column. OpenRefine will retain the first unique value and erase the rest. Then you can switch from \u201cShow as rows\u201d to \u201cShow as records\u201d and OpenRefine will convert the data based on the remaining values in the first column. Be careful that your data is sorted properly before you begin blanking down - not just the first column but other columns you may want to have in a certain order. For example, you may have multiple identical entries in the first column, one with a value in the second column and one with an empty cell in the second column. In this case you want the value to come first, so that you can clean up empty rows later, once you blank down. \n+\n+If, conversely, you\u2019ve received data with empty cells because it was already in something akin to records mode, you can fill down information to the rest of the rows. This will duplicate whatever value exists in the topmost cell with a value: if the first row in the record is blank, it will take information from the next cell, or the cell after that, until it finds a value. The blank cells above this will remain blank.\n+\n+## Split multi-valued cells\n+\n+Splitting cells with more than one value in them is a common way to get your data from single rows into multi-row records. Survey data, for example, frequently allows respondents to \u201cSelect all that apply,\u201d or an inventory list might have items filed under more than one category. \n+\n+You can split a column based on any character or series of characters you input, such as a semi-colon (;) or a slash (/). The default is a comma. Splitting based on a separator will remove the separator characters, so you may wish to include a space with your separator (; ) if it exists in your data.\n+\n+You can use [expressions](expressions) to design the point at which a cell should split itself into two or more rows. This can be used to identify special characters or create more advanced evaluations. You can split on a line-break by entering `\\n` and checking the \u201cregular expression\u201d checkbox. \n+\n+This can be useful if the split is not straightforward: say, if a capital letter indicates the beginning of a new string, or if you need to _not_ always split on a character that appears in both the strings and as a separator. Remember that this will remove all the matching characters. \n+\n+You can also split based on the lengths of the strings you expect to find. This can be useful if you have predictable data in the cells: for example, a 10-digit phone number, followed by a space, followed by another 10-digit phone number. Any characters past the explicit length you\u2019ve specified will be discarded: if you split by \u201c11, 10\u201d any characters that may come after the 21st character will disappear. If some cells only have one phone number, you will end up with blank rows. \n+\n+If you have data that should be split into multiple columns instead of multiple rows, see [split into several columns(columnediting#split-into-several-columns). \n+\n+## Join multi-valued cells\n+\n+Joining will reverse the \u201csplit multi-valued cells\u201d operation, or join up information from multiple rows into one row. All the strings will be compressed into the topmost cell in the record, in the order they appear. A window will appear where you can set the separator; the default is a comma and a space (, ). This separator is optional. \n+\n+## Cluster and edit\n+\n+Creating a facet on a column is a great way to look for inconsistencies in your data; clustering is a great way to fix those inconsistencies. Clustering uses a variety of comparison methods to find text entries that are similar but not exact, then shares those results with you so that you can merge the cells that should match. Where editing a single cell or text facet at a time can be time-consuming and difficult, clustering is quick and streamlined. \n+\n+Clustering always requires the user to approve each suggested edit - it will display values it thinks are variations on the same thing, and you can select which version to keep and apply across all those matching cells (or type in your own version). OpenRefine will do a number of cleanup operations behind the scenes, in memory, in order to do its analysis, but only the merges you approve will modify your data. \n+\n+You can start the process in two ways: using the dropdown menu on your column, select \u201cEdit cells\u201d > \u201cCluster and edit\u2026\u201d or create a text facet and then press the \u201cCluster\u201d button that appears in the facet box. \n+\n+![A screenshot of the Clustering window.](/img/cluster.png)\n+\n+The clustering pop-up window will take a small amount of time to analyze your column, and then make some suggestions based on the clustering method currently active. \n+\n+For each cluster identified, you can pick one of the existing values to apply to all cells, or manually type in a new value in the text box. And, of course, you can choose not to cluster them at all. OpenRefine will keep analyzing every time you make a change, with \u201cMerge selected & re-cluster,\u201d and you can work through all the methods this way. \n+\n+You can also export the currently identified clusters as a JSON file, or close the window with or without applying your changes. You can also use the histograms on the right to narrow down to, for example, clusters with lots of matching rows, or clusters of long or short values. \n+\n+### Clustering methods\n+\n+You don\u2019t need to understand the details behind each clustering method to apply them successfully to your data. The order in which these methods are presented in the interface and on this page is the order we recommend - starting with the most strict rules and moving to the most lax, which require more human supervision to apply correctly. \n+\n+The clustering pop-up window offers you a variety of clustering methods:\n+\n+*   key collision\n+    *   fingerprint\n+    *   ngram-fingerprint\n+    *   metaphone3\n+    *   cologne-phonetic\n+    *   Daitch-Mokotoff\n+    *   Beider-Morse\n+*   nearest neighbor\n+    *   levenshtein\n+    *   ppm\n+\n+**Key collisions** are very fast and can process millions of cells in seconds:\n+\n+**Fingerprinting** is the least likely to produce false positives, so it\u2019s a good place to start. It does the same kind of data-cleaning behind the scenes that you might think to do manually: fix whitespace into single spaces, put all uppercase letters into lowercase, discard punctuation, convert special characters to their ASCII equivalent, split all strings (words) and reorganize them alphabetically (so \u201cZhenyi, Wang\u201d becomes \u201cWang Zhenyi\u201d). This makes comparing those types of name values very easy.\n+\n+**N-gram fingerprinting** allows you to set the _n_ value to whatever number you\u2019d like, and will create n-grams of _n_ size (after doing some cleaning), alphabetize them, then join them back together into a _fingerprint_. For example, a 1-gram fingerprint will simply organize all the letters in the cell into alphabetical order - by creating grams with one character length. A 2-gram fingerprint will find all the two-character grams, remove duplicates, alphabetize them, and join them back together. This can help match cells that have typos, or incorrect spaces (such as matching \u201clookout\u201d and \u201clook out,\u201d which fingerprinting itself won\u2019t identify). The higher the _n_ value, the fewer clusters will be identified. With 1-grams, keep an eye out for mismatched values that are near-anagrams of each other (such as \u201cWellington\u201d and \u201cElgin Town\u201d). \n+\n+The next four methods are phonetic algorithsm: they know whether two letters sound the same when pronounced out loud, and assess text values based on that (such as knowing that a word with an \u201cS\u201d might be a mistype of a word with a \u201cZ\u201d).  They are great for spotting mistakes made by not knowing the spelling of a word or name after only hearing it spoken aloud. \n+\n+**Metaphone3 fingerprinting** is an English-language phonetic algorithm. For example, \"Reuben Gevorkiantz\" and \"Ruben Gevorkyants\" share the same phonetic fingerprint in English.\n+\n+**Cologne fingerprinting** is another phonetic algorithm, but for German pronunciation. \n+\n+**Daitch-Mokotoff** is a phonetic algorithm for Slavic and Yiddish words, especially names. **Baider-Morse** is a version of Daitch-Mokotoff that is slightly more strict. \n+\n+Regardless of the language of your data, applying each of them might find different potential matches: for example, Metaphone clusters \u201cCornwall\u201d and \u201cCorn Hill\u201d and \u201cGreen Hill,\u201d while Cologne clusters \u201cGreenvale\u201d and \u201cGranville\u201d and \u201cCornwall\u201d and \u201cGreen Wall.\u201d \n+\n+**Nearest neighbor **clustering methods are slower than key collision methods. They allow the user to set a radius - a threshold for matching or not matching. OpenRefine uses a \u201cblocking\u201d method first, which sorts values based on whether they have a certain amount of similarity (the default is \u201c6\u201d for a six-character string of identical characters) and then runs the nearest-neighbor operations on those sorted groups. We recommend setting the block number to at least three, and then increasing it if you need to be more strict (for example, if every value with \u201criver\u201d is being matched, you should increase it to 6 or more). Increasing the radius will make the matches more lax, as bigger differences will be clustered:\n+\n+**Levenshtein distance** counts the number of operations required to make one value perfectly match another. As in the key collision methods above, it will do things like change uppercase to lowercase, fix whitespace, change special characters, etc. Each character that gets changed counts as 1 \u201cdistance.\u201d \u201cNew York\u201d and \u201cnewyork\u201d have an edit distance value of 3 (\u201cN\u201d to \u201cn\u201d, \u201cY\u201d to \u201cy,\u201d remove the space). It can do relatively advanced operations, such as understand the distance between \u201cM. Makeba\u201d and \u201cMiriam Makeba\u201d (5), but it may create false positives if these distances are greater than other, simpler transformations (such as the one-character distance to \u201cB. Makeba,\u201d another person entirely).", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5MDQ0NQ==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475890445", "bodyText": "\"Edits\" it is! I don't think it needs a link but if you have one or two to suggest I'd like to see them.", "author": "allanaaa", "createdAt": "2020-08-24T20:58:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODkwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMDI0Nw==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475830247", "bodyText": "Note that this isn't \"title case\" as a librarian or book editor would do it.", "author": "tfmorris", "createdAt": "2020-08-24T19:00:55Z", "path": "docs/docs/manual/cellediting.md", "diffHunk": "@@ -0,0 +1,162 @@\n+---\n+id: cellediting\n+title: Cell editing\n+sidebar_label: Cell editing\n+---\n+## Overview\n+\n+OpenRefine offers a number of features to edit and improve the contents of cells automatically and efficiently. \n+\n+One way of doing this is editing through a [text facet](facets#text-facet). Once you have created a facet on a column, hover over the displayed results in the sidebar. Click on the small \u201cedit\u201d button that appears to the right of the facet, and type in a new value. This will apply to all the cells in the facet. \n+\n+## Transform\n+\n+Select \u201cEdit cells\u201d > \u201cTransforms\u201d to open up an expressions window. From here, you can apply [expressions](expressions) to your data. The simplest examples are GREL functions such as `toUppercase` or `toLowercase`, used in expressions as `toUppercase(value)` or `toLowercase(value)`. In all of these cases, `value` is the value in each cell in the selected column. \n+\n+Use the preview to ensure your data is being transformed correctly. \n+\n+You can also switch to the \u201cHistory\u201d tab inside the expressions window to reuse expressions you\u2019ve already attempted in this project, whether they have been undone or not. \n+\n+OpenRefine offers you some frequently-used transformations in the next menu option, \u201cCommon transforms.\u201d For more custom transforms, read up on [expressions](expressions). \n+\n+## Common transforms\n+\n+### Trim leading and trailing whitespace\n+\n+Often cell contents that should be identical, and look identical, are different because of space or line-break characters that are invisible to users. This function will get rid of any characters that sit before or after visible text characters.\n+\n+### Collapse consecutive whitespace\n+\n+You may also find that some text cells contain what look like spaces but are actually tabs, or contain multiple spaces in a row. This function will remove all space characters that sit in sequence and replace them with a single space. \n+\n+### Unescape HTML \n+\n+Your data may come from an HTML-formatted source that expresses some characters through references (such as \"&amp;nbsp;\" for a space, or \"%u0107\" for a \u0107) instead of the actual Unicode characters. You can use the \u201cunescape HTML entities\u201d transform to look for these codes and replace them with the characters they represent. \n+\n+### Replace smart quotes with ASCII\n+\n+Smart quotes (or curly quotes) recognize whether they come at the beginning or end of a string, and will generate an \u201copen\u201d quote (\u201c) and a \u201cclose\u201d quote (\u201d). These characters are not ASCII-compliant (though they are UTF8-compliant) so you can use this tranform to replace them with a straight double quote character (\") instead. \n+\n+### Case transforms\n+\n+You can transform an entire column of text into UPPERCASE, lowercase, or Title Case using these three options. This can be useful if you are planning to do textual analysis and wish to avoid case-sensitivity (which many functions are) causing problems in your analysis. ", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMTUwOQ==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475831509", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            As detailed in [Data types](exploring#data-types), OpenRefine recognizes seven data types: string, number, boolean, date, array, error, and null. When you use these transforms, OpenRefine will check to see if the given values can be converted, then both transform the data in the cells (such as \u201c3\u201d as a text string to \u201c3\u201d as a number) and convert the data type on each successfully transformed cell. Cells that cannot be transformed will output the original value and maintain their original data type. \n          \n          \n            \n            As detailed in [Data types](exploring#data-types), OpenRefine recognizes five data types: string, number, boolean, date, and array. It also has an internal data type for storing errors. When you use these transforms, OpenRefine will check to see if the given values can be converted, then both transform the data in the cells (such as \u201c3\u201d as a text string to \u201c3\u201d as a number) and convert the data type on each successfully transformed cell. Cells that cannot be transformed will keep the original value and data type.", "author": "tfmorris", "createdAt": "2020-08-24T19:03:26Z", "path": "docs/docs/manual/cellediting.md", "diffHunk": "@@ -0,0 +1,162 @@\n+---\n+id: cellediting\n+title: Cell editing\n+sidebar_label: Cell editing\n+---\n+## Overview\n+\n+OpenRefine offers a number of features to edit and improve the contents of cells automatically and efficiently. \n+\n+One way of doing this is editing through a [text facet](facets#text-facet). Once you have created a facet on a column, hover over the displayed results in the sidebar. Click on the small \u201cedit\u201d button that appears to the right of the facet, and type in a new value. This will apply to all the cells in the facet. \n+\n+## Transform\n+\n+Select \u201cEdit cells\u201d > \u201cTransforms\u201d to open up an expressions window. From here, you can apply [expressions](expressions) to your data. The simplest examples are GREL functions such as `toUppercase` or `toLowercase`, used in expressions as `toUppercase(value)` or `toLowercase(value)`. In all of these cases, `value` is the value in each cell in the selected column. \n+\n+Use the preview to ensure your data is being transformed correctly. \n+\n+You can also switch to the \u201cHistory\u201d tab inside the expressions window to reuse expressions you\u2019ve already attempted in this project, whether they have been undone or not. \n+\n+OpenRefine offers you some frequently-used transformations in the next menu option, \u201cCommon transforms.\u201d For more custom transforms, read up on [expressions](expressions). \n+\n+## Common transforms\n+\n+### Trim leading and trailing whitespace\n+\n+Often cell contents that should be identical, and look identical, are different because of space or line-break characters that are invisible to users. This function will get rid of any characters that sit before or after visible text characters.\n+\n+### Collapse consecutive whitespace\n+\n+You may also find that some text cells contain what look like spaces but are actually tabs, or contain multiple spaces in a row. This function will remove all space characters that sit in sequence and replace them with a single space. \n+\n+### Unescape HTML \n+\n+Your data may come from an HTML-formatted source that expresses some characters through references (such as \"&amp;nbsp;\" for a space, or \"%u0107\" for a \u0107) instead of the actual Unicode characters. You can use the \u201cunescape HTML entities\u201d transform to look for these codes and replace them with the characters they represent. \n+\n+### Replace smart quotes with ASCII\n+\n+Smart quotes (or curly quotes) recognize whether they come at the beginning or end of a string, and will generate an \u201copen\u201d quote (\u201c) and a \u201cclose\u201d quote (\u201d). These characters are not ASCII-compliant (though they are UTF8-compliant) so you can use this tranform to replace them with a straight double quote character (\") instead. \n+\n+### Case transforms\n+\n+You can transform an entire column of text into UPPERCASE, lowercase, or Title Case using these three options. This can be useful if you are planning to do textual analysis and wish to avoid case-sensitivity (which many functions are) causing problems in your analysis. \n+\n+### Data-type transforms\n+\n+As detailed in [Data types](exploring#data-types), OpenRefine recognizes seven data types: string, number, boolean, date, array, error, and null. When you use these transforms, OpenRefine will check to see if the given values can be converted, then both transform the data in the cells (such as \u201c3\u201d as a text string to \u201c3\u201d as a number) and convert the data type on each successfully transformed cell. Cells that cannot be transformed will output the original value and maintain their original data type. ", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5MzM4Mg==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475893382", "bodyText": "Apparently we don't want to include \"array\" in this list either, according to last week's conversation about data types. This whole sentence will be cleaned up.", "author": "allanaaa", "createdAt": "2020-08-24T21:04:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMTUwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMjc3MQ==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475832771", "bodyText": "A common error here is not using \"Make sort permanent,\" so it's probably worth mentioning.", "author": "tfmorris", "createdAt": "2020-08-24T19:05:55Z", "path": "docs/docs/manual/cellediting.md", "diffHunk": "@@ -0,0 +1,162 @@\n+---\n+id: cellediting\n+title: Cell editing\n+sidebar_label: Cell editing\n+---\n+## Overview\n+\n+OpenRefine offers a number of features to edit and improve the contents of cells automatically and efficiently. \n+\n+One way of doing this is editing through a [text facet](facets#text-facet). Once you have created a facet on a column, hover over the displayed results in the sidebar. Click on the small \u201cedit\u201d button that appears to the right of the facet, and type in a new value. This will apply to all the cells in the facet. \n+\n+## Transform\n+\n+Select \u201cEdit cells\u201d > \u201cTransforms\u201d to open up an expressions window. From here, you can apply [expressions](expressions) to your data. The simplest examples are GREL functions such as `toUppercase` or `toLowercase`, used in expressions as `toUppercase(value)` or `toLowercase(value)`. In all of these cases, `value` is the value in each cell in the selected column. \n+\n+Use the preview to ensure your data is being transformed correctly. \n+\n+You can also switch to the \u201cHistory\u201d tab inside the expressions window to reuse expressions you\u2019ve already attempted in this project, whether they have been undone or not. \n+\n+OpenRefine offers you some frequently-used transformations in the next menu option, \u201cCommon transforms.\u201d For more custom transforms, read up on [expressions](expressions). \n+\n+## Common transforms\n+\n+### Trim leading and trailing whitespace\n+\n+Often cell contents that should be identical, and look identical, are different because of space or line-break characters that are invisible to users. This function will get rid of any characters that sit before or after visible text characters.\n+\n+### Collapse consecutive whitespace\n+\n+You may also find that some text cells contain what look like spaces but are actually tabs, or contain multiple spaces in a row. This function will remove all space characters that sit in sequence and replace them with a single space. \n+\n+### Unescape HTML \n+\n+Your data may come from an HTML-formatted source that expresses some characters through references (such as \"&amp;nbsp;\" for a space, or \"%u0107\" for a \u0107) instead of the actual Unicode characters. You can use the \u201cunescape HTML entities\u201d transform to look for these codes and replace them with the characters they represent. \n+\n+### Replace smart quotes with ASCII\n+\n+Smart quotes (or curly quotes) recognize whether they come at the beginning or end of a string, and will generate an \u201copen\u201d quote (\u201c) and a \u201cclose\u201d quote (\u201d). These characters are not ASCII-compliant (though they are UTF8-compliant) so you can use this tranform to replace them with a straight double quote character (\") instead. \n+\n+### Case transforms\n+\n+You can transform an entire column of text into UPPERCASE, lowercase, or Title Case using these three options. This can be useful if you are planning to do textual analysis and wish to avoid case-sensitivity (which many functions are) causing problems in your analysis. \n+\n+### Data-type transforms\n+\n+As detailed in [Data types](exploring#data-types), OpenRefine recognizes seven data types: string, number, boolean, date, array, error, and null. When you use these transforms, OpenRefine will check to see if the given values can be converted, then both transform the data in the cells (such as \u201c3\u201d as a text string to \u201c3\u201d as a number) and convert the data type on each successfully transformed cell. Cells that cannot be transformed will output the original value and maintain their original data type. \n+\n+For example, the following column of strings on the left will transform into the values on the right:\n+\n+|Input|>|Output|\n+|---|---|---|\n+|23/12/2019|>|2019-12-23T00:00:00Z|\n+|14-10-2015|>|2015-10-14T00:00:00Z|\n+|2012 02 16|>|2012-02-16T00:00:00Z|\n+|August 2nd 1964|>|1964-08-02T00:00:00Z|\n+|today|>|today|\n+|never|>|never|\n+\n+This is based on OpenRefine\u2019s ability to recognize dates with the [`toDate()` function](expressions#dates). \n+\n+Clicking the \u201ctoday\u201d cell and editing its data type manually will convert \u201ctoday\u201d into a value such as \u201c2020-08-14T00:00:00Z\u201d. Attempting the same data-type change on \u201cnever\u201d will give you an error message and refuse to proceed.  \n+\n+Because these common transforms do not offer the ability to output an error instead of the original cell contents, be careful to look for unconverted and untransformed values. You will see a yellow alert at the top of screen that will tell you how many cells were converted - if this number does not match your current row set, you will need to look for and manually correct the remaining cells. \n+\n+You can also convert cells into null values or empty strings. This can be useful if you wish to, for example, erase duplicates that you have identified and are analyzing as a subset. \n+\n+## Fill down and blank down\n+\n+Fill down and blank down are two functions most frequently used when encountering data organized into [records](exploring#row-types-rows-vs-records) - that is, multiple rows associated with one specific entity. \n+\n+If you receive information in rows mode and want to convert it to records mode, the easiest way is to sort your first column by the value that you want to use as a unique records key, then blank down all the duplicates in that column. OpenRefine will retain the first unique value and erase the rest. Then you can switch from \u201cShow as rows\u201d to \u201cShow as records\u201d and OpenRefine will convert the data based on the remaining values in the first column. Be careful that your data is sorted properly before you begin blanking down - not just the first column but other columns you may want to have in a certain order. For example, you may have multiple identical entries in the first column, one with a value in the second column and one with an empty cell in the second column. In this case you want the value to come first, so that you can clean up empty rows later, once you blank down. ", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNDgyMw==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475834823", "bodyText": "cross() is a pretty advanced function. I think various string manipulation functions are likely much more commonly used.", "author": "tfmorris", "createdAt": "2020-08-24T19:09:47Z", "path": "docs/docs/manual/columnediting.md", "diffHunk": "@@ -0,0 +1,128 @@\n+---\n+id: columnediting\n+title: Column editing\n+sidebar_label: Column editing\n+---\n+\n+## Overview\n+\n+Column editing contains some of the most powerful data-improvement methods in OpenRefine. While we call it \u201cedit column,\u201d in fact many of the best features involve using one column of data to add entirely new columns and fields to your dataset. \n+\n+## Split or Join\n+\n+Many users find that they frequently need to make their data more granular: for example, splitting a \u201cFirstname Lastname\u201d column into two columns, one for first names and one for last names. You may want to split out an address column into columns for street addresses, cities, territories, and postal codes. \n+\n+The reverse is also often true: you may have several columns of category values that you want to join into one \u201ccategory\u201d column. \n+\n+### Split into several columns...\n+\n+![A screenshot of the settings window for splitting columns.](/img/columnsplit.png)\n+\n+Splitting one column into several columns requires you to identify the character, string lengths, or evaluating expression you want to split on. Just like [splitting multi-valued cells into rows](cellediting#split-multi-valued-cells), splitting cells into multiple columns will remove the separator character or string you indicate. Lengths will discard any information that comes after the specified total length. \n+\n+You can also specify a maximum number of new columns to be made: separator characters after this limit will be ignored, and the remaining characters will end up in the last column.\n+\n+New columns will be named after the original column, with a number: \u201cLocation 1,\u201d \u201cLocation 2,\u201d etc. You can have the original column removed with this operation, and you can have [data types](exploring#data-types) identified where possible. This function will work best with converting to numbers, and may not work with dates.\n+\n+### Join columns\u2026\n+\n+![A screenshot of the settings window for joining columns.](/img/columnjoin.png)\n+\n+You can join columns by selecting \u201cEdit column\u201d > \u201cJoin columns\u2026\u201d. All the columns currently in your dataset will appear in the pop-up window. You can select or un-select all the columns you want to join, and drag columns to put them in the order you want to join them in. You will define a separator character (optional) and define a string to insert into empty cells (nulls). \n+\n+The joined data will appear in the column you originally selected, or you can create a new column based on this join and specify a name. You can delete all the columns that were used in this join operation. \n+\n+## Add column based on this column\n+\n+This selection will open up an [expressions](expressions) window where you can transform the data from this column (using `value`) or write a complex expression that takes information from any number of columns or from external reconciliation sources. \n+\n+One common use of this function is to join information from two projects together in one place. Just like referring from one table to another table in an entity-relationship database, you need a key that exists in both. ", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNTc2MQ==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475835761", "bodyText": "5 seconds is very long for most web services. They should certainly be polite, but reducing this to 1 second or less if fine for the rate limit on most web services.", "author": "tfmorris", "createdAt": "2020-08-24T19:11:36Z", "path": "docs/docs/manual/columnediting.md", "diffHunk": "@@ -0,0 +1,128 @@\n+---\n+id: columnediting\n+title: Column editing\n+sidebar_label: Column editing\n+---\n+\n+## Overview\n+\n+Column editing contains some of the most powerful data-improvement methods in OpenRefine. While we call it \u201cedit column,\u201d in fact many of the best features involve using one column of data to add entirely new columns and fields to your dataset. \n+\n+## Split or Join\n+\n+Many users find that they frequently need to make their data more granular: for example, splitting a \u201cFirstname Lastname\u201d column into two columns, one for first names and one for last names. You may want to split out an address column into columns for street addresses, cities, territories, and postal codes. \n+\n+The reverse is also often true: you may have several columns of category values that you want to join into one \u201ccategory\u201d column. \n+\n+### Split into several columns...\n+\n+![A screenshot of the settings window for splitting columns.](/img/columnsplit.png)\n+\n+Splitting one column into several columns requires you to identify the character, string lengths, or evaluating expression you want to split on. Just like [splitting multi-valued cells into rows](cellediting#split-multi-valued-cells), splitting cells into multiple columns will remove the separator character or string you indicate. Lengths will discard any information that comes after the specified total length. \n+\n+You can also specify a maximum number of new columns to be made: separator characters after this limit will be ignored, and the remaining characters will end up in the last column.\n+\n+New columns will be named after the original column, with a number: \u201cLocation 1,\u201d \u201cLocation 2,\u201d etc. You can have the original column removed with this operation, and you can have [data types](exploring#data-types) identified where possible. This function will work best with converting to numbers, and may not work with dates.\n+\n+### Join columns\u2026\n+\n+![A screenshot of the settings window for joining columns.](/img/columnjoin.png)\n+\n+You can join columns by selecting \u201cEdit column\u201d > \u201cJoin columns\u2026\u201d. All the columns currently in your dataset will appear in the pop-up window. You can select or un-select all the columns you want to join, and drag columns to put them in the order you want to join them in. You will define a separator character (optional) and define a string to insert into empty cells (nulls). \n+\n+The joined data will appear in the column you originally selected, or you can create a new column based on this join and specify a name. You can delete all the columns that were used in this join operation. \n+\n+## Add column based on this column\n+\n+This selection will open up an [expressions](expressions) window where you can transform the data from this column (using `value`) or write a complex expression that takes information from any number of columns or from external reconciliation sources. \n+\n+One common use of this function is to join information from two projects together in one place. Just like referring from one table to another table in an entity-relationship database, you need a key that exists in both. \n+\n+The expression is\n+\n+```cell.cross('arg1','arg2').cells['arg3'].value[arg4]```\n+\n+where \n+\n+*   **arg1** is the name of the project you want to pull data from (you will get an error in the Preview window if there are multiple projects with the identified name)\n+*   **arg2** is the column in that project with matching values to the column in the current project\n+*   **arg3** is the column in that project you\u2019d like to copy over (you can only specify one column at a time)\n+*   and **arg4** is which value in that column to import (most likely 0).\n+\n+Learn more about [cross()](expressions#cross) and other GREL functions to use in this window on the [Expressions](expressions) page. \n+\n+Some of the other most common ways to add a new column based on an existing one are separate functions, and are explained below.\n+\n+\n+## Add column by fetching URLs\n+\n+Through the \"Add column by fetching URLs\" function, OpenRefine supports the ability to fetch HTML or data from web pages or services. In this operation you will be taking strings from your selected column and inserting them into URL strings. This presumes your chosen column contains parts of paths to valid HTML pages or files online. \n+\n+If you have a column of URLs and watch to fetch the information that they point to, you can simply run the expression as `value`. If your column has, for example, unique identifiers for Wikidata entities (numerical values starting with Q), you can download the JSON-formatted metadata about each entity with\n+\n+```\u201chttps://www.wikidata.org/wiki/Special:EntityData/\u201d + value + \u201c.json\u201d```\n+\n+or whatever metadata format you prefer. [Information about these Wikidata options can be found here](https://www.wikidata.org/wiki/Wikidata:Data_access).\n+\n+This service is more useful when getting metadata files instead of HTML files, but you may wish to work with a page\u2019s entire HTML contents and then parse out information from that. Be cautioned that the fetching process can take quite some time and that servers may not want to fulfill hundreds or thousands of page requests in seconds. \n+\n+Fetching allows you to set a \u201cthrottle delay\u201d which determines the amount of time between requests. The default is 5 seconds per row in your dataset (5000 milliseconds), so you can estimate how long it will take to work through the entire column using that number. We recommend leaving this value at 5000 or greater. ", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5NTI2Mw==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475895263", "bodyText": "Is \"leaving this value at 1000 or greater\" okay? Or should we provide some guidance on how to calculate this?\nWould it also be worth changing the default in the program?", "author": "allanaaa", "createdAt": "2020-08-24T21:08:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNTc2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjU2MjUwNA==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r476562504", "bodyText": "In our meeting today we agreed, so there's an issue for this now: #3127\nIn terms of guidance we'll simply cut that \"recommend\" sentence.", "author": "allanaaa", "createdAt": "2020-08-25T16:02:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNTc2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzA4OQ==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475837089", "bodyText": "We should warn users that the authorization credentials get logged in the operation history in plain text, representing a security concern that they need to be aware of.", "author": "tfmorris", "createdAt": "2020-08-24T19:14:15Z", "path": "docs/docs/manual/columnediting.md", "diffHunk": "@@ -0,0 +1,128 @@\n+---\n+id: columnediting\n+title: Column editing\n+sidebar_label: Column editing\n+---\n+\n+## Overview\n+\n+Column editing contains some of the most powerful data-improvement methods in OpenRefine. While we call it \u201cedit column,\u201d in fact many of the best features involve using one column of data to add entirely new columns and fields to your dataset. \n+\n+## Split or Join\n+\n+Many users find that they frequently need to make their data more granular: for example, splitting a \u201cFirstname Lastname\u201d column into two columns, one for first names and one for last names. You may want to split out an address column into columns for street addresses, cities, territories, and postal codes. \n+\n+The reverse is also often true: you may have several columns of category values that you want to join into one \u201ccategory\u201d column. \n+\n+### Split into several columns...\n+\n+![A screenshot of the settings window for splitting columns.](/img/columnsplit.png)\n+\n+Splitting one column into several columns requires you to identify the character, string lengths, or evaluating expression you want to split on. Just like [splitting multi-valued cells into rows](cellediting#split-multi-valued-cells), splitting cells into multiple columns will remove the separator character or string you indicate. Lengths will discard any information that comes after the specified total length. \n+\n+You can also specify a maximum number of new columns to be made: separator characters after this limit will be ignored, and the remaining characters will end up in the last column.\n+\n+New columns will be named after the original column, with a number: \u201cLocation 1,\u201d \u201cLocation 2,\u201d etc. You can have the original column removed with this operation, and you can have [data types](exploring#data-types) identified where possible. This function will work best with converting to numbers, and may not work with dates.\n+\n+### Join columns\u2026\n+\n+![A screenshot of the settings window for joining columns.](/img/columnjoin.png)\n+\n+You can join columns by selecting \u201cEdit column\u201d > \u201cJoin columns\u2026\u201d. All the columns currently in your dataset will appear in the pop-up window. You can select or un-select all the columns you want to join, and drag columns to put them in the order you want to join them in. You will define a separator character (optional) and define a string to insert into empty cells (nulls). \n+\n+The joined data will appear in the column you originally selected, or you can create a new column based on this join and specify a name. You can delete all the columns that were used in this join operation. \n+\n+## Add column based on this column\n+\n+This selection will open up an [expressions](expressions) window where you can transform the data from this column (using `value`) or write a complex expression that takes information from any number of columns or from external reconciliation sources. \n+\n+One common use of this function is to join information from two projects together in one place. Just like referring from one table to another table in an entity-relationship database, you need a key that exists in both. \n+\n+The expression is\n+\n+```cell.cross('arg1','arg2').cells['arg3'].value[arg4]```\n+\n+where \n+\n+*   **arg1** is the name of the project you want to pull data from (you will get an error in the Preview window if there are multiple projects with the identified name)\n+*   **arg2** is the column in that project with matching values to the column in the current project\n+*   **arg3** is the column in that project you\u2019d like to copy over (you can only specify one column at a time)\n+*   and **arg4** is which value in that column to import (most likely 0).\n+\n+Learn more about [cross()](expressions#cross) and other GREL functions to use in this window on the [Expressions](expressions) page. \n+\n+Some of the other most common ways to add a new column based on an existing one are separate functions, and are explained below.\n+\n+\n+## Add column by fetching URLs\n+\n+Through the \"Add column by fetching URLs\" function, OpenRefine supports the ability to fetch HTML or data from web pages or services. In this operation you will be taking strings from your selected column and inserting them into URL strings. This presumes your chosen column contains parts of paths to valid HTML pages or files online. \n+\n+If you have a column of URLs and watch to fetch the information that they point to, you can simply run the expression as `value`. If your column has, for example, unique identifiers for Wikidata entities (numerical values starting with Q), you can download the JSON-formatted metadata about each entity with\n+\n+```\u201chttps://www.wikidata.org/wiki/Special:EntityData/\u201d + value + \u201c.json\u201d```\n+\n+or whatever metadata format you prefer. [Information about these Wikidata options can be found here](https://www.wikidata.org/wiki/Wikidata:Data_access).\n+\n+This service is more useful when getting metadata files instead of HTML files, but you may wish to work with a page\u2019s entire HTML contents and then parse out information from that. Be cautioned that the fetching process can take quite some time and that servers may not want to fulfill hundreds or thousands of page requests in seconds. \n+\n+Fetching allows you to set a \u201cthrottle delay\u201d which determines the amount of time between requests. The default is 5 seconds per row in your dataset (5000 milliseconds), so you can estimate how long it will take to work through the entire column using that number. We recommend leaving this value at 5000 or greater. \n+\n+![A screenshot of the settings window for fetching URLs.](/img/fetchingURLs.png)\n+\n+Note the following:\n+\n+* Many systems prevent you from making too many requests per second. To avoid this problem, set the throttle delay, which tells OpenRefine to wait the specified number of milliseconds between URL requests.\n+* Before pressing OK, copy/paste a URL or two from the right column in the dialog and test them in another browser tab to make sure they work.\n+* In some situations you may need to set[ HTTP request headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers). To set these, click the small \u201cShow\u201d button next to \"HTTP headers to be used when fetching URLs\" in the settings window. You can set the following request headers:\n+  * [User-Agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent)\n+  * [Accept](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept)\n+  * [Authorization](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization)", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzODc3Nw==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475838777", "bodyText": "In addition to Mac, also Windows users who are using the OpenRefine kit with the bundled JRE.\nI'm not sure this merits such a prominent mention though. Historically when this happens there is a cluster of problems for a lot of users, but it's a relatively infrequent occurrence.", "author": "tfmorris", "createdAt": "2020-08-24T19:17:24Z", "path": "docs/docs/manual/columnediting.md", "diffHunk": "@@ -0,0 +1,128 @@\n+---\n+id: columnediting\n+title: Column editing\n+sidebar_label: Column editing\n+---\n+\n+## Overview\n+\n+Column editing contains some of the most powerful data-improvement methods in OpenRefine. While we call it \u201cedit column,\u201d in fact many of the best features involve using one column of data to add entirely new columns and fields to your dataset. \n+\n+## Split or Join\n+\n+Many users find that they frequently need to make their data more granular: for example, splitting a \u201cFirstname Lastname\u201d column into two columns, one for first names and one for last names. You may want to split out an address column into columns for street addresses, cities, territories, and postal codes. \n+\n+The reverse is also often true: you may have several columns of category values that you want to join into one \u201ccategory\u201d column. \n+\n+### Split into several columns...\n+\n+![A screenshot of the settings window for splitting columns.](/img/columnsplit.png)\n+\n+Splitting one column into several columns requires you to identify the character, string lengths, or evaluating expression you want to split on. Just like [splitting multi-valued cells into rows](cellediting#split-multi-valued-cells), splitting cells into multiple columns will remove the separator character or string you indicate. Lengths will discard any information that comes after the specified total length. \n+\n+You can also specify a maximum number of new columns to be made: separator characters after this limit will be ignored, and the remaining characters will end up in the last column.\n+\n+New columns will be named after the original column, with a number: \u201cLocation 1,\u201d \u201cLocation 2,\u201d etc. You can have the original column removed with this operation, and you can have [data types](exploring#data-types) identified where possible. This function will work best with converting to numbers, and may not work with dates.\n+\n+### Join columns\u2026\n+\n+![A screenshot of the settings window for joining columns.](/img/columnjoin.png)\n+\n+You can join columns by selecting \u201cEdit column\u201d > \u201cJoin columns\u2026\u201d. All the columns currently in your dataset will appear in the pop-up window. You can select or un-select all the columns you want to join, and drag columns to put them in the order you want to join them in. You will define a separator character (optional) and define a string to insert into empty cells (nulls). \n+\n+The joined data will appear in the column you originally selected, or you can create a new column based on this join and specify a name. You can delete all the columns that were used in this join operation. \n+\n+## Add column based on this column\n+\n+This selection will open up an [expressions](expressions) window where you can transform the data from this column (using `value`) or write a complex expression that takes information from any number of columns or from external reconciliation sources. \n+\n+One common use of this function is to join information from two projects together in one place. Just like referring from one table to another table in an entity-relationship database, you need a key that exists in both. \n+\n+The expression is\n+\n+```cell.cross('arg1','arg2').cells['arg3'].value[arg4]```\n+\n+where \n+\n+*   **arg1** is the name of the project you want to pull data from (you will get an error in the Preview window if there are multiple projects with the identified name)\n+*   **arg2** is the column in that project with matching values to the column in the current project\n+*   **arg3** is the column in that project you\u2019d like to copy over (you can only specify one column at a time)\n+*   and **arg4** is which value in that column to import (most likely 0).\n+\n+Learn more about [cross()](expressions#cross) and other GREL functions to use in this window on the [Expressions](expressions) page. \n+\n+Some of the other most common ways to add a new column based on an existing one are separate functions, and are explained below.\n+\n+\n+## Add column by fetching URLs\n+\n+Through the \"Add column by fetching URLs\" function, OpenRefine supports the ability to fetch HTML or data from web pages or services. In this operation you will be taking strings from your selected column and inserting them into URL strings. This presumes your chosen column contains parts of paths to valid HTML pages or files online. \n+\n+If you have a column of URLs and watch to fetch the information that they point to, you can simply run the expression as `value`. If your column has, for example, unique identifiers for Wikidata entities (numerical values starting with Q), you can download the JSON-formatted metadata about each entity with\n+\n+```\u201chttps://www.wikidata.org/wiki/Special:EntityData/\u201d + value + \u201c.json\u201d```\n+\n+or whatever metadata format you prefer. [Information about these Wikidata options can be found here](https://www.wikidata.org/wiki/Wikidata:Data_access).\n+\n+This service is more useful when getting metadata files instead of HTML files, but you may wish to work with a page\u2019s entire HTML contents and then parse out information from that. Be cautioned that the fetching process can take quite some time and that servers may not want to fulfill hundreds or thousands of page requests in seconds. \n+\n+Fetching allows you to set a \u201cthrottle delay\u201d which determines the amount of time between requests. The default is 5 seconds per row in your dataset (5000 milliseconds), so you can estimate how long it will take to work through the entire column using that number. We recommend leaving this value at 5000 or greater. \n+\n+![A screenshot of the settings window for fetching URLs.](/img/fetchingURLs.png)\n+\n+Note the following:\n+\n+* Many systems prevent you from making too many requests per second. To avoid this problem, set the throttle delay, which tells OpenRefine to wait the specified number of milliseconds between URL requests.\n+* Before pressing OK, copy/paste a URL or two from the right column in the dialog and test them in another browser tab to make sure they work.\n+* In some situations you may need to set[ HTTP request headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers). To set these, click the small \u201cShow\u201d button next to \"HTTP headers to be used when fetching URLs\" in the settings window. You can set the following request headers:\n+  * [User-Agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent)\n+  * [Accept](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept)\n+  * [Authorization](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization)\n+\n+### Common errors\n+\n+When OpenRefine attempts to fetch information from a web page or service, it can fail in a variety of ways. The following information is meant to help troubleshoot and fix problems encountered when using this function.\n+\n+First, make sure that your fetching operation is storing errors (check \u201cstore error\u201d). The run the fetch and look at the error messages. \n+\n+**\"Received fatal alert: handshake_failure\" **can occur when you are trying to retrieve information over HTTPS but the remote site is using an encryption not supported by the Java virtual machine being used by OpenRefine.\n+\n+You can check which encryption methods are supported by your OpenRefine/Java installation by using a service such as **How's my SSL**. Add the URL `https://www.howsmyssl.com/a/check` to an OpenRefine cell and run \"Add column by fetching URLs\" on it, which will provide a description of the SSL client being used. \n+\n+You can try installing additional encryption supports by installing the [Java Cryptography Extension](https://www.oracle.com/java/technologies/javase-jce8-downloads.html). Note on OpenRefine for Mac, these updated cipher suites need to be dropped into the Java install within the OpenRefine application: something like `/Applications/OpenRefine.app/Contents/PlugIns/jdk1.8.0_60.jdk/Contents/Home/jre/lib/security`.", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg5NzI3OA==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475897278", "bodyText": "Yes, I wondered the same - not having anecdotal experience with any of these errors, I'm glad someone piped up.\nHaving reordered with the 4xx/5xx errors first, can any of these be eliminated from the list as no longer being \"common\"?", "author": "allanaaa", "createdAt": "2020-08-24T21:12:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzODc3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjU4MTc1NQ==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r486581755", "bodyText": "FYI to all, these are the current error messages listed - this is your chance to let me know if anything needs to be removed or added:\n\"HTTP error 403 : Forbidden\"\n\"HTTP error 404 : Not Found\"\n\"HTTP error 500 : Internal Server Error\"\n\u201cerror: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure\u201d\n\"sun.security.validator.ValidatorException: PKIX path building failed\"", "author": "allanaaa", "createdAt": "2020-09-10T19:23:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzODc3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYxNjIxOQ==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r486616219", "bodyText": "@allanaaa You mean just for the Fetch URLs operation however, right?  because there's also about 250+ error message kinds for Transforming data that could get potentially stored in a cell depending on if you checked the radio button to store the error. ;-)", "author": "thadguidry", "createdAt": "2020-09-10T20:32:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzODc3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzOTUyNA==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475839524", "bodyText": "4xx errors are going to be the most common, by far, so they should go first, followed by 5xx, then everything else.", "author": "tfmorris", "createdAt": "2020-08-24T19:19:00Z", "path": "docs/docs/manual/columnediting.md", "diffHunk": "@@ -0,0 +1,128 @@\n+---\n+id: columnediting\n+title: Column editing\n+sidebar_label: Column editing\n+---\n+\n+## Overview\n+\n+Column editing contains some of the most powerful data-improvement methods in OpenRefine. While we call it \u201cedit column,\u201d in fact many of the best features involve using one column of data to add entirely new columns and fields to your dataset. \n+\n+## Split or Join\n+\n+Many users find that they frequently need to make their data more granular: for example, splitting a \u201cFirstname Lastname\u201d column into two columns, one for first names and one for last names. You may want to split out an address column into columns for street addresses, cities, territories, and postal codes. \n+\n+The reverse is also often true: you may have several columns of category values that you want to join into one \u201ccategory\u201d column. \n+\n+### Split into several columns...\n+\n+![A screenshot of the settings window for splitting columns.](/img/columnsplit.png)\n+\n+Splitting one column into several columns requires you to identify the character, string lengths, or evaluating expression you want to split on. Just like [splitting multi-valued cells into rows](cellediting#split-multi-valued-cells), splitting cells into multiple columns will remove the separator character or string you indicate. Lengths will discard any information that comes after the specified total length. \n+\n+You can also specify a maximum number of new columns to be made: separator characters after this limit will be ignored, and the remaining characters will end up in the last column.\n+\n+New columns will be named after the original column, with a number: \u201cLocation 1,\u201d \u201cLocation 2,\u201d etc. You can have the original column removed with this operation, and you can have [data types](exploring#data-types) identified where possible. This function will work best with converting to numbers, and may not work with dates.\n+\n+### Join columns\u2026\n+\n+![A screenshot of the settings window for joining columns.](/img/columnjoin.png)\n+\n+You can join columns by selecting \u201cEdit column\u201d > \u201cJoin columns\u2026\u201d. All the columns currently in your dataset will appear in the pop-up window. You can select or un-select all the columns you want to join, and drag columns to put them in the order you want to join them in. You will define a separator character (optional) and define a string to insert into empty cells (nulls). \n+\n+The joined data will appear in the column you originally selected, or you can create a new column based on this join and specify a name. You can delete all the columns that were used in this join operation. \n+\n+## Add column based on this column\n+\n+This selection will open up an [expressions](expressions) window where you can transform the data from this column (using `value`) or write a complex expression that takes information from any number of columns or from external reconciliation sources. \n+\n+One common use of this function is to join information from two projects together in one place. Just like referring from one table to another table in an entity-relationship database, you need a key that exists in both. \n+\n+The expression is\n+\n+```cell.cross('arg1','arg2').cells['arg3'].value[arg4]```\n+\n+where \n+\n+*   **arg1** is the name of the project you want to pull data from (you will get an error in the Preview window if there are multiple projects with the identified name)\n+*   **arg2** is the column in that project with matching values to the column in the current project\n+*   **arg3** is the column in that project you\u2019d like to copy over (you can only specify one column at a time)\n+*   and **arg4** is which value in that column to import (most likely 0).\n+\n+Learn more about [cross()](expressions#cross) and other GREL functions to use in this window on the [Expressions](expressions) page. \n+\n+Some of the other most common ways to add a new column based on an existing one are separate functions, and are explained below.\n+\n+\n+## Add column by fetching URLs\n+\n+Through the \"Add column by fetching URLs\" function, OpenRefine supports the ability to fetch HTML or data from web pages or services. In this operation you will be taking strings from your selected column and inserting them into URL strings. This presumes your chosen column contains parts of paths to valid HTML pages or files online. \n+\n+If you have a column of URLs and watch to fetch the information that they point to, you can simply run the expression as `value`. If your column has, for example, unique identifiers for Wikidata entities (numerical values starting with Q), you can download the JSON-formatted metadata about each entity with\n+\n+```\u201chttps://www.wikidata.org/wiki/Special:EntityData/\u201d + value + \u201c.json\u201d```\n+\n+or whatever metadata format you prefer. [Information about these Wikidata options can be found here](https://www.wikidata.org/wiki/Wikidata:Data_access).\n+\n+This service is more useful when getting metadata files instead of HTML files, but you may wish to work with a page\u2019s entire HTML contents and then parse out information from that. Be cautioned that the fetching process can take quite some time and that servers may not want to fulfill hundreds or thousands of page requests in seconds. \n+\n+Fetching allows you to set a \u201cthrottle delay\u201d which determines the amount of time between requests. The default is 5 seconds per row in your dataset (5000 milliseconds), so you can estimate how long it will take to work through the entire column using that number. We recommend leaving this value at 5000 or greater. \n+\n+![A screenshot of the settings window for fetching URLs.](/img/fetchingURLs.png)\n+\n+Note the following:\n+\n+* Many systems prevent you from making too many requests per second. To avoid this problem, set the throttle delay, which tells OpenRefine to wait the specified number of milliseconds between URL requests.\n+* Before pressing OK, copy/paste a URL or two from the right column in the dialog and test them in another browser tab to make sure they work.\n+* In some situations you may need to set[ HTTP request headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers). To set these, click the small \u201cShow\u201d button next to \"HTTP headers to be used when fetching URLs\" in the settings window. You can set the following request headers:\n+  * [User-Agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent)\n+  * [Accept](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept)\n+  * [Authorization](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization)\n+\n+### Common errors\n+\n+When OpenRefine attempts to fetch information from a web page or service, it can fail in a variety of ways. The following information is meant to help troubleshoot and fix problems encountered when using this function.\n+\n+First, make sure that your fetching operation is storing errors (check \u201cstore error\u201d). The run the fetch and look at the error messages. \n+\n+**\"Received fatal alert: handshake_failure\" **can occur when you are trying to retrieve information over HTTPS but the remote site is using an encryption not supported by the Java virtual machine being used by OpenRefine.\n+\n+You can check which encryption methods are supported by your OpenRefine/Java installation by using a service such as **How's my SSL**. Add the URL `https://www.howsmyssl.com/a/check` to an OpenRefine cell and run \"Add column by fetching URLs\" on it, which will provide a description of the SSL client being used. \n+\n+You can try installing additional encryption supports by installing the [Java Cryptography Extension](https://www.oracle.com/java/technologies/javase-jce8-downloads.html). Note on OpenRefine for Mac, these updated cipher suites need to be dropped into the Java install within the OpenRefine application: something like `/Applications/OpenRefine.app/Contents/PlugIns/jdk1.8.0_60.jdk/Contents/Home/jre/lib/security`.\n+\n+**\"sun.security.validator.ValidatorException: PKIX path building failed\"**can occur when you try to retrieve information over HTTPS but the remote site is using a certificate not trusted by your local Java installation. You will need to make sure that the certificate, or (more likely) the root certificate, is trusted. \n+\n+The list of trusted certificates is stored in an encrypted file called `cacerts` in your local Java installation. This can be read and updated by a tool called \u201ckeytool.\u201d You can find directions on how to add a security certificate to the list of trusted certificates for a Java installation [here](http://magicmonster.com/kb/prg/java/ssl/pkix_path_building_failed.html) and [here](http://javarevisited.blogspot.co.uk/2012/03/add-list-certficates-java-keystore.html).\n+\n+Note on OpenRefine for Mac, you need to update the `cacerts` file within the OpenRefine application: something like `/PlugIns/jdk1.8.0_60.jdk/Contents/Home/jre/lib/security/cacerts`.\n+\n+**\"HTTP error 403 : Forbidden\" **can be simply down to you not having access to the URL you are trying to use. If you can access the same URL with your browser, the remote site may be blocking OpenRefine because it doesn't recognize its request as valid. Changing the[ User-Agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) request header may help. If you believe you should have access to a site but are \u201cforbidden,\u201d you may wish to contract the administrators.", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MDc4Mg==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r475840782", "bodyText": "It might be better to use a non-commercial example like VIAF here (plus, we probably have more librarian users)", "author": "tfmorris", "createdAt": "2020-08-24T19:21:31Z", "path": "docs/docs/manual/columnediting.md", "diffHunk": "@@ -0,0 +1,128 @@\n+---\n+id: columnediting\n+title: Column editing\n+sidebar_label: Column editing\n+---\n+\n+## Overview\n+\n+Column editing contains some of the most powerful data-improvement methods in OpenRefine. While we call it \u201cedit column,\u201d in fact many of the best features involve using one column of data to add entirely new columns and fields to your dataset. \n+\n+## Split or Join\n+\n+Many users find that they frequently need to make their data more granular: for example, splitting a \u201cFirstname Lastname\u201d column into two columns, one for first names and one for last names. You may want to split out an address column into columns for street addresses, cities, territories, and postal codes. \n+\n+The reverse is also often true: you may have several columns of category values that you want to join into one \u201ccategory\u201d column. \n+\n+### Split into several columns...\n+\n+![A screenshot of the settings window for splitting columns.](/img/columnsplit.png)\n+\n+Splitting one column into several columns requires you to identify the character, string lengths, or evaluating expression you want to split on. Just like [splitting multi-valued cells into rows](cellediting#split-multi-valued-cells), splitting cells into multiple columns will remove the separator character or string you indicate. Lengths will discard any information that comes after the specified total length. \n+\n+You can also specify a maximum number of new columns to be made: separator characters after this limit will be ignored, and the remaining characters will end up in the last column.\n+\n+New columns will be named after the original column, with a number: \u201cLocation 1,\u201d \u201cLocation 2,\u201d etc. You can have the original column removed with this operation, and you can have [data types](exploring#data-types) identified where possible. This function will work best with converting to numbers, and may not work with dates.\n+\n+### Join columns\u2026\n+\n+![A screenshot of the settings window for joining columns.](/img/columnjoin.png)\n+\n+You can join columns by selecting \u201cEdit column\u201d > \u201cJoin columns\u2026\u201d. All the columns currently in your dataset will appear in the pop-up window. You can select or un-select all the columns you want to join, and drag columns to put them in the order you want to join them in. You will define a separator character (optional) and define a string to insert into empty cells (nulls). \n+\n+The joined data will appear in the column you originally selected, or you can create a new column based on this join and specify a name. You can delete all the columns that were used in this join operation. \n+\n+## Add column based on this column\n+\n+This selection will open up an [expressions](expressions) window where you can transform the data from this column (using `value`) or write a complex expression that takes information from any number of columns or from external reconciliation sources. \n+\n+One common use of this function is to join information from two projects together in one place. Just like referring from one table to another table in an entity-relationship database, you need a key that exists in both. \n+\n+The expression is\n+\n+```cell.cross('arg1','arg2').cells['arg3'].value[arg4]```\n+\n+where \n+\n+*   **arg1** is the name of the project you want to pull data from (you will get an error in the Preview window if there are multiple projects with the identified name)\n+*   **arg2** is the column in that project with matching values to the column in the current project\n+*   **arg3** is the column in that project you\u2019d like to copy over (you can only specify one column at a time)\n+*   and **arg4** is which value in that column to import (most likely 0).\n+\n+Learn more about [cross()](expressions#cross) and other GREL functions to use in this window on the [Expressions](expressions) page. \n+\n+Some of the other most common ways to add a new column based on an existing one are separate functions, and are explained below.\n+\n+\n+## Add column by fetching URLs\n+\n+Through the \"Add column by fetching URLs\" function, OpenRefine supports the ability to fetch HTML or data from web pages or services. In this operation you will be taking strings from your selected column and inserting them into URL strings. This presumes your chosen column contains parts of paths to valid HTML pages or files online. \n+\n+If you have a column of URLs and watch to fetch the information that they point to, you can simply run the expression as `value`. If your column has, for example, unique identifiers for Wikidata entities (numerical values starting with Q), you can download the JSON-formatted metadata about each entity with\n+\n+```\u201chttps://www.wikidata.org/wiki/Special:EntityData/\u201d + value + \u201c.json\u201d```\n+\n+or whatever metadata format you prefer. [Information about these Wikidata options can be found here](https://www.wikidata.org/wiki/Wikidata:Data_access).\n+\n+This service is more useful when getting metadata files instead of HTML files, but you may wish to work with a page\u2019s entire HTML contents and then parse out information from that. Be cautioned that the fetching process can take quite some time and that servers may not want to fulfill hundreds or thousands of page requests in seconds. \n+\n+Fetching allows you to set a \u201cthrottle delay\u201d which determines the amount of time between requests. The default is 5 seconds per row in your dataset (5000 milliseconds), so you can estimate how long it will take to work through the entire column using that number. We recommend leaving this value at 5000 or greater. \n+\n+![A screenshot of the settings window for fetching URLs.](/img/fetchingURLs.png)\n+\n+Note the following:\n+\n+* Many systems prevent you from making too many requests per second. To avoid this problem, set the throttle delay, which tells OpenRefine to wait the specified number of milliseconds between URL requests.\n+* Before pressing OK, copy/paste a URL or two from the right column in the dialog and test them in another browser tab to make sure they work.\n+* In some situations you may need to set[ HTTP request headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers). To set these, click the small \u201cShow\u201d button next to \"HTTP headers to be used when fetching URLs\" in the settings window. You can set the following request headers:\n+  * [User-Agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent)\n+  * [Accept](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept)\n+  * [Authorization](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization)\n+\n+### Common errors\n+\n+When OpenRefine attempts to fetch information from a web page or service, it can fail in a variety of ways. The following information is meant to help troubleshoot and fix problems encountered when using this function.\n+\n+First, make sure that your fetching operation is storing errors (check \u201cstore error\u201d). The run the fetch and look at the error messages. \n+\n+**\"Received fatal alert: handshake_failure\" **can occur when you are trying to retrieve information over HTTPS but the remote site is using an encryption not supported by the Java virtual machine being used by OpenRefine.\n+\n+You can check which encryption methods are supported by your OpenRefine/Java installation by using a service such as **How's my SSL**. Add the URL `https://www.howsmyssl.com/a/check` to an OpenRefine cell and run \"Add column by fetching URLs\" on it, which will provide a description of the SSL client being used. \n+\n+You can try installing additional encryption supports by installing the [Java Cryptography Extension](https://www.oracle.com/java/technologies/javase-jce8-downloads.html). Note on OpenRefine for Mac, these updated cipher suites need to be dropped into the Java install within the OpenRefine application: something like `/Applications/OpenRefine.app/Contents/PlugIns/jdk1.8.0_60.jdk/Contents/Home/jre/lib/security`.\n+\n+**\"sun.security.validator.ValidatorException: PKIX path building failed\"**can occur when you try to retrieve information over HTTPS but the remote site is using a certificate not trusted by your local Java installation. You will need to make sure that the certificate, or (more likely) the root certificate, is trusted. \n+\n+The list of trusted certificates is stored in an encrypted file called `cacerts` in your local Java installation. This can be read and updated by a tool called \u201ckeytool.\u201d You can find directions on how to add a security certificate to the list of trusted certificates for a Java installation [here](http://magicmonster.com/kb/prg/java/ssl/pkix_path_building_failed.html) and [here](http://javarevisited.blogspot.co.uk/2012/03/add-list-certficates-java-keystore.html).\n+\n+Note on OpenRefine for Mac, you need to update the `cacerts` file within the OpenRefine application: something like `/PlugIns/jdk1.8.0_60.jdk/Contents/Home/jre/lib/security/cacerts`.\n+\n+**\"HTTP error 403 : Forbidden\" **can be simply down to you not having access to the URL you are trying to use. If you can access the same URL with your browser, the remote site may be blocking OpenRefine because it doesn't recognize its request as valid. Changing the[ User-Agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) request header may help. If you believe you should have access to a site but are \u201cforbidden,\u201d you may wish to contract the administrators.\n+\n+**\"HTTP error 404 : Not Found\"** indicates that the information you are requesting does not exist, perhaps due to a problem with your cell values if it only happening in certain rows.** \"HTTP error 500 : Internal Server Error\"** indicates the remote server is having a problem filling your request. You may wish to simply wait and try again later, or double-check the URLs. \n+\n+## Add columns from reconciled values\n+\n+The \u201cAdd columns from reconciled values\u2026\u201d feature operates on reconciled columns in OpenRefine - that is, columns containing data that has been through [reconciliation](#reconcile) processes. See that section for more details about how to get your data into a reconciled format. \n+\n+Once you have pulled reconciliation values and selected one for each cell, selecting \u201cAdd column from reconciled values\u201d will bring up a window to choose which information you\u2019d like to generate into a new column. If you have reconciled against Wikidata, for example, you will see the option of adding their unique identifiers as a new column (automatically named \u201cQid\u201d). \n+\n+The quality of the suggested properties will depend on how you have reconciled your data beforehand: reconciling against a specific type will provide you with suggested properties of that type.\n+\n+![A screenshot of the settings window for adding reconciled values.](/img/columnreconciled.png)\n+\n+If you have left any values unreconciled in your column, you will see \u201c&lt;not reconciled>\u201d in the preview. These will generate blank cells if you continue with the column addition process. \n+\n+One reason to reconcile a dataset to some database is that it allows you to pull data from the database into OpenRefine. There are two ways to do this:\n+\n+*   If the reconciliation service supports the[ Data Extension API](https://github.com/OpenRefine/OpenRefine/wiki/Data%20Extension%20API), then you can use the \"Add columns from reconciled values\" action to augment your OpenRefine project with new columns. For example, if you have a column of chemical elements identified by name, you can fetch categorical information about them such as their atomic number and their element symbol, as the animation shows below.\n+\n+![A screenshare of elements fetching related information.](/img/reconcileelements.gif)\n+\n+*   If the reconciliation service does not support this feature, look out for a generic web API for that data source. You can use the \"Add column by fetching URLs\" operation to call this API with the IDs obtained from the reconciliation process. For instance, if you have used the OpenCorporates service, you can use[ their API](https://api.opencorporates.com/documentation/API-Reference) to fetch JSON-formatted data about the reconciled companies. The GREL expression `\"https://api.opencorporates.com/companies/\"+cell.recon.match.id` will be translated to URLs that can then be parsed in OpenRefine.", "originalCommit": "0b8c282800aaba80043fe05bcf74960b3d2fb7bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjUwNzAyNA==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r486507024", "bodyText": "I started with VIAF but I didn't love their metadata formats as a concrete example. I went with the Getty ULAN instead. I would love some feedback on this choice though:\nhttps://deploy-preview-3103--openrefine-docs.netlify.app/manual/reconciling#add-columns-by-fetching-urls\n\nIf the reconciliation service cannot extend data, look for a generic web API for that data source, or a structured URL that points to their dataset entities via unique IDs (such as https://viaf.org/viaf/000000). You can use the \"Edit column\" \u2192 \"Add column by fetching URLs\" operation to call this API or URL with the IDs obtained from the reconciliation process. This will require using GREL expressions.\nYou will likely not want to pull the entire HTML content of the pages at the ends of these URLs, so look to see whether the service offers a metadata endpoint, such as JSON-formatted data. You can either use a column of IDs, or you can pull the ID from each matched cell during the fetching process.\nFor example, if you have reconciled artists to the Getty's ULAN, and have their unique ULAN IDs as a column, you can generate a new column of JSON-formatted data by using \"Add column by fetching URLs\" and entering the GREL expression \"http://vocab.getty.edu/\" + value + \".json\" in the window. For this service, the unique IDs are formatted \"ulan/000000\" and so the generated URLs look like \"http://vocab.getty.edu/ulan/000000.json.\"\nYou can use the Add entity identifiers column operation above if you don't already have a column of unique IDs.\nYou can alternatively insert the ID directly from the matched column using a GREL expression like \"http://vocab.getty.edu/\" + cell.recon.match.id + \".json\" instead.\nRemember to set an appropriate throttle and to refer to the service documentation to ensure your compliance with their terms.", "author": "allanaaa", "createdAt": "2020-09-10T17:17:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MDc4Mg=="}], "type": "inlineReview"}, {"oid": "a07642ac763f552973cb9a06cabf2931036bf250", "url": "https://github.com/OpenRefine/OpenRefine/commit/a07642ac763f552973cb9a06cabf2931036bf250", "message": "Update docs/docs/manual/cellediting.md\n\nCo-authored-by: Tom Morris <tfmorris@gmail.com>", "committedDate": "2020-08-24T20:50:13Z", "type": "commit"}, {"oid": "83b548f0a2011f8bb411111e3b40060b078000d7", "url": "https://github.com/OpenRefine/OpenRefine/commit/83b548f0a2011f8bb411111e3b40060b078000d7", "message": "Vairous updates from Tom's comments", "committedDate": "2020-08-24T21:15:36Z", "type": "commit"}, {"oid": "c33596feb2f39d61ddf61ab1f6d983d2226305e3", "url": "https://github.com/OpenRefine/OpenRefine/commit/c33596feb2f39d61ddf61ab1f6d983d2226305e3", "message": "Merge branch 'docs-transforming' of https://github.com/allanaaa/OpenRefine into docs-transforming", "committedDate": "2020-08-24T21:16:14Z", "type": "commit"}, {"oid": "1975c7fe2452a6655d3396080874b9497f81f491", "url": "https://github.com/OpenRefine/OpenRefine/commit/1975c7fe2452a6655d3396080874b9497f81f491", "message": "Reconciling + Transposing", "committedDate": "2020-09-10T17:06:50Z", "type": "commit"}, {"oid": "a6acec07dd1e98958f09e00c24b47fa62d26dcae", "url": "https://github.com/OpenRefine/OpenRefine/commit/a6acec07dd1e98958f09e00c24b47fa62d26dcae", "message": "Mistakes!", "committedDate": "2020-09-10T17:11:01Z", "type": "commit"}, {"oid": "4abd1047fb19104154bdcb1ef9523e5b78c45871", "url": "https://github.com/OpenRefine/OpenRefine/commit/4abd1047fb19104154bdcb1ef9523e5b78c45871", "message": "Another mistake!", "committedDate": "2020-09-10T17:14:41Z", "type": "commit"}, {"oid": "81d3ce13b7f976ac5332d4ec6ae394f9a9b13746", "url": "https://github.com/OpenRefine/OpenRefine/commit/81d3ce13b7f976ac5332d4ec6ae394f9a9b13746", "message": "column editing > fetching URLs", "committedDate": "2020-09-10T19:13:06Z", "type": "commit"}, {"oid": "e5521d62a16232df26fdcb79b5f0a19599dcb223", "url": "https://github.com/OpenRefine/OpenRefine/commit/e5521d62a16232df26fdcb79b5f0a19599dcb223", "message": "Update cellediting.md", "committedDate": "2020-09-10T19:20:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzExMDI0Nw==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r487110247", "bodyText": "I would remove this part, since it is specific to this service.", "author": "wetneb", "createdAt": "2020-09-11T15:09:24Z", "path": "docs/docs/manual/reconciling.md", "diffHunk": "@@ -0,0 +1,192 @@\n+---\n+id: reconciling\n+title: Reconciling\n+sidebar_label: Reconciling\n+---\n+\n+## Overview\n+\n+Reconciliation is the process of matching your dataset with that of an external source. Authoritative datasets are produced by libraries, archives, museums, academic organizations, scientific institutions, non-profits, and interest groups. To reconcile your OpenRefine project against an authority, that authority must offer a web service that conforms to the [Reconciliation Service API standards](https://reconciliation-api.github.io/specs/0.1/). \n+\n+You may wish to reconcile in order to fix spelling or variations in proper names, to clean up manually-entered subject headings against authorities such as the [Library of Congress Subject Headings](https://id.loc.gov/authorities/subjects.html) (LCSH), to link your data to an existing set, to add it to an open and editable system such as [Wikidata](https://www.wikidata.org), or to see whether entities in your project appear in some specific list or not, such as the [Panama Papers](https://aleph.occrp.org/datasets/734).\n+\n+Reconciliation is semi-automated: OpenRefine matches your cell values to the reconciliation information as best it can, but human judgment is required to ensure the process is successful. Reconciling happens by default through string searching, so typos, whitespace, and extraneous characters will have an effect on the results. \n+\n+We strongly recommend planning your reconciliation operations as iterative: reconcile multiple times with different settings, from different services, with different subgroups of your data. \n+\n+## Sources\n+\n+There is a [current list of reconcilable authorities](https://reconciliation-api.github.io/testbench/) that includes instructions for adding new services via Wikidata editing.  OpenRefine maintains a [further list of sources on the wiki](https://github.com/OpenRefine/OpenRefine/wiki/Reconcilable-Data-Sources), which can be edited by anyone.\n+\n+Other services may exist that are not yet listed in these two places: for example, the [310 datasets hosted by the Organized Crime and Corruption Reporting Project (OCCRP)](https://aleph.occrp.org/datasets/) each have their own reconciliation URL, or you can reconcile against their entire database with the URL listed [here](https://reconciliation-api.github.io/testbench/). For another example, you can reconcile against the entire Virtual International Authority File (VIAF) dataset, or [only the contributions from certain institutions](http://refine.codefork.com/). Search online to see if the authority you wish to reconcile against has an available service.\n+\n+OpenRefine offers Wikidata reconciliation by default - see the [Wikidata](wikidata) page for more information particular to that service.\n+\n+:::info\n+Some OpenRefine extensions can add reconciliation services, and can also add enhanced reconciliation capacities. Check the list of extensions on the [Downloads page](https://openrefine.org/download.html) for more information.\n+:::\n+\n+## Getting started\n+\n+Select \u201cReconcile\u201d \u2192 \u201cStart reconciling\u201d on a column. If you want to reconcile only some cells in that column, first use filters and facets to isolate them.\n+\n+In the reconciliation window, you will see Wikidata offered as a default service. To add another service, click \u201cAdd Standard Service\u2026\u201d and paste in the URL of a [service](#sources). You should see the name of the service appear in the list of Services if the URL is correct. \n+\n+![The reconciliation window.](/img/reconcilewindow.png)\n+\n+Once you select a service, the service may sample your selected column and identify some [suggested categories (\"types\")](#reconciling-by-type) to reconcile against. Other services will suggest their available types without sampling, and some services have no types. \n+\n+For example, if you had a list of artists represented in a gallery collection, you could reconcile their names against the Getty Research Institute\u2019s [Union List of Artist Names (ULAN)](https://www.getty.edu/research/tools/vocabularies/ulan/). The same Getty reconciliation URL will offer you ULAN, AAT (Art and Architecture Thesaurus), and TGN (Thesaurus of Geographic Names).\n+\n+![The reconciliation window with types.](/img/reconcilewindow2.png)\n+\n+Refer to the documentation specific to the reconciliation service to learn whether types are offered, which types are offered, and which one is most appropriate for your column. You may wish to facet your data and reconcile batches against different types.\n+\n+Reconciliation can be a time-consuming process, especially with large datasets. We suggest starting with a small test batch. There is no throttle (delay between requests) to set for the reconciliation process. The amount of time will vary for each service, and based on your settings.\n+\n+When the process is done, you will see the reconciliation data in the cells. \n+If the cell was successfully matched, it displays a single dark blue link. In this case, the reconciliation is confident that the match is correct, and you should not have to check it manually. \n+If there is no clear match, a few candidates are displayed, together with their reconciliation score, with light blue links. You will need to select the correct one. \n+\n+For each matching decision you make, you have two options: match this cell only ![button to perform a single match](https://openrefine-wikidata.toolforge.org/static/screenshot_single_match.png), or also use the same identifier for all other cells containing the same original string ![button to perform a multiple match](https://openrefine-wikidata.toolforge.org/static/screenshot_bulk_match.png).\n+\n+With some services, you can hover your mouse over the suggestions to see more information about the candidates or matches. Each participating service (and each type) will deliver different structured data that may help you compare the candidates. For example, the Getty ULAN shows an artist\u2019s discipline, nationality, and birth and death years: \n+\n+![Hovering over matches.](/img/reconcilehover.png)\n+\n+Hovering over the suggestion will also offer the two matching options as buttons. \n+\n+For each cell, you can manually \u201cCreate new item,\u201d which will take the cell\u2019s current value and apply it as though it is a match. This will not become a blue link, because at this time there is nothing to link to: it is like a draft entity stored only in your project. You can use this feature to prepare these entries for eventual upload to an editable service such as Wikidata.\n+\n+### Reconciliation facets\n+\n+Under \"Reconcile\" \u2192 \"Facets\" you can see a number of reconciliation-specific faceting options. OpenRefine automatically creates two facets for you when you reconcile a column. \n+\n+One is a numeric facet for \"best candidate's score,\" the range of reconciliation scores of only the best candidate of each cell. Each service calculates scores differently and has a different range, but higher scores always mean better matches. You can facet for higher scores in the numeric facet, and then approve them all in bulk, by using \u201cReconcile\u201d \u2192 \u201cActions\u201d \u2192 \u201cMatch each cell to its best candidate.\u201d \n+\n+There is also a \u201cjudgment\u201d facet created, which lets you filter for the cells that haven't been matched (pick \"none\" in the facet). As you process each cell, its judgment changes from \u201cnone\u201d to \u201cmatched\u201d and it disappears from the view.\n+\n+You can add other reconciliation facets by selecting \u201cReconcile\u201d \u2192 \u201cFacets\u201d on your column. You can facet by your judgements (\u201cmatched,\u201d or \u201cnone\u201d for unreconciled cells, or \u201cnew\u201d for entities you've created), by the action you\u2019ve performed on that cell (chosen a \u201csingle\u201d match, or no action, as \u201cunknown\u201d), or the timestamps on the edits you\u2019ve made so far (these appear as millisecond counts since an arbitrary point: they can be sorted alphabetically to move forward and back in time). \n+\n+You can facet only the best candidates for each cell, based on:\n+*   the score (calculated based on each service's own methods)\n+*   the edit distance (how many single-character edits would be required to get your original value to the candidate value)\n+*   the word similarity (calculated on individual word matching, not including [stop words](https://en.wikipedia.org/wiki/Stop_word)). \n+\n+You can also look at each best candidate\u2019s:\n+*   type (the ones you have selected in successive reconciliation attempts, or other types returned by the service based on the cell values) \n+*   type match (\u201ctrue\u201d if you selected a type and it succeeded, \u201cfalse\u201d if you reconciled against no particular type, and \u201c(no type)\u201d if it didn\u2019t reconcile)\n+*   name match (\u201ctrue\u201d if you\u2019ve matched, \u201cfalse\u201d if you haven\u2019t yet chosen from the candidates, or \u201c(unreconciled)\u201d if it didn\u2019t reconcile). \n+\n+These facets are useful for doing successive reconciliation attempts,  against different types, and with different supplementary information.\n+\n+### Reconciliation actions\n+\n+You can use the \u201cReconcile\u201d \u2192 \"Actions\" menu options to perform bulk changes, which will apply only to your current set of rows or records:\n+*   Match each cell to its best candidate (by highest score)\n+*   Create a new item for each cell (discard any suggested matches)\n+*   Create one new item for similar cells (a new entity will be created for each unique string)\n+*   Match all filtered cells to... (a specific item from the chosen service, via a search box. For [services with the \"suggest entities\" property](https://reconciliation-api.github.io/testbench/).)\n+*   Discard all reconciliation judgments (reverts back to multiple candidates per cell, including cells that may have been auto-matched in the original reconciliation process)\n+*   Clear reconciliation data, reverting all cells back to their original values.\n+\n+The other options available under \"Reconcile\" are:\n+*   Copy reconciliation data... (to an existing column: if the original values in your reconciliation column are identical to those in your chosen column, the matched and/or new cells will copy over. Unmatched values will not change.) \n+*   [Use values as identifiers](#reconciling-with-unique-identifiers) (if you are reconciling with unique identifiers instead of by doing string searches).\n+*   [Add entity identifiers column](#add-entity-identifiers-column).\n+\n+## Reconciling with unique identifiers\n+\n+Reconciliation services use unique identifiers for their entities. For example, the 14th Dalai Lama has the VIAF ID [38242123](https://viaf.org/viaf/38242123/) and the Wikidata ID [Q17293](https://www.wikidata.org/wiki/Q37349). If you can supply the correct identifiers directly to your chosen reconciliation service, reconciliation will be a fully automated process. \n+\n+Select the column with unique identifiers and apply the operation \u201cReconcile\u201d \u2192 \u201cUse values as identifiers.\u201d This will bring up the list of reconciliation services you have already added (to add a new service, open the \u201cStart reconciling\u2026\u201d window first). If you reconcile a column of IDs, other columns cannot be included.\n+\n+Matching identifiers does not actually \"reconcile,\" that is, query the external service to identify matches. All cells will appear as dark blue \"confirmed\" matches. You may get false positives, which you will need to hover over or click on to identify:\n+\n+![Hovering over an error.](/img/reconcileIDerror.png)\n+\n+## Reconciling by type\n+\n+Reconciliation services, once added to OpenRefine, may suggest types from their databases. These types will usually be whatever the service specializes in: people, events, places, buildings, tools, plants, animals, organizations, etc.  \n+\n+Reconciling against a type may be faster and more accurate, but may result in fewer matches. Some services have hierarchical types (such as \"woman\" as a subtype of \"human\"). When you reconcile against a more specific type, unmatched values may fall back to more broad types. Other services may not do this, so you may need to do successive reconciliation attempts against different types. Refer to the documentation specific to the reconciliation service to learn more. \n+\n+When you select a service from the list, OpenRefine will load some or all available types. Some services will sample the first ten rows of your column to suggest types (check the [\"Suggest types\" column on this table of services](https://reconciliation-api.github.io/testbench/)). You will see a service\u2019s types in the reconciliation window:\n+\n+![Reconciling using a type.](/img/reconcile-by-type.png)\n+\n+In this example, \u201cPerson\u201d and \u201cCorporate Name\u201d are potential types offered by VIAF. You can also use the \u201cReconcile against type:\u201d field to enter in another type that the service offers. When you start typing, this field may search and suggest existing types. For VIAF, you could enter \u201c/book/book\u201d if your column contained publications.\n+\n+Types are structured to fit their content: the Wikidata \u201chuman\u201d type, for example, can include fields for birth and death dates, nationality, etc. The VIAF \u201cperson\u201d type can include nationality and gender. You can use this to [include more properties](#reconciling-with-additional-columns) and find better matches.\n+\n+If your column doesn\u2019t fit one specific type offered, you can \u201cReconcile against no particular type.\u201d This may take longer for some services.\n+\n+We recommend working in batches and reconciling against different types, moving from specific to broad. You can create a \u201cbest candidate\u2019s type\u201d facet to see which types are being represented. Some candidates may return more than one type, depending on the service.\n+\n+## Reconciling with additional columns\n+\n+Some of your cells may be ambiguous, in the sense that a string can point to more than one entity: there are dozens of places called \u201cParis\u201d and many characters, people, and pieces of culture, too. Selecting non-geographic or more localized types can help narrow that down, but if your chosen service doesn't provide a useful type, you can include more properties that make it clear whether you're looking for Paris, France. \n+\n+![Reconciling sometimes turns up ambiguous matches.](/img/reconcileParis.gif) \n+\n+Including supplementary information can be useful, depending on the service (such as including birthdate information about each person you are trying to reconcile). The other columns in your project will appear in the reconciliation window, with an \u201cInclude?\u201d checkbox available on each. \n+\n+You can fill in the \u201cAs Property\u201d field with the type of information you are including - when you start typing, potential fields may pop up, such as \u201cbirthDate\u201d in the case of ULAN or \"Geburtsdatum\" in the case of Integrated Authority File (GND). Use the documentation for your chosen service to identify the fields in their terms. Some services will not be able to search with your \"As Property\" entry, but you can still manually supply the field name. Refer to the service to make sure you enter it correctly. \n+\n+![Including a birth-date type.](/img/reconcile-by-type.png)\n+\n+If your data formatting does not exactly match that of the service you are reconciling, you may be able to use asterisks (&#42;) as wildcards to encourage more matches. [This example from the GND](https://blog.lobid.org/2019/09/30/openrefine-examples.html) uses wildcards to match a column of birth years (YYYY&#42;) to birth dates formatted as YYYY-MM-DD.", "originalCommit": "e5521d62a16232df26fdcb79b5f0a19599dcb223", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNjExOQ==", "url": "https://github.com/OpenRefine/OpenRefine/pull/3103#discussion_r487126119", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Matching identifiers does not actually \"reconcile,\" that is, query the external service to identify matches. All cells will appear as dark blue \"confirmed\" matches. You may get false positives, which you will need to hover over or click on to identify:\n          \n          \n            \n            Matching identifiers does not actually validate identifiers. All cells will appear as dark blue \"confirmed\" matches. You should check before this operation that the identifiers in the column exist on the target service.", "author": "wetneb", "createdAt": "2020-09-11T15:35:23Z", "path": "docs/docs/manual/reconciling.md", "diffHunk": "@@ -0,0 +1,192 @@\n+---\n+id: reconciling\n+title: Reconciling\n+sidebar_label: Reconciling\n+---\n+\n+## Overview\n+\n+Reconciliation is the process of matching your dataset with that of an external source. Authoritative datasets are produced by libraries, archives, museums, academic organizations, scientific institutions, non-profits, and interest groups. To reconcile your OpenRefine project against an authority, that authority must offer a web service that conforms to the [Reconciliation Service API standards](https://reconciliation-api.github.io/specs/0.1/). \n+\n+You may wish to reconcile in order to fix spelling or variations in proper names, to clean up manually-entered subject headings against authorities such as the [Library of Congress Subject Headings](https://id.loc.gov/authorities/subjects.html) (LCSH), to link your data to an existing set, to add it to an open and editable system such as [Wikidata](https://www.wikidata.org), or to see whether entities in your project appear in some specific list or not, such as the [Panama Papers](https://aleph.occrp.org/datasets/734).\n+\n+Reconciliation is semi-automated: OpenRefine matches your cell values to the reconciliation information as best it can, but human judgment is required to ensure the process is successful. Reconciling happens by default through string searching, so typos, whitespace, and extraneous characters will have an effect on the results. \n+\n+We strongly recommend planning your reconciliation operations as iterative: reconcile multiple times with different settings, from different services, with different subgroups of your data. \n+\n+## Sources\n+\n+There is a [current list of reconcilable authorities](https://reconciliation-api.github.io/testbench/) that includes instructions for adding new services via Wikidata editing.  OpenRefine maintains a [further list of sources on the wiki](https://github.com/OpenRefine/OpenRefine/wiki/Reconcilable-Data-Sources), which can be edited by anyone.\n+\n+Other services may exist that are not yet listed in these two places: for example, the [310 datasets hosted by the Organized Crime and Corruption Reporting Project (OCCRP)](https://aleph.occrp.org/datasets/) each have their own reconciliation URL, or you can reconcile against their entire database with the URL listed [here](https://reconciliation-api.github.io/testbench/). For another example, you can reconcile against the entire Virtual International Authority File (VIAF) dataset, or [only the contributions from certain institutions](http://refine.codefork.com/). Search online to see if the authority you wish to reconcile against has an available service.\n+\n+OpenRefine offers Wikidata reconciliation by default - see the [Wikidata](wikidata) page for more information particular to that service.\n+\n+:::info\n+Some OpenRefine extensions can add reconciliation services, and can also add enhanced reconciliation capacities. Check the list of extensions on the [Downloads page](https://openrefine.org/download.html) for more information.\n+:::\n+\n+## Getting started\n+\n+Select \u201cReconcile\u201d \u2192 \u201cStart reconciling\u201d on a column. If you want to reconcile only some cells in that column, first use filters and facets to isolate them.\n+\n+In the reconciliation window, you will see Wikidata offered as a default service. To add another service, click \u201cAdd Standard Service\u2026\u201d and paste in the URL of a [service](#sources). You should see the name of the service appear in the list of Services if the URL is correct. \n+\n+![The reconciliation window.](/img/reconcilewindow.png)\n+\n+Once you select a service, the service may sample your selected column and identify some [suggested categories (\"types\")](#reconciling-by-type) to reconcile against. Other services will suggest their available types without sampling, and some services have no types. \n+\n+For example, if you had a list of artists represented in a gallery collection, you could reconcile their names against the Getty Research Institute\u2019s [Union List of Artist Names (ULAN)](https://www.getty.edu/research/tools/vocabularies/ulan/). The same Getty reconciliation URL will offer you ULAN, AAT (Art and Architecture Thesaurus), and TGN (Thesaurus of Geographic Names).\n+\n+![The reconciliation window with types.](/img/reconcilewindow2.png)\n+\n+Refer to the documentation specific to the reconciliation service to learn whether types are offered, which types are offered, and which one is most appropriate for your column. You may wish to facet your data and reconcile batches against different types.\n+\n+Reconciliation can be a time-consuming process, especially with large datasets. We suggest starting with a small test batch. There is no throttle (delay between requests) to set for the reconciliation process. The amount of time will vary for each service, and based on your settings.\n+\n+When the process is done, you will see the reconciliation data in the cells. \n+If the cell was successfully matched, it displays a single dark blue link. In this case, the reconciliation is confident that the match is correct, and you should not have to check it manually. \n+If there is no clear match, a few candidates are displayed, together with their reconciliation score, with light blue links. You will need to select the correct one. \n+\n+For each matching decision you make, you have two options: match this cell only ![button to perform a single match](https://openrefine-wikidata.toolforge.org/static/screenshot_single_match.png), or also use the same identifier for all other cells containing the same original string ![button to perform a multiple match](https://openrefine-wikidata.toolforge.org/static/screenshot_bulk_match.png).\n+\n+With some services, you can hover your mouse over the suggestions to see more information about the candidates or matches. Each participating service (and each type) will deliver different structured data that may help you compare the candidates. For example, the Getty ULAN shows an artist\u2019s discipline, nationality, and birth and death years: \n+\n+![Hovering over matches.](/img/reconcilehover.png)\n+\n+Hovering over the suggestion will also offer the two matching options as buttons. \n+\n+For each cell, you can manually \u201cCreate new item,\u201d which will take the cell\u2019s current value and apply it as though it is a match. This will not become a blue link, because at this time there is nothing to link to: it is like a draft entity stored only in your project. You can use this feature to prepare these entries for eventual upload to an editable service such as Wikidata.\n+\n+### Reconciliation facets\n+\n+Under \"Reconcile\" \u2192 \"Facets\" you can see a number of reconciliation-specific faceting options. OpenRefine automatically creates two facets for you when you reconcile a column. \n+\n+One is a numeric facet for \"best candidate's score,\" the range of reconciliation scores of only the best candidate of each cell. Each service calculates scores differently and has a different range, but higher scores always mean better matches. You can facet for higher scores in the numeric facet, and then approve them all in bulk, by using \u201cReconcile\u201d \u2192 \u201cActions\u201d \u2192 \u201cMatch each cell to its best candidate.\u201d \n+\n+There is also a \u201cjudgment\u201d facet created, which lets you filter for the cells that haven't been matched (pick \"none\" in the facet). As you process each cell, its judgment changes from \u201cnone\u201d to \u201cmatched\u201d and it disappears from the view.\n+\n+You can add other reconciliation facets by selecting \u201cReconcile\u201d \u2192 \u201cFacets\u201d on your column. You can facet by your judgements (\u201cmatched,\u201d or \u201cnone\u201d for unreconciled cells, or \u201cnew\u201d for entities you've created), by the action you\u2019ve performed on that cell (chosen a \u201csingle\u201d match, or no action, as \u201cunknown\u201d), or the timestamps on the edits you\u2019ve made so far (these appear as millisecond counts since an arbitrary point: they can be sorted alphabetically to move forward and back in time). \n+\n+You can facet only the best candidates for each cell, based on:\n+*   the score (calculated based on each service's own methods)\n+*   the edit distance (how many single-character edits would be required to get your original value to the candidate value)\n+*   the word similarity (calculated on individual word matching, not including [stop words](https://en.wikipedia.org/wiki/Stop_word)). \n+\n+You can also look at each best candidate\u2019s:\n+*   type (the ones you have selected in successive reconciliation attempts, or other types returned by the service based on the cell values) \n+*   type match (\u201ctrue\u201d if you selected a type and it succeeded, \u201cfalse\u201d if you reconciled against no particular type, and \u201c(no type)\u201d if it didn\u2019t reconcile)\n+*   name match (\u201ctrue\u201d if you\u2019ve matched, \u201cfalse\u201d if you haven\u2019t yet chosen from the candidates, or \u201c(unreconciled)\u201d if it didn\u2019t reconcile). \n+\n+These facets are useful for doing successive reconciliation attempts,  against different types, and with different supplementary information.\n+\n+### Reconciliation actions\n+\n+You can use the \u201cReconcile\u201d \u2192 \"Actions\" menu options to perform bulk changes, which will apply only to your current set of rows or records:\n+*   Match each cell to its best candidate (by highest score)\n+*   Create a new item for each cell (discard any suggested matches)\n+*   Create one new item for similar cells (a new entity will be created for each unique string)\n+*   Match all filtered cells to... (a specific item from the chosen service, via a search box. For [services with the \"suggest entities\" property](https://reconciliation-api.github.io/testbench/).)\n+*   Discard all reconciliation judgments (reverts back to multiple candidates per cell, including cells that may have been auto-matched in the original reconciliation process)\n+*   Clear reconciliation data, reverting all cells back to their original values.\n+\n+The other options available under \"Reconcile\" are:\n+*   Copy reconciliation data... (to an existing column: if the original values in your reconciliation column are identical to those in your chosen column, the matched and/or new cells will copy over. Unmatched values will not change.) \n+*   [Use values as identifiers](#reconciling-with-unique-identifiers) (if you are reconciling with unique identifiers instead of by doing string searches).\n+*   [Add entity identifiers column](#add-entity-identifiers-column).\n+\n+## Reconciling with unique identifiers\n+\n+Reconciliation services use unique identifiers for their entities. For example, the 14th Dalai Lama has the VIAF ID [38242123](https://viaf.org/viaf/38242123/) and the Wikidata ID [Q17293](https://www.wikidata.org/wiki/Q37349). If you can supply the correct identifiers directly to your chosen reconciliation service, reconciliation will be a fully automated process. \n+\n+Select the column with unique identifiers and apply the operation \u201cReconcile\u201d \u2192 \u201cUse values as identifiers.\u201d This will bring up the list of reconciliation services you have already added (to add a new service, open the \u201cStart reconciling\u2026\u201d window first). If you reconcile a column of IDs, other columns cannot be included.\n+\n+Matching identifiers does not actually \"reconcile,\" that is, query the external service to identify matches. All cells will appear as dark blue \"confirmed\" matches. You may get false positives, which you will need to hover over or click on to identify:", "originalCommit": "e5521d62a16232df26fdcb79b5f0a19599dcb223", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "20d40ce3c0c6842adef5aad826faf405f2d5bd1b", "url": "https://github.com/OpenRefine/OpenRefine/commit/20d40ce3c0c6842adef5aad826faf405f2d5bd1b", "message": "Update docs/docs/manual/reconciling.md\n\nCo-authored-by: Antonin Delpeuch <antonin@delpeuch.eu>", "committedDate": "2020-09-11T16:58:33Z", "type": "commit"}, {"oid": "ac44225aba983000cf05c9adddeaf97f898ef82a", "url": "https://github.com/OpenRefine/OpenRefine/commit/ac44225aba983000cf05c9adddeaf97f898ef82a", "message": "Move + edit reconciliation page", "committedDate": "2020-09-11T20:06:28Z", "type": "commit"}, {"oid": "dc1cfd44b5018e4be9d76307f12a0cad3b03eeeb", "url": "https://github.com/OpenRefine/OpenRefine/commit/dc1cfd44b5018e4be9d76307f12a0cad3b03eeeb", "message": "Merge branch 'docs-transforming' of https://github.com/allanaaa/OpenRefine into docs-transforming", "committedDate": "2020-09-11T20:07:33Z", "type": "commit"}, {"oid": "98c1dfd4a64a97fa5a04fceb95fe561dfcc23fdd", "url": "https://github.com/OpenRefine/OpenRefine/commit/98c1dfd4a64a97fa5a04fceb95fe561dfcc23fdd", "message": "Update reconciling.md", "committedDate": "2020-09-11T20:17:16Z", "type": "commit"}, {"oid": "7dafe6228af626f2815a0ba296092230caf25f1e", "url": "https://github.com/OpenRefine/OpenRefine/commit/7dafe6228af626f2815a0ba296092230caf25f1e", "message": "Update columnediting.md", "committedDate": "2020-09-17T19:43:35Z", "type": "commit"}, {"oid": "138a6684277ad7c06e4233a73c84e2440a88f4dd", "url": "https://github.com/OpenRefine/OpenRefine/commit/138a6684277ad7c06e4233a73c84e2440a88f4dd", "message": "Merge branch 'master' into docs-transforming", "committedDate": "2020-09-17T19:52:01Z", "type": "commit"}, {"oid": "e73b665c2a5e27ef3ca9255dd82a7ecf6ac185cc", "url": "https://github.com/OpenRefine/OpenRefine/commit/e73b665c2a5e27ef3ca9255dd82a7ecf6ac185cc", "message": "Edit transposing\n\n+ fetch error message update\n+ misc formatting", "committedDate": "2020-09-18T17:07:34Z", "type": "commit"}, {"oid": "e5a72a597d4e1d6f09e9d322f6710ef94bbccd20", "url": "https://github.com/OpenRefine/OpenRefine/commit/e5a72a597d4e1d6f09e9d322f6710ef94bbccd20", "message": "Merge branch 'docs-transforming' of https://github.com/allanaaa/OpenRefine into docs-transforming", "committedDate": "2020-09-18T17:07:36Z", "type": "commit"}, {"oid": "4dc6abba5dfd64140a8f463943b377164d598989", "url": "https://github.com/OpenRefine/OpenRefine/commit/4dc6abba5dfd64140a8f463943b377164d598989", "message": "Title fix", "committedDate": "2020-10-05T16:44:21Z", "type": "commit"}, {"oid": "d3dcd031d8b26a518c1659a041cea0cc25d6078a", "url": "https://github.com/OpenRefine/OpenRefine/commit/d3dcd031d8b26a518c1659a041cea0cc25d6078a", "message": "Phrasing", "committedDate": "2020-10-05T16:44:29Z", "type": "commit"}]}