{"pr_number": 587, "pr_title": "Update RecordFileParser.loadRecordFile() to match design", "pr_createdAt": "2020-03-08T18:21:01Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/587", "timeline": [{"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "message": "Update RecordFileParser.loadRecordFile() to match design\n\nMost RFP tests are at parse() level, so not much test changes.\nWhen we separate fs stuff from RFP, tests will be updated to test just loadRecordFile().\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-08T18:32:57Z", "type": "commit"}, {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "message": "Update RecordFileParser.loadRecordFile() to match design\n\nMost RFP tests are at parse() level, so not much test changes.\nWhen we separate fs stuff from RFP, tests will be updated to test just loadRecordFile().\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-08T18:32:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NDQzOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389764439", "bodyText": "nit: Combine declaration and assignment", "author": "steven-sheehy", "createdAt": "2020-03-09T15:24:42Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -139,25 +143,16 @@ public static String readPrevFileHash(String fileName) {\n     /**\n      * Given a service record name, read and parse and return as a list of service record pair\n      *\n-     * @param streamFileData       containing information about file to be processed\n-     * @param expectedPrevFileHash the hash of the previous record file in the series\n-     * @param thisFileHash         the hash of this file\n-     * @return return boolean indicating method success\n-     * @throws Exception\n+     * @param streamFileData containing information about file to be processed\n      */\n-    public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash, String expectedPrevFileHash) {\n+    public void loadRecordFile(StreamFileData streamFileData) {\n         String fileName = streamFileData.getFilename();\n+        String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Optional<RecordFile> recordFile;\n-        try {\n-            recordFile = recordStreamFileListener.onStart(streamFileData);\n-            if (recordFile.isEmpty()) {\n-                return true; // skip file\n-            }\n-            recordFile.get().setFileHash(thisFileHash);\n-            recordFile.get().setPreviousHash(expectedPrevFileHash);\n-        } catch (ImporterException e) {\n-            log.error(\"Error processing file \" + fileName, e);\n-            return false;\n+        recordFile = recordStreamFileListener.onStart(streamFileData);", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4MTY4NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389881684", "bodyText": "done.", "author": "apeksharma", "createdAt": "2020-03-09T18:30:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NDQzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NTI3Mg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389765272", "bodyText": "Change to catch Exception since you're only rethrowing IOException and could miss a RuntimeException.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:25:53Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -287,27 +270,24 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n      * @throws Exception\n      */\n     private void loadRecordFiles(List<String> fileNames) {\n-        String prevFileHash = applicationStatusRepository\n-                .findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Collections.sort(fileNames);\n-\n         for (String name : fileNames) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n-            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(name));\n             InputStream fileInputStream;\n             try {\n                 fileInputStream = new FileInputStream(new File(name));\n             } catch (FileNotFoundException e) {\n                 log.warn(\"File does not exist {}\", name);\n                 return;\n             }\n-            StreamFileData streamFileData = new StreamFileData(name, fileInputStream);\n-            if (loadRecordFile(streamFileData, thisFileHash, prevFileHash)) {\n-                prevFileHash = thisFileHash;\n+            try {\n+                loadRecordFile(new StreamFileData(name, fileInputStream));\n                 Utility.moveFileToParsedDir(name, \"/parsedRecordFiles/\");\n-            } else {\n+            } catch (ImporterException e) {", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5NzQyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389897426", "bodyText": "done.", "author": "apeksharma", "createdAt": "2020-03-09T18:59:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NTI3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NzYxOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389767619", "bodyText": "Since this is returning here on error, you might as well move the catch up even higher to parse() and consolidate all error handling in one spot.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:29:14Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -287,27 +270,24 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n      * @throws Exception\n      */\n     private void loadRecordFiles(List<String> fileNames) {\n-        String prevFileHash = applicationStatusRepository\n-                .findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Collections.sort(fileNames);\n-\n         for (String name : fileNames) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n-            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(name));\n             InputStream fileInputStream;\n             try {\n                 fileInputStream = new FileInputStream(new File(name));\n             } catch (FileNotFoundException e) {\n                 log.warn(\"File does not exist {}\", name);\n                 return;\n             }\n-            StreamFileData streamFileData = new StreamFileData(name, fileInputStream);\n-            if (loadRecordFile(streamFileData, thisFileHash, prevFileHash)) {\n-                prevFileHash = thisFileHash;\n+            try {\n+                loadRecordFile(new StreamFileData(name, fileInputStream));\n                 Utility.moveFileToParsedDir(name, \"/parsedRecordFiles/\");\n-            } else {\n+            } catch (ImporterException e) {\n+                log.error(\"Error parsing file {}\", name, e);\n+                recordStreamFileListener.onError();", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTI1Mzc0OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391253748", "bodyText": "trying to keep fs and db (onError) logic in different functions so that splitting out RecordFileReader (fs-dependent) would be cleaner. Let's leave it like this for now, no harm.", "author": "apeksharma", "createdAt": "2020-03-11T20:37:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NzYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MTk2OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389771969", "bodyText": "Please change back to Exception (catch and rethrow ImporterException first) since you will miss unchecked exceptions. That or remove this catch and catch Exception in layer above, but then you miss out on formatted timing message. That may not be a big deal since we have metrics and timings for errors is probably not important.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:35:43Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -247,38 +237,31 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n                             break;\n \n                         default:\n-                            log.error(\"Unknown record file delimiter {} for file {}\", typeDelimiter, fileName);\n-                            recordStreamFileListener.onError();\n-                            return false;\n+                            throw new ParserException(String.format(\n+                                    \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n                     }\n-                } catch (Exception e) {\n-                    log.error(\"Exception {}\", e);\n-                    recordStreamFileListener.onError();\n-                    return false;\n-                }\n             }\n \n+            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(fileName));\n+            recordFile.get().setFileHash(thisFileHash);\n+            recordFile.get().setPreviousHash(expectedPrevFileHash);\n             log.trace(\"Calculated file hash for the current file {}\", thisFileHash);\n             recordStreamFileListener.onEnd(recordFile.get());\n \n             if (!Utility.hashIsEmpty(thisFileHash)) {\n                 applicationStatusRepository\n                         .updateStatusValue(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, thisFileHash);\n             }\n-            success = true;\n-        } catch (Exception e) {\n-            log.error(\"Error parsing record file {} after {}\", fileName, stopwatch, e);\n-            recordStreamFileListener.onError();\n+        } catch (IOException e) {", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5NTk3NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389895974", "bodyText": "done the latter.", "author": "apeksharma", "createdAt": "2020-03-09T18:56:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MTk2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MzQ2NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389773464", "bodyText": "This whole block has an extra indentation after try/catch removal.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:37:56Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -167,12 +162,8 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n                     byte typeDelimiter = dis.readByte();", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4NjA5NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389886095", "bodyText": "left such for easier first review since diffs are cleaner.\nre-aligning now.", "author": "apeksharma", "createdAt": "2020-03-09T18:38:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MzQ2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3NTMxMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389775312", "bodyText": "This metric is now always unsuccessful since you don't set success to true.", "author": "steven-sheehy", "createdAt": "2020-03-09T15:40:41Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -247,38 +237,31 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n                             break;\n \n                         default:\n-                            log.error(\"Unknown record file delimiter {} for file {}\", typeDelimiter, fileName);\n-                            recordStreamFileListener.onError();\n-                            return false;\n+                            throw new ParserException(String.format(\n+                                    \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n                     }\n-                } catch (Exception e) {\n-                    log.error(\"Exception {}\", e);\n-                    recordStreamFileListener.onError();\n-                    return false;\n-                }\n             }\n \n+            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(fileName));\n+            recordFile.get().setFileHash(thisFileHash);\n+            recordFile.get().setPreviousHash(expectedPrevFileHash);\n             log.trace(\"Calculated file hash for the current file {}\", thisFileHash);\n             recordStreamFileListener.onEnd(recordFile.get());\n \n             if (!Utility.hashIsEmpty(thisFileHash)) {\n                 applicationStatusRepository\n                         .updateStatusValue(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, thisFileHash);\n             }\n-            success = true;\n-        } catch (Exception e) {\n-            log.error(\"Error parsing record file {} after {}\", fileName, stopwatch, e);\n-            recordStreamFileListener.onError();\n+        } catch (IOException e) {\n+            throw new ParserException(String.format(\"Error parsing record file %s after %s\", fileName, stopwatch), e);\n         } finally {\n             log.info(\"Finished parsing {} transactions from record file {} in {}\", counter, fileName, stopwatch);\n-\n             parseDurationMetric.tag(\"type\", \"record\")\n                     .tag(\"success\", success.toString())", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5NzMxMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389897312", "bodyText": "ahh. fixed", "author": "apeksharma", "createdAt": "2020-03-09T18:59:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3NTMxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3ODUxMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389778513", "bodyText": "Can you enhance this to not Hex.encodeHexString(readFileHash) twice if previous is empty?", "author": "steven-sheehy", "createdAt": "2020-03-09T15:45:22Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -167,12 +162,8 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n                     byte typeDelimiter = dis.readByte();\n \n                     switch (typeDelimiter) {", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg4ODE1Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389888153", "bodyText": "done.", "author": "apeksharma", "createdAt": "2020-03-09T18:42:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3ODUxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc5MDgyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389790826", "bodyText": "Can you add a test for when processed hash is empty in db? Ops does this quite a bit to reset environments.", "author": "steven-sheehy", "createdAt": "2020-03-09T16:03:31Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -165,7 +165,9 @@ void invalidFile() throws Exception {\n         recordFileParser.parse();\n \n         // then\n-        assertNoneProcessed();\n+        assertParsedFiles();\n+        verifyNoInteractions(recordItemListener);\n+        verify(recordStreamFileListener).onError();\n     }\n ", "originalCommit": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTI1NjczNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391256735", "bodyText": "discussed offline.", "author": "apeksharma", "createdAt": "2020-03-11T20:43:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc5MDgyNg=="}], "type": "inlineReview"}, {"oid": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "message": "address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-11T21:08:15Z", "type": "commit"}, {"oid": "e556179de4e99e8077a60a7fb380bf8504b3a703", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e556179de4e99e8077a60a7fb380bf8504b3a703", "message": "add @cacheput\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-11T22:20:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTYzMTA3OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391631079", "bodyText": "This section seems like one of those bloated sections. It's not easy to get a view of all that needs to be done and it's not possible to test each case separately.\nCould we make each case call a method that handles the given scenario (e.g. readPreviousHash(), readRecord()/readTransaction() and readSignature()).\nThese are then more isolated and can be tested and more easily managed.", "author": "Nana-EC", "createdAt": "2020-03-12T13:47:07Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -139,125 +138,105 @@ public static String readPrevFileHash(String fileName) {\n     /**\n      * Given a service record name, read and parse and return as a list of service record pair\n      *\n-     * @param streamFileData       containing information about file to be processed\n-     * @param expectedPrevFileHash the hash of the previous record file in the series\n-     * @param thisFileHash         the hash of this file\n-     * @return return boolean indicating method success\n-     * @throws Exception\n+     * @param streamFileData containing information about file to be processed\n      */\n-    public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash, String expectedPrevFileHash) {\n+    public void loadRecordFile(StreamFileData streamFileData) throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n         String fileName = streamFileData.getFilename();\n-        Optional<RecordFile> recordFile;\n-        try {\n-            recordFile = recordStreamFileListener.onStart(streamFileData);\n-            if (recordFile.isEmpty()) {\n-                return true; // skip file\n-            }\n-            recordFile.get().setFileHash(thisFileHash);\n-            recordFile.get().setPreviousHash(expectedPrevFileHash);\n-        } catch (ImporterException e) {\n-            log.error(\"Error processing file \" + fileName, e);\n-            return false;\n+        String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+        Optional<RecordFile> recordFile = recordStreamFileListener.onStart(streamFileData);\n+        if (recordFile.isEmpty()) {\n+            return; // skip file\n         }\n         long counter = 0;\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n         Integer recordFileVersion = 0;\n         Boolean success = false;\n \n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n-                    byte typeDelimiter = dis.readByte();\n-\n-                    switch (typeDelimiter) {\n-                        case FileDelimiter.RECORD_TYPE_PREV_HASH:\n-                            byte[] readFileHash = new byte[48];\n-                            dis.read(readFileHash);\n-\n-                            if (Utility.hashIsEmpty(expectedPrevFileHash)) {\n-                                log.error(\"Previous file hash not available\");\n-                                expectedPrevFileHash = Hex.encodeHexString(readFileHash);\n+                byte typeDelimiter = dis.readByte();\n+\n+                switch (typeDelimiter) {", "originalCommit": "e556179de4e99e8077a60a7fb380bf8504b3a703", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc3MTY3NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391771675", "bodyText": "yes, and share them, i think this piece of code is partially duplicated in some other place too.\nTried not doing those in this PR though - keep changes small for faster easier reviews & quick progress (although that doesn't seem to be working).\nAbout your suggestion, yes, in one of the followup changes.", "author": "apeksharma", "createdAt": "2020-03-12T17:16:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTYzMTA3OQ=="}], "type": "inlineReview"}]}