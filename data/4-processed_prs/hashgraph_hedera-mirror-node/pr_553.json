{"pr_number": 553, "pr_title": "Parser re-design", "pr_createdAt": "2020-02-24T19:47:55Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/553", "timeline": [{"oid": "2e18c0d768f115e8038c572631ce62744e63a425", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/2e18c0d768f115e8038c572631ce62744e63a425", "message": "Address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-26T09:29:43Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY1NjE3Mg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384656172", "bodyText": "Should add transaction record bytes as well", "author": "steven-sheehy", "createdAt": "2020-02-26T17:43:19Z", "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,172 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileParser --> RecordItemParser --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+public interface StreamEventsHandler {\n+    void onBatchStart(String batchName) throws ImporterException;\n+    void onBatchComplete(String batchName) throws ImporterException;\n+    void onError(Throwable e);\n+}\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction) throws ImporterException;\n+    void onEntity(c.h.m.i.d.Entities) throws ImporterException;\n+    void onEntityUpdate(c.h.m.i.d.Entities) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage) throws ImporterException;\n+}\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+### RecordItemParser\n+\n+```java\n+public class RecordItemParser {\n+    private final RecordStreamEventsHandler RecordStreamEventsHandler;  // injected dependency\n+\n+    public void onRecordItem(RecordItem recordItem) throws ImporterException {\n+        // process recordItem\n+    }\n+}\n+```\n+\n+```java\n+@Value\n+public class RecordItem {\n+    private final Transaction transaction;\n+    private final TransactionRecord record;\n+    private final byte[] transactionRawBytes;", "originalCommit": "496383c55255481fe5bc9ee85b39a01d21d5cb19", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2MTE4Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384661183", "bodyText": "transactionBytes to match field in our domain", "author": "steven-sheehy", "createdAt": "2020-02-26T17:52:16Z", "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,172 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileParser --> RecordItemParser --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+public interface StreamEventsHandler {\n+    void onBatchStart(String batchName) throws ImporterException;\n+    void onBatchComplete(String batchName) throws ImporterException;\n+    void onError(Throwable e);\n+}\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction) throws ImporterException;\n+    void onEntity(c.h.m.i.d.Entities) throws ImporterException;\n+    void onEntityUpdate(c.h.m.i.d.Entities) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage) throws ImporterException;\n+}\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+### RecordItemParser\n+\n+```java\n+public class RecordItemParser {\n+    private final RecordStreamEventsHandler RecordStreamEventsHandler;  // injected dependency\n+\n+    public void onRecordItem(RecordItem recordItem) throws ImporterException {\n+        // process recordItem\n+    }\n+}\n+```\n+\n+```java\n+@Value\n+public class RecordItem {\n+    private final Transaction transaction;\n+    private final TransactionRecord record;\n+    private final byte[] transactionRawBytes;", "originalCommit": "496383c55255481fe5bc9ee85b39a01d21d5cb19", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgwMzI2Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384803266", "bodyText": "Instead of Foo can we just show Record in the diagram, remove the extra text flow below and add a note that a similar flow will exist for balance and event?", "author": "steven-sheehy", "createdAt": "2020-02-26T22:21:34Z", "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,220 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)", "originalCommit": "0c3c12990351821c01cde4321675ac45a47c6d34", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI3MzkxMQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385273911", "bodyText": "Add a non-goal that we are not attempting to make mirror node be ran without PostgreSQL. It will still require it to store application state.", "author": "steven-sheehy", "createdAt": "2020-02-27T17:54:35Z", "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately", "originalCommit": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI3OTgwNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385279807", "bodyText": "These 3 methods should be removed. Coupling the parser to the handler is not a good idea as the handler doesn't care if it comes from a file or gossip nor that it is batch together or not. We won't be able to batch tens of thousands of transactions in a single transaction either, so item listener will have to have separate batching mechanism.\nonError is not necessary either. We don't currently have a parse error and notify recordfilelogger about it. We just notify about new transactions that reached consensus.", "author": "steven-sheehy", "createdAt": "2020-02-27T18:05:42Z", "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {\n+    void onFileStart(StreamFileInfo streamFileInfo) throws ImporterException;", "originalCommit": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyMjY2Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385422666", "bodyText": "resolving since we discussed this in the meeting.", "author": "apeksharma", "createdAt": "2020-02-27T23:06:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI3OTgwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI4MTQ2OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385281468", "bodyText": "Would be nice to have marker interface to share among different item types", "author": "steven-sheehy", "createdAt": "2020-02-27T18:09:09Z", "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {\n+    void onFileStart(StreamFileInfo streamFileInfo) throws ImporterException;\n+    void onFileComplete(StreamFileInfo streamFileInfo) throws ImporterException;\n+    void onError();\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.record;\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction transaction) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer cryptoTransfer) throws ImporterException;\n+    void onNonFeeTransfer(c.h.m.i.d.NonFeeTransfer nonFeeTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage topicMessage) throws ImporterException;\n+    void onContractResult(c.h.m.i.d.ContractResult contractResult) throws ImporterException;\n+    void onFileData(c.h.m.i.d.FileData fileData) throws ImporterException;\n+    void onLiveHash(c.h.m.i.d.LiveHash liveHash) throws ImporterException;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.balance;\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+Note that there are no functions for entities. Updating entities in batch in not possible right now since\n+`t_transactions` table refers to entity ids. For entities, first, schema changes are needed to remove entity ids,\n+then `onEntity` and `onEntityUpdate` functions will be added to insert/update entities in bulk. For the purpose of\n+immediate refactor, we can leave entities in `RecordItemParser` (until perf optimizations via schema change in\n+milestone 2).\n+\n+### StreamItemListener\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamItemListener<T> {\n+    void onItem(T item) throws ImporterException;\n+}\n+```\n+\n+#### RecordItemListener\n+\n+```java\n+package com.hedera.mirror.importer.parser.record;\n+\n+public interface RecordItemListener extends StreamItemListener<RecordItem> {\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+@Value\n+public class RecordItem {", "originalCommit": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI4NjE5MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385286190", "bodyText": "Not a fan of this name since Events is mixed with gossip events. Maybe parsed something to indicate its converted from proto to our domain? ParsedItemHandler?", "author": "steven-sheehy", "createdAt": "2020-02-27T18:18:20Z", "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {", "originalCommit": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8d7f465bc3bcea9665c4ef64640c2f4a6795617c", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/8d7f465bc3bcea9665c4ef64640c2f4a6795617c", "message": "parser design\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:26Z", "type": "commit"}, {"oid": "b590a80b8a82c72f1eb983d192800b1a949e867d", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/b590a80b8a82c72f1eb983d192800b1a949e867d", "message": "Address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:26Z", "type": "commit"}, {"oid": "e9726fea33106483a96235e70c48a94d4c539e42", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e9726fea33106483a96235e70c48a94d4c539e42", "message": "remove redundant class diagram\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:26Z", "type": "commit"}, {"oid": "144893f950e02d57d0bd9898150900672af02378", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/144893f950e02d57d0bd9898150900672af02378", "message": "add interfaces\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:27Z", "type": "commit"}, {"oid": "ae706cf82414618ceda55c988f5f86476c6ab293", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/ae706cf82414618ceda55c988f5f86476c6ab293", "message": "add package names\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:27Z", "type": "commit"}, {"oid": "8c01a18519bf30a74a16dccf8bd9d54843a82202", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/8c01a18519bf30a74a16dccf8bd9d54843a82202", "message": "add generics and StreamItemListener. Add StreamFile domain\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:27Z", "type": "commit"}, {"oid": "bab8e6db0050d5a63fbd10709ae20aacf4a4486d", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/bab8e6db0050d5a63fbd10709ae20aacf4a4486d", "message": "update images\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:28Z", "type": "commit"}, {"oid": "50a7320012383a01fc0edaa36f9a620bec700b76", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/50a7320012383a01fc0edaa36f9a620bec700b76", "message": "remove entity functions from RecordStreamEventsHandler\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:28Z", "type": "commit"}, {"oid": "debc7f91c19c87fe99c36783fefbe6a6703b3386", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/debc7f91c19c87fe99c36783fefbe6a6703b3386", "message": "address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-27T23:07:28Z", "type": "commit"}, {"oid": "c12b94fa95aa92bf4cf473847c84427b93a55817", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c12b94fa95aa92bf4cf473847c84427b93a55817", "message": "add links to tasks' tickets\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-28T00:28:21Z", "type": "commit"}, {"oid": "c12b94fa95aa92bf4cf473847c84427b93a55817", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c12b94fa95aa92bf4cf473847c84427b93a55817", "message": "add links to tasks' tickets\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-02-28T00:28:21Z", "type": "forcePushed"}]}