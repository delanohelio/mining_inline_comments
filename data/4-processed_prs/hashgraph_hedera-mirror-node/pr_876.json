{"pr_number": 876, "pr_title": "Populate consensus_(start|end) for historical entries in t_record_files and fix name column", "pr_createdAt": "2020-07-17T01:46:10Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/876", "timeline": [{"oid": "6b8ac904725915681737e80418ff8a97f710331d", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/6b8ac904725915681737e80418ff8a97f710331d", "message": "add flyway db migration script to populate consensus_start and consensus_end for historic rows in t_record_files\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>", "committedDate": "2020-07-17T01:39:43Z", "type": "commit"}, {"oid": "31366b4086f7f69ba477698e19712a9f15ea750e", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/31366b4086f7f69ba477698e19712a9f15ea750e", "message": "add comment for clarity\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>", "committedDate": "2020-07-17T13:44:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyNzYzNA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r456527634", "bodyText": "There aren't any rows where consensus_start = 0 and consensus_end != 0 or vice versa. As a result, we can optimize this to combine the two update statements into one. If the runtime difference is negligible than we can keep separate.", "author": "steven-sheehy", "createdAt": "2020-07-17T15:51:06Z", "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.28.0__populate_consensus_start_end_for_record_files.sql", "diffHunk": "@@ -0,0 +1,85 @@\n+------------\n+-- functions\n+------------\n+drop function if exists extractNsFromFilePath(varchar);\n+create function extractNsFromFilePath(filePath varchar) returns bigint as\n+$$\n+declare\n+\tbasename varchar;\n+\tsecsStr  varchar;\n+\tsecs     bigint;\n+\tnsecsStr varchar;\n+\tnsecs    bigint;\n+begin\n+    -- get the basename from the file path, note the file extension is stripped\n+    -- it's a variant of the default Java Instant string, e.g., '2019-08-30T18_10_00.419072Z'\n+\tbasename := regexp_replace(filePath, '^.*/([^/]*?)(\\.[^/.]+)?$', '\\1');\n+\n+\tsecsStr := split_part(basename, '.', 1);\n+\tsecsStr := translate(secsStr, 'T_', ' :');\n+\tsecs := extract(epoch from to_timestamp(secsStr, 'YYYY-MM-DD HH24:MI:SS'));\n+\n+\tnsecsStr := regexp_replace(basename, '.*\\.([0-9]*)Z', '\\1');\n+\tnsecsStr := rpad(nsecsStr, 9, '0');\n+\tnsecs := to_number(nsecsStr, '999999999');\n+\n+\treturn secs * 1000000000 + nsecs;\n+end;\n+$$ language plpgsql;\n+\n+drop function if exists getLastConsensusNsInRange(bigint, bigint);\n+-- get the last consensus_ns from table transaction where consensus_ns is in the range [startNs, endNs)\n+-- will throw exception if no such last consensus_ns found\n+create function getLastConsensusNsInRange(startNs bigint, endNs bigint) returns bigint as\n+$$\n+declare\n+\tlastConsensusNs bigint;\n+begin\n+\tselect consensus_ns\n+\tinto strict lastConsensusNs\n+\tfrom transaction\n+\twhere consensus_ns >= startNs\n+\t  and consensus_ns < endNs\n+\torder by consensus_ns desc\n+\tlimit 1;\n+\treturn lastConsensusNs;\n+end;\n+$$ language plpgsql;\n+\n+drop function if exists getNextRecordFileConsensusStartAfterNs(bigint);\n+-- given a timestamp ns, find the immediate next record file after ns and return its consensus_start\n+create function getNextRecordFileConsensusStartAfterNs(ns bigint) returns bigint as\n+$$\n+declare\n+\tnextConsensusStart bigint;\n+begin\n+\tselect consensus_start\n+\tinto strict nextConsensusStart\n+\tfrom t_record_files\n+\twhere consensus_start > ns\n+\torder by consensus_start\n+\tlimit 1;\n+\treturn nextConsensusStart;\n+exception\n+\twhen NO_DATA_FOUND then\n+\t\t-- no record file with consensus_start after ns found, use bigint max\n+\t\treturn 9223372036854775807;\n+end;\n+$$ language plpgsql;\n+\n+\n+-- set consensus_start to the ns extracted from file name if it's 0\n+update t_record_files\n+set consensus_start = extractNsFromFilePath(name)\n+where consensus_start = 0;\n+\n+-- set consensus_end to the consensus timestamp of the last transaction in the record file\n+update t_record_files\n+set consensus_end = getLastConsensusNsInRange(consensus_start, getNextRecordFileConsensusStartAfterNs(consensus_start))\n+where consensus_end = 0;", "originalCommit": "31366b4086f7f69ba477698e19712a9f15ea750e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjY5MzI3MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r456693271", "bodyText": "there are 2 constraints:\n\npostgresql does not support inline variable assignment like sql server & mysql,\n declare @var1 int;\n update some_table\n set @var1 = col1 = func1(),\n        col2 = func2(@var1);\n\n\nconsensus_start of all entries have to be fully populated first, so we know the range to search for the last consensus_us for a record file. for example, if it's not done so, as shown in the table below, we can't get correct timestamp range to search the last transaction for record file id 1.\n\n\n\nid\nconsensus_start\nconsensus_end\n\n\n\n\n1\n1570800761443132000\n0\n\n\n2\n0\n0", "author": "xin-hedera", "createdAt": "2020-07-17T22:04:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyNzYzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU3MzA1NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r456573055", "bodyText": "Doing a select on transaction for each row in t_record_files will probably not be very efficient considering the size difference between the two. Has this been tested in development database using a copied t_record_files so as to not impact the application? How long does this migration take to run?\nIf it's slow, consider inverting the logic to loop over transaction in a cursor and finding the rows that correspond to the record file table.", "author": "steven-sheehy", "createdAt": "2020-07-17T17:20:06Z", "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.28.0__populate_consensus_start_end_for_record_files.sql", "diffHunk": "@@ -0,0 +1,85 @@\n+------------\n+-- functions\n+------------\n+drop function if exists extractNsFromFilePath(varchar);\n+create function extractNsFromFilePath(filePath varchar) returns bigint as\n+$$\n+declare\n+\tbasename varchar;\n+\tsecsStr  varchar;\n+\tsecs     bigint;\n+\tnsecsStr varchar;\n+\tnsecs    bigint;\n+begin\n+    -- get the basename from the file path, note the file extension is stripped\n+    -- it's a variant of the default Java Instant string, e.g., '2019-08-30T18_10_00.419072Z'\n+\tbasename := regexp_replace(filePath, '^.*/([^/]*?)(\\.[^/.]+)?$', '\\1');\n+\n+\tsecsStr := split_part(basename, '.', 1);\n+\tsecsStr := translate(secsStr, 'T_', ' :');\n+\tsecs := extract(epoch from to_timestamp(secsStr, 'YYYY-MM-DD HH24:MI:SS'));\n+\n+\tnsecsStr := regexp_replace(basename, '.*\\.([0-9]*)Z', '\\1');\n+\tnsecsStr := rpad(nsecsStr, 9, '0');\n+\tnsecs := to_number(nsecsStr, '999999999');\n+\n+\treturn secs * 1000000000 + nsecs;\n+end;\n+$$ language plpgsql;\n+\n+drop function if exists getLastConsensusNsInRange(bigint, bigint);\n+-- get the last consensus_ns from table transaction where consensus_ns is in the range [startNs, endNs)\n+-- will throw exception if no such last consensus_ns found\n+create function getLastConsensusNsInRange(startNs bigint, endNs bigint) returns bigint as\n+$$\n+declare\n+\tlastConsensusNs bigint;\n+begin\n+\tselect consensus_ns", "originalCommit": "31366b4086f7f69ba477698e19712a9f15ea750e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njc0MzQ2NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r456743465", "bodyText": "updated to use cursor for transaction, ordered by consensus_ns.\nfor the data in mirror node dev environment, to process 888526 rows in t_record_files, and 225,359,235 transactions, it took ~820 seconds.", "author": "xin-hedera", "createdAt": "2020-07-18T03:36:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU3MzA1NQ=="}], "type": "inlineReview"}, {"oid": "838bb7a76170b3ac57505b0e53c4fc5ae1f4b03e", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/838bb7a76170b3ac57505b0e53c4fc5ae1f4b03e", "message": "db migration script optimization\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>", "committedDate": "2020-07-18T02:36:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEyMjQ2Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r457122467", "bodyText": "There's an item to modify the t_record_files to remove /var/lib/hedera-mirror-importer/recordstreams/valid/ #102 .\nIf it's not to much overhead since you've pulled out the basename I'd consider doing it here since you are updating the table.", "author": "Nana-EC", "createdAt": "2020-07-20T07:17:14Z", "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.27.1__populate_consensus_start_end_for_record_files.sql", "diffHunk": "@@ -0,0 +1,106 @@\n+------------\n+-- functions\n+------------\n+drop function if exists extractNsFromFilePath(varchar);\n+create function extractNsFromFilePath(filePath varchar) returns bigint as\n+$$\n+declare\n+\tbasename varchar;\n+\tsecsStr  varchar;\n+\tsecs     bigint;\n+\tnsecsStr varchar;\n+\tnsecs    bigint;\n+begin\n+\t-- get the basename from the file path, note the file extension is stripped\n+\t-- it's a variant of the default Java Instant string, e.g., '2019-08-30T18_10_00.419072Z'\n+\tbasename := regexp_replace(filePath, '^.*/([^/]*?)(\\.[^/.]+)?$', '\\1');\n+\n+\tsecsStr := split_part(basename, '.', 1);\n+\tsecsStr := translate(secsStr, 'T_', ' :');\n+\tsecs := extract(epoch from to_timestamp(secsStr, 'YYYY-MM-DD HH24:MI:SS'));\n+\n+\tnsecsStr := regexp_replace(basename, '.*\\.([0-9]*)Z', '\\1');\n+\tnsecsStr := rpad(nsecsStr, 9, '0');\n+\tnsecs := to_number(nsecsStr, '999999999');\n+\n+\treturn secs * 1000000000 + nsecs;\n+end;\n+$$ language plpgsql;\n+\n+drop function if exists getNextRecordFileConsensusStart(bigint);\n+-- given the record file id, find the immediate next record file and return its consensus_start\n+-- if no record file found, return bigint max\n+create function getNextRecordFileConsensusStart(currentId bigint) returns bigint as\n+$$\n+declare\n+\tnextConsensusStart bigint;\n+begin\n+\tselect consensus_start\n+\tinto strict nextConsensusStart\n+\tfrom t_record_files\n+\twhere id > currentId\n+\torder by id\n+\tlimit 1;\n+\treturn nextConsensusStart;\n+exception\n+\twhen NO_DATA_FOUND then\n+\t\t-- no record file found, use bigint max\n+\t\treturn 9223372036854775807;\n+end;\n+$$ language plpgsql;\n+\n+drop function if exists updateConsensusEndForRecordFiles();\n+create function updateConsensusEndForRecordFiles() returns void as\n+$$\n+declare\n+\ttxnCursor          refcursor;\n+\trecordFile         record;\n+\tconsensusEnd       bigint;\n+\tcurrentNs          bigint;\n+\tnextConsensusStart bigint;\n+begin\n+\topen txnCursor no scroll for select consensus_ns from transaction order by consensus_ns;\n+\tcurrentNs := 0;\n+\n+\tfor recordFile in\n+\t\tselect id\n+\t\tfrom t_record_files\n+\t\twhere consensus_end = 0\n+\t\torder by id\n+\t\tloop\n+\t\t\tif currentNs is NULL then\n+\t\t\t\traise exception 'No transactions left in cursor, but there are still record files to process, current at id %', recordFile.id;\n+\t\t\tend if;\n+\n+\t\t\tnextConsensusStart := getNextRecordFileConsensusStart(recordFile.id);\n+\t\t\twhile true\n+\t\t\t\tloop\n+\t\t\t\t\tconsensusEnd := currentNs;\n+\t\t\t\t\tfetch txnCursor into currentNs;\n+\t\t\t\t\tif currentNs is NULL or currentNs >= nextConsensusStart then\n+\t\t\t\t\t\texit; -- exit the while loop\n+\t\t\t\t\tend if;\n+\t\t\t\tend loop;\n+\n+\t\t\tif consensusEnd = 0 then\n+\t\t\t\traise exception 'Fatal! no valid consensus_end found for record file id %', recordFile.id;\n+\t\t\tend if;\n+\n+\t\t\tupdate t_record_files\n+\t\t\tset consensus_end = consensusEnd\n+\t\t\twhere id = recordFile.id;\n+\t\tend loop;\n+end\n+$$ language plpgsql;\n+\n+-- set consensus_start to the ns extracted from file name if it's 0\n+update t_record_files\n+set consensus_start = extractNsFromFilePath(name)", "originalCommit": "838bb7a76170b3ac57505b0e53c4fc5ae1f4b03e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzQ3NTgzOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r457475838", "bodyText": "I think #102 has to be done in two separate steps:\n\nchange java code to store just the filename\nuse a db migration script to update the historical values in t_record_files\n\nAnd they have to work in the order and in two different versions.", "author": "xin-hedera", "createdAt": "2020-07-20T15:09:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEyMjQ2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzUxMTEyOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r457511128", "bodyText": "Also thanks for mentioning #102. I'm fixing the corresponding code for event file, I thought it's intended to the the full path.", "author": "xin-hedera", "createdAt": "2020-07-20T15:47:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEyMjQ2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY4MTY1OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r457681658", "bodyText": "Update of the name in the old rows is handled by a separate db script, V1.27.2__update_name_of_record_file_to_filename.sql because consensus_start is updated for rows where consensus_start=0 while the name fix applies to rows where name like '/%.rcd'.", "author": "xin-hedera", "createdAt": "2020-07-20T20:46:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzEyMjQ2Nw=="}], "type": "inlineReview"}, {"oid": "874890c5462985c75377d402599a5c09b4b24d02", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/874890c5462985c75377d402599a5c09b4b24d02", "message": "store file name not the full file path in EventFile.name\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>", "committedDate": "2020-07-20T15:36:27Z", "type": "commit"}, {"oid": "226de784b082393ef1408b35b4df24e9c9696f19", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/226de784b082393ef1408b35b4df24e9c9696f19", "message": "use file name instead of full file path for name field of RecordFile and EventFile\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>", "committedDate": "2020-07-20T20:36:47Z", "type": "commit"}, {"oid": "226de784b082393ef1408b35b4df24e9c9696f19", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/226de784b082393ef1408b35b4df24e9c9696f19", "message": "use file name instead of full file path for name field of RecordFile and EventFile\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>", "committedDate": "2020-07-20T20:36:47Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY5MzYxNA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r457693614", "bodyText": "Can we change parseRecordFile to take in a File instead of using this logic?", "author": "steven-sheehy", "createdAt": "2020-07-20T21:10:21Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/util/Utility.java", "diffHunk": "@@ -137,8 +138,8 @@\n     public static RecordFile parseRecordFile(String filePath, String expectedPrevFileHash, Instant verifyHashAfter,\n                                              Consumer<RecordItem> recordItemConsumer) {\n         RecordFile recordFile = new RecordFile();\n-        recordFile.setName(filePath);\n-        String fileName = Utility.getFileName(filePath);\n+        String fileName = FilenameUtils.getName(filePath);", "originalCommit": "226de784b082393ef1408b35b4df24e9c9696f19", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcxNzM0NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r457717344", "bodyText": "sure. and the change is bigger than I thought.", "author": "xin-hedera", "createdAt": "2020-07-20T22:03:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY5MzYxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEzNDI5OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r458134298", "bodyText": "We shouldn't remove StreamFileData. The purpose of that file is to abstract out the fact that we're storing the stream file on the filesystem in case we want to store it in a queue or the database in the future. I just meant the minimal change to the RecordFileDownloader to pass File. For RecordFileParser, can just construct a new File(streamFileData.getFilename()). Or we can just revert last commit and leave as is and revist later.", "author": "steven-sheehy", "createdAt": "2020-07-21T14:20:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY5MzYxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE0NTcxNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/876#discussion_r458145717", "bodyText": "i'll revert the last commit and just change the signature of Utility.recordFileParser.\nA relevant question, is StreamFileData.filename supposed to be the file name or the full file path? I have to change both RecordStreamFileListener.onStart(StreamFileData) implementations since it checks duplication against t_record_files using the StreamFileData.filename.\nWith t_record_files.name updated to the file name, I have to either change StreamFileData.filename to match t_record_files.name or change onStart implementation to get file name from full file path (yes, current implementation saves full pauth in StreamFileData.filename).", "author": "xin-hedera", "createdAt": "2020-07-21T14:34:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY5MzYxNA=="}], "type": "inlineReview"}, {"oid": "fbecc7c8251c60a85335a9f8dd8699d882b5c50a", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/fbecc7c8251c60a85335a9f8dd8699d882b5c50a", "message": "use file name instead of file path to query t_record_files to check duplicate\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>", "committedDate": "2020-07-21T14:51:26Z", "type": "commit"}, {"oid": "fbecc7c8251c60a85335a9f8dd8699d882b5c50a", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/fbecc7c8251c60a85335a9f8dd8699d882b5c50a", "message": "use file name instead of file path to query t_record_files to check duplicate\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>", "committedDate": "2020-07-21T14:51:26Z", "type": "forcePushed"}]}