{"pr_number": 1860, "pr_title": "HBASE-24380 : Provide WAL splitting journal logging", "pr_createdAt": "2020-06-05T18:14:09Z", "pr_url": "https://github.com/apache/hbase/pull/1860", "timeline": [{"oid": "8c6f6fa5f2a6ee35e882a8d1206d03ef1c1320e8", "url": "https://github.com/apache/hbase/commit/8c6f6fa5f2a6ee35e882a8d1206d03ef1c1320e8", "message": "HBASE-24380 : Provide WAL splitting journal logging", "committedDate": "2020-06-05T18:12:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk0MjkxNw==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r438942917", "bodyText": "Same", "author": "apurtell", "createdAt": "2020-06-11T17:14:11Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/OutputSink.java", "diffHunk": "@@ -129,10 +138,13 @@ long getTotalSkippedEdits() {\n \n   /**\n    * @param buffer A buffer of some number of edits for a given region.\n+   * @param status MonitoredTask instance to capture WAL splitting\n+   * @throws IOException For any IO errors\n    */\n-  abstract void append(EntryBuffers.RegionEntryBuffer buffer) throws IOException;\n+  abstract void append(EntryBuffers.RegionEntryBuffer buffer, MonitoredTask status)\n+    throws IOException;\n \n-  abstract List<Path> close() throws IOException;\n+  abstract List<Path> close(MonitoredTask status) throws IOException;", "originalCommit": "8c6f6fa5f2a6ee35e882a8d1206d03ef1c1320e8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk0MzI0Nw==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r438943247", "bodyText": "Same", "author": "apurtell", "createdAt": "2020-06-11T17:14:52Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/RecoveredEditsOutputSink.java", "diffHunk": "@@ -52,15 +53,16 @@ public RecoveredEditsOutputSink(WALSplitter walSplitter,\n   }\n \n   @Override\n-  public void append(EntryBuffers.RegionEntryBuffer buffer) throws IOException {\n+  public void append(EntryBuffers.RegionEntryBuffer buffer, MonitoredTask status)", "originalCommit": "8c6f6fa5f2a6ee35e882a8d1206d03ef1c1320e8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk0MzQyMg==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r438943422", "bodyText": "Same", "author": "apurtell", "createdAt": "2020-06-11T17:15:09Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/RecoveredEditsOutputSink.java", "diffHunk": "@@ -86,26 +88,27 @@ private RecoveredEditsWriter getRecoveredEditsWriter(TableName tableName, byte[]\n   }\n \n   @Override\n-  public List<Path> close() throws IOException {\n+  public List<Path> close(MonitoredTask status) throws IOException {", "originalCommit": "8c6f6fa5f2a6ee35e882a8d1206d03ef1c1320e8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk0MzUxNQ==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r438943515", "bodyText": "Same", "author": "apurtell", "createdAt": "2020-06-11T17:15:18Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/RecoveredEditsOutputSink.java", "diffHunk": "@@ -86,26 +88,27 @@ private RecoveredEditsWriter getRecoveredEditsWriter(TableName tableName, byte[]\n   }\n \n   @Override\n-  public List<Path> close() throws IOException {\n+  public List<Path> close(MonitoredTask status) throws IOException {\n     boolean isSuccessful = true;\n     try {\n-      isSuccessful &= finishWriterThreads();\n+      isSuccessful = finishWriterThreads();\n     } finally {\n-      isSuccessful &= closeWriters();\n+      isSuccessful &= closeWriters(status);\n     }\n     return isSuccessful ? splits : null;\n   }\n \n   /**\n    * Close all of the output streams.\n    *\n+   * @param status MonitoredTask instance to capture WAL splitting\n    * @return true when there is no error.\n    */\n-  private boolean closeWriters() throws IOException {\n+  private boolean closeWriters(MonitoredTask status) throws IOException {", "originalCommit": "8c6f6fa5f2a6ee35e882a8d1206d03ef1c1320e8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk0NDM2Mw==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r438944363", "bodyText": "Does this context have access to the OutputSink's MonitoredTask field? Can we do that instead, so we don't have to change these method signatures?", "author": "apurtell", "createdAt": "2020-06-11T17:16:55Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/BoundedRecoveredEditsOutputSink.java", "diffHunk": "@@ -83,25 +85,26 @@ public void append(EntryBuffers.RegionEntryBuffer buffer) throws IOException {\n   }\n \n   @Override\n-  public List<Path> close() throws IOException {\n+  public List<Path> close(MonitoredTask status) throws IOException {", "originalCommit": "8c6f6fa5f2a6ee35e882a8d1206d03ef1c1320e8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk0NDQ0MQ==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r438944441", "bodyText": "Does this context have access to the OutputSink's MonitoredTask field? Can we do that instead, so we don't have to change these method signatures?", "author": "apurtell", "createdAt": "2020-06-11T17:17:04Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/BoundedRecoveredEditsOutputSink.java", "diffHunk": "@@ -57,7 +58,8 @@ public BoundedRecoveredEditsOutputSink(WALSplitter walSplitter,\n   }\n \n   @Override\n-  public void append(EntryBuffers.RegionEntryBuffer buffer) throws IOException {\n+  public void append(EntryBuffers.RegionEntryBuffer buffer, MonitoredTask status)", "originalCommit": "8c6f6fa5f2a6ee35e882a8d1206d03ef1c1320e8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1bc4ca8f92be0c4098789b130e6e1d822eab0fe6", "url": "https://github.com/apache/hbase/commit/1bc4ca8f92be0c4098789b130e6e1d822eab0fe6", "message": "addressing review - use protected MonitorTask", "committedDate": "2020-06-11T18:10:33Z", "type": "commit"}, {"oid": "e17311ca80976e3a2484c555a416bb699e49067e", "url": "https://github.com/apache/hbase/commit/e17311ca80976e3a2484c555a416bb699e49067e", "message": "adding error msgs where possible", "committedDate": "2020-06-11T18:32:13Z", "type": "commit"}, {"oid": "b3d2ea2b416eb5dda8f50679ee37d73d45083297", "url": "https://github.com/apache/hbase/commit/b3d2ea2b416eb5dda8f50679ee37d73d45083297", "message": "add more status updates", "committedDate": "2020-06-12T10:38:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5MzI1Ng==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r440993256", "bodyText": "Will take care of removal of this import.", "author": "virajjasani", "createdAt": "2020-06-16T16:41:26Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/BoundedRecoveredEditsOutputSink.java", "diffHunk": "@@ -29,6 +29,7 @@\n import java.util.concurrent.atomic.AtomicInteger;\n \n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.monitoring.MonitoredTask;", "originalCommit": "b3d2ea2b416eb5dda8f50679ee37d73d45083297", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5MzQyMg==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r440993422", "bodyText": "same here", "author": "virajjasani", "createdAt": "2020-06-16T16:41:42Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/BoundedRecoveredHFilesOutputSink.java", "diffHunk": "@@ -41,6 +41,7 @@\n import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n import org.apache.hadoop.hbase.io.hfile.HFileContext;\n import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;\n+import org.apache.hadoop.hbase.monitoring.MonitoredTask;", "originalCommit": "b3d2ea2b416eb5dda8f50679ee37d73d45083297", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAxOTI4Nw==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r441019287", "bodyText": "Missing null check here?", "author": "apurtell", "createdAt": "2020-06-16T17:24:58Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/AbstractRecoveredEditsOutputSink.java", "diffHunk": "@@ -233,7 +251,10 @@ void writeRegionEntries(List<WAL.Entry> entries) throws IOException {\n         incrementNanoTime(System.nanoTime() - startTime);\n       } catch (IOException e) {\n         e = e instanceof RemoteException ? ((RemoteException) e).unwrapRemoteException() : e;\n-        LOG.error(HBaseMarkers.FATAL, \"Got while writing log entry to log\", e);\n+        final String errorMsg =\n+          \"Failed to write log entry \" + currentWalEntry.toString() + \" to log\";", "originalCommit": "b3d2ea2b416eb5dda8f50679ee37d73d45083297", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA1MTE0Mg==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r441051142", "bodyText": "IOException is thrown by writer.append(logEntry) and when we reach there, we are quite certain that currentWalEntry will be assigned some value for sure.", "author": "virajjasani", "createdAt": "2020-06-16T18:18:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAxOTI4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA1NzgxOQ==", "url": "https://github.com/apache/hbase/pull/1860#discussion_r441057819", "bodyText": "But this brings a good point, Exception catch should rather be at a place where it is needed, entire block doesn't need to be within try/catch if only single line of code is throwing specific Exception. Let me take care of this.", "author": "virajjasani", "createdAt": "2020-06-16T18:27:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAxOTI4Nw=="}], "type": "inlineReview"}, {"oid": "6bd43928db902c228b27bbb46b37d25ab727646d", "url": "https://github.com/apache/hbase/commit/6bd43928db902c228b27bbb46b37d25ab727646d", "message": "handle IOException for writer.append()", "committedDate": "2020-06-16T18:50:28Z", "type": "commit"}, {"oid": "73c67e70c6c08c420502c505445ac7250370bf9d", "url": "https://github.com/apache/hbase/commit/73c67e70c6c08c420502c505445ac7250370bf9d", "message": "redundant import", "committedDate": "2020-06-16T18:54:26Z", "type": "commit"}]}