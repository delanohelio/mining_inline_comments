{"pr_number": 1858, "pr_title": "HBASE-24506 async client deadlock", "pr_createdAt": "2020-06-05T08:50:30Z", "pr_url": "https://github.com/apache/hbase/pull/1858", "timeline": [{"oid": "08b77a5eca368f391f528e009c95e749d5fa750f", "url": "https://github.com/apache/hbase/commit/08b77a5eca368f391f528e009c95e749d5fa750f", "message": "HBASE-24506 async client deadlock", "committedDate": "2020-06-05T08:56:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA3NDI3Mw==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436074273", "bodyText": "just checking you want these to be java asserts? production jdks are almost never run with asserts enabled", "author": "busbey", "createdAt": "2020-06-05T17:53:15Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -146,45 +163,43 @@ private void established(Channel ch) throws IOException {\n   private boolean reloginInProgress;\n \n   private void scheduleRelogin(Throwable error) {\n+    assert eventLoop.inEventLoop();", "originalCommit": "08b77a5eca368f391f528e009c95e749d5fa750f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjI0NDk5Ng==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436244996", "bodyText": "My intention is to let later developpers know that this method must be called in the event loop thread. Do not want to introduce any overhead when executing the code in production, as in production, if it is not called in an event loop thread, it will be a ctitical bug and can not be recovered, so I do not think it worth other checks like Preconditions.checkXXX...", "author": "Apache9", "createdAt": "2020-06-06T06:53:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA3NDI3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExMzYwNw==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436113607", "bodyText": "Curious to know your thoughts on the performance implications of this change. Now that the event loop is responsible for more than what it was doing before, how would it affect the overall throughput.", "author": "bharathv", "createdAt": "2020-06-05T19:09:45Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -253,52 +268,38 @@ public void operationComplete(Future<Boolean> future) throws Exception {\n   }\n \n   private void connect() {\n+    assert eventLoop.inEventLoop();\n     LOG.trace(\"Connecting to {}\", remoteId.address);\n \n-    this.channel = new Bootstrap().group(rpcClient.group).channel(rpcClient.channelClass)\n-        .option(ChannelOption.TCP_NODELAY, rpcClient.isTcpNoDelay())\n-        .option(ChannelOption.SO_KEEPALIVE, rpcClient.tcpKeepAlive)\n-        .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, rpcClient.connectTO)\n-        .handler(new BufferCallBeforeInitHandler()).localAddress(rpcClient.localAddr)\n-        .remoteAddress(remoteId.address).connect().addListener(new ChannelFutureListener() {\n-\n-          @Override\n-          public void operationComplete(ChannelFuture future) throws Exception {\n-            Channel ch = future.channel();\n-            if (!future.isSuccess()) {\n-              failInit(ch, toIOE(future.cause()));\n-              rpcClient.failedServers.addToFailedServers(remoteId.address, future.cause());\n-              return;\n-            }\n-            ch.writeAndFlush(connectionHeaderPreamble.retainedDuplicate());\n-            if (useSasl) {\n-              saslNegotiate(ch);\n-            } else {\n-              // send the connection header to server\n-              ch.write(connectionHeaderWithLength.retainedDuplicate());\n-              established(ch);\n-            }\n-          }\n-        }).channel();\n-  }\n+    this.channel = new Bootstrap().group(eventLoop).channel(rpcClient.channelClass)\n+      .option(ChannelOption.TCP_NODELAY, rpcClient.isTcpNoDelay())\n+      .option(ChannelOption.SO_KEEPALIVE, rpcClient.tcpKeepAlive)\n+      .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, rpcClient.connectTO)\n+      .handler(new BufferCallBeforeInitHandler()).localAddress(rpcClient.localAddr)\n+      .remoteAddress(remoteId.address).connect().addListener(new ChannelFutureListener() {\n \n-  private void write(Channel ch, final Call call) {\n-    ch.writeAndFlush(call).addListener(new ChannelFutureListener() {\n-\n-      @Override\n-      public void operationComplete(ChannelFuture future) throws Exception {\n-        // Fail the call if we failed to write it out. This usually because the channel is\n-        // closed. This is needed because we may shutdown the channel inside event loop and\n-        // there may still be some pending calls in the event loop queue after us.\n-        if (!future.isSuccess()) {\n-          call.setException(toIOE(future.cause()));\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          Channel ch = future.channel();\n+          if (!future.isSuccess()) {\n+            failInit(ch, toIOE(future.cause()));\n+            rpcClient.failedServers.addToFailedServers(remoteId.address, future.cause());\n+            return;\n+          }\n+          ch.writeAndFlush(connectionHeaderPreamble.retainedDuplicate());\n+          if (useSasl) {\n+            saslNegotiate(ch);\n+          } else {\n+            // send the connection header to server\n+            ch.write(connectionHeaderWithLength.retainedDuplicate());\n+            established(ch);\n+          }\n         }\n-      }\n-    });\n+      }).channel();\n   }\n \n-  @Override\n-  public synchronized void sendRequest(final Call call, HBaseRpcController hrc) throws IOException {\n+  private void sendRequest0(Call call, HBaseRpcController hrc) throws IOException {\n+    assert eventLoop.inEventLoop();", "originalCommit": "08b77a5eca368f391f528e009c95e749d5fa750f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE1NTM1Ng==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436155356", "bodyText": "+1 I don't think the assert should be sitting in a hot path.", "author": "esteban", "createdAt": "2020-06-05T20:43:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExMzYwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjI0NDQyOA==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436244428", "bodyText": "I think you two are talking about different things? For the assert, just want to make sure that later developpers do not break the assumption as usually we will enable assert for UTs. For a production cluster where you want performance, you can just disable assert.\nAnd on the performance effect on event loop, I think it would be fine. As when you call write on a channel, finally they will switch to the event loop thread to call actual handlers. But anyway, we could run a PE to see the performance impact.", "author": "Apache9", "createdAt": "2020-06-06T06:42:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExMzYwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyMzAwOQ==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436123009", "bodyText": "nit: would the first if() be ever true for client threads?", "author": "bharathv", "createdAt": "2020-06-05T19:32:02Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -73,40 +73,53 @@\n   private static final Logger LOG = LoggerFactory.getLogger(NettyRpcConnection.class);\n \n   private static final ScheduledExecutorService RELOGIN_EXECUTOR =\n-      Executors.newSingleThreadScheduledExecutor(Threads.newDaemonThreadFactory(\"Relogin\"));\n+    Executors.newSingleThreadScheduledExecutor(Threads.newDaemonThreadFactory(\"Relogin\"));\n \n   private final NettyRpcClient rpcClient;\n \n+  // the event loop used to set up the connection, we will also execute other operations for this\n+  // connection in this event loop, to avoid locking everywhere.\n+  private final EventLoop eventLoop;\n+\n   private ByteBuf connectionHeaderPreamble;\n \n   private ByteBuf connectionHeaderWithLength;\n \n-  @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = \"IS2_INCONSISTENT_SYNC\",\n-      justification = \"connect is also under lock as notifyOnCancel will call our action directly\")\n-  private Channel channel;\n+  private volatile Channel channel;\n \n   NettyRpcConnection(NettyRpcClient rpcClient, ConnectionId remoteId) throws IOException {\n     super(rpcClient.conf, AbstractRpcClient.WHEEL_TIMER, remoteId, rpcClient.clusterId,\n-        rpcClient.userProvider.isHBaseSecurityEnabled(), rpcClient.codec, rpcClient.compressor);\n+      rpcClient.userProvider.isHBaseSecurityEnabled(), rpcClient.codec, rpcClient.compressor);\n     this.rpcClient = rpcClient;\n+    this.eventLoop = rpcClient.group.next();\n     byte[] connectionHeaderPreamble = getConnectionHeaderPreamble();\n     this.connectionHeaderPreamble =\n-        Unpooled.directBuffer(connectionHeaderPreamble.length).writeBytes(connectionHeaderPreamble);\n+      Unpooled.directBuffer(connectionHeaderPreamble.length).writeBytes(connectionHeaderPreamble);\n     ConnectionHeader header = getConnectionHeader();\n     this.connectionHeaderWithLength = Unpooled.directBuffer(4 + header.getSerializedSize());\n     this.connectionHeaderWithLength.writeInt(header.getSerializedSize());\n     header.writeTo(new ByteBufOutputStream(this.connectionHeaderWithLength));\n   }\n \n-  @Override\n-  protected synchronized void callTimeout(Call call) {\n-    if (channel != null) {\n-      channel.pipeline().fireUserEventTriggered(new CallEvent(TIMEOUT, call));\n+  private void execute(Runnable action) {\n+    if (eventLoop.inEventLoop()) {", "originalCommit": "08b77a5eca368f391f528e009c95e749d5fa750f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjI0NDE5MA==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436244190", "bodyText": "If your client is also in the same event loop thread then it will return yes.", "author": "Apache9", "createdAt": "2020-06-06T06:39:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyMzAwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyOTEwNQ==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436129105", "bodyText": "Just a question, why does it have to be giant synchronized? What is the un-safe shared state? Wondering if we can narrow down the lock and simplify the threading model to fix the actual problem.", "author": "bharathv", "createdAt": "2020-06-05T19:47:02Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -253,52 +268,38 @@ public void operationComplete(Future<Boolean> future) throws Exception {\n   }\n \n   private void connect() {\n+    assert eventLoop.inEventLoop();\n     LOG.trace(\"Connecting to {}\", remoteId.address);\n \n-    this.channel = new Bootstrap().group(rpcClient.group).channel(rpcClient.channelClass)\n-        .option(ChannelOption.TCP_NODELAY, rpcClient.isTcpNoDelay())\n-        .option(ChannelOption.SO_KEEPALIVE, rpcClient.tcpKeepAlive)\n-        .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, rpcClient.connectTO)\n-        .handler(new BufferCallBeforeInitHandler()).localAddress(rpcClient.localAddr)\n-        .remoteAddress(remoteId.address).connect().addListener(new ChannelFutureListener() {\n-\n-          @Override\n-          public void operationComplete(ChannelFuture future) throws Exception {\n-            Channel ch = future.channel();\n-            if (!future.isSuccess()) {\n-              failInit(ch, toIOE(future.cause()));\n-              rpcClient.failedServers.addToFailedServers(remoteId.address, future.cause());\n-              return;\n-            }\n-            ch.writeAndFlush(connectionHeaderPreamble.retainedDuplicate());\n-            if (useSasl) {\n-              saslNegotiate(ch);\n-            } else {\n-              // send the connection header to server\n-              ch.write(connectionHeaderWithLength.retainedDuplicate());\n-              established(ch);\n-            }\n-          }\n-        }).channel();\n-  }\n+    this.channel = new Bootstrap().group(eventLoop).channel(rpcClient.channelClass)\n+      .option(ChannelOption.TCP_NODELAY, rpcClient.isTcpNoDelay())\n+      .option(ChannelOption.SO_KEEPALIVE, rpcClient.tcpKeepAlive)\n+      .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, rpcClient.connectTO)\n+      .handler(new BufferCallBeforeInitHandler()).localAddress(rpcClient.localAddr)\n+      .remoteAddress(remoteId.address).connect().addListener(new ChannelFutureListener() {\n \n-  private void write(Channel ch, final Call call) {\n-    ch.writeAndFlush(call).addListener(new ChannelFutureListener() {\n-\n-      @Override\n-      public void operationComplete(ChannelFuture future) throws Exception {\n-        // Fail the call if we failed to write it out. This usually because the channel is\n-        // closed. This is needed because we may shutdown the channel inside event loop and\n-        // there may still be some pending calls in the event loop queue after us.\n-        if (!future.isSuccess()) {\n-          call.setException(toIOE(future.cause()));\n+        @Override\n+        public void operationComplete(ChannelFuture future) throws Exception {\n+          Channel ch = future.channel();\n+          if (!future.isSuccess()) {\n+            failInit(ch, toIOE(future.cause()));\n+            rpcClient.failedServers.addToFailedServers(remoteId.address, future.cause());\n+            return;\n+          }\n+          ch.writeAndFlush(connectionHeaderPreamble.retainedDuplicate());\n+          if (useSasl) {\n+            saslNegotiate(ch);\n+          } else {\n+            // send the connection header to server\n+            ch.write(connectionHeaderWithLength.retainedDuplicate());\n+            established(ch);\n+          }\n         }\n-      }\n-    });\n+      }).channel();\n   }\n \n-  @Override\n-  public synchronized void sendRequest(final Call call, HBaseRpcController hrc) throws IOException {", "originalCommit": "08b77a5eca368f391f528e009c95e749d5fa750f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjI0NDg1OA==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436244858", "bodyText": "The lock is to make sure that we always use the up to date Channel instance. You can see the old code, every time when we want to use the channel field, we will have a lock on it. And on the old sendRequest implementation, the problem is that, we need to hold the lock for the rpc controller, so that there will be no race when users call startCancel on the rpc controller. And to prevent dead lock, the preferred order is to acquire connection lock first, and then rpc controller lock, so we have to acquire the lock before calling notifyOnCancel method of the rpc controller...", "author": "Apache9", "createdAt": "2020-06-06T06:50:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyOTEwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjMyMTczMQ==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436321731", "bodyText": "Thanks for the explanation.\n\nThe lock is to make sure that we always use the up to date Channel instance.\n\nYa, this is the part that was not clear to me. As I understand it, Netty channel implementations are thread-safe (correct me if I'm wrong here). If I read the netty code correctly, all the channel/pipeline operations are internally enqueued on the eventloop.\nSo why can't we just make it a volatile and we have the up to date channel  for all threads to operate on? That removes one lock from the nested locking protocol for Channels and RpcControllers. In other words, whats the need to serialize all the operations on a channel inside NettyRpcConnection, before with synchronized and now with the event loop.\n(Also posted a question for you on jira, just so that I understand the problem 100%, thanks for your patience).", "author": "bharathv", "createdAt": "2020-06-07T03:49:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyOTEwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjMzNzY1Ng==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436337656", "bodyText": "This is covered already right? Maybe older comment, I might have read it in different order. Sorry for the confusion.\nBtw +1 for volatile channel and removal of synchronized from this method as netty is taking care of incoming requests already.", "author": "virajjasani", "createdAt": "2020-06-07T08:12:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyOTEwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjM0NjU5Nw==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436346597", "bodyText": "The channel instance is created on-demand in NettyRpcConnection, so we need to acquire lock to prevernt multiple creations. And also, the channel instance could be cleaned up, this is another reason that we need to acquire lock, otherwise there will be race that you operate on a closed channel and cause trouble.", "author": "Apache9", "createdAt": "2020-06-07T10:07:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyOTEwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQwOTg5NQ==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436409895", "bodyText": "Hmm okay. I still think the locking can be made fine grained with rw locks for channel and totally get rid of eventloop but its okay, your perf run shows no regression, so its fine.", "author": "bharathv", "createdAt": "2020-06-07T22:57:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyOTEwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE1MzEyNg==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436153126", "bodyText": "Same as @busbey mentioned at L166, asserts are not usually enabled.", "author": "esteban", "createdAt": "2020-06-05T20:38:05Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -146,45 +163,43 @@ private void established(Channel ch) throws IOException {\n   private boolean reloginInProgress;\n \n   private void scheduleRelogin(Throwable error) {\n+    assert eventLoop.inEventLoop();\n     if (error instanceof FallbackDisallowedException) {\n       return;\n     }\n     if (!provider.canRetry()) {\n       LOG.trace(\"SASL Provider does not support retries\");\n       return;\n     }\n-    synchronized (this) {\n-      if (reloginInProgress) {\n-        return;\n-      }\n-      reloginInProgress = true;\n-      RELOGIN_EXECUTOR.schedule(new Runnable() {\n+    if (reloginInProgress) {\n+      return;\n+    }\n+    reloginInProgress = true;\n+    RELOGIN_EXECUTOR.schedule(new Runnable() {\n \n-        @Override\n-        public void run() {\n-          try {\n-            provider.relogin();\n-          } catch (IOException e) {\n-            LOG.warn(\"Relogin failed\", e);\n-          }\n-          synchronized (this) {\n-            reloginInProgress = false;\n-          }\n+      @Override\n+      public void run() {\n+        try {\n+          provider.relogin();\n+        } catch (IOException e) {\n+          LOG.warn(\"Relogin failed\", e);\n         }\n-      }, ThreadLocalRandom.current().nextInt(reloginMaxBackoff), TimeUnit.MILLISECONDS);\n-    }\n+        eventLoop.execute(() -> {\n+          reloginInProgress = false;\n+        });\n+      }\n+    }, ThreadLocalRandom.current().nextInt(reloginMaxBackoff), TimeUnit.MILLISECONDS);\n   }\n \n   private void failInit(Channel ch, IOException e) {\n-    synchronized (this) {\n-      // fail all pending calls\n-      ch.pipeline().fireUserEventTriggered(BufferCallEvent.fail(e));\n-      shutdown0();\n-      return;\n-    }\n+    assert eventLoop.inEventLoop();", "originalCommit": "08b77a5eca368f391f528e009c95e749d5fa750f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE1MzMwMQ==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436153301", "bodyText": "same 08b77a5#r436153126", "author": "esteban", "createdAt": "2020-06-05T20:38:32Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -146,45 +163,43 @@ private void established(Channel ch) throws IOException {\n   private boolean reloginInProgress;\n \n   private void scheduleRelogin(Throwable error) {\n+    assert eventLoop.inEventLoop();\n     if (error instanceof FallbackDisallowedException) {\n       return;\n     }\n     if (!provider.canRetry()) {\n       LOG.trace(\"SASL Provider does not support retries\");\n       return;\n     }\n-    synchronized (this) {\n-      if (reloginInProgress) {\n-        return;\n-      }\n-      reloginInProgress = true;\n-      RELOGIN_EXECUTOR.schedule(new Runnable() {\n+    if (reloginInProgress) {\n+      return;\n+    }\n+    reloginInProgress = true;\n+    RELOGIN_EXECUTOR.schedule(new Runnable() {\n \n-        @Override\n-        public void run() {\n-          try {\n-            provider.relogin();\n-          } catch (IOException e) {\n-            LOG.warn(\"Relogin failed\", e);\n-          }\n-          synchronized (this) {\n-            reloginInProgress = false;\n-          }\n+      @Override\n+      public void run() {\n+        try {\n+          provider.relogin();\n+        } catch (IOException e) {\n+          LOG.warn(\"Relogin failed\", e);\n         }\n-      }, ThreadLocalRandom.current().nextInt(reloginMaxBackoff), TimeUnit.MILLISECONDS);\n-    }\n+        eventLoop.execute(() -> {\n+          reloginInProgress = false;\n+        });\n+      }\n+    }, ThreadLocalRandom.current().nextInt(reloginMaxBackoff), TimeUnit.MILLISECONDS);\n   }\n \n   private void failInit(Channel ch, IOException e) {\n-    synchronized (this) {\n-      // fail all pending calls\n-      ch.pipeline().fireUserEventTriggered(BufferCallEvent.fail(e));\n-      shutdown0();\n-      return;\n-    }\n+    assert eventLoop.inEventLoop();\n+    // fail all pending calls\n+    ch.pipeline().fireUserEventTriggered(BufferCallEvent.fail(e));\n+    shutdown0();\n   }\n \n   private void saslNegotiate(final Channel ch) {\n+    assert eventLoop.inEventLoop();", "originalCommit": "08b77a5eca368f391f528e009c95e749d5fa750f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE1MzUwNQ==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436153505", "bodyText": "same 08b77a5#r436153126", "author": "esteban", "createdAt": "2020-06-05T20:39:02Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -253,52 +268,38 @@ public void operationComplete(Future<Boolean> future) throws Exception {\n   }\n \n   private void connect() {\n+    assert eventLoop.inEventLoop();", "originalCommit": "08b77a5eca368f391f528e009c95e749d5fa750f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1b7c5ba8bc51a932ec47bddc0613b4d8ed217b63", "url": "https://github.com/apache/hbase/commit/1b7c5ba8bc51a932ec47bddc0613b4d8ed217b63", "message": "HBASE-24506 async client deadlock", "committedDate": "2020-06-06T08:04:22Z", "type": "forcePushed"}, {"oid": "fc72e3d96c1327b20dafff1ecd190826bee1297a", "url": "https://github.com/apache/hbase/commit/fc72e3d96c1327b20dafff1ecd190826bee1297a", "message": "HBASE-24506 async client deadlock", "committedDate": "2020-06-06T13:11:49Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjMzNjIxNg==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436336216", "bodyText": "nit: if we want to go till depth of 4, want to use MutableShort?", "author": "virajjasani", "createdAt": "2020-06-07T07:51:44Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -73,40 +79,77 @@\n   private static final Logger LOG = LoggerFactory.getLogger(NettyRpcConnection.class);\n \n   private static final ScheduledExecutorService RELOGIN_EXECUTOR =\n-      Executors.newSingleThreadScheduledExecutor(Threads.newDaemonThreadFactory(\"Relogin\"));\n+    Executors.newSingleThreadScheduledExecutor(Threads.newDaemonThreadFactory(\"Relogin\"));\n \n   private final NettyRpcClient rpcClient;\n \n+  // the event loop used to set up the connection, we will also execute other operations for this\n+  // connection in this event loop, to avoid locking everywhere.\n+  private final EventLoop eventLoop;\n+\n   private ByteBuf connectionHeaderPreamble;\n \n   private ByteBuf connectionHeaderWithLength;\n \n-  @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = \"IS2_INCONSISTENT_SYNC\",\n-      justification = \"connect is also under lock as notifyOnCancel will call our action directly\")\n-  private Channel channel;\n+  // make it volatile so in the isActive method below we do not need to switch to the event loop\n+  // thread to access this field.\n+  private volatile Channel channel;\n \n   NettyRpcConnection(NettyRpcClient rpcClient, ConnectionId remoteId) throws IOException {\n     super(rpcClient.conf, AbstractRpcClient.WHEEL_TIMER, remoteId, rpcClient.clusterId,\n-        rpcClient.userProvider.isHBaseSecurityEnabled(), rpcClient.codec, rpcClient.compressor);\n+      rpcClient.userProvider.isHBaseSecurityEnabled(), rpcClient.codec, rpcClient.compressor);\n     this.rpcClient = rpcClient;\n+    this.eventLoop = rpcClient.group.next();\n     byte[] connectionHeaderPreamble = getConnectionHeaderPreamble();\n     this.connectionHeaderPreamble =\n-        Unpooled.directBuffer(connectionHeaderPreamble.length).writeBytes(connectionHeaderPreamble);\n+      Unpooled.directBuffer(connectionHeaderPreamble.length).writeBytes(connectionHeaderPreamble);\n     ConnectionHeader header = getConnectionHeader();\n     this.connectionHeaderWithLength = Unpooled.directBuffer(4 + header.getSerializedSize());\n     this.connectionHeaderWithLength.writeInt(header.getSerializedSize());\n     header.writeTo(new ByteBufOutputStream(this.connectionHeaderWithLength));\n   }\n \n-  @Override\n-  protected synchronized void callTimeout(Call call) {\n-    if (channel != null) {\n-      channel.pipeline().fireUserEventTriggered(new CallEvent(TIMEOUT, call));\n+  private static final FastThreadLocal<MutableInt> DEPTH = new FastThreadLocal<MutableInt>() {", "originalCommit": "fc72e3d96c1327b20dafff1ecd190826bee1297a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjM3MDgyNg==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436370826", "bodyText": "The overhead is very small I suppose? Only a final static field...\nUsing Short or Byte is easy to introduce other problems as when comparing they will be cast to int...", "author": "Apache9", "createdAt": "2020-06-07T14:46:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjMzNjIxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjMzNjY1NQ==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436336655", "bodyText": "nit: Would you prefer converting to lambda () -> ?", "author": "virajjasani", "createdAt": "2020-06-07T07:57:46Z", "path": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/NettyRpcConnection.java", "diffHunk": "@@ -153,35 +200,30 @@ private void scheduleRelogin(Throwable error) {\n       LOG.trace(\"SASL Provider does not support retries\");\n       return;\n     }\n-    synchronized (this) {\n-      if (reloginInProgress) {\n-        return;\n-      }\n-      reloginInProgress = true;\n-      RELOGIN_EXECUTOR.schedule(new Runnable() {\n+    if (reloginInProgress) {\n+      return;\n+    }\n+    reloginInProgress = true;\n+    RELOGIN_EXECUTOR.schedule(new Runnable() {", "originalCommit": "fc72e3d96c1327b20dafff1ecd190826bee1297a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "03931bd005f0479061aa97b92144bb6f8ea37aa9", "url": "https://github.com/apache/hbase/commit/03931bd005f0479061aa97b92144bb6f8ea37aa9", "message": "HBASE-24506 async client deadlock", "committedDate": "2020-06-07T14:41:56Z", "type": "forcePushed"}, {"oid": "8d01fbc5a873321695b7db9191e91dbed4538576", "url": "https://github.com/apache/hbase/commit/8d01fbc5a873321695b7db9191e91dbed4538576", "message": "HBASE-24506 async client deadlock", "committedDate": "2020-06-07T14:43:20Z", "type": "commit"}, {"oid": "8d01fbc5a873321695b7db9191e91dbed4538576", "url": "https://github.com/apache/hbase/commit/8d01fbc5a873321695b7db9191e91dbed4538576", "message": "HBASE-24506 async client deadlock", "committedDate": "2020-06-07T14:43:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjQxNzU0Mw==", "url": "https://github.com/apache/hbase/pull/1858#discussion_r436417543", "bodyText": "haha, nice test :-)", "author": "bharathv", "createdAt": "2020-06-08T00:38:33Z", "path": "hbase-client/src/test/java/org/apache/hadoop/hbase/ipc/TestNettyRpcConnection.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.ipc;\n+\n+import static org.hamcrest.CoreMatchers.instanceOf;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.fail;\n+\n+import java.io.IOException;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.lang.reflect.Modifier;\n+import java.net.InetSocketAddress;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.HBaseConfiguration;\n+import org.apache.hadoop.hbase.security.User;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hbase.thirdparty.com.google.common.io.Closeables;\n+\n+public class TestNettyRpcConnection {\n+\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+    HBaseClassTestRule.forClass(TestNettyRpcConnection.class);\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(TestNettyRpcConnection.class);\n+\n+  private static NettyRpcClient CLIENT;\n+\n+  private static NettyRpcConnection CONN;\n+\n+  @BeforeClass\n+  public static void setUp() throws IOException {\n+    CLIENT = new NettyRpcClient(HBaseConfiguration.create());\n+    CONN = new NettyRpcConnection(CLIENT,\n+      new ConnectionId(User.getCurrent(), \"test\", new InetSocketAddress(\"localhost\", 1234)));\n+  }\n+\n+  @AfterClass\n+  public static void tearDown() throws IOException {\n+    Closeables.close(CLIENT, true);\n+  }\n+\n+  @Test\n+  public void testPrivateMethodExecutedInEventLoop() throws IllegalAccessException {\n+    // make sure the test is executed with \"-ea\"\n+    assertThrows(AssertionError.class, () -> {\n+      assert false;\n+    });\n+    for (Method method : NettyRpcConnection.class.getDeclaredMethods()) {\n+      if (Modifier.isPrivate(method.getModifiers()) && !method.getName().contains(\"$\")) {\n+        LOG.info(\"checking {}\", method);\n+        method.setAccessible(true);\n+        // all private methods should be called inside the event loop thread, so calling it from", "originalCommit": "8d01fbc5a873321695b7db9191e91dbed4538576", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}