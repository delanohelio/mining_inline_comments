{"pr_number": 2579, "pr_title": "HBASE-24999 Master manages ReplicationServers", "pr_createdAt": "2020-10-22T07:25:17Z", "pr_url": "https://github.com/apache/hbase/pull/2579", "timeline": [{"oid": "00f78bac9699aff4578744eee6ba799375f6fbab", "url": "https://github.com/apache/hbase/commit/00f78bac9699aff4578744eee6ba799375f6fbab", "message": "HBASE-24999 Master manages ReplicationServers", "committedDate": "2020-10-22T08:45:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA5MjAxOA==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r510092018", "bodyText": "Would it make sense to extend ServerManager, or maybe both this one and ServerManager could implement a common interface? It seems there is a common workflow for server managers.", "author": "wchevreuil", "createdAt": "2020-10-22T11:40:35Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/ReplicationServerManager.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentNavigableMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.ScheduledChore;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The ServerManager class manages info about replication servers.\n+ * <p>\n+ * Maintains lists of online and dead servers.\n+ * <p>\n+ * Servers are distinguished in two different ways.  A given server has a\n+ * location, specified by hostname and port, and of which there can only be one\n+ * online at any given time.  A server instance is specified by the location\n+ * (hostname and port) as well as the startcode (timestamp from when the server\n+ * was started).  This is used to differentiate a restarted instance of a given\n+ * server from the original instance.\n+ */\n+@InterfaceAudience.Private\n+public class ReplicationServerManager {", "originalCommit": "00f78bac9699aff4578744eee6ba799375f6fbab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTY3NDg0NA==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511674844", "bodyText": "Yes. But we want do this refator after we finished this, because ReplicationServerManager may have new featrues but ServerManager not need. It is not easy to decide that extend ServerManager or implement a common interface. Thanks.", "author": "infraio", "createdAt": "2020-10-26T00:55:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA5MjAxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA5NjUzOA==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r510096538", "bodyText": "Nit: should we log server is getting expired?", "author": "wchevreuil", "createdAt": "2020-10-22T11:48:43Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/ReplicationServerManager.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentNavigableMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.ScheduledChore;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The ServerManager class manages info about replication servers.\n+ * <p>\n+ * Maintains lists of online and dead servers.\n+ * <p>\n+ * Servers are distinguished in two different ways.  A given server has a\n+ * location, specified by hostname and port, and of which there can only be one\n+ * online at any given time.  A server instance is specified by the location\n+ * (hostname and port) as well as the startcode (timestamp from when the server\n+ * was started).  This is used to differentiate a restarted instance of a given\n+ * server from the original instance.\n+ */\n+@InterfaceAudience.Private\n+public class ReplicationServerManager {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ReplicationServerManager.class);\n+\n+  public static final String ONLINE_SERVER_REFRESH_INTERVAL =\n+      \"hbase.master.replication.server.refresh.interval\";\n+  public static final int ONLINE_SERVER_REFRESH_INTERVAL_DEFAULT = 60 * 1000; // 1 mins\n+\n+  private final MasterServices master;\n+\n+  /** Map of registered servers to their current load */\n+  private final ConcurrentNavigableMap<ServerName, ServerMetrics> onlineServers =\n+    new ConcurrentSkipListMap<>();\n+\n+  private OnlineServerRefresher onlineServerRefresher;\n+  private int refreshPeriod;\n+\n+  /**\n+   * Constructor.\n+   */\n+  public ReplicationServerManager(final MasterServices master) {\n+    this.master = master;\n+  }\n+\n+  /**\n+   * start chore in ServerManager\n+   */\n+  public void startChore() {\n+    Configuration conf = master.getConfiguration();\n+    refreshPeriod = conf.getInt(ONLINE_SERVER_REFRESH_INTERVAL,\n+        ONLINE_SERVER_REFRESH_INTERVAL_DEFAULT);\n+    onlineServerRefresher = new OnlineServerRefresher(\"ReplicationServerRefresher\", refreshPeriod);\n+    master.getChoreService().scheduleChore(onlineServerRefresher);\n+  }\n+\n+  /**\n+   * Stop the ServerManager.\n+   */\n+  public void stop() {\n+    if (onlineServerRefresher != null) {\n+      onlineServerRefresher.cancel();\n+    }\n+  }\n+\n+  public void serverReport(ServerName sn, ServerMetrics sl) {\n+    if (null == this.onlineServers.replace(sn, sl)) {\n+      if (!checkAndRecordNewServer(sn, sl)) {\n+        LOG.info(\"ReplicationServerReport ignored, could not record the server: {}\", sn);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Check is a server of same host and port already exists,\n+   * if not, or the existed one got a smaller start code, record it.\n+   *\n+   * @param serverName the server to check and record\n+   * @param sl the server load on the server\n+   * @return true if the server is recorded, otherwise, false\n+   */\n+  boolean checkAndRecordNewServer(final ServerName serverName, final ServerMetrics sl) {\n+    ServerName existingServer = null;\n+    synchronized (this.onlineServers) {\n+      existingServer = findServerWithSameHostnamePortWithLock(serverName);\n+      if (existingServer != null && (existingServer.getStartcode() > serverName.getStartcode())) {\n+        LOG.info(\"ReplicationServer serverName={} rejected; we already have {} registered with \"\n+          + \"same hostname and port\", serverName, existingServer);\n+        return false;\n+      }\n+      recordNewServerWithLock(serverName, sl);\n+      // Note that we assume that same ts means same server, and don't expire in that case.\n+      if (existingServer != null && (existingServer.getStartcode() < serverName.getStartcode())) {\n+        LOG.info(\"Triggering server recovery; existingServer {} looks stale, new server: {}\",\n+            existingServer, serverName);\n+        expireServerWithLock(existingServer);\n+      }\n+    }\n+    return true;\n+  }\n+\n+  /**\n+   * Assumes onlineServers is locked.\n+   * @return ServerName with matching hostname and port.\n+   */\n+  private ServerName findServerWithSameHostnamePortWithLock(final ServerName serverName) {\n+    ServerName end = ServerName.valueOf(serverName.getHostname(), serverName.getPort(),\n+      Long.MAX_VALUE);\n+\n+    ServerName r = onlineServers.lowerKey(end);\n+    if (r != null && ServerName.isSameAddress(r, serverName)) {\n+      return r;\n+    }\n+    return null;\n+  }\n+\n+  private void recordNewServerWithLock(final ServerName serverName, final ServerMetrics sl) {\n+    LOG.info(\"Registering ReplicationServer={}\", serverName);\n+    this.onlineServers.put(serverName, sl);\n+  }\n+\n+  /**\n+   * Expire the passed server. Remove it from list of online servers\n+   */\n+  public void expireServerWithLock(final ServerName serverName) {\n+    onlineServers.remove(serverName);", "originalCommit": "00f78bac9699aff4578744eee6ba799375f6fbab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNzQ0OQ==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511707449", "bodyText": "OK", "author": "ddupg", "createdAt": "2020-10-26T03:52:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA5NjUzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDI0NDM2Ng==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r510244366", "bodyText": "Is it true that an empty list would be returned if we can't reach slave master? Looks like we either throw an IOException or a RemoteException.", "author": "wchevreuil", "createdAt": "2020-10-22T15:14:31Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HBaseReplicationEndpoint.java", "diffHunk": "@@ -288,39 +258,26 @@ public boolean isAborted() {\n     return false;\n   }\n \n-  /**\n-   * Get the connection to peer cluster\n-   * @return connection to peer cluster\n-   * @throws IOException If anything goes wrong connecting\n-   */\n-  private synchronized AsyncClusterConnection getPeerConnection() throws IOException {\n-    if (peerConnection == null) {\n-      Configuration conf = ctx.getConfiguration();\n-      peerConnection = ClusterConnectionFactory.createAsyncClusterConnection(conf, null,\n-          UserProvider.instantiate(conf).getCurrent());\n-    }\n-    return peerConnection;\n-  }\n-\n   /**\n    * Get the list of all the servers that are responsible for replication sink\n    * from the specified peer master\n    * @return list of server addresses or an empty list if the slave is unavailable", "originalCommit": "00f78bac9699aff4578744eee6ba799375f6fbab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTcwNzM1NQ==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511707355", "bodyText": "Yes, I ignored changing the comment.\nFixed it.", "author": "ddupg", "createdAt": "2020-10-26T03:52:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDI0NDM2Ng=="}], "type": "inlineReview"}, {"oid": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "url": "https://github.com/apache/hbase/commit/6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "message": "HBASE-24999 Master manages ReplicationServers", "committedDate": "2020-10-26T03:50:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczODE5OA==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511738198", "bodyText": "ServerManager\u3000=> ReplicationServerManager?", "author": "infraio", "createdAt": "2020-10-26T06:19:08Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/ReplicationServerManager.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentNavigableMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.ScheduledChore;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The ServerManager class manages info about replication servers.", "originalCommit": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTczODUyOA==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511738528", "bodyText": "private method?", "author": "infraio", "createdAt": "2020-10-26T06:20:23Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/ReplicationServerManager.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentNavigableMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.ScheduledChore;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The ServerManager class manages info about replication servers.\n+ * <p>\n+ * Maintains lists of online and dead servers.\n+ * <p>\n+ * Servers are distinguished in two different ways.  A given server has a\n+ * location, specified by hostname and port, and of which there can only be one\n+ * online at any given time.  A server instance is specified by the location\n+ * (hostname and port) as well as the startcode (timestamp from when the server\n+ * was started).  This is used to differentiate a restarted instance of a given\n+ * server from the original instance.\n+ */\n+@InterfaceAudience.Private\n+public class ReplicationServerManager {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ReplicationServerManager.class);\n+\n+  public static final String ONLINE_SERVER_REFRESH_INTERVAL =\n+      \"hbase.master.replication.server.refresh.interval\";\n+  public static final int ONLINE_SERVER_REFRESH_INTERVAL_DEFAULT = 60 * 1000; // 1 mins\n+\n+  private final MasterServices master;\n+\n+  /** Map of registered servers to their current load */\n+  private final ConcurrentNavigableMap<ServerName, ServerMetrics> onlineServers =\n+    new ConcurrentSkipListMap<>();\n+\n+  private OnlineServerRefresher onlineServerRefresher;\n+  private int refreshPeriod;\n+\n+  /**\n+   * Constructor.\n+   */\n+  public ReplicationServerManager(final MasterServices master) {\n+    this.master = master;\n+  }\n+\n+  /**\n+   * start chore in ServerManager\n+   */\n+  public void startChore() {\n+    Configuration conf = master.getConfiguration();\n+    refreshPeriod = conf.getInt(ONLINE_SERVER_REFRESH_INTERVAL,\n+        ONLINE_SERVER_REFRESH_INTERVAL_DEFAULT);\n+    onlineServerRefresher = new OnlineServerRefresher(\"ReplicationServerRefresher\", refreshPeriod);\n+    master.getChoreService().scheduleChore(onlineServerRefresher);\n+  }\n+\n+  /**\n+   * Stop the ServerManager.\n+   */\n+  public void stop() {\n+    if (onlineServerRefresher != null) {\n+      onlineServerRefresher.cancel();\n+    }\n+  }\n+\n+  public void serverReport(ServerName sn, ServerMetrics sl) {\n+    if (null == this.onlineServers.replace(sn, sl)) {\n+      if (!checkAndRecordNewServer(sn, sl)) {\n+        LOG.info(\"ReplicationServerReport ignored, could not record the server: {}\", sn);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Check is a server of same host and port already exists,\n+   * if not, or the existed one got a smaller start code, record it.\n+   *\n+   * @param serverName the server to check and record\n+   * @param sl the server load on the server\n+   * @return true if the server is recorded, otherwise, false\n+   */\n+  boolean checkAndRecordNewServer(final ServerName serverName, final ServerMetrics sl) {", "originalCommit": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MDcxNg==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511740716", "bodyText": "So in the new impl, it will always register zk listener but ignored the zk event if not use zk?", "author": "infraio", "createdAt": "2020-10-26T06:28:28Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HBaseReplicationEndpoint.java", "diffHunk": "@@ -445,7 +418,7 @@ public PeerRegionServerListener(HBaseReplicationEndpoint endpoint) {\n \n     @Override\n     public synchronized void nodeChildrenChanged(String path) {\n-      if (path.equals(regionServerListNode)) {\n+      if (replicationEndpoint.fetchServersUseZk && path.equals(regionServerListNode)) {", "originalCommit": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MTAzNg==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511741036", "bodyText": "Add comment in the class javadoc for this new impl?", "author": "infraio", "createdAt": "2020-10-26T06:29:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MDcxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg1MjAyMw==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511852023", "bodyText": "OK", "author": "ddupg", "createdAt": "2020-10-26T10:18:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MDcxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MTQ2OQ==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511741469", "bodyText": "private method is enough?", "author": "infraio", "createdAt": "2020-10-26T06:30:53Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -388,4 +446,152 @@ protected ReplicationServerRpcServices createRpcServices() throws IOException {\n   protected boolean setAbortRequested() {\n     return abortRequested.compareAndSet(false, true);\n   }\n+\n+  protected void tryReplicationServerReport(long reportStartTime, long reportEndTime)", "originalCommit": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTc0MTUwNQ==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r511741505", "bodyText": "Ditto.", "author": "infraio", "createdAt": "2020-10-26T06:31:03Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -388,4 +446,152 @@ protected ReplicationServerRpcServices createRpcServices() throws IOException {\n   protected boolean setAbortRequested() {\n     return abortRequested.compareAndSet(false, true);\n   }\n+\n+  protected void tryReplicationServerReport(long reportStartTime, long reportEndTime)\n+      throws IOException {\n+    ReplicationServerStatusService.BlockingInterface rss = rssStub;\n+    if (rss == null) {\n+      createReplicationServerStatusStub(true);\n+      rss = rssStub;\n+      if (rss == null) {\n+        return;\n+      }\n+    }\n+    ClusterStatusProtos.ServerLoad sl = buildServerLoad(reportStartTime, reportEndTime);\n+    try {\n+      RegionServerReportRequest.Builder request = RegionServerReportRequest\n+          .newBuilder();\n+      request.setServer(ProtobufUtil.toServerName(this.serverName));\n+      request.setLoad(sl);\n+      rss.replicationServerReport(null, request.build());\n+    } catch (ServiceException se) {\n+      IOException ioe = ProtobufUtil.getRemoteException(se);\n+      if (ioe instanceof YouAreDeadException) {\n+        // This will be caught and handled as a fatal error in run()\n+        throw ioe;\n+      }\n+      if (rssStub == rss) {\n+        rssStub = null;\n+      }\n+      // Couldn't connect to the master, get location from zk and reconnect\n+      // Method blocks until new master is found or we are stopped\n+      createReplicationServerStatusStub(true);\n+    }\n+  }\n+\n+  private ClusterStatusProtos.ServerLoad buildServerLoad(long reportStartTime, long reportEndTime) {\n+    long usedMemory = -1L;\n+    long maxMemory = -1L;\n+    final MemoryUsage usage = MemorySizeUtil.safeGetHeapMemoryUsage();\n+    if (usage != null) {\n+      usedMemory = usage.getUsed();\n+      maxMemory = usage.getMax();\n+    }\n+\n+    ClusterStatusProtos.ServerLoad.Builder serverLoad = ClusterStatusProtos.ServerLoad.newBuilder();\n+    serverLoad.setTotalNumberOfRequests(rpcServices.requestCount.sum());\n+    serverLoad.setUsedHeapMB((int) (usedMemory / 1024 / 1024));\n+    serverLoad.setMaxHeapMB((int) (maxMemory / 1024 / 1024));\n+\n+    serverLoad.setReportStartTime(reportStartTime);\n+    serverLoad.setReportEndTime(reportEndTime);\n+\n+    // for the replicationLoad purpose. Only need to get from one executorService\n+    // either source or sink will get the same info\n+    ReplicationSinkService sinks = getReplicationSinkService();\n+\n+    if (sinks != null) {\n+      // always refresh first to get the latest value\n+      ReplicationLoad rLoad = sinks.refreshAndGetReplicationLoad();\n+      if (rLoad != null) {\n+        serverLoad.setReplLoadSink(rLoad.getReplicationLoadSink());\n+      }\n+    }\n+    return serverLoad.build();\n+  }\n+\n+  /**\n+   * Get the current master from ZooKeeper and open the RPC connection to it. To get a fresh\n+   * connection, the current rssStub must be null. Method will block until a master is available.\n+   * You can break from this block by requesting the server stop.\n+   * @param refresh If true then master address will be read from ZK, otherwise use cached data\n+   * @return master + port, or null if server has been stopped\n+   */\n+  protected synchronized ServerName createReplicationServerStatusStub(boolean refresh) {", "originalCommit": "6140c03a48c6e3d67869b5cdae9f97ab3ab5eecc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8", "url": "https://github.com/apache/hbase/commit/cb2c73feda971dd9cbbde171f07c8ed753acc1b8", "message": "HBASE-24999 Master manages ReplicationServers", "committedDate": "2020-10-26T10:14:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM1NTM1OQ==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r512355359", "bodyText": "One new question: ReplicationServer should not have request count metric? Because this metric should mean that read metric or write metric?", "author": "infraio", "createdAt": "2020-10-27T01:02:03Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java", "diffHunk": "@@ -3402,4 +3406,33 @@ public ListReplicationSinkServersResponse listReplicationSinkServers(\n     }\n     return builder.build();\n   }\n+\n+  @Override\n+  public RegionServerReportResponse replicationServerReport(RpcController controller,\n+      RegionServerReportRequest request) throws ServiceException {\n+    try {\n+      master.checkServiceStarted();\n+      int versionNumber = 0;\n+      String version = \"0.0.0\";\n+      VersionInfo versionInfo = VersionInfoUtil.getCurrentClientVersionInfo();\n+      if (versionInfo != null) {\n+        version = versionInfo.getVersion();\n+        versionNumber = VersionInfoUtil.getVersionNumber(versionInfo);\n+      }\n+      ClusterStatusProtos.ServerLoad sl = request.getLoad();\n+      ServerName serverName = ProtobufUtil.toServerName(request.getServer());\n+      ServerMetrics oldMetrics = master.getReplicationServerManager().getServerMetrics(serverName);\n+      ServerMetrics newMetrics =\n+          ServerMetricsBuilder.toServerMetrics(serverName, versionNumber, version, sl);\n+      master.getReplicationServerManager().serverReport(serverName, newMetrics);\n+      if (sl != null && master.metricsMaster != null) {\n+        // Up our metrics.\n+        master.metricsMaster.incrementRequests(sl.getTotalNumberOfRequests()", "originalCommit": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM5OTE3OA==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r512399178", "bodyText": "RegionServer increments request count metric in all RPC method, including replicateWALEntry, so the request count metric should mean more than just reading and writing metric?", "author": "ddupg", "createdAt": "2020-10-27T03:44:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM1NTM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjQxMzg0Ng==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r512413846", "bodyText": "Got it.", "author": "infraio", "createdAt": "2020-10-27T04:45:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM1NTM1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM2MTc4NQ==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r512361785", "bodyText": "The return ServerName never used?", "author": "infraio", "createdAt": "2020-10-27T01:25:51Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/HReplicationServer.java", "diffHunk": "@@ -388,4 +446,152 @@ protected ReplicationServerRpcServices createRpcServices() throws IOException {\n   protected boolean setAbortRequested() {\n     return abortRequested.compareAndSet(false, true);\n   }\n+\n+  private void tryReplicationServerReport(long reportStartTime, long reportEndTime)\n+      throws IOException {\n+    ReplicationServerStatusService.BlockingInterface rss = rssStub;\n+    if (rss == null) {\n+      createReplicationServerStatusStub(true);\n+      rss = rssStub;\n+      if (rss == null) {\n+        return;\n+      }\n+    }\n+    ClusterStatusProtos.ServerLoad sl = buildServerLoad(reportStartTime, reportEndTime);\n+    try {\n+      RegionServerReportRequest.Builder request = RegionServerReportRequest\n+          .newBuilder();\n+      request.setServer(ProtobufUtil.toServerName(this.serverName));\n+      request.setLoad(sl);\n+      rss.replicationServerReport(null, request.build());\n+    } catch (ServiceException se) {\n+      IOException ioe = ProtobufUtil.getRemoteException(se);\n+      if (ioe instanceof YouAreDeadException) {\n+        // This will be caught and handled as a fatal error in run()\n+        throw ioe;\n+      }\n+      if (rssStub == rss) {\n+        rssStub = null;\n+      }\n+      // Couldn't connect to the master, get location from zk and reconnect\n+      // Method blocks until new master is found or we are stopped\n+      createReplicationServerStatusStub(true);\n+    }\n+  }\n+\n+  private ClusterStatusProtos.ServerLoad buildServerLoad(long reportStartTime, long reportEndTime) {\n+    long usedMemory = -1L;\n+    long maxMemory = -1L;\n+    final MemoryUsage usage = MemorySizeUtil.safeGetHeapMemoryUsage();\n+    if (usage != null) {\n+      usedMemory = usage.getUsed();\n+      maxMemory = usage.getMax();\n+    }\n+\n+    ClusterStatusProtos.ServerLoad.Builder serverLoad = ClusterStatusProtos.ServerLoad.newBuilder();\n+    serverLoad.setTotalNumberOfRequests(rpcServices.requestCount.sum());\n+    serverLoad.setUsedHeapMB((int) (usedMemory / 1024 / 1024));\n+    serverLoad.setMaxHeapMB((int) (maxMemory / 1024 / 1024));\n+\n+    serverLoad.setReportStartTime(reportStartTime);\n+    serverLoad.setReportEndTime(reportEndTime);\n+\n+    // for the replicationLoad purpose. Only need to get from one executorService\n+    // either source or sink will get the same info\n+    ReplicationSinkService sinks = getReplicationSinkService();\n+\n+    if (sinks != null) {\n+      // always refresh first to get the latest value\n+      ReplicationLoad rLoad = sinks.refreshAndGetReplicationLoad();\n+      if (rLoad != null) {\n+        serverLoad.setReplLoadSink(rLoad.getReplicationLoadSink());\n+      }\n+    }\n+    return serverLoad.build();\n+  }\n+\n+  /**\n+   * Get the current master from ZooKeeper and open the RPC connection to it. To get a fresh\n+   * connection, the current rssStub must be null. Method will block until a master is available.\n+   * You can break from this block by requesting the server stop.\n+   * @param refresh If true then master address will be read from ZK, otherwise use cached data\n+   * @return master + port, or null if server has been stopped\n+   */\n+  private synchronized ServerName createReplicationServerStatusStub(boolean refresh) {", "originalCommit": "cb2c73feda971dd9cbbde171f07c8ed753acc1b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM5OTE5OQ==", "url": "https://github.com/apache/hbase/pull/2579#discussion_r512399199", "bodyText": "It should be useful, let me fix it.", "author": "ddupg", "createdAt": "2020-10-27T03:44:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjM2MTc4NQ=="}], "type": "inlineReview"}, {"oid": "a84cabfa51dd886f2448b9477e89db5f3e6ee5fd", "url": "https://github.com/apache/hbase/commit/a84cabfa51dd886f2448b9477e89db5f3e6ee5fd", "message": "HBASE-24999 Master manages ReplicationServers", "committedDate": "2020-10-27T03:43:33Z", "type": "commit"}, {"oid": "a84cabfa51dd886f2448b9477e89db5f3e6ee5fd", "url": "https://github.com/apache/hbase/commit/a84cabfa51dd886f2448b9477e89db5f3e6ee5fd", "message": "HBASE-24999 Master manages ReplicationServers", "committedDate": "2020-10-27T03:43:33Z", "type": "forcePushed"}]}