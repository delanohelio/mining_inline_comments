{"pr_number": 2490, "pr_title": "HBASE-24419 Normalizer merge plans should consider more than 2 regions when possible", "pr_createdAt": "2020-10-01T17:15:52Z", "pr_url": "https://github.com/apache/hbase/pull/2490", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc5MDA4MQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499790081", "bodyText": "Good. Normalizer is growing-up!", "author": "saintstack", "createdAt": "2020-10-05T18:27:06Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -406,11 +396,8 @@ public void run() {\n   private final LockManager lockManager = new LockManager(this);\n \n   private RSGroupBasedLoadBalancer balancer;\n-  // a lock to prevent concurrent normalization actions.\n-  private final ReentrantLock normalizationInProgressLock = new ReentrantLock();\n-  private RegionNormalizer normalizer;\n   private BalancerChore balancerChore;\n-  private RegionNormalizerChore normalizerChore;\n+  private RegionNormalizerManager regionNormalizerManager;", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc5MDk4Mg==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499790982", "bodyText": "These things have to be public on HMaster?", "author": "saintstack", "createdAt": "2020-10-05T18:28:53Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -3003,18 +2933,20 @@ public double getAverageLoad() {\n     return regionStates.getAverageLoad();\n   }\n \n-  /*\n-   * @return the count of region split plans executed\n+  /**\n+   * Exposed here for metrics.\n+   * @see RegionNormalizerManager#getSplitPlanCount()\n    */\n   public long getSplitPlanCount() {\n-    return splitPlanCount;\n+    return regionNormalizerManager.getSplitPlanCount();\n   }\n \n-  /*\n-   * @return the count of region merge plans executed\n+  /**\n+   * Exposed here for metrics.\n+   * @see RegionNormalizerManager#getMergePlanCount()\n    */\n   public long getMergePlanCount() {\n-    return mergePlanCount;\n+    return regionNormalizerManager.getMergePlanCount();", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkxMjU3Mw==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499912573", "bodyText": "Yeah these are exposed as metrics, all of which hang off of the HMaster instance. I think it's a larger refactor (and probably backward incompatible) to move these various metrics down a level in the metric name dotted-path.", "author": "ndimiduk", "createdAt": "2020-10-05T22:46:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc5MDk4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc5OTAzMw==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499799033", "bodyText": "Changing signature but this should be fine since this is IA.Private.", "author": "saintstack", "createdAt": "2020-10-05T18:44:23Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterRpcServices.java", "diffHunk": "@@ -1953,20 +1952,27 @@ public SetNormalizerRunningResponse setNormalizerRunning(RpcController controlle\n     rpcPreCheck(\"setNormalizerRunning\");\n \n     // Sets normalizer on/off flag in ZK.\n-    boolean prevValue = master.getRegionNormalizerTracker().isNormalizerOn();\n-    boolean newValue = request.getOn();\n-    try {\n-      master.getRegionNormalizerTracker().setNormalizerOn(newValue);\n-    } catch (KeeperException ke) {\n-      LOG.warn(\"Error flipping normalizer switch\", ke);\n-    }\n+    // TODO: this method is totally broken in terms of atomicity of actions and values read.\n+    //  1. The contract has this RPC returning the previous value. There isn't a ZKUtil method\n+    //     that lets us retrieve the previous value as part of setting a new value, so we simply\n+    //     perform a read before issuing the update. Thus we have a data race opportunity, between\n+    //     when the `prevValue` is read and whatever is actually overwritten.\n+    //  2. Down in `setNormalizerOn`, the call to `createAndWatch` inside of the catch clause can\n+    //     itself fail in the event that the znode already exists. Thus, another data race, between\n+    //     when the initial `setData` call is notified of the absence of the target znode and the\n+    //     subsequent `createAndWatch`, with another client creating said node.\n+    //  That said, there's supposed to be only one active master and thus there's supposed to be\n+    //  only one process with the authority to modify the value.\n+    final boolean prevValue = master.getRegionNormalizerManager().isNormalizerOn();\n+    final boolean newValue = request.getOn();\n+    master.getRegionNormalizerManager().setNormalizerOn(newValue);\n     LOG.info(\"{} set normalizerSwitch={}\", master.getClientIdAuditPrefix(), newValue);\n     return SetNormalizerRunningResponse.newBuilder().setPrevNormalizerValue(prevValue).build();\n   }\n \n   @Override\n   public IsNormalizerEnabledResponse isNormalizerEnabled(RpcController controller,", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkxMjc1NQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499912755", "bodyText": "Yes there are a number of changed signatures on methods and classes, all IA.Private.", "author": "ndimiduk", "createdAt": "2020-10-05T22:46:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc5OTAzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc5OTYxNw==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499799617", "bodyText": "What is this?  Is it substantial enough to be added to this Interface?", "author": "saintstack", "createdAt": "2020-10-05T18:45:28Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/MasterServices.java", "diffHunk": "@@ -354,6 +353,13 @@ long splitRegion(\n    */\n   boolean isInMaintenanceMode();\n \n+  /**\n+   * Checks master state before initiating action over region topology.\n+   * @param action the name of the action under consideration, for logging.\n+   * @return {@code true} when the caller should exit early, {@code false} otherwise.\n+   */\n+  boolean skipRegionManagementAction(final String action);", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgwMDg3Nw==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499800877", "bodyText": "merge? You mean split?\ngit blame doesn't explain why this is here?", "author": "saintstack", "createdAt": "2020-10-05T18:47:43Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/SplitTableRegionProcedure.java", "diffHunk": "@@ -570,8 +569,10 @@ private void preSplitRegion(final MasterProcedureEnv env)\n     try {\n       env.getMasterServices().getMasterQuotaManager().onRegionSplit(this.getParentRegion());\n     } catch (QuotaExceededException e) {\n-      env.getMasterServices().getRegionNormalizer().planSkipped(this.getParentRegion(),\n-          NormalizationPlan.PlanType.SPLIT);\n+      // TODO: why is this here? merge requests can be submitted by actors other than the normalizer", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkxMzA5Mg==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499913092", "bodyText": "Sorry, this is a copy-paste error in the comment.\nI added it because these callbacks seem to me to be only partially implemented.", "author": "ndimiduk", "createdAt": "2020-10-05T22:47:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgwMDg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgwMjA2Nw==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499802067", "bodyText": "method is createNormalizeService but it returns a 'manager'.", "author": "saintstack", "createdAt": "2020-10-05T18:49:57Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/RegionNormalizerFactory.java", "diffHunk": "@@ -32,13 +35,30 @@\n   private RegionNormalizerFactory() {\n   }\n \n+  public static RegionNormalizerManager createNormalizerService(", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMjQ2MQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499812461", "bodyText": "These ok?\nFindBugs\u2122 is licenced under the LGPL. Copyright \u00a9 2006 University of Maryland.", "author": "saintstack", "createdAt": "2020-10-05T19:09:03Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/RegionNormalizerManager.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import edu.umd.cs.findbugs.annotations.NonNull;", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkxMzM5OQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499913399", "bodyText": "It's on our class path... if it's LGPL, why is it there?", "author": "ndimiduk", "createdAt": "2020-10-05T22:48:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMjQ2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkyMDY1NA==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499920654", "bodyText": "These classes are on our classpath and come from the clean-room implementation of FindBugs, https://github.com/stephenc/findbugs-annotations, via the com.github.stephenc.findbugs:findbugs-annotations:1.3.9-1 dependency. We're okay here.", "author": "ndimiduk", "createdAt": "2020-10-05T23:12:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMjQ2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkzMjg2Mw==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499932863", "bodyText": "good", "author": "saintstack", "createdAt": "2020-10-05T23:53:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMjQ2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMjkxMA==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499812910", "bodyText": "Check it already started or that silly?", "author": "saintstack", "createdAt": "2020-10-05T19:09:55Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/RegionNormalizerManager.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import edu.umd.cs.findbugs.annotations.NonNull;\n+import edu.umd.cs.findbugs.annotations.Nullable;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.apache.zookeeper.KeeperException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * This class encapsulates the details of the {@link RegionNormalizer} subsystem.\n+ */\n+@InterfaceAudience.Private\n+public class RegionNormalizerManager {\n+  private static final Logger LOG = LoggerFactory.getLogger(RegionNormalizerManager.class);\n+\n+  private final RegionNormalizerTracker regionNormalizerTracker;\n+  private final RegionNormalizerChore regionNormalizerChore;\n+  private final RegionNormalizerWorkQueue<TableName> workQueue;\n+  private final RegionNormalizerWorker worker;\n+  private final ExecutorService pool;\n+\n+  public RegionNormalizerManager(\n+    @NonNull  final RegionNormalizerTracker regionNormalizerTracker,\n+    @Nullable final RegionNormalizerChore regionNormalizerChore,\n+    @Nullable final RegionNormalizerWorkQueue<TableName> workQueue,\n+    @Nullable final RegionNormalizerWorker worker\n+  ) {\n+    this.regionNormalizerTracker = regionNormalizerTracker;\n+    this.regionNormalizerChore = regionNormalizerChore;\n+    this.workQueue = workQueue;\n+    this.worker = worker;\n+    this.pool = Executors.newSingleThreadExecutor(new ThreadFactoryBuilder()\n+      .setDaemon(true)\n+      .setNameFormat(\"normalizer-worker-%d\")\n+      .setUncaughtExceptionHandler(\n+        (thread, throwable) ->\n+          LOG.error(\"Uncaught exception, worker thread likely terminated.\", throwable))\n+      .build());\n+  }\n+\n+  public void start() {\n+    regionNormalizerTracker.start();", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkzNzI2NQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499937265", "bodyText": "Now guarding this on a \"startStopLock\".", "author": "ndimiduk", "createdAt": "2020-10-06T00:08:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMjkxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMzA1OA==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499813058", "bodyText": "Ok if already stopped? idempotent?", "author": "saintstack", "createdAt": "2020-10-05T19:10:13Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/RegionNormalizerManager.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import edu.umd.cs.findbugs.annotations.NonNull;\n+import edu.umd.cs.findbugs.annotations.Nullable;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.apache.zookeeper.KeeperException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * This class encapsulates the details of the {@link RegionNormalizer} subsystem.\n+ */\n+@InterfaceAudience.Private\n+public class RegionNormalizerManager {\n+  private static final Logger LOG = LoggerFactory.getLogger(RegionNormalizerManager.class);\n+\n+  private final RegionNormalizerTracker regionNormalizerTracker;\n+  private final RegionNormalizerChore regionNormalizerChore;\n+  private final RegionNormalizerWorkQueue<TableName> workQueue;\n+  private final RegionNormalizerWorker worker;\n+  private final ExecutorService pool;\n+\n+  public RegionNormalizerManager(\n+    @NonNull  final RegionNormalizerTracker regionNormalizerTracker,\n+    @Nullable final RegionNormalizerChore regionNormalizerChore,\n+    @Nullable final RegionNormalizerWorkQueue<TableName> workQueue,\n+    @Nullable final RegionNormalizerWorker worker\n+  ) {\n+    this.regionNormalizerTracker = regionNormalizerTracker;\n+    this.regionNormalizerChore = regionNormalizerChore;\n+    this.workQueue = workQueue;\n+    this.worker = worker;\n+    this.pool = Executors.newSingleThreadExecutor(new ThreadFactoryBuilder()\n+      .setDaemon(true)\n+      .setNameFormat(\"normalizer-worker-%d\")\n+      .setUncaughtExceptionHandler(\n+        (thread, throwable) ->\n+          LOG.error(\"Uncaught exception, worker thread likely terminated.\", throwable))\n+      .build());\n+  }\n+\n+  public void start() {\n+    regionNormalizerTracker.start();\n+    if (worker != null) {\n+      // worker will be null when master is in maintenance mode.\n+      pool.submit(worker);\n+    }\n+  }\n+\n+  public void stop() {\n+    pool.shutdownNow(); // shutdownNow to interrupt the worker thread sitting on `take()`", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkzNzI4NQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499937285", "bodyText": "Now guarding this on a \"startStopLock\".", "author": "ndimiduk", "createdAt": "2020-10-06T00:08:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMzA1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxNDAwMg==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r499814002", "bodyText": "Got this far. Will be back to review more.", "author": "saintstack", "createdAt": "2020-10-05T19:12:01Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/RegionNormalizerManager.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.normalizer;\n+\n+import edu.umd.cs.findbugs.annotations.NonNull;\n+import edu.umd.cs.findbugs.annotations.Nullable;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.zookeeper.RegionNormalizerTracker;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.apache.zookeeper.KeeperException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.apache.hbase.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n+/**\n+ * This class encapsulates the details of the {@link RegionNormalizer} subsystem.\n+ */\n+@InterfaceAudience.Private\n+public class RegionNormalizerManager {\n+  private static final Logger LOG = LoggerFactory.getLogger(RegionNormalizerManager.class);\n+\n+  private final RegionNormalizerTracker regionNormalizerTracker;\n+  private final RegionNormalizerChore regionNormalizerChore;\n+  private final RegionNormalizerWorkQueue<TableName> workQueue;\n+  private final RegionNormalizerWorker worker;\n+  private final ExecutorService pool;\n+\n+  public RegionNormalizerManager(\n+    @NonNull  final RegionNormalizerTracker regionNormalizerTracker,\n+    @Nullable final RegionNormalizerChore regionNormalizerChore,\n+    @Nullable final RegionNormalizerWorkQueue<TableName> workQueue,\n+    @Nullable final RegionNormalizerWorker worker\n+  ) {\n+    this.regionNormalizerTracker = regionNormalizerTracker;\n+    this.regionNormalizerChore = regionNormalizerChore;\n+    this.workQueue = workQueue;\n+    this.worker = worker;\n+    this.pool = Executors.newSingleThreadExecutor(new ThreadFactoryBuilder()\n+      .setDaemon(true)\n+      .setNameFormat(\"normalizer-worker-%d\")\n+      .setUncaughtExceptionHandler(\n+        (thread, throwable) ->\n+          LOG.error(\"Uncaught exception, worker thread likely terminated.\", throwable))\n+      .build());\n+  }\n+\n+  public void start() {\n+    regionNormalizerTracker.start();\n+    if (worker != null) {\n+      // worker will be null when master is in maintenance mode.\n+      pool.submit(worker);\n+    }\n+  }\n+\n+  public void stop() {\n+    pool.shutdownNow(); // shutdownNow to interrupt the worker thread sitting on `take()`\n+    regionNormalizerTracker.stop();\n+  }\n+\n+  public RegionNormalizerChore getRegionNormalizerChore() {\n+    return regionNormalizerChore;\n+  }\n+\n+  /**\n+   * Return {@code true} if region normalizer is on, {@code false} otherwise\n+   */\n+  public boolean isNormalizerOn() {\n+    return regionNormalizerTracker.isNormalizerOn();\n+  }\n+\n+  /**\n+   * Set region normalizer on/off\n+   * @param normalizerOn whether normalizer should be on or off\n+   */\n+  public void setNormalizerOn(boolean normalizerOn) {\n+    try {\n+      regionNormalizerTracker.setNormalizerOn(normalizerOn);\n+    } catch (KeeperException e) {\n+      LOG.warn(\"Error flipping normalizer switch\", e);\n+    }\n+  }\n+\n+  /**\n+   * Call-back for the case where plan couldn't be executed due to constraint violation,\n+   * such as namespace quota.\n+   * @param type type of plan that was skipped.\n+   */\n+  public void planSkipped(NormalizationPlan.PlanType type) {\n+    // TODO: this appears to be used only for testing.\n+    if (worker != null) {\n+      worker.planSkipped(type);\n+    }\n+  }\n+\n+  /**\n+   * Retrieve a count of the number of times plans of type {@code type} were submitted but skipped.\n+   * @param type type of plan for which skipped count is to be returned\n+   */\n+  public long getSkippedCount(NormalizationPlan.PlanType type) {\n+    // TODO: this appears to be used only for testing.\n+    return worker == null ? 0 : worker.getSkippedCount(type);\n+  }\n+\n+  /**\n+   * Return the number of times a {@link SplitNormalizationPlan} has been submitted.\n+   */\n+  public long getSplitPlanCount() {\n+    return worker == null ? 0 : worker.getSplitPlanCount();\n+  }\n+\n+  /**\n+   * Return the number of times a {@link MergeNormalizationPlan} has been submitted.\n+   */\n+  public long getMergePlanCount() {\n+    return worker == null ? 0 : worker.getMergePlanCount();\n+  }\n+\n+  /**\n+   * Submit tables for normalization.\n+   * @param tables   a list of tables to submit.\n+   * @param priority {@code true} when these requested tables should skip to the front of the queue.\n+   * @return {@code true} when work was queued, {@code false} otherwise.\n+   */\n+  public boolean normalizeRegions(List<TableName> tables, boolean priority) {\n+    if (workQueue == null) {\n+      return false;\n+    }\n+    if (priority) {\n+      workQueue.putAllFirst(tables);\n+    } else {\n+      workQueue.putAll(tables);\n+    }\n+    return true;\n+  }\n+}", "originalCommit": "450c4d5e1865577f85af1a9751567cc121d55d00", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fa59808c63f092ee0a60d6e02625d6168a22f828", "url": "https://github.com/apache/hbase/commit/fa59808c63f092ee0a60d6e02625d6168a22f828", "message": "HBASE-24419 Normalizer merge plans should consider more than 2 regions when possible\n\nThe core change here is to the loop in\n`SimpleRegionNormalizer#computeMergeNormalizationPlans`. It's a nested\nloop that walks the table's region chain once, looking for contiguous\nsequences of regions that meet the criteria for merge. The outer loop\ntracks the starting point of the next sequence, the inner loop looks\nfor the end of that sequence. A single sequence becomes an instance of\n`MergeNormalizationPlan`.", "committedDate": "2020-10-09T16:56:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2MDMzMA==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r502560330", "bodyText": "Upgraded this datatype to a long because this is the type returned by the region size info we get from AM.", "author": "ndimiduk", "createdAt": "2020-10-09T16:59:58Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -124,10 +126,10 @@ private static Period parseMergeMinRegionAge(final Configuration conf) {\n     return Period.ofDays(settledValue);\n   }\n \n-  private static int parseMergeMinRegionSizeMb(final Configuration conf) {\n-    final int parsedValue =\n-      conf.getInt(MERGE_MIN_REGION_SIZE_MB_KEY, DEFAULT_MERGE_MIN_REGION_SIZE_MB);\n-    final int settledValue = Math.max(0, parsedValue);\n+  private static long parseMergeMinRegionSizeMb(final Configuration conf) {", "originalCommit": "fa59808c63f092ee0a60d6e02625d6168a22f828", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2MDY5OQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r502560699", "bodyText": "The meat of this patch is this new nested loop.", "author": "ndimiduk", "createdAt": "2020-10-09T17:00:38Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -315,35 +317,61 @@ private boolean skipForMerge(final RegionStates regionStates, final RegionInfo r\n    * towards target average or target region count.\n    */\n   private List<NormalizationPlan> computeMergeNormalizationPlans(final NormalizeContext ctx) {\n-    if (ctx.getTableRegions().size() < minRegionCount) {\n+    if (isEmpty(ctx.getTableRegions()) || ctx.getTableRegions().size() < minRegionCount) {\n       LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\"\n         + \" is {}, not computing merge plans.\", ctx.getTableName(), ctx.getTableRegions().size(),\n         minRegionCount);\n       return Collections.emptyList();\n     }\n \n-    final double avgRegionSizeMb = ctx.getAverageRegionSizeMb();\n+    final long avgRegionSizeMb = (long) ctx.getAverageRegionSizeMb();\n+    if (avgRegionSizeMb < mergeMinRegionSizeMb) {\n+      return Collections.emptyList();\n+    }\n     LOG.debug(\"Computing normalization plan for table {}. average region size: {}, number of\"\n       + \" regions: {}.\", ctx.getTableName(), avgRegionSizeMb, ctx.getTableRegions().size());\n \n-    final List<NormalizationPlan> plans = new ArrayList<>();\n-    for (int candidateIdx = 0; candidateIdx < ctx.getTableRegions().size() - 1; candidateIdx++) {\n-      final RegionInfo current = ctx.getTableRegions().get(candidateIdx);\n-      final RegionInfo next = ctx.getTableRegions().get(candidateIdx + 1);\n-      if (skipForMerge(ctx.getRegionStates(), current)\n-        || skipForMerge(ctx.getRegionStates(), next)) {\n-        continue;\n+    // this nested loop walks the table's region chain once, looking for contiguous sequences of\n+    // regions that meet the criteria for merge. The outer loop tracks the starting point of the\n+    // next sequence, the inner loop looks for the end of that sequence. A single sequence becomes\n+    // an instance of MergeNormalizationPlan.\n+\n+    final List<NormalizationPlan> plans = new LinkedList<>();\n+    final List<NormalizationTarget> rangeMembers = new LinkedList<>();\n+    long sumRangeMembersSizeMb;\n+    int current = 0;\n+    for (int rangeStart = 0;", "originalCommit": "fa59808c63f092ee0a60d6e02625d6168a22f828", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU2MjA2Ng==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r502562066", "bodyText": "I realized all my waiting in tests (1) use conditions that are shipped in the hamcrest library (2) have failure messages that look like failed Matcher explanations.", "author": "ndimiduk", "createdAt": "2020-10-09T17:03:16Z", "path": "hbase-common/src/test/java/org/apache/hadoop/hbase/MatcherPredicate.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase;\n+\n+import java.util.function.Supplier;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.hamcrest.Description;\n+import org.hamcrest.Matcher;\n+import org.hamcrest.StringDescription;\n+\n+/**\n+ * An implementation of {@link Waiter.ExplainingPredicate} that uses Hamcrest {@link Matcher} for both", "originalCommit": "fa59808c63f092ee0a60d6e02625d6168a22f828", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1025d7ef7eae05d0cb51403bb677097c1da18036", "url": "https://github.com/apache/hbase/commit/1025d7ef7eae05d0cb51403bb677097c1da18036", "message": "HBASE-24419 Normalizer merge plans should consider more than 2 regions when possible\n\nThe core change here is to the loop in\n`SimpleRegionNormalizer#computeMergeNormalizationPlans`. It's a nested\nloop that walks the table's region chain once, looking for contiguous\nsequences of regions that meet the criteria for merge. The outer loop\ntracks the starting point of the next sequence, the inner loop looks\nfor the end of that sequence. A single sequence becomes an instance of\n`MergeNormalizationPlan`.", "committedDate": "2020-10-09T17:13:56Z", "type": "forcePushed"}, {"oid": "b936da6332b69f0f629811b579635bf85dbbe624", "url": "https://github.com/apache/hbase/commit/b936da6332b69f0f629811b579635bf85dbbe624", "message": "HBASE-24419 Normalizer merge plans should consider more than 2 regions when possible\n\nThe core change here is to the loop in\n`SimpleRegionNormalizer#computeMergeNormalizationPlans`. It's a nested\nloop that walks the table's region chain once, looking for contiguous\nsequences of regions that meet the criteria for merge. The outer loop\ntracks the starting point of the next sequence, the inner loop looks\nfor the end of that sequence. A single sequence becomes an instance of\n`MergeNormalizationPlan`.", "committedDate": "2020-10-12T23:22:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY0NDQwMA==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r509644400", "bodyText": "In this case, shall we check if there is already something in rangeMembers and add it to the plan?", "author": "huaxiangsun", "createdAt": "2020-10-21T20:08:38Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.java", "diffHunk": "@@ -315,35 +316,60 @@ private boolean skipForMerge(final RegionStates regionStates, final RegionInfo r\n    * towards target average or target region count.\n    */\n   private List<NormalizationPlan> computeMergeNormalizationPlans(final NormalizeContext ctx) {\n-    if (ctx.getTableRegions().size() < minRegionCount) {\n+    if (isEmpty(ctx.getTableRegions()) || ctx.getTableRegions().size() < minRegionCount) {\n       LOG.debug(\"Table {} has {} regions, required min number of regions for normalizer to run\"\n         + \" is {}, not computing merge plans.\", ctx.getTableName(), ctx.getTableRegions().size(),\n         minRegionCount);\n       return Collections.emptyList();\n     }\n \n-    final double avgRegionSizeMb = ctx.getAverageRegionSizeMb();\n+    final long avgRegionSizeMb = (long) ctx.getAverageRegionSizeMb();\n+    if (avgRegionSizeMb < mergeMinRegionSizeMb) {\n+      return Collections.emptyList();\n+    }\n     LOG.debug(\"Computing normalization plan for table {}. average region size: {}, number of\"\n       + \" regions: {}.\", ctx.getTableName(), avgRegionSizeMb, ctx.getTableRegions().size());\n \n-    final List<NormalizationPlan> plans = new ArrayList<>();\n-    for (int candidateIdx = 0; candidateIdx < ctx.getTableRegions().size() - 1; candidateIdx++) {\n-      final RegionInfo current = ctx.getTableRegions().get(candidateIdx);\n-      final RegionInfo next = ctx.getTableRegions().get(candidateIdx + 1);\n-      if (skipForMerge(ctx.getRegionStates(), current)\n-        || skipForMerge(ctx.getRegionStates(), next)) {\n-        continue;\n+    // this nested loop walks the table's region chain once, looking for contiguous sequences of\n+    // regions that meet the criteria for merge. The outer loop tracks the starting point of the\n+    // next sequence, the inner loop looks for the end of that sequence. A single sequence becomes\n+    // an instance of MergeNormalizationPlan.\n+\n+    final List<NormalizationPlan> plans = new LinkedList<>();\n+    final List<NormalizationTarget> rangeMembers = new LinkedList<>();\n+    long sumRangeMembersSizeMb;\n+    int current = 0;\n+    for (int rangeStart = 0;\n+         rangeStart < ctx.getTableRegions().size() - 1 && current < ctx.getTableRegions().size();) {\n+      // walk the region chain looking for contiguous sequences of regions that can be merged.\n+      rangeMembers.clear();\n+      sumRangeMembersSizeMb = 0;\n+      for (current = rangeStart; current < ctx.getTableRegions().size(); current++) {\n+        final RegionInfo regionInfo = ctx.getTableRegions().get(current);\n+        final long regionSizeMb = getRegionSizeMB(regionInfo);\n+        if (skipForMerge(ctx.getRegionStates(), regionInfo)) {\n+          // this region cannot participate in a range. resume the outer loop.\n+          rangeStart = Math.max(current, rangeStart + 1);", "originalCommit": "b936da6332b69f0f629811b579635bf85dbbe624", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY0ODA5MQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r509648091", "bodyText": "Meant for the case that  region 1, 2, 3, 4, 5\nLet say 1 and 2 are in rangeMembers, but 3 needs to be skipped. In this case, 1,2 needs to be added to plans.", "author": "huaxiangsun", "createdAt": "2020-10-21T20:11:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY0NDQwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY0OTk5MA==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r509649990", "bodyText": "Oh, nvm, it is taken care of, after the break, there is a check to see if there are enough members which deserves a plan.", "author": "huaxiangsun", "createdAt": "2020-10-21T20:12:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY0NDQwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY5MjExMQ==", "url": "https://github.com/apache/hbase/pull/2490#discussion_r509692111", "bodyText": "This line of questions convinces me you really read the code. Thank you for the thoughtful review!", "author": "ndimiduk", "createdAt": "2020-10-21T20:59:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTY0NDQwMA=="}], "type": "inlineReview"}, {"oid": "9498ea6c8f4d5ce6bdb9eac429859b015faba9d1", "url": "https://github.com/apache/hbase/commit/9498ea6c8f4d5ce6bdb9eac429859b015faba9d1", "message": "HBASE-24419 Normalizer merge plans should consider more than 2 regions when possible\n\nThe core change here is to the loop in\n`SimpleRegionNormalizer#computeMergeNormalizationPlans`. It's a nested\nloop that walks the table's region chain once, looking for contiguous\nsequences of regions that meet the criteria for merge. The outer loop\ntracks the starting point of the next sequence, the inner loop looks\nfor the end of that sequence. A single sequence becomes an instance of\n`MergeNormalizationPlan`.\n\nSigned-off-by: Huaxiang Sun <huaxiangsun@apache.org>", "committedDate": "2020-10-21T21:01:51Z", "type": "forcePushed"}, {"oid": "962df6e1db14c1500b67017286e80ee624bea405", "url": "https://github.com/apache/hbase/commit/962df6e1db14c1500b67017286e80ee624bea405", "message": "HBASE-24419 Normalizer merge plans should consider more than 2 regions when possible\n\nThe core change here is to the loop in\n`SimpleRegionNormalizer#computeMergeNormalizationPlans`. It's a nested\nloop that walks the table's region chain once, looking for contiguous\nsequences of regions that meet the criteria for merge. The outer loop\ntracks the starting point of the next sequence, the inner loop looks\nfor the end of that sequence. A single sequence becomes an instance of\n`MergeNormalizationPlan`.\n\nSigned-off-by: Huaxiang Sun <huaxiangsun@apache.org>", "committedDate": "2020-10-29T16:52:04Z", "type": "commit"}, {"oid": "962df6e1db14c1500b67017286e80ee624bea405", "url": "https://github.com/apache/hbase/commit/962df6e1db14c1500b67017286e80ee624bea405", "message": "HBASE-24419 Normalizer merge plans should consider more than 2 regions when possible\n\nThe core change here is to the loop in\n`SimpleRegionNormalizer#computeMergeNormalizationPlans`. It's a nested\nloop that walks the table's region chain once, looking for contiguous\nsequences of regions that meet the criteria for merge. The outer loop\ntracks the starting point of the next sequence, the inner loop looks\nfor the end of that sequence. A single sequence becomes an instance of\n`MergeNormalizationPlan`.\n\nSigned-off-by: Huaxiang Sun <huaxiangsun@apache.org>", "committedDate": "2020-10-29T16:52:04Z", "type": "forcePushed"}]}