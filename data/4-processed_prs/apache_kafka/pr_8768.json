{"pr_number": 8768, "pr_title": "KAFKA-10023: Enforce broker-wide and per-listener connection creation\u2026", "pr_createdAt": "2020-06-01T00:02:20Z", "pr_url": "https://github.com/apache/kafka/pull/8768", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY3NzgyOQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r433677829", "bodyText": "I am not convinced by this. The main issue being that other reporters will report the metric. If we really want to not report a metric, I think that we need a solution which works for all reporters. Could you perhaps elaborate more on the need here?\nI can think of the following alternatives:\n\nadd a flag to the sensor to indicate if it must be reported or not.\ndon't rely on metrics to create/store the sensor but have a local reference.", "author": "dajac", "createdAt": "2020-06-02T07:36:05Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/JmxReporter.java", "diffHunk": "@@ -161,6 +162,9 @@ private KafkaMbean removeAttribute(KafkaMetric metric, String mBeanName) {\n     private String addAttribute(KafkaMetric metric) {\n         try {\n             MetricName metricName = metric.metricName();\n+            if (metricName.tags().containsKey(DO_NOT_REPORT_TAG)) {\n+                return null;\n+            }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc4NjE2Ng==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r439786166", "bodyText": "You are right, I replaced this with your first alternative.", "author": "apovzner", "createdAt": "2020-06-14T02:44:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY3NzgyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY5MjgyOQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r433692829", "bodyText": "nit: extra space after the ..", "author": "dajac", "createdAt": "2020-06-02T08:03:24Z", "path": "core/src/main/scala/kafka/server/KafkaConfig.scala", "diffHunk": "@@ -689,6 +691,11 @@ object KafkaConfig {\n     \"should be configured based on broker capacity while listener limits should be configured based on application requirements. \" +\n     \"New connections are blocked if either the listener or broker limit is reached. Connections on the inter-broker listener are \" +\n     \"permitted even if broker-wide limit is reached. The least recently used connection on another listener will be closed in this case.\"\n+  val MaxConnectionCreationRateDoc = \"The maximum connection creation rate we allow in the broker at any time. Listener-level limits \" +\n+    s\"may also be configured by prefixing the config name with the listener prefix, for example, <code>listener.name.internal.$MaxConnectionCreationRateProp</code>.\" +\n+    \"Broker-wide connection rate limit should be configured based on broker capacity while listener limits should be configured based on \" +\n+    \"application requirements. New connections will be throttled if either the listener or the broker limit is reached, with the exception \" +\n+    \" of inter-broker listener. Connections on the inter-broker listener will be throttled only when the listener-level rate limit is reached. \"", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY5NTg2OA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r433695868", "bodyText": "A thread waiting here will be notified when a connection is closed (when dec is called). As connections in AK are long lived, couldn't we end up in a case where a connection is throttled for a longer period than the computed trottleTimeMs if no connection is closed in between?", "author": "dajac", "createdAt": "2020-06-02T08:08:56Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1256,11 +1272,17 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def waitForConnectionSlot(listenerName: ListenerName,\n                                     acceptorBlockedPercentMeter: com.yammer.metrics.core.Meter): Unit = {\n     counts.synchronized {\n-      if (!connectionSlotAvailable(listenerName)) {\n+      val startTimeMs = time.milliseconds()\n+      val throttleTimeMs = math.max(recordConnectionAndGetThrottleTimeMs(listenerName, startTimeMs), 0)\n+\n+      if (throttleTimeMs > 0 || !connectionSlotAvailable(listenerName)) {\n         val startNs = time.nanoseconds\n+        val endThrottleTimeMs = startTimeMs + throttleTimeMs\n+        var remainingThrottleTimeMs = throttleTimeMs\n         do {\n-          counts.wait()\n-        } while (!connectionSlotAvailable(listenerName))\n+          counts.wait(remainingThrottleTimeMs)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE0Mzg1MA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r439143850", "bodyText": "This is exactly the behavior proposed in KIP -- if we reach any limit (number of connections or connection rate), we need to wait. So, if there is no space for a new connection, and the delay due to rate limit has passed, we would have to wait for a connection slot. However, remember that if we are waiting on an inter-broker connection slot, the broker finds and closes a connection of another listener to accommodate inter-broker connection. See KIP-402.", "author": "apovzner", "createdAt": "2020-06-12T00:23:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY5NTg2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAyOTQxMw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440029413", "bodyText": "Thanks for the clarification. I am sorry but I misread the code the first time.", "author": "dajac", "createdAt": "2020-06-15T08:58:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY5NTg2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY5NjM3NA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r433696374", "bodyText": "nit: This variable is not really needed.", "author": "dajac", "createdAt": "2020-06-02T08:09:50Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1287,15 +1309,97 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      val throttleTimeMs = math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzcwMDgxOQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r433700819", "bodyText": "nit: () can be removed after value.", "author": "dajac", "createdAt": "2020-06-02T08:17:24Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1306,18 +1410,26 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n       val value = maxConnections(configs)\n       if (value <= 0)\n         throw new ConfigException(\"Invalid max.connections $listenerMax\")\n+\n+      val rate = maxConnectionCreationRate(configs)\n+      if (rate <= 0)\n+        throw new ConfigException(s\"Invalid ${KafkaConfig.MaxConnectionCreationRateProp} $rate\")\n     }\n \n     override def reconfigure(configs: util.Map[String, _]): Unit = {\n       lock.synchronized {\n         _maxConnections = maxConnections(configs)\n+        updateConnectionRateQuota(maxConnectionCreationRate(configs), Some(listener.value()))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzcwMTAxOA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r433701018", "bodyText": "nit: I would put an empty line before declaring the method.", "author": "dajac", "createdAt": "2020-06-02T08:17:46Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1306,18 +1410,26 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n       val value = maxConnections(configs)\n       if (value <= 0)\n         throw new ConfigException(\"Invalid max.connections $listenerMax\")\n+\n+      val rate = maxConnectionCreationRate(configs)\n+      if (rate <= 0)\n+        throw new ConfigException(s\"Invalid ${KafkaConfig.MaxConnectionCreationRateProp} $rate\")\n     }\n \n     override def reconfigure(configs: util.Map[String, _]): Unit = {\n       lock.synchronized {\n         _maxConnections = maxConnections(configs)\n+        updateConnectionRateQuota(maxConnectionCreationRate(configs), Some(listener.value()))\n         lock.notifyAll()\n       }\n     }\n \n     private def maxConnections(configs: util.Map[String, _]): Int = {\n       Option(configs.get(KafkaConfig.MaxConnectionsProp)).map(_.toString.toInt).getOrElse(Int.MaxValue)\n     }\n+    private def maxConnectionCreationRate(configs: util.Map[String, _]): Int = {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzcwNTA3Nw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r433705077", "bodyText": "Wouldn't it make sense to expose the metrics? I think that they could be useful to know if connections are throttled at the broker or at the listener level, no? Moreover, the number of metrics is small so it should not hurt.", "author": "dajac", "createdAt": "2020-06-02T08:24:47Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1287,15 +1309,97 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      val throttleTimeMs = math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+      throttleTimeMs\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {\n+    try {\n+      sensor.record(1.0, timeMs)\n+      0\n+    } catch {\n+      case e: QuotaViolationException =>\n+        val throttleTimeMs = QuotaUtils.boundedThrottleTime(\n+          e.value, e.bound, QuotaUtils.rateMetricWindowSize(e.metric, timeMs), maxThrottleTimeMs).toInt\n+        debug(s\"Quota violated for sensor (${sensor.name}). Delay time: $throttleTimeMs ms\")\n+        throttleTimeMs\n+    }\n+  }\n+\n+  /**\n+   * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n+   * listener or broker-wide, if listener is not provided.\n+   * @param quotaLimit connection creation rate quota\n+   * @param listenerOpt listener name if sensor is for a listener\n+   */\n+  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val sensor = metrics.sensor(s\"ConnectionCreationRate-$quotaEntity\", rateQuotaMetricConfig(quotaLimit))\n+    sensor.add(connectionRateMetricName(listenerOpt), new Rate)\n+    info(s\"Created ConnectionCreationRate-$quotaEntity sensor, quotaLimit=$quotaLimit\")\n+    sensor\n+  }\n+\n+  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n+    val metric = metrics.metric(connectionRateMetricName((listenerOpt)))\n+    metric.config(rateQuotaMetricConfig(quotaLimit))\n+    info(s\"Updated ${listenerOpt.getOrElse(\"broker\")} max connection creation rate to $quotaLimit\")\n+  }\n+\n+  private def connectionRateMetricName(listenerOpt: Option[String]): MetricName = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    metrics.metricName(\n+      s\"connection-creation-rate-$quotaEntity\",\n+      \"connection-quota-no-jmx\",\n+      s\"Tracking $quotaEntity connection creation rate\",\n+      rateQuotaMetricTags(listenerOpt))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc4NjM3OQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r439786379", "bodyText": "We already have a yammer Meter that reports connection creation rate, also tagged with listener and processor. This same meter tracks both connection creation rate and total. Here is connetion creation rate metric:\nkafka.server:type=socket-server-metrics,listener={listener_name},networkProcessor={#},name=connection-creation-rate\nI had to add a Rate metric here because it both tracks rate and quota, and allows to calculate throttle time the same way we do with client (request & bandwidth) quotas.", "author": "apovzner", "createdAt": "2020-06-14T02:49:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzcwNTA3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA0Njg4NQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440046885", "bodyText": "Ack. I did not know this.", "author": "dajac", "createdAt": "2020-06-15T09:28:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzcwNTA3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzcxNTI5Nw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r433715297", "bodyText": "nit: Could we define a val for 7 and reuse it bellow as well?", "author": "dajac", "createdAt": "2020-06-02T08:41:51Z", "path": "core/src/test/scala/integration/kafka/network/DynamicConnectionQuotaTest.scala", "diffHunk": "@@ -163,13 +167,65 @@ class DynamicConnectionQuotaTest extends BaseRequestTest {\n     TestUtils.waitUntilTrue(() => initialConnectionCount == connectionCount, \"Connections not closed\")\n   }\n \n+  @Test\n+  def testDynamicListenerConnectionCreationRateQuota(): Unit = {\n+    // Create another listener. PLAINTEXT is an inter-broker listener\n+    // keep default limits\n+    val newListenerNames = Seq(\"PLAINTEXT\", \"EXTERNAL\")\n+    val newListeners = \"PLAINTEXT://localhost:0,EXTERNAL://localhost:0\"\n+    val props = new Properties\n+    props.put(KafkaConfig.ListenersProp, newListeners)\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT\")\n+    reconfigureServers(props, perBrokerConfig = true, (KafkaConfig.ListenersProp, newListeners))\n+    waitForListener(\"EXTERNAL\")\n+\n+    // new broker-wide connection rate limit\n+    val connRateLimit = 18\n+\n+    // before setting connection rate to 10, verify we can do at least double that by default (no limit)\n+    verifyConnectionRate(2 * connRateLimit, Int.MaxValue, \"PLAINTEXT\")\n+\n+    // Reduce total broker connection rate limit to 10 at the cluster level and verify the limit is enforced\n+    props.clear()  // so that we do not pass security protocol map which cannot be set at the cluster level\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, connRateLimit.toString)\n+    reconfigureServers(props, perBrokerConfig = false, (KafkaConfig.MaxConnectionCreationRateProp, connRateLimit.toString))\n+    verifyConnectionRate(10, connRateLimit, \"PLAINTEXT\")\n+\n+    // Set 7 conn/sec rate limit for each listener and verify it gets enforced\n+    val plaintextListenerProp = s\"${listener.configPrefix}${KafkaConfig.MaxConnectionCreationRateProp}\"\n+    props.put(s\"listener.name.external.${KafkaConfig.MaxConnectionCreationRateProp}\", \"7\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAyODQyOQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440028429", "bodyText": "Thinking a bit more about this, did you consider adding the flag to MetricConfig? It may be a bit simpler and cleaner as it avoids having to add the flag to all the methods. What do you think?", "author": "dajac", "createdAt": "2020-06-15T08:57:24Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/Metrics.java", "diffHunk": "@@ -572,16 +572,18 @@ public synchronized void removeReporter(MetricsReporter reporter) {\n         }\n     }\n \n-    synchronized void registerMetric(KafkaMetric metric) {\n+    synchronized void registerMetric(KafkaMetric metric, boolean report) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMDY1MA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r454010650", "bodyText": "That's a good idea I haven't thought about. I tried that and it does look better. Will update PR with this approach.", "author": "apovzner", "createdAt": "2020-07-13T23:40:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAyODQyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAzMjk0Mw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440032943", "bodyText": "nit: () can be omitted here.", "author": "dajac", "createdAt": "2020-06-15T09:04:53Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1258,11 +1274,17 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def waitForConnectionSlot(listenerName: ListenerName,\n                                     acceptorBlockedPercentMeter: com.yammer.metrics.core.Meter): Unit = {\n     counts.synchronized {\n-      if (!connectionSlotAvailable(listenerName)) {\n+      val startTimeMs = time.milliseconds()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAzNjg2MA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440036860", "bodyText": "It is a bit confusing to have startTimeMs and startNs defined few lines apart. Is it worth renaming startTimeMs to startThrottleTimeMs to clearly state that this is used as part of the throttle time computing. It would also be consistent with endThrottleTimeMs.", "author": "dajac", "createdAt": "2020-06-15T09:11:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDAzMjk0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA0NjUxNg==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440046516", "bodyText": "What about returning Collections.emptyMap when listenerOpt is not defined and using Collections.singletonMap when it is?", "author": "dajac", "createdAt": "2020-06-15T09:27:49Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1289,15 +1311,95 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {\n+    try {\n+      sensor.record(1.0, timeMs)\n+      0\n+    } catch {\n+      case e: QuotaViolationException =>\n+        val throttleTimeMs = QuotaUtils.boundedThrottleTime(\n+          e.value, e.bound, QuotaUtils.rateMetricWindowSize(e.metric, timeMs), maxThrottleTimeMs).toInt\n+        debug(s\"Quota violated for sensor (${sensor.name}). Delay time: $throttleTimeMs ms\")\n+        throttleTimeMs\n+    }\n+  }\n+\n+  /**\n+   * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n+   * listener or broker-wide, if listener is not provided.\n+   * @param quotaLimit connection creation rate quota\n+   * @param listenerOpt listener name if sensor is for a listener\n+   */\n+  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val sensor = metrics.sensor(s\"ConnectionCreationRate-$quotaEntity\", rateQuotaMetricConfig(quotaLimit))\n+    sensor.add(connectionRateMetricName(listenerOpt), new Rate, null, false)\n+    info(s\"Created ConnectionCreationRate-$quotaEntity sensor, quotaLimit=$quotaLimit\")\n+    sensor\n+  }\n+\n+  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n+    val metric = metrics.metric(connectionRateMetricName((listenerOpt)))\n+    metric.config(rateQuotaMetricConfig(quotaLimit))\n+    info(s\"Updated ${listenerOpt.getOrElse(\"broker\")} max connection creation rate to $quotaLimit\")\n+  }\n+\n+  private def connectionRateMetricName(listenerOpt: Option[String]): MetricName = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    metrics.metricName(\n+      s\"connection-creation-rate-$quotaEntity\",\n+      \"connection-quota-no-jmx\",\n+      s\"Tracking $quotaEntity connection creation rate\",\n+      rateQuotaMetricTags(listenerOpt))\n+  }\n+\n+  private def rateQuotaMetricConfig(quotaLimit: Int): MetricConfig = {\n+    new MetricConfig()\n+      .timeWindow(config.quotaWindowSizeSeconds.toLong, TimeUnit.SECONDS)\n+      .samples(config.numQuotaSamples)\n+      .quota(new Quota(quotaLimit, true))\n+  }\n+\n+  private def rateQuotaMetricTags(listenerOpt: Option[String]): util.Map[String, String] = {\n+    val tags = new util.LinkedHashMap[String, String]\n+    listenerOpt.foreach(listener => tags.put(\"listener\", listener))\n+    tags", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjUwMjgxMQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r452502811", "bodyText": "I realized that I don't need tags here anymore, since the name of the metric contains the name of the listener, so the metrics are already distinct per listener (and broker-wide). I removed that method altogether.", "author": "apovzner", "createdAt": "2020-07-09T21:33:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA0NjUxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA0Njc2MQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440046761", "bodyText": "nit: I would rename this one now.", "author": "dajac", "createdAt": "2020-06-15T09:28:16Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1289,15 +1311,95 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {\n+    try {\n+      sensor.record(1.0, timeMs)\n+      0\n+    } catch {\n+      case e: QuotaViolationException =>\n+        val throttleTimeMs = QuotaUtils.boundedThrottleTime(\n+          e.value, e.bound, QuotaUtils.rateMetricWindowSize(e.metric, timeMs), maxThrottleTimeMs).toInt\n+        debug(s\"Quota violated for sensor (${sensor.name}). Delay time: $throttleTimeMs ms\")\n+        throttleTimeMs\n+    }\n+  }\n+\n+  /**\n+   * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n+   * listener or broker-wide, if listener is not provided.\n+   * @param quotaLimit connection creation rate quota\n+   * @param listenerOpt listener name if sensor is for a listener\n+   */\n+  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val sensor = metrics.sensor(s\"ConnectionCreationRate-$quotaEntity\", rateQuotaMetricConfig(quotaLimit))\n+    sensor.add(connectionRateMetricName(listenerOpt), new Rate, null, false)\n+    info(s\"Created ConnectionCreationRate-$quotaEntity sensor, quotaLimit=$quotaLimit\")\n+    sensor\n+  }\n+\n+  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n+    val metric = metrics.metric(connectionRateMetricName((listenerOpt)))\n+    metric.config(rateQuotaMetricConfig(quotaLimit))\n+    info(s\"Updated ${listenerOpt.getOrElse(\"broker\")} max connection creation rate to $quotaLimit\")\n+  }\n+\n+  private def connectionRateMetricName(listenerOpt: Option[String]): MetricName = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    metrics.metricName(\n+      s\"connection-creation-rate-$quotaEntity\",\n+      \"connection-quota-no-jmx\",", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA1MTU5Ng==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440051596", "bodyText": "nit: Are the parenthesis around listenerOpt really necessary?", "author": "dajac", "createdAt": "2020-06-15T09:36:47Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1289,15 +1311,95 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {\n+    try {\n+      sensor.record(1.0, timeMs)\n+      0\n+    } catch {\n+      case e: QuotaViolationException =>\n+        val throttleTimeMs = QuotaUtils.boundedThrottleTime(\n+          e.value, e.bound, QuotaUtils.rateMetricWindowSize(e.metric, timeMs), maxThrottleTimeMs).toInt\n+        debug(s\"Quota violated for sensor (${sensor.name}). Delay time: $throttleTimeMs ms\")\n+        throttleTimeMs\n+    }\n+  }\n+\n+  /**\n+   * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n+   * listener or broker-wide, if listener is not provided.\n+   * @param quotaLimit connection creation rate quota\n+   * @param listenerOpt listener name if sensor is for a listener\n+   */\n+  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val sensor = metrics.sensor(s\"ConnectionCreationRate-$quotaEntity\", rateQuotaMetricConfig(quotaLimit))\n+    sensor.add(connectionRateMetricName(listenerOpt), new Rate, null, false)\n+    info(s\"Created ConnectionCreationRate-$quotaEntity sensor, quotaLimit=$quotaLimit\")\n+    sensor\n+  }\n+\n+  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n+    val metric = metrics.metric(connectionRateMetricName((listenerOpt)))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA1MjUwNA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440052504", "bodyText": "nit: As the quotaEntity is also computed by the caller methods, would it make sense to pass it as an argument to connectionRateMetricName?", "author": "dajac", "createdAt": "2020-06-15T09:38:22Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1289,15 +1311,95 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {\n+    try {\n+      sensor.record(1.0, timeMs)\n+      0\n+    } catch {\n+      case e: QuotaViolationException =>\n+        val throttleTimeMs = QuotaUtils.boundedThrottleTime(\n+          e.value, e.bound, QuotaUtils.rateMetricWindowSize(e.metric, timeMs), maxThrottleTimeMs).toInt\n+        debug(s\"Quota violated for sensor (${sensor.name}). Delay time: $throttleTimeMs ms\")\n+        throttleTimeMs\n+    }\n+  }\n+\n+  /**\n+   * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n+   * listener or broker-wide, if listener is not provided.\n+   * @param quotaLimit connection creation rate quota\n+   * @param listenerOpt listener name if sensor is for a listener\n+   */\n+  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val sensor = metrics.sensor(s\"ConnectionCreationRate-$quotaEntity\", rateQuotaMetricConfig(quotaLimit))\n+    sensor.add(connectionRateMetricName(listenerOpt), new Rate, null, false)\n+    info(s\"Created ConnectionCreationRate-$quotaEntity sensor, quotaLimit=$quotaLimit\")\n+    sensor\n+  }\n+\n+  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n+    val metric = metrics.metric(connectionRateMetricName((listenerOpt)))\n+    metric.config(rateQuotaMetricConfig(quotaLimit))\n+    info(s\"Updated ${listenerOpt.getOrElse(\"broker\")} max connection creation rate to $quotaLimit\")\n+  }\n+\n+  private def connectionRateMetricName(listenerOpt: Option[String]): MetricName = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA1NTk5Mg==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440055992", "bodyText": "Not related to your PR but it seems that listenerMax is never defined. I think that value should be used instead here. Could you fix this? Could you also use MaxConnectionsProp instead of max.connections as you did for the other already?", "author": "dajac", "createdAt": "2020-06-15T09:44:10Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1308,18 +1410,27 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n       val value = maxConnections(configs)\n       if (value <= 0)\n         throw new ConfigException(\"Invalid max.connections $listenerMax\")", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjUwNzk5MA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r452507990", "bodyText": "yes, good catch. Fixed.", "author": "apovzner", "createdAt": "2020-07-09T21:45:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDA1NTk5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDExNjE4Mw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440116183", "bodyText": "to 18?", "author": "dajac", "createdAt": "2020-06-15T11:42:32Z", "path": "core/src/test/scala/integration/kafka/network/DynamicConnectionQuotaTest.scala", "diffHunk": "@@ -163,13 +167,66 @@ class DynamicConnectionQuotaTest extends BaseRequestTest {\n     TestUtils.waitUntilTrue(() => initialConnectionCount == connectionCount, \"Connections not closed\")\n   }\n \n+  @Test\n+  def testDynamicListenerConnectionCreationRateQuota(): Unit = {\n+    // Create another listener. PLAINTEXT is an inter-broker listener\n+    // keep default limits\n+    val newListenerNames = Seq(\"PLAINTEXT\", \"EXTERNAL\")\n+    val newListeners = \"PLAINTEXT://localhost:0,EXTERNAL://localhost:0\"\n+    val props = new Properties\n+    props.put(KafkaConfig.ListenersProp, newListeners)\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT\")\n+    reconfigureServers(props, perBrokerConfig = true, (KafkaConfig.ListenersProp, newListeners))\n+    waitForListener(\"EXTERNAL\")\n+\n+    // new broker-wide connection rate limit\n+    val connRateLimit = 18\n+\n+    // before setting connection rate to 10, verify we can do at least double that by default (no limit)\n+    verifyConnectionRate(2 * connRateLimit, Int.MaxValue, \"PLAINTEXT\")\n+\n+    // Reduce total broker connection rate limit to 10 at the cluster level and verify the limit is enforced", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDEyOTgyOQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440129829", "bodyText": "Can't we use assertTrue here to simplify?", "author": "dajac", "createdAt": "2020-06-15T12:09:34Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -329,15 +613,46 @@ class ConnectionQuotasTest {\n   }\n \n   // this method must be called on a separate thread, because connectionQuotas.inc() may block\n+  private def acceptConnectionsAndVerifyRate(connectionQuotas: ConnectionQuotas,\n+                                             listenerDesc: ListenerDesc,\n+                                             numConnections: Long,\n+                                             timeIntervalMs: Long,\n+                                             expectedRate: Int,\n+                                             epsilon: Int) : Unit = {\n+    val startTimeMs = System.currentTimeMillis\n+    acceptConnections(connectionQuotas, listenerDesc.listenerName, listenerDesc.defaultIp, numConnections, timeIntervalMs)\n+    val elapsedSeconds = TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis - startTimeMs)\n+    val actualRate = (numConnections.toDouble / elapsedSeconds).toInt\n+    if (actualRate - epsilon > expectedRate || actualRate + epsilon < expectedRate)\n+      throw new TestFailedException(\n+        (e: StackDepthException) =>\n+          Some(s\"Expected rate $expectedRate, but got $actualRate ($numConnections connections / $elapsedSeconds sec)\"),\n+        None,\n+        Position.here)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzMDI3Nw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r453130277", "bodyText": "Yes, I had a memory that asserting from another thread would not do the right thing, but I think that was a very old memory. Checked and it works well. Replaced with assertTrue.", "author": "apovzner", "createdAt": "2020-07-11T00:24:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDEyOTgyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDEzNDM5Mw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440134393", "bodyText": "I wonder if we could just check that the metric's config is correctly re-configured instead of testing the number of connections accepted. The goal of the test is not really to verify that the quota works but rather to ensure that metric is correctly re-configured. Have you considered this? The same would apply to testMaxBrokerConnectionRateReconfiguration.", "author": "dajac", "createdAt": "2020-06-15T12:18:08Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -302,21 +312,295 @@ class ConnectionQuotasTest {\n       }\n       // all connections should get added\n       overLimitFutures.foreach(_.get(5, TimeUnit.SECONDS))\n-      listeners.values.foreach { listener =>\n-        assertEquals(s\"Number of connections on $listener:\",\n-          listenerMaxConnections, connectionQuotas.get(listener.defaultIp))\n+      verifyConnectionCountOnEveryListener(connectionQuotas, listenerMaxConnections)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateBelowLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the total rate < broker-wide quota, and verify there is no throttling\n+      val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+      val connectionsPerListener = 200 // should take 5 seconds to create 200 connections with rate = 40/sec\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs)): Runnable)\n       }\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+\n+      // the blocked percent should still be 0, because no limits were reached\n+      verifyNoBlockedPercentRecordedOnAllListeners()\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateAboveLimit(): Unit = {\n+    val brokerRateLimit = 90\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // each listener creates connections such that the total connection rate > broker-wide quota\n+      val connCreateIntervalMs = 10      // connection creation rate = 100\n+      val connectionsPerListener = 400\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs)): Runnable)\n+      }\n+      futures.foreach(_.get(20, TimeUnit.SECONDS))\n+\n+      // verify that connections on non-inter-broker listener are throttled\n+      verifyOnlyNonInterBrokerListenersBlockedPercentRecorded()\n+\n+      // expect all connections to be created (no limit on the number of connections)\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testListenerConnectionRateLimitWhenActualRateBelowLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val listenerRateLimit = 50\n+    val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionCreationRateProp -> listenerRateLimit.toString).asJava\n+    addListenersAndVerify(config, listenerConfig, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the rate < listener quota on every listener, and verify there is no throttling\n+      val connectionsPerListener = 200 // should take 5 seconds to create 200 connections with rate = 40/sec\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs)): Runnable)\n+      }\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+\n+      // the blocked percent should still be 0, because no limits were reached\n+      verifyNoBlockedPercentRecordedOnAllListeners()\n+\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testListenerConnectionRateLimitWhenActualRateAboveLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val listenerRateLimit = 30\n+    val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionCreationRateProp -> listenerRateLimit.toString).asJava\n+    addListenersAndVerify(config, listenerConfig, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the rate > listener quota on every listener\n+      // run a bit longer (20 seconds) to also verify the throttle rate\n+      val connectionsPerListener = 600 // should take 20 seconds to create 600 connections with rate = 30/sec\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() =>\n+          // epsilon is set to account for the worst-case where the measurement is taken just before or after the quota window\n+          acceptConnectionsAndVerifyRate(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs, listenerRateLimit, 5)): Runnable)\n+      }\n+      futures.foreach(_.get(30, TimeUnit.SECONDS))\n+\n+      // verify that every listener was throttled\n+      blockedPercentMeters.foreach { case (name, meter) =>\n+        assertTrue(s\"Expected BlockedPercentMeter metric for $name listener to be recorded\", meter.count() > 0)\n+      }\n+\n+      // while the connection creation rate was throttled,\n+      // expect all connections got created (not limit on the number of connections)\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionListenerMustBeAboveZero(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    connectionQuotas.addListener(config, listeners(\"EXTERNAL\").listenerName)\n+\n+    val maxListenerConnectionRate = 0\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionCreationRateProp -> maxListenerConnectionRate.toString).asJava\n+    assertThrows[ConfigException] {\n+      connectionQuotas.maxConnectionsPerListener(listeners(\"EXTERNAL\").listenerName).validateReconfiguration(listenerConfig)\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionRateReconfiguration(): Unit = {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEzMTAxMA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r453131010", "bodyText": "I still think it's important to test all the way that it does throttle to the correct value. We had a bug pretty recently, KAFKA-9658, where adding and then removing bandwidth quotas via a dynamic config changed the config and even changed some data structs, but not all data structs to actually change the throttling behavior. So, I feel more confident keeping the test up to checking the throttle.", "author": "apovzner", "createdAt": "2020-07-11T00:29:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDEzNDM5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg5Mzk4OQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r454893989", "bodyText": "Fair enough.", "author": "dajac", "createdAt": "2020-07-15T08:48:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDEzNDM5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDEzNTU2Mw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440135563", "bodyText": "I really like the explanation next to the constants! I would recommend to group all the constants in the beginning of the test case. That would help to get a quick overview of the test case.", "author": "dajac", "createdAt": "2020-06-15T12:20:25Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -302,21 +312,295 @@ class ConnectionQuotasTest {\n       }\n       // all connections should get added\n       overLimitFutures.foreach(_.get(5, TimeUnit.SECONDS))\n-      listeners.values.foreach { listener =>\n-        assertEquals(s\"Number of connections on $listener:\",\n-          listenerMaxConnections, connectionQuotas.get(listener.defaultIp))\n+      verifyConnectionCountOnEveryListener(connectionQuotas, listenerMaxConnections)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateBelowLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the total rate < broker-wide quota, and verify there is no throttling\n+      val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+      val connectionsPerListener = 200 // should take 5 seconds to create 200 connections with rate = 40/sec", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDE0MDE4Mw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440140183", "bodyText": "nit: We could perhaps create a small help method like brokerProps that accepts a Map of customer configuration pairs and returns a KafkaConfig. That would reduce the boilerplate code.", "author": "dajac", "createdAt": "2020-06-15T12:28:59Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -302,21 +312,295 @@ class ConnectionQuotasTest {\n       }\n       // all connections should get added\n       overLimitFutures.foreach(_.get(5, TimeUnit.SECONDS))\n-      listeners.values.foreach { listener =>\n-        assertEquals(s\"Number of connections on $listener:\",\n-          listenerMaxConnections, connectionQuotas.get(listener.defaultIp))\n+      verifyConnectionCountOnEveryListener(connectionQuotas, listenerMaxConnections)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateBelowLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the total rate < broker-wide quota, and verify there is no throttling\n+      val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+      val connectionsPerListener = 200 // should take 5 seconds to create 200 connections with rate = 40/sec\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs)): Runnable)\n       }\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+\n+      // the blocked percent should still be 0, because no limits were reached\n+      verifyNoBlockedPercentRecordedOnAllListeners()\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateAboveLimit(): Unit = {\n+    val brokerRateLimit = 90\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk2NTE0Mg==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r453965142", "bodyText": "the test code has just one extra prop in addition to brokerPropsWithDefaultConnectionLimits -- somehow it is easier to read the current way. I will keep it.", "author": "apovzner", "createdAt": "2020-07-13T22:04:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDE0MDE4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDE0MTA1NA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440141054", "bodyText": "It seems that almost all the test cases instantiate an executor with listeners.size. Have you considered moving this to the setUp method and moving the shutdownNow to the tearDown?", "author": "dajac", "createdAt": "2020-06-15T12:30:39Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -302,21 +312,295 @@ class ConnectionQuotasTest {\n       }\n       // all connections should get added\n       overLimitFutures.foreach(_.get(5, TimeUnit.SECONDS))\n-      listeners.values.foreach { listener =>\n-        assertEquals(s\"Number of connections on $listener:\",\n-          listenerMaxConnections, connectionQuotas.get(listener.defaultIp))\n+      verifyConnectionCountOnEveryListener(connectionQuotas, listenerMaxConnections)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateBelowLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the total rate < broker-wide quota, and verify there is no throttling\n+      val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+      val connectionsPerListener = 200 // should take 5 seconds to create 200 connections with rate = 40/sec\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs)): Runnable)\n       }\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+\n+      // the blocked percent should still be 0, because no limits were reached\n+      verifyNoBlockedPercentRecordedOnAllListeners()\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateAboveLimit(): Unit = {\n+    val brokerRateLimit = 90\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk2MjMyNg==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r453962326", "bodyText": "others use single thread, but yes, makes sense just to create one upfront using listeners.size. Will do that.", "author": "apovzner", "createdAt": "2020-07-13T22:00:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDE0MTA1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDE0MjU5Nw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r440142597", "bodyText": "nit: Would it make sense to add the pendant of verifyNoBlockedPercentRecordedOnAllListeners for this block? Something like verifyNonZeroBlockedPercentRecordedOnAllListeners?", "author": "dajac", "createdAt": "2020-06-15T12:33:31Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -302,21 +312,295 @@ class ConnectionQuotasTest {\n       }\n       // all connections should get added\n       overLimitFutures.foreach(_.get(5, TimeUnit.SECONDS))\n-      listeners.values.foreach { listener =>\n-        assertEquals(s\"Number of connections on $listener:\",\n-          listenerMaxConnections, connectionQuotas.get(listener.defaultIp))\n+      verifyConnectionCountOnEveryListener(connectionQuotas, listenerMaxConnections)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateBelowLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the total rate < broker-wide quota, and verify there is no throttling\n+      val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+      val connectionsPerListener = 200 // should take 5 seconds to create 200 connections with rate = 40/sec\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs)): Runnable)\n       }\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+\n+      // the blocked percent should still be 0, because no limits were reached\n+      verifyNoBlockedPercentRecordedOnAllListeners()\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testBrokerConnectionRateLimitWhenActualRateAboveLimit(): Unit = {\n+    val brokerRateLimit = 90\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // each listener creates connections such that the total connection rate > broker-wide quota\n+      val connCreateIntervalMs = 10      // connection creation rate = 100\n+      val connectionsPerListener = 400\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs)): Runnable)\n+      }\n+      futures.foreach(_.get(20, TimeUnit.SECONDS))\n+\n+      // verify that connections on non-inter-broker listener are throttled\n+      verifyOnlyNonInterBrokerListenersBlockedPercentRecorded()\n+\n+      // expect all connections to be created (no limit on the number of connections)\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testListenerConnectionRateLimitWhenActualRateBelowLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val listenerRateLimit = 50\n+    val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionCreationRateProp -> listenerRateLimit.toString).asJava\n+    addListenersAndVerify(config, listenerConfig, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the rate < listener quota on every listener, and verify there is no throttling\n+      val connectionsPerListener = 200 // should take 5 seconds to create 200 connections with rate = 40/sec\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs)): Runnable)\n+      }\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+\n+      // the blocked percent should still be 0, because no limits were reached\n+      verifyNoBlockedPercentRecordedOnAllListeners()\n+\n+      verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testListenerConnectionRateLimitWhenActualRateAboveLimit(): Unit = {\n+    val brokerRateLimit = 125\n+    val listenerRateLimit = 30\n+    val connCreateIntervalMs = 25 // connection creation rate = 40/sec per listener (3 * 40 = 120/sec total)\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionCreationRateProp, brokerRateLimit.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionCreationRateProp -> listenerRateLimit.toString).asJava\n+    addListenersAndVerify(config, listenerConfig, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // create connections with the rate > listener quota on every listener\n+      // run a bit longer (20 seconds) to also verify the throttle rate\n+      val connectionsPerListener = 600 // should take 20 seconds to create 600 connections with rate = 30/sec\n+      val futures = listeners.values.map { listener =>\n+        executor.submit((() =>\n+          // epsilon is set to account for the worst-case where the measurement is taken just before or after the quota window\n+          acceptConnectionsAndVerifyRate(connectionQuotas, listener, connectionsPerListener, connCreateIntervalMs, listenerRateLimit, 5)): Runnable)\n+      }\n+      futures.foreach(_.get(30, TimeUnit.SECONDS))\n+\n+      // verify that every listener was throttled\n+      blockedPercentMeters.foreach { case (name, meter) =>\n+        assertTrue(s\"Expected BlockedPercentMeter metric for $name listener to be recorded\", meter.count() > 0)\n+      }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg5MDE4MA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r454890180", "bodyText": "nit: Shall we add a javadoc to this one as well?", "author": "dajac", "createdAt": "2020-07-15T08:42:48Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1289,15 +1311,89 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg5MDI4MQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r454890281", "bodyText": "nit: Shall we add a javadoc to this one as well?", "author": "dajac", "createdAt": "2020-07-15T08:42:59Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1289,15 +1311,89 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {\n+    try {\n+      sensor.record(1.0, timeMs)\n+      0\n+    } catch {\n+      case e: QuotaViolationException =>\n+        val throttleTimeMs = QuotaUtils.boundedThrottleTime(\n+          e.value, e.bound, QuotaUtils.rateMetricWindowSize(e.metric, timeMs), maxThrottleTimeMs).toInt\n+        debug(s\"Quota violated for sensor (${sensor.name}). Delay time: $throttleTimeMs ms\")\n+        throttleTimeMs\n+    }\n+  }\n+\n+  /**\n+   * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n+   * listener or broker-wide, if listener is not provided.\n+   * @param quotaLimit connection creation rate quota\n+   * @param listenerOpt listener name if sensor is for a listener\n+   */\n+  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val sensor = metrics.sensor(s\"ConnectionCreationRate-$quotaEntity\", rateQuotaMetricConfig(quotaLimit))\n+    sensor.add(connectionRateMetricName(quotaEntity), new Rate, null)\n+    info(s\"Created ConnectionCreationRate-$quotaEntity sensor, quotaLimit=$quotaLimit\")\n+    sensor\n+  }\n+\n+  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI5NTU4Mg==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r457295582", "bodyText": "We don't talk about this in the KIP and this is a public class. Why are we skipping reporting anyway?", "author": "rajinisivaram", "createdAt": "2020-07-20T11:25:11Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricConfig.java", "diffHunk": "@@ -97,5 +99,13 @@ public MetricConfig recordLevel(Sensor.RecordingLevel recordingLevel) {\n         return this;\n     }\n \n+    public boolean skipReporting() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzM5MDAzNA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r457390034", "bodyText": "I asked the very same question: #8768 (comment). Basically, we already have the same metrics defined as part of the SelectorMetrics so the ones added here collides.\nThinking a bit more about this, I wonder if we could use Sensors without adding them to the registry at all.", "author": "dajac", "createdAt": "2020-07-20T13:36:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI5NTU4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk0NDgzNw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r457944837", "bodyText": "If we are using a sensor to determine throttle time that is different from the one in Selector, we might want to expose  it as a metric anyway. In case of a bug, we want to know this metric, not one in Selector. Perhaps we could use connections-accepted instead of connections-created or something like that. In any case, skipReporting seems odd, so as @dajac  said, using a Sensor that is not added to the metrics registry may be an option too.", "author": "rajinisivaram", "createdAt": "2020-07-21T08:58:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI5NTU4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzMwMjY0Nw==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r457302647", "bodyText": "broker is a valid listener name, perhaps a reasonable name for inter-broker listener.", "author": "rajinisivaram", "createdAt": "2020-07-20T11:36:42Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1289,15 +1311,89 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {\n+    try {\n+      sensor.record(1.0, timeMs)\n+      0\n+    } catch {\n+      case e: QuotaViolationException =>\n+        val throttleTimeMs = QuotaUtils.boundedThrottleTime(\n+          e.value, e.bound, QuotaUtils.rateMetricWindowSize(e.metric, timeMs), maxThrottleTimeMs).toInt\n+        debug(s\"Quota violated for sensor (${sensor.name}). Delay time: $throttleTimeMs ms\")\n+        throttleTimeMs\n+    }\n+  }\n+\n+  /**\n+   * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n+   * listener or broker-wide, if listener is not provided.\n+   * @param quotaLimit connection creation rate quota\n+   * @param listenerOpt listener name if sensor is for a listener\n+   */\n+  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val sensor = metrics.sensor(s\"ConnectionCreationRate-$quotaEntity\", rateQuotaMetricConfig(quotaLimit))\n+    sensor.add(connectionRateMetricName(quotaEntity), new Rate, null)\n+    info(s\"Created ConnectionCreationRate-$quotaEntity sensor, quotaLimit=$quotaLimit\")\n+    sensor\n+  }\n+\n+  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzMwMzg1OQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r457303859", "bodyText": "We could just make connectionRateSensor a val", "author": "rajinisivaram", "createdAt": "2020-07-20T11:38:36Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1289,15 +1311,89 @@ class ConnectionQuotas(config: KafkaConfig, time: Time) extends Logging {\n   private def maxListenerConnections(listenerName: ListenerName): Int =\n     maxConnectionsPerListener.get(listenerName).map(_.maxConnections).getOrElse(Int.MaxValue)\n \n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to listener-level limit or to broker-wide\n+   * limit, whichever the longest. The delay is capped to the quota window size defined by QuotaWindowSizeSecondsProp\n+   *\n+   * @param listenerName listener for which calculate the delay\n+   * @param timeMs current time in milliseconds\n+   * @return delay in milliseconds\n+   */\n+  private def recordConnectionAndGetThrottleTimeMs(listenerName: ListenerName, timeMs: Long): Long = {\n+    val listenerThrottleTimeMs = maxConnectionsPerListener\n+      .get(listenerName)\n+      .map(listenerQuota => recordAndGetThrottleTimeMs(listenerQuota.connectionRateSensor, timeMs))\n+      .getOrElse(0)\n+\n+    if (protectedListener(listenerName)) {\n+      listenerThrottleTimeMs\n+    } else {\n+      val brokerThrottleTimeMs = recordAndGetThrottleTimeMs(brokerConnectionRateSensor, timeMs)\n+      math.max(brokerThrottleTimeMs, listenerThrottleTimeMs)\n+    }\n+  }\n+\n+  private def recordAndGetThrottleTimeMs(sensor: Sensor, timeMs: Long): Int = {\n+    try {\n+      sensor.record(1.0, timeMs)\n+      0\n+    } catch {\n+      case e: QuotaViolationException =>\n+        val throttleTimeMs = QuotaUtils.boundedThrottleTime(\n+          e.value, e.bound, QuotaUtils.rateMetricWindowSize(e.metric, timeMs), maxThrottleTimeMs).toInt\n+        debug(s\"Quota violated for sensor (${sensor.name}). Delay time: $throttleTimeMs ms\")\n+        throttleTimeMs\n+    }\n+  }\n+\n+  /**\n+   * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n+   * listener or broker-wide, if listener is not provided.\n+   * @param quotaLimit connection creation rate quota\n+   * @param listenerOpt listener name if sensor is for a listener\n+   */\n+  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val sensor = metrics.sensor(s\"ConnectionCreationRate-$quotaEntity\", rateQuotaMetricConfig(quotaLimit))\n+    sensor.add(connectionRateMetricName(quotaEntity), new Rate, null)\n+    info(s\"Created ConnectionCreationRate-$quotaEntity sensor, quotaLimit=$quotaLimit\")\n+    sensor\n+  }\n+\n+  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n+    val quotaEntity = listenerOpt.getOrElse(\"broker\")\n+    val metric = metrics.metric(connectionRateMetricName(quotaEntity))\n+    metric.config(rateQuotaMetricConfig(quotaLimit))\n+    info(s\"Updated $quotaEntity max connection creation rate to $quotaLimit\")\n+  }\n+\n+  private def connectionRateMetricName(quotaEntity: String): MetricName = {\n+    metrics.metricName(\n+      s\"connection-creation-rate-$quotaEntity\",\n+      \"connection-quota\",\n+      s\"Tracking $quotaEntity connection creation rate\")\n+  }\n+\n+  private def rateQuotaMetricConfig(quotaLimit: Int): MetricConfig = {\n+    new MetricConfig()\n+      .timeWindow(config.quotaWindowSizeSeconds.toLong, TimeUnit.SECONDS)\n+      .samples(config.numQuotaSamples)\n+      .quota(new Quota(quotaLimit, true))\n+      .skipReporting(true)\n+  }\n+\n   class ListenerConnectionQuota(lock: Object, listener: ListenerName) extends ListenerReconfigurable {\n     @volatile private var _maxConnections = Int.MaxValue\n+    private val _connectionRateSensor = createConnectionRateQuotaSensor(Int.MaxValue, Some(listener.value))\n \n     def maxConnections: Int = _maxConnections\n+    def connectionRateSensor: Sensor = _connectionRateSensor", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzMwODU4NQ==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r457308585", "bodyText": "Is this required for all tests or only the new connection rate tests?", "author": "rajinisivaram", "createdAt": "2020-07-20T11:45:46Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -70,37 +80,38 @@ class ConnectionQuotasTest {\n         blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n           s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n     }\n+    // use system time, because ConnectionQuota causes the current thread to wait with timeout, which waits based on\n+    // system time; so using mock time will likely result in test flakiness due to a mixed use of mock and system time\n+    metrics = new Metrics(new MetricConfig(), Collections.emptyList(), Time.SYSTEM)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE3NTE1NA==", "url": "https://github.com/apache/kafka/pull/8768#discussion_r468175154", "bodyText": "This is required for all tests. For tests that are not supposed to trigger throttling due to connection rate quota, we want this because if the code incorrectly throttles to limit rate (calls wait() with timeout), the existing tests may start failing in a way that is hard to debug (timeout too early or too late, not in a place we expect).", "author": "apovzner", "createdAt": "2020-08-10T20:44:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzMwODU4NQ=="}], "type": "inlineReview"}, {"oid": "a57b5b4a119a28fb6cf92fe55236515ddce08f23", "url": "https://github.com/apache/kafka/commit/a57b5b4a119a28fb6cf92fe55236515ddce08f23", "message": "KAFKA-10023: Enforce broker-wide and per-listener connection creation rate", "committedDate": "2020-08-06T23:01:01Z", "type": "commit"}, {"oid": "aae01fabcb35cb170572a50a58af9ffc817169e0", "url": "https://github.com/apache/kafka/commit/aae01fabcb35cb170572a50a58af9ffc817169e0", "message": "fixed bad merge", "committedDate": "2020-08-06T23:01:01Z", "type": "commit"}, {"oid": "c7476516c596b08f0532929880fc9a3fae534f2d", "url": "https://github.com/apache/kafka/commit/c7476516c596b08f0532929880fc9a3fae534f2d", "message": "addressed initial review", "committedDate": "2020-08-06T23:01:02Z", "type": "commit"}, {"oid": "45f62a9775b6a72bd8548985f52877251778da0e", "url": "https://github.com/apache/kafka/commit/45f62a9775b6a72bd8548985f52877251778da0e", "message": "moved no reporting flag to MetricConfig and addressed other comments", "committedDate": "2020-08-06T23:01:02Z", "type": "commit"}, {"oid": "61fff7cc8d5611ba8c3bc20311bf993a57a99d38", "url": "https://github.com/apache/kafka/commit/61fff7cc8d5611ba8c3bc20311bf993a57a99d38", "message": "reverted unintended changes (removed spaces in a comment)", "committedDate": "2020-08-06T23:01:02Z", "type": "commit"}, {"oid": "13acc153ac32258ad64b7971a363e70a8eeccfac", "url": "https://github.com/apache/kafka/commit/13acc153ac32258ad64b7971a363e70a8eeccfac", "message": "one more revert", "committedDate": "2020-08-06T23:01:02Z", "type": "commit"}, {"oid": "0c7d9ce557373b44c16a945587c0b6d045491ae2", "url": "https://github.com/apache/kafka/commit/0c7d9ce557373b44c16a945587c0b6d045491ae2", "message": "Fixed merge issue, reporting connection-accept-rate metrics", "committedDate": "2020-08-11T01:29:42Z", "type": "commit"}, {"oid": "0c7d9ce557373b44c16a945587c0b6d045491ae2", "url": "https://github.com/apache/kafka/commit/0c7d9ce557373b44c16a945587c0b6d045491ae2", "message": "Fixed merge issue, reporting connection-accept-rate metrics", "committedDate": "2020-08-11T01:29:42Z", "type": "forcePushed"}, {"oid": "508a754f397b5a1939c44dfcba72ba996bc912c5", "url": "https://github.com/apache/kafka/commit/508a754f397b5a1939c44dfcba72ba996bc912c5", "message": "clean up connection rate sensors", "committedDate": "2020-08-17T03:37:50Z", "type": "commit"}]}