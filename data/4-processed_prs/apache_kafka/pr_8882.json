{"pr_number": 8882, "pr_title": "KAFKA-10165: Remove Percentiles from e2e metrics", "pr_createdAt": "2020-06-16T20:14:37Z", "pr_url": "https://github.com/apache/kafka/pull/8882", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNTQ2Mw==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441115463", "bodyText": "This previously relied on a lookup of the actual current system time. I thought we decided to use the cached system time. Can you set me straight, @ableegoldman ?", "author": "vvcephei", "createdAt": "2020-06-16T20:15:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextImpl.java", "diffHunk": "@@ -235,7 +235,7 @@ public StateStore getStateStore(final String name) {\n         setCurrentNode(child);\n         child.process(key, value);\n         if (child.isTerminalNode()) {\n-            streamTask.maybeRecordE2ELatency(timestamp(), child.name());\n+            streamTask.maybeRecordE2ELatency(timestamp(), currentSystemTimeMs(), child.name());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE2NDA4Nw==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441164087", "bodyText": "Oh, hm, I thought we decided to push the stateful-node-level metrics to TRACE so we could get the actual time at each node without a (potential) performance hit. But with the INFO-level metrics it would be ok since we're only updating it twice per process.\nBut maybe I'm misremembering...I suppose ideally we could run some benchmarks for both cases and see if it really makes a difference...", "author": "ableegoldman", "createdAt": "2020-06-16T21:54:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNTQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE2OTA2Mg==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441169062", "bodyText": "Ok, but right now, this is an INFO level metric, right?", "author": "vvcephei", "createdAt": "2020-06-16T22:06:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNTQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE3MDU3OA==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441170578", "bodyText": "This will probably need to get refactored when you do the second PR.", "author": "vvcephei", "createdAt": "2020-06-16T22:10:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNTQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE3MTk3NQ==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441171975", "bodyText": "Yeah. I'm just not 100% sure we all agreed it was alright to get the actual system time even for the task-level metrics ... so we should probably stick with the cached time for now", "author": "ableegoldman", "createdAt": "2020-06-16T22:13:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNTQ2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNjA1Mg==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441116052", "bodyText": "Standby tasks don't currently register any sensors, but I personally rather to be defensive and idempotently ensure we remove any sensors while closing.", "author": "vvcephei", "createdAt": "2020-06-16T20:16:53Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -160,18 +162,21 @@ public void postCommit() {\n \n     @Override\n     public void closeClean() {\n+        streamsMetrics.removeAllTaskLevelSensors(Thread.currentThread().getName(), id.toString());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE1NTkwNQ==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441155905", "bodyText": "Sounds good. But why do it both here and in closeDirty vs doing so in close(clean)?", "author": "ableegoldman", "createdAt": "2020-06-16T21:35:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNjA1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE2OTMyNw==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441169327", "bodyText": "I'd like to inline close(boolean), but am resisting the urge... This is a compromise ;)", "author": "vvcephei", "createdAt": "2020-06-16T22:07:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNjA1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE3MjIyOA==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441172228", "bodyText": "Fair enough. I thought the answer might be something like that...", "author": "ableegoldman", "createdAt": "2020-06-16T22:14:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNjA1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNjk3OA==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441116978", "bodyText": "We previously relied on the task manager to remove these sensors before calling close, but forgot to do it before recycling. In retrospect, it's better to do it within the same class that creates the sensors to begin with.", "author": "vvcephei", "createdAt": "2020-06-16T20:18:43Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -456,12 +457,14 @@ public void postCommit() {\n \n     @Override\n     public void closeClean() {\n+        streamsMetrics.removeAllTaskLevelSensors(Thread.currentThread().getName(), id.toString());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE1OTM4MA==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441159380", "bodyText": "Agreed, we should clean up anything we created in the same class", "author": "ableegoldman", "createdAt": "2020-06-16T21:43:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNjk3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNzQyOA==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441117428", "bodyText": "Fixes the sensor leak by simply registering these as task-level sensors. Note the node name is still provided to scope the sensors themselves.", "author": "vvcephei", "createdAt": "2020-06-16T20:19:35Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -150,18 +151,18 @@ public StreamTask(final TaskId id,\n         punctuateLatencySensor = TaskMetrics.punctuateSensor(threadId, taskId, streamsMetrics);\n         bufferedRecordsSensor = TaskMetrics.activeBufferedRecordsSensor(threadId, taskId, streamsMetrics);\n \n-        for (final String terminalNode : topology.terminalNodes()) {\n+        for (final String terminalNodeName : topology.terminalNodes()) {\n             e2eLatencySensors.put(\n-                terminalNode,\n-                ProcessorNodeMetrics.recordE2ELatencySensor(threadId, taskId, terminalNode, RecordingLevel.INFO, streamsMetrics)\n+                terminalNodeName,\n+                TaskMetrics.e2ELatencySensor(threadId, taskId, terminalNodeName, RecordingLevel.INFO, streamsMetrics)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExODI0MQ==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441118241", "bodyText": "We erroneously ignored the provided recordingLevel and set them to debug. It didn't manifest because this method happens to always be called with a recordingLevel of debug anyway.", "author": "vvcephei", "createdAt": "2020-06-16T20:21:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/ProcessorNodeMetrics.java", "diffHunk": "@@ -337,7 +307,7 @@ private static Sensor throughputAndLatencySensorWithParent(final String threadId\n             descriptionOfCount,\n             descriptionOfAvgLatency,\n             descriptionOfMaxLatency,\n-            RecordingLevel.DEBUG,\n+            recordingLevel,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExODUzNQ==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441118535", "bodyText": "Dropped the percentiles metric.", "author": "vvcephei", "createdAt": "2020-06-16T20:21:43Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -675,27 +670,6 @@ public static void addMinAndMaxAndP99AndP90ToSensor(final Sensor sensor,\n                 tags),\n             new Max()\n         );\n-\n-        sensor.add(", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE2MTUyMw==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441161523", "bodyText": "Github won't let me comment on these lines, but we should remove the two percentiles-necessitated constants above (PERCENTILES_SIZE_IN_BYTES and MAXIMUM_E2E_LATENCY)", "author": "ableegoldman", "createdAt": "2020-06-16T21:48:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExODUzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE2OTYyOA==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441169628", "bodyText": "Ah, missed those. Thanks!", "author": "vvcephei", "createdAt": "2020-06-16T22:08:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExODUzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExOTE2Ng==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441119166", "bodyText": "Just cleaning up some oddball literals.", "author": "vvcephei", "createdAt": "2020-06-16T20:22:52Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -400,20 +402,20 @@ public void shouldRecordBufferedRecords() {\n \n         final KafkaMetric metric = getMetric(\"active-buffer\", \"%s-count\", task.id().toString(), StreamsConfig.METRICS_LATEST);\n \n-        assertThat(metric.metricValue(), equalTo(0.0d));\n+        assertThat(metric.metricValue(), equalTo(0.0));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExOTc2OA==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441119768", "bodyText": "This test wasn't really testing the \"terminal node\" code path in ProcessorContextImpl, just that this overload actually fetches the current system time. Since I removed the overload, we don't need the test.", "author": "vvcephei", "createdAt": "2020-06-16T20:24:06Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -454,24 +456,7 @@ public void shouldRecordE2ELatencyOnProcessForSourceNodes() {\n         task.addRecords(partition1, singletonList(getConsumerRecord(partition1, 0L)));\n         task.process(100L);\n \n-        assertThat(maxMetric.metricValue(), equalTo(100d));\n-    }\n-\n-    @Test\n-    public void shouldRecordE2ELatencyOnProcessForTerminalNodes() {\n-        time = new MockTime(0L, 0L, 0L);\n-        metrics = new Metrics(new MetricConfig().recordLevel(Sensor.RecordingLevel.INFO), time);\n-        task = createStatelessTask(createConfig(false, \"0\"), StreamsConfig.METRICS_LATEST);\n-\n-        final String terminalNode = processorStreamTime.name();\n-\n-        final Metric maxMetric = getProcessorMetric(\"record-e2e-latency\", \"%s-max\", task.id().toString(), terminalNode, StreamsConfig.METRICS_LATEST);\n-\n-        // e2e latency = 100\n-        time.setCurrentTimeMs(100L);\n-        task.maybeRecordE2ELatency(0L, terminalNode);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEyMDA5Mg==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441120092", "bodyText": "Verified this fails on trunk.", "author": "vvcephei", "createdAt": "2020-06-16T20:24:47Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1806,11 +1793,19 @@ public void shouldRecycleTask() {\n         task.initializeIfNeeded();\n         task.completeRestoration();\n \n+        assertThat(getTaskMetrics(), not(empty()));\n+\n         task.closeAndRecycleState();\n \n+        assertThat(getTaskMetrics(), empty());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE3NTI2Ng==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441175266", "bodyText": "\ud83d\ude4f", "author": "ableegoldman", "createdAt": "2020-06-16T22:22:11Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java", "diffHunk": "@@ -366,6 +369,37 @@ public void shouldThrowOnCloseCleanCheckpointError() {\n         EasyMock.replay(stateManager);\n     }\n \n+    @Test\n+    public void shouldUnregisterMetricsInCloseClean() {\n+        EasyMock.expect(stateManager.changelogPartitions()).andReturn(Collections.emptySet()).anyTimes();\n+        EasyMock.replay(stateManager);\n+\n+        task = createStandbyTask();\n+        task.initializeIfNeeded();\n+\n+        task.suspend();\n+        task.closeClean();\n+        // Currently, there are no metrics registered for standby tasks.\n+        // This is a regression test so that, if we add some, we will be sure to deregister them.\n+        assertThat(getTaskMetrics(), empty());\n+    }\n+\n+    @Test\n+    public void shouldUnregisterMetricsInCloseDirty() {\n+        EasyMock.expect(stateManager.changelogPartitions()).andReturn(Collections.emptySet()).anyTimes();\n+        EasyMock.replay(stateManager);\n+\n+        task = createStandbyTask();\n+        task.initializeIfNeeded();\n+\n+        task.suspend();\n+        task.closeDirty();\n+\n+        // Currently, there are no metrics registered for standby tasks.\n+        // This is a regression test so that, if we add some, we will be sure to deregister them.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7c3c51ffcb65b50c344ab05733874964e1d1064c", "url": "https://github.com/apache/kafka/commit/7c3c51ffcb65b50c344ab05733874964e1d1064c", "message": "KAFKA-10165: Remove Percentiles from e2e metrics", "committedDate": "2020-06-17T03:35:02Z", "type": "commit"}, {"oid": "ae1a3908bcaad82e30ad35a0e4462d7a4b7978b5", "url": "https://github.com/apache/kafka/commit/ae1a3908bcaad82e30ad35a0e4462d7a4b7978b5", "message": "separate test case for closeAndRecycle metrics", "committedDate": "2020-06-17T03:42:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc4MTQ5OA==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441781498", "bodyText": "@vvcephei I'm not familiar enough with the metrics classification to know if this will be an issue or just an oddity, but we now have allegedly task-level metrics but with the processor-node-level tags/grouping. It's kind of a \"task metric in implementation, processor node metric in interface\" -- might be confusing for us but should be alright for users, yeah?", "author": "ableegoldman", "createdAt": "2020-06-17T19:25:25Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/TaskMetrics.java", "diffHunk": "@@ -133,6 +142,25 @@ public static Sensor activeBufferedRecordsSensor(final String threadId,\n         return sensor;\n     }\n \n+    public static Sensor e2ELatencySensor(final String threadId,\n+                                          final String taskId,\n+                                          final String processorNodeId,\n+                                          final RecordingLevel recordingLevel,\n+                                          final StreamsMetricsImpl streamsMetrics) {\n+        final String sensorName = processorNodeId + \"-\" + RECORD_E2E_LATENCY;\n+        final Sensor sensor = streamsMetrics.taskLevelSensor(threadId, taskId, sensorName, recordingLevel);\n+        final Map<String, String> tagMap = streamsMetrics.nodeLevelTagMap(threadId, taskId, processorNodeId);\n+        addMinAndMaxToSensor(\n+            sensor,\n+            PROCESSOR_NODE_LEVEL_GROUP,", "originalCommit": "ae1a3908bcaad82e30ad35a0e4462d7a4b7978b5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc4MjI4Ng==", "url": "https://github.com/apache/kafka/pull/8882#discussion_r441782286", "bodyText": "We give it the task sensor prefix which becomes part of the full sensor name, rather than the processor node prefix", "author": "ableegoldman", "createdAt": "2020-06-17T19:26:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc4MTQ5OA=="}], "type": "inlineReview"}]}