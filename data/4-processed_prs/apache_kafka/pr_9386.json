{"pr_number": 9386, "pr_title": "KAFKA-10024: Add dynamic configuration and enforce quota for per-IP connection rate limits (KIP-612, part 2)", "pr_createdAt": "2020-10-06T20:44:56Z", "pr_url": "https://github.com/apache/kafka/pull/9386", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA4NDkyNA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r502084924", "bodyText": "It would be more efficient if we throttled IPs after we know that we can accept a connection based on broker-wide and per-listener limits, since reaching broker/listener limits block the acceptor thread while throttling IPs needs more processing. Otherwise, if you reach both broker and per IP limit, the broker will continue accepting and delaying connections where it is justified to block an acceptor thread based on reaching a broker rate limit. Basically, call waitForConnectionSlot first. Similar how we check per IP limit on number of connections after we know that we can accept a new connection based on broker/listener limits.", "author": "apovzner", "createdAt": "2020-10-08T23:55:56Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1203,14 +1262,27 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private val listenerCounts = mutable.Map[ListenerName, Int]()\n   private[network] val maxConnectionsPerListener = mutable.Map[ListenerName, ListenerConnectionQuota]()\n   @volatile private var totalCount = 0\n-\n+  @volatile private var defaultConnectionRatePerIp = DynamicConfig.Ip.DefaultConnectionCreationRate\n+  private val inactiveSensorExpirationTimeSeconds = TimeUnit.HOURS.toSeconds(1);\n+  private val connectionRatePerIp = new ConcurrentHashMap[InetAddress, Int]()\n+  private val lock = new ReentrantReadWriteLock()\n+  private val sensorAccessor = new SensorAccess(lock, metrics)\n   // sensor that tracks broker-wide connection creation rate and limit (quota)\n-  private val brokerConnectionRateSensor = createConnectionRateQuotaSensor(config.maxConnectionCreationRate)\n+  private val brokerConnectionRateSensor = getOrCreateConnectionRateQuotaSensor(config.maxConnectionCreationRate, BrokerQuotaEntity)\n   private val maxThrottleTimeMs = TimeUnit.SECONDS.toMillis(config.quotaWindowSizeSeconds.toLong)\n \n+\n   def inc(listenerName: ListenerName, address: InetAddress, acceptorBlockedPercentMeter: com.yammer.metrics.core.Meter): Unit = {\n     counts.synchronized {\n-      waitForConnectionSlot(listenerName, acceptorBlockedPercentMeter)\n+      val startThrottleTimeMs = time.milliseconds\n+\n+      val ipThrottleTimeMs = recordIpConnectionMaybeThrottle(address, startThrottleTimeMs)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA5MTQzNQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r502091435", "bodyText": "@apovzner\nmy reasoning for this is the following:\nconsider the case where we accept a connection at the broker/listener level, but reject it on IP level.\nwe would have already recorded the broker connection, so we'd be allocating rate to a rejected connection.\nI suppose this we can work around this in a similar manner to recordIpConnectionMaybeThrottle by unrecording the listener/broker connection if the IP gets rejected.", "author": "splett2", "createdAt": "2020-10-09T00:21:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA4NDkyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA5MjE1OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r502092158", "bodyText": "I see. Yes, I think unrecording is more efficient than keeping more delayed connections than needed. Basically, when you unrecord from per-IP metric, you can also unrecord from broker and listener metric as well.", "author": "apovzner", "createdAt": "2020-10-09T00:24:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA4NDkyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA4Njc3Nw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r502086777", "bodyText": "You can use you new constant DynamicConfig.Ip.UnlimitedConnectionCreationRate instead of Int.MaxValue here.", "author": "apovzner", "createdAt": "2020-10-09T00:03:05Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1242,7 +1314,56 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRate(ip: Option[String], maxConnectionRate: Option[Int]): Unit = {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == \"connection-accept-rate\" &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(\"ip\")\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }\n+\n+    ip match {\n+      case Some(addr) =>\n+        val address = InetAddress.getByName(addr)\n+        if (maxConnectionRate.isDefined) {\n+          info(s\"Updating max connection rate override for $address to ${maxConnectionRate.get}\")\n+          connectionRatePerIp.put(address, maxConnectionRate.get)\n+        } else {\n+          info(s\"Removing max connection rate override for $address\")\n+          connectionRatePerIp.remove(address)\n+        }\n+        updateConnectionRateQuota(connectionRateForIp(address), IpQuotaEntity(address))\n+      case None =>\n+        val newQuota = maxConnectionRate.getOrElse(Int.MaxValue)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA5MjUwOA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r502092508", "bodyText": "actually in this case, it should reset to DynamicConfig.Ip.DefaultConnectionCreationRate right?", "author": "splett2", "createdAt": "2020-10-09T00:25:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA4Njc3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA5MTMyMw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r502091323", "bodyText": "It would be useful to add a test where we have both per-listener and per IP limit, and verify that it throttles based on which limit is reached first. Something like: 2 IPs, each per IP limit < per-listener limit, but sum of per IP limits > listener limit. So, if you reach limit on one IP, the broker would not throttle the second IP until it reaches per listener limit. Does not have to be exactly this, just need to verify how per IP throttling interacts with per listener throttling.", "author": "apovzner", "createdAt": "2020-10-09T00:20:40Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -409,6 +409,67 @@ class ConnectionQuotasTest {\n     verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n   }\n \n+  @Test", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI0OTg3Mg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503249872", "bodyText": "Could we define this constant in a companion object?", "author": "dajac", "createdAt": "2020-10-12T12:06:41Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1203,14 +1261,28 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private val listenerCounts = mutable.Map[ListenerName, Int]()\n   private[network] val maxConnectionsPerListener = mutable.Map[ListenerName, ListenerConnectionQuota]()\n   @volatile private var totalCount = 0\n-\n+  @volatile private var defaultConnectionRatePerIp = DynamicConfig.Ip.DefaultConnectionCreationRate\n+  private val inactiveSensorExpirationTimeSeconds = TimeUnit.HOURS.toSeconds(1);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI1MTA4OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503251089", "bodyText": "Couldn't we rely on the ConnectionQuotaEntity trait to get these informations? That would avoid having to pattern match on the entity to get them.", "author": "dajac", "createdAt": "2020-10-12T12:09:08Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1394,28 +1554,38 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n    * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n    * listener or broker-wide, if listener is not provided.\n    * @param quotaLimit connection creation rate quota\n-   * @param listenerOpt listener name if sensor is for a listener\n+   * @param connectionQuotaEntity entity to create the sensor for\n    */\n-  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n-    val sensorName = listenerOpt.map(listener => s\"ConnectionAcceptRate-$listener\").getOrElse(\"ConnectionAcceptRate\")\n-    val sensor = metrics.sensor(sensorName, rateQuotaMetricConfig(quotaLimit))\n-    sensor.add(connectionRateMetricName(listenerOpt), new Rate, null)\n-    info(s\"Created $sensorName sensor, quotaLimit=$quotaLimit\")\n-    sensor\n+  private def getOrCreateConnectionRateQuotaSensor(quotaLimit: Int, connectionQuotaEntity: ConnectionQuotaEntity): Sensor = {\n+    val (sensorName, sensorExpiration) = connectionQuotaEntity match {\n+      case BrokerQuotaEntity => (\"ConnectionAcceptRate\", Long.MaxValue)\n+      case listenerEntity: ListenerQuotaEntity => (s\"ConnectionAcceptRate-${listenerEntity.entityName}\", Long.MaxValue)\n+      case ipEntity: IpQuotaEntity => (s\"ConnectionAcceptRate-${ipEntity.entityName}\", inactiveSensorExpirationTimeSeconds)\n+    }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI1MTM0MQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503251341", "bodyText": "Same comment as before. Couldn't we rely on the ConnectionQuotaEntity trait here as well?", "author": "dajac", "createdAt": "2020-10-12T12:09:42Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1394,28 +1554,38 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n    * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n    * listener or broker-wide, if listener is not provided.\n    * @param quotaLimit connection creation rate quota\n-   * @param listenerOpt listener name if sensor is for a listener\n+   * @param connectionQuotaEntity entity to create the sensor for\n    */\n-  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n-    val sensorName = listenerOpt.map(listener => s\"ConnectionAcceptRate-$listener\").getOrElse(\"ConnectionAcceptRate\")\n-    val sensor = metrics.sensor(sensorName, rateQuotaMetricConfig(quotaLimit))\n-    sensor.add(connectionRateMetricName(listenerOpt), new Rate, null)\n-    info(s\"Created $sensorName sensor, quotaLimit=$quotaLimit\")\n-    sensor\n+  private def getOrCreateConnectionRateQuotaSensor(quotaLimit: Int, connectionQuotaEntity: ConnectionQuotaEntity): Sensor = {\n+    val (sensorName, sensorExpiration) = connectionQuotaEntity match {\n+      case BrokerQuotaEntity => (\"ConnectionAcceptRate\", Long.MaxValue)\n+      case listenerEntity: ListenerQuotaEntity => (s\"ConnectionAcceptRate-${listenerEntity.entityName}\", Long.MaxValue)\n+      case ipEntity: IpQuotaEntity => (s\"ConnectionAcceptRate-${ipEntity.entityName}\", inactiveSensorExpirationTimeSeconds)\n+    }\n+    sensorAccessor.getOrCreate(\n+      sensorName,\n+      sensorExpiration,\n+      sensor => sensor.add(connectionRateMetricName(connectionQuotaEntity), new Rate, rateQuotaMetricConfig(quotaLimit))\n+    )\n   }\n \n   /**\n-   * Updates quota configuration for a given listener or broker-wide (if 'listenerOpt' is None)\n+   * Updates quota configuration for a given connection quota entity\n    */\n-  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n-    val metric = metrics.metric(connectionRateMetricName(listenerOpt))\n-    metric.config(rateQuotaMetricConfig(quotaLimit))\n-    info(s\"Updated ${listenerOpt.getOrElse(\"broker-wide\")} max connection creation rate to $quotaLimit\")\n+  private def updateConnectionRateQuota(quotaLimit: Int, connectionQuotaEntity: ConnectionQuotaEntity): Unit = {\n+    val metricOpt = Option(metrics.metric(connectionRateMetricName(connectionQuotaEntity)))\n+    metricOpt.foreach { metric =>\n+      metric.config(rateQuotaMetricConfig(quotaLimit))\n+      info(s\"Updated ${connectionQuotaEntity.entityName} max connection creation rate to $quotaLimit\")\n+    }\n   }\n \n-  private def connectionRateMetricName(listenerOpt: Option[String]): MetricName = {\n-    val tags = listenerOpt.map(listener => Map(\"listener\" -> listener)).getOrElse(Map())\n-    val namePrefix = listenerOpt.map(_ => \"\").getOrElse(\"broker-\")\n+  private def connectionRateMetricName(connectionQuotaEntity: ConnectionQuotaEntity): MetricName = {\n+    val (namePrefix, tags) = connectionQuotaEntity match {\n+      case BrokerQuotaEntity => (\"broker-\", Map.empty[String, String])\n+      case listener: ListenerQuotaEntity => (\"\", Map(\"listener\" -> listener.entityName))\n+      case ip: IpQuotaEntity => (\"\", Map(\"ip\" -> ip.entityName))\n+    }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI1MTU2MA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503251560", "bodyText": "nit: Can't we reuse connectionRateQuota directly?", "author": "dajac", "createdAt": "2020-10-12T12:10:10Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1371,6 +1492,45 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n     }\n   }\n \n+  /**\n+   * To avoid over-recording listener/broker connection rate, we unrecord a listener or broker connection\n+   * if the IP gets throttled later.\n+   *\n+   * @param listenerName listener to unrecord connection\n+   * @param timeMs current time in milliseconds\n+   */\n+  private def unrecordListenerConnection(listenerName: ListenerName, timeMs: Long): Unit = {\n+    if (!protectedListener(listenerName)) {\n+      brokerConnectionRateSensor.record(-1.0, timeMs, false)\n+    }\n+    maxConnectionsPerListener\n+      .get(listenerName)\n+      .foreach(_.connectionRateSensor.record(-1.0, timeMs, false))\n+  }\n+\n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to the IP limit.\n+   * If the connection would cause an IP quota violation, un-record the connection\n+   *\n+   * @param address\n+   * @param timeMs\n+   * @return\n+   */\n+  private def recordIpConnectionMaybeThrottle(address: InetAddress, timeMs: Long): Long = {\n+    val connectionRateQuota = connectionRateForIp(address)\n+    val quotaEnabled = connectionRateQuota != DynamicConfig.Ip.UnlimitedConnectionCreationRate\n+    if (!quotaEnabled) {\n+      return 0\n+    }\n+    val sensor = getOrCreateConnectionRateQuotaSensor(connectionRateForIp(address), IpQuotaEntity(address))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI5NTI0Ng==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503295246", "bodyText": "Instead of recording, checking the quota, and unrecording if the quota is violated, we may be able to check the quota and record only if the quota is not violated yet. Your implementation suggests that we want to enforce a strict quota here. We did so for the controller mutations with the following implementation:\ntry {\n      quotaSensor synchronized {\n        quotaSensor.checkQuotas(timeMs)\n        quotaSensor.record(permits, timeMs, false)\n      }\n    } catch {\n      case e: QuotaViolationException =>\n         ...\n    }\n\nIt seems that this should work here as well. Let me know what you think about this.", "author": "dajac", "createdAt": "2020-10-12T13:27:08Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1371,6 +1492,45 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n     }\n   }\n \n+  /**\n+   * To avoid over-recording listener/broker connection rate, we unrecord a listener or broker connection\n+   * if the IP gets throttled later.\n+   *\n+   * @param listenerName listener to unrecord connection\n+   * @param timeMs current time in milliseconds\n+   */\n+  private def unrecordListenerConnection(listenerName: ListenerName, timeMs: Long): Unit = {\n+    if (!protectedListener(listenerName)) {\n+      brokerConnectionRateSensor.record(-1.0, timeMs, false)\n+    }\n+    maxConnectionsPerListener\n+      .get(listenerName)\n+      .foreach(_.connectionRateSensor.record(-1.0, timeMs, false))\n+  }\n+\n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to the IP limit.\n+   * If the connection would cause an IP quota violation, un-record the connection\n+   *\n+   * @param address\n+   * @param timeMs\n+   * @return\n+   */\n+  private def recordIpConnectionMaybeThrottle(address: InetAddress, timeMs: Long): Long = {\n+    val connectionRateQuota = connectionRateForIp(address)\n+    val quotaEnabled = connectionRateQuota != DynamicConfig.Ip.UnlimitedConnectionCreationRate\n+    if (!quotaEnabled) {\n+      return 0\n+    }\n+    val sensor = getOrCreateConnectionRateQuotaSensor(connectionRateForIp(address), IpQuotaEntity(address))\n+    val throttleMs = recordAndGetThrottleTimeMs(sensor, timeMs)\n+    if (throttleMs > 0) {\n+      // unrecord the connection since we won't accept the connection\n+      sensor.record(-1.0, timeMs, false)\n+    }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2NDk1NQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503664955", "bodyText": "I didn't do this because I saw that checkQuotas checks whether we are at the upper bound, not whether recording a new connection would throw an exception, which I suppose is why you are calling record with checkQuotas = false.\nI think it makes sense to do here. The actual rate of permitted connections ends up being 1 higher than otherwise, but I think that's fine.", "author": "splett2", "createdAt": "2020-10-13T04:48:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI5NTI0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIxOTY2OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r504219669", "bodyText": "actually, i thought a bit more about it and in the case where an IP is supposed to be completely throttled (rate limit == 0), we would be accepting connections at a rate of 1 which would be very weird/unacceptable behavior. I left it at is. Let me know if that makes sense or if I have some holes in my logic.", "author": "splett2", "createdAt": "2020-10-13T19:58:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI5NTI0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI5NzM5OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503297399", "bodyText": "Do we really need to store delayed sockets per IP? It seems that we just close all the sockets in throttledSockets later on so it is not really necessary. Or have I missed something?\nSimilarly, we use a DelayQueue for the other quotas. Is there any reason why we don't use the same data structure here?", "author": "dajac", "createdAt": "2020-10-12T13:30:42Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -697,6 +714,31 @@ private[kafka] class Acceptor(val endPoint: EndPoint,\n         info(s\"Rejected connection from ${e.ip}, address already has the configured maximum of ${e.count} connections.\")\n         close(endPoint.listenerName, socketChannel)\n         None\n+      case e: ConnectionThrottledException =>\n+        val ip = socketChannel.socket.getInetAddress\n+        debug(s\"Delaying closing of connection from $ip for ${e.throttleTimeMs} ms\")\n+        val delayQueue = throttledSockets.computeIfAbsent(ip, _ => new mutable.Queue[DelayedCloseSocket])", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2ODI0MA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503668240", "bodyText": "I went with this data structure because throttle end time should be monotonic for a specific IP but not necessarily for all IPs. By maintaining a queue per IP, we can get constant time adds/removes for a throttled IP.\nThe downside of this is that in the case where there are no connections to unthrottle, closeThrottledConnections runs in O(n) for number of throttled IPs.\nOn the other hand DelayQueue uses a heap internally and has O(log(n)) for each add/remove, and constant time for checking whether there are IPs to unthrottle. In scenarios where many connections will get unthrottled at once, the DelayQueue will perform significantly worse, since each DelayQueue.dequeue call will be O(log(n)).\nI admit this could be a premature optimization, and a delay queue could work better in practice. Let me know what you think.", "author": "splett2", "createdAt": "2020-10-13T05:02:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI5NzM5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2Nzc2MQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510867761", "bodyText": "Thanks for the explanation.\nI do agree that in the worst case scenario where we would have all the connections ready to be unthrottled, the heap based solution would perform worse. On the other hand, if there are no connections ready to be unthrottled, checking the heap is O(1) whereas we would be O(N) where N is the number of throttled connections.\nOn average, I do believe that the number of connections ready to be unthrottled at every run of the acceptor loop will be smaller (or even zero) than the total number of throttled connections. Cleaning M throttling connections with the heap would be O(M log(N)) which is better than O(N) if M < N / log(N).\nI lean towards using a delay queue at the moment.", "author": "dajac", "createdAt": "2020-10-23T13:02:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI5NzM5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjg4NzQ5OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r512887499", "bodyText": "I agree, that it is better to optimize for checking connections vs. overhead of adding/removing to the queue, because closeThrottledConnections runs pretty often (on a loop), which I think also means that finding that there are no connections yet to unthrottle would also be common. Or very few connections to unthrottle. So, after reading all your evaluations above, I am also leaning towards using a delay queue here.\nNot sure if the question # 1 about why we need to delay closing a connection got answered, so answering just in case. Since we want to throttle accepting connections from an IP, closing a connection due to reaching IP quota right away would not help with throttling accepting connections since that IP is going to reconnect.", "author": "apovzner", "createdAt": "2020-10-27T17:28:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI5NzM5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NzQ0Mw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r516997443", "bodyText": "Okay, I replaced the map/queue with a priority queue.\nI did not use the java DelayQueue similar to the implementation in ClientQuotaManager because this throttling implementation does not use timeout-based polling or require a synchronized data structure, and there's significantly more boilerplate needed for a DelayQueue", "author": "splett2", "createdAt": "2020-11-03T22:40:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzI5NzM5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNzcwNg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503307706", "bodyText": "Out of curiosity, have we considered using a \"reaper\" running in a separate thread to drain the queue and close throttled connections?", "author": "dajac", "createdAt": "2020-10-12T13:46:49Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -600,43 +607,10 @@ private[kafka] class Acceptor(val endPoint: EndPoint,\n     serverChannel.register(nioSelector, SelectionKey.OP_ACCEPT)\n     startupComplete()\n     try {\n-      var currentProcessorIndex = 0\n       while (isRunning) {\n         try {\n-          val ready = nioSelector.select(500)\n-          if (ready > 0) {\n-            val keys = nioSelector.selectedKeys()\n-            val iter = keys.iterator()\n-            while (iter.hasNext && isRunning) {\n-              try {\n-                val key = iter.next\n-                iter.remove()\n-\n-                if (key.isAcceptable) {\n-                  accept(key).foreach { socketChannel =>\n-                    // Assign the channel to the next processor (using round-robin) to which the\n-                    // channel can be added without blocking. If newConnections queue is full on\n-                    // all processors, block until the last one is able to accept a connection.\n-                    var retriesLeft = synchronized(processors.length)\n-                    var processor: Processor = null\n-                    do {\n-                      retriesLeft -= 1\n-                      processor = synchronized {\n-                        // adjust the index (if necessary) and retrieve the processor atomically for\n-                        // correct behaviour in case the number of processors is reduced dynamically\n-                        currentProcessorIndex = currentProcessorIndex % processors.length\n-                        processors(currentProcessorIndex)\n-                      }\n-                      currentProcessorIndex += 1\n-                    } while (!assignNewConnection(socketChannel, processor, retriesLeft == 0))\n-                  }\n-                } else\n-                  throw new IllegalStateException(\"Unrecognized key state for acceptor thread.\")\n-              } catch {\n-                case e: Throwable => error(\"Error while accepting connection\", e)\n-              }\n-            }\n-          }\n+          acceptNewConnections()\n+          closeThrottledConnections()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY3MDg3Ng==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503670876", "bodyText": "I did consider this. I chose to do the work of closing connections in the acceptor thread to mirror the Processor thread which similarly has a openSomeConnections(), closeSomeConnections() loop.\nDitto for Selector.poll()\nAdditionally, as a future extension, we may want to re-try accepting a connection after its throttle time expires, and adding a new reaper thread would add additional complexity for that logic.", "author": "splett2", "createdAt": "2020-10-13T05:12:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNzcwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDk1MzEwMA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510953100", "bodyText": "That makes sense.", "author": "dajac", "createdAt": "2020-10-23T15:12:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNzcwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwODQwNw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503308407", "bodyText": "If we were using a shared DelayQueue for all IPs, iterating over all the IPs wouldn't be necessary when there are no throttled connections ready to be closed yet.", "author": "dajac", "createdAt": "2020-10-12T13:47:59Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -697,6 +714,31 @@ private[kafka] class Acceptor(val endPoint: EndPoint,\n         info(s\"Rejected connection from ${e.ip}, address already has the configured maximum of ${e.count} connections.\")\n         close(endPoint.listenerName, socketChannel)\n         None\n+      case e: ConnectionThrottledException =>\n+        val ip = socketChannel.socket.getInetAddress\n+        debug(s\"Delaying closing of connection from $ip for ${e.throttleTimeMs} ms\")\n+        val delayQueue = throttledSockets.computeIfAbsent(ip, _ => new mutable.Queue[DelayedCloseSocket])\n+        val endThrottleTimeMs = e.startThrottleTimeMs + e.throttleTimeMs\n+        delayQueue += DelayedCloseSocket(socketChannel, endThrottleTimeMs)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Close sockets for any connections that have been throttled\n+   */\n+  private def closeThrottledConnections(): Unit = {\n+    val timeMs = time.milliseconds\n+    val iter = throttledSockets.values.iterator\n+    while (iter.hasNext) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwODg3Mg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503308872", "bodyText": "Could we use a constant for the name and use it everywhere? Same for the tag.", "author": "dajac", "createdAt": "2020-10-12T13:48:47Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1242,7 +1314,56 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRate(ip: Option[String], maxConnectionRate: Option[Int]): Unit = {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == \"connection-accept-rate\" &&", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwOTgyNg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503309826", "bodyText": "nit: We could use pattern matching here to treat both cases.", "author": "dajac", "createdAt": "2020-10-12T13:50:13Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1242,7 +1314,56 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRate(ip: Option[String], maxConnectionRate: Option[Int]): Unit = {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == \"connection-accept-rate\" &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(\"ip\")\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }\n+\n+    ip match {\n+      case Some(addr) =>\n+        val address = InetAddress.getByName(addr)\n+        if (maxConnectionRate.isDefined) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMxNjg0Ng==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503316846", "bodyText": "nit: Could we use directly the Admin client here? We don't use the ZK admin client in the suite at all so it would be better if we don't use it. I am not sure if this depends on the pending implementation that you mentioned.", "author": "dajac", "createdAt": "2020-10-12T14:00:51Z", "path": "core/src/test/scala/integration/kafka/network/DynamicConnectionQuotaTest.scala", "diffHunk": "@@ -240,6 +256,16 @@ class DynamicConnectionQuotaTest extends BaseRequestTest {\n       s\"Admin client connection not closed (initial = $initialConnectionCount, current = $connectionCount)\")\n   }\n \n+  private def updateIpConnectionRate(ip: Option[String], updatedRate: Int): Unit = {\n+    adminZkClient.changeIpConfig(ip.getOrElse(ConfigEntityName.Default),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2NTM2OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r503665368", "bodyText": "yeah, that depends on pending implementation. I planned on using adminZkClient in the interim and then replacing it with Admin in the PR adding KafkaApis support.", "author": "splett2", "createdAt": "2020-10-13T04:50:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMxNjg0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3OTMyMA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510879320", "bodyText": "Ack, thanks.", "author": "dajac", "createdAt": "2020-10-23T13:21:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMxNjg0Ng=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDgzMzAzMA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510833030", "bodyText": "nit: Could we make this one private?", "author": "dajac", "createdAt": "2020-10-23T11:59:22Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -526,10 +527,14 @@ private[kafka] abstract class AbstractServerThread(connectionQuotas: ConnectionQ\n     if (channel != null) {\n       debug(s\"Closing connection from ${channel.socket.getRemoteSocketAddress()}\")\n       connectionQuotas.dec(listenerName, channel.socket.getInetAddress)\n-      CoreUtils.swallow(channel.socket().close(), this, Level.ERROR)\n-      CoreUtils.swallow(channel.close(), this, Level.ERROR)\n+      closeSocket(channel)\n     }\n   }\n+\n+  protected def closeSocket(channel: SocketChannel): Unit = {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjg4ODM2MA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r512888360", "bodyText": "this method is also called from the derived class.", "author": "apovzner", "createdAt": "2020-10-27T17:29:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDgzMzAzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3MzQ5NA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510873494", "bodyText": "I wonder if using newQuota is correct here. My understanding is that ip == None means that we update the default quota which is used if there is not per ip quota defined. So, we should also check if there is a per ip quota defined before overriding it with the new default, isn't it?\nI would be great if we could add more unit tests to cover this logic with multiple IPs and/or default.", "author": "dajac", "createdAt": "2020-10-23T13:12:05Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1246,7 +1337,57 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRate(ip: Option[String], maxConnectionRate: Option[Int]): Unit = {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == ConnectionRateMetricName &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(IpMetricTag)\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }\n+\n+    ip match {\n+      case Some(addr) =>\n+        val address = InetAddress.getByName(addr)\n+        maxConnectionRate match {\n+          case Some(rate) =>\n+            info(s\"Updating max connection rate override for $address to $rate\")\n+            connectionRatePerIp.put(address, rate)\n+          case None =>\n+            info(s\"Removing max connection rate override for $address\")\n+            connectionRatePerIp.remove(address)\n+        }\n+        updateConnectionRateQuota(connectionRateForIp(address), IpQuotaEntity(address))\n+      case None =>\n+        val newQuota = maxConnectionRate.getOrElse(DynamicConfig.Ip.DefaultConnectionCreationRate)\n+        info(s\"Updating default max IP connection rate to $newQuota\")\n+        defaultConnectionRatePerIp = newQuota\n+        val allMetrics = metrics.metrics\n+        allMetrics.forEach { (metricName, metric) =>\n+          if (isIpConnectionRateMetric(metricName) && shouldUpdateQuota(metric, newQuota)) {\n+            info(s\"Updating existing connection rate sensor for ${metricName.tags} to $newQuota\")\n+            metric.config(rateQuotaMetricConfig(newQuota))\n+          }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjk1MTUzNQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r512951535", "bodyText": "@splett2 Maybe I was not looking at the right place in this PR, but does this PR handles the case if someone sets non-unlimited per IP default quota? Basically, /config/ips/ znode.\nBecause if default is set and it is not unlimited, removing quota for an IP should fall back to configured IP default, and if IP default is not set, then fall back to DynamicConfig.Ip.DefaultConnectionCreationRate. Which I think means that we need to have \"\" ip in the connectionRatePerIp if default is not unlimited, and use it when creating per-IP sensor with the right quota.", "author": "apovzner", "createdAt": "2020-10-27T18:59:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3MzQ5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjMwOTQ4MQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r516309481", "bodyText": "@dajac\ngood catch, we shouldn't be using newQuota here. I agree, this should have been covered by testing, I'll work on adding some more unit tests for the metric config updating.\n@apovzner\nIt should handle that case, yeah.\nIf default is set to some value, when we remove quota for an ip, e.g. updateConnectionRate(Some(ip), None), we remove the connection rate entry from the map and then call getOrDefault(ip, defaultConnectionRatePerIp)which should be whatever the non-unlimited per-IP default quota is.", "author": "splett2", "createdAt": "2020-11-02T22:56:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3MzQ5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3NDQzNg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510874436", "bodyText": "nit: Add . at the end of the sentence.", "author": "dajac", "createdAt": "2020-10-23T13:13:45Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1375,6 +1516,45 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n     }\n   }\n \n+  /**\n+   * To avoid over-recording listener/broker connection rate, we unrecord a listener or broker connection\n+   * if the IP gets throttled later.\n+   *\n+   * @param listenerName listener to unrecord connection\n+   * @param timeMs current time in milliseconds\n+   */\n+  private def unrecordListenerConnection(listenerName: ListenerName, timeMs: Long): Unit = {\n+    if (!protectedListener(listenerName)) {\n+      brokerConnectionRateSensor.record(-1.0, timeMs, false)\n+    }\n+    maxConnectionsPerListener\n+      .get(listenerName)\n+      .foreach(_.connectionRateSensor.record(-1.0, timeMs, false))\n+  }\n+\n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to the IP limit.\n+   * If the connection would cause an IP quota violation, un-record the connection", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3NDc1OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510874758", "bodyText": "nit: To be completed.", "author": "dajac", "createdAt": "2020-10-23T13:14:18Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1375,6 +1516,45 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n     }\n   }\n \n+  /**\n+   * To avoid over-recording listener/broker connection rate, we unrecord a listener or broker connection\n+   * if the IP gets throttled later.\n+   *\n+   * @param listenerName listener to unrecord connection\n+   * @param timeMs current time in milliseconds\n+   */\n+  private def unrecordListenerConnection(listenerName: ListenerName, timeMs: Long): Unit = {\n+    if (!protectedListener(listenerName)) {\n+      brokerConnectionRateSensor.record(-1.0, timeMs, false)\n+    }\n+    maxConnectionsPerListener\n+      .get(listenerName)\n+      .foreach(_.connectionRateSensor.record(-1.0, timeMs, false))\n+  }\n+\n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to the IP limit.\n+   * If the connection would cause an IP quota violation, un-record the connection\n+   *\n+   * @param address\n+   * @param timeMs\n+   * @return", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3NzM4OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510877388", "bodyText": "nit: To be completed.", "author": "dajac", "createdAt": "2020-10-23T13:18:47Z", "path": "core/src/main/scala/kafka/zk/AdminZkClient.scala", "diffHunk": "@@ -384,6 +386,28 @@ class AdminZkClient(zkClient: KafkaZkClient) extends Logging {\n     changeEntityConfig(ConfigType.User, sanitizedEntityName, configs)\n   }\n \n+  /**\n+   * validates the IP configs\n+   * @param ip\n+   * @param configs", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3NzUwOQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510877509", "bodyText": "nit: To be completed.", "author": "dajac", "createdAt": "2020-10-23T13:18:58Z", "path": "core/src/main/scala/kafka/zk/AdminZkClient.scala", "diffHunk": "@@ -384,6 +386,28 @@ class AdminZkClient(zkClient: KafkaZkClient) extends Logging {\n     changeEntityConfig(ConfigType.User, sanitizedEntityName, configs)\n   }\n \n+  /**\n+   * validates the IP configs\n+   * @param ip\n+   * @param configs\n+   */\n+  def validateIpConfig(ip: String, configs: Properties): Unit = {\n+    if (ip != ConfigEntityName.Default && !Utils.validHostPattern(ip))\n+      throw new AdminOperationException(s\"IP $ip is not a valid address.\")\n+    DynamicConfig.Ip.validate(configs)\n+  }\n+\n+  /**\n+   * Update the config for an IP. These overrides will be persisted between sessions, and will override any default\n+   * IP properties.\n+   * @param ip\n+   * @param configs", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3OTE5MQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510879191", "bodyText": "What is 255.255.3.4?", "author": "dajac", "createdAt": "2020-10-23T13:21:36Z", "path": "core/src/test/scala/integration/kafka/network/DynamicConnectionQuotaTest.scala", "diffHunk": "@@ -240,6 +256,16 @@ class DynamicConnectionQuotaTest extends BaseRequestTest {\n       s\"Admin client connection not closed (initial = $initialConnectionCount, current = $connectionCount)\")\n   }\n \n+  private def updateIpConnectionRate(ip: Option[String], updatedRate: Int): Unit = {\n+    adminZkClient.changeIpConfig(ip.getOrElse(ConfigEntityName.Default),\n+      CoreUtils.propsWith(DynamicConfig.Ip.IpConnectionRateOverrideProp, updatedRate.toString))\n+    // use a random throwaway address if ip isn't specified to get the default value\n+    TestUtils.waitUntilTrue(() => servers.head.socketServer.connectionQuotas.\n+      connectionRateForIp(InetAddress.getByName(ip.getOrElse(\"255.255.3.4\"))) == updatedRate,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjMwMTQyMw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r516301423", "bodyText": "This is admittedly a little weird.\nIf None is given as the IP, we want to update the default connection rate.\nTo verify that the default connection rate was updated, we need to call connectionRateForIp with some arbitrary IP address that hasn't been given a specific override. In this case, I used an arbitrary IP, 255.255.3.4 as mentioned in the comment.", "author": "splett2", "createdAt": "2020-11-02T22:42:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3OTE5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg4Mjc3MQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510882771", "bodyText": "It would be great if we could add few more tests to check the dynamic quotas. For instance, we could check the in-memory quota as well as the quota in the metrics for a given IP when there is nothing, when there is a default set, when there is a quota for the IP.\nWe could also add a test to verify that updating the default quota does not change the per-ip quota if it is already set.", "author": "dajac", "createdAt": "2020-10-23T13:27:23Z", "path": "core/src/test/scala/integration/kafka/network/DynamicConnectionQuotaTest.scala", "diffHunk": "@@ -222,14 +222,30 @@ class DynamicConnectionQuotaTest extends BaseRequestTest {\n     reconfigureServers(props, perBrokerConfig = true, (plaintextListenerProp, newPlaintextRateLimit.toString))\n \n     val plaintextFuture = executor.submit((() =>\n-      verifyConnectionRate(10, newPlaintextRateLimit, \"PLAINTEXT\")): Runnable)\n+      verifyConnectionRate(10, newPlaintextRateLimit, \"PLAINTEXT\", ignoreIOExceptions = false)): Runnable)\n     val externalFuture = executor.submit((() =>\n-      verifyConnectionRate(3, listenerConnRateLimit, \"EXTERNAL\")): Runnable)\n+      verifyConnectionRate(3, listenerConnRateLimit, \"EXTERNAL\", ignoreIOExceptions = false)): Runnable)\n+\n     plaintextFuture.get(40, TimeUnit.SECONDS)\n     externalFuture.get(40, TimeUnit.SECONDS)\n     waitForConnectionCount(initialConnectionCount)\n   }\n \n+  @Test", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDkxODI0NA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510918244", "bodyText": "It would be good to add few basic unit tests to verify the basics. Stuff like verifying that the quota is updated in-memory, verifying that the metrics are updated correctly (got caught by this recently), etc.", "author": "dajac", "createdAt": "2020-10-23T14:21:03Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -409,6 +410,96 @@ class ConnectionQuotasTest {\n     verifyConnectionCountOnEveryListener(connectionQuotas, connectionsPerListener)\n   }\n \n+  @Test\n+  def testIpConnectionRateWhenActualRateBelowLimit(): Unit = {\n+    val ipConnectionRateLimit = 30\n+    val connCreateIntervalMs = 40 // connection creation rate = 25/sec\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    val config = KafkaConfig.fromProps(props)\n+    connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+    addListenersAndVerify(config, connectionQuotas)\n+    val externalListener = listeners(\"EXTERNAL\")\n+    connectionQuotas.updateIpConnectionRate(Some(externalListener.defaultIp.getHostAddress), Some(ipConnectionRateLimit))\n+    val numConnections = 200 // should take 8 seconds to create 200 connections with rate = 25/s\n+    // create connections with the rate < ip quota and verify there is no throttling\n+    var future = executor.submit((() => acceptConnections(connectionQuotas, externalListener, numConnections,\n+      connCreateIntervalMs)): Runnable)\n+    future.get(15, TimeUnit.SECONDS)\n+    assertEquals(s\"Number of connections on $externalListener:\",\n+      numConnections, connectionQuotas.get(externalListener.defaultIp))\n+\n+    val adminListener = listeners(\"ADMIN\")\n+    val unthrottledConnectionCreateInterval = 20 // connection creation rate = 50/s, should take 4s for 200 connections\n+    // create connections with an IP with no quota and verify there is no throttling\n+    future = executor.submit((() => acceptConnections(connectionQuotas, adminListener, numConnections,\n+      unthrottledConnectionCreateInterval)): Runnable)\n+    future.get(10, TimeUnit.SECONDS)\n+\n+    assertEquals(s\"Number of connections on $adminListener:\",\n+      numConnections, connectionQuotas.get(adminListener.defaultIp))\n+\n+    // acceptor shouldn't block for IP rate throttling\n+    verifyNoBlockedPercentRecordedOnAllListeners()\n+  }\n+\n+  @Test\n+  def testIpConnectionRateWhenActualRateAboveLimit(): Unit = {\n+    val ipConnectionRateLimit = 20\n+    val connCreateIntervalMs = 25 // connection creation rate = 40/sec\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    val config = KafkaConfig.fromProps(props)\n+    connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+    addListenersAndVerify(config, connectionQuotas)\n+    val externalListener = listeners(\"EXTERNAL\").listenerName\n+    connectionQuotas.updateIpConnectionRate(Some(knownHost.getHostAddress), Some(ipConnectionRateLimit))\n+    // create connections with the rate > ip quota\n+    val numConnections = 200\n+    assertTrue(\"Expected IP to be throttled by overriden IP rate limit\", acceptConnections(connectionQuotas,\n+      externalListener, knownHost, numConnections, connCreateIntervalMs, expectIpThrottle = true))\n+    assertTrue(s\"Number of connections on $externalListener: should be at least the IP rate limit\",\n+      connectionQuotas.get(knownHost) >= ipConnectionRateLimit)\n+\n+    // verify that default quota applies to IPs without a quota override\n+    connectionQuotas.updateIpConnectionRate(None, Some(ipConnectionRateLimit))\n+    val adminListener = listeners(\"ADMIN\").listenerName\n+    assertTrue(\"Expected IP to be throttled by default rate limit\",\n+      acceptConnections(connectionQuotas, adminListener, unknownHost, numConnections, connCreateIntervalMs, expectIpThrottle = true))\n+    assertTrue(s\"Number of connections on $adminListener: should be at least the IP rate limit\",\n+      connectionQuotas.get(unknownHost) >= ipConnectionRateLimit)\n+\n+    // acceptor shouldn't block for IP rate throttling\n+    verifyNoBlockedPercentRecordedOnAllListeners()\n+  }\n+\n+  @Test\n+  def testIpConnectionRateWithListenerConnectionRate(): Unit = {\n+    val ipConnectionRateLimit = 25\n+    val listenerRateLimit = 35\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    val config = KafkaConfig.fromProps(props)\n+    connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+    // with a default per-IP limit of 25 and a listener rate of 30, only one IP should be able to saturate their IP rate\n+    // limit, the other IP will hit listener rate limits and block\n+    connectionQuotas.updateIpConnectionRate(None, Some(ipConnectionRateLimit))\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionCreationRateProp -> listenerRateLimit.toString).asJava\n+    addListenersAndVerify(config, listenerConfig, connectionQuotas)\n+    val listener = listeners(\"EXTERNAL\").listenerName\n+    // use a small number of connections because a longer-running test will have both IPs throttle at different times\n+    val numConnections = 35\n+    val futures = List(\n+      executor.submit((() => acceptConnections(connectionQuotas, listener, knownHost, numConnections,\n+        0, true)): Callable[Boolean]),\n+      executor.submit((() => acceptConnections(connectionQuotas, listener, unknownHost, numConnections,\n+        0, true)): Callable[Boolean])\n+    )\n+\n+    val ipsThrottledResults = futures.map(_.get(3, TimeUnit.SECONDS))\n+    val throttledIps = ipsThrottledResults.filter(identity)\n+    // at most one IP should get IP throttled before the acceptor blocks on listener quota\n+    assertTrue(\"Expected BlockedPercentMeter metric for EXTERNAL listener to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+    assertTrue(\"Expect at most one IP to get throttled\", throttledIps.size < 2)\n+  }\n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDkyMjM2OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510922369", "bodyText": "nit: \".\" at the end.", "author": "dajac", "createdAt": "2020-10-23T14:26:57Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1246,7 +1337,57 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDkyMjc5OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510922798", "bodyText": "nit: . at the end of the sentence.", "author": "dajac", "createdAt": "2020-10-23T14:27:35Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -680,6 +659,46 @@ private[kafka] class Acceptor(val endPoint: EndPoint,\n     serverChannel\n   }\n \n+  /**\n+   * Listen for new connections and assign accepted connections to processors using round-robin", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDkyMzI4NA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510923284", "bodyText": "nit: . at the end.", "author": "dajac", "createdAt": "2020-10-23T14:28:16Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -699,6 +718,31 @@ private[kafka] class Acceptor(val endPoint: EndPoint,\n         info(s\"Rejected connection from ${e.ip}, address already has the configured maximum of ${e.count} connections.\")\n         close(endPoint.listenerName, socketChannel)\n         None\n+      case e: ConnectionThrottledException =>\n+        val ip = socketChannel.socket.getInetAddress\n+        debug(s\"Delaying closing of connection from $ip for ${e.throttleTimeMs} ms\")\n+        val delayQueue = throttledSockets.computeIfAbsent(ip, _ => new mutable.Queue[DelayedCloseSocket])\n+        val endThrottleTimeMs = e.startThrottleTimeMs + e.throttleTimeMs\n+        delayQueue += DelayedCloseSocket(socketChannel, endThrottleTimeMs)\n+        None\n+    }\n+  }\n+\n+  /**\n+   * Close sockets for any connections that have been throttled", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDkyMzk4NQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510923985", "bodyText": "nit: Could we add some doc to explain this trait?", "author": "dajac", "createdAt": "2020-10-23T14:29:18Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1196,6 +1240,41 @@ private[kafka] class Processor(val id: Int,\n   }\n }\n \n+sealed trait ConnectionQuotaEntity {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDkyOTA0MA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510929040", "bodyText": "nit: metricOpt is not really necessary. We could directly put foreach on the line above.", "author": "dajac", "createdAt": "2020-10-23T14:36:45Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1398,33 +1578,33 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n    * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n    * listener or broker-wide, if listener is not provided.\n    * @param quotaLimit connection creation rate quota\n-   * @param listenerOpt listener name if sensor is for a listener\n+   * @param connectionQuotaEntity entity to create the sensor for\n    */\n-  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n-    val sensorName = listenerOpt.map(listener => s\"ConnectionAcceptRate-$listener\").getOrElse(\"ConnectionAcceptRate\")\n-    val sensor = metrics.sensor(sensorName, rateQuotaMetricConfig(quotaLimit))\n-    sensor.add(connectionRateMetricName(listenerOpt), new Rate, null)\n-    info(s\"Created $sensorName sensor, quotaLimit=$quotaLimit\")\n-    sensor\n+  private def getOrCreateConnectionRateQuotaSensor(quotaLimit: Int, connectionQuotaEntity: ConnectionQuotaEntity): Sensor = {\n+    sensorAccessor.getOrCreate(\n+      connectionQuotaEntity.sensorName,\n+      connectionQuotaEntity.sensorExpiration,\n+      sensor => sensor.add(connectionRateMetricName(connectionQuotaEntity), new Rate, rateQuotaMetricConfig(quotaLimit))\n+    )\n   }\n \n   /**\n-   * Updates quota configuration for a given listener or broker-wide (if 'listenerOpt' is None)\n+   * Updates quota configuration for a given connection quota entity\n    */\n-  private def updateConnectionRateQuota(quotaLimit: Int, listenerOpt: Option[String] = None): Unit = {\n-    val metric = metrics.metric(connectionRateMetricName(listenerOpt))\n-    metric.config(rateQuotaMetricConfig(quotaLimit))\n-    info(s\"Updated ${listenerOpt.getOrElse(\"broker-wide\")} max connection creation rate to $quotaLimit\")\n+  private def updateConnectionRateQuota(quotaLimit: Int, connectionQuotaEntity: ConnectionQuotaEntity): Unit = {\n+    val metricOpt = Option(metrics.metric(connectionRateMetricName(connectionQuotaEntity)))\n+    metricOpt.foreach { metric =>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDk0NzgwOA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r510947808", "bodyText": "nit: Could we use MaxConnectionsPerIpProp instead of hardcoding the string?", "author": "dajac", "createdAt": "2020-10-23T15:03:49Z", "path": "core/src/test/scala/unit/kafka/network/SocketServerTest.scala", "diffHunk": "@@ -880,6 +872,72 @@ class SocketServerTest {\n     }\n   }\n \n+  @Test\n+  def testConnectionRatePerIp(): Unit = {\n+    val overrideProps = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    overrideProps.remove(\"max.connections.per.ip\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjkyODgxNQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r512928815", "bodyText": "There are some corner cases here where startThrottleTimeMs could be in the past if waitForConnectionSlot() waited for an active connection slot to become available (if we exceeded the limit for the number of active connections), or waited for broker-wide or listener-wide rate to get back to quota. In some cases, ipThrottleTimeMs would be zero if we checked against the current time here.\nSince getting System.currentTimeMillis() is not that expensive (as it used to be), I think it would be better to revert to waitForConnectionSlot getting its own time (as before this PR), and then recordIpConnectionMaybeThrottle getting current time and also calling the code block below and throwing ConnectionThrottledException. And then adding a comment here that recordIpConnectionMaybeThrottle would throw an exception if per-IP quota is exceeded. What do you think?", "author": "apovzner", "createdAt": "2020-10-27T18:22:18Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1207,14 +1286,26 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private val listenerCounts = mutable.Map[ListenerName, Int]()\n   private[network] val maxConnectionsPerListener = mutable.Map[ListenerName, ListenerConnectionQuota]()\n   @volatile private var totalCount = 0\n-\n+  @volatile private var defaultConnectionRatePerIp = DynamicConfig.Ip.DefaultConnectionCreationRate\n+  private val connectionRatePerIp = new ConcurrentHashMap[InetAddress, Int]()\n+  private val lock = new ReentrantReadWriteLock()\n+  private val sensorAccessor = new SensorAccess(lock, metrics)\n   // sensor that tracks broker-wide connection creation rate and limit (quota)\n-  private val brokerConnectionRateSensor = createConnectionRateQuotaSensor(config.maxConnectionCreationRate)\n+  private val brokerConnectionRateSensor = getOrCreateConnectionRateQuotaSensor(config.maxConnectionCreationRate, BrokerQuotaEntity)\n   private val maxThrottleTimeMs = TimeUnit.SECONDS.toMillis(config.quotaWindowSizeSeconds.toLong)\n \n   def inc(listenerName: ListenerName, address: InetAddress, acceptorBlockedPercentMeter: com.yammer.metrics.core.Meter): Unit = {\n     counts.synchronized {\n-      waitForConnectionSlot(listenerName, acceptorBlockedPercentMeter)\n+      val startThrottleTimeMs = time.milliseconds\n+\n+      waitForConnectionSlot(listenerName, startThrottleTimeMs, acceptorBlockedPercentMeter)\n+\n+      val ipThrottleTimeMs = recordIpConnectionMaybeThrottle(address, startThrottleTimeMs)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NTA4Mw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r516995083", "bodyText": "seems reasonable", "author": "splett2", "createdAt": "2020-11-03T22:34:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjkyODgxNQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "f87e0b52c72a8f093f1d15f21c1322c2067b1444", "url": "https://github.com/apache/kafka/commit/f87e0b52c72a8f093f1d15f21c1322c2067b1444", "message": "Socket server IP throttling and ZK IP entity configs", "committedDate": "2020-11-06T23:27:19Z", "type": "commit"}, {"oid": "3a3b92fbcc2e5e1fa4ce05a6d78d2466d41204c1", "url": "https://github.com/apache/kafka/commit/3a3b92fbcc2e5e1fa4ce05a6d78d2466d41204c1", "message": "fix scala compilation", "committedDate": "2020-11-06T23:27:19Z", "type": "commit"}, {"oid": "3c42d494909b5ff895b6eeabd9d137111b8d0b30", "url": "https://github.com/apache/kafka/commit/3c42d494909b5ff895b6eeabd9d137111b8d0b30", "message": "fix flaky SocketServer test", "committedDate": "2020-11-06T23:27:19Z", "type": "commit"}, {"oid": "0b2cdeaca01dbf453c8b0d5ae468f449b2420cbc", "url": "https://github.com/apache/kafka/commit/0b2cdeaca01dbf453c8b0d5ae468f449b2420cbc", "message": "apply listener/broker throttle before ip throttle, add test for interaction", "committedDate": "2020-11-06T23:27:19Z", "type": "commit"}, {"oid": "55eba6c6268a28e1172e5d48c06296f07668a4f0", "url": "https://github.com/apache/kafka/commit/55eba6c6268a28e1172e5d48c06296f07668a4f0", "message": "address feedback", "committedDate": "2020-11-06T23:27:19Z", "type": "commit"}, {"oid": "0d8408c8fb88441252dda02f449a171f71752122", "url": "https://github.com/apache/kafka/commit/0d8408c8fb88441252dda02f449a171f71752122", "message": "improve test reliability", "committedDate": "2020-11-06T23:27:19Z", "type": "commit"}, {"oid": "bacc407eb4352dde25b9a2dc9ebf88b1714657f0", "url": "https://github.com/apache/kafka/commit/bacc407eb4352dde25b9a2dc9ebf88b1714657f0", "message": "Address feedback", "committedDate": "2020-11-06T23:27:19Z", "type": "commit"}, {"oid": "bacc407eb4352dde25b9a2dc9ebf88b1714657f0", "url": "https://github.com/apache/kafka/commit/bacc407eb4352dde25b9a2dc9ebf88b1714657f0", "message": "Address feedback", "committedDate": "2020-11-06T23:27:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA1NDgyNA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r519054824", "bodyText": "I removed use of sensorAccess, since all calls to sensorAccessor.getOrCreate were performed with the counts lock, so the read-write lock is redundant.", "author": "splett2", "createdAt": "2020-11-06T23:31:13Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1659,19 +1648,22 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n    * @param connectionQuotaEntity entity to create the sensor for\n    */\n   private def getOrCreateConnectionRateQuotaSensor(quotaLimit: Int, connectionQuotaEntity: ConnectionQuotaEntity): Sensor = {\n-    sensorAccessor.getOrCreate(\n-      connectionQuotaEntity.sensorName,\n-      connectionQuotaEntity.sensorExpiration,\n-      sensor => sensor.add(connectionRateMetricName(connectionQuotaEntity), new Rate, rateQuotaMetricConfig(quotaLimit))\n-    )\n+    Option(metrics.getSensor(connectionQuotaEntity.sensorName)).getOrElse {\n+      val sensor = metrics.sensor(\n+        connectionQuotaEntity.sensorName,\n+        rateQuotaMetricConfig(quotaLimit),\n+        connectionQuotaEntity.sensorExpiration\n+      )\n+      sensor.add(connectionRateMetricName(connectionQuotaEntity), new Rate, null)\n+      sensor\n+    }", "originalCommit": "bacc407eb4352dde25b9a2dc9ebf88b1714657f0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e67c8681a06053ed0abc46d6754c7da693835d33", "url": "https://github.com/apache/kafka/commit/e67c8681a06053ed0abc46d6754c7da693835d33", "message": "Synchronize updates to ip quotas, and use unsynchronized map", "committedDate": "2020-11-06T23:33:55Z", "type": "commit"}, {"oid": "e67c8681a06053ed0abc46d6754c7da693835d33", "url": "https://github.com/apache/kafka/commit/e67c8681a06053ed0abc46d6754c7da693835d33", "message": "Synchronize updates to ip quotas, and use unsynchronized map", "committedDate": "2020-11-06T23:33:55Z", "type": "forcePushed"}, {"oid": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "url": "https://github.com/apache/kafka/commit/c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "message": "fix compilation", "committedDate": "2020-11-09T14:59:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM0NDcxOQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521344719", "bodyText": "nit: It is a bit weird to have this case class define in the middle of the block of variables. Would it make sense to move it to another place? May be after the block of variables?", "author": "dajac", "createdAt": "2020-11-11T13:06:09Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -538,14 +542,20 @@ private[kafka] class Acceptor(val endPoint: EndPoint,\n                               val recvBufferSize: Int,\n                               brokerId: Int,\n                               connectionQuotas: ConnectionQuotas,\n-                              metricPrefix: String) extends AbstractServerThread(connectionQuotas) with KafkaMetricsGroup {\n+                              metricPrefix: String,\n+                              time: Time) extends AbstractServerThread(connectionQuotas) with KafkaMetricsGroup {\n \n   private val nioSelector = NSelector.open()\n   val serverChannel = openServerSocket(endPoint.host, endPoint.port)\n   private val processors = new ArrayBuffer[Processor]()\n   private val processorsStarted = new AtomicBoolean\n   private val blockedPercentMeter = newMeter(s\"${metricPrefix}AcceptorBlockedPercent\",\n     \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> endPoint.listenerName.value))\n+  private var currentProcessorIndex = 0\n+  private[network] case class DelayedCloseSocket(socket: SocketChannel, endThrottleTimeMs: Long) extends Ordered[DelayedCloseSocket] {", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM0NjcyMQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521346721", "bodyText": "Out of curiosity, have we considered using a DelayQueue instead of PriorityQueue? I was wondering if that could reduce the logic on our side. I am not sure if it is worth doing it though.", "author": "dajac", "createdAt": "2020-11-11T13:09:55Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -538,14 +542,20 @@ private[kafka] class Acceptor(val endPoint: EndPoint,\n                               val recvBufferSize: Int,\n                               brokerId: Int,\n                               connectionQuotas: ConnectionQuotas,\n-                              metricPrefix: String) extends AbstractServerThread(connectionQuotas) with KafkaMetricsGroup {\n+                              metricPrefix: String,\n+                              time: Time) extends AbstractServerThread(connectionQuotas) with KafkaMetricsGroup {\n \n   private val nioSelector = NSelector.open()\n   val serverChannel = openServerSocket(endPoint.host, endPoint.port)\n   private val processors = new ArrayBuffer[Processor]()\n   private val processorsStarted = new AtomicBoolean\n   private val blockedPercentMeter = newMeter(s\"${metricPrefix}AcceptorBlockedPercent\",\n     \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> endPoint.listenerName.value))\n+  private var currentProcessorIndex = 0\n+  private[network] case class DelayedCloseSocket(socket: SocketChannel, endThrottleTimeMs: Long) extends Ordered[DelayedCloseSocket] {\n+    override def compare(that: DelayedCloseSocket): Int = endThrottleTimeMs compare that.endThrottleTimeMs\n+  }\n+  private[network] val throttledSockets = new mutable.PriorityQueue[DelayedCloseSocket]()", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0OTEyNg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521549126", "bodyText": "I explained elsewhere, but my comment on may have gotten lost in the weeds.\nfor reference:\nI did not use the java DelayQueue similar to the implementation in ClientQuotaManager because this throttling implementation does not use timeout-based polling or require a synchronized data structure, and there's a bit more boilerplate needed for using a DelayQueue.", "author": "splett2", "createdAt": "2020-11-11T18:14:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM0NjcyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTg4ODIwOA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r525888208", "bodyText": "Thanks for the clarification. I have missed that previous comment.", "author": "dajac", "createdAt": "2020-11-18T08:14:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM0NjcyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM0NzE1MQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521347151", "bodyText": "nit: We may want to clear throttledSockets for completeness.", "author": "dajac", "createdAt": "2020-11-11T13:10:47Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -647,9 +624,10 @@ private[kafka] class Acceptor(val endPoint: EndPoint,\n         }\n       }\n     } finally {\n-      debug(\"Closing server socket and selector.\")\n+      debug(\"Closing server socket, selector, and any throttled sockets.\")\n       CoreUtils.swallow(serverChannel.close(), this, Level.ERROR)\n       CoreUtils.swallow(nioSelector.close(), this, Level.ERROR)\n+      throttledSockets.foreach(throttledSocket => closeSocket(throttledSocket.socket))", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM1MzMyMg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521353322", "bodyText": "nit: un-record the connection for both IP, and throw ConnectionThrottledException. It seems that something is missing. Perhaps, you meant for both IP and the listener, and throw ...? We can also add a dot at the end of the sentence.", "author": "dajac", "createdAt": "2020-11-11T13:21:29Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1453,6 +1582,47 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n     }\n   }\n \n+  /**\n+   * To avoid over-recording listener/broker connection rate, we unrecord a listener or broker connection\n+   * if the IP gets throttled later.\n+   *\n+   * @param listenerName listener to unrecord connection\n+   * @param timeMs current time in milliseconds\n+   */\n+  private def unrecordListenerConnection(listenerName: ListenerName, timeMs: Long): Unit = {\n+    if (!protectedListener(listenerName)) {\n+      brokerConnectionRateSensor.record(-1.0, timeMs, false)\n+    }\n+    maxConnectionsPerListener\n+      .get(listenerName)\n+      .foreach(_.connectionRateSensor.record(-1.0, timeMs, false))\n+  }\n+\n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to the IP limit.\n+   * If the connection would cause an IP quota violation, un-record the connection for both IP,\n+   * and throw ConnectionThrottledException", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2OTU1MA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521369550", "bodyText": "What would happen if addr can't be resolved by name? For instance, say that we have 10.0.0.0.1 in ZK or a string which does not represent an IP. It may be worth verifying the IP in the IpConfigHandler. If the ip is not valid, we could handle it properly.", "author": "dajac", "createdAt": "2020-11-11T13:48:21Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1324,7 +1401,59 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required.\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRateQuota(ip: Option[String], maxConnectionRate: Option[Int]): Unit = {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == ConnectionRateMetricName &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(IpMetricTag)\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }\n+    counts.synchronized {\n+      ip match {\n+        case Some(addr) =>\n+          val address = InetAddress.getByName(addr)", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNDUyNw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521614527", "bodyText": "Moved IP resolution to IpConfigHandler.", "author": "splett2", "createdAt": "2020-11-11T20:18:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2OTU1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3NTEwMg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521375102", "bodyText": "I do wonder if synchronizing on counts is a good idea here. When a single IP is updated, that is not an issue. However, we all the metrics are updated, that could take some time depending on the number of metrics. Holding the lock in this case means that we can't accept any new connections until the update is completed. Am I getting this right?", "author": "dajac", "createdAt": "2020-11-11T13:57:10Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1324,7 +1401,59 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required.\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRateQuota(ip: Option[String], maxConnectionRate: Option[Int]): Unit = {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == ConnectionRateMetricName &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(IpMetricTag)\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }\n+    counts.synchronized {", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0NTcxMg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521545712", "bodyText": "yeah, it's undesirable behavior. However, this is in line with ClientQuotaManager.updateQuota, which write locks when updating quota, and also has to iterate over all metrics for any default quota updates.\nI can't think of a good alternative, but I'm open to suggestions.", "author": "splett2", "createdAt": "2020-11-11T18:08:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3NTEwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg1NjQxNw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521856417", "bodyText": "After thinking on this a bit more, I think that only locking on updates to defaultConnectionRatePerIp should be sufficient for correctness.\nZK dynamic config changes are processed within one thread, so we will only have one thread executing in updateIpConnectionRateQuota. If we want to be really careful about this, we can have updateIpConnectionRateQuota synchronized on ConnectionQuotas.\nThe case we want to avoid by synchronizing on counts is that thread 1 reads defaultConnectionRatePerIp as connection rate limit A while calling inc(), then thread 2 updates connection rate and quota metric config to B, then thread 1 resumes execution and creates a sensor/metric with quota limit A => inconsistency.\nIf we synchronize on counts for only updates to connectionRateForIp/defaultConnectionRate, we know that thread 1 that has read a connection rate quota as A will finish creating quota metrics with quota metric config A before thread 2 acquires the counts lock and updates connectionRateForIp/defaultConnectionRate to B.\nAfter thread 2 releases the counts lock, subsequent threads calling inc() will read the quota as B and create a metric as B. Thread 2 can then be able to update any quota metrics from A to B, without holding the counts lock knowing that there are no operations that could have read the default connection rate limit as A without already having finished created the sensor with quota as A, and that all subsequent quotas will be read and created as B.\nThe only issue remaining is that we can get concurrent reads of connectionRatePerIp while updating quota metrics, but we can just replace mutable.Map with ConcurrentHashMap which is preferable to coarsely locking on counts.\nLet me know if I'm missing something here with respect to thread safety.", "author": "splett2", "createdAt": "2020-11-12T05:55:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3NTEwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1OTU4OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r525959588", "bodyText": "Thanks for the explanation, David. I agree with your approach. In the end, we want to ensure that we don't create a Sensor/Metrics while connectionRateForIp/defaultConnectionRate are updated. It think that it is fine to rely counts lock to achieve this but we should add some comments to make this clear. I was considering if we should use a different and more explicit lock to achieve this but I am fine with using counts as long as we add good comments.\nHaving updateIpConnectionRateQuota synchronized on ConnectionQuotas sounds good to me. I think that we have to ensure that metrics are updated by one thread only. Otherwise, we may have inconsistencies.", "author": "dajac", "createdAt": "2020-11-18T10:03:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3NTEwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM2MTI4OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r526361289", "bodyText": "I reviewed the commit with the locking change, and it looks correct to me. Thanks for writing up a thorough evaluation of the new logic. I think using counts as a lock is reasonable here, because we need to synchronize a lot of the same data that is used on the inc() path (protected by counts).  I agree about adding clear comments.", "author": "apovzner", "createdAt": "2020-11-18T19:26:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3NTEwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM4MTc0OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521381748", "bodyText": "As mentioned in a previous comment, it may be worth validating the IP here.", "author": "dajac", "createdAt": "2020-11-11T14:07:50Z", "path": "core/src/main/scala/kafka/server/ConfigHandler.scala", "diffHunk": "@@ -185,6 +186,19 @@ class UserConfigHandler(private val quotaManagers: QuotaManagers, val credential\n   }\n }\n \n+class IpConfigHandler(private val connectionQuotas: ConnectionQuotas) extends ConfigHandler with Logging {\n+\n+  def processConfigChanges(ip: String, config: Properties): Unit = {\n+    val ipConnectionRateQuota = Option(config.getProperty(DynamicConfig.Ip.IpConnectionRateOverrideProp)).map(_.toInt)\n+    val updatedIp =\n+      if (ip != ConfigEntityName.Default)\n+        Some(ip)", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM5NjY1MA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521396650", "bodyText": "nit: Could we break this long line?", "author": "dajac", "createdAt": "2020-11-11T14:29:50Z", "path": "core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala", "diffHunk": "@@ -193,6 +194,64 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {\n     assertEquals(Quota.upperBound(200000),  quotaManagers.fetch.quota(\"ANONYMOUS\", \"overriddenUserClientId\"))\n   }\n \n+  @Test\n+  def testIpQuotaInitialization(): Unit = {\n+    val server = servers.head\n+    val ipOverrideProps = new Properties()\n+    ipOverrideProps.put(DynamicConfig.Ip.IpConnectionRateOverrideProp, \"10\")\n+    val ipDefaultProps = new Properties()\n+    ipDefaultProps.put(DynamicConfig.Ip.IpConnectionRateOverrideProp, \"20\")\n+    server.shutdown()\n+\n+    adminZkClient.changeIpConfig(ConfigEntityName.Default, ipDefaultProps)\n+    adminZkClient.changeIpConfig(\"1.2.3.4\", ipOverrideProps)\n+\n+    // Remove config change znodes to force quota initialization only through loading of ip quotas\n+    zkClient.getChildren(ConfigEntityChangeNotificationZNode.path).foreach { p => zkClient.deletePath(ConfigEntityChangeNotificationZNode.path + \"/\" + p) }", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQwMDI2OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521400268", "bodyText": "This block is somewhat repeated multiple times in the test. How about defining a verifyConnectionQuota helper which verifies the quota of a given IP?", "author": "dajac", "createdAt": "2020-11-11T14:34:50Z", "path": "core/src/test/scala/unit/kafka/server/DynamicConfigChangeTest.scala", "diffHunk": "@@ -193,6 +194,64 @@ class DynamicConfigChangeTest extends KafkaServerTestHarness {\n     assertEquals(Quota.upperBound(200000),  quotaManagers.fetch.quota(\"ANONYMOUS\", \"overriddenUserClientId\"))\n   }\n \n+  @Test\n+  def testIpQuotaInitialization(): Unit = {\n+    val server = servers.head\n+    val ipOverrideProps = new Properties()\n+    ipOverrideProps.put(DynamicConfig.Ip.IpConnectionRateOverrideProp, \"10\")\n+    val ipDefaultProps = new Properties()\n+    ipDefaultProps.put(DynamicConfig.Ip.IpConnectionRateOverrideProp, \"20\")\n+    server.shutdown()\n+\n+    adminZkClient.changeIpConfig(ConfigEntityName.Default, ipDefaultProps)\n+    adminZkClient.changeIpConfig(\"1.2.3.4\", ipOverrideProps)\n+\n+    // Remove config change znodes to force quota initialization only through loading of ip quotas\n+    zkClient.getChildren(ConfigEntityChangeNotificationZNode.path).foreach { p => zkClient.deletePath(ConfigEntityChangeNotificationZNode.path + \"/\" + p) }\n+    server.startup()\n+\n+    val connectionQuotas = server.socketServer.connectionQuotas\n+    assertEquals(10L, connectionQuotas.connectionRateForIp(InetAddress.getByName(\"1.2.3.4\")))\n+    assertEquals(20L, connectionQuotas.connectionRateForIp(InetAddress.getByName(\"2.4.6.8\")))\n+  }\n+\n+  @Test\n+  def testIpQuotaConfigChange(): Unit = {\n+    val ipOverrideProps = new Properties()\n+    ipOverrideProps.put(DynamicConfig.Ip.IpConnectionRateOverrideProp, \"10\")\n+    val ipDefaultProps = new Properties()\n+    ipDefaultProps.put(DynamicConfig.Ip.IpConnectionRateOverrideProp, \"20\")\n+\n+    val overriddenIp = InetAddress.getByName(\"1.2.3.4\")\n+    val defaultQuotaIp = InetAddress.getByName(\"2.3.4.5\")\n+    adminZkClient.changeIpConfig(ConfigEntityName.Default, ipDefaultProps)\n+    adminZkClient.changeIpConfig(overriddenIp.getHostAddress, ipOverrideProps)\n+\n+    val connectionQuotas = servers.head.socketServer.connectionQuotas\n+\n+    TestUtils.retry(10000) {", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQxNDMwNw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521414307", "bodyText": "I wonder if this could be a source of flakiness. If I understand this correctly, it works because all the connections are within the same sample interval (1s). Am I understanding it right? That's probably true most of the time but could be false sometimes, especially on overloaded Jenkins machines. Could we mock the time to avoid this?", "author": "dajac", "createdAt": "2020-11-11T14:55:07Z", "path": "core/src/test/scala/unit/kafka/network/SocketServerTest.scala", "diffHunk": "@@ -880,6 +872,72 @@ class SocketServerTest {\n     }\n   }\n \n+  @Test\n+  def testConnectionRatePerIp(): Unit = {\n+    val overrideProps = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    overrideProps.remove(KafkaConfig.MaxConnectionsPerIpProp)\n+    overrideProps.put(KafkaConfig.NumQuotaSamplesProp, String.valueOf(2))\n+    val connectionRate = 5\n+    val overrideServer = new SocketServer(KafkaConfig.fromProps(overrideProps), new Metrics(), Time.SYSTEM, credentialProvider)\n+    overrideServer.connectionQuotas.updateIpConnectionRateQuota(None, Some(connectionRate))\n+    try {\n+      overrideServer.startup()\n+      // make the maximum allowable number of connections\n+      (0 until connectionRate).map(_ => connect(overrideServer))\n+      // now try one more (should get throttled)\n+      var conn = connect(overrideServer)", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQyMDUyNg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521420526", "bodyText": "Could we verify here that the externalListener still has the correct quota?", "author": "dajac", "createdAt": "2020-11-11T15:04:07Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -477,6 +568,99 @@ class ConnectionQuotasTest {\n     assertTrue(\"Expected BlockedPercentMeter metric for EXTERNAL listener to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n   }\n \n+  @Test\n+  def testIpConnectionRateUpdate(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+    connectionQuotas.addListener(config, listeners(\"EXTERNAL\").listenerName)\n+    connectionQuotas.addListener(config, listeners(\"ADMIN\").listenerName)\n+    connectionQuotas.addListener(config, listeners(\"REPLICATION\").listenerName)\n+    val defaultIpRate = 50\n+    val defaultOverrideRate = 20\n+    val overrideIpRate = 30\n+    val externalListener = listeners(\"EXTERNAL\")\n+    val adminListener = listeners(\"ADMIN\")\n+    // set a non-unlimited default quota so that we create ip rate sensors/metrics\n+    connectionQuotas.updateIpConnectionRateQuota(None, Some(defaultIpRate))\n+    connectionQuotas.inc(externalListener.listenerName, externalListener.defaultIp, blockedPercentMeters(\"EXTERNAL\"))\n+    connectionQuotas.inc(adminListener.listenerName, adminListener.defaultIp, blockedPercentMeters(\"ADMIN\"))\n+\n+    // both IPs should have the default rate\n+    verifyIpConnectionQuota(externalListener.defaultIp, defaultIpRate)\n+    verifyIpConnectionQuota(adminListener.defaultIp, defaultIpRate)\n+\n+    // external listener should have its in-memory quota and metric config updated\n+    connectionQuotas.updateIpConnectionRateQuota(Some(externalListener.defaultIp.getHostAddress), Some(overrideIpRate))\n+    verifyIpConnectionQuota(externalListener.defaultIp, overrideIpRate)\n+\n+    // update default\n+    connectionQuotas.updateIpConnectionRateQuota(None, Some(defaultOverrideRate))\n+\n+    // external listener IP should not have its quota updated to the new default\n+    verifyIpConnectionQuota(externalListener.defaultIp, overrideIpRate)\n+    // admin listener IP should have its quota updated with to the new default\n+    verifyIpConnectionQuota(adminListener.defaultIp, defaultOverrideRate)\n+\n+    // remove default connection rate quota\n+    connectionQuotas.updateIpConnectionRateQuota(None, None)\n+    verifyIpConnectionQuota(adminListener.defaultIp, DynamicConfig.Ip.DefaultConnectionCreationRate)", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQyMDc5Mw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521420793", "bodyText": "It seems that REPLICATION is never used in the test. We may remove it.", "author": "dajac", "createdAt": "2020-11-11T15:04:27Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -477,6 +568,99 @@ class ConnectionQuotasTest {\n     assertTrue(\"Expected BlockedPercentMeter metric for EXTERNAL listener to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n   }\n \n+  @Test\n+  def testIpConnectionRateUpdate(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+    connectionQuotas.addListener(config, listeners(\"EXTERNAL\").listenerName)\n+    connectionQuotas.addListener(config, listeners(\"ADMIN\").listenerName)\n+    connectionQuotas.addListener(config, listeners(\"REPLICATION\").listenerName)", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQyMTc2MA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521421760", "bodyText": "We may find better names for this test and/or the previous one. What is the difference between testIpConnectionRateUpdate and testIpConnectionRateQuotaUpdate?", "author": "dajac", "createdAt": "2020-11-11T15:05:55Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -477,6 +568,99 @@ class ConnectionQuotasTest {\n     assertTrue(\"Expected BlockedPercentMeter metric for EXTERNAL listener to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n   }\n \n+  @Test\n+  def testIpConnectionRateUpdate(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+    connectionQuotas.addListener(config, listeners(\"EXTERNAL\").listenerName)\n+    connectionQuotas.addListener(config, listeners(\"ADMIN\").listenerName)\n+    connectionQuotas.addListener(config, listeners(\"REPLICATION\").listenerName)\n+    val defaultIpRate = 50\n+    val defaultOverrideRate = 20\n+    val overrideIpRate = 30\n+    val externalListener = listeners(\"EXTERNAL\")\n+    val adminListener = listeners(\"ADMIN\")\n+    // set a non-unlimited default quota so that we create ip rate sensors/metrics\n+    connectionQuotas.updateIpConnectionRateQuota(None, Some(defaultIpRate))\n+    connectionQuotas.inc(externalListener.listenerName, externalListener.defaultIp, blockedPercentMeters(\"EXTERNAL\"))\n+    connectionQuotas.inc(adminListener.listenerName, adminListener.defaultIp, blockedPercentMeters(\"ADMIN\"))\n+\n+    // both IPs should have the default rate\n+    verifyIpConnectionQuota(externalListener.defaultIp, defaultIpRate)\n+    verifyIpConnectionQuota(adminListener.defaultIp, defaultIpRate)\n+\n+    // external listener should have its in-memory quota and metric config updated\n+    connectionQuotas.updateIpConnectionRateQuota(Some(externalListener.defaultIp.getHostAddress), Some(overrideIpRate))\n+    verifyIpConnectionQuota(externalListener.defaultIp, overrideIpRate)\n+\n+    // update default\n+    connectionQuotas.updateIpConnectionRateQuota(None, Some(defaultOverrideRate))\n+\n+    // external listener IP should not have its quota updated to the new default\n+    verifyIpConnectionQuota(externalListener.defaultIp, overrideIpRate)\n+    // admin listener IP should have its quota updated with to the new default\n+    verifyIpConnectionQuota(adminListener.defaultIp, defaultOverrideRate)\n+\n+    // remove default connection rate quota\n+    connectionQuotas.updateIpConnectionRateQuota(None, None)\n+    verifyIpConnectionQuota(adminListener.defaultIp, DynamicConfig.Ip.DefaultConnectionCreationRate)\n+\n+    // remove override for external listener IP\n+    connectionQuotas.updateIpConnectionRateQuota(Some(externalListener.defaultIp.getHostAddress), None)\n+    verifyIpConnectionQuota(externalListener.defaultIp, DynamicConfig.Ip.DefaultConnectionCreationRate)\n+  }\n+\n+  @Test\n+  def testIpConnectionRateQuotaUpdate(): Unit = {", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU2NDc3MQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521564771", "bodyText": "I renamed to testIpConnectionRateMetricUpdate and testEnforcedIpConnectionRateQuotaUpdate to clarify.", "author": "splett2", "createdAt": "2020-11-11T18:43:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQyMTc2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQyNDYzMQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521424631", "bodyText": "nit: An empty line could be removed.", "author": "dajac", "createdAt": "2020-11-11T15:10:06Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -477,6 +568,99 @@ class ConnectionQuotasTest {\n     assertTrue(\"Expected BlockedPercentMeter metric for EXTERNAL listener to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n   }\n \n+  @Test\n+  def testIpConnectionRateUpdate(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+    connectionQuotas.addListener(config, listeners(\"EXTERNAL\").listenerName)\n+    connectionQuotas.addListener(config, listeners(\"ADMIN\").listenerName)\n+    connectionQuotas.addListener(config, listeners(\"REPLICATION\").listenerName)\n+    val defaultIpRate = 50\n+    val defaultOverrideRate = 20\n+    val overrideIpRate = 30\n+    val externalListener = listeners(\"EXTERNAL\")\n+    val adminListener = listeners(\"ADMIN\")\n+    // set a non-unlimited default quota so that we create ip rate sensors/metrics\n+    connectionQuotas.updateIpConnectionRateQuota(None, Some(defaultIpRate))\n+    connectionQuotas.inc(externalListener.listenerName, externalListener.defaultIp, blockedPercentMeters(\"EXTERNAL\"))\n+    connectionQuotas.inc(adminListener.listenerName, adminListener.defaultIp, blockedPercentMeters(\"ADMIN\"))\n+\n+    // both IPs should have the default rate\n+    verifyIpConnectionQuota(externalListener.defaultIp, defaultIpRate)\n+    verifyIpConnectionQuota(adminListener.defaultIp, defaultIpRate)\n+\n+    // external listener should have its in-memory quota and metric config updated\n+    connectionQuotas.updateIpConnectionRateQuota(Some(externalListener.defaultIp.getHostAddress), Some(overrideIpRate))\n+    verifyIpConnectionQuota(externalListener.defaultIp, overrideIpRate)\n+\n+    // update default\n+    connectionQuotas.updateIpConnectionRateQuota(None, Some(defaultOverrideRate))\n+\n+    // external listener IP should not have its quota updated to the new default\n+    verifyIpConnectionQuota(externalListener.defaultIp, overrideIpRate)\n+    // admin listener IP should have its quota updated with to the new default\n+    verifyIpConnectionQuota(adminListener.defaultIp, defaultOverrideRate)\n+\n+    // remove default connection rate quota\n+    connectionQuotas.updateIpConnectionRateQuota(None, None)\n+    verifyIpConnectionQuota(adminListener.defaultIp, DynamicConfig.Ip.DefaultConnectionCreationRate)\n+\n+    // remove override for external listener IP\n+    connectionQuotas.updateIpConnectionRateQuota(Some(externalListener.defaultIp.getHostAddress), None)\n+    verifyIpConnectionQuota(externalListener.defaultIp, DynamicConfig.Ip.DefaultConnectionCreationRate)\n+  }\n+\n+  @Test\n+  def testIpConnectionRateQuotaUpdate(): Unit = {\n+    val ipConnectionRateLimit = 20\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    val config = KafkaConfig.fromProps(props)\n+    connectionQuotas = new ConnectionQuotas(config, Time.SYSTEM, metrics)\n+    addListenersAndVerify(config, connectionQuotas)\n+    val externalListener = listeners(\"EXTERNAL\")\n+    connectionQuotas.updateIpConnectionRateQuota(Some(externalListener.defaultIp.getHostAddress), Some(ipConnectionRateLimit))\n+    // create connections with the rate > ip quota\n+    val connectionRate = 40\n+    assertThrows[ConnectionThrottledException] {\n+      acceptConnections(connectionQuotas, externalListener, connectionRate)\n+    }\n+    assertEquals(s\"Number of connections on $externalListener:\",\n+      ipConnectionRateLimit, connectionQuotas.get(externalListener.defaultIp))\n+\n+    // increase ip quota, we should accept connections up to the new quota limit\n+    val updatedRateLimit = 30\n+    connectionQuotas.updateIpConnectionRateQuota(Some(externalListener.defaultIp.getHostAddress), Some(updatedRateLimit))\n+    assertThrows[ConnectionThrottledException] {\n+      acceptConnections(connectionQuotas, externalListener, connectionRate)\n+    }\n+    assertEquals(s\"Number of connections on $externalListener:\",\n+      updatedRateLimit, connectionQuotas.get(externalListener.defaultIp))\n+\n+    // remove IP quota, all connections should get accepted\n+    connectionQuotas.updateIpConnectionRateQuota(Some(externalListener.defaultIp.getHostAddress), None)\n+    acceptConnections(connectionQuotas, externalListener, connectionRate)\n+    assertEquals(s\"Number of connections on $externalListener:\",\n+      connectionRate + updatedRateLimit, connectionQuotas.get(externalListener.defaultIp))\n+\n+    // create connections on a different IP,\n+    val adminListener = listeners(\"ADMIN\")\n+    acceptConnections(connectionQuotas, adminListener, connectionRate)\n+    assertEquals(s\"Number of connections on $adminListener:\",\n+      connectionRate, connectionQuotas.get(adminListener.defaultIp))\n+\n+    // set a default IP quota, verify that quota gets propagated\n+    connectionQuotas.updateIpConnectionRateQuota(None, Some(ipConnectionRateLimit))\n+    assertThrows[ConnectionThrottledException] {\n+      acceptConnections(connectionQuotas, adminListener, connectionRate)\n+    }\n+    assertEquals(s\"Number of connections on $adminListener:\",\n+      connectionRate + ipConnectionRateLimit, connectionQuotas.get(adminListener.defaultIp))\n+\n+", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2NDc1Mg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521464752", "bodyText": "When we hit this line, should we just stopped trying more connections? ipThrottled will remain true regardless.", "author": "dajac", "createdAt": "2020-11-11T16:06:55Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -633,18 +837,27 @@ class ConnectionQuotasTest {\n                                 listenerName: ListenerName,\n                                 address: InetAddress,\n                                 numConnections: Long,\n-                                timeIntervalMs: Long) : Unit = {\n+                                timeIntervalMs: Long,\n+                                expectIpThrottle: Boolean): Boolean = {\n     var nextSendTime = System.currentTimeMillis + timeIntervalMs\n+    var ipThrottled = false\n     for (_ <- 0L until numConnections) {\n       // this method may block if broker-wide or listener limit on the number of connections is reached\n-      connectionQuotas.inc(listenerName, address, blockedPercentMeters(listenerName.value))\n-\n+      try {\n+        connectionQuotas.inc(listenerName, address, blockedPercentMeters(listenerName.value))\n+      } catch {\n+        case e: ConnectionThrottledException =>\n+          if (!expectIpThrottle)\n+            throw e\n+          ipThrottled = true", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzY4MjcxOA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r523682718", "bodyText": "I took a closer look at some of the IP throttling tests, and I think they are a little too coarse-grained with respect to testing the quota rate being enforced. I updated the IP throttling rate above/below tests that don't expect to block to use acceptConnectionsAndVerifyRate with MockTime to verify that the expected quota rate holds while getting throttled.\nIt's a little messy, because a lot of the other tests for broker/listener quotas have to use Time.SYSTEM due to monitor waiting. I think it should also be possible to rewrite the broker/listener connection rate quota tests to use mock time by extending the Time interface, but I would prefer to do that in a follow-up PR.", "author": "splett2", "createdAt": "2020-11-15T03:10:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2NDc1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1NTc4MA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r525955780", "bodyText": "Sounds good. Let's try to clean this up in the follow-up PR.", "author": "dajac", "createdAt": "2020-11-18T09:57:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2NDc1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyODY4OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r526528689", "bodyText": "Thanks. I filed https://issues.apache.org/jira/browse/KAFKA-10744 for the clean up/conversion.", "author": "splett2", "createdAt": "2020-11-19T01:17:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2NDc1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2NzA0Mg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521467042", "bodyText": "Here we say long but it is actually an INT that is defined below.", "author": "dajac", "createdAt": "2020-11-11T16:10:13Z", "path": "core/src/main/scala/kafka/server/DynamicConfig.scala", "diffHunk": "@@ -127,6 +127,22 @@ object DynamicConfig {\n     def validate(props: Properties) = DynamicConfig.validate(userConfigs, props, customPropsAllowed = false)\n   }\n \n+  object Ip {\n+    val IpConnectionRateOverrideProp = \"connection_creation_rate\"\n+    val UnlimitedConnectionCreationRate = Int.MaxValue\n+    val DefaultConnectionCreationRate = UnlimitedConnectionCreationRate\n+    val IpOverrideDoc = \"A long representing the upper bound of connections accepted for the specified IP.\"", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ2OTk4OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r521469989", "bodyText": "It seems that we don't have any unit tests which exercise this un-recording logic. I wonder if we could add a unit test that verifies that the listener rate does not change when a connection is rejected due to violating the per-ip quota or something along these lines.", "author": "dajac", "createdAt": "2020-11-11T16:14:41Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1453,6 +1582,47 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n     }\n   }\n \n+  /**\n+   * To avoid over-recording listener/broker connection rate, we unrecord a listener or broker connection\n+   * if the IP gets throttled later.\n+   *\n+   * @param listenerName listener to unrecord connection\n+   * @param timeMs current time in milliseconds\n+   */\n+  private def unrecordListenerConnection(listenerName: ListenerName, timeMs: Long): Unit = {\n+    if (!protectedListener(listenerName)) {\n+      brokerConnectionRateSensor.record(-1.0, timeMs, false)\n+    }\n+    maxConnectionsPerListener\n+      .get(listenerName)\n+      .foreach(_.connectionRateSensor.record(-1.0, timeMs, false))\n+  }\n+\n+  /**\n+   * Calculates the delay needed to bring the observed connection creation rate to the IP limit.\n+   * If the connection would cause an IP quota violation, un-record the connection for both IP,\n+   * and throw ConnectionThrottledException\n+   *\n+   * @param listenerName listener to unrecord connection if throttled\n+   * @param address ip address to record connection\n+   */\n+  private def recordIpConnectionMaybeThrottle(listenerName: ListenerName, address: InetAddress): Unit = {\n+    val connectionRateQuota = connectionRateForIp(address)\n+    val quotaEnabled = connectionRateQuota != DynamicConfig.Ip.UnlimitedConnectionCreationRate\n+    if (quotaEnabled) {\n+      val sensor = getOrCreateConnectionRateQuotaSensor(connectionRateQuota, IpQuotaEntity(address))\n+      val timeMs = time.milliseconds\n+      val throttleMs = recordAndGetThrottleTimeMs(sensor, timeMs)\n+      if (throttleMs > 0) {\n+        trace(s\"Throttling $address for $throttleMs ms\")\n+        // unrecord the connection since we won't accept the connection\n+        sensor.record(-1.0, timeMs, false)\n+        unrecordListenerConnection(listenerName, timeMs)", "originalCommit": "c8da17f3adf7ccfbb6df4b19918982d7bb8cdb05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2b9b71980c489dd8b871ef7e3b614de399049fac", "url": "https://github.com/apache/kafka/commit/2b9b71980c489dd8b871ef7e3b614de399049fac", "message": "Address feedback", "committedDate": "2020-11-11T20:18:22Z", "type": "commit"}, {"oid": "c882dbf31738287626f675429f209a1b53a6fb6d", "url": "https://github.com/apache/kafka/commit/c882dbf31738287626f675429f209a1b53a6fb6d", "message": "finer-grained locking on  in updateIpConnectionRateQuota", "committedDate": "2020-11-12T06:23:43Z", "type": "commit"}, {"oid": "3eb0bdb44360f3faebf9b3217d968b0f5985fef3", "url": "https://github.com/apache/kafka/commit/3eb0bdb44360f3faebf9b3217d968b0f5985fef3", "message": "use hostAddress in sensor name for consistency", "committedDate": "2020-11-14T17:20:52Z", "type": "commit"}, {"oid": "75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "url": "https://github.com/apache/kafka/commit/75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "message": "update ip quota tests to use MockTime and update testIpConnectionRateAbove/Below to verify rate", "committedDate": "2020-11-15T04:07:27Z", "type": "commit"}, {"oid": "75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "url": "https://github.com/apache/kafka/commit/75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "message": "update ip quota tests to use MockTime and update testIpConnectionRateAbove/Below to verify rate", "committedDate": "2020-11-15T04:07:27Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk0OTY1NQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r525949655", "bodyText": "nit: Could we add an empty line after this one?", "author": "dajac", "createdAt": "2020-11-18T09:48:53Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1324,7 +1404,60 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required.\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRateQuota(ip: Option[InetAddress], maxConnectionRate: Option[Int]): Unit = synchronized {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == ConnectionRateMetricName &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(IpMetricTag)\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }", "originalCommit": "75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1MDQ5OA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r525950498", "bodyText": "It would be great to add a comment here explaining why we do this. As connectionRatePerIp is a ConcurrentMap, it is not obvious.", "author": "dajac", "createdAt": "2020-11-18T09:50:02Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1324,7 +1404,60 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required.\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRateQuota(ip: Option[InetAddress], maxConnectionRate: Option[Int]): Unit = synchronized {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == ConnectionRateMetricName &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(IpMetricTag)\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }\n+    ip match {\n+      case Some(address) =>\n+        counts.synchronized {", "originalCommit": "75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1MDY2NA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r525950664", "bodyText": "We could also add a similar comment here.", "author": "dajac", "createdAt": "2020-11-18T09:50:17Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1324,7 +1404,60 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required.\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRateQuota(ip: Option[InetAddress], maxConnectionRate: Option[Int]): Unit = synchronized {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == ConnectionRateMetricName &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(IpMetricTag)\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }\n+    ip match {\n+      case Some(address) =>\n+        counts.synchronized {\n+          maxConnectionRate match {\n+            case Some(rate) =>\n+              info(s\"Updating max connection rate override for $address to $rate\")\n+              connectionRatePerIp.put(address, rate)\n+            case None =>\n+              info(s\"Removing max connection rate override for $address\")\n+              connectionRatePerIp.remove(address)\n+          }\n+        }\n+        updateConnectionRateQuota(connectionRateForIp(address), IpQuotaEntity(address))\n+      case None =>\n+        counts.synchronized {", "originalCommit": "75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1Mjk0Mw==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r525952943", "bodyText": "It may be better to keep IP as string in connectionRateForIp in order to avoid having to resolve them when we update the metrics. I don't see any reason to InetAddress internally. Is there any? InetAddress.getByName seems sufficient when we validate the configuration in the config handler.", "author": "dajac", "createdAt": "2020-11-18T09:53:35Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1324,7 +1404,60 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n   private[network] def updateBrokerMaxConnectionRate(maxConnectionRate: Int): Unit = {\n     // if there is a connection waiting on the rate throttle delay, we will let it wait the original delay even if\n     // the rate limit increases, because it is just one connection per listener and the code is simpler that way\n-    updateConnectionRateQuota(maxConnectionRate)\n+    updateConnectionRateQuota(maxConnectionRate, BrokerQuotaEntity)\n+  }\n+\n+  /**\n+   * Update the connection rate quota for a given IP and updates quota configs for updated IPs.\n+   * If an IP is given, metric config will be updated only for the given IP, otherwise\n+   * all metric configs will be checked and updated if required.\n+   *\n+   * @param ip ip to update or default if None\n+   * @param maxConnectionRate new connection rate, or resets entity to default if None\n+   */\n+  def updateIpConnectionRateQuota(ip: Option[InetAddress], maxConnectionRate: Option[Int]): Unit = synchronized {\n+    def isIpConnectionRateMetric(metricName: MetricName) = {\n+      metricName.name == ConnectionRateMetricName &&\n+      metricName.group == MetricsGroup &&\n+      metricName.tags.containsKey(IpMetricTag)\n+    }\n+\n+    def shouldUpdateQuota(metric: KafkaMetric, quotaLimit: Int) = {\n+      quotaLimit != metric.config.quota.bound\n+    }\n+    ip match {\n+      case Some(address) =>\n+        counts.synchronized {\n+          maxConnectionRate match {\n+            case Some(rate) =>\n+              info(s\"Updating max connection rate override for $address to $rate\")\n+              connectionRatePerIp.put(address, rate)\n+            case None =>\n+              info(s\"Removing max connection rate override for $address\")\n+              connectionRatePerIp.remove(address)\n+          }\n+        }\n+        updateConnectionRateQuota(connectionRateForIp(address), IpQuotaEntity(address))\n+      case None =>\n+        counts.synchronized {\n+          defaultConnectionRatePerIp = maxConnectionRate.getOrElse(DynamicConfig.Ip.DefaultConnectionCreationRate)\n+        }\n+        info(s\"Updated default max IP connection rate to $defaultConnectionRatePerIp\")\n+        metrics.metrics.forEach { (metricName, metric) =>\n+          if (isIpConnectionRateMetric(metricName)) {\n+            val quota = connectionRateForIp(InetAddress.getByName(metricName.tags.get(IpMetricTag)))", "originalCommit": "75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzAwMA==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r526527000", "bodyText": "reasons for using InetAddress would be that it's more consistent with the other IP-related data structures in ConnectionQuotas, maxConnectionsPerIpOverrides and counts.\nadditionally, inc() is called with an InetAddress, so it's convenient to keep our data structure using InetAddress as a key so that we don't need to convert InetAddress => String in cases where we would not create a sensor (e.g., when IP quotas are disabled).", "author": "splett2", "createdAt": "2020-11-19T01:12:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1Mjk0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjcyOTI2OQ==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r526729269", "bodyText": "Make sense, thanks.", "author": "dajac", "createdAt": "2020-11-19T09:52:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1Mjk0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1MzY2Ng==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r525953666", "bodyText": "Could we also add a comment here which states that we don't explicitly protect this section because we hold the counts lock.", "author": "dajac", "createdAt": "2020-11-18T09:54:39Z", "path": "core/src/main/scala/kafka/network/SocketServer.scala", "diffHunk": "@@ -1476,33 +1650,36 @@ class ConnectionQuotas(config: KafkaConfig, time: Time, metrics: Metrics) extend\n    * Creates sensor for tracking the connection creation rate and corresponding connection rate quota for a given\n    * listener or broker-wide, if listener is not provided.\n    * @param quotaLimit connection creation rate quota\n-   * @param listenerOpt listener name if sensor is for a listener\n+   * @param connectionQuotaEntity entity to create the sensor for\n    */\n-  private def createConnectionRateQuotaSensor(quotaLimit: Int, listenerOpt: Option[String] = None): Sensor = {\n-    val sensorName = listenerOpt.map(listener => s\"ConnectionAcceptRate-$listener\").getOrElse(\"ConnectionAcceptRate\")\n-    val sensor = metrics.sensor(sensorName, rateQuotaMetricConfig(quotaLimit))\n-    sensor.add(connectionRateMetricName(listenerOpt), new Rate, null)\n-    info(s\"Created $sensorName sensor, quotaLimit=$quotaLimit\")\n-    sensor\n+  private def getOrCreateConnectionRateQuotaSensor(quotaLimit: Int, connectionQuotaEntity: ConnectionQuotaEntity): Sensor = {\n+    Option(metrics.getSensor(connectionQuotaEntity.sensorName)).getOrElse {", "originalCommit": "75a1873ad004dd4356ec9c21af69615fa0c1e3a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNTIxMg==", "url": "https://github.com/apache/kafka/pull/9386#discussion_r526525212", "bodyText": "I will add this detail to recordIpConnectionMaybeThrottle. I think that is a more fitting place to put the comment, since that's the section of code that calls connectionRateForIp and getOrCreateConnectionRateQuotaSensor which are the components we need to be atomic.", "author": "splett2", "createdAt": "2020-11-19T01:06:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk1MzY2Ng=="}], "type": "inlineReview"}, {"oid": "156149090a3ff4bd6394dbc8432d2747e518d1d8", "url": "https://github.com/apache/kafka/commit/156149090a3ff4bd6394dbc8432d2747e518d1d8", "message": "comments for IP connection rate quota locking", "committedDate": "2020-11-19T01:19:35Z", "type": "commit"}]}