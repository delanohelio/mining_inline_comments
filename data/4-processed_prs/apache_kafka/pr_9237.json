{"pr_number": 9237, "pr_title": "KAFKA-10454 / Update copartitionSourceGroups when optimization algorithm is triggered", "pr_createdAt": "2020-09-01T09:37:59Z", "pr_url": "https://github.com/apache/kafka/pull/9237", "timeline": [{"oid": "7a23c6922ad6f1623c8a04ddde99c0ae1862f527", "url": "https://github.com/apache/kafka/commit/7a23c6922ad6f1623c8a04ddde99c0ae1862f527", "message": "KAFKA-10454 / integration test", "committedDate": "2020-09-01T09:37:06Z", "type": "commit"}, {"oid": "6f0ce0198458fa0bbf74c64c2020151acfa98447", "url": "https://github.com/apache/kafka/commit/6f0ce0198458fa0bbf74c64c2020151acfa98447", "message": "KAFKA-10454 / Fix copartition sources when topology optimization is triggered", "committedDate": "2020-09-09T19:46:39Z", "type": "commit"}, {"oid": "ec84a86fce571219696a2351724bc652c4db7311", "url": "https://github.com/apache/kafka/commit/ec84a86fce571219696a2351724bc652c4db7311", "message": "KAFKA-10454 / revert some changes", "committedDate": "2020-09-09T19:50:01Z", "type": "commit"}, {"oid": "ac26e58942ddeeed9e66fea3c7b5b53bb6aab143", "url": "https://github.com/apache/kafka/commit/ac26e58942ddeeed9e66fea3c7b5b53bb6aab143", "message": "KAFKA-10454 / remove extra line", "committedDate": "2020-09-09T19:51:14Z", "type": "commit"}, {"oid": "e61f2eaba369bcc1b4da8991b5ce22c45fba16fb", "url": "https://github.com/apache/kafka/commit/e61f2eaba369bcc1b4da8991b5ce22c45fba16fb", "message": "KAFKA-10454 / fix checkstyle", "committedDate": "2020-09-09T19:58:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTg4NTg5OA==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r485885898", "bodyText": "I'm not really sure what the threading model is when building the topology, but chose to be safe and made all the accessors synchronized.", "author": "lkokhreidze", "createdAt": "2020-09-09T19:58:54Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -632,8 +632,18 @@ public final void addInternalTopic(final String topicName,\n         internalTopicNamesWithProperties.put(topicName, internalTopicProperties);\n     }\n \n-    public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+    public final synchronized void copartitionSources(final Collection<String> sourceNodes) {\n+        copartitionSourceGroups.add(new HashSet<>(sourceNodes));\n+    }\n+\n+    public final synchronized void maybeUpdateCopartitionSourceGroups(final String replacedNodeName,", "originalCommit": "ac26e58942ddeeed9e66fea3c7b5b53bb6aab143", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTg4NjQyMw==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r485886423", "bodyText": "There's already another StreamTableIntegrationTest present, but it works with TopologyTestDriver so I thought it would be better and easier to keep them separate.", "author": "lkokhreidze", "createdAt": "2020-09-09T19:59:38Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamTableJoinTopologyOptimizationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.TopicDescription;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(value = Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class StreamTableJoinTopologyOptimizationIntegrationTest {", "originalCommit": "ac26e58942ddeeed9e66fea3c7b5b53bb6aab143", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "203cbc6f60926e3e169c2c81defb681ca2c49f1e", "url": "https://github.com/apache/kafka/commit/203cbc6f60926e3e169c2c81defb681ca2c49f1e", "message": "KAFKA-10454 / fix test checkstyle", "committedDate": "2020-09-09T20:04:41Z", "type": "commit"}, {"oid": "3ab1e18e5d0a57206ef3fbbcbc376aca0103eebe", "url": "https://github.com/apache/kafka/commit/3ab1e18e5d0a57206ef3fbbcbc376aca0103eebe", "message": "KAFKA-10454 / make validateCopartition synchronized", "committedDate": "2020-09-09T20:27:50Z", "type": "commit"}, {"oid": "b3365f2c046a839101288a0e56be2f73423bf6b4", "url": "https://github.com/apache/kafka/commit/b3365f2c046a839101288a0e56be2f73423bf6b4", "message": "Merge branch 'trunk' into KAFKA-10454", "committedDate": "2020-09-14T10:26:29Z", "type": "commit"}, {"oid": "36ec38bd292d8b0b139c15c69392542eef3e438b", "url": "https://github.com/apache/kafka/commit/36ec38bd292d8b0b139c15c69392542eef3e438b", "message": "Merge branch 'trunk' into KAFKA-10454", "committedDate": "2020-09-22T07:31:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg0NjM3OQ==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r497846379", "bodyText": "building a topology is done on the main thread when calling StreamBuilder.build() so I think it's safe to remove synchronized.", "author": "bbejeck", "createdAt": "2020-09-30T22:58:20Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -632,11 +632,21 @@ public final void addInternalTopic(final String topicName,\n         internalTopicNamesWithProperties.put(topicName, internalTopicProperties);\n     }\n \n-    public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+    public final synchronized void copartitionSources(final Collection<String> sourceNodes) {", "originalCommit": "36ec38bd292d8b0b139c15c69392542eef3e438b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM4MzY5Ng==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r498383696", "bodyText": "Thanks for confirming, removed synchronized.", "author": "lkokhreidze", "createdAt": "2020-10-01T16:47:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg0NjM3OQ=="}], "type": "inlineReview"}, {"oid": "1ad0a87d45177a1f36a141f841848f4825832597", "url": "https://github.com/apache/kafka/commit/1ad0a87d45177a1f36a141f841848f4825832597", "message": "Merge branch 'trunk' into KAFKA-10454", "committedDate": "2020-10-01T16:32:30Z", "type": "commit"}, {"oid": "a6eb3686facb4acc705ca7932f8eb5fc28548619", "url": "https://github.com/apache/kafka/commit/a6eb3686facb4acc705ca7932f8eb5fc28548619", "message": "KAFKA-10454 / remove synchronized", "committedDate": "2020-10-01T16:47:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY3MDc5OQ==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r499670799", "bodyText": "nit: I think we can remove synchronized here as well", "author": "bbejeck", "createdAt": "2020-10-05T15:08:37Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,10 +633,20 @@ public final void addInternalTopic(final String topicName,\n     }\n \n     public final void copartitionSources(final Collection<String> sourceNodes) {\n-        copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n+        copartitionSourceGroups.add(new HashSet<>(sourceNodes));\n     }\n \n-    public void validateCopartition() {\n+    public final void maybeUpdateCopartitionSourceGroups(final String replacedNodeName,\n+                                                         final String optimizedNodeName) {\n+        for (final Set<String> copartitionSourceGroup : copartitionSourceGroups) {\n+            if (copartitionSourceGroup.contains(replacedNodeName)) {\n+                copartitionSourceGroup.remove(replacedNodeName);\n+                copartitionSourceGroup.add(optimizedNodeName);\n+            }\n+        }\n+    }\n+\n+    public synchronized void validateCopartition() {", "originalCommit": "a6eb3686facb4acc705ca7932f8eb5fc28548619", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY5MTExMg==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r499691112", "bodyText": "Sorry, somehow missed this one. On it.", "author": "lkokhreidze", "createdAt": "2020-10-05T15:37:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY3MDc5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY5MjA4Mw==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r499692083", "bodyText": "Done.", "author": "lkokhreidze", "createdAt": "2020-10-05T15:38:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTY3MDc5OQ=="}], "type": "inlineReview"}, {"oid": "66366e4b98b60dabf4e477a32aae8ca88a33f508", "url": "https://github.com/apache/kafka/commit/66366e4b98b60dabf4e477a32aae8ca88a33f508", "message": "KAFKA-10454 / remove synchronized from validateCopartition", "committedDate": "2020-10-05T15:37:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwODc1Mw==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r499908753", "bodyText": "super nit: I missed this before, but the last statement could be an else", "author": "bbejeck", "createdAt": "2020-10-05T22:34:46Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamTableJoinTopologyOptimizationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.AdminClientConfig;\n+import org.apache.kafka.clients.admin.TopicDescription;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.IntegerDeserializer;\n+import org.apache.kafka.common.serialization.IntegerSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(value = Parameterized.class)\n+@Category({IntegrationTest.class})\n+public class StreamTableJoinTopologyOptimizationIntegrationTest {\n+    private static final int NUM_BROKERS = 1;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(NUM_BROKERS);\n+\n+    private String tableTopic;\n+    private String inputTopic;\n+    private String outputTopic;\n+    private String applicationId;\n+\n+    private Properties streamsConfiguration;\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    @Parameterized.Parameter\n+    public String topologyOptimization;\n+\n+    @Parameterized.Parameters(name = \"Optimization = {0}\")\n+    public static Collection<?> topologyOptimization() {\n+        return Arrays.asList(new String[][]{\n+            {StreamsConfig.OPTIMIZE},\n+            {StreamsConfig.NO_OPTIMIZATION}\n+        });\n+    }\n+\n+    @Before\n+    public void before() throws InterruptedException {\n+        streamsConfiguration = new Properties();\n+\n+        final String safeTestName = safeUniqueTestName(getClass(), testName);\n+\n+        tableTopic = \"table-topic\" + safeTestName;\n+        inputTopic = \"stream-topic-\" + safeTestName;\n+        outputTopic = \"output-topic-\" + safeTestName;\n+        applicationId = \"app-\" + safeTestName;\n+\n+        CLUSTER.createTopic(inputTopic, 4, 1);\n+        CLUSTER.createTopic(tableTopic, 2, 1);\n+        CLUSTER.createTopic(outputTopic, 4, 1);\n+\n+        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, applicationId);\n+        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers());\n+        streamsConfiguration.put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+        streamsConfiguration.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);\n+        streamsConfiguration.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n+        streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n+        streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());\n+        streamsConfiguration.put(StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG, topologyOptimization);\n+    }\n+\n+    @After\n+    public void whenShuttingDown() throws IOException {\n+        IntegrationTestUtils.purgeLocalStreamsState(streamsConfiguration);\n+    }\n+\n+    @Test\n+    public void shouldDoStreamTableJoinWithDifferentNumberOfPartitions() throws Exception {\n+        final String storeName = \"store\";\n+        final String selectKeyName = \"selectKey\";\n+\n+        final StreamsBuilder streamsBuilder = new StreamsBuilder();\n+\n+        final KStream<Integer, String> stream = streamsBuilder.stream(inputTopic);\n+        final KTable<Integer, String> table = streamsBuilder.table(tableTopic, Materialized.as(storeName));\n+\n+        stream\n+            .selectKey((key, value) -> key, Named.as(selectKeyName))\n+            .join(table, (value1, value2) -> value2)\n+            .to(outputTopic);\n+\n+        startStreams(streamsBuilder);\n+\n+        final long timestamp = System.currentTimeMillis();\n+\n+        final List<KeyValue<Integer, String>> expectedRecords = Arrays.asList(\n+            new KeyValue<>(1, \"A\"),\n+            new KeyValue<>(2, \"B\")\n+        );\n+\n+        sendEvents(inputTopic, timestamp, expectedRecords);\n+        sendEvents(outputTopic, timestamp, expectedRecords);\n+\n+        startStreams(streamsBuilder);\n+\n+        validateReceivedMessages(\n+            outputTopic,\n+            new IntegerDeserializer(),\n+            new StringDeserializer(),\n+            expectedRecords\n+        );\n+\n+        final Set<String> allTopicsInCluster = CLUSTER.getAllTopicsInCluster();\n+\n+        final String repartitionTopicName = applicationId + \"-\" + selectKeyName + \"-repartition\";\n+        final String tableChangelogStoreName = applicationId + \"-\" + storeName + \"-changelog\";\n+\n+        assertTrue(topicExists(repartitionTopicName));\n+        assertEquals(2, getNumberOfPartitionsForTopic(repartitionTopicName));\n+\n+        if (StreamsConfig.OPTIMIZE.equals(topologyOptimization)) {\n+            assertFalse(allTopicsInCluster.contains(tableChangelogStoreName));\n+        } else if (StreamsConfig.NO_OPTIMIZATION.equals(topologyOptimization)) {", "originalCommit": "66366e4b98b60dabf4e477a32aae8ca88a33f508", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDAyMzg0NA==", "url": "https://github.com/apache/kafka/pull/9237#discussion_r500023844", "bodyText": "I did it on purpose. Potentially there can be some changes regarding those values and felt like being explicit on what is being tested would be better.", "author": "lkokhreidze", "createdAt": "2020-10-06T06:02:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwODc1Mw=="}], "type": "inlineReview"}]}