{"pr_number": 8702, "pr_title": "MINOR: Fix join group request timeout lower bound", "pr_createdAt": "2020-05-21T00:56:02Z", "pr_url": "https://github.com/apache/kafka/pull/8702", "timeline": [{"oid": "6db0ec91706286f52b0159d66122c5df46524d89", "url": "https://github.com/apache/kafka/commit/6db0ec91706286f52b0159d66122c5df46524d89", "message": "MINOR: Fix join group request timeout lower bound", "committedDate": "2020-05-21T00:55:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM4OTkyOQ==", "url": "https://github.com/apache/kafka/pull/8702#discussion_r428389929", "bodyText": "The previous max check was wrong, but an alternative here is to use rebalanceTimeout + 5s in all cases regardless of the request timeout.", "author": "hachikuji", "createdAt": "2020-05-21T01:01:30Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java", "diffHunk": "@@ -565,8 +566,8 @@ private void recordRebalanceFailure() {\n \n         // Note that we override the request timeout using the rebalance timeout since that is the\n         // maximum time that it may block on the coordinator. We add an extra 5 seconds for small delays.\n-\n-        int joinGroupTimeoutMs = Math.max(rebalanceConfig.rebalanceTimeoutMs, rebalanceConfig.rebalanceTimeoutMs + 5000);\n+        int joinGroupTimeoutMs = Math.max(client.defaultRequestTimeoutMs(),", "originalCommit": "6db0ec91706286f52b0159d66122c5df46524d89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODk4NjczOQ==", "url": "https://github.com/apache/kafka/pull/8702#discussion_r428986739", "bodyText": "Could we log a debug info here for the timeout we used?", "author": "abbccdda", "createdAt": "2020-05-22T00:42:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM4OTkyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyNTMyNQ==", "url": "https://github.com/apache/kafka/pull/8702#discussion_r429325325", "bodyText": "I added the request timeout to the send message in NetworkClient. Also made some tweaks for more consistent logging.", "author": "hachikuji", "createdAt": "2020-05-22T15:49:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM4OTkyOQ=="}], "type": "inlineReview"}, {"oid": "92f5fab9e8c4e482a7a8164d5116256f0638c22a", "url": "https://github.com/apache/kafka/commit/92f5fab9e8c4e482a7a8164d5116256f0638c22a", "message": "Fix checkstyle", "committedDate": "2020-05-21T01:17:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODk4NzQ0NA==", "url": "https://github.com/apache/kafka/pull/8702#discussion_r428987444", "bodyText": "We could just test mockTime.sleep(REQUEST_TIMEOUT_MS + 1) for this case and get rid of expectedRequestDeadline", "author": "abbccdda", "createdAt": "2020-05-22T00:45:00Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinatorTest.java", "diffHunk": "@@ -312,8 +313,27 @@ public void testJoinGroupRequestTimeout() {\n         mockTime.sleep(REQUEST_TIMEOUT_MS + 1);\n         assertFalse(consumerClient.poll(future, mockTime.timer(0)));\n \n-        mockTime.sleep(REBALANCE_TIMEOUT_MS - REQUEST_TIMEOUT_MS + 5000);\n+        mockTime.sleep(REBALANCE_TIMEOUT_MS - REQUEST_TIMEOUT_MS + AbstractCoordinator.JOIN_GROUP_TIMEOUT_LAPSE);\n         assertTrue(consumerClient.poll(future, mockTime.timer(0)));\n+        assertTrue(future.exception() instanceof DisconnectException);\n+    }\n+\n+    @Test\n+    public void testJoinGroupRequestTimeoutLowerBoundedByDefaultRequestTimeout() {\n+        int rebalanceTimeoutMs = REQUEST_TIMEOUT_MS - 10000;\n+        setupCoordinator(RETRY_BACKOFF_MS, rebalanceTimeoutMs, Optional.empty());\n+        mockClient.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));\n+        coordinator.ensureCoordinatorReady(mockTime.timer(0));\n+\n+        RequestFuture<ByteBuffer> future = coordinator.sendJoinGroupRequest();\n+\n+        long expectedRequestDeadline = mockTime.milliseconds() + REQUEST_TIMEOUT_MS;\n+        mockTime.sleep(rebalanceTimeoutMs + AbstractCoordinator.JOIN_GROUP_TIMEOUT_LAPSE + 1);\n+        assertFalse(consumerClient.poll(future, mockTime.timer(0)));\n+\n+        mockTime.sleep(expectedRequestDeadline - mockTime.milliseconds() + 1);", "originalCommit": "92f5fab9e8c4e482a7a8164d5116256f0638c22a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyODQxNg==", "url": "https://github.com/apache/kafka/pull/8702#discussion_r429328416", "bodyText": "We need to take into account the time that has already passed. I was a little annoyed at having to write REQUEST_TIMEOUT - rebalanceTimeoutMs - AbstractCoordinator.JOIN_GROUP_TIMEOUT_LAPSE. A bit annoying either way I guess.", "author": "hachikuji", "createdAt": "2020-05-22T15:55:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODk4NzQ0NA=="}], "type": "inlineReview"}, {"oid": "023302f48c3e2b1da07af111f8077d2f84cb466f", "url": "https://github.com/apache/kafka/commit/023302f48c3e2b1da07af111f8077d2f84cb466f", "message": "Consistent request/response logging", "committedDate": "2020-05-22T15:48:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyNzQ0Mw==", "url": "https://github.com/apache/kafka/pull/8702#discussion_r429327443", "bodyText": "Given that we have to work with all client versions, it's just as common for the client not to match the broker version, so it's not really useful for the behavior to be different when they do match.", "author": "hachikuji", "createdAt": "2020-05-22T15:53:21Z", "path": "clients/src/main/java/org/apache/kafka/clients/NetworkClient.java", "diffHunk": "@@ -502,14 +502,8 @@ private void doSend(ClientRequest clientRequest, boolean isInternalRequest, long\n         String destination = clientRequest.destination();\n         RequestHeader header = clientRequest.makeHeader(request.version());\n         if (log.isDebugEnabled()) {\n-            int latestClientVersion = clientRequest.apiKey().latestVersion();\n-            if (header.apiVersion() == latestClientVersion) {\n-                log.trace(\"Sending {} {} with correlation id {} to node {}\", clientRequest.apiKey(), request,", "originalCommit": "023302f48c3e2b1da07af111f8077d2f84cb466f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM1MjQ1MQ==", "url": "https://github.com/apache/kafka/pull/8702#discussion_r429352451", "bodyText": "SG.", "author": "guozhangwang", "createdAt": "2020-05-22T16:48:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyNzQ0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyNzk0Ng==", "url": "https://github.com/apache/kafka/pull/8702#discussion_r429327946", "bodyText": "Letting some requests be debug level, but making the responses be trace often means we are left with only half of the picture.", "author": "hachikuji", "createdAt": "2020-05-22T15:54:19Z", "path": "clients/src/main/java/org/apache/kafka/clients/NetworkClient.java", "diffHunk": "@@ -839,20 +833,22 @@ private void handleCompletedReceives(List<ClientResponse> responses, long now) {\n             InFlightRequest req = inFlightRequests.completeNext(source);\n             Struct responseStruct = parseStructMaybeUpdateThrottleTimeMetrics(receive.payload(), req.header,\n                 throttleTimeSensor, now);\n-            if (log.isTraceEnabled()) {", "originalCommit": "023302f48c3e2b1da07af111f8077d2f84cb466f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}