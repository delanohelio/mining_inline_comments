{"pr_number": 7952, "pr_title": "KAFKA-9418: Add new sendOffsetsToTransaction API to KafkaProducer", "pr_createdAt": "2020-01-13T23:32:18Z", "pr_url": "https://github.com/apache/kafka/pull/7952", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjA4OA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686088", "bodyText": "Addressing: #7897 (comment)", "author": "abbccdda", "createdAt": "2020-01-15T03:53:53Z", "path": "clients/src/test/java/org/apache/kafka/common/message/MessageTest.java", "diffHunk": "@@ -431,11 +431,11 @@ public void testTxnOffsetCommitRequestVersions() throws Exception {\n \n             if (version < 3) {\n                 final short finalVersion = version;\n-                assertThrows(UnsupportedVersionException.class, () -> testAllMessageRoundTripsFromVersion(finalVersion, requestData));\n+                assertThrows(UnsupportedVersionException.class, () -> testEquivalentMessageRoundTrip(finalVersion, requestData));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjIwNA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686204", "bodyText": "Addressing #7897 (comment)", "author": "abbccdda", "createdAt": "2020-01-15T03:54:37Z", "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "diffHunk": "@@ -2489,16 +2489,20 @@ class GroupCoordinatorTest {\n     val rebalanceResult = staticMembersJoinAndRebalance(leaderInstanceId, followerInstanceId)\n \n     val leaderNoMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n-      Map(tp -> offset), groupInstanceId = leaderInstanceId)\n+      Map(tp -> offset), memberId = JoinGroupRequest.UNKNOWN_MEMBER_ID, groupInstanceId = leaderInstanceId)\n     assertEquals(Errors.FENCED_INSTANCE_ID, leaderNoMemberIdCommitOffsetResult (tp))\n \n+    val leaderInvalidMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4NjI5Mw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r366686293", "bodyText": "This and the following new tests are addressing the comments for separating valid and invalid scenario: #7897 (comment)", "author": "abbccdda", "createdAt": "2020-01-15T03:55:10Z", "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "diffHunk": "@@ -2489,16 +2489,20 @@ class GroupCoordinatorTest {\n     val rebalanceResult = staticMembersJoinAndRebalance(leaderInstanceId, followerInstanceId)\n \n     val leaderNoMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n-      Map(tp -> offset), groupInstanceId = leaderInstanceId)\n+      Map(tp -> offset), memberId = JoinGroupRequest.UNKNOWN_MEMBER_ID, groupInstanceId = leaderInstanceId)\n     assertEquals(Errors.FENCED_INSTANCE_ID, leaderNoMemberIdCommitOffsetResult (tp))\n \n+    val leaderInvalidMemberIdCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n+      Map(tp -> offset), memberId = \"invalid-member\", groupInstanceId = leaderInstanceId)\n+    assertEquals(Errors.FENCED_INSTANCE_ID, leaderInvalidMemberIdCommitOffsetResult (tp))\n+\n     val leaderCommitOffsetResult = commitTransactionalOffsets(groupId, producerId, producerEpoch,\n       Map(tp -> offset), rebalanceResult.leaderId, leaderInstanceId)\n     assertEquals(Errors.NONE, leaderCommitOffsetResult (tp))\n   }\n \n   @Test\n-  def testTxnCommitOffsetWithUnknownMemberId(): Unit = {\n+  def testTxnCommitOffsetWithInvalidMemberId(): Unit = {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367149611", "bodyText": "We will throw IllegalStateException if unexpected group fencing exception was thrown for old API", "author": "abbccdda", "createdAt": "2020-01-15T22:52:00Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1497,15 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (isGroupFencingException(error)) {\n+                    if (enableGroupFencing) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3ODQ5NQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367578495", "bodyText": "I think this check is overkill.", "author": "hachikuji", "createdAt": "2020-01-16T18:26:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU5MTM1NQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367591355", "bodyText": "But theoretically possible?", "author": "abbccdda", "createdAt": "2020-01-16T18:54:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2NTI5OA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367765298", "bodyText": "After offline discussion, this shall be removed for simplicity.", "author": "abbccdda", "createdAt": "2020-01-17T04:32:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0OTYxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDE5MQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150191", "bodyText": "We unify the API for groupId and groupMetadata commit here, which includes the groupId within the metadata struct.\nA boolean flag indicating whether to turn on global fencing shall be passed down to the txn commit sender to determine whether we should include (member.id, instance.id, generation.id) in the request.", "author": "abbccdda", "createdAt": "2020-01-15T22:53:42Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDQ1Mg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150452", "bodyText": "This separation is to avoid if-else loop complexity warning from checkstyle.", "author": "abbccdda", "createdAt": "2020-01-15T22:54:30Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1524,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupFencingException(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID\n+                   || error == Errors.UNKNOWN_MEMBER_ID\n+                   || error == Errors.ILLEGAL_GENERATION;\n+    }\n+\n+    private boolean isFatalException(Errors error) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MDY0NQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367150645", "bodyText": "When working with the multi-version API, I realized that by making the data initialization internal could save a lot of caller's effort.", "author": "abbccdda", "createdAt": "2020-01-15T22:55:07Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "diffHunk": "@@ -45,9 +45,39 @@\n \n         public final TxnOffsetCommitRequestData data;\n \n-        public Builder(TxnOffsetCommitRequestData data) {\n+        public Builder(final String transactionalId,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTE2NA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367151164", "bodyText": "The test coverage for KafkaProducerTest is weak in general. We just did the bare minimum here to route the request through a full init->begin->commit->end workflow and make sure it is working properly.", "author": "abbccdda", "createdAt": "2020-01-15T22:56:37Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -689,6 +698,90 @@ public void testInitTransactionWhileThrottled() {\n         }\n     }\n \n+    @Test", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367151792", "bodyText": "The purpose of this cachedGroupMetadata is to avoid the creation of groupMetadata everytime we call the old API. It could also be served as a security check on whether the consumer group id has changed in the middle by sending out a warning indicating some illegal state. In Streams or other general EOS use cases, this should never happen.", "author": "abbccdda", "createdAt": "2020-01-15T22:58:20Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIzOTgzMQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367239831", "bodyText": "Hmm, this feels like premature optimization. The offsets map is more likely to be a problem. Also, I'm not sure we should restrict the usage. It is possible today to send offsets for multiple groups. Is there a good reason to restrict this even if it doesn't make sense in streams?", "author": "hachikuji", "createdAt": "2020-01-16T05:43:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NTQ4MA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367585480", "bodyText": "While this is allowed, I couldn't imagine the case as straightforward when you are committing offsets for 2 consumer groups within the same txn. But I agree we probably don't need to log a warning or anything here.", "author": "abbccdda", "createdAt": "2020-01-16T18:42:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNDE4Nw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367604187", "bodyText": "I also feel it may be overkill to cache the cachedGroupMetadata on the producer side -- is it part of the reasons violating ClassFanOutComplexity and ClassDataAbstractionCoupling?", "author": "guozhangwang", "createdAt": "2020-01-16T19:22:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2NTUzOQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367765539", "bodyText": "Sounds good, we shall abandon the cache and just initialize a new one everytime: it shouldn't be a big memory overhead after I think about it. (maybe 100B every commit interval)", "author": "abbccdda", "createdAt": "2020-01-17T04:34:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MTc5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1MjA0Mg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367152042", "bodyText": "This is just leveraging the same security check here, no harm to do for both API calls.", "author": "abbccdda", "createdAt": "2020-01-15T22:58:59Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone\n+     * mode EOS applications are still relying on it. If the broker version is lower than 2.5.0 which doesn't support the new underlying protocol,\n+     * this API call will throw UnsupportedVersionException.\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.common.errors.IllegalGenerationException if the passed in consumer metadata has illegal generation\n+     * @throws org.apache.kafka.common.errors.UnknownMemberIdException if the passed in consumer metadata has unknown member.id\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,\n+               IllegalGenerationException,\n+               UnknownMemberIdException,\n+               FencedInstanceIdException {\n+        if (!cachedGroupMetadata.groupId().equals(groupMetadata.groupId())) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1NjUxMw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367156513", "bodyText": "The 3 tests here are primarily evaluating that when we are on groupMetadata mode, we could correctly detect FENCED_INSTANCE_ID, UNKNOWN_MEMBER_ID and ILLEGAL_GENERATION exceptions.", "author": "abbccdda", "createdAt": "2020-01-15T23:13:11Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -940,6 +948,204 @@ public void testUnsupportedForMessageFormatInTxnOffsetCommit() {\n         assertFatalError(UnsupportedForMessageFormatException.class);\n     }\n \n+    @Test\n+    public void testFencedInstanceIdInTxnOffsetCommitByGroupMetadata() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODc3NA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158774", "bodyText": "A full test to set all 3 group fields", "author": "abbccdda", "createdAt": "2020-01-15T23:20:48Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -2157,6 +2397,56 @@ public void shouldFailAbortIfAddOffsetsFailsWithFatalError() {\n         assertTrue(transactionManager.hasFatalError());\n     }\n \n+    @Test\n+    public void testSendOffsetsWithGroupMetadata() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODkzNg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158936", "bodyText": "Use new API for compatibility test.", "author": "abbccdda", "createdAt": "2020-01-15T23:21:24Z", "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "diffHunk": "@@ -71,7 +73,19 @@ class TransactionsBounceTest extends KafkaServerTestHarness {\n   }\n \n   @Test\n-  def testBrokerFailure(): Unit = {\n+  def testWithGroupId(): Unit = {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODk4Ng==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367158986", "bodyText": "Same here for compatibility.", "author": "abbccdda", "createdAt": "2020-01-15T23:21:32Z", "path": "core/src/test/scala/integration/kafka/api/TransactionsTest.scala", "diffHunk": "@@ -227,7 +227,20 @@ class TransactionsTest extends KafkaServerTestHarness {\n   }\n \n   @Test\n-  def testSendOffsets() = {\n+  def testSendOffsetsWithGroupId() = {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIzODgyOA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367238828", "bodyText": "Not from this patch, but this should be private.", "author": "hachikuji", "createdAt": "2020-01-16T05:38:29Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -28,7 +28,10 @@\n     final private String memberId;\n     final Optional<String> groupInstanceId;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3Mzk3MQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367573971", "bodyText": "I don't think this comment should be in the javadoc. If we did deprecate the other API, we would just mark the other as deprecated.", "author": "hachikuji", "createdAt": "2020-01-16T18:16:20Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NDY1NA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367574654", "bodyText": "I'm wondering if we should use CommitFailedException. In the consumer, we do not expose illegal generation and unknown member id errors directly to the user.", "author": "hachikuji", "createdAt": "2020-01-16T18:17:53Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * This API won't deprecate the existing {@link KafkaProducer#sendOffsetsToTransaction(Map, String) sendOffsets} API as standalone\n+     * mode EOS applications are still relying on it. If the broker version is lower than 2.5.0 which doesn't support the new underlying protocol,\n+     * this API call will throw UnsupportedVersionException.\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.common.errors.IllegalGenerationException if the passed in consumer metadata has illegal generation", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4OTQ4Nw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367589487", "bodyText": "That's a good suggestion, I could wrap unknown member id and illegal generation by a commit failed exception.", "author": "abbccdda", "createdAt": "2020-01-16T18:50:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NDY1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NTk3Mg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367575972", "bodyText": "nit: I think we can do away with enableGroupFencing and derive its value from ConsumerGroupMetadata. In spite of my comment on the previous PR, it may be simpler to just let the defaults be consistent with the expected default values and just have one path below.", "author": "hachikuji", "createdAt": "2020-01-16T18:20:52Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNzUyOA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367607528", "bodyText": "How do we distinguish with the case where only groupId is passed, v.s. the whole groupMetadata is passed but other fields are UNKNOWN_XXX? Do we guarantee that groupMetadata#generationId should never be UNKNOWN_GENERATION_ID (from the broker-side logic we would not check if the generationId < 0)? If yes then we can use that as the boolean flag and get rid of enableGroupFencing.", "author": "guozhangwang", "createdAt": "2020-01-16T19:29:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NTk3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzY4NjUwMg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367686502", "bodyText": "I think we should validate the object when it is received in sendOffsets.", "author": "hachikuji", "createdAt": "2020-01-16T22:38:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NTk3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NjQwMQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367576401", "bodyText": "nit: this definition looks really awkward", "author": "hachikuji", "createdAt": "2020-01-16T18:21:50Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +176,15 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,\n+                                                                                     IllegalGenerationException,\n+                                                                                     UnknownMemberIdException,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU5MDkwNA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367590904", "bodyText": "You mean exception throwing right?", "author": "abbccdda", "createdAt": "2020-01-16T18:53:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcwMjg3Nw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367702877", "bodyText": "Yeah, since these are runtime exceptions, I think you can leave them off. Users can see the documentation to see what errors we throw.", "author": "hachikuji", "createdAt": "2020-01-16T23:31:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3NjQwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NDg3MA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367584870", "bodyText": "nit: if you want a new paragraph you need to add <p>", "author": "mjsax", "createdAt": "2020-01-16T18:40:49Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +644,68 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        if (!cachedGroupMetadata.groupId().equals(consumerGroupId)) {\n+            // Generally this logic should only be triggered once during first call.\n+            log.warn(\"Cached consumer groupId changed from {} to {}. If the old group id is not empty, this indicates an abuse of this API\",\n+                cachedGroupMetadata.groupId(), consumerGroupId);\n+            cachedGroupMetadata = new ConsumerGroupMetadata(consumerGroupId,\n+                JoinGroupRequest.UNKNOWN_GENERATION_ID, JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty());\n+        }\n+        sendOffsetsToTransactionInternal(offsets, cachedGroupMetadata, false);\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2NTcwMg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367765702", "bodyText": "Sounds good", "author": "abbccdda", "createdAt": "2020-01-17T04:34:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NDg3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4Njg3OQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367586879", "bodyText": "ConsumerGroupMetadata does not have a proper toString() implementation -- if we want to log the object, we should add ConsumerGroupMetadata#toString() to ensure a readable log message.", "author": "mjsax", "createdAt": "2020-01-16T18:45:25Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                                            String consumerGroupId) {\n+                                                                            final ConsumerGroupMetadata groupMetadata,\n+                                                                            final boolean enableGroupFencing) {\n         ensureTransactional();\n         maybeFailWithError();\n         if (currentState != State.IN_TRANSACTION)\n             throw new KafkaException(\"Cannot send offsets to transaction either because the producer is not in an \" +\n                     \"active transaction\");\n \n-        log.debug(\"Begin adding offsets {} for consumer group {} to transaction\", offsets, consumerGroupId);\n+        log.debug(\"Begin adding offsets {} for consumer group {} to transaction\", offsets, groupMetadata);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NzMxOQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367587319", "bodyText": "nit: avoid double spaces", "author": "mjsax", "createdAt": "2020-01-16T18:46:17Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -986,22 +987,33 @@ private TxnRequestHandler addPartitionsToTransactionHandler() {\n \n     private TxnOffsetCommitHandler txnOffsetCommitHandler(TransactionalRequestResult result,\n                                                           Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                          String consumerGroupId) {\n+                                                          ConsumerGroupMetadata groupMetadata,\n+                                                          boolean enableGroupFencing) {\n         for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n             OffsetAndMetadata offsetAndMetadata = entry.getValue();\n             CommittedOffset committedOffset = new CommittedOffset(offsetAndMetadata.offset(),\n                     offsetAndMetadata.metadata(), offsetAndMetadata.leaderEpoch());\n             pendingTxnOffsetCommits.put(entry.getKey(), committedOffset);\n         }\n-        TxnOffsetCommitRequest.Builder builder = new TxnOffsetCommitRequest.Builder(\n-            new TxnOffsetCommitRequestData()\n-                .setTransactionalId(transactionalId)\n-                .setGroupId(consumerGroupId)\n-                .setProducerId(producerIdAndEpoch.producerId)\n-                .setProducerEpoch(producerIdAndEpoch.epoch)\n-                .setTopics(TxnOffsetCommitRequest.getTopics(pendingTxnOffsetCommits))\n-        );\n-        return new TxnOffsetCommitHandler(result, builder);\n+\n+        final  TxnOffsetCommitRequest.Builder builder;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2NTk0OQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367765949", "bodyText": "Good catch!", "author": "abbccdda", "createdAt": "2020-01-17T04:36:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NzMxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4OTkwMw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367589903", "bodyText": "Why this change? Should sendOffsetsToTransaction not be able to handle null gracefully? Seems it would be a regression if we change the behavior and start to fail on null?", "author": "mjsax", "createdAt": "2020-01-16T18:51:44Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +151,15 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        producer.sendOffsetsToTransaction(null, \"\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2OTI0Nw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367769247", "bodyText": "It is actually not, I will try to specify the object type so we don't need to use 0 length string", "author": "abbccdda", "createdAt": "2020-01-17T04:56:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4OTkwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYwNjk0OA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367606948", "bodyText": "nit: The first param offsets can be final as well.", "author": "guozhangwang", "createdAt": "2020-01-16T19:28:29Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -329,17 +329,18 @@ private TransactionalRequestResult beginCompletingTransaction(TransactionResult\n     }\n \n     public synchronized TransactionalRequestResult sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n-                                                                            String consumerGroupId) {\n+                                                                            final ConsumerGroupMetadata groupMetadata,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyNzY4NA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367627684", "bodyText": "See my other comment: it seems we initialize generationId / memberId as UNKNOWN anyways, which means that if enableFencing is false it would stay as UNKNOWN_XX and the broker would not check its generationId or memberId, so it seem we can get rid of the boolean flag indeed since if only groupId is passed in, the other fields' default value is sufficient to bypass the fencing.", "author": "guozhangwang", "createdAt": "2020-01-16T20:14:50Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "diffHunk": "@@ -45,9 +45,39 @@\n \n         public final TxnOffsetCommitRequestData data;\n \n-        public Builder(TxnOffsetCommitRequestData data) {\n+        public Builder(final String transactionalId,\n+                       final String consumerGroupId,\n+                       final long producerId,\n+                       final short producerEpoch,\n+                       final Map<TopicPartition, CommittedOffset> pendingTxnOffsetCommits) {\n+            this(transactionalId,\n+                consumerGroupId,\n+                producerId,\n+                producerEpoch,\n+                pendingTxnOffsetCommits,\n+                JoinGroupRequest.UNKNOWN_MEMBER_ID,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc2OTM1Ng==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367769356", "bodyText": "Yep, we could just get rid of the check entirely, as for groupId based commit the other fields will all be default.", "author": "abbccdda", "createdAt": "2020-01-17T04:57:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyNzY4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc3ODkwMA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367778900", "bodyText": "Test changes in this class are only for new API coverage.", "author": "abbccdda", "createdAt": "2020-01-17T05:51:59Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -16,14 +16,15 @@\n  */\n package org.apache.kafka.clients.producer;\n \n+import org.apache.kafka.clients.consumer.ConsumerGroupMetadata;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc3OTYzOA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r367779638", "bodyText": "After some thoughts, I feel hesitated to classify the FencedInstanceId as a sub type of CommitFailed, for producer exception handling we should abort the current transaction and let consumer rejoin the group as needed. For instanceId fenced, it is more fatal as an indicator of a malicious client that should fail the entire client. Like @hachikuji proposed, it makes sense for us to specify new EOS example code once the changes are merged so that we could make sure the API is user friendly: https://issues.apache.org/jira/browse/KAFKA-9447", "author": "abbccdda", "createdAt": "2020-01-17T05:55:53Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNjg3OA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368206878", "bodyText": "I guess we could also get an auth error for the groupId.", "author": "hachikuji", "createdAt": "2020-01-18T05:04:32Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzEyMA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207120", "bodyText": "More of a meta comment, but after this  patch, it would be possible for users to use ephemeral transactional Ids since we can rely on the group coordinator fencing. One of the potential follow-ups is to figure out how to make this work from a security perspective. For example, we could piggyback on Group write permission to enforce access.", "author": "hachikuji", "createdAt": "2020-01-18T05:10:20Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,11 +625,13 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NzMzMw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368257333", "bodyText": "So the producer.id generation is guaranteed to be unique by Zk? If that's the case, I also agree that we should cleanup txn.id security logic. Got 2 tickets to track: https://issues.apache.org/jira/browse/KAFKA-9453\nhttps://issues.apache.org/jira/browse/KAFKA-9454", "author": "abbccdda", "createdAt": "2020-01-19T00:51:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzEyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzI2Ng==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207266", "bodyText": "How about this?\n\n... if the commit failed and cannot be retried (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.", "author": "hachikuji", "createdAt": "2020-01-18T05:14:02Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzI4Mw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207283", "bodyText": "It seems like we don't need to mention 0.11 here since the requirement for 2.5 is stricter.", "author": "hachikuji", "createdAt": "2020-01-18T05:15:04Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NjkyMA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368256920", "bodyText": "The 0.11 and 2.5 unsupported version exceptions are different IMHO.", "author": "abbccdda", "createdAt": "2020-01-19T00:38:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzI4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzM1Mg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207352", "bodyText": "Not really sure why we need this method. Why not move the body into the sendOffsetsToTransaction with the same arguments?", "author": "hachikuji", "createdAt": "2020-01-18T05:16:30Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,\n+               CommitFailedException,\n+               FencedInstanceIdException {\n+        sendOffsetsToTransactionInternal(offsets, groupMetadata);\n+    }\n+\n+    private void sendOffsetsToTransactionInternal(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata consumerGroupMetadata) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1Njg2Nw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368256867", "bodyText": "This is a legacy, I will clean up", "author": "abbccdda", "createdAt": "2020-01-19T00:37:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzM1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzM4Nw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207387", "bodyText": "nit: as mentioned elsewhere, I don't think we need to add all of these exceptions to the method. They are all runtime exceptions, so it's still up to the user to read the docs.", "author": "hachikuji", "createdAt": "2020-01-18T05:17:50Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -632,9 +640,51 @@ public void beginTransaction() throws ProducerFencedException {\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransactionInternal(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized. See the exception for more details\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException if the commit failed and cannot be retried.\n+     * @throws org.apache.kafka.common.errors.FencedInstanceIdException if the passed in consumer metadata has a fenced group.instance.id\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, ConsumerGroupMetadata groupMetadata)\n+        throws ProducerFencedException,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzQ3NQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207475", "bodyText": "nit: we may as well spell out \"Transaction.\" Also, we should probably add :  before the message.", "author": "hachikuji", "createdAt": "2020-01-18T05:20:00Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1476,9 +1482,11 @@ public void handleResponse(AbstractResponse response) {\n                 } else if (error == Errors.GROUP_AUTHORIZATION_FAILED) {\n                     abortableError(GroupAuthorizationException.forGroupId(builder.data.groupId()));\n                     break;\n-                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n-                        || error == Errors.INVALID_PRODUCER_EPOCH\n-                        || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT) {\n+                } else if (error == Errors.UNKNOWN_MEMBER_ID\n+                        || error == Errors.ILLEGAL_GENERATION) {\n+                    abortableError(new CommitFailedException(\"Txn offset Commit failed due to consumer group metadata mismatch\" + error.exception().getMessage()));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368207549", "bodyText": "I still don't think this should be a fatal error for the producer. As long as we can still abort the transaction, it should be an abortable error. It's similar to the handling of GROUP_AUTHORIZATION_FAILED.", "author": "hachikuji", "createdAt": "2020-01-18T05:21:49Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,11 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isFatalException(Errors error) {\n+        return error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED\n+                   || error == Errors.INVALID_PRODUCER_EPOCH\n+                   || error == Errors.UNSUPPORTED_FOR_MESSAGE_FORMAT\n+                   || error == Errors.FENCED_INSTANCE_ID;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI1NzA0OA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368257048", "bodyText": "I'm not strong about this either, as consumer should always be the reliable source for fencing, while producer's exception handling could be simplified.", "author": "abbccdda", "createdAt": "2020-01-19T00:42:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzQ0MA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368263440", "bodyText": "Should we make fenced_instance_id non-fatal as well?", "author": "guozhangwang", "createdAt": "2020-01-19T03:45:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI3MjUzNw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368272537", "bodyText": "Just addressed this @guozhangwang", "author": "abbccdda", "createdAt": "2020-01-19T07:36:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3ODk3NA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369678974", "bodyText": "Wait, how did we end up back here? I thought we agreed this should not be fatal for the producer? I think it should have a separate branch above, similar to the handling of GROUP_AUTHORIZATION_FAILED.", "author": "hachikuji", "createdAt": "2020-01-22T16:51:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwMTkxOA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369701918", "bodyText": "Ugh, my b", "author": "abbccdda", "createdAt": "2020-01-22T17:34:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwNzU0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MjkwNg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368262906", "bodyText": "Why we still have other exceptions declared while in KafkaProducer only ProducerFenced is declared?", "author": "guozhangwang", "createdAt": "2020-01-19T03:29:25Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/Producer.java", "diffHunk": "@@ -53,6 +57,15 @@\n     void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                   String consumerGroupId) throws ProducerFencedException;\n \n+    /**\n+     * See {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata)}\n+     */\n+    void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                  ConsumerGroupMetadata groupMetadata) throws ProducerFencedException,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI3MjQyNA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368272424", "bodyText": "Will cleanup", "author": "abbccdda", "createdAt": "2020-01-19T07:34:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MjkwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzI5NQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368263295", "bodyText": "Where is this function defined?", "author": "guozhangwang", "createdAt": "2020-01-19T03:40:33Z", "path": "core/src/test/scala/integration/kafka/api/TransactionsBounceTest.scala", "diffHunk": "@@ -103,7 +117,7 @@ class TransactionsBounceTest extends KafkaServerTestHarness {\n             !shouldAbort), new ErrorLoggingCallback(outputTopic, record.key, record.value, true))\n         }\n         trace(s\"Sent ${records.size} messages. Committing offsets.\")\n-        producer.sendOffsetsToTransaction(TestUtils.consumerPositions(consumer).asJava, consumerGroup)\n+        commit(producer, consumerGroup, consumer)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI3MjUyOA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368272528", "bodyText": "It's defined as a passed in parameter for testBrokerFailure", "author": "abbccdda", "createdAt": "2020-01-19T07:35:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI2MzI5NQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzYzOA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313638", "bodyText": "It's not really valid to commit offsets with a null groupId. Why don't we use requireNonNull?", "author": "hachikuji", "createdAt": "2020-01-19T18:49:40Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -172,6 +173,13 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         this.sentOffsets = true;\n     }\n \n+    @Override\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {\n+        String groupId = groupMetadata != null ? groupMetadata.groupId() : null;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMyMTA1MQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368321051", "bodyText": "We could do that, it's just a legacy logic for allowing null groupId", "author": "abbccdda", "createdAt": "2020-01-19T20:41:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzYzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0MDA5MA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369140090", "bodyText": "It never actually made sense since the producer itself doesn't support it.", "author": "hachikuji", "createdAt": "2020-01-21T17:28:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzYzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313647", "bodyText": "Might be worth adding a null check here for groupMetadata. Another simple validation is ensuring that if generationId > 0, then memberId should be non-empty.", "author": "hachikuji", "createdAt": "2020-01-19T18:49:44Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +623,60 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from\n+     *                               new {@link KafkaProducer#sendOffsetsToTransaction(Map, ConsumerGroupMetadata) sendOffsets}.\n      * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n      * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n      *         does not support transactions (i.e. if its version is lower than 0.11.0.0)\n-     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException  fatal error indicating the message\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n      *         format used for the offsets topic on the broker does not support transactions\n      * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n-     *         transactional.id is not authorized. See the exception for more details\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n      * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n      *         other unexpected error\n      */\n     public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                          String consumerGroupId) throws ProducerFencedException {\n+        sendOffsetsToTransaction(offsets, new ConsumerGroupMetadata(\n+            consumerGroupId, JoinGroupRequest.UNKNOWN_GENERATION_ID,\n+            JoinGroupRequest.UNKNOWN_MEMBER_ID, Optional.empty()));\n+    }\n+\n+    /**\n+     * Sends a list of specified offsets to the consumer group coordinator, and also marks\n+     * those offsets as part of the current transaction. These offsets will be considered\n+     * committed only if the transaction is committed successfully. The committed offset should\n+     * be the next message your application will consume, i.e. lastProcessedMessageOffset + 1.\n+     * <p>\n+     * This method should be used when you need to batch consumed and produced messages\n+     * together, typically in a consume-transform-produce pattern. Thus, the specified\n+     * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * Note, that the consumer should have {@code enable.auto.commit=false} and should\n+     * also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n+     * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n+     *\n+     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started.\n+     * @throws ProducerFencedException fatal error indicating another producer with the same transactional.id is active\n+     * @throws org.apache.kafka.common.errors.UnsupportedVersionException fatal error indicating the broker\n+     *         does not support transactions (i.e. if its version is lower than 0.11.0.0) or\n+     *         the broker doesn't support latest version of transactional API with consumer group metadata (i.e. if its version is\n+     *         lower than 2.5.0).\n+     * @throws org.apache.kafka.common.errors.UnsupportedForMessageFormatException fatal error indicating the message\n+     *         format used for the offsets topic on the broker does not support transactions\n+     * @throws org.apache.kafka.common.errors.AuthorizationException fatal error indicating that the configured\n+     *         transactional.id is not authorized, or the consumer group id is not authorized.\n+     * @throws org.apache.kafka.clients.consumer.CommitFailedException  if the commit failed and cannot be retried\n+     *         (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.\n+     * @throws KafkaException if the producer has encountered a previous fatal or abortable error, or for any\n+     *         other unexpected error\n+     */\n+    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n+                                         ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODcxMTEzNQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368711135", "bodyText": "Why do we need a null check here? The groupMetadata itself will through NPE if it is not defined on TransactionManager#sendOffsetsToTransaction", "author": "abbccdda", "createdAt": "2020-01-20T20:12:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0MDg1OQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369140859", "bodyText": "We can give a clear message saying null is not supported. If it's an NPE somewhere down the stack then the user doesn't know if it's a bug or not.", "author": "hachikuji", "createdAt": "2020-01-21T17:30:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI5MDE3OA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369290178", "bodyText": "sg", "author": "abbccdda", "createdAt": "2020-01-21T23:00:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzY0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzc2Mg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313762", "bodyText": "Might be nice to have an overload which sets only groupId.", "author": "hachikuji", "createdAt": "2020-01-19T18:51:38Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -26,9 +26,12 @@\n     final private String groupId;\n     final private int generationId;\n     final private String memberId;\n-    final Optional<String> groupInstanceId;\n+    final private Optional<String> groupInstanceId;\n \n-    public ConsumerGroupMetadata(String groupId, int generationId, String memberId, Optional<String> groupInstanceId) {\n+    public ConsumerGroupMetadata(String groupId,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxOTY0MQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368319641", "bodyText": "Sg", "author": "abbccdda", "createdAt": "2020-01-19T20:24:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzc2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368313968", "bodyText": "I think there's probably a good case to raise this one directly as an abortable error instead of getting wrapped in CommitFailedException. Although it is not fatal for the producer, the user shouldn't ignore it.", "author": "hachikuji", "createdAt": "2020-01-19T18:55:52Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java", "diffHunk": "@@ -1497,4 +1505,16 @@ public void handleResponse(AbstractResponse response) {\n             }\n         }\n     }\n+\n+    private boolean isGroupMetadataMisMatch(Errors error) {\n+        return error == Errors.FENCED_INSTANCE_ID", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzMjc2MA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368332760", "bodyText": "User will have to handle this exception properly by either:\n\naborting the transaction as recommended\nfail the entire application to be more strict\nother cases as they see fit\n\nSo no matter how to handle it, the error shall not be ignored. If we are throwing 3 different types of exceptions, user would as well need to catch 3 different types of exceptions IMHO", "author": "abbccdda", "createdAt": "2020-01-19T23:33:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0NDI5NA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369144294", "bodyText": "My expectation for illegal generation and unknown member id is that it can be more or less ignored. The user should abort the transaction, but then continue after rejoining the group. The instance fenced error means a new instance of the application has been started somewhere and the application should be stopped.\nBy the way, this is why I suggested writing some example code which shows what we consider to be proper handling. This will give us a better idea if the handling is reasonable, awkward, or incomplete.", "author": "hachikuji", "createdAt": "2020-01-21T17:37:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI5MTM4NA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369291384", "bodyText": "That's true, we also had a jira to track it here: https://issues.apache.org/jira/browse/KAFKA-9447", "author": "abbccdda", "createdAt": "2020-01-21T23:04:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxMzk2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDIwNQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314205", "bodyText": "To ensure that we are really testing the state machine as expected, we should provide a valid groupId. Similarly below.", "author": "hachikuji", "createdAt": "2020-01-19T19:00:04Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -152,15 +154,17 @@ public void shouldBeginTransactions() {\n     @Test(expected = IllegalStateException.class)\n     public void shouldThrowOnSendOffsetsToTransactionIfTransactionsNotInitialized() {\n         buildMockProducer(true);\n-        producer.sendOffsetsToTransaction(null, null);\n+        String groupId = null;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzMjg2NA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368332864", "bodyText": "I guess the MockProducer is putting the null check later than the state check. I could re-order them if you feel better about it.", "author": "abbccdda", "createdAt": "2020-01-19T23:35:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDIwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0MTcxNg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369141716", "bodyText": "The purpose of this test is to raise an exception if the transaction hasn't been initialized. But we are also providing an invalid groupId. To make sure we hit the right error case, we should provide a valid groupId.", "author": "hachikuji", "createdAt": "2020-01-21T17:31:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDIwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDMzNQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314335", "bodyText": "These test cases seem to be identical code other than the error. Can we factor out a helper?", "author": "hachikuji", "createdAt": "2020-01-19T19:01:42Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -940,6 +946,134 @@ public void testUnsupportedForMessageFormatInTxnOffsetCommit() {\n         assertFatalError(UnsupportedForMessageFormatException.class);\n     }\n \n+    @Test\n+    public void testFencedInstanceIdInTxnOffsetCommitByGroupMetadata() {\n+        final String consumerGroupId = \"consumer\";\n+        final long pid = 13131L;\n+        final short epoch = 1;\n+        final TopicPartition tp = new TopicPartition(\"foo\", 0);\n+        final String memberId = \"member\";\n+        final String fencedMemberId = \"fenced_member\";\n+        final String instanceId = \"instance\";\n+\n+        doInitTransactions(pid, epoch);\n+\n+        transactionManager.beginTransaction();\n+\n+        TransactionalRequestResult sendOffsetsResult = transactionManager.sendOffsetsToTransaction(\n+            singletonMap(tp, new OffsetAndMetadata(39L)),\n+            new ConsumerGroupMetadata(consumerGroupId, 5, fencedMemberId, Optional.of(instanceId)));\n+\n+        prepareAddOffsetsToTxnResponse(Errors.NONE, consumerGroupId, pid, epoch);\n+        sender.runOnce();  // AddOffsetsToTxn Handled, TxnOffsetCommit Enqueued\n+        sender.runOnce();  // FindCoordinator Enqueued\n+\n+        prepareFindCoordinatorResponse(Errors.NONE, false, CoordinatorType.GROUP, consumerGroupId);\n+        sender.runOnce();  // FindCoordinator Returned\n+\n+        client.prepareResponse(request -> {\n+            TxnOffsetCommitRequest txnOffsetCommitRequest = (TxnOffsetCommitRequest) request;\n+            assertEquals(consumerGroupId, txnOffsetCommitRequest.data.groupId());\n+            assertEquals(pid, txnOffsetCommitRequest.data.producerId());\n+            assertEquals(epoch, txnOffsetCommitRequest.data.producerEpoch());\n+            return txnOffsetCommitRequest.data.groupInstanceId().equals(instanceId)\n+                && !txnOffsetCommitRequest.data.memberId().equals(memberId);\n+        }, new TxnOffsetCommitResponse(0, singletonMap(tp, Errors.FENCED_INSTANCE_ID)));\n+\n+        sender.runOnce();  // TxnOffsetCommit Handled\n+\n+        assertTrue(transactionManager.hasError());\n+        assertTrue(transactionManager.lastError() instanceof CommitFailedException);\n+        assertTrue(sendOffsetsResult.isCompleted());\n+        assertFalse(sendOffsetsResult.isSuccessful());\n+        assertTrue(sendOffsetsResult.error() instanceof CommitFailedException);\n+        assertAbortableError(CommitFailedException.class);\n+    }\n+\n+    @Test\n+    public void testUnknownMemberIdInTxnOffsetCommitByGroupMetadata() {\n+        final String consumerGroupId = \"consumer\";\n+        final long pid = 13131L;\n+        final short epoch = 1;\n+        final TopicPartition tp = new TopicPartition(\"foo\", 0);\n+        final String memberId = \"member\";\n+        final String unknownMemberId = \"unknownMember\";\n+\n+        doInitTransactions(pid, epoch);\n+\n+        transactionManager.beginTransaction();\n+\n+        TransactionalRequestResult sendOffsetsResult = transactionManager.sendOffsetsToTransaction(\n+            singletonMap(tp, new OffsetAndMetadata(39L)),\n+            new ConsumerGroupMetadata(consumerGroupId, 5, unknownMemberId, Optional.empty()));\n+\n+        prepareAddOffsetsToTxnResponse(Errors.NONE, consumerGroupId, pid, epoch);\n+        sender.runOnce();  // AddOffsetsToTxn Handled, TxnOffsetCommit Enqueued\n+        sender.runOnce();  // FindCoordinator Enqueued\n+\n+        prepareFindCoordinatorResponse(Errors.NONE, false, CoordinatorType.GROUP, consumerGroupId);\n+        sender.runOnce();  // FindCoordinator Returned\n+\n+        client.prepareResponse(request -> {\n+            TxnOffsetCommitRequest txnOffsetCommitRequest = (TxnOffsetCommitRequest) request;\n+            assertEquals(consumerGroupId, txnOffsetCommitRequest.data.groupId());\n+            assertEquals(pid, txnOffsetCommitRequest.data.producerId());\n+            assertEquals(epoch, txnOffsetCommitRequest.data.producerEpoch());\n+            return !txnOffsetCommitRequest.data.memberId().equals(memberId);\n+        }, new TxnOffsetCommitResponse(0, singletonMap(tp, Errors.UNKNOWN_MEMBER_ID)));\n+        sender.runOnce();  // TxnOffsetCommit Handled\n+\n+        assertTrue(transactionManager.hasError());\n+        assertTrue(transactionManager.lastError() instanceof CommitFailedException);\n+        assertTrue(sendOffsetsResult.isCompleted());\n+        assertFalse(sendOffsetsResult.isSuccessful());\n+        assertTrue(sendOffsetsResult.error() instanceof CommitFailedException);\n+        assertAbortableError(CommitFailedException.class);\n+    }\n+\n+    @Test\n+    public void testIllegalGenerationInTxnOffsetCommitByGroupMetadata() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxOTcxNg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368319716", "bodyText": "Actually there are a couple of differences inside the test, such as error type, consumer metadata creation, and request matcher. Probably we could just leave as it is since new readers would just fix one by reading through the whole block", "author": "abbccdda", "createdAt": "2020-01-19T20:24:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDMzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDQ5OA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368314498", "bodyText": "Seems this test case would be more interesting if we tried to commit a separate set of offsets before aborting", "author": "hachikuji", "createdAt": "2020-01-19T19:04:14Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/MockProducerTest.java", "diffHunk": "@@ -568,6 +638,31 @@ public void shouldPreserveCommittedConsumerGroupsOffsetsOnAbortIfTransactionsAre\n         assertThat(producer.consumerGroupOffsetsHistory(), equalTo(Collections.singletonList(expectedResult)));\n     }\n \n+    @Test\n+    public void shouldPreserveOffsetsFromCommitByGroupMetadataOnAbortIfTransactionsAreEnabled() {\n+        buildMockProducer(true);\n+        producer.initTransactions();\n+        producer.beginTransaction();\n+\n+        String group = \"g\";\n+        Map<TopicPartition, OffsetAndMetadata> groupCommit = new HashMap<TopicPartition, OffsetAndMetadata>() {\n+            {\n+                put(new TopicPartition(topic, 0), new OffsetAndMetadata(42L, null));\n+                put(new TopicPartition(topic, 1), new OffsetAndMetadata(73L, null));\n+            }\n+        };\n+        producer.sendOffsetsToTransaction(groupCommit, groupMetadata(group));\n+        producer.commitTransaction();\n+\n+        producer.beginTransaction();\n+        producer.abortTransaction();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzMzA2NQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r368333065", "bodyText": "ack", "author": "abbccdda", "createdAt": "2020-01-19T23:38:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxNDQ5OA=="}], "type": "inlineReview"}, {"oid": "4e2486ce7d1650613e88aca761a556635084a8e1", "url": "https://github.com/apache/kafka/commit/4e2486ce7d1650613e88aca761a556635084a8e1", "message": "Revert \"revert client side changes\"\n\nThis reverts commit 437f8456983ba6234644c62a5cbfee5e77814cfb.", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "ce8856cd302b9f4cfd05f5601e7552c4b6f933b4", "url": "https://github.com/apache/kafka/commit/ce8856cd302b9f4cfd05f5601e7552c4b6f933b4", "message": "add producer send offsets", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "6770680646eb1309223d7293ee20e3327c3a1894", "url": "https://github.com/apache/kafka/commit/6770680646eb1309223d7293ee20e3327c3a1894", "message": "style fix", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "eac6fe6f70d35ed320cbef5793ff0448e81e5619", "url": "https://github.com/apache/kafka/commit/eac6fe6f70d35ed320cbef5793ff0448e81e5619", "message": "address Matthias comments from previous PR", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "49b163fc8b2443ad1c0ed9eafc2f1c83a0f60a96", "url": "https://github.com/apache/kafka/commit/49b163fc8b2443ad1c0ed9eafc2f1c83a0f60a96", "message": "illegal state tests for group related exception", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "850e6602c1eb3457ae5098aaf45cb8e8d8ddcc79", "url": "https://github.com/apache/kafka/commit/850e6602c1eb3457ae5098aaf45cb8e8d8ddcc79", "message": "hide details about txn commit data creation", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "2dd1a1dc742f38eb4cfa86fe91ba1fe088a13c40", "url": "https://github.com/apache/kafka/commit/2dd1a1dc742f38eb4cfa86fe91ba1fe088a13c40", "message": "premilinary producer txn API tests", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "271014808657ca81816d49f1292bd7fd14dc388c", "url": "https://github.com/apache/kafka/commit/271014808657ca81816d49f1292bd7fd14dc388c", "message": "txn commit test fix", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "d45fa60572ee931a940f67063d812912e15102e6", "url": "https://github.com/apache/kafka/commit/d45fa60572ee931a940f67063d812912e15102e6", "message": "address comments", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "966c309d4e367300434557bd7b156878d1ffb3af", "url": "https://github.com/apache/kafka/commit/966c309d4e367300434557bd7b156878d1ffb3af", "message": "address Jason's comments", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "88050c172b89ec1f6c4969988ce2cbb1adcf7089", "url": "https://github.com/apache/kafka/commit/88050c172b89ec1f6c4969988ce2cbb1adcf7089", "message": "Guozhang's comment for cleanup Producer.java", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "aabe1a5c0f3c5be2d4946aa1b09af66fb2ad5656", "url": "https://github.com/apache/kafka/commit/aabe1a5c0f3c5be2d4946aa1b09af66fb2ad5656", "message": "address Jason's comments", "committedDate": "2020-01-21T23:23:19Z", "type": "commit"}, {"oid": "a08d25ecc111385e24d4bcff452a04b81587c525", "url": "https://github.com/apache/kafka/commit/a08d25ecc111385e24d4bcff452a04b81587c525", "message": "add checks to group metadata", "committedDate": "2020-01-21T23:23:40Z", "type": "commit"}, {"oid": "a08d25ecc111385e24d4bcff452a04b81587c525", "url": "https://github.com/apache/kafka/commit/a08d25ecc111385e24d4bcff452a04b81587c525", "message": "add checks to group metadata", "committedDate": "2020-01-21T23:23:40Z", "type": "forcePushed"}, {"oid": "2706908e3524f76c2ef749d3907815de4360fd8f", "url": "https://github.com/apache/kafka/commit/2706908e3524f76c2ef749d3907815de4360fd8f", "message": "expose FencedInstanceId exception", "committedDate": "2020-01-22T04:31:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY2OTUwMw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369669503", "bodyText": "nit: usually we write this like this:\nthis.groupInstanceId = requireNonNull(groupInstanceId, \"group.instance.id can't be null\");", "author": "hachikuji", "createdAt": "2020-01-22T16:35:27Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -26,15 +29,29 @@\n     final private String groupId;\n     final private int generationId;\n     final private String memberId;\n-    final Optional<String> groupInstanceId;\n+    final private Optional<String> groupInstanceId;\n \n-    public ConsumerGroupMetadata(String groupId, int generationId, String memberId, Optional<String> groupInstanceId) {\n+    public ConsumerGroupMetadata(String groupId,\n+                                 int generationId,\n+                                 String memberId,\n+                                 Optional<String> groupInstanceId) {\n         this.groupId = groupId;\n         this.generationId = generationId;\n+\n+        Objects.requireNonNull(memberId, \"member.id can't be null\");\n         this.memberId = memberId;\n+\n+        Objects.requireNonNull(groupInstanceId, \"group.instance.id can't be null\");", "originalCommit": "2706908e3524f76c2ef749d3907815de4360fd8f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MTUzNg==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369671536", "bodyText": "nit: I don't think there's any reason to mention this. Unexpected errors fall under KafkaException, which is listed below.", "author": "hachikuji", "createdAt": "2020-01-22T16:38:55Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -619,22 +622,61 @@ public void beginTransaction() throws ProducerFencedException {\n      * and should also not commit offsets manually (via {@link KafkaConsumer#commitSync(Map) sync} or\n      * {@link KafkaConsumer#commitAsync(Map, OffsetCommitCallback) async} commits).\n      *\n-     * @throws IllegalStateException if no transactional.id has been configured or no transaction has been started\n+     * @throws IllegalStateException if no transactional.id has been configured, no transaction has been started,\n+     *                               or encounters unexpected group fencing exception which should only be returned from", "originalCommit": "2706908e3524f76c2ef749d3907815de4360fd8f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MjQ1Ng==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369672456", "bodyText": "nit: we may as well move this check into ConsumerGroupMetadata since we have some other null checks there.", "author": "hachikuji", "createdAt": "2020-01-22T16:40:26Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -1228,6 +1270,17 @@ private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[]\n                         record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n     }\n \n+    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n+        if (groupMetadata == null) {\n+            throw new IllegalStateException(\"Consumer group metadata could not be null\");\n+        } else if (groupMetadata.groupId() == null) {", "originalCommit": "2706908e3524f76c2ef749d3907815de4360fd8f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwMTQ3Nw==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369701477", "bodyText": "The check is a little bit over-specific for ConsumerGroupMetadata itself, which is why I put advanced check in here so that people could construct group metadata in error format as they want.", "author": "abbccdda", "createdAt": "2020-01-22T17:33:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MjQ1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcyMTIyOA==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369721228", "bodyText": "Can you elaborate why this is different from e.g. the memberId?", "author": "hachikuji", "createdAt": "2020-01-22T18:13:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3MjQ1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY3Mjc3MQ==", "url": "https://github.com/apache/kafka/pull/7952#discussion_r369672771", "bodyText": "I think these should all be IllegalArgumentException. The producer is not in an illegal state.", "author": "hachikuji", "createdAt": "2020-01-22T16:40:57Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -1228,6 +1270,17 @@ private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[]\n                         record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n     }\n \n+    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n+        if (groupMetadata == null) {\n+            throw new IllegalStateException(\"Consumer group metadata could not be null\");", "originalCommit": "2706908e3524f76c2ef749d3907815de4360fd8f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9cf4a2a546625f337c4e2e28da3e6b3a956fa309", "url": "https://github.com/apache/kafka/commit/9cf4a2a546625f337c4e2e28da3e6b3a956fa309", "message": "final comment", "committedDate": "2020-01-22T17:48:18Z", "type": "commit"}, {"oid": "9cf4a2a546625f337c4e2e28da3e6b3a956fa309", "url": "https://github.com/apache/kafka/commit/9cf4a2a546625f337c4e2e28da3e6b3a956fa309", "message": "final comment", "committedDate": "2020-01-22T17:48:18Z", "type": "forcePushed"}, {"oid": "e81e0daaec396ec5be7cc3d3cc2adae42f242e95", "url": "https://github.com/apache/kafka/commit/e81e0daaec396ec5be7cc3d3cc2adae42f242e95", "message": "move group.id null check", "committedDate": "2020-01-22T18:43:20Z", "type": "commit"}]}