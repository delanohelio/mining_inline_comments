{"pr_number": 8621, "pr_title": "KAFKA-9466: Update Kafka Streams docs for KIP-447", "pr_createdAt": "2020-05-06T02:01:05Z", "pr_url": "https://github.com/apache/kafka/pull/8621", "timeline": [{"oid": "081cb43541bc7eb3f81a49bd658a4b098e2ec89b", "url": "https://github.com/apache/kafka/commit/081cb43541bc7eb3f81a49bd658a4b098e2ec89b", "message": "KAFKA-9466: Update Kafka Streams docs for KIP-447", "committedDate": "2020-05-06T01:59:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDUxNDgyNg==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r420514826", "bodyText": "downgrade your", "author": "abbccdda", "createdAt": "2020-05-06T02:34:22Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n+        <code>processing.guarantee</code>) is available.\n+        To use this new feature, your brokers must be on version 2.5.x or newer.\n+        A switch from <code>\"exactly_once\"</code> to <code>\"exactly_once_beta\"</code> (or the other way around) is\n+        only possible if the application is on version 2.6.x.\n+        Hence, if you want to upgrade your application from an older version and enable this feature,\n+        you first need to upgrade your application to version 2.6.x staying on <code>\"exactly_once\"</code>\n+        and afterwards do second round of rolling bounces to switch to <code>\"exactly_once_beta\"</code>.\n+        For a downgrade do the revers: first switch the config from <code>\"exactly_once_beta\"</code> to\n+        <code>\"exactly_once\"</code>to disable the feature on your 2.6.x application.\n+        Afterward, you can downgrade you application to a pre 2.6.x version.", "originalCommit": "081cb43541bc7eb3f81a49bd658a4b098e2ec89b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDUxNTAxMw==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r420515013", "bodyText": "by setting", "author": "abbccdda", "createdAt": "2020-05-06T02:35:08Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -72,6 +86,15 @@ <h1>Upgrade Guide and API Changes</h1>\n         More details about the new config <code>StreamsConfig#TOPOLOGY_OPTIMIZATION</code> can be found in <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-295%3A+Add+Streams+Configuration+Allowing+for+Optional+Topology+Optimization\">KIP-295</a>.\n     </p>\n \n+    <h3><a id=\"streams_api_changes_260\" href=\"#streams_api_changes_260\">Streams API changes in 2.6.0</a></h3>\n+    <p>\n+        We added a new processing mode that improves application scalability using exactly-once guarantees\n+        (via <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics\">KIP-447</a>>).\n+        You can enable this new feature be setting the configuration parameter <code>processing.guarantee</code> to the", "originalCommit": "081cb43541bc7eb3f81a49bd658a4b098e2ec89b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDUxNTE3Mg==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r420515172", "bodyText": "nit: could just say this feature as we mentioned new feature earlier.", "author": "abbccdda", "createdAt": "2020-05-06T02:35:45Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -72,6 +86,15 @@ <h1>Upgrade Guide and API Changes</h1>\n         More details about the new config <code>StreamsConfig#TOPOLOGY_OPTIMIZATION</code> can be found in <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-295%3A+Add+Streams+Configuration+Allowing+for+Optional+Topology+Optimization\">KIP-295</a>.\n     </p>\n \n+    <h3><a id=\"streams_api_changes_260\" href=\"#streams_api_changes_260\">Streams API changes in 2.6.0</a></h3>\n+    <p>\n+        We added a new processing mode that improves application scalability using exactly-once guarantees\n+        (via <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics\">KIP-447</a>>).\n+        You can enable this new feature be setting the configuration parameter <code>processing.guarantee</code> to the\n+        new value <code>\"exactly_once_beta\"</code>.\n+        Note that you need brokers with version 2.5 or newer to use this new feature.", "originalCommit": "081cb43541bc7eb3f81a49bd658a4b098e2ec89b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDUxNTQ2Mg==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r420515462", "bodyText": "Do we need to attach a link to KIP here as well?", "author": "abbccdda", "createdAt": "2020-05-06T02:37:11Z", "path": "docs/upgrade.html", "diffHunk": "@@ -19,6 +19,12 @@\n \n <script id=\"upgrade-template\" type=\"text/x-handlebars-template\">\n \n+<h5><a id=\"upgrade_260_notable\" href=\"#upgrade_260_notable\">Notable changes in 2.6.0</a></h5>\n+<ul>\n+    <li>Kafka Streams adds a new processing mode (requires broker 2.5 or newer) that improves application", "originalCommit": "081cb43541bc7eb3f81a49bd658a4b098e2ec89b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE2NjgyMQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r421166821", "bodyText": "I don't think we need but sound like a good idea :)", "author": "mjsax", "createdAt": "2020-05-07T00:21:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDUxNTQ2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDUxNjE1MA==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r420516150", "bodyText": "It's a bit unfortunate that inside StreamsConfig we don't have further information concerning the difference between EOS and EOS beta. Maybe we just talk more into details to compare between the two here? Just need to let user understand that EOS beta does guarantee the same semantics with potentially better scalability as an improvement in 2.5 & 2.6.", "author": "abbccdda", "createdAt": "2020-05-06T02:40:22Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,16 +206,16 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n \n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n+        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value (default value is <b>at_least_once</b>) to <b>exactly_once</b> or <b>exactly_once_beta</b> (requires brokers version 2.5 or newer).\n         More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.", "originalCommit": "081cb43541bc7eb3f81a49bd658a4b098e2ec89b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE2Nzk3Mg==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r421167972", "bodyText": "Oh, I missed to extend this section... IMHO, it good to have the details in the config section as many users (especially existing users) won't read the \"concepts\" page.", "author": "mjsax", "createdAt": "2020-05-07T00:25:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDUxNjE1MA=="}], "type": "inlineReview"}, {"oid": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "url": "https://github.com/apache/kafka/commit/883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "message": "Github comments", "committedDate": "2020-05-07T00:59:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1OTA3OQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r421759079", "bodyText": "We could also mention the potential outcome if broker is not on >= 2.5.x, which is a hard crash in this transition.", "author": "abbccdda", "createdAt": "2020-05-07T19:59:34Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n+        <code>processing.guarantee</code>) is available.\n+        To use this new feature, your brokers must be on version 2.5.x or newer.", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1MzA0OQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r421953049", "bodyText": "I guess we can. However, isn't a hard crash always the result?", "author": "mjsax", "createdAt": "2020-05-08T05:53:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1OTA3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwOTA5OQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422309099", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"\n          \n          \n            \n                    As of the 2.6.0 release, Kafka Streams supports an improved implementation of exactly-once processing, named \"exactly-once beta\",", "author": "JimGalasyn", "createdAt": "2020-05-08T18:45:33Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n+\n+        As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwOTIzMg==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422309232", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    (requires broker version 2.5.0 or newer).\n          \n          \n            \n                    which requires broker version 2.5.0 or newer.", "author": "JimGalasyn", "createdAt": "2020-05-08T18:45:48Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n+\n+        As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"\n+        (requires broker version 2.5.0 or newer).", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMwOTc5OQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422309799", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    This implementation is more efficient (i.e., less client and broker resource utilization; like client threads, used network connections etc.)\n          \n          \n            \n                    This implementation is more efficient, because it reduces client and broker resource utilization, like client threads and used network connections,", "author": "JimGalasyn", "createdAt": "2020-05-08T18:46:56Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n+\n+        As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"\n+        (requires broker version 2.5.0 or newer).\n+        This implementation is more efficient (i.e., less client and broker resource utilization; like client threads, used network connections etc.)", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMDAwNQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422310005", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    and allows for higher throughput and improved scalability.\n          \n          \n            \n                    and it enables higher throughput and improved scalability.", "author": "JimGalasyn", "createdAt": "2020-05-08T18:47:25Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n+\n+        As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"\n+        (requires broker version 2.5.0 or newer).\n+        This implementation is more efficient (i.e., less client and broker resource utilization; like client threads, used network connections etc.)\n+        and allows for higher throughput and improved scalability.", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMDQ4MA==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422310480", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    To read more details on how this is done inside the brokers and Kafka Streams, readers are recommended to read\n          \n          \n            \n                    For more information on how this is done inside the brokers and Kafka Streams, see", "author": "JimGalasyn", "createdAt": "2020-05-08T18:48:22Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n+\n+        As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"\n+        (requires broker version 2.5.0 or newer).\n+        This implementation is more efficient (i.e., less client and broker resource utilization; like client threads, used network connections etc.)\n+        and allows for higher throughput and improved scalability.\n+        To read more details on how this is done inside the brokers and Kafka Streams, readers are recommended to read", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMDgwNw==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422310807", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n          \n          \n            \n                    For more information on how this is done inside Kafka Streams, see <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />", "author": "JimGalasyn", "createdAt": "2020-05-08T18:48:56Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMTIxNQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422311215", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    In order to achieve exactly-once semantics when running Kafka Streams applications,\n          \n          \n            \n                    To enable exactly-once semantics when running Kafka Streams applications,", "author": "JimGalasyn", "createdAt": "2020-05-08T18:49:44Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n+\n+        As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"\n+        (requires broker version 2.5.0 or newer).\n+        This implementation is more efficient (i.e., less client and broker resource utilization; like client threads, used network connections etc.)\n+        and allows for higher throughput and improved scalability.\n+        To read more details on how this is done inside the brokers and Kafka Streams, readers are recommended to read\n+        <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics\">KIP-447</a>.<br />\n+\n+        In order to achieve exactly-once semantics when running Kafka Streams applications,", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMTM0MA==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422311340", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    users can simply set the <code>processing.guarantee</code> config value (default value is <b>at_least_once</b>)\n          \n          \n            \n                    set the <code>processing.guarantee</code> config value (default value is <b>at_least_once</b>)", "author": "JimGalasyn", "createdAt": "2020-05-08T18:50:00Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n+\n+        As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"\n+        (requires broker version 2.5.0 or newer).\n+        This implementation is more efficient (i.e., less client and broker resource utilization; like client threads, used network connections etc.)\n+        and allows for higher throughput and improved scalability.\n+        To read more details on how this is done inside the brokers and Kafka Streams, readers are recommended to read\n+        <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics\">KIP-447</a>.<br />\n+\n+        In order to achieve exactly-once semantics when running Kafka Streams applications,\n+        users can simply set the <code>processing.guarantee</code> config value (default value is <b>at_least_once</b>)", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMTYyNQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422311625", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    More details can be found in the <a href=\"/{{version}}/documentation/streams/developer-guide/config-streams.html\">Kafka Streams Configs</a> section.\n          \n          \n            \n                    For more information, see the <a href=\"/{{version}}/documentation/streams/developer-guide/config-streams.html\">Kafka Streams Configs</a> section.", "author": "JimGalasyn", "createdAt": "2020-05-08T18:50:35Z", "path": "docs/streams/core-concepts.html", "diffHunk": "@@ -206,17 +206,26 @@ <h2><a id=\"streams_processing_guarantee\" href=\"#streams_processing_guarantee\">Pr\n         to the stream processing pipeline, known as the <a href=\"http://lambda-architecture.net/\">Lambda Architecture</a>.\n         Prior to 0.11.0.0, Kafka only provides at-least-once delivery guarantees and hence any stream processing systems that leverage it as the backend storage could not guarantee end-to-end exactly-once semantics.\n         In fact, even for those stream processing systems that claim to support exactly-once processing, as long as they are reading from / writing to Kafka as the source / sink, their applications cannot actually guarantee that\n-        no duplicates will be generated throughout the pipeline.\n+        no duplicates will be generated throughout the pipeline.<br />\n \n         Since the 0.11.0.0 release, Kafka has added support to allow its producers to send messages to different topic partitions in a <a href=\"https://kafka.apache.org/documentation/#semantics\">transactional and idempotent manner</a>,\n         and Kafka Streams has hence added the end-to-end exactly-once processing semantics by leveraging these features.\n         More specifically, it guarantees that for any record read from the source Kafka topics, its processing results will be reflected exactly once in the output Kafka topic as well as in the state stores for stateful operations.\n         Note the key difference between Kafka Streams end-to-end exactly-once guarantee with other stream processing frameworks' claimed guarantees is that Kafka Streams tightly integrates with the underlying Kafka storage system and ensure that\n         commits on the input topic offsets, updates on the state stores, and writes to the output topics will be completed atomically instead of treating Kafka as an external system that may have side-effects.\n-        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.\n-\n-        In order to achieve exactly-once semantics when running Kafka Streams applications, users can simply set the <code>processing.guarantee</code> config value to <b>exactly_once</b> (default value is <b>at_least_once</b>).\n-        More details can be found in the <a href=\"/{{version}}/documentation#streamsconfigs\"><b>Kafka Streams Configs</b></a> section.\n+        To read more details on how this is done inside Kafka Streams, readers are recommended to read <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%3A+Streams+Exactly-Once+Semantics\">KIP-129</a>.<br />\n+\n+        As of the 2.6.0 release, Kafka Streams supports an improve implementation of exactly-once processing called \"exactly-once beta\"\n+        (requires broker version 2.5.0 or newer).\n+        This implementation is more efficient (i.e., less client and broker resource utilization; like client threads, used network connections etc.)\n+        and allows for higher throughput and improved scalability.\n+        To read more details on how this is done inside the brokers and Kafka Streams, readers are recommended to read\n+        <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics\">KIP-447</a>.<br />\n+\n+        In order to achieve exactly-once semantics when running Kafka Streams applications,\n+        users can simply set the <code>processing.guarantee</code> config value (default value is <b>at_least_once</b>)\n+        to <b>exactly_once</b> (requires brokers version 0.11.0 or newer) or <b>exactly_once_beta</b> (requires brokers version 2.5 or newer).\n+        More details can be found in the <a href=\"/{{version}}/documentation/streams/developer-guide/config-streams.html\">Kafka Streams Configs</a> section.", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMjQwOQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422312409", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                             For development you can change this, by adjusting broker setting\n          \n          \n            \n                             For development, you can change this configuration by adjusting broker setting", "author": "JimGalasyn", "createdAt": "2020-05-08T18:52:09Z", "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -456,13 +457,22 @@ <h4><a class=\"toc-backref\" href=\"#id11\">num.stream.threads</a><a class=\"headerli\n         <div class=\"section\" id=\"processing-guarantee\">\n           <span id=\"streams-developer-guide-processing-guarantee\"></span><h4><a class=\"toc-backref\" href=\"#id25\">processing.guarantee</a><a class=\"headerlink\" href=\"#processing-guarantee\" title=\"Permalink to this headline\"></a></h4>\n           <blockquote>\n-            <div>The processing guarantee that should be used. Possible values are <code class=\"docutils literal\"><span class=\"pre\">\"at_least_once\"</span></code> (default) and <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once\"</span></code>.\n-                 Note that if exactly-once processing is enabled, the default for parameter <code class=\"docutils literal\"><span class=\"pre\">commit.interval.ms</span></code> changes to 100ms.\n+            <div>The processing guarantee that should be used.\n+                 Possible values are <code class=\"docutils literal\"><span class=\"pre\">\"at_least_once\"</span></code> (default),\n+                 <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once\"</span></code>,\n+                 and <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once_beta\"</span></code>.\n+                 Using <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once\"</span></code> requires broker\n+                 version 0.11.0 or newer, while using <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once_beta\"</span></code>\n+                 requires broker version 2.5 or newer.\n+                 Note that if exactly-once processing is enabled, the default for parameter\n+                 <code class=\"docutils literal\"><span class=\"pre\">commit.interval.ms</span></code> changes to 100ms.\n                  Additionally, consumers are configured with <code class=\"docutils literal\"><span class=\"pre\">isolation.level=\"read_committed\"</span></code>\n-                 and producers are configured with <code class=\"docutils literal\"><span class=\"pre\">retries=Integer.MAX_VALUE</span></code>, <code class=\"docutils literal\"><span class=\"pre\">enable.idempotence=true</span></code>,\n-                 and <code class=\"docutils literal\"><span class=\"pre\">max.in.flight.requests.per.connection=1</span></code> per default.\n+                 and producers are configured with <code class=\"docutils literal\"><span class=\"pre\">enable.idempotence=true</span></code> per default.\n                  Note that by default exactly-once processing requires a cluster of at least three brokers what is the recommended setting for production.\n-                 For development you can change this, by adjusting broker setting <code class=\"docutils literal\"><span class=\"pre\">transaction.state.log.replication.factor</span></code> and <code class=\"docutils literal\"><span class=\"pre\">transaction.state.log.min.isr</span></code> to the number of broker you want to use.\n+                 For development you can change this, by adjusting broker setting", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMjU4Mg==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422312582", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                             to the number of broker you want to use.\n          \n          \n            \n                             to the number of brokers you want to use.", "author": "JimGalasyn", "createdAt": "2020-05-08T18:52:32Z", "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -456,13 +457,22 @@ <h4><a class=\"toc-backref\" href=\"#id11\">num.stream.threads</a><a class=\"headerli\n         <div class=\"section\" id=\"processing-guarantee\">\n           <span id=\"streams-developer-guide-processing-guarantee\"></span><h4><a class=\"toc-backref\" href=\"#id25\">processing.guarantee</a><a class=\"headerlink\" href=\"#processing-guarantee\" title=\"Permalink to this headline\"></a></h4>\n           <blockquote>\n-            <div>The processing guarantee that should be used. Possible values are <code class=\"docutils literal\"><span class=\"pre\">\"at_least_once\"</span></code> (default) and <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once\"</span></code>.\n-                 Note that if exactly-once processing is enabled, the default for parameter <code class=\"docutils literal\"><span class=\"pre\">commit.interval.ms</span></code> changes to 100ms.\n+            <div>The processing guarantee that should be used.\n+                 Possible values are <code class=\"docutils literal\"><span class=\"pre\">\"at_least_once\"</span></code> (default),\n+                 <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once\"</span></code>,\n+                 and <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once_beta\"</span></code>.\n+                 Using <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once\"</span></code> requires broker\n+                 version 0.11.0 or newer, while using <code class=\"docutils literal\"><span class=\"pre\">\"exactly_once_beta\"</span></code>\n+                 requires broker version 2.5 or newer.\n+                 Note that if exactly-once processing is enabled, the default for parameter\n+                 <code class=\"docutils literal\"><span class=\"pre\">commit.interval.ms</span></code> changes to 100ms.\n                  Additionally, consumers are configured with <code class=\"docutils literal\"><span class=\"pre\">isolation.level=\"read_committed\"</span></code>\n-                 and producers are configured with <code class=\"docutils literal\"><span class=\"pre\">retries=Integer.MAX_VALUE</span></code>, <code class=\"docutils literal\"><span class=\"pre\">enable.idempotence=true</span></code>,\n-                 and <code class=\"docutils literal\"><span class=\"pre\">max.in.flight.requests.per.connection=1</span></code> per default.\n+                 and producers are configured with <code class=\"docutils literal\"><span class=\"pre\">enable.idempotence=true</span></code> per default.\n                  Note that by default exactly-once processing requires a cluster of at least three brokers what is the recommended setting for production.\n-                 For development you can change this, by adjusting broker setting <code class=\"docutils literal\"><span class=\"pre\">transaction.state.log.replication.factor</span></code> and <code class=\"docutils literal\"><span class=\"pre\">transaction.state.log.min.isr</span></code> to the number of broker you want to use.\n+                 For development you can change this, by adjusting broker setting\n+                 <code class=\"docutils literal\"><span class=\"pre\">transaction.state.log.replication.factor</span></code>\n+                 and <code class=\"docutils literal\"><span class=\"pre\">transaction.state.log.min.isr</span></code>\n+                 to the number of broker you want to use.", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMjg2NA==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422312864", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n          \n          \n            \n                    Starting in Kafka Streams 2.6.x, a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter", "author": "JimGalasyn", "createdAt": "2020-05-08T18:53:04Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMzA0NA==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422313044", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Hence, if you want to upgrade your application from an older version and enable this feature,\n          \n          \n            \n                    If you want to upgrade your application from an older version and enable this feature,", "author": "JimGalasyn", "createdAt": "2020-05-08T18:53:31Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n+        <code>processing.guarantee</code>) is available.\n+        To use this new feature, your brokers must be on version 2.5.x or newer.\n+        A switch from <code>\"exactly_once\"</code> to <code>\"exactly_once_beta\"</code> (or the other way around) is\n+        only possible if the application is on version 2.6.x.\n+        Hence, if you want to upgrade your application from an older version and enable this feature,", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMzM0OQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422313349", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    you first need to upgrade your application to version 2.6.x staying on <code>\"exactly_once\"</code>\n          \n          \n            \n                    you first need to upgrade your application to version 2.6.x, staying on <code>\"exactly_once\"</code>,", "author": "JimGalasyn", "createdAt": "2020-05-08T18:54:02Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n+        <code>processing.guarantee</code>) is available.\n+        To use this new feature, your brokers must be on version 2.5.x or newer.\n+        A switch from <code>\"exactly_once\"</code> to <code>\"exactly_once_beta\"</code> (or the other way around) is\n+        only possible if the application is on version 2.6.x.\n+        Hence, if you want to upgrade your application from an older version and enable this feature,\n+        you first need to upgrade your application to version 2.6.x staying on <code>\"exactly_once\"</code>", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMzUzMQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422313531", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    and afterwards do second round of rolling bounces to switch to <code>\"exactly_once_beta\"</code>.\n          \n          \n            \n                    and then do second round of rolling bounces to switch to <code>\"exactly_once_beta\"</code>.", "author": "JimGalasyn", "createdAt": "2020-05-08T18:54:25Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n+        <code>processing.guarantee</code>) is available.\n+        To use this new feature, your brokers must be on version 2.5.x or newer.\n+        A switch from <code>\"exactly_once\"</code> to <code>\"exactly_once_beta\"</code> (or the other way around) is\n+        only possible if the application is on version 2.6.x.\n+        Hence, if you want to upgrade your application from an older version and enable this feature,\n+        you first need to upgrade your application to version 2.6.x staying on <code>\"exactly_once\"</code>\n+        and afterwards do second round of rolling bounces to switch to <code>\"exactly_once_beta\"</code>.", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxMzk4MQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422313981", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    For a downgrade do the revers: first switch the config from <code>\"exactly_once_beta\"</code> to\n          \n          \n            \n                    For a downgrade, do the reverse: first switch the config from <code>\"exactly_once_beta\"</code> to", "author": "JimGalasyn", "createdAt": "2020-05-08T18:55:22Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n+        <code>processing.guarantee</code>) is available.\n+        To use this new feature, your brokers must be on version 2.5.x or newer.\n+        A switch from <code>\"exactly_once\"</code> to <code>\"exactly_once_beta\"</code> (or the other way around) is\n+        only possible if the application is on version 2.6.x.\n+        Hence, if you want to upgrade your application from an older version and enable this feature,\n+        you first need to upgrade your application to version 2.6.x staying on <code>\"exactly_once\"</code>\n+        and afterwards do second round of rolling bounces to switch to <code>\"exactly_once_beta\"</code>.\n+        For a downgrade do the revers: first switch the config from <code>\"exactly_once_beta\"</code> to", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxNDE1Nw==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422314157", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    <code>\"exactly_once\"</code>to disable the feature on your 2.6.x application.\n          \n          \n            \n                    <code>\"exactly_once\"</code> to disable the feature in your 2.6.x application.", "author": "JimGalasyn", "createdAt": "2020-05-08T18:55:41Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n+        <code>processing.guarantee</code>) is available.\n+        To use this new feature, your brokers must be on version 2.5.x or newer.\n+        A switch from <code>\"exactly_once\"</code> to <code>\"exactly_once_beta\"</code> (or the other way around) is\n+        only possible if the application is on version 2.6.x.\n+        Hence, if you want to upgrade your application from an older version and enable this feature,\n+        you first need to upgrade your application to version 2.6.x staying on <code>\"exactly_once\"</code>\n+        and afterwards do second round of rolling bounces to switch to <code>\"exactly_once_beta\"</code>.\n+        For a downgrade do the revers: first switch the config from <code>\"exactly_once_beta\"</code> to\n+        <code>\"exactly_once\"</code>to disable the feature on your 2.6.x application.", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxNDg2MQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422314861", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Afterward, you can downgrade your application to a pre 2.6.x version.\n          \n          \n            \n                    Afterward, you can downgrade your application to a pre-2.6.x version.", "author": "JimGalasyn", "createdAt": "2020-05-08T18:57:17Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -52,6 +52,20 @@ <h1>Upgrade Guide and API Changes</h1>\n         <li> restart all new ({{fullDotVersion}}) application instances </li>\n     </ul>\n \n+    <p>\n+        As of Kafka Streams 2.6.x a new processing mode <code>\"exactly_once_beta\"</code> (configurable via parameter\n+        <code>processing.guarantee</code>) is available.\n+        To use this new feature, your brokers must be on version 2.5.x or newer.\n+        A switch from <code>\"exactly_once\"</code> to <code>\"exactly_once_beta\"</code> (or the other way around) is\n+        only possible if the application is on version 2.6.x.\n+        Hence, if you want to upgrade your application from an older version and enable this feature,\n+        you first need to upgrade your application to version 2.6.x staying on <code>\"exactly_once\"</code>\n+        and afterwards do second round of rolling bounces to switch to <code>\"exactly_once_beta\"</code>.\n+        For a downgrade do the revers: first switch the config from <code>\"exactly_once_beta\"</code> to\n+        <code>\"exactly_once\"</code>to disable the feature on your 2.6.x application.\n+        Afterward, you can downgrade your application to a pre 2.6.x version.", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxNTI2OQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422315269", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    internally Streams switches from a producer per thread to a producer per task runtime model\n          \n          \n            \n                    internally Streams switches from a producer-per-thread to a producer-per-task runtime model.", "author": "JimGalasyn", "createdAt": "2020-05-08T18:58:07Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -761,16 +784,19 @@ <h3><a id=\"streams_api_changes_0110\" href=\"#streams_api_changes_0110\">Streams AP\n \n     <p> Metrics using exactly-once semantics: </p>\n     <p>\n-        If exactly-once processing is enabled via the <code>processing.guarantees</code> parameter, internally Streams switches from a producer per thread to a producer per task runtime model.\n+        If <code>\"exactly_once\"</code> processing is enabled via the <code>processing.guarantee</code> parameter,\n+        internally Streams switches from a producer per thread to a producer per task runtime model", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxNTk5MQ==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422315991", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    (Note: using <code>\"exactly_once_beta\"</code> does use a producer per thread and thus <code>client.id</code> don't change\n          \n          \n            \n                    Using <code>\"exactly_once_beta\"</code> does use a producer-per-thread, so <code>client.id</code> doesn't change,", "author": "JimGalasyn", "createdAt": "2020-05-08T18:59:30Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -761,16 +784,19 @@ <h3><a id=\"streams_api_changes_0110\" href=\"#streams_api_changes_0110\">Streams AP\n \n     <p> Metrics using exactly-once semantics: </p>\n     <p>\n-        If exactly-once processing is enabled via the <code>processing.guarantees</code> parameter, internally Streams switches from a producer per thread to a producer per task runtime model.\n+        If <code>\"exactly_once\"</code> processing is enabled via the <code>processing.guarantee</code> parameter,\n+        internally Streams switches from a producer per thread to a producer per task runtime model\n+        (Note: using <code>\"exactly_once_beta\"</code> does use a producer per thread and thus <code>client.id</code> don't change", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMxNjEyNA==", "url": "https://github.com/apache/kafka/pull/8621#discussion_r422316124", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    compare to <code>\"at_least_once\"</code> for this case).\n          \n          \n            \n                    compared with <code>\"at_least_once\"</code> for this case).", "author": "JimGalasyn", "createdAt": "2020-05-08T18:59:48Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -761,16 +784,19 @@ <h3><a id=\"streams_api_changes_0110\" href=\"#streams_api_changes_0110\">Streams AP\n \n     <p> Metrics using exactly-once semantics: </p>\n     <p>\n-        If exactly-once processing is enabled via the <code>processing.guarantees</code> parameter, internally Streams switches from a producer per thread to a producer per task runtime model.\n+        If <code>\"exactly_once\"</code> processing is enabled via the <code>processing.guarantee</code> parameter,\n+        internally Streams switches from a producer per thread to a producer per task runtime model\n+        (Note: using <code>\"exactly_once_beta\"</code> does use a producer per thread and thus <code>client.id</code> don't change\n+        compare to <code>\"at_least_once\"</code> for this case).", "originalCommit": "883c0d11ab4ff3f15b5cfd0cc44b16b0614bbf6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3e9498b33b33805007d7bf1451c7f1a8f3195c6e", "url": "https://github.com/apache/kafka/commit/3e9498b33b33805007d7bf1451c7f1a8f3195c6e", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:10:04Z", "type": "commit"}, {"oid": "61df8b639751a3c3dc13e09db3e0c6625d863ad3", "url": "https://github.com/apache/kafka/commit/61df8b639751a3c3dc13e09db3e0c6625d863ad3", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:10:33Z", "type": "commit"}, {"oid": "ca8ad53d3be7c3532a4cfd6be3c7e10460dc30f2", "url": "https://github.com/apache/kafka/commit/ca8ad53d3be7c3532a4cfd6be3c7e10460dc30f2", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:11:01Z", "type": "commit"}, {"oid": "b8be60bc8349a26757d955fdabb62386dfcf5b79", "url": "https://github.com/apache/kafka/commit/b8be60bc8349a26757d955fdabb62386dfcf5b79", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:11:16Z", "type": "commit"}, {"oid": "3379d81628f6c2821a70b9951a77541912868ff9", "url": "https://github.com/apache/kafka/commit/3379d81628f6c2821a70b9951a77541912868ff9", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:11:29Z", "type": "commit"}, {"oid": "42e23879243575b6f4402ae884705e1842058bdc", "url": "https://github.com/apache/kafka/commit/42e23879243575b6f4402ae884705e1842058bdc", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:11:41Z", "type": "commit"}, {"oid": "b3f2fcaa978ffdad38310960d663c4ae4722fd93", "url": "https://github.com/apache/kafka/commit/b3f2fcaa978ffdad38310960d663c4ae4722fd93", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:11:56Z", "type": "commit"}, {"oid": "90f0ff2bc5bf3b906b5685abddf1f24e64f3cfac", "url": "https://github.com/apache/kafka/commit/90f0ff2bc5bf3b906b5685abddf1f24e64f3cfac", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:12:18Z", "type": "commit"}, {"oid": "24f4c9ce074eb395adcc7a13901a2e66ecec5652", "url": "https://github.com/apache/kafka/commit/24f4c9ce074eb395adcc7a13901a2e66ecec5652", "message": "Update docs/streams/core-concepts.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:12:29Z", "type": "commit"}, {"oid": "d0f753c315a21c7175ebfbdb4ff28ca526284a39", "url": "https://github.com/apache/kafka/commit/d0f753c315a21c7175ebfbdb4ff28ca526284a39", "message": "Update docs/streams/developer-guide/config-streams.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:12:44Z", "type": "commit"}, {"oid": "b0f4104d1e8296a88ead7dfc66209f63e2bfb327", "url": "https://github.com/apache/kafka/commit/b0f4104d1e8296a88ead7dfc66209f63e2bfb327", "message": "Update docs/streams/developer-guide/config-streams.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:12:54Z", "type": "commit"}, {"oid": "602e909e0abe2ab320a2bdc89a995862fb3d9bf1", "url": "https://github.com/apache/kafka/commit/602e909e0abe2ab320a2bdc89a995862fb3d9bf1", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:13:09Z", "type": "commit"}, {"oid": "d22cae3037521407e36a4d70a081212f8165f328", "url": "https://github.com/apache/kafka/commit/d22cae3037521407e36a4d70a081212f8165f328", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:13:20Z", "type": "commit"}, {"oid": "5afd7c73d808af8471d1f222f1c34f5207cf1d23", "url": "https://github.com/apache/kafka/commit/5afd7c73d808af8471d1f222f1c34f5207cf1d23", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:13:35Z", "type": "commit"}, {"oid": "fdac684ec8d3d2f99cd967d0de9440324ecad9da", "url": "https://github.com/apache/kafka/commit/fdac684ec8d3d2f99cd967d0de9440324ecad9da", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:13:49Z", "type": "commit"}, {"oid": "dddd1b35c1584afb014fee8b1001be72a0f25fae", "url": "https://github.com/apache/kafka/commit/dddd1b35c1584afb014fee8b1001be72a0f25fae", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:14:08Z", "type": "commit"}, {"oid": "b778a7a754504074c4d2a501fc7e826f11eeb54f", "url": "https://github.com/apache/kafka/commit/b778a7a754504074c4d2a501fc7e826f11eeb54f", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:14:21Z", "type": "commit"}, {"oid": "82a72adb0c7364d9b882eb070d195c1a140f4352", "url": "https://github.com/apache/kafka/commit/82a72adb0c7364d9b882eb070d195c1a140f4352", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:14:36Z", "type": "commit"}, {"oid": "05830b0a895833aa116e4c34b9286dac7f7cb15b", "url": "https://github.com/apache/kafka/commit/05830b0a895833aa116e4c34b9286dac7f7cb15b", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:14:50Z", "type": "commit"}, {"oid": "f6f609336cc42f7c79102ce5c1e508fe7c2b7f09", "url": "https://github.com/apache/kafka/commit/f6f609336cc42f7c79102ce5c1e508fe7c2b7f09", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:15:12Z", "type": "commit"}, {"oid": "a2a46281f1c699c9d558676e2912dda23383dfa8", "url": "https://github.com/apache/kafka/commit/a2a46281f1c699c9d558676e2912dda23383dfa8", "message": "Update docs/streams/upgrade-guide.html\n\nCo-authored-by: Jim Galasyn <jim.galasyn@confluent.io>", "committedDate": "2020-05-08T22:15:27Z", "type": "commit"}]}