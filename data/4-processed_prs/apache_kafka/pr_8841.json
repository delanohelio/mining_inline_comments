{"pr_number": 8841, "pr_title": "KAFKA-10123 Fix incorrect value for AWAIT_RESET#hasPosition", "pr_createdAt": "2020-06-09T21:16:08Z", "pr_url": "https://github.com/apache/kafka/pull/8841", "timeline": [{"oid": "034ca938e91dc6f81440b39733e29028a1729bca", "url": "https://github.com/apache/kafka/commit/034ca938e91dc6f81440b39733e29028a1729bca", "message": "Fix incorrect result for AWAIT_RESET#hasPosition\n\nAlso ensure we are updating the position with the current leader info even when\nfetching from older brokers", "committedDate": "2020-06-09T20:58:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMzIwOA==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r437913208", "bodyText": "As it produced a bug, could you add some comment for this method?", "author": "chia7712", "createdAt": "2020-06-10T07:26:34Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -978,7 +1000,7 @@ public boolean hasValidPosition() {\n \n             @Override\n             public boolean hasPosition() {", "originalCommit": "034ca938e91dc6f81440b39733e29028a1729bca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM0Njg3MQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r438346871", "bodyText": "It's a bit weird to add a comment here and not elsewhere. It looks like a clear bug since hasValidPosition returns false. Generally, comments are useful when it's not obvious. What kind of clarification would you like to see?", "author": "ijuma", "createdAt": "2020-06-10T19:05:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMzIwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUxMDEyMQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r439510121", "bodyText": "I added some javadoc to the interface", "author": "mumrah", "createdAt": "2020-06-12T16:08:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMzIwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxODYxMA==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r437918610", "bodyText": "nit: newPosition can be created lazy.", "author": "chia7712", "createdAt": "2020-06-10T07:36:37Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -799,6 +806,21 @@ private boolean maybeValidatePosition(Metadata.LeaderAndEpoch currentLeaderAndEp\n             return this.fetchState.equals(FetchStates.AWAIT_VALIDATION);\n         }\n \n+        /**\n+         * For older versions of the API, we cannot perform offset validation so we simply transition directly to FETCHING\n+         *\n+         * @param currentLeaderAndEpoch\n+         */\n+        private void updatePositionLeaderNoValidation(Metadata.LeaderAndEpoch currentLeaderAndEpoch) {\n+            if (position != null && !position.currentLeader.equals(currentLeaderAndEpoch)) {\n+                FetchPosition newPosition = new FetchPosition(position.offset, position.offsetEpoch, currentLeaderAndEpoch);", "originalCommit": "034ca938e91dc6f81440b39733e29028a1729bca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY4MzY1Mg==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441683652", "bodyText": "+1. Moving this into the transition function below seems reasonable.", "author": "hachikuji", "createdAt": "2020-06-17T16:44:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxODYxMA=="}], "type": "inlineReview"}, {"oid": "e07605c5ff441814fb44acee4d630cca92c886f8", "url": "https://github.com/apache/kafka/commit/e07605c5ff441814fb44acee4d630cca92c886f8", "message": "Add some protection against NPE when reading the position", "committedDate": "2020-06-10T14:59:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2Mjg5NQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r438362895", "bodyText": "Would it make sense to move hasPosition to TopicPartitionState? Then we could just turn this into a null check on position.", "author": "hachikuji", "createdAt": "2020-06-10T19:36:48Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -978,7 +1000,7 @@ public boolean hasValidPosition() {\n \n             @Override\n             public boolean hasPosition() {", "originalCommit": "e07605c5ff441814fb44acee4d630cca92c886f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg3MDQ1Mg==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r438870452", "bodyText": "I thought about this too, but if i recall, the whole point of adding the state enum was to not rely on the instance variables to deduce the state. I think another solution here would be to have some kind of empty position monad to avoid the null in the first place.", "author": "mumrah", "createdAt": "2020-06-11T15:27:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2Mjg5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTAwOTA5NA==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r439009094", "bodyText": "Sure, but that led to the opposite problem, in which the enum was inconsistent with the state. In regard to position, I think we should handle this at transition time as mentioned below. If we ensure that position is not null in the fetching and validating states, then I don't see a problem changing hasPosition to check it directly.", "author": "hachikuji", "createdAt": "2020-06-11T19:07:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2Mjg5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQ0NTg0MQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r439445841", "bodyText": "Ok, sounds good", "author": "mumrah", "createdAt": "2020-06-12T14:16:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2Mjg5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2ODk0OQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r438368949", "bodyText": "I think the invariant that we try to maintain is that we should have a position if we are in the FETCHING state. I'd suggest we detect this in transitionState and raise the exception at that point. Otherwise, we could reach an illegal state and the consumer would just stop fetching the partition. Failing fast is probably preferable. What I have in mind is just something like this:\n        private void transitionState(FetchState newState, Runnable runIfTransitioned) {\n            FetchState nextState = this.fetchState.transitionTo(newState);\n            if (nextState.equals(newState)) {\n                if (position == null && (nextState == FETCHING || nextState == AWAIT_VALIDATION))\n                   throw new IllegalStateException();\n                this.fetchState = nextState;\n                runIfTransitioned.run();\n            }\n        }", "author": "hachikuji", "createdAt": "2020-06-10T19:48:11Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -675,36 +676,41 @@ private ListOffsetResult fetchOffsetsByTimes(Map<TopicPartition, Long> timestamp\n                     completedFetch.partition);\n         } else {\n             FetchPosition position = subscriptions.position(completedFetch.partition);\n-            if (completedFetch.nextFetchOffset == position.offset) {\n-                List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n-\n-                log.trace(\"Returning {} fetched records at offset {} for assigned partition {}\",\n-                        partRecords.size(), position, completedFetch.partition);\n-\n-                if (completedFetch.nextFetchOffset > position.offset) {\n-                    FetchPosition nextPosition = new FetchPosition(\n-                            completedFetch.nextFetchOffset,\n-                            completedFetch.lastEpoch,\n-                            position.currentLeader);\n-                    log.trace(\"Update fetching position to {} for partition {}\", nextPosition, completedFetch.partition);\n-                    subscriptions.position(completedFetch.partition, nextPosition);\n-                }\n+            if (position != null) {", "originalCommit": "e07605c5ff441814fb44acee4d630cca92c886f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM3OTI0Nw==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r438379247", "bodyText": "Yea, I see what you mean. It's probably a good idea to add a check here.", "author": "mumrah", "createdAt": "2020-06-10T20:08:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2ODk0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODg2NzUzNQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r438867535", "bodyText": "I think we need the check in transition since we set the position in the runnable sometimes. E.g.,\n    private void transitionState(FetchState newState, Runnable runIfTransitioned) {\n            FetchState nextState = this.fetchState.transitionTo(newState);\n            if (nextState.equals(newState)) {\n                this.fetchState = nextState;\n                runIfTransitioned.run();\n                if (this.position == null && nextState.hasPosition()) {\n                    throw new IllegalStateException(\"Transitioned subscription state to \" + nextState + \", but position is null\");\n                }\n            }\n        }", "author": "mumrah", "createdAt": "2020-06-11T15:24:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2ODk0OQ=="}], "type": "inlineReview"}, {"oid": "8fd47fb7c97c5c15e0a7458f7d6df116a28819ee", "url": "https://github.com/apache/kafka/commit/8fd47fb7c97c5c15e0a7458f7d6df116a28819ee", "message": "Fix some logic that was inverted with the change to AWAIT_RESET", "committedDate": "2020-06-10T20:51:44Z", "type": "commit"}, {"oid": "0795a276de2060cfb6d56243f5a7c944fa1b3a0b", "url": "https://github.com/apache/kafka/commit/0795a276de2060cfb6d56243f5a7c944fa1b3a0b", "message": "Fix logic inversion in resetMissingPositions", "committedDate": "2020-06-11T14:14:31Z", "type": "commit"}, {"oid": "2a8764e7ef6ba8fe9d81c968605c1b65301eb5e9", "url": "https://github.com/apache/kafka/commit/2a8764e7ef6ba8fe9d81c968605c1b65301eb5e9", "message": "Feedback from PR", "committedDate": "2020-06-11T18:00:53Z", "type": "commit"}, {"oid": "c9e7ff335ce94b0bcf0094bfcb128bbcb2429d5a", "url": "https://github.com/apache/kafka/commit/c9e7ff335ce94b0bcf0094bfcb128bbcb2429d5a", "message": "Always skip validation regardless of position's leader+epoch", "committedDate": "2020-06-11T18:01:27Z", "type": "commit"}, {"oid": "7d676c1e7f892ea4dbed194e44aadd262fd0f13d", "url": "https://github.com/apache/kafka/commit/7d676c1e7f892ea4dbed194e44aadd262fd0f13d", "message": "Merge remote-tracking branch 'apache-github/trunk' into KAFKA-10123", "committedDate": "2020-06-11T20:27:12Z", "type": "commit"}, {"oid": "01c18ce17c0d950214ddcbd8d4fb55a7421365ba", "url": "https://github.com/apache/kafka/commit/01c18ce17c0d950214ddcbd8d4fb55a7421365ba", "message": "Feedback from PR", "committedDate": "2020-06-12T02:39:32Z", "type": "commit"}, {"oid": "37500eea93caf87f49c952dd56f39f3887dc1a5e", "url": "https://github.com/apache/kafka/commit/37500eea93caf87f49c952dd56f39f3887dc1a5e", "message": "Cleanup javadoc", "committedDate": "2020-06-12T14:18:31Z", "type": "commit"}, {"oid": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93", "url": "https://github.com/apache/kafka/commit/63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93", "message": "Merge remote-tracking branch 'apache-github/trunk' into KAFKA-10123", "committedDate": "2020-06-15T13:58:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk4NDcwNQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r440984705", "bodyText": "This comment applies to a few of the added null checks where we have already validated that the partition is \"fetchable.\" I am wondering if it would be more consistent to raise an exception.", "author": "hachikuji", "createdAt": "2020-06-16T16:29:21Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -675,36 +676,41 @@ private ListOffsetResult fetchOffsetsByTimes(Map<TopicPartition, Long> timestamp\n                     completedFetch.partition);\n         } else {\n             FetchPosition position = subscriptions.position(completedFetch.partition);\n-            if (completedFetch.nextFetchOffset == position.offset) {\n-                List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n-\n-                log.trace(\"Returning {} fetched records at offset {} for assigned partition {}\",\n-                        partRecords.size(), position, completedFetch.partition);\n-\n-                if (completedFetch.nextFetchOffset > position.offset) {\n-                    FetchPosition nextPosition = new FetchPosition(\n-                            completedFetch.nextFetchOffset,\n-                            completedFetch.lastEpoch,\n-                            position.currentLeader);\n-                    log.trace(\"Update fetching position to {} for partition {}\", nextPosition, completedFetch.partition);\n-                    subscriptions.position(completedFetch.partition, nextPosition);\n-                }\n+            if (position != null) {\n+                if (completedFetch.nextFetchOffset == position.offset) {\n+                    List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n+\n+                    log.trace(\"Returning {} fetched records at offset {} for assigned partition {}\",\n+                            partRecords.size(), position, completedFetch.partition);\n+\n+                    if (completedFetch.nextFetchOffset > position.offset) {\n+                        FetchPosition nextPosition = new FetchPosition(\n+                                completedFetch.nextFetchOffset,\n+                                completedFetch.lastEpoch,\n+                                position.currentLeader);\n+                        log.trace(\"Update fetching position to {} for partition {}\", nextPosition, completedFetch.partition);\n+                        subscriptions.position(completedFetch.partition, nextPosition);\n+                    }\n \n-                Long partitionLag = subscriptions.partitionLag(completedFetch.partition, isolationLevel);\n-                if (partitionLag != null)\n-                    this.sensors.recordPartitionLag(completedFetch.partition, partitionLag);\n+                    Long partitionLag = subscriptions.partitionLag(completedFetch.partition, isolationLevel);\n+                    if (partitionLag != null)\n+                        this.sensors.recordPartitionLag(completedFetch.partition, partitionLag);\n \n-                Long lead = subscriptions.partitionLead(completedFetch.partition);\n-                if (lead != null) {\n-                    this.sensors.recordPartitionLead(completedFetch.partition, lead);\n-                }\n+                    Long lead = subscriptions.partitionLead(completedFetch.partition);\n+                    if (lead != null) {\n+                        this.sensors.recordPartitionLead(completedFetch.partition, lead);\n+                    }\n \n-                return partRecords;\n+                    return partRecords;\n+                } else {\n+                    // these records aren't next in line based on the last consumed position, ignore them\n+                    // they must be from an obsolete request\n+                    log.debug(\"Ignoring fetched records for {} at offset {} since the current position is {}\",\n+                            completedFetch.partition, completedFetch.nextFetchOffset, position);\n+                }\n             } else {\n-                // these records aren't next in line based on the last consumed position, ignore them\n-                // they must be from an obsolete request\n-                log.debug(\"Ignoring fetched records for {} at offset {} since the current position is {}\",\n-                        completedFetch.partition, completedFetch.nextFetchOffset, position);\n+                log.warn(\"Ignoring fetched records for {} at offset {} since the current position is undefined\",", "originalCommit": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAwNzEzMQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441007131", "bodyText": "Would IllegalStateException make sense here (since we just checked that the partition was fetchable)?", "author": "mumrah", "createdAt": "2020-06-16T17:04:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk4NDcwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAzNjg4Ng==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441036886", "bodyText": "Sounds fine to me.", "author": "hachikuji", "createdAt": "2020-06-16T17:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk4NDcwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5MDM0Mw==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r440990343", "bodyText": "Should we change the name of this method to something like resetInitializingPositions?", "author": "hachikuji", "createdAt": "2020-06-16T16:37:01Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -647,7 +647,7 @@ public synchronized void resetMissingPositions() {\n         assignment.stream().forEach(state -> {\n             TopicPartition tp = state.topicPartition();\n             TopicPartitionState partitionState = state.value();\n-            if (!partitionState.hasPosition()) {\n+            if (partitionState.fetchState.equals(FetchStates.INITIALIZING)) {", "originalCommit": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5Mzc4MA==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r440993780", "bodyText": "Since the usage is a bit different, maybe we could change the name to requiresPosition. Then this check seems a little more intuitive:\n                if (this.position == null && nextState.requiresPosition()) {\n                    throw new IllegalStateException(\"Transitioned subscription state to \" + nextState + \", but position is null\");\n                }", "author": "hachikuji", "createdAt": "2020-06-16T16:42:18Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -924,10 +949,19 @@ default FetchState transitionTo(FetchState newState) {\n             }\n         }\n \n+        /**\n+         * Return the valid states which this state can transition to\n+         */\n         Collection<FetchState> validTransitions();\n \n+        /**\n+         * Test if this state has a position", "originalCommit": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5NjYwMw==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r440996603", "bodyText": "Would it make sense to set position explicitly to null if the FetchState does not expect to have it. For example, it seems currently when we reset the offset, we leave position at whatever value it had previously. If we were initializing, then it would be null. If we had an offset out of range, it would be non-null. It might be easier to reason about the logic if it is always null in the AWAIT_RESET state.", "author": "hachikuji", "createdAt": "2020-06-16T16:46:56Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -745,6 +745,9 @@ private void transitionState(FetchState newState, Runnable runIfTransitioned) {\n             if (nextState.equals(newState)) {\n                 this.fetchState = nextState;\n                 runIfTransitioned.run();\n+                if (this.position == null && nextState.hasPosition()) {", "originalCommit": "63c1b14a4c251ed5c2ff76e0d735ca95df3f9f93", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEwOTM5OA==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441109398", "bodyText": "Yea, sounds good \ud83d\udc4d", "author": "mumrah", "createdAt": "2020-06-16T20:03:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5NjYwMw=="}], "type": "inlineReview"}, {"oid": "4ad8e5a4fbcb7d835a70f868a7d6a41bddd8e998", "url": "https://github.com/apache/kafka/commit/4ad8e5a4fbcb7d835a70f868a7d6a41bddd8e998", "message": "Feedback from PR", "committedDate": "2020-06-16T19:19:43Z", "type": "commit"}, {"oid": "56b2fca4790018429bfecf801433bf5fe0aeceb6", "url": "https://github.com/apache/kafka/commit/56b2fca4790018429bfecf801433bf5fe0aeceb6", "message": "Merge remote-tracking branch 'apache-github/trunk' into KAFKA-10123", "committedDate": "2020-06-16T19:19:47Z", "type": "commit"}, {"oid": "994150ee13aa286713e0a608cb3b3093767cdfd3", "url": "https://github.com/apache/kafka/commit/994150ee13aa286713e0a608cb3b3093767cdfd3", "message": "Merge remote-tracking branch 'apache-github/trunk' into KAFKA-10123", "committedDate": "2020-06-16T20:02:13Z", "type": "commit"}, {"oid": "e12d62f270f029de1f9ee995f04fb24f2329bce2", "url": "https://github.com/apache/kafka/commit/e12d62f270f029de1f9ee995f04fb24f2329bce2", "message": "Merge remote-tracking branch 'mumrah/KAFKA-10123' into KAFKA-10123", "committedDate": "2020-06-16T20:02:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTExNTk3Mw==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441115973", "bodyText": "nit: maybe we could check for null first so that we avoid the nesting below (and reduce the diff)\nif (position == null)\n  throw new IllegalStateException(\"Missing position for fetchable partition \" + completedFetch.partition);\n\nif (completedFetch.nextFetchOffset == position.offset) {\n...", "author": "hachikuji", "createdAt": "2020-06-16T20:16:44Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -675,36 +676,40 @@ private ListOffsetResult fetchOffsetsByTimes(Map<TopicPartition, Long> timestamp\n                     completedFetch.partition);\n         } else {\n             FetchPosition position = subscriptions.position(completedFetch.partition);\n-            if (completedFetch.nextFetchOffset == position.offset) {\n-                List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n-\n-                log.trace(\"Returning {} fetched records at offset {} for assigned partition {}\",\n-                        partRecords.size(), position, completedFetch.partition);\n-\n-                if (completedFetch.nextFetchOffset > position.offset) {\n-                    FetchPosition nextPosition = new FetchPosition(\n-                            completedFetch.nextFetchOffset,\n-                            completedFetch.lastEpoch,\n-                            position.currentLeader);\n-                    log.trace(\"Update fetching position to {} for partition {}\", nextPosition, completedFetch.partition);\n-                    subscriptions.position(completedFetch.partition, nextPosition);\n-                }\n+            if (position != null) {", "originalCommit": "e12d62f270f029de1f9ee995f04fb24f2329bce2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9885fa68582b988852b3da01796119b57df53fba", "url": "https://github.com/apache/kafka/commit/9885fa68582b988852b3da01796119b57df53fba", "message": "Reduce diff on Fetcher#fetchRecords", "committedDate": "2020-06-16T22:59:36Z", "type": "commit"}, {"oid": "bf29e79c4e00c34b800280f533b8c3fcf6becbd9", "url": "https://github.com/apache/kafka/commit/bf29e79c4e00c34b800280f533b8c3fcf6becbd9", "message": "Update/remove assertions relating to position after a reset", "committedDate": "2020-06-17T13:43:39Z", "type": "commit"}, {"oid": "10f1e90d0288747c579dd760701e6c0f29052ba4", "url": "https://github.com/apache/kafka/commit/10f1e90d0288747c579dd760701e6c0f29052ba4", "message": "Checkstyle", "committedDate": "2020-06-17T14:29:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY3NDA2Ng==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441674066", "bodyText": "Hmm, if the position is null, we raise out of range?", "author": "hachikuji", "createdAt": "2020-06-17T16:29:12Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -1281,11 +1291,12 @@ private CompletedFetch initializeCompletedFetch(CompletedFetch nextCompletedFetc\n                 Optional<Integer> clearedReplicaId = subscriptions.clearPreferredReadReplica(tp);\n                 if (!clearedReplicaId.isPresent()) {\n                     // If there's no preferred replica to clear, we're fetching from the leader so handle this error normally\n-                    if (fetchOffset != subscriptions.position(tp).offset) {\n+                    FetchPosition position = subscriptions.position(tp);\n+                    if (position != null && fetchOffset != position.offset) {\n                         log.debug(\"Discarding stale fetch response for partition {} since the fetched offset {} \" +\n-                                \"does not match the current offset {}\", tp, fetchOffset, subscriptions.position(tp));\n+                                \"does not match the current offset {}\", tp, fetchOffset, position);\n                     } else {\n-                        handleOffsetOutOfRange(subscriptions.position(tp), tp, \"error response in offset fetch\");\n+                        handleOffsetOutOfRange(position, tp, \"error response in offset fetch\");", "originalCommit": "10f1e90d0288747c579dd760701e6c0f29052ba4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc0MjkwMQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441742901", "bodyText": "What should we do here for null position? This can happen if we get OOOR while we're in the middle of a reset. Maybe we should just log a warning? Or maybe just change the condition to\nif (position == null || fetchOffset != position.offset)", "author": "mumrah", "createdAt": "2020-06-17T18:25:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY3NDA2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc3NjIzNQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441776235", "bodyText": "Since we have the check for hasValidPosition at the start of this method, we could raise an exception. However, in the success case, we currently just ignore the response if the position is null. I'm ok with either option.", "author": "hachikuji", "createdAt": "2020-06-17T19:15:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY3NDA2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTkzMzExMw==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441933113", "bodyText": "I'm inclined to keep the same behavior as we previously did and just warn (not that we expect this case to get hit anymore)", "author": "mumrah", "createdAt": "2020-06-18T02:28:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY3NDA2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY3NDc2OA==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441674768", "bodyText": "nit: rename variable as well?", "author": "hachikuji", "createdAt": "2020-06-17T16:30:23Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerCoordinator.java", "diffHunk": "@@ -783,7 +783,7 @@ public boolean rejoinNeededOrPending() {\n      * @return true iff the operation completed within the timeout\n      */\n     public boolean refreshCommittedOffsetsIfNeeded(Timer timer) {\n-        final Set<TopicPartition> missingFetchPositions = subscriptions.missingFetchPositions();\n+        final Set<TopicPartition> missingFetchPositions = subscriptions.initializingPartitions();", "originalCommit": "10f1e90d0288747c579dd760701e6c0f29052ba4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY4MDYxOA==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441680618", "bodyText": "nit: document return", "author": "hachikuji", "createdAt": "2020-06-17T16:40:07Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -782,6 +787,13 @@ private void reset(OffsetResetStrategy strategy) {\n             });\n         }\n \n+        /**\n+         * Check if the position exists and needs to be validated. If so, enter the AWAIT_VALIDATION state. This method\n+         * also will update the position with the current leader and epoch.\n+         *\n+         * @param currentLeaderAndEpoch leader and epoch to compare the offset with\n+         * @return", "originalCommit": "10f1e90d0288747c579dd760701e6c0f29052ba4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY4NDA2Mw==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441684063", "bodyText": "nit: fix doc", "author": "hachikuji", "createdAt": "2020-06-17T16:45:30Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/SubscriptionState.java", "diffHunk": "@@ -924,10 +951,19 @@ default FetchState transitionTo(FetchState newState) {\n             }\n         }\n \n+        /**\n+         * Return the valid states which this state can transition to\n+         */\n         Collection<FetchState> validTransitions();\n \n-        boolean hasPosition();\n+        /**\n+         * Test if this state has a position", "originalCommit": "10f1e90d0288747c579dd760701e6c0f29052ba4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY5MDkzNA==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441690934", "bodyText": "This test would might be more interesting if we did a seek which required validation. Could we provide an epoch in the fetch position? Maybe both cases should be covered?", "author": "hachikuji", "createdAt": "2020-06-17T16:56:21Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/SubscriptionStateTest.java", "diffHunk": "@@ -673,4 +673,37 @@ public void onPartitionsRevoked(Collection<TopicPartition> partitions) {\n \n     }\n \n+    @Test\n+    public void resetOffsetNoValidation() {\n+        // Check that offset reset works when we can't validate offsets (older brokers)\n+\n+        Node broker1 = new Node(1, \"localhost\", 9092);\n+        state.assignFromUser(Collections.singleton(tp0));\n+\n+        // Reset offsets\n+        state.requestOffsetReset(tp0, OffsetResetStrategy.EARLIEST);\n+\n+        // Attempt to validate with older API version, should do nothing\n+        ApiVersions oldApis = new ApiVersions();\n+        oldApis.update(\"1\", NodeApiVersions.create(ApiKeys.OFFSET_FOR_LEADER_EPOCH.id, (short) 0, (short) 2));\n+        assertFalse(state.maybeValidatePositionForCurrentLeader(oldApis, tp0, new Metadata.LeaderAndEpoch(\n+                Optional.of(broker1), Optional.empty())));\n+        assertFalse(state.hasValidPosition(tp0));\n+        assertFalse(state.awaitingValidation(tp0));\n+        assertTrue(state.isOffsetResetNeeded(tp0));\n+\n+        // Complete the reset via unvalidated seek\n+        state.seekUnvalidated(tp0, new SubscriptionState.FetchPosition(10L));", "originalCommit": "10f1e90d0288747c579dd760701e6c0f29052ba4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTc0NzkzNQ==", "url": "https://github.com/apache/kafka/pull/8841#discussion_r441747935", "bodyText": "Sure, I'll add another case", "author": "mumrah", "createdAt": "2020-06-17T18:34:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY5MDkzNA=="}], "type": "inlineReview"}, {"oid": "332aeffedcbe435eafab63be4f51e7f4449e9891", "url": "https://github.com/apache/kafka/commit/332aeffedcbe435eafab63be4f51e7f4449e9891", "message": "Feedback from PR", "committedDate": "2020-06-17T18:55:26Z", "type": "commit"}]}