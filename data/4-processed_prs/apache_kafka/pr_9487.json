{"pr_number": 9487, "pr_title": "KAFKA-9331: Add a streams specific uncaught exception handler", "pr_createdAt": "2020-10-23T20:45:51Z", "pr_url": "https://github.com/apache/kafka/pull/9487", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE0ODYwMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r511148601", "bodyText": "This will call closeToError but I am testing if that has a problem. So far it does not", "author": "wcarlson5", "createdAt": "2020-10-23T20:48:43Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -782,7 +849,12 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 cacheSizePerThread,\n                 stateDirectory,\n                 delegatingStateRestoreListener,\n-                i + 1);\n+                i + 1,\n+                KafkaStreams.this::close,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE0OTAxNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r511149017", "bodyText": "moved into stream thread because of a concurrent operation exception that appeared", "author": "wcarlson5", "createdAt": "2020-10-23T20:49:47Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -346,26 +351,92 @@ public void setStateListener(final KafkaStreams.StateListener listener) {\n      * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread} abruptly\n      * terminates due to an uncaught exception.\n      *\n-     * @param eh the uncaught exception handler for all internal threads; {@code null} deletes the current handler\n+     * @param uncaughtExceptionHandler the uncaught exception handler for all internal threads; {@code null} deletes the current handler\n      * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     *\n+     * @Deprecated Since 2.7.0. Use {@link KafkaStreams#setUncaughtExceptionHandler(StreamsUncaughtExceptionHandler)} instead.\n+     *\n      */\n-    public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh) {\n+    public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler uncaughtExceptionHandler) {\n         synchronized (stateLock) {\n             if (state == State.CREATED) {\n                 for (final StreamThread thread : threads) {\n-                    thread.setUncaughtExceptionHandler(eh);\n+                    thread.setUncaughtExceptionHandler(uncaughtExceptionHandler);\n                 }\n \n                 if (globalStreamThread != null) {\n-                    globalStreamThread.setUncaughtExceptionHandler(eh);\n+                    globalStreamThread.setUncaughtExceptionHandler(uncaughtExceptionHandler);\n                 }\n             } else {\n                 throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n-                    \"Current state is: \" + state);\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads; {@code null} deletes the current handler\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException @NotNull if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n             }\n         }\n     }\n \n+    private StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse handleStreamsUncaughtException(final Throwable e,\n+                                                                                                         final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        switch (action) {\n+//            case REPLACE_STREAM_THREAD:\n+//                log.error(\"Encountered the following exception during processing \" +\n+//                        \"and the the stream thread will be replaced: \", e);\n+//            this.addStreamsThread();\n+//                break;\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the client is going to shut down: \", e);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (e instanceof Error) {\n+                    log.error(\"This option requires the thread to stay running to start the shutdown.\" +\n+                            \"Therefore it is not suitable for Error types.\");\n+                }\n+//                for (final StreamThread streamThread: threads) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjMyMDQ0Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r512320447", "bodyText": "Method was a few lines too long", "author": "wcarlson5", "createdAt": "2020-10-26T23:03:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -659,7 +727,6 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                          final Time time) throws StreamsException {\n         this.config = config;\n         this.time = time;\n-", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNzk1MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517507950", "bodyText": "IMO, it would be better to extract code to methods instead of removing some lines.", "author": "cadonna", "createdAt": "2020-11-04T17:22:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjMyMDQ0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUyNzYwNQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514527605", "bodyText": "Is this spacing on purpose?", "author": "lct45", "createdAt": "2020-10-29T19:57:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -346,26 +351,89 @@ public void setStateListener(final KafkaStreams.StateListener listener) {\n      * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread} abruptly\n      * terminates due to an uncaught exception.\n      *\n-     * @param eh the uncaught exception handler for all internal threads; {@code null} deletes the current handler\n+     * @param uncaughtExceptionHandler the uncaught exception handler for all internal threads; {@code null} deletes the current handler\n      * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     *\n+     * @Deprecated Since 2.7.0. Use {@link KafkaStreams#setUncaughtExceptionHandler(StreamsUncaughtExceptionHandler)} instead.\n+     *\n      */\n-    public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh) {\n+    public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler uncaughtExceptionHandler) {\n         synchronized (stateLock) {\n             if (state == State.CREATED) {\n                 for (final StreamThread thread : threads) {\n-                    thread.setUncaughtExceptionHandler(eh);\n+                    thread.setUncaughtExceptionHandler(uncaughtExceptionHandler);\n                 }\n \n                 if (globalStreamThread != null) {\n-                    globalStreamThread.setUncaughtExceptionHandler(eh);\n+                    globalStreamThread.setUncaughtExceptionHandler(uncaughtExceptionHandler);\n                 }\n             } else {\n                 throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n-                    \"Current state is: \" + state);\n+                        \"Current state is: \" + state);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzMTU5Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514531597", "bodyText": "Is this section going to be re-added after the other thread handling stuff gets figured out?", "author": "lct45", "createdAt": "2020-10-29T20:03:00Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -346,26 +351,89 @@ public void setStateListener(final KafkaStreams.StateListener listener) {\n      * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread} abruptly\n      * terminates due to an uncaught exception.\n      *\n-     * @param eh the uncaught exception handler for all internal threads; {@code null} deletes the current handler\n+     * @param uncaughtExceptionHandler the uncaught exception handler for all internal threads; {@code null} deletes the current handler\n      * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     *\n+     * @Deprecated Since 2.7.0. Use {@link KafkaStreams#setUncaughtExceptionHandler(StreamsUncaughtExceptionHandler)} instead.\n+     *\n      */\n-    public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh) {\n+    public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler uncaughtExceptionHandler) {\n         synchronized (stateLock) {\n             if (state == State.CREATED) {\n                 for (final StreamThread thread : threads) {\n-                    thread.setUncaughtExceptionHandler(eh);\n+                    thread.setUncaughtExceptionHandler(uncaughtExceptionHandler);\n                 }\n \n                 if (globalStreamThread != null) {\n-                    globalStreamThread.setUncaughtExceptionHandler(eh);\n+                    globalStreamThread.setUncaughtExceptionHandler(uncaughtExceptionHandler);\n                 }\n             } else {\n                 throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n-                    \"Current state is: \" + state);\n+                        \"Current state is: \" + state);\n             }\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads; {@code null} deletes the current handler\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException @NotNull if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse handleStreamsUncaughtException(final Throwable e,\n+                                                                                                         final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        switch (action) {\n+//            case REPLACE_STREAM_THREAD:", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDU2NjcwMA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514566700", "bodyText": "It will. I don't know if we should merge as comment or just add it later", "author": "wcarlson5", "createdAt": "2020-10-29T21:05:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzMTU5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NjgzMA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r516996830", "bodyText": "It's normally kinda weird to merge commented-out code. I'd either delete it or instead have a todo, like // TODO KAFKA-XXXX: add case REPLACE_STREAM_THREAD once KIP-??? is implemented, where KAFKA-XXXX is a follow-up ticket you create to implement this feature.", "author": "vvcephei", "createdAt": "2020-11-03T22:38:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzMTU5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ4NjEzNQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517486135", "bodyText": "I would also remove the commented-out code.", "author": "cadonna", "createdAt": "2020-11-04T16:49:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzMTU5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzNTM1Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514535353", "bodyText": "Supposed to be here?", "author": "lct45", "createdAt": "2020-10-29T20:07:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/errors/StreamsUncaughtExceptionHandler.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.errors;\n+\n+public interface StreamsUncaughtExceptionHandler {\n+    /**\n+     * Inspect the exception received in a stream thread and respond with an action.\n+     * @param exception the actual exception\n+     */\n+    StreamThreadExceptionResponse handle(final Throwable exception);\n+\n+    /**\n+     * Enumeration that describes the response from the exception handler.\n+     */\n+    enum StreamThreadExceptionResponse {\n+        //        REPLACE_THREAD(0, \"REPLACE_THREAD\"),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDU2NzAyOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514567028", "bodyText": "Same as the other use in KS", "author": "wcarlson5", "createdAt": "2020-10-29T21:05:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzNTM1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkxMDUzOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517910538", "bodyText": "Could you also remove the commented-out code here.", "author": "cadonna", "createdAt": "2020-11-05T09:34:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzNTM1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzNTczNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514535737", "bodyText": "two new lines in a row", "author": "lct45", "createdAt": "2020-10-29T20:08:33Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -282,6 +284,15 @@ public boolean isRunning() {\n     private final Admin adminClient;\n     private final InternalTopologyBuilder builder;\n \n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzNjM2Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514536366", "bodyText": "extra line", "author": "lct45", "createdAt": "2020-10-29T20:09:41Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -567,10 +590,46 @@ void runLoop() {\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final Exception e) {\n+                if (this.streamsUncaughtExceptionHandler == null) {\n+                    throw e;\n+                }\n+                if (Thread.getDefaultUncaughtExceptionHandler() != null && newHandler) {\n+                    log.error(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                            \"The old handler will be ignored as long as a new handler is set.\");\n+                } else {\n+                    throw e;\n+                }\n+                if (this.streamsUncaughtExceptionHandler.handle(e) != StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION) {\n+                    throw e;\n+                }\n             }\n         }\n     }\n \n+    /**\n+     * Sets the streams uncaught exception handler.\n+     *\n+     * @param streamsUncaughtExceptionHandler the user handler wrapped in shell to execute the action\n+     */\n+    public void setStreamsUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        this.streamsUncaughtExceptionHandler = streamsUncaughtExceptionHandler;\n+        this.newHandler = true;\n+    }\n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzNjUwOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514536509", "bodyText": "extra line (:", "author": "lct45", "createdAt": "2020-10-29T20:09:56Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -567,10 +590,46 @@ void runLoop() {\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final Exception e) {\n+                if (this.streamsUncaughtExceptionHandler == null) {\n+                    throw e;\n+                }\n+                if (Thread.getDefaultUncaughtExceptionHandler() != null && newHandler) {\n+                    log.error(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                            \"The old handler will be ignored as long as a new handler is set.\");\n+                } else {\n+                    throw e;\n+                }\n+                if (this.streamsUncaughtExceptionHandler.handle(e) != StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION) {\n+                    throw e;\n+                }\n             }\n         }\n     }\n \n+    /**\n+     * Sets the streams uncaught exception handler.\n+     *\n+     * @param streamsUncaughtExceptionHandler the user handler wrapped in shell to execute the action\n+     */\n+    public void setStreamsUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        this.streamsUncaughtExceptionHandler = streamsUncaughtExceptionHandler;\n+        this.newHandler = true;\n+    }\n+\n+\n+    public void shutdownToError() {\n+        shutdownErrorHook.shutdown();\n+    }\n+\n+    public void sendShutdownRequest(final AssignorError assignorError) {\n+        log.warn(\"Detected that shutdown was requested. \" +\n+                \"The all clients in this app will now begin to shutdown\");\n+        assignmentErrorCode.set(assignorError.code());\n+        mainConsumer.enforceRebalance();\n+    }\n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUzODMwNg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514538306", "bodyText": "extra line", "author": "lct45", "createdAt": "2020-10-29T20:13:34Z", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -616,13 +623,22 @@ public void shouldNotSetGlobalRestoreListenerAfterStarting() {\n     public void shouldThrowExceptionSettingUncaughtExceptionHandlerNotInCreateState() {\n         final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n         streams.start();\n-        try {\n-            streams.setUncaughtExceptionHandler(null);\n-            fail(\"Should throw IllegalStateException\");\n-        } catch (final IllegalStateException e) {\n-            // expected\n-        }\n+        assertThrows(IllegalStateException.class, () -> streams.setUncaughtExceptionHandler((StreamsUncaughtExceptionHandler) null));\n+    }\n+\n+    @Test\n+    public void shouldThrowExceptionSettingStreamsUncaughtExceptionHandlerNotInCreateState() {\n+        final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n+        streams.start();\n+        assertThrows(IllegalStateException.class, () -> streams.setUncaughtExceptionHandler((StreamsUncaughtExceptionHandler) null));\n+\n     }\n+    @Test\n+    public void shouldThrowNullPointerExceptionSettingStreamsUncaughtExceptionHandlerIfNull() {\n+        final KafkaStreams streams = new KafkaStreams(getBuilderWithSource().build(), props, supplier, time);\n+        assertThrows(NullPointerException.class, () -> streams.setUncaughtExceptionHandler((StreamsUncaughtExceptionHandler) null));\n+    }\n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDU0MDIwMA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r514540200", "bodyText": "line!", "author": "lct45", "createdAt": "2020-10-29T20:17:02Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk4NDkyNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r516984927", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n          \n          \n            \n                 * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}", "author": "vvcephei", "createdAt": "2020-11-03T22:10:24Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +374,66 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NDQyNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r516994424", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads; {@code null} deletes the current handler\n          \n          \n            \n                 * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n          \n      \n    \n    \n  \n\nIn L389, we say that we throw an exception if the handler is null, which sounds like a more reasonable API to me.", "author": "vvcephei", "createdAt": "2020-11-03T22:32:35Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +374,66 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads; {@code null} deletes the current handler", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NTYzMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r516995632", "bodyText": "What's up with the @NotNull on this line? I don't think I've seen that before.", "author": "vvcephei", "createdAt": "2020-11-03T22:35:32Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +374,66 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads; {@code null} deletes the current handler\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException @NotNull if streamsUncaughtExceptionHandler is null.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ4MTcxOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517481718", "bodyText": "I don't remember putting it there so it was probably a mistake", "author": "wcarlson5", "createdAt": "2020-11-04T16:43:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NTYzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5ODE4MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r516998180", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            log.error(\"Encountered the following exception during processing \" +\n          \n          \n            \n                                    \"and the client is going to shut down: \", e);\n          \n          \n            \n                            log.error(\"Encountered the following exception during processing \" +\n          \n          \n            \n                                    \"and the registered exception handler opted to \" + action + \". The streams client is going to shut down now. \", e);\n          \n      \n    \n    \n  \n\nJust a little extra information, so we don't always have to pull up this code block to remember what exact response action this message corresponds to.", "author": "vvcephei", "createdAt": "2020-11-03T22:41:56Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +374,66 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads; {@code null} deletes the current handler\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException @NotNull if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse handleStreamsUncaughtException(final Throwable e,\n+                                                                                                         final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        switch (action) {\n+//            case REPLACE_STREAM_THREAD:\n+//                log.error(\"Encountered the following exception during processing \" +\n+//                        \"and the the stream thread will be replaced: \", e);\n+//            this.addStreamsThread();\n+//                break;\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the client is going to shut down: \", e);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwODkxNg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517008916", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                log.error(\"This option requires the thread to stay running to start the shutdown.\" +\n          \n          \n            \n                                        \"Therefore it is not suitable for Error types.\");\n          \n          \n            \n                                log.error(\"This option requires running threads to shut down the application,\" +\n          \n          \n            \n                                        \"but the uncaught exception was an Error, which means this runtime is no longer in a well-defined state. Attempting to send the shutdown command anyway.\", e);", "author": "vvcephei", "createdAt": "2020-11-03T23:10:01Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +374,66 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads; {@code null} deletes the current handler\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException @NotNull if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse handleStreamsUncaughtException(final Throwable e,\n+                                                                                                         final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        switch (action) {\n+//            case REPLACE_STREAM_THREAD:\n+//                log.error(\"Encountered the following exception during processing \" +\n+//                        \"and the the stream thread will be replaced: \", e);\n+//            this.addStreamsThread();\n+//                break;\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the client is going to shut down: \", e);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (e instanceof Error) {\n+                    log.error(\"This option requires the thread to stay running to start the shutdown.\" +\n+                            \"Therefore it is not suitable for Error types.\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwOTUzOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517009538", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        log.info(\"Can not close to error from state \" + state());\n          \n          \n            \n                        log.info(\"Can not transition to error from state \" + state());\n          \n      \n    \n    \n  \n\nDidn't follow the prior message. Is this what you meant?", "author": "vvcephei", "createdAt": "2020-11-03T23:11:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -997,6 +1064,72 @@ private boolean close(final long timeoutMs) {\n         }\n     }\n \n+    private void closeToError() {\n+        if (!setState(State.ERROR)) {\n+            // if transition failed, it means it was either in PENDING_SHUTDOWN\n+            // or NOT_RUNNING already; just check that all threads have been stopped\n+            log.info(\"Can not close to error from state \" + state());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ4NTI1Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517485257", "bodyText": "That works", "author": "wcarlson5", "createdAt": "2020-11-04T16:48:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwOTUzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwOTc3OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517009778", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        log.info(\"closing to ERROR\");\n          \n          \n            \n                        log.info(\"Transitioning to ERROR state\");\n          \n      \n    \n    \n  \n\nSimilar confusion here...", "author": "vvcephei", "createdAt": "2020-11-03T23:12:30Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -997,6 +1064,72 @@ private boolean close(final long timeoutMs) {\n         }\n     }\n \n+    private void closeToError() {\n+        if (!setState(State.ERROR)) {\n+            // if transition failed, it means it was either in PENDING_SHUTDOWN\n+            // or NOT_RUNNING already; just check that all threads have been stopped\n+            log.info(\"Can not close to error from state \" + state());\n+        } else {\n+            log.info(\"closing to ERROR\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMjI4Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517012283", "bodyText": "This doesn't look like an \"error\". At best it's a \"warn\" log, but only if we think that this combination definitely looks like a misconfiguration. Even then, why wouldn't we check for the misconfiguration in KafkaStreams, since both the new and old handlers would be set over there?", "author": "vvcephei", "createdAt": "2020-11-03T23:20:08Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java", "diffHunk": "@@ -311,6 +317,22 @@ public void run() {\n                 \"Updating global state failed. You can restart KafkaStreams to recover from this error.\",\n                 recoverableException\n             );\n+        } catch (final Exception e) {\n+            if (this.streamsUncaughtExceptionHandler == null) {\n+                throw e;\n+            }\n+            if (Thread.getDefaultUncaughtExceptionHandler() != null && newHandler) {\n+                log.error(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                        \"The old handler will be ignored as long as a new handler is set.\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzU3Njc1OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517576758", "bodyText": "I think it is simpler to check in the Stream thread because we don't in KafkaStreams if the handlers have been set so we would have to check the stream thread a global thread so it would be much easier to just check in the thread. I do agree that it should be bumped down to warn through.", "author": "wcarlson5", "createdAt": "2020-11-04T19:20:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMjI4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMjgzOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517012839", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        if (this.streamsUncaughtExceptionHandler.handle(e) != StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION) {\n          \n          \n            \n                            throw e;\n          \n          \n            \n                        } else {\n          \n          \n            \n                            log.warn(\"Exception in global stream thread cause the application to attempt to shutdown.\" +\n          \n          \n            \n                                    \" This action will succeed only if there is at least one StreamThread running on ths client\");\n          \n          \n            \n                        }\n          \n          \n            \n                        if (this.streamsUncaughtExceptionHandler.handle(e) = StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION) {\n          \n          \n            \n                            log.warn(\"Exception in global stream thread cause the application to attempt to shutdown.\" +\n          \n          \n            \n                                    \" This action will succeed only if there is at least one StreamThread running on ths client\");\n          \n          \n            \n                        }\n          \n      \n    \n    \n  \n\nThis looked a bit off...", "author": "vvcephei", "createdAt": "2020-11-03T23:21:52Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java", "diffHunk": "@@ -311,6 +317,22 @@ public void run() {\n                 \"Updating global state failed. You can restart KafkaStreams to recover from this error.\",\n                 recoverableException\n             );\n+        } catch (final Exception e) {\n+            if (this.streamsUncaughtExceptionHandler == null) {\n+                throw e;\n+            }\n+            if (Thread.getDefaultUncaughtExceptionHandler() != null && newHandler) {\n+                log.error(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                        \"The old handler will be ignored as long as a new handler is set.\");\n+            } else {\n+                throw e;\n+            }\n+            if (this.streamsUncaughtExceptionHandler.handle(e) != StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION) {\n+                throw e;\n+            } else {\n+                log.warn(\"Exception in global stream thread cause the application to attempt to shutdown.\" +\n+                        \" This action will succeed only if there is at least one StreamThread running on ths client\");\n+            }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMzU0Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517013547", "bodyText": "It doesn't look like this needs to be shared outside of this thread. It seems like it just needs to be shared between the StreamThread and its Consumer?", "author": "vvcephei", "createdAt": "2020-11-03T23:24:09Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -294,7 +304,10 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n                                       final long cacheSizeBytes,\n                                       final StateDirectory stateDirectory,\n                                       final StateRestoreListener userStateRestoreListener,\n-                                      final int threadIdx) {\n+                                      final int threadIdx,\n+                                      final ShutdownErrorHook shutdownErrorHook,\n+                                      final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler,\n+                                      final AtomicInteger assignmentErrorCode) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzYyMTc1Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517621757", "bodyText": "You are right it seems that it is not necessary", "author": "wcarlson5", "createdAt": "2020-11-04T20:47:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMzU0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ2NDk2OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517464968", "bodyText": "Could you please also add the needed changes to system test streams_upgrade_test.py::StreamsUpgradeTest.test_version_probing_upgrade to this PR.", "author": "cadonna", "createdAt": "2020-11-04T16:19:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/StreamsAssignmentProtocolVersions.java", "diffHunk": "@@ -19,7 +19,7 @@\n public final class StreamsAssignmentProtocolVersions {\n     public static final int UNKNOWN = -1;\n     public static final int EARLIEST_PROBEABLE_VERSION = 3;\n-    public static final int LATEST_SUPPORTED_VERSION = 8;\n+    public static final int LATEST_SUPPORTED_VERSION = 9;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzU0MzYzOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517543638", "bodyText": "Can you also leave a comment here reminding us to fix the version probing system test whenever this protocol number is bumped? Since we apparently always forget", "author": "ableegoldman", "createdAt": "2020-11-04T18:22:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ2NDk2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzYyNzg0Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517627843", "bodyText": "thanks for the reminder. I think I I under stood the test ad incrementing to the next version, as the version is now 9", "author": "wcarlson5", "createdAt": "2020-11-04T20:59:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ2NDk2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ3NDEyOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517474129", "bodyText": "I guess this should be 2.8.0, shouldn't it?", "author": "cadonna", "createdAt": "2020-11-04T16:32:17Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -346,18 +351,21 @@ public void setStateListener(final KafkaStreams.StateListener listener) {\n      * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread} abruptly\n      * terminates due to an uncaught exception.\n      *\n-     * @param eh the uncaught exception handler for all internal threads; {@code null} deletes the current handler\n+     * @param uncaughtExceptionHandler the uncaught exception handler for all internal threads; {@code null} deletes the current handler\n      * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     *\n+     * @Deprecated Since 2.7.0. Use {@link KafkaStreams#setUncaughtExceptionHandler(StreamsUncaughtExceptionHandler)} instead.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI2MzM2OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518263368", "bodyText": "yes", "author": "wcarlson5", "createdAt": "2020-11-05T18:14:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ3NDEyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517505173", "bodyText": "Wouldn't it also be possible to start a shutdown thread here which closes the client without timeout? I think the other shutdown thread in close is rather useless (or I do simply not get its value).", "author": "cadonna", "createdAt": "2020-11-04T17:18:01Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +374,63 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse handleStreamsUncaughtException(final Throwable e,\n+                                                                                                         final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \\\" + action + \\\".\" +\n+                        \" The streams client is going to shut down now. \", e);\n+                close(Duration.ZERO);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI2MzkzNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518263937", "bodyText": "It might be but I do not think that it is necessary", "author": "wcarlson5", "createdAt": "2020-11-05T18:15:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI2OTQ5Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518269493", "bodyText": "Why not? It would be much cleaner. We would close all stuff like admin client and the metrics, remove the client metrics and set the state to NOT_RUNNING which is not necessarily done with timeout zero (probably not because of the death lock). Additionally, we would get an nice info debug saying Streams client stopped completely instead of Streams client cannot stop completely within the timeout. ;-)", "author": "cadonna", "createdAt": "2020-11-05T18:25:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI4MzUzOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518283539", "bodyText": "My last comment is not true! Sorry! Everything alright!", "author": "cadonna", "createdAt": "2020-11-05T18:49:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA0NDExMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523044111", "bodyText": "I still have a question here. Since the stream thread is alive when it calls close() there will not be a deadlock anymore. So, why do we call close() with duration zero?", "author": "cadonna", "createdAt": "2020-11-13T16:00:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA3OTk2NQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523079965", "bodyText": "we should be able to change it to close()", "author": "wcarlson5", "createdAt": "2020-11-13T16:56:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ0NzI1Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524447256", "bodyText": "I think I'd personally still prefer the non-blocking version. It seems better to avoid blocking indefinitely when a thread is trying to shut itself down due to some unknown exception (or error).", "author": "vvcephei", "createdAt": "2020-11-16T17:30:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxNzEzNQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524817135", "bodyText": "Since the stream thread is alive when it calls close() there will not be a deadlock anymore. So, why do we call close() with duration zero\n\n@cadonna can you clarify? I thought we would still be in danger of deadlock if we use the blocking close(), since close() will not return until every thread has joined but the StreamThread that called close() would be stuck in this blocking call and thus never stop/join", "author": "ableegoldman", "createdAt": "2020-11-17T01:03:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTE2MTQzNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525161434", "bodyText": "I thought we would still be in danger of deadlock if we use the blocking close(), since close() will not return until every thread has joined but the StreamThread that called close() would be stuck in this blocking call and thus never stop/join\n\nOK, I think you are right. I focused too much on\nif (!thread.isRunning()) {\n    thread.join();\n}\n\nwithout considering that before the stream threads are shutdown which makes them not running.\nIn the meantime, I understood a bit better the motivation of the shutdown thread in close(). The shutdown thread ensures that the timeout is still consiered in case close() is called by a stream thread. I think we should revisit it. But that is outside the scope of this PR.\nTo unblock this PR, I am fine with close(Duration.Zero), but I have the feeling we could do better.", "author": "cadonna", "createdAt": "2020-11-17T13:41:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNTE3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkwOTQ2Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517909467", "bodyText": "Is this comment correct? In this code path we do NOT check that all threads have been stopped.", "author": "cadonna", "createdAt": "2020-11-05T09:32:23Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -997,6 +1061,72 @@ private boolean close(final long timeoutMs) {\n         }\n     }\n \n+    private void closeToError() {\n+        if (!setState(State.ERROR)) {\n+            // if transition failed, it means it was either in PENDING_SHUTDOWN\n+            // or NOT_RUNNING already; just check that all threads have been stopped", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI2NDkyNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518264927", "bodyText": "I don't think we actually need it either way so I will just remove it", "author": "wcarlson5", "createdAt": "2020-11-05T18:17:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkwOTQ2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkxNTAzOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517915038", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    properties  = mkObjectProperties(\n          \n          \n            \n                            mkMap(\n          \n          \n            \n                                    mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n          \n          \n            \n                                    mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n          \n          \n            \n                                    mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n          \n          \n            \n                                    mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n          \n          \n            \n                                    mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n          \n          \n            \n                                    mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n          \n          \n            \n                                    mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n          \n          \n            \n                                    mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n          \n          \n            \n                                    mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n          \n          \n            \n                                    mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n          \n          \n            \n                            )\n          \n          \n            \n                    );\n          \n          \n            \n                    properties  = mkObjectProperties(\n          \n          \n            \n                        mkMap(\n          \n          \n            \n                            mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n          \n          \n            \n                            mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n          \n          \n            \n                            mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n          \n          \n            \n                            mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n          \n          \n            \n                            mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n          \n          \n            \n                            mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n          \n          \n            \n                            mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n          \n          \n            \n                            mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n          \n          \n            \n                            mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n          \n          \n            \n                            mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n          \n          \n            \n                        )\n          \n          \n            \n                    );", "author": "cadonna", "createdAt": "2020-11-05T09:41:15Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n+                        mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n+                        mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n+                        mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkxNjM0NQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517916345", "bodyText": "The name is a bit ambiguous. I would go for StreamsUncaughtExceptionHandlerIntegrationTest", "author": "cadonna", "createdAt": "2020-11-05T09:43:22Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI2NTgwMw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518265803", "bodyText": "sure", "author": "wcarlson5", "createdAt": "2020-11-05T18:18:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzkxNjM0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5MzQ5OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517993498", "bodyText": "What is the benefit of using a latch versus simply sleeping here?\nActually, you should use StreamsTestUtils.startKafkaStreamsAndWaitForRunningState() to avoid flakiness coming from the Kafka Streams client not being in state RUNNING before the verifications.", "author": "cadonna", "createdAt": "2020-11-05T11:51:47Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n+                        mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n+                        mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n+                        mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldShutdownThreadUsingOldHandler() throws Exception {\n+        //\n+        //\n+        // Also note that this is an integration test because so many components have to come together to\n+        // ensure these configurations wind up where they belong, and any number of future code changes\n+        // could break this change.\n+\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            final AtomicBoolean flag = new AtomicBoolean(false);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> flag.set(true));\n+\n+            kafkaStreams.start();\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(15, TimeUnit.SECONDS);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI2Nzk1Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518267956", "bodyText": "Thats a good idea, I didn't see that option", "author": "wcarlson5", "createdAt": "2020-11-05T18:22:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5MzQ5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODMyNjc3Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518326776", "bodyText": "Actually the latch ensures the rebalance gets processed", "author": "wcarlson5", "createdAt": "2020-11-05T19:55:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5MzQ5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzk5NTkzNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r517995934", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        log.error(\"An application is requesting Shutdown\");\n          \n          \n            \n                        log.error(\"A Kafka Streams client in this Kafka Streams application is requesting to shutdown\");\n          \n      \n    \n    \n  \n\nAn application is actually a group of Kafka Streams clients (or instances).", "author": "cadonna", "createdAt": "2020-11-05T11:55:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsRebalanceListener.java", "diffHunk": "@@ -60,6 +60,9 @@ public void onPartitionsAssigned(final Collection<TopicPartition> partitions) {\n         }  else if (assignmentErrorCode.get() == AssignorError.ASSIGNMENT_ERROR.code()) {\n             log.error(\"Received error code {}\", AssignorError.ASSIGNMENT_ERROR);\n             throw new TaskAssignmentException(\"Hit an unexpected exception during task assignment phase of rebalance\");\n+        } else if (assignmentErrorCode.get() == AssignorError.SHUTDOWN_REQUESTED.code()) {\n+            log.error(\"An application is requesting Shutdown\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAwODcxMA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518008710", "bodyText": "You could wait for this flag to become true with TestUtils.waitForCondition() before you verify the other criteria.", "author": "cadonna", "createdAt": "2020-11-05T12:19:08Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n+                        mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n+                        mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n+                        mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldShutdownThreadUsingOldHandler() throws Exception {\n+        //\n+        //\n+        // Also note that this is an integration test because so many components have to come together to\n+        // ensure these configurations wind up where they belong, and any number of future code changes\n+        // could break this change.\n+\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            final AtomicBoolean flag = new AtomicBoolean(false);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> flag.set(true));\n+\n+            kafkaStreams.start();\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(15, TimeUnit.SECONDS);\n+\n+            assertThat(processorValueCollector.size(), equalTo(2));\n+            assertThat(kafkaStreams.state(), equalTo(KafkaStreams.State.ERROR));\n+            assertThat(\"handler was called\", flag.get());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3MTIxNQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518271215", "bodyText": "good idea", "author": "wcarlson5", "createdAt": "2020-11-05T18:28:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAwODcxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxMDc4MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518010780", "bodyText": "Why do clean the state twice?", "author": "cadonna", "createdAt": "2020-11-05T12:23:05Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM3MTcyMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518371722", "bodyText": "good questions", "author": "wcarlson5", "createdAt": "2020-11-05T21:17:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxMDc4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxNDExOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518014119", "bodyText": "Why do you need to set all these properties?", "author": "cadonna", "createdAt": "2020-11-05T12:29:10Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n+                        mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n+                        mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n+                        mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3MTkxOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518271918", "bodyText": "we probably don't need all of them. I will trim them down", "author": "wcarlson5", "createdAt": "2020-11-05T18:29:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAxNDExOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAyMTI1MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518021251", "bodyText": "I would remove these comments.", "author": "cadonna", "createdAt": "2020-11-05T12:41:57Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n+                        mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n+                        mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n+                        mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldShutdownThreadUsingOldHandler() throws Exception {\n+        //\n+        //\n+        // Also note that this is an integration test because so many components have to come together to\n+        // ensure these configurations wind up where they belong, and any number of future code changes\n+        // could break this change.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzMzcyMw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518033723", "bodyText": "I had a hard time to understand this. We write just one record to the topic, but we end up processing two records. This is true, because we use two stream threads and there is no commit between the processing of the record of the first stream thread and the processing of the second stream thread. Why do you use two stream threads here?", "author": "cadonna", "createdAt": "2020-11-05T13:03:05Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n+                        mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n+                        mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n+                        mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldShutdownThreadUsingOldHandler() throws Exception {\n+        //\n+        //\n+        // Also note that this is an integration test because so many components have to come together to\n+        // ensure these configurations wind up where they belong, and any number of future code changes\n+        // could break this change.\n+\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            final AtomicBoolean flag = new AtomicBoolean(false);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> flag.set(true));\n+\n+            kafkaStreams.start();\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(15, TimeUnit.SECONDS);\n+\n+            assertThat(processorValueCollector.size(), equalTo(2));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI3NDM1OQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518274359", "bodyText": "I use 2 threads there to make sure the old behavior is being followed. Just one thread dies and then the next thread is tries. The second thread makes sure that the new path is not closing the client unintentionally.", "author": "wcarlson5", "createdAt": "2020-11-05T18:33:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzMzcyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzNTMwMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518035301", "bodyText": "Most of the above comments also apply to the other tests.", "author": "cadonna", "createdAt": "2020-11-05T13:05:41Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        cleanStateBeforeTest(CLUSTER, idempotentTopic, inputTopic);\n+\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+                mkMap(\n+                        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                        mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                        mkEntry(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, \"5\"),\n+                        mkEntry(StreamsConfig.ACCEPTABLE_RECOVERY_LAG_CONFIG, \"6\"),\n+                        mkEntry(StreamsConfig.MAX_WARMUP_REPLICAS_CONFIG, \"7\"),\n+                        mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"480000\"),\n+                        mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                        mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                        mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+                )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldShutdownThreadUsingOldHandler() throws Exception {\n+        //\n+        //\n+        // Also note that this is an integration test because so many components have to come together to\n+        // ensure these configurations wind up where they belong, and any number of future code changes\n+        // could break this change.\n+\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            final AtomicBoolean flag = new AtomicBoolean(false);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> flag.set(true));\n+\n+            kafkaStreams.start();\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(15, TimeUnit.SECONDS);\n+\n+            assertThat(processorValueCollector.size(), equalTo(2));\n+            assertThat(kafkaStreams.state(), equalTo(KafkaStreams.State.ERROR));\n+            assertThat(\"handler was called\", flag.get());\n+        }\n+    }\n+\n+    @Test\n+    public void shouldShutdownClient() throws Exception {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODAzOTAyNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518039024", "bodyText": "Why are those fields all package-private instead of private?\nWe usually define string constants as private static final String IDEMPOTENT_TOPIC = \"idempotentTopic\".", "author": "cadonna", "createdAt": "2020-11-05T13:11:58Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";\n+    String appId = \"\";", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0Mjg2NQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518042865", "bodyText": "I do not understand the motivation behind this topic. Could you clarify?", "author": "cadonna", "createdAt": "2020-11-05T13:18:06Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.cleanStateBeforeTest;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+public class StreamsHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    String inputTopic;\n+    StreamsBuilder builder;\n+    Properties properties;\n+    List<String> processorValueCollector;\n+    String idempotentTopic = \"idempotentTopic\";", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODMzNTYzMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518335631", "bodyText": "it can be removed", "author": "wcarlson5", "createdAt": "2020-11-05T20:11:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0Mjg2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NDQ3Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518044472", "bodyText": "Unit tests for this case are missing.", "author": "cadonna", "createdAt": "2020-11-05T13:20:37Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsRebalanceListener.java", "diffHunk": "@@ -60,6 +60,9 @@ public void onPartitionsAssigned(final Collection<TopicPartition> partitions) {\n         }  else if (assignmentErrorCode.get() == AssignorError.ASSIGNMENT_ERROR.code()) {\n             log.error(\"Received error code {}\", AssignorError.ASSIGNMENT_ERROR);\n             throw new TaskAssignmentException(\"Hit an unexpected exception during task assignment phase of rebalance\");\n+        } else if (assignmentErrorCode.get() == AssignorError.SHUTDOWN_REQUESTED.code()) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM3MTUxMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518371511", "bodyText": "added unit test", "author": "wcarlson5", "createdAt": "2020-11-05T21:17:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA0NDQ3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3ODExNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518478117", "bodyText": "I had a little trouble following the Handler class. Some trivial things -- eg the handler in the StreamThread is named streamsUncaughtExceptionHandler but it's actually not a StreamsUncaughtExceptionHandler. Also the usage of the return value; IIUC it's supposed to indicate whether to use the new handler or fall back on the old one. To me it sounds like if handle returns true that means we should handle it, ie we should not rethrow the exception, but this looks like the opposite of what we do now. Honestly either interpretation is ok with me, as long as it's documented somewhere\nDo we really need the Handler in the first place though? It's already pretty confusing that we have to deal with two types of handlers (old and new) so I'd prefer not to add a third unless it's really necessary. It seems like we can just inline the logic of whether to invoke the new handler or rethrow the exception, which would also clear up the confusion around the meaning of the return value. But I might be missing something here -- WDYT?", "author": "ableegoldman", "createdAt": "2020-11-06T01:55:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -567,10 +589,34 @@ void runLoop() {\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final Exception e) {\n+                if (this.streamsUncaughtExceptionHandler.handle(e)) {", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgzNzI1MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518837250", "bodyText": "We could do the logic inline how ever this does make it slightly simpler. Also we only expose the streamsUncaughtExceptionHandler to the user and @vvcephei had a problem with the wrapping that again with the same type. So we introduced a wrapper class. if we renamed it from Handler to streamsUncaughtExceptionHandlerWrapper would that make it more clear?", "author": "wcarlson5", "createdAt": "2020-11-06T15:46:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3ODExNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3OTUyNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518479524", "bodyText": "Seems like we can just pass in a Runnable with KafkaStreams::closeToError instead of adding a whole ShutdownErrorHook functional interface", "author": "ableegoldman", "createdAt": "2020-11-06T01:59:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -282,6 +283,17 @@ public boolean isRunning() {\n     private final Admin adminClient;\n     private final InternalTopologyBuilder builder;\n \n+    private Handler streamsUncaughtExceptionHandler;\n+    private ShutdownErrorHook shutdownErrorHook;\n+    private AtomicInteger assignmentErrorCode;\n+    public interface ShutdownErrorHook {\n+        void shutdown();\n+    }", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg0Mjc0Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518842747", "bodyText": "Yes we can", "author": "wcarlson5", "createdAt": "2020-11-06T15:55:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3OTUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MTg4Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518481887", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"The all clients in this app will now begin to shutdown\");\n          \n          \n            \n                            \"All clients in this app will now begin to shutdown\");", "author": "ableegoldman", "createdAt": "2020-11-06T02:07:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -567,10 +589,34 @@ void runLoop() {\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final Exception e) {\n+                if (this.streamsUncaughtExceptionHandler.handle(e)) {\n+                    throw e;\n+                }\n             }\n         }\n     }\n \n+    /**\n+     * Sets the streams uncaught exception handler.\n+     *\n+     * @param streamsUncaughtExceptionHandler the user handler wrapped in shell to execute the action\n+     */\n+    public void setStreamsUncaughtExceptionHandler(final Handler streamsUncaughtExceptionHandler) {\n+        this.streamsUncaughtExceptionHandler = streamsUncaughtExceptionHandler;\n+    }\n+\n+    public void shutdownToError() {\n+        shutdownErrorHook.shutdown();\n+    }\n+\n+    public void sendShutdownRequest(final AssignorError assignorError) {\n+        log.warn(\"Detected that shutdown was requested. \" +\n+                \"The all clients in this app will now begin to shutdown\");", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MjgzMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518482832", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                log.error(\"Exception in global stream thread cause the application to attempt to shutdown.\" +\n          \n          \n            \n                                        \" This action will succeed only if there is at least one StreamThread running on ths client.\" +\n          \n          \n            \n                                        \" Currently there is no running threads so will now close the client.\");\n          \n          \n            \n                                log.error(\"Exception in global thread caused the application to attempt to shutdown.\" +\n          \n          \n            \n                                        \" This action will succeed only if there is at least one StreamThread running on this client.\" +\n          \n          \n            \n                                        \" Currently there are no running threads so will now close the client.\");", "author": "ableegoldman", "createdAt": "2020-11-06T02:11:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +373,84 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamThread.Handler handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private boolean handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            return true;\n+        }\n+        return handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+    }\n+\n+    private boolean handleStreamsUncaughtException(final Throwable e,\n+                                                   final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            log.warn(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                    \"The old handler will be ignored as long as a new handler is set.\");\n+        }\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \\\" + action + \\\".\" +\n+                        \" The streams client is going to shut down now. \", e);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (e instanceof Error) {\n+                    log.error(\"This option requires running threads to shut down the application.\" +\n+                            \"but the uncaught exception was an Error, which means this runtime is no \" +\n+                            \"longer in a well-defined state. Attempting to send the shutdown command anyway.\", e);\n+                }\n+                if (Thread.currentThread().equals(globalStreamThread) && threads.stream().noneMatch(StreamThread::isRunning)) {\n+                    log.error(\"Exception in global stream thread cause the application to attempt to shutdown.\" +\n+                            \" This action will succeed only if there is at least one StreamThread running on ths client.\" +\n+                            \" Currently there is no running threads so will now close the client.\");", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MzE5NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518483194", "bodyText": "Should this be logged at error?", "author": "ableegoldman", "createdAt": "2020-11-06T02:12:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -996,6 +1082,62 @@ private boolean close(final long timeoutMs) {\n         }\n     }\n \n+    private void closeToError() {\n+        if (!setState(State.ERROR)) {\n+            log.info(\"Can not transition to error from state \" + state());", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgzODQyMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518838421", "bodyText": "In the normal close method the corresponding log is also info. As multiple thread will be calling this at once I would rather not flood the logs with error unnecessarily.", "author": "wcarlson5", "createdAt": "2020-11-06T15:48:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MzE5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODkxMzUxNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518913514", "bodyText": "Gotcha. In that case maybe we shouldn't log anything here at all? Or just reword it to clarify that this is expected (eg \"Skipping shutdown since we are already in ERROR\") since \"Can not transition...\" kind of sounds like something went wrong", "author": "ableegoldman", "createdAt": "2020-11-06T17:57:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MzE5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODkzODg1Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518938852", "bodyText": "That is a good idea, Ill change the log", "author": "wcarlson5", "createdAt": "2020-11-06T18:47:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MzE5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NDI3MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518484271", "bodyText": "Looks like we call setState(ERROR) three times in this method, is that intentional?", "author": "ableegoldman", "createdAt": "2020-11-06T02:16:48Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -996,6 +1082,62 @@ private boolean close(final long timeoutMs) {\n         }\n     }\n \n+    private void closeToError() {\n+        if (!setState(State.ERROR)) {\n+            log.info(\"Can not transition to error from state \" + state());\n+        } else {\n+            log.info(\"Transitioning to ERROR state\");\n+            stateDirCleaner.shutdownNow();\n+            if (rocksDBMetricsRecordingService != null) {\n+                rocksDBMetricsRecordingService.shutdownNow();\n+            }\n+\n+            // wait for all threads to join in a separate thread;\n+            // save the current thread so that if it is a stream thread\n+            // we don't attempt to join it and cause a deadlock\n+            final Thread shutdownThread = new Thread(() -> {\n+                // notify all the threads to stop; avoid deadlocks by stopping any\n+                // further state reports from the thread since we're shutting down\n+                for (final StreamThread thread : threads) {\n+                    thread.shutdown();\n+                }\n+\n+                for (final StreamThread thread : threads) {\n+                    try {\n+                        if (!thread.isRunning()) {\n+                            thread.join();\n+                        }\n+                    } catch (final InterruptedException ex) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.shutdown();\n+                }\n+\n+                if (globalStreamThread != null && !globalStreamThread.stillRunning()) {\n+                    try {\n+                        globalStreamThread.join();\n+                    } catch (final InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                    globalStreamThread = null;\n+                }\n+\n+                adminClient.close();\n+\n+                streamsMetrics.removeAllClientLevelMetrics();\n+                metrics.close();\n+                setState(State.ERROR);\n+            }, \"kafka-streams-close-thread\");\n+\n+            shutdownThread.setDaemon(true);\n+            shutdownThread.start();\n+            setState(State.ERROR);", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgzODU4Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518838586", "bodyText": "No, I hadn't seen that", "author": "wcarlson5", "createdAt": "2020-11-06T15:49:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NDI3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTI4MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518485280", "bodyText": "It probably doesn't matter too much since handleRebalanceComplete doesn't do anything that important at the mometn, but it seems like we should call it before shutting down, not after.", "author": "ableegoldman", "createdAt": "2020-11-06T02:20:24Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsRebalanceListener.java", "diffHunk": "@@ -60,6 +60,11 @@ public void onPartitionsAssigned(final Collection<TopicPartition> partitions) {\n         }  else if (assignmentErrorCode.get() == AssignorError.ASSIGNMENT_ERROR.code()) {\n             log.error(\"Received error code {}\", AssignorError.ASSIGNMENT_ERROR);\n             throw new TaskAssignmentException(\"Hit an unexpected exception during task assignment phase of rebalance\");\n+        } else if (assignmentErrorCode.get() == AssignorError.SHUTDOWN_REQUESTED.code()) {\n+            log.error(\"A Kafka Streams client in this Kafka Streams application is requesting to shutdown the application\");\n+            streamThread.shutdownToError();\n+            taskManager.handleRebalanceComplete();", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg0MDEyMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518840121", "bodyText": "We can do that, it doesn't seem make difference which order it is called. However if it is not called it will get stuck continually rebalancing. We return because setting the state to partitions assigned will cause an error", "author": "wcarlson5", "createdAt": "2020-11-06T15:51:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTI4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI4ODY3OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523288678", "bodyText": "For the same reason I had to add to the other cases as the close from the new handler will not finish otherwise", "author": "wcarlson5", "createdAt": "2020-11-13T23:49:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTI4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTc0OQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518485749", "bodyText": "This should probably stay final so we don't accidentally change it ever", "author": "ableegoldman", "createdAt": "2020-11-06T02:22:02Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ReferenceContainer.java", "diffHunk": "@@ -30,7 +30,7 @@\n     public Admin adminClient;\n     public TaskManager taskManager;\n     public StreamsMetadataState streamsMetadataState;\n-    public final AtomicInteger assignmentErrorCode = new AtomicInteger();\n+    public AtomicInteger assignmentErrorCode = new AtomicInteger();", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg0MDYwMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518840602", "bodyText": "I was changing it intentionally but I think I can get away with not", "author": "wcarlson5", "createdAt": "2020-11-06T15:52:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTc0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4ODU3Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518488577", "bodyText": "This cast makes me kind of uncomfortable...either the assignmentErrorCode that we have in the AssignmentInfo is conceptually the same as the one we're adding to the SubscriptionInfo (in which case it should be the same type), or it's not the same, in which case we should use a different variable to track it.\nPersonally I think it's probably simpler to keep them the same, and just add an int errorCode field to the Subscription instead of a byte shutdownRequested field. But it's your choice", "author": "ableegoldman", "createdAt": "2020-11-06T02:32:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -255,8 +255,9 @@ public ByteBuffer subscriptionUserData(final Set<String> topics) {\n             taskManager.processId(),\n             userEndPoint,\n             taskManager.getTaskOffsetSums(),\n-            uniqueField)\n-                .encode();\n+            uniqueField,\n+            (byte) assignmentErrorCode.get()", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4OTI2MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518489261", "bodyText": "I think we should mirror the errorCode in the AssignmentInfo here, both in terms of naming and type. If we're going to use the same AssignorError for both, then they should really be the same. And we may want to send other kinds of error codes in the subscription going forward: better to just encode a single int than a separate byte for every logical error code. I don't think we'll notice the extra three bytes since Subscriptions aren't sent that frequently", "author": "ableegoldman", "createdAt": "2020-11-06T02:35:01Z", "path": "streams/src/main/resources/common/message/SubscriptionInfoData.json", "diffHunk": "@@ -57,6 +57,11 @@\n       \"name\": \"uniqueField\",\n       \"versions\": \"8+\",\n       \"type\": \"int8\"\n+    },\n+    {\n+      \"name\": \"shutdownRequested\",\n+      \"versions\": \"9+\",\n+      \"type\": \"int8\"", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg1MDQxOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518850419", "bodyText": "I think I agree on the name, I am not sure about the type. We should be able to fit thousands of different error code into the byte so we should not run out of space. The reason the errorCode. is an integer in the first place is because there is not AtomicByte that I know of.", "author": "wcarlson5", "createdAt": "2020-11-06T16:08:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4OTI2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA3NzA0OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r520077048", "bodyText": "I'm not really worried that we'd run out of space, I just think it sends a signal that the Assignment and Subscription error codes are semantically distinct and don't refer to the same underlying concept. So it seems better to go with the simpler approach than over-optimize to save an occasional three bytes", "author": "ableegoldman", "createdAt": "2020-11-09T19:47:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4OTI2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDEwNDg4NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r520104884", "bodyText": "#9273 (comment)\nI originally had it at int32, but @vvcephei suggested int16, now it is int8.\nwould you be good with int16 or do you think int32 is the way?", "author": "wcarlson5", "createdAt": "2020-11-09T20:38:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4OTI2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5NjUyNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522596527", "bodyText": "This wording is a little difficult to parse", "author": "ableegoldman", "createdAt": "2020-11-13T03:51:22Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA2OTYxMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523069611", "bodyText": "changed to  In order to get the thread uses use Thread.currentThread()\nDoes that work better?", "author": "wcarlson5", "createdAt": "2020-11-13T16:40:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5NjUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5NjgzMw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523296833", "bodyText": "Is there an extra uses in there or am I not looking at this sentence from the right angle?", "author": "ableegoldman", "createdAt": "2020-11-14T00:16:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5NjUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMyNzEwNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523327104", "bodyText": "I appreciate the benefit of the doubt :) but you are right there is an extra uses", "author": "wcarlson5", "createdAt": "2020-11-14T01:23:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5NjUyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5NzQ4Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522597486", "bodyText": "Just curious, what's the motivation for doing it like this vs just immediately throwing the exception?", "author": "ableegoldman", "createdAt": "2020-11-13T03:55:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA3MDg0NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523070844", "bodyText": "We have to do the casting in order to throw the exception. Otherwise the compiler complains about checked vs unchecked exceptions", "author": "wcarlson5", "createdAt": "2020-11-13T16:42:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5NzQ4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5ODAwOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522598008", "bodyText": "nit: parameters unaligned", "author": "ableegoldman", "createdAt": "2020-11-13T03:57:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable e,\n+                                                   final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5ODE0Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522598142", "bodyText": "That's a lot of line breaks \ud83d\ude43", "author": "ableegoldman", "createdAt": "2020-11-13T03:58:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable e,\n+                                                   final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            log.warn(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                    \"The old handler will be ignored as long as a new handler is set.\");\n+        }\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \\\" + action + \\\".\" +\n+                        \" The streams client is going to shut down now. \", e);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (e instanceof Error) {\n+                    log.error(\"This option requires running threads to shut down the application.\" +\n+                            \"but the uncaught exception was an Error, which means this runtime is no \" +\n+                            \"longer in a well-defined state. Attempting to send the shutdown command anyway.\", e);\n+                }\n+                if (Thread.currentThread().equals(globalStreamThread) && threads.stream().noneMatch(StreamThread::isRunning)) {\n+                    log.error(\"Exception in global thread caused the application to attempt to shutdown.\" +\n+                            \" This action will succeed only if there is at least one StreamThread running on this client.\" +\n+                            \" Currently there are no running threads so will now close the client.\");\n+                    close(Duration.ZERO);\n+                } else {\n+                    for (final StreamThread streamThread : threads) {\n+                        streamThread.sendShutdownRequest(AssignorError.SHUTDOWN_REQUESTED);\n+                    }\n+                    log.error(\"Encountered the following exception during processing \" +\n+                            \"and the application is going to shut down: \", e);\n+                }\n+                break;\n+        }\n+    }\n+\n+\n+\n+", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA3MzU5NQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523073595", "bodyText": "that is a lot of line breaks", "author": "wcarlson5", "createdAt": "2020-11-13T16:46:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5ODE0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5ODcwNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522598707", "bodyText": "Is everything after this line the same as the code in the regular close()? Might be a good idea to move it to a separate method so we don't accidentally forget to update one of them if we ever need to make changes to how we close", "author": "ableegoldman", "createdAt": "2020-11-13T04:00:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -996,6 +1093,60 @@ private boolean close(final long timeoutMs) {\n         }\n     }\n \n+    private void closeToError() {\n+        if (!setState(State.ERROR)) {\n+            log.info(\"Skipping shutdown since we are already in \" + state());\n+        } else {\n+            log.info(\"Transitioning to ERROR state\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA3OTQ1Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523079456", "bodyText": "Everything except the state we leave it in. We can move most of it to a helper", "author": "wcarlson5", "createdAt": "2020-11-13T16:56:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU5ODcwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxMzMzNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522613334", "bodyText": "It seems like we shouldn't both handle the exception in the catch block AND shut down the client in the finally block. If the new handler is used, then we've already shut down the client or possibly started to shut down the whole application. It's tricky, though, because if the old handler was used then we do want to make sure that the global thread is all cleaned up before rethrowing the exception.\nSeems like we need some way to detect whether we're using the old or the new handler after all. But I think you can do it without too many changes, since basically the rule is \"if they set a new handler at all OR didn't set either handler, then use the new one\". So maybe you can just make the StreamsUncaughtExceptionHandler a local field instead of the Consumer<>, and leave it as null to indicate that the old handler should be used and therefore this shutdown logic should be invoked. Otherwise just call the new handler directly. Or something like that...you'd know this code better than me, WDYT?", "author": "ableegoldman", "createdAt": "2020-11-13T04:26:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java", "diffHunk": "@@ -311,6 +314,8 @@ public void run() {\n                 \"Updating global state failed. You can restart KafkaStreams to recover from this error.\",\n                 recoverableException\n             );\n+        } catch (final Exception e) {\n+            this.streamsUncaughtExceptionHandler.accept(e);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA5MDE2MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523090161", "bodyText": "There is a logic to use the old handler if the conditions you laid out are true. The odd series of casts of exception types in handleStreamsUncaughtExceptionDefaultWrapper are what makes this happen.\nThis is a bit tricky but I think we want to close the client either way. As we don't have plans to replace the global thread and shutting  down the application is best effort. We talked about this a while back and we decided the global handler was mainly for information and the return type we would try to follow but we need to make sure we at least close the client.", "author": "wcarlson5", "createdAt": "2020-11-13T17:07:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxMzMzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMwMjk3Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523302976", "bodyText": "Ah ok I thought we executed this cleanup logic in the GlobalStreamThread's shutdown method but now I see that's not true. Sorry for the confusion there.\nI do see some minor outstanding issues here, mainly around the state diagram. Let's say the user opts to SHUTDOWN_CLIENT in the new handler: the intended semantics are to end up in NOT_RUNNING\nBut I think what would happen is that from the global thread we would immediately call KafkaStreams#close , which kicks off a shutdown thread to wait for all threads to join and then sets the state to NOT_RUNNING. Then when the handler returns, it would transition the global thread to PENDING_SHUTDOWN and then finally to DEAD. And during the transition to DEAD, we would actually end up transitioning the KafkaStreams instance to ERROR, rather than NOT_RUNNING as intended. So probably, we just need to update the onChange method in KafkaStreams.\nThis also reminds me of another thing, we need to update the FSM diagram and allowed transitions in KafkaStreams to reflect the new semantics we decided on for ERROR (which IIRC is basically just to make it a terminal state). Does that sound right to you?", "author": "ableegoldman", "createdAt": "2020-11-14T00:47:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxMzMzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMwMzA2Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523303062", "bodyText": "I suspect the tests didn't catch this because we would still transition out of ERROR to PENDING_SHUTDOWN and finally NOT_RUNNING in this case. But really, we shouldn't transition to ERROR in the first place", "author": "ableegoldman", "createdAt": "2020-11-14T00:47:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxMzMzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMzNDMzNQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523334335", "bodyText": "I don't think it will actually transition to ERROR because the handler will call close before the global thread is dead, which will transition to PEDING_SHUTDOWN, there is no transition to ERROR from either PENDING_SHUTDOWN or NOT_RUNNING.\nthe FSM will be part of the add thread work as it doesn't really make sense to remove the change to error until we can add threads", "author": "wcarlson5", "createdAt": "2020-11-14T01:32:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxMzMzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3NTYxNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523375614", "bodyText": "Oh you're totally right, sorry for letting my paranoia start spreading conspiracy theories here \ud83d\ude42  Given all this I'd still claim that the FSM is in need to being cleaned up a bit (or a lot), but if you'd prefer to hold off on that until the add thread work then I'm all good here. Thanks for humoring me and explaining the state of things. I just wanted/want to make sure we don't overlook anything, since there's a lot going on.\nFor example in the current code, if the global thread dies with the old handler still in use then we'll transition to ERROR. However the user still has to be responsible for closing the client themselves, and it will ultimately transition from ERROR to NOT_RUNNING. Whereas if we transition to ERROR as the result of a SHUTDOWN_APPLICATION error code, the user should NOT try to invoke close themselves, and the ERROR state will be terminal. That's pretty confusing eg for users who use a state listener and wait for the transition to ERROR to call close(). We should make sure that ERROR has the same semantics across the board by the end of all this work.\nAnyways I'm just thinking out loud here, to reiterate I'm perfectly happy to merge this as-is. But for reasons like the above, I think it's important to tackle the FSM in the next PR and make sure it all gets sorted out by the next AK release", "author": "ableegoldman", "createdAt": "2020-11-14T04:45:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxMzMzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQzNzk0MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524437940", "bodyText": "+1 to sorting out FSM before next release, I have a ticket to track the work. I started to change it and it ballooned out to be much more expansive than I thought. This PR is already complicated enough, so we can add is later.", "author": "wcarlson5", "createdAt": "2020-11-16T17:17:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxMzMzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxNjUxNQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522616515", "bodyText": "Hmm...this one seems like it should be a fatal error, so is it safe to just pass it along to the user and let them potentially just keep replacing the thread? (I know that option doesn't exist yet, but it will). There are some instances where we interpret errors as permanently fatal and choose to shut down the entire application, eg some errors during assignment. Should we do the same here? cc @abbccdda or @mjsax for more context on this error", "author": "ableegoldman", "createdAt": "2020-11-13T04:30:37Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -559,18 +552,52 @@ void runLoop() {\n                 }\n             } catch (final TaskCorruptedException e) {\n                 log.warn(\"Detected the states of tasks \" + e.corruptedTaskWithChangelogs() + \" are corrupted. \" +\n-                             \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n+                        \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n                 try {\n                     taskManager.handleCorruption(e.corruptedTaskWithChangelogs());\n                 } catch (final TaskMigratedException taskMigrated) {\n                     handleTaskMigrated(taskMigrated);\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final UnsupportedVersionException e) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA5NTIzMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523095231", "bodyText": "I think this is fine for now. When we add replace thread as an option we can include overrides when handling the response that prevent the thread from being restarted in certain error cases.", "author": "wcarlson5", "createdAt": "2020-11-13T17:10:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxNjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ3NTM4OQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524475389", "bodyText": "Personally, as long as users have the information available to understand the nature of the error, it's fine to let them make their own decision about how to handle it. Maybe another team is in the middle of a broker upgrade, for example, and the owner of this app would like to just keep trying until the broker team gets it together.", "author": "vvcephei", "createdAt": "2020-11-16T18:14:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxNjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4NzYwOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524487609", "bodyText": "That is probably fine. We can really get into it when we add the replace option, as now all calls to the handler are fatal.", "author": "wcarlson5", "createdAt": "2020-11-16T18:35:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxNjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxNDkzMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524814932", "bodyText": "That's a fair point about broker upgrades, but don't we require the brokers to be upgraded to a version that supports EOS before turning on eos-beta?\nAnyways I was wondering if there was something special about this exception such that ignoring it could violate eos or corrupt the state of the program. I'll ping the eos experts to assuage my concerns", "author": "ableegoldman", "createdAt": "2020-11-17T00:56:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxNjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxOTA2Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524819063", "bodyText": "Just to clarify I think it's ok to leave this as-is for now, since as Walker said all handler options are fatal at this point", "author": "ableegoldman", "createdAt": "2020-11-17T01:08:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxNjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgyNDY0OQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524824649", "bodyText": "Mm ok actually I think this should be fine. I was thinking of the handler as just \"swallowing\" the exception, but in reality the user would still let the current thread die and just spin up a new one in its place. And then the new one would hit this UnsupportedVersionException and so on, until the brokers are upgraded. So there shouldn't be any way to get into a bad state", "author": "ableegoldman", "createdAt": "2020-11-17T01:25:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYxNjUxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyMjIyOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522622229", "bodyText": "I think we should add the errorCode parameter to the existing constructor rather than add a new one. It shouldn't be possible to construct a version 9 subscription that doesn't have an errorCode", "author": "ableegoldman", "createdAt": "2020-11-13T04:37:49Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/SubscriptionInfo.java", "diffHunk": "@@ -77,6 +77,20 @@ private static void validateVersions(final int version, final int latestSupporte\n         }\n     }\n \n+    public SubscriptionInfo(final int version,\n+                            final int latestSupportedVersion,\n+                            final UUID processId,\n+                            final String userEndPoint,\n+                            final Map<TaskId, Long> taskOffsetSums,\n+                            final byte uniqueField,\n+                            final byte errorCode) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyMjg4Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522622882", "bodyText": "Nice, thanks for the comment. Btw anytime we bump this protocol version we should add the corresponding unit tests, eg SubscriptionInfoTest#shouldEncodeAndDecodeVersion8()", "author": "ableegoldman", "createdAt": "2020-11-13T04:38:35Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/StreamsAssignmentProtocolVersions.java", "diffHunk": "@@ -19,7 +19,8 @@\n public final class StreamsAssignmentProtocolVersions {\n     public static final int UNKNOWN = -1;\n     public static final int EARLIEST_PROBEABLE_VERSION = 3;\n-    public static final int LATEST_SUPPORTED_VERSION = 8;\n+    public static final int LATEST_SUPPORTED_VERSION = 9;\n+    //When changing the versions update this test: streams_upgrade_test.py::StreamsUpgradeTest.test_version_probing_upgrade", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzEwOTM5Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523109393", "bodyText": "I'll add that to the comment, and add a test", "author": "wcarlson5", "createdAt": "2020-11-13T17:28:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyMjg4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyNjY5Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522626697", "bodyText": "Does the comment relate to the @deprecation suppression? Either way this probably makes more sense as a comment on the PR than in the code.  Given how bad we are about updating comments, I'd try to avoid anything that describes a change and reserve code comments for describing what's currently going on (or better yet, \"why\")", "author": "ableegoldman", "createdAt": "2020-11-13T04:43:11Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java", "diffHunk": "@@ -647,6 +647,7 @@ public void shouldNotViolateEosIfOneTaskGetsFencedUsingIsolatedAppInstances() th\n         return data;\n     }\n \n+    @SuppressWarnings(\"deprecation\") //the threads should no longer fail one thread one at a time", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzEwMzE0Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523103147", "bodyText": "When we remove the old handler we either need to remove the test or remove the suppression. That is what I am hoping the comment will do", "author": "wcarlson5", "createdAt": "2020-11-13T17:21:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyNjY5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyNzI5Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522627296", "bodyText": "same here, what is the comment referring to? Also what does it mean for a test to be deprecated \ud83e\udd14", "author": "ableegoldman", "createdAt": "2020-11-13T04:43:39Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/KStreamRepartitionIntegrationTest.java", "diffHunk": "@@ -144,6 +143,7 @@ public void whenShuttingDown() throws IOException {\n     }\n \n     @Test\n+    @Deprecated //a single thread should no longer die", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzMDE0MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523230140", "bodyText": "So the problem that I am facing is that many tests are set up to work with the old handler. I was able to adapt most to use the new handler but not all. Some, like a few EOS tests, require one thread to die at a time. So I either suppress the deprecation or tag the test as deprecated, thus indicating it should be removed when the old handler is.\nAnother problem is that a few tests rely on the threads dying one at a time or they test behavior in this case but they do not set an old handler. So I can either 1) set an old handler and mark for deletion or 2) adapt for the new out come. For the ones I could, I changed to the new flow but I could not do that with all of them.\n@vvcephei @ableegoldman @cadonna How would you suggest updating these tests?", "author": "wcarlson5", "createdAt": "2020-11-13T21:01:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyNzI5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMxOTY3Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523319677", "bodyText": "I think any test that's trying to verify some unrelated behavior and just using the \"one thread dies at a time\" paradigm as a tool to do so should not be deleted. I'm sure in most if not all cases, there's some way to modify the test to verify that specific behavior either using the new handler or multiple apps or rewriting it altogether.\nBut, there are a lot of tests that do this and a lot of them are pretty tricky, so I wouldn't want to stall this PR on waiting for all of these tests to be updated/adapted. I think we should file tickets for all of these tests and just try to pick up one or two of them every so often. Maybe that's being overly optimistic about our inclination to pick up small tasks even over a long period, but it's better than losing track of them altogether. WDYT?", "author": "ableegoldman", "createdAt": "2020-11-14T01:15:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyNzI5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMzNDczMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523334732", "bodyText": "I agree we shouldn't remove the valid test cases. Maybe the ones that are more complicated I can just set an idempotent old handler and mark as deprecated and we can file tickets to update. Either we work them down or when we go to remove the old handler they will fail and we need to fix them then.", "author": "wcarlson5", "createdAt": "2020-11-14T01:35:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYyNzI5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYzNTA1OQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522635059", "bodyText": "ditto here", "author": "ableegoldman", "createdAt": "2020-11-13T04:49:40Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/QueryableStateIntegrationTest.java", "diffHunk": "@@ -1013,6 +1013,7 @@ public void shouldNotMakeStoreAvailableUntilAllStoresAvailable() throws Exceptio\n     }\n \n     @Test\n+    @Deprecated //A single thread should no longer die", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE0MTk5OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523141998", "bodyText": "same as above", "author": "wcarlson5", "createdAt": "2020-11-13T18:21:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYzNTA1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYzOTk0Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522639947", "bodyText": "Is the latch ever being counted down anywhere? You might want to take a look at some of the test utils, there's a lot of useful stuff so you don't have to implement everything from scratch. If you just want to make sure that the client gets to CLOSED within 15s then I'd recommend TestUtils#waitForCondition", "author": "ableegoldman", "createdAt": "2020-11-13T04:55:41Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsUncaughtExceptionHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+@SuppressWarnings(\"deprecation\") //Need to call the old handler, will remove those calls when the old handler is removed\n+public class StreamsUncaughtExceptionHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static List<String> processorValueCollector;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+            mkMap(\n+                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+            )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldShutdownThreadUsingOldHandler() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            final AtomicBoolean flag = new AtomicBoolean(false);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> flag.set(true));\n+\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(15, TimeUnit.SECONDS);\n+\n+            TestUtils.waitForCondition(flag::get, \"Handler was called\");\n+            assertThat(processorValueCollector.size(), equalTo(2));\n+            assertThat(kafkaStreams.state(), equalTo(KafkaStreams.State.ERROR));\n+        }\n+    }\n+\n+    @Test\n+    public void shouldShutdownClient() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> fail(\"should not hit old handler\"));\n+\n+            kafkaStreams.setUncaughtExceptionHandler(exception -> SHUTDOWN_CLIENT);\n+\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(15, TimeUnit.SECONDS);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI4MDA5Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523280093", "bodyText": "That is useful thanks. I went with waitForApplicationState", "author": "wcarlson5", "createdAt": "2020-11-13T23:14:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjYzOTk0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY0MTA3Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522641072", "bodyText": "Is this the only property that changed? Might be clearer if you just override what you need to here", "author": "ableegoldman", "createdAt": "2020-11-13T04:57:10Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StreamsUncaughtExceptionHandlerIntegrationTest.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.streams.integration;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KStream;\n+import org.apache.kafka.streams.kstream.Named;\n+import org.apache.kafka.streams.processor.AbstractProcessor;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.StreamsTestUtils;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkObjectProperties;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_CLIENT;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.purgeLocalStreamsState;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.equalTo;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.Assert.fail;\n+\n+@Category(IntegrationTest.class)\n+@SuppressWarnings(\"deprecation\") //Need to call the old handler, will remove those calls when the old handler is removed\n+public class StreamsUncaughtExceptionHandlerIntegrationTest {\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    private static String inputTopic;\n+    private static StreamsBuilder builder;\n+    private static Properties properties;\n+    private static List<String> processorValueCollector;\n+    private static String appId = \"\";\n+\n+    @Before\n+    public void setup() {\n+        final String testId = safeUniqueTestName(getClass(), testName);\n+        appId = \"appId_\" + testId;\n+        inputTopic = \"input\" + testId;\n+        IntegrationTestUtils.cleanStateBeforeTest(CLUSTER, inputTopic);\n+\n+        builder  = new StreamsBuilder();\n+\n+        processorValueCollector = new ArrayList<>();\n+\n+        final KStream<String, String> stream = builder.stream(inputTopic);\n+        stream.process(() -> new ShutdownProcessor(processorValueCollector), Named.as(\"process\"));\n+\n+        properties  = mkObjectProperties(\n+            mkMap(\n+                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2),\n+                mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class),\n+                mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class)\n+            )\n+        );\n+    }\n+\n+    @After\n+    public void teardown() throws IOException {\n+        purgeLocalStreamsState(properties);\n+    }\n+\n+    @Test\n+    public void shouldShutdownThreadUsingOldHandler() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            final AtomicBoolean flag = new AtomicBoolean(false);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> flag.set(true));\n+\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(15, TimeUnit.SECONDS);\n+\n+            TestUtils.waitForCondition(flag::get, \"Handler was called\");\n+            assertThat(processorValueCollector.size(), equalTo(2));\n+            assertThat(kafkaStreams.state(), equalTo(KafkaStreams.State.ERROR));\n+        }\n+    }\n+\n+    @Test\n+    public void shouldShutdownClient() throws Exception {\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(builder.build(), properties)) {\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> fail(\"should not hit old handler\"));\n+\n+            kafkaStreams.setUncaughtExceptionHandler(exception -> SHUTDOWN_CLIENT);\n+\n+            StreamsTestUtils.startKafkaStreamsAndWaitForRunningState(kafkaStreams);\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(15, TimeUnit.SECONDS);\n+\n+            assertThat(processorValueCollector.size(), equalTo(1));\n+            assertThat(kafkaStreams.state(), equalTo(KafkaStreams.State.NOT_RUNNING));\n+        }\n+    }\n+\n+    @Test\n+    public void shouldShutdownApplication() throws Exception {\n+        final Topology topology = builder.build();\n+\n+        try (final KafkaStreams kafkaStreams = new KafkaStreams(topology, properties)) {\n+            final KafkaStreams kafkaStreams1 = new KafkaStreams(topology, properties);\n+            final CountDownLatch latch = new CountDownLatch(1);\n+            kafkaStreams.setUncaughtExceptionHandler((t, e) -> fail(\"should not hit old handler\"));\n+            kafkaStreams1.setUncaughtExceptionHandler((t, e) -> fail(\"should not hit old handler\"));\n+            kafkaStreams.setUncaughtExceptionHandler(exception -> SHUTDOWN_APPLICATION);\n+            kafkaStreams1.setUncaughtExceptionHandler(exception -> SHUTDOWN_APPLICATION);\n+\n+            kafkaStreams.start();\n+            kafkaStreams1.start();\n+\n+            produceMessages(0L, inputTopic, \"A\");\n+            latch.await(30, TimeUnit.SECONDS);\n+\n+            assertThat(processorValueCollector.size(), equalTo(1));\n+            assertThat(kafkaStreams.state(), equalTo(KafkaStreams.State.ERROR));\n+            assertThat(kafkaStreams1.state(), equalTo(KafkaStreams.State.ERROR));\n+        }\n+    }\n+\n+    @Test\n+    public void shouldShutdownSingleThreadApplication() throws Exception {\n+        final Properties properties  = mkObjectProperties(\n+            mkMap(\n+                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId),\n+                mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()),\n+                mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI4MDcwNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523280707", "bodyText": "Agree", "author": "wcarlson5", "createdAt": "2020-11-13T23:17:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY0MTA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1MDcwNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522650704", "bodyText": "We should probably use an actual handler here to make sure it works with the GlobalThread. Actually maybe we should add a few unit tests here to make sure that it closes down and rethrows when the old handler is used, but handles the exception internally when the new handler is used, etc", "author": "ableegoldman", "createdAt": "2020-11-13T05:09:14Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStreamThreadTest.java", "diffHunk": "@@ -113,7 +113,8 @@ public String newStoreName(final String prefix) {\n             new StreamsMetricsImpl(new Metrics(), \"test-client\", StreamsConfig.METRICS_LATEST, time),\n             time,\n             \"clientId\",\n-            stateRestoreListener\n+            stateRestoreListener,\n+            e -> { }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1NDA4MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r522654080", "bodyText": "Why set the exception handler in this test and no others?", "author": "ableegoldman", "createdAt": "2020-11-13T05:13:23Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -1000,7 +1012,17 @@ public void restore(final Map<TaskId, Task> tasks) {\n             CLIENT_ID,\n             new LogContext(\"\"),\n             new AtomicInteger(),\n-            new AtomicLong(Long.MAX_VALUE)\n+            new AtomicLong(Long.MAX_VALUE),\n+            null,\n+            e -> {\n+                if (e instanceof RuntimeException) {\n+                    throw (RuntimeException) e;\n+                } else if (e instanceof Error) {\n+                    throw (Error) e;\n+                } else {\n+                    throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", e);\n+                }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3NzM3NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523277374", "bodyText": "Because otherwise the task migrated exception sends it into a endless rebalance", "author": "wcarlson5", "createdAt": "2020-11-13T23:04:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1NDA4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMyMjc3Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523322776", "bodyText": "But TaskMigratedException should never be thrown all the way up to the exception handler. Is that what you're seeing?", "author": "ableegoldman", "createdAt": "2020-11-14T01:18:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1NDA4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMzNzIyNg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523337226", "bodyText": "Not quite. If I remove the handler and just run it there is an illegal state exception which runs endlessly until the handler can exit the loop. It looks like the thread hadn't started all the way before the TaskMigratedExcpetion is thrown\nINFO State transition from STARTING to PENDING_SHUTDOWN (org.apache.kafka.streams.processor.internals.StreamThread:223) [", "author": "wcarlson5", "createdAt": "2020-11-14T01:52:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1NDA4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3MjQ2NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523372464", "bodyText": "Ah ok so there's some other IllegalStateException that would get swallowed if we just used e -> {} like in the other tests, so we need to explicitly rethrow it? That seems fine, although it makes me think that we should go ahead and use a \"real\" handler in all of the tests, not just this one. Otherwise there could be some bug which causes an unexpected exception, but the test would just swallow it and silently pass.\nCan we just use the default handler wrapper for all of these tests so they reflect realistic scenarios?", "author": "ableegoldman", "createdAt": "2020-11-14T04:08:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1NDA4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQzNTI0MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524435241", "bodyText": "The default is in KafkaStreams, but I see your point. We can make all of them rethrow then we will not have to worry about swallowing", "author": "wcarlson5", "createdAt": "2020-11-16T17:13:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1NDA4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzAyODE2Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523028163", "bodyText": "nit: usually we indent 4 spaces, not 8.", "author": "cadonna", "createdAt": "2020-11-13T15:35:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzAzNDI3MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523034271", "bodyText": "Are you sure this is the correct method to call? As far as I understand the the javadocs and the decompiled code, this method does not return the handler you can set on a Thread with setUncaughtExceptionHandler().", "author": "cadonna", "createdAt": "2020-11-13T15:45:11Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable e,\n+                                                   final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA4OTc0Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523089743", "bodyText": "If that's the case, then we really should just set a flag on KafkaStreams to indicate whether that handler has been set.", "author": "vvcephei", "createdAt": "2020-11-13T17:06:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzAzNDI3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzEzODMyNQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523138325", "bodyText": "We can just set a flag through to be safe", "author": "wcarlson5", "createdAt": "2020-11-13T18:17:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzAzNDI3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA0MTQ1NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523041454", "bodyText": "I guess, you wanted to do this\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"and the registered exception handler opted to \\\" + action + \\\".\" +\n          \n          \n            \n                                    \"and the registered exception handler opted to \" + action + \".\" +", "author": "cadonna", "createdAt": "2020-11-13T15:56:14Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable e,\n+                                                   final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            log.warn(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                    \"The old handler will be ignored as long as a new handler is set.\");\n+        }\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \\\" + action + \\\".\" +", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA3Mjc4MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523072781", "bodyText": "yes good catch", "author": "wcarlson5", "createdAt": "2020-11-13T16:45:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA0MTQ1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA0MTg0Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523041842", "bodyText": "Please use a more meaningful parameter name.", "author": "cadonna", "createdAt": "2020-11-13T15:56:53Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable e,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA4MDU5MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523080590", "bodyText": "The name is a bit confusing. The best I could come up is handleStreamsUncaughtExceptionByDefault(), but I am sure there is a better name.", "author": "cadonna", "createdAt": "2020-11-13T16:57:57Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +375,93 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * So inorder to get the thread as the java handler type uses use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzEzNjU2OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523136568", "bodyText": "how about defaultStreamsUncaughtExceptionHandler?", "author": "wcarlson5", "createdAt": "2020-11-13T18:14:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA4MDU5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMyNzMzOA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523327338", "bodyText": "Well it's not exactly a default, technically this method is always used to decide which handler to invoke (which may or may not invoke a default handler). Any of these would be fine by me but I'll throw one more idea out there: invokeOldOrNewUncaughtExceptionHandler", "author": "ableegoldman", "createdAt": "2020-11-14T01:24:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA4MDU5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQzMzg4MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524433881", "bodyText": "It's actually not always used. It is only used until a new handler is set in which it is over written. Once that happens we don't want the old handler to be set so we do not wrap a user provided handler with this method", "author": "wcarlson5", "createdAt": "2020-11-16T17:11:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzA4MDU5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMxMTIxOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523311219", "bodyText": "What happens if we try to read the error code of an earlier subscription version? I genuinely don't know what the generated code does, but we should make sure it doesn't throw an NPE or something. Could you add a unit test for this case?", "author": "ableegoldman", "createdAt": "2020-11-14T01:05:18Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/SubscriptionInfo.java", "diffHunk": "@@ -115,6 +119,10 @@ private SubscriptionInfo(final SubscriptionInfoData subscriptionInfoData) {\n         this.data = subscriptionInfoData;\n     }\n \n+    public int errorCode() {\n+        return data.errorCode();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMzNzc4NQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523337785", "bodyText": "Good idea. It does not seem to do anything. but good to have a test for it", "author": "wcarlson5", "createdAt": "2020-11-14T01:56:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMxMTIxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ0MTUxNQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524441515", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * In order to get the thread use Thread.currentThread()\n          \n          \n            \n                 * In order to get the thread that threw the exception, use Thread.currentThread().", "author": "vvcephei", "createdAt": "2020-11-16T17:22:55Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +377,90 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * In order to get the thread use Thread.currentThread()", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ0ODE2MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524448160", "bodyText": "Likewise, here, it seems better to do a non-blocking close.", "author": "vvcephei", "createdAt": "2020-11-16T17:31:54Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +377,90 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * In order to get the thread use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                    \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void defaultStreamsUncaughtExceptionHandler(final Throwable throwable) {\n+        if (oldHanlder) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable throwable,\n+                                                final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(throwable);\n+        if (oldHanlder) {\n+            log.warn(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                    \"The old handler will be ignored as long as a new handler is set.\");\n+        }\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \" + action + \".\" +\n+                        \" The streams client is going to shut down now. \", throwable);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (throwable instanceof Error) {\n+                    log.error(\"This option requires running threads to shut down the application.\" +\n+                            \"but the uncaught exception was an Error, which means this runtime is no \" +\n+                            \"longer in a well-defined state. Attempting to send the shutdown command anyway.\", throwable);\n+                }\n+                if (Thread.currentThread().equals(globalStreamThread) && threads.stream().noneMatch(StreamThread::isRunning)) {\n+                    log.error(\"Exception in global thread caused the application to attempt to shutdown.\" +\n+                            \" This action will succeed only if there is at least one StreamThread running on this client.\" +\n+                            \" Currently there are no running threads so will now close the client.\");\n+                    close();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5MDIxMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524490211", "bodyText": "It doesn't really matter to me, though I think that non blocking is probably  preferable.", "author": "wcarlson5", "createdAt": "2020-11-16T18:39:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ0ODE2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ3MDY4Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524470683", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        \"and the application is going to shut down: \", throwable);\n          \n          \n            \n                                        \"and sent shutdown request for the entire application.\", throwable);", "author": "vvcephei", "createdAt": "2020-11-16T18:07:11Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +377,90 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * In order to get the thread use Thread.currentThread()\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                    \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void defaultStreamsUncaughtExceptionHandler(final Throwable throwable) {\n+        if (oldHanlder) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable throwable,\n+                                                final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(throwable);\n+        if (oldHanlder) {\n+            log.warn(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                    \"The old handler will be ignored as long as a new handler is set.\");\n+        }\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \" + action + \".\" +\n+                        \" The streams client is going to shut down now. \", throwable);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (throwable instanceof Error) {\n+                    log.error(\"This option requires running threads to shut down the application.\" +\n+                            \"but the uncaught exception was an Error, which means this runtime is no \" +\n+                            \"longer in a well-defined state. Attempting to send the shutdown command anyway.\", throwable);\n+                }\n+                if (Thread.currentThread().equals(globalStreamThread) && threads.stream().noneMatch(StreamThread::isRunning)) {\n+                    log.error(\"Exception in global thread caused the application to attempt to shutdown.\" +\n+                            \" This action will succeed only if there is at least one StreamThread running on this client.\" +\n+                            \" Currently there are no running threads so will now close the client.\");\n+                    close();\n+                } else {\n+                    for (final StreamThread streamThread : threads) {\n+                        streamThread.sendShutdownRequest(AssignorError.SHUTDOWN_REQUESTED);\n+                    }\n+                    log.error(\"Encountered the following exception during processing \" +\n+                            \"and the application is going to shut down: \", throwable);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ3ODcxNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524478717", "bodyText": "I think I'd like to re-raise Sophie's concern here. It doesn't compute for me why we are casting an int to a byte here..", "author": "vvcephei", "createdAt": "2020-11-16T18:20:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -255,8 +255,9 @@ public ByteBuffer subscriptionUserData(final Set<String> topics) {\n             taskManager.processId(),\n             userEndPoint,\n             taskManager.getTaskOffsetSums(),\n-            uniqueField)\n-                .encode();\n+            uniqueField,\n+            (byte) assignmentErrorCode.get()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0MDQxNg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r524540416", "bodyText": "I guess I must have misunderstood  your earlier comment. I thought you wanted it to stay a byte so that is why I pushed back. But if you have no objections I will just change it", "author": "wcarlson5", "createdAt": "2020-11-16T20:06:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ3ODcxNw=="}], "type": "inlineReview"}, {"oid": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "url": "https://github.com/apache/kafka/commit/c170379a33e35b56d0dea2158f9ff9f1b52ba914", "message": "Still has a problem with actually shutting down the application", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "8c20e715e172202dfa8d229af20f1fd95e85e9c8", "url": "https://github.com/apache/kafka/commit/8c20e715e172202dfa8d229af20f1fd95e85e9c8", "message": "in progress", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "1e86e6c37bc9a423efb301c963cfc146d98c0b7b", "url": "https://github.com/apache/kafka/commit/1e86e6c37bc9a423efb301c963cfc146d98c0b7b", "message": "needed to stop the rebalance", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "a969ca55572bc041cdbc907aa5b43cf676ac0eb3", "url": "https://github.com/apache/kafka/commit/a969ca55572bc041cdbc907aa5b43cf676ac0eb3", "message": "Still has a problem with actually shutting down the application", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "cde16becd223ee64b5c59f8e458641d2f37c9e04", "url": "https://github.com/apache/kafka/commit/cde16becd223ee64b5c59f8e458641d2f37c9e04", "message": "style", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "a70d7b8a5c8df0f585a0e825067328d95cb8b644", "url": "https://github.com/apache/kafka/commit/a70d7b8a5c8df0f585a0e825067328d95cb8b644", "message": "added old handler logic back to global stream threads", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "769e471050e905313f071fb7fff4e72d9caa3801", "url": "https://github.com/apache/kafka/commit/769e471050e905313f071fb7fff4e72d9caa3801", "message": "fixed mem error", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "07dbf7dc4d1db8988d2a98b586c789d9337ee20f", "url": "https://github.com/apache/kafka/commit/07dbf7dc4d1db8988d2a98b586c789d9337ee20f", "message": "style and system test msgs", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "8cf9c891f6f61ac83ff3077e40c26e2f998e4f78", "url": "https://github.com/apache/kafka/commit/8cf9c891f6f61ac83ff3077e40c26e2f998e4f78", "message": "java doc changes", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "a4a95594eabeafb6e8f6a2eaa953cb77264726dd", "url": "https://github.com/apache/kafka/commit/a4a95594eabeafb6e8f6a2eaa953cb77264726dd", "message": "refactor and address comments", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "96f0e8fe7d840de9576d974994a62e36a010dbf1", "url": "https://github.com/apache/kafka/commit/96f0e8fe7d840de9576d974994a62e36a010dbf1", "message": "incremented version number in probing test", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "cd377bae8a9ba7ba1aa5463e47b954985b11f2f4", "url": "https://github.com/apache/kafka/commit/cd377bae8a9ba7ba1aa5463e47b954985b11f2f4", "message": "address comments", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "5d08b9f24021198581a7271f98a0a7db3d7d4c0b", "url": "https://github.com/apache/kafka/commit/5d08b9f24021198581a7271f98a0a7db3d7d4c0b", "message": "Address comments and clean up named", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "256600903ebc08ab486a034e31905093ec457cca", "url": "https://github.com/apache/kafka/commit/256600903ebc08ab486a034e31905093ec457cca", "message": "change log statement", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "c4718d6673e295727a22cc9361b0dac8e5a8a3d2", "url": "https://github.com/apache/kafka/commit/c4718d6673e295727a22cc9361b0dac8e5a8a3d2", "message": "added tag and make logic better", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "527373b4b5d4d70dc180f825fe6de8ce1663987b", "url": "https://github.com/apache/kafka/commit/527373b4b5d4d70dc180f825fe6de8ce1663987b", "message": "address comments", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "e426f49dce4fbf3d9cc1f4fe51a1329ad5883288", "url": "https://github.com/apache/kafka/commit/e426f49dce4fbf3d9cc1f4fe51a1329ad5883288", "message": "typo", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "9747f6be998f08f1c5061983d13affd065c90811", "url": "https://github.com/apache/kafka/commit/9747f6be998f08f1c5061983d13affd065c90811", "message": "add test", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "48dbafc48759cf5e133ebc8f3e07120c088e42ca", "url": "https://github.com/apache/kafka/commit/48dbafc48759cf5e133ebc8f3e07120c088e42ca", "message": "Made so tests can no longer swallow", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "f07aba83e3037253a8bf3966308cd1e7fe8c0073", "url": "https://github.com/apache/kafka/commit/f07aba83e3037253a8bf3966308cd1e7fe8c0073", "message": "removed indent", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "0236aa86ba071dbeab8bf0d517cf9c13e949c65e", "url": "https://github.com/apache/kafka/commit/0236aa86ba071dbeab8bf0d517cf9c13e949c65e", "message": "address comments", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "3f2b8b2cf7885c81f0bf737b29a0646895f1aa9b", "url": "https://github.com/apache/kafka/commit/3f2b8b2cf7885c81f0bf737b29a0646895f1aa9b", "message": "address comments", "committedDate": "2020-11-17T18:23:43Z", "type": "commit"}, {"oid": "56f94913ab0c3a53ffdff86d83e81c7c3c92317f", "url": "https://github.com/apache/kafka/commit/56f94913ab0c3a53ffdff86d83e81c7c3c92317f", "message": "remove byte", "committedDate": "2020-11-17T18:23:43Z", "type": "commit"}, {"oid": "2cf792c124cf199ebc5948909f0df8e54aa6d2e4", "url": "https://github.com/apache/kafka/commit/2cf792c124cf199ebc5948909f0df8e54aa6d2e4", "message": "fixed flaky test sometime causing buf underflow", "committedDate": "2020-11-17T19:20:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTE2OTc5MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525169791", "bodyText": "There is something wrong in this sentence.", "author": "cadonna", "createdAt": "2020-11-17T13:52:01Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +377,90 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * In order to get the thread use that threw the exception, Thread.currentThread().", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ0NDk1OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525444958", "bodyText": "need to remove use", "author": "wcarlson5", "createdAt": "2020-11-17T19:43:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTE2OTc5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTE3MDkyMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525170922", "bodyText": "oldHanlder -> oldHandler", "author": "cadonna", "createdAt": "2020-11-17T13:53:37Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +377,90 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * In order to get the thread use that threw the exception, Thread.currentThread().\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                    \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void defaultStreamsUncaughtExceptionHandler(final Throwable throwable) {\n+        if (oldHanlder) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ0MjI0OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525442248", "bodyText": "oops", "author": "wcarlson5", "createdAt": "2020-11-17T19:41:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTE3MDkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTE5NDU0OQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525194549", "bodyText": "nit: remove line", "author": "cadonna", "createdAt": "2020-11-17T14:26:06Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -559,18 +552,52 @@ void runLoop() {\n                 }\n             } catch (final TaskCorruptedException e) {\n                 log.warn(\"Detected the states of tasks \" + e.corruptedTaskWithChangelogs() + \" are corrupted. \" +\n-                             \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n+                        \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n                 try {\n                     taskManager.handleCorruption(e.corruptedTaskWithChangelogs());\n                 } catch (final TaskMigratedException taskMigrated) {\n                     handleTaskMigrated(taskMigrated);\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final UnsupportedVersionException e) {\n+                final String errorMessage = e.getMessage();\n+                if (errorMessage != null &&\n+                        errorMessage.startsWith(\"Broker unexpectedly doesn't support requireStable flag on version \")) {\n+\n+                    log.error(\"Shutting down because the Kafka cluster seems to be on a too old version. \" +\n+                                    \"Setting {}=\\\"{}\\\" requires broker version 2.5 or higher.\",\n+                            StreamsConfig.PROCESSING_GUARANTEE_CONFIG,\n+                            EXACTLY_ONCE_BETA);\n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "url": "https://github.com/apache/kafka/commit/1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "message": "couple of comments", "committedDate": "2020-11-17T19:51:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzNjU1NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525636554", "bodyText": "I think it makes more sense to transition to ERROR in this case than to NOT_RUNNING. But let's put this on file with the other FSM-related work planned for following PRs", "author": "ableegoldman", "createdAt": "2020-11-18T01:32:09Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +377,90 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * In order to get the thread that threw the exception, Thread.currentThread().\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                    \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void defaultStreamsUncaughtExceptionHandler(final Throwable throwable) {\n+        if (oldHandler) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable throwable,\n+                                                final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(throwable);\n+        if (oldHandler) {\n+            log.warn(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                    \"The old handler will be ignored as long as a new handler is set.\");\n+        }\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \" + action + \".\" +\n+                        \" The streams client is going to shut down now. \", throwable);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (throwable instanceof Error) {\n+                    log.error(\"This option requires running threads to shut down the application.\" +\n+                            \"but the uncaught exception was an Error, which means this runtime is no \" +\n+                            \"longer in a well-defined state. Attempting to send the shutdown command anyway.\", throwable);\n+                }\n+                if (Thread.currentThread().equals(globalStreamThread) && threads.stream().noneMatch(StreamThread::isRunning)) {\n+                    log.error(\"Exception in global thread caused the application to attempt to shutdown.\" +\n+                            \" This action will succeed only if there is at least one StreamThread running on this client.\" +\n+                            \" Currently there are no running threads so will now close the client.\");\n+                    close(Duration.ZERO);", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY4MDg3NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525680874", "bodyText": "I am on the fence about this. I do think its would be consistent to be not running but also it did shutdown cleanly. We made this choice when ERROR still meant all threads had died and that is not true now. In the end I just went with what we had in the KIP rather than try to change it. Though I could be swayed to leave this in ERROR.", "author": "wcarlson5", "createdAt": "2020-11-18T02:46:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzNjU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTcwMTY5MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525701691", "bodyText": "That's fair. I guess I was thinking less about the inherent meaning of ERROR vs NOT_RUNNING, and more about not behaving differently in this special case. ie if there are still StreamThreads running when a user selects SHUTDOWN_APPLICATION, then we ultimately transition to ERROR. So it strikes me as a bit odd to transition to NOT_RUNNING just because we didn't happen to have any threads left.", "author": "ableegoldman", "createdAt": "2020-11-18T03:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzNjU1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MDA4OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525640088", "bodyText": "Why do we shut down the global thread only after all stream threads have completed their shutdown? Seems like it would be more efficient to send the shutdown signal to everyone first, and then wait for all the threads to join. Can you try this out in the followup PR?", "author": "ableegoldman", "createdAt": "2020-11-18T01:43:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -932,56 +1028,62 @@ public synchronized boolean close(final long timeout, final TimeUnit timeUnit) {\n         return close(timeoutMs);\n     }\n \n-    private boolean close(final long timeoutMs) {\n-        if (!setState(State.PENDING_SHUTDOWN)) {\n-            // if transition failed, it means it was either in PENDING_SHUTDOWN\n-            // or NOT_RUNNING already; just check that all threads have been stopped\n-            log.info(\"Already in the pending shutdown state, wait to complete shutdown\");\n-        } else {\n-            stateDirCleaner.shutdownNow();\n-            if (rocksDBMetricsRecordingService != null) {\n-                rocksDBMetricsRecordingService.shutdownNow();\n-            }\n+    private Thread shutdownHelper(final boolean error) {\n+        stateDirCleaner.shutdownNow();\n+        if (rocksDBMetricsRecordingService != null) {\n+            rocksDBMetricsRecordingService.shutdownNow();\n+        }\n \n-            // wait for all threads to join in a separate thread;\n-            // save the current thread so that if it is a stream thread\n-            // we don't attempt to join it and cause a deadlock\n-            final Thread shutdownThread = new Thread(() -> {\n-                // notify all the threads to stop; avoid deadlocks by stopping any\n-                // further state reports from the thread since we're shutting down\n-                for (final StreamThread thread : threads) {\n-                    thread.shutdown();\n-                }\n+        // wait for all threads to join in a separate thread;\n+        // save the current thread so that if it is a stream thread\n+        // we don't attempt to join it and cause a deadlock\n+        return new Thread(() -> {\n+            // notify all the threads to stop; avoid deadlocks by stopping any\n+            // further state reports from the thread since we're shutting down\n+            for (final StreamThread thread : threads) {\n+                thread.shutdown();\n+            }\n \n-                for (final StreamThread thread : threads) {\n-                    try {\n-                        if (!thread.isRunning()) {\n-                            thread.join();\n-                        }\n-                    } catch (final InterruptedException ex) {\n-                        Thread.currentThread().interrupt();\n+            for (final StreamThread thread : threads) {\n+                try {\n+                    if (!thread.isRunning()) {\n+                        thread.join();\n                     }\n+                } catch (final InterruptedException ex) {\n+                    Thread.currentThread().interrupt();\n                 }\n+            }\n \n-                if (globalStreamThread != null) {\n-                    globalStreamThread.shutdown();\n-                }\n+            if (globalStreamThread != null) {\n+                globalStreamThread.shutdown();\n+            }", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY3ODIzNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525678234", "bodyText": "You are right I think. I just copied from the normal close method because I knew it worked. In a follow up we can maybe change both of these. Do you think that there should be a ak ticket to track it?", "author": "wcarlson5", "createdAt": "2020-11-18T02:44:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MDA4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY5Mjk2MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525692960", "bodyText": "Eh, I wouldn't bother with an AK ticket if this will be tackled in the next PR. I'll just make a list of all the minor followup work somewhere to keep track", "author": "ableegoldman", "createdAt": "2020-11-18T02:59:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MDA4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525650632", "bodyText": "I just realized that this is going to be a problem with the way the ERROR state is being used. IF we closeToError then we transition to ERROR and shut down, however ERROR -> PENDING_SHUTDOWN is still an allowed transition so there's nothing to prevent the shutdown from being triggered again when a user calls close(). And note that a lot of users most likely have a state listener at the moment which does exactly that, ie when it sees a transition to ERROR it immediately invokes close (because that's what you should do with the current semantics)\nJust another thing that I think we can fix with some minor rewiring of the FSM.", "author": "ableegoldman", "createdAt": "2020-11-18T02:14:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -932,56 +1028,62 @@ public synchronized boolean close(final long timeout, final TimeUnit timeUnit) {\n         return close(timeoutMs);\n     }\n \n-    private boolean close(final long timeoutMs) {\n-        if (!setState(State.PENDING_SHUTDOWN)) {\n-            // if transition failed, it means it was either in PENDING_SHUTDOWN\n-            // or NOT_RUNNING already; just check that all threads have been stopped\n-            log.info(\"Already in the pending shutdown state, wait to complete shutdown\");\n-        } else {\n-            stateDirCleaner.shutdownNow();\n-            if (rocksDBMetricsRecordingService != null) {\n-                rocksDBMetricsRecordingService.shutdownNow();\n-            }\n+    private Thread shutdownHelper(final boolean error) {\n+        stateDirCleaner.shutdownNow();\n+        if (rocksDBMetricsRecordingService != null) {\n+            rocksDBMetricsRecordingService.shutdownNow();\n+        }\n \n-            // wait for all threads to join in a separate thread;\n-            // save the current thread so that if it is a stream thread\n-            // we don't attempt to join it and cause a deadlock\n-            final Thread shutdownThread = new Thread(() -> {\n-                // notify all the threads to stop; avoid deadlocks by stopping any\n-                // further state reports from the thread since we're shutting down\n-                for (final StreamThread thread : threads) {\n-                    thread.shutdown();\n-                }\n+        // wait for all threads to join in a separate thread;\n+        // save the current thread so that if it is a stream thread\n+        // we don't attempt to join it and cause a deadlock\n+        return new Thread(() -> {\n+            // notify all the threads to stop; avoid deadlocks by stopping any\n+            // further state reports from the thread since we're shutting down\n+            for (final StreamThread thread : threads) {\n+                thread.shutdown();\n+            }\n \n-                for (final StreamThread thread : threads) {\n-                    try {\n-                        if (!thread.isRunning()) {\n-                            thread.join();\n-                        }\n-                    } catch (final InterruptedException ex) {\n-                        Thread.currentThread().interrupt();\n+            for (final StreamThread thread : threads) {\n+                try {\n+                    if (!thread.isRunning()) {\n+                        thread.join();\n                     }\n+                } catch (final InterruptedException ex) {\n+                    Thread.currentThread().interrupt();\n                 }\n+            }\n \n-                if (globalStreamThread != null) {\n-                    globalStreamThread.shutdown();\n-                }\n+            if (globalStreamThread != null) {\n+                globalStreamThread.shutdown();\n+            }\n \n-                if (globalStreamThread != null && !globalStreamThread.stillRunning()) {\n-                    try {\n-                        globalStreamThread.join();\n-                    } catch (final InterruptedException e) {\n-                        Thread.currentThread().interrupt();\n-                    }\n-                    globalStreamThread = null;\n+            if (globalStreamThread != null && !globalStreamThread.stillRunning()) {\n+                try {\n+                    globalStreamThread.join();\n+                } catch (final InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n                 }\n+                globalStreamThread = null;\n+            }\n \n-                adminClient.close();\n+            adminClient.close();\n \n-                streamsMetrics.removeAllClientLevelMetrics();\n-                metrics.close();\n+            streamsMetrics.removeAllClientLevelMetrics();\n+            metrics.close();\n+            if (!error) {\n                 setState(State.NOT_RUNNING);\n-            }, \"kafka-streams-close-thread\");\n+            }\n+        }, \"kafka-streams-close-thread\");\n+    }\n+\n+    private boolean close(final long timeoutMs) {\n+        if (!setState(State.PENDING_SHUTDOWN)) {", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY4MTY0Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525681642", "bodyText": "This is currently the plan to remove that transition. It is pretty much the only change we plan to make to the FSM.", "author": "wcarlson5", "createdAt": "2020-11-18T02:47:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTczNDQxNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525734417", "bodyText": "WDYT about having both NOT_RUNNING and ERROR go through PENDING_SHUTDOWN, rather than just transitioning directly and permanently to ERROR? At a high level I think it just makes sense for ERROR and NOT_RUNNING to be symmetric. Also any benefit to having an intermediate PENDING_SHUTDOWN for the NOT_RUNNING case presumably applies to the ERROR case as well. eg, it indicates whether Streams has completed its shutdown or not: users know that an app in PENDING_SHUTDOWN should never be killed, its only safe to do so once it reaches NOT_RUNNING. We should provide the same functionality and only transition to ERROR after the shutdown is complete", "author": "ableegoldman", "createdAt": "2020-11-18T03:30:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjIxMTQwOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r526211409", "bodyText": "I do think that Error should not have direct transition. However I don't like using PENDING_SHUTDOWN , mostly because we can already distinguish between the two states and it would be best to inform right away. Also it could be a problem if we went to set Error and some how it went from PENDING_SHUTDOWN to NOT_RUNNING. I am in favor of adding something like PENDING_ERROR just to be more precise.", "author": "wcarlson5", "createdAt": "2020-11-18T16:08:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ3NzI1OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r526477258", "bodyText": "Sounds reasonable", "author": "ableegoldman", "createdAt": "2020-11-18T22:53:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1ODYzOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525658639", "bodyText": "Hm ok this might be a problem. Since this is thrown from another catch block and not from the try block, it won't be caught by the catch block below and will slip through the exception handler.", "author": "ableegoldman", "createdAt": "2020-11-18T02:23:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java", "diffHunk": "@@ -311,6 +314,8 @@ public void run() {\n                 \"Updating global state failed. You can restart KafkaStreams to recover from this error.\",\n                 recoverableException", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY4Njg0Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525686843", "bodyText": "like in stream thread we can just add a call to the handler", "author": "wcarlson5", "createdAt": "2020-11-18T02:53:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1ODYzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY2MzY0MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525663640", "bodyText": "We should remember to update the wording here when we add the REPLACE_THREAD functionality", "author": "ableegoldman", "createdAt": "2020-11-18T02:28:30Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -559,18 +552,51 @@ void runLoop() {\n                 }\n             } catch (final TaskCorruptedException e) {\n                 log.warn(\"Detected the states of tasks \" + e.corruptedTaskWithChangelogs() + \" are corrupted. \" +\n-                             \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n+                        \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n                 try {\n                     taskManager.handleCorruption(e.corruptedTaskWithChangelogs());\n                 } catch (final TaskMigratedException taskMigrated) {\n                     handleTaskMigrated(taskMigrated);\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final UnsupportedVersionException e) {\n+                final String errorMessage = e.getMessage();\n+                if (errorMessage != null &&\n+                        errorMessage.startsWith(\"Broker unexpectedly doesn't support requireStable flag on version \")) {\n+\n+                    log.error(\"Shutting down because the Kafka cluster seems to be on a too old version. \" +", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "35dc69a461be58624c13ce4a252ed483d1f4c65d", "url": "https://github.com/apache/kafka/commit/35dc69a461be58624c13ce4a252ed483d1f4c65d", "message": "respond to exception", "committedDate": "2020-11-18T03:39:02Z", "type": "commit"}]}