{"pr_number": 9270, "pr_title": "KAFKA-10284: Group membership update due to static member rejoin should be persisted", "pr_createdAt": "2020-09-09T08:53:03Z", "pr_url": "https://github.com/apache/kafka/pull/9270", "timeline": [{"oid": "058aa1d9f17cce6a3f7fff9023ebf42b8f4f642e", "url": "https://github.com/apache/kafka/commit/058aa1d9f17cce6a3f7fff9023ebf42b8f4f642e", "message": "KAFKA-10284: Group membership update due to static member rejoin should be persisted", "committedDate": "2020-09-09T08:34:14Z", "type": "commit"}, {"oid": "7466bcd4086646c7e0dfa1906adca42610a6f601", "url": "https://github.com/apache/kafka/commit/7466bcd4086646c7e0dfa1906adca42610a6f601", "message": "formatting", "committedDate": "2020-09-09T13:23:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjg5Njk5Nw==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r492896997", "bodyText": "nit: alignment", "author": "abbccdda", "createdAt": "2020-09-22T17:05:00Z", "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "diffHunk": "@@ -3882,6 +3942,21 @@ class GroupCoordinatorTest {\n     Await.result(responseFuture, Duration(rebalanceTimeout + 100, TimeUnit.MILLISECONDS))\n   }\n \n+  private def staticJoinGroupWithPersistence(groupId: String,\n+                                 memberId: String,", "originalCommit": "7466bcd4086646c7e0dfa1906adca42610a6f601", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQyNjgxOA==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r494426818", "bodyText": "Fixed, thanks!", "author": "feyman2016", "createdAt": "2020-09-24T15:49:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjg5Njk5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjg5OTQxMA==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r492899410", "bodyText": "Should we reply join failure if the persistence of the group metadata failed?", "author": "abbccdda", "createdAt": "2020-09-22T17:08:49Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupCoordinator.scala", "diffHunk": "@@ -1040,21 +1040,36 @@ class GroupCoordinator(val brokerId: Int,\n \n     group.currentState match {\n       case Stable =>\n-        info(s\"Static member joins during Stable stage will not trigger rebalance.\")\n-        group.maybeInvokeJoinCallback(member, JoinGroupResult(\n-          members = List.empty,\n-          memberId = newMemberId,\n-          generationId = group.generationId,\n-          protocolType = group.protocolType,\n-          protocolName = group.protocolName,\n-          // We want to avoid current leader performing trivial assignment while the group\n-          // is in stable stage, because the new assignment in leader's next sync call\n-          // won't be broadcast by a stable group. This could be guaranteed by\n-          // always returning the old leader id so that the current leader won't assume itself\n-          // as a leader based on the returned message, since the new member.id won't match\n-          // returned leader id, therefore no assignment will be performed.\n-          leaderId = currentLeader,\n-          error = Errors.NONE))\n+        // check if group's selectedProtocol of next generation will change, if not, simply store group to persist the\n+        // updated static member, if yes, rebalance should be triggered to let the group's assignment and selectProtocol consistent\n+        val selectedProtocolOfNextGeneration = group.selectProtocol\n+        if (group.protocolName.contains(selectedProtocolOfNextGeneration)) {\n+          info(s\"Static member which joins during Stable stage and doesn't affect selectProtocol will not trigger rebalance.\")\n+          val groupAssignment: Map[String, Array[Byte]] = group.allMemberMetadata.map(member => member.memberId -> member.assignment).toMap\n+          groupManager.storeGroup(group, groupAssignment, error => {\n+            group.inLock {\n+              if (error != Errors.NONE) {", "originalCommit": "7466bcd4086646c7e0dfa1906adca42610a6f601", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQyNTk0NA==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r494425944", "bodyText": "Indeed, here need to be revised, will update~", "author": "feyman2016", "createdAt": "2020-09-24T15:48:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjg5OTQxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzgxODc2Ng==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r497818766", "bodyText": "Hi @feyman2016 , I just noticed this PR. Thanks for picking this up!\nI'm wondering something along similar lines; should we move the whole join callback inside this block? It seems like that's the way we can delay the join group response until after the update is actually persisted.", "author": "vvcephei", "createdAt": "2020-09-30T21:44:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjg5OTQxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTE5NjA5Mg==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r499196092", "bodyText": "Thanks for the review, @vvcephei . You're right for the current commit, but as @abbccdda mentioned, the current commit does have issues, I'm revising it to reset the static member in the group and return the error if storeGroup encountered any errors. Code is ready, but met some local issues when writing unittests, will update once it's ready.", "author": "feyman2016", "createdAt": "2020-10-04T01:28:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjg5OTQxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTEzMzQ4OA==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r505133488", "bodyText": "@vvcephei  @abbccdda Revised the persistence failure handling logic, now it will revert the member id update in the groupMetaData if any persistence error encountered and call the responseCallback with the returned error.", "author": "feyman2016", "createdAt": "2020-10-15T02:51:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjg5OTQxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjkwMDIyNw==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r492900227", "bodyText": "Could you elaborate why this case is possible? We do have checks for !group.supportsProtocols(protocolType, MemberMetadata.plainProtocolSet(protocols) in the caller, so if the group protocol is incompatible, won't we just reject the rejoin?", "author": "abbccdda", "createdAt": "2020-09-22T17:10:08Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupCoordinator.scala", "diffHunk": "@@ -1040,21 +1040,36 @@ class GroupCoordinator(val brokerId: Int,\n \n     group.currentState match {\n       case Stable =>\n-        info(s\"Static member joins during Stable stage will not trigger rebalance.\")\n-        group.maybeInvokeJoinCallback(member, JoinGroupResult(\n-          members = List.empty,\n-          memberId = newMemberId,\n-          generationId = group.generationId,\n-          protocolType = group.protocolType,\n-          protocolName = group.protocolName,\n-          // We want to avoid current leader performing trivial assignment while the group\n-          // is in stable stage, because the new assignment in leader's next sync call\n-          // won't be broadcast by a stable group. This could be guaranteed by\n-          // always returning the old leader id so that the current leader won't assume itself\n-          // as a leader based on the returned message, since the new member.id won't match\n-          // returned leader id, therefore no assignment will be performed.\n-          leaderId = currentLeader,\n-          error = Errors.NONE))\n+        // check if group's selectedProtocol of next generation will change, if not, simply store group to persist the\n+        // updated static member, if yes, rebalance should be triggered to let the group's assignment and selectProtocol consistent\n+        val selectedProtocolOfNextGeneration = group.selectProtocol\n+        if (group.protocolName.contains(selectedProtocolOfNextGeneration)) {\n+          info(s\"Static member which joins during Stable stage and doesn't affect selectProtocol will not trigger rebalance.\")\n+          val groupAssignment: Map[String, Array[Byte]] = group.allMemberMetadata.map(member => member.memberId -> member.assignment).toMap\n+          groupManager.storeGroup(group, groupAssignment, error => {\n+            group.inLock {\n+              if (error != Errors.NONE) {\n+                warn(s\"Failed to persist metadata for group ${group.groupId}: ${error.message}\")\n+              }\n+            }\n+          })\n+          group.maybeInvokeJoinCallback(member, JoinGroupResult(\n+            members = List.empty,\n+            memberId = newMemberId,\n+            generationId = group.generationId,\n+            protocolType = group.protocolType,\n+            protocolName = group.protocolName,\n+            // We want to avoid current leader performing trivial assignment while the group\n+            // is in stable stage, because the new assignment in leader's next sync call\n+            // won't be broadcast by a stable group. This could be guaranteed by\n+            // always returning the old leader id so that the current leader won't assume itself\n+            // as a leader based on the returned message, since the new member.id won't match\n+            // returned leader id, therefore no assignment will be performed.\n+            leaderId = currentLeader,\n+            error = Errors.NONE))\n+        } else {\n+          maybePrepareRebalance(group, s\"Group's selectedProtocol will change because static member ${member.memberId} with instance id $groupInstanceId joined with change of protocol\")", "originalCommit": "7466bcd4086646c7e0dfa1906adca42610a6f601", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQyNDQ1Mg==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r494424452", "bodyText": "For example, if previously there are one leader + one follower(both static) in a group, the protocols are: List((\"range\", metadata), (\"roundrobin\", metadata)) for both, and current selected protocol is range, if later the follower join again with protocols: List((\"roundrobin\", metadata)), and the selectedProtocol should be roundrobin, now, the selectedProtocol and the actual assignment is not consistent, here I let it rebalance to make sure that the selectedProtocol and actual assignment are consistent. On the other way around, if we don't do the rebalance, we cannot successfully persist the group since this line val metadata = memberMetadata.metadata(protocol) in kafka.coordinator.group.GroupMetadataManager#groupMetadataValue will fail. Test staticMemberRejoinWithUnknownMemberIdAndChangeOfProtocolWithSelectedProtocolChanged  is for this case.", "author": "feyman2016", "createdAt": "2020-09-24T15:46:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjkwMDIyNw=="}], "type": "inlineReview"}, {"oid": "ee2adcec557223c56def176096d88527a629eb9c", "url": "https://github.com/apache/kafka/commit/ee2adcec557223c56def176096d88527a629eb9c", "message": "fix format", "committedDate": "2020-09-24T15:47:05Z", "type": "commit"}, {"oid": "6b743e83192649deb56b772c1d132b7f5b701be1", "url": "https://github.com/apache/kafka/commit/6b743e83192649deb56b772c1d132b7f5b701be1", "message": "update persistence failure handling logic", "committedDate": "2020-10-15T02:39:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcyMTgwNw==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r505721807", "bodyText": "Seems the helper only gets called once?", "author": "abbccdda", "createdAt": "2020-10-15T17:37:26Z", "path": "core/src/test/scala/unit/kafka/coordinator/group/GroupCoordinatorTest.scala", "diffHunk": "@@ -3789,6 +3844,41 @@ class GroupCoordinatorTest {\n                             requireKnownMemberId: Boolean = false): Future[JoinGroupResult] = {\n     val (responseFuture, responseCallback) = setupJoinGroupCallback\n \n+    EasyMock.expect(replicaManager.getMagic(EasyMock.anyObject())).andReturn(Some(RecordBatch.MAGIC_VALUE_V1)).anyTimes()\n+    EasyMock.replay(replicaManager)\n+\n+    groupCoordinator.handleJoinGroup(groupId, memberId, groupInstanceId,\n+      requireKnownMemberId, \"clientId\", \"clientHost\", rebalanceTimeout, sessionTimeout, protocolType, protocols, responseCallback)\n+    responseFuture\n+  }\n+\n+  private def sendStaticJoinGroupWithPersistence(groupId: String,", "originalCommit": "6b743e83192649deb56b772c1d132b7f5b701be1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjAwMTcwNA==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r506001704", "bodyText": "Yes, exactly, should I make it inline ?", "author": "feyman2016", "createdAt": "2020-10-16T02:40:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcyMTgwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU1MTY0Nw==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r506551647", "bodyText": "Hey @feyman2016 ,\nI'm still wondering if this block should be inside the callback of storeGroup. Otherwise, we would already have sent the response to the client before the storeGroup completes, and the client will never see the error response on L1058.\nOr did we specifically decide to make the storeGroup call best effort?\n(cc @abbccdda )", "author": "vvcephei", "createdAt": "2020-10-16T15:35:20Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupCoordinator.scala", "diffHunk": "@@ -1037,24 +1037,52 @@ class GroupCoordinator(val brokerId: Int,\n \n     val knownStaticMember = group.get(newMemberId)\n     group.updateMember(knownStaticMember, protocols, responseCallback)\n+    val oldProtocols = knownStaticMember.supportedProtocols\n \n     group.currentState match {\n       case Stable =>\n-        info(s\"Static member joins during Stable stage will not trigger rebalance.\")\n-        group.maybeInvokeJoinCallback(member, JoinGroupResult(\n-          members = List.empty,\n-          memberId = newMemberId,\n-          generationId = group.generationId,\n-          protocolType = group.protocolType,\n-          protocolName = group.protocolName,\n-          // We want to avoid current leader performing trivial assignment while the group\n-          // is in stable stage, because the new assignment in leader's next sync call\n-          // won't be broadcast by a stable group. This could be guaranteed by\n-          // always returning the old leader id so that the current leader won't assume itself\n-          // as a leader based on the returned message, since the new member.id won't match\n-          // returned leader id, therefore no assignment will be performed.\n-          leaderId = currentLeader,\n-          error = Errors.NONE))\n+        // check if group's selectedProtocol of next generation will change, if not, simply store group to persist the\n+        // updated static member, if yes, rebalance should be triggered to let the group's assignment and selectProtocol consistent\n+        val selectedProtocolOfNextGeneration = group.selectProtocol\n+        if (group.protocolName.contains(selectedProtocolOfNextGeneration)) {\n+          info(s\"Static member which joins during Stable stage and doesn't affect selectProtocol will not trigger rebalance.\")\n+          val groupAssignment: Map[String, Array[Byte]] = group.allMemberMetadata.map(member => member.memberId -> member.assignment).toMap\n+          groupManager.storeGroup(group, groupAssignment, error => {\n+            if (error != Errors.NONE) {\n+              warn(s\"Failed to persist metadata for group ${group.groupId}: ${error.message}\")\n+\n+              // Failed to persist member.id of the given static member, revert the update of the static member in the group.\n+              group.updateMember(knownStaticMember, oldProtocols, null)\n+              val oldMember = group.replaceGroupInstance(newMemberId, oldMemberId, groupInstanceId)\n+              completeAndScheduleNextHeartbeatExpiration(group, oldMember)\n+              responseCallback(JoinGroupResult(\n+                List.empty,\n+                memberId = JoinGroupRequest.UNKNOWN_MEMBER_ID,\n+                generationId = group.generationId,\n+                protocolType = group.protocolType,\n+                protocolName = group.protocolName,\n+                leaderId = currentLeader,\n+                error = error\n+              ))\n+            }\n+          })\n+          group.maybeInvokeJoinCallback(member, JoinGroupResult(\n+            members = List.empty,\n+            memberId = newMemberId,\n+            generationId = group.generationId,\n+            protocolType = group.protocolType,\n+            protocolName = group.protocolName,\n+            // We want to avoid current leader performing trivial assignment while the group\n+            // is in stable stage, because the new assignment in leader's next sync call\n+            // won't be broadcast by a stable group. This could be guaranteed by\n+            // always returning the old leader id so that the current leader won't assume itself\n+            // as a leader based on the returned message, since the new member.id won't match\n+            // returned leader id, therefore no assignment will be performed.\n+            leaderId = currentLeader,\n+            error = Errors.NONE))", "originalCommit": "6b743e83192649deb56b772c1d132b7f5b701be1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzM0NjMzOQ==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r507346339", "bodyText": "@vvcephei I think it make sense, will put the call of group.maybeInvokeJoinCallback in the callback, thanks!", "author": "feyman2016", "createdAt": "2020-10-19T01:59:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU1MTY0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODY2ODI4OA==", "url": "https://github.com/apache/kafka/pull/9270#discussion_r508668288", "bodyText": "@vvcephei Updated as proposed, thanks!", "author": "feyman2016", "createdAt": "2020-10-20T16:22:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU1MTY0Nw=="}], "type": "inlineReview"}, {"oid": "3c982b7dc0797370530f0c9d5c565c6a955d3d46", "url": "https://github.com/apache/kafka/commit/3c982b7dc0797370530f0c9d5c565c6a955d3d46", "message": "revise callback", "committedDate": "2020-10-20T04:25:31Z", "type": "commit"}, {"oid": "c9f358d6b8eaf14e5d5da232ba7f5ca024f0ef7a", "url": "https://github.com/apache/kafka/commit/c9f358d6b8eaf14e5d5da232ba7f5ca024f0ef7a", "message": "Merge remote-tracking branch 'apache/trunk' into KAFKA-10284", "committedDate": "2020-10-21T15:09:25Z", "type": "commit"}]}