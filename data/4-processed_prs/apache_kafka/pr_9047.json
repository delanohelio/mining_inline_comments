{"pr_number": 9047, "pr_title": "KAFKA-9274: Remove `retries` for global task", "pr_createdAt": "2020-07-21T07:21:50Z", "pr_url": "https://github.com/apache/kafka/pull/9047", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg4OTI0Mg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r457889242", "bodyText": "This is just added until the first PR is merged to unblock the work on this PR.", "author": "mjsax", "createdAt": "2020-07-21T07:22:19Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -523,6 +524,8 @@\n     public static final String STATE_DIR_CONFIG = \"state.dir\";\n     private static final String STATE_DIR_DOC = \"Directory location for state store. This path must be unique for each streams instance sharing the same underlying filesystem.\";\n \n+    public static final String TASK_TIMEOUT_MS_CONFIG = \"task.timeout.ms\";", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE3Mjk5MA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458172990", "bodyText": "Minor note: it's confusing to track down exceptions when they are re-thrown like this, because the stacktrace would only reference L223. Even though there is a small performance penalty, it's better for maintainability to always throw a new exception like new RetryableException(timeoutException).\nIn this particular case, it may be more appropriate just to remove the try-catch and add a throws declaration. There are two things that make me think this:\n\nThe log message here says, \"will retry\", but this method can have no idea whether or not it'll be retried\nThe calling method has a comment that says this method logs the error, which is also an assumption that may not survive refactoring\n\nIt seems like we can resolve all three of these maintenence problems by just moving the log message to the caller.\nThis feedback also applies elsewhere.", "author": "vvcephei", "createdAt": "2020-07-21T15:09:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -184,32 +217,21 @@ public void registerStore(final StateStore store, final StateRestoreCallback sta\n \n         log.info(\"Restoring state for global store {}\", store.name());\n         final List<TopicPartition> topicPartitions = topicPartitionsForStore(store);\n-        Map<TopicPartition, Long> highWatermarks = null;\n \n-        int attempts = 0;\n-        while (highWatermarks == null) {\n-            try {\n-                highWatermarks = globalConsumer.endOffsets(topicPartitions);\n-            } catch (final TimeoutException retryableException) {\n-                if (++attempts > retries) {\n-                    log.error(\"Failed to get end offsets for topic partitions of global store {} after {} retry attempts. \" +\n-                        \"You can increase the number of retries via configuration parameter `retries`.\",\n-                        store.name(),\n-                        retries,\n-                        retryableException);\n-                    throw new StreamsException(String.format(\"Failed to get end offsets for topic partitions of global store %s after %d retry attempts. \" +\n-                            \"You can increase the number of retries via configuration parameter `retries`.\", store.name(), retries),\n-                        retryableException);\n-                }\n-                log.debug(\"Failed to get end offsets for partitions {}, backing off for {} ms to retry (attempt {} of {})\",\n-                    topicPartitions,\n-                    retryBackoffMs,\n-                    attempts,\n-                    retries,\n-                    retryableException);\n-                Utils.sleep(retryBackoffMs);\n-            }\n+        final Map<TopicPartition, Long> highWatermarks;\n+        try {\n+            highWatermarks = globalConsumer.endOffsets(topicPartitions);\n+        } catch (final TimeoutException retryableException) {\n+            log.debug(\n+                \"Failed to get end offsets for partitions {}. The broker may be transiently unavailable at the moment. Will retry.\",\n+                topicPartitions,\n+                retryableException\n+            );\n+\n+            // handled in `GlobalStateMangerImpl#initialize()`\n+            throw retryableException;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE3MzY1MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458173651", "bodyText": "The varargs version of debug does not take a cause at the end. This exception will not be logged. You have to use the version that only takes (String, Exception).", "author": "vvcephei", "createdAt": "2020-07-21T15:10:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -184,32 +217,21 @@ public void registerStore(final StateStore store, final StateRestoreCallback sta\n \n         log.info(\"Restoring state for global store {}\", store.name());\n         final List<TopicPartition> topicPartitions = topicPartitionsForStore(store);\n-        Map<TopicPartition, Long> highWatermarks = null;\n \n-        int attempts = 0;\n-        while (highWatermarks == null) {\n-            try {\n-                highWatermarks = globalConsumer.endOffsets(topicPartitions);\n-            } catch (final TimeoutException retryableException) {\n-                if (++attempts > retries) {\n-                    log.error(\"Failed to get end offsets for topic partitions of global store {} after {} retry attempts. \" +\n-                        \"You can increase the number of retries via configuration parameter `retries`.\",\n-                        store.name(),\n-                        retries,\n-                        retryableException);\n-                    throw new StreamsException(String.format(\"Failed to get end offsets for topic partitions of global store %s after %d retry attempts. \" +\n-                            \"You can increase the number of retries via configuration parameter `retries`.\", store.name(), retries),\n-                        retryableException);\n-                }\n-                log.debug(\"Failed to get end offsets for partitions {}, backing off for {} ms to retry (attempt {} of {})\",\n-                    topicPartitions,\n-                    retryBackoffMs,\n-                    attempts,\n-                    retries,\n-                    retryableException);\n-                Utils.sleep(retryBackoffMs);\n-            }\n+        final Map<TopicPartition, Long> highWatermarks;\n+        try {\n+            highWatermarks = globalConsumer.endOffsets(topicPartitions);\n+        } catch (final TimeoutException retryableException) {\n+            log.debug(\n+                \"Failed to get end offsets for partitions {}. The broker may be transiently unavailable at the moment. Will retry.\",\n+                topicPartitions,\n+                retryableException", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE3NjU2OA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458176568", "bodyText": "Double-brace initialization is an anti-pattern. It would be preferable to use mkProperties.", "author": "vvcephei", "createdAt": "2020-07-21T15:14:48Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -613,69 +617,262 @@ public boolean lockGlobalState() throws IOException {\n     }\n \n     @Test\n-    public void shouldRetryWhenEndOffsetsThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldNotRetryWhenEndOffsetsThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<org.apache.kafka.common.TopicPartition> partitions) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        consumer.updatePartitions(t1.topic(), Collections.singletonList(new PartitionInfo(t1.topic(), t1.partition(), null, null, null)));\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n     }\n \n     @Test\n-    public void shouldRetryWhenPartitionsForThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldRetryAtLeastOnceWhenEndOffsetsThrowsTimeoutException() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized List<PartitionInfo> partitionsFor(final String topic) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        consumer.updatePartitions(t1.topic(), Collections.singletonList(new PartitionInfo(t1.topic(), t1.partition(), null, null, null)));\n+        consumer.updatePartitions(t2.topic(), Collections.singletonList(new PartitionInfo(t2.topic(), t2.partition(), null, null, null)));\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 2);\n+    }\n+\n+    @Test\n+    public void shouldRetryWhenEndOffsetsThrowsTimeoutExceptionUntilTaskTimeoutExpired() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        consumer.updatePartitions(t1.topic(), Collections.singletonList(new PartitionInfo(t1.topic(), t1.partition(), null, null, null)));\n+        consumer.updatePartitions(t2.topic(), Collections.singletonList(new PartitionInfo(t2.topic(), t2.partition(), null, null, null)));\n+        consumer.updatePartitions(t3.topic(), Collections.singletonList(new PartitionInfo(t3.topic(), t3.partition(), null, null, null)));\n+        consumer.updatePartitions(t4.topic(), Collections.singletonList(new PartitionInfo(t4.topic(), t4.partition(), null, null, null)));\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTIzMQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481231", "bodyText": "Added a couple of side fixed for the docs.", "author": "mjsax", "createdAt": "2020-07-22T01:31:09Z", "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -203,7 +203,7 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n           </tr>\n           <tr class=\"row-even\"><td>commit.interval.ms</td>\n             <td>Low</td>\n-            <td colspan=\"2\">The frequency with which to save the position (offsets in source topics) of tasks.</td>\n+            <td colspan=\"2\">The frequency in milliseconds with which to save the position (offsets in source topics) of tasks.</td>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTMxNQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481315", "bodyText": "Forgot to remove retries in the first PR.", "author": "mjsax", "createdAt": "2020-07-22T01:31:28Z", "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -308,15 +308,10 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n             <td colspan=\"2\">The replication factor for changelog topics and repartition topics created by the application.</td>\n             <td>1</td>\n           </tr>\n-          <tr class=\"row-odd\"><td>retries</td>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTM4MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481381", "bodyText": "Forgot to add the new config in the first PR", "author": "mjsax", "createdAt": "2020-07-22T01:31:40Z", "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -326,13 +321,18 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n           <tr class=\"row-even\"><td>state.cleanup.delay.ms</td>\n             <td>Low</td>\n             <td colspan=\"2\">The amount of time in milliseconds to wait before deleting state when a partition has migrated.</td>\n-            <td>600000 milliseconds</td>\n+            <td>600000 milliseconds (10 minutes)</td>\n           </tr>\n           <tr class=\"row-odd\"><td>state.dir</td>\n             <td>High</td>\n             <td colspan=\"2\">Directory location for state stores.</td>\n             <td><code class=\"docutils literal\"><span class=\"pre\">/tmp/kafka-streams</span></code></td>\n           </tr>\n+          <tr class=\"row-odd\"><td>task.timeout.ms</td>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTUyMQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481521", "bodyText": "Fixed some typos. And added reference to max.block.ms config", "author": "mjsax", "createdAt": "2020-07-22T01:32:11Z", "path": "docs/streams/upgrade-guide.html", "diffHunk": "@@ -95,11 +95,12 @@ <h3><a id=\"streams_api_changes_270\" href=\"#streams_api_changes_270\">Streams API\n     </p>\n \n     <p>\n-        The configuration parameter <code>retries</code> is deprecated in favor of a the new parameter <code>task.timeout.ms</code>.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTYyNg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481626", "bodyText": "As above.", "author": "mjsax", "createdAt": "2020-07-22T01:32:36Z", "path": "docs/upgrade.html", "diffHunk": "@@ -23,8 +23,8 @@ <h5><a id=\"upgrade_270_notable\" href=\"#upgrade_270_notable\">Notable changes in 2\n <ul>\n     <li>The configuration parameter <code>retries</code> is deprecated for the producer, admin, and Kafka Streams clients\n         via <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-572%3A+Improve+timeouts+and+retries+in+Kafka+Streams\">KIP-572</a>.\n-        You should use the producer's <code>delivery.timeout.ms</code>, admin's <code>default.api.timeout.ms</code>, and\n-        Kafka Streams' new <code>task.timeout.ms</code> parameters instead.\n+        You should use the producer's <code>delivery.timeout.ms</code> and <code>max.block.ms</code>, admin's", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTY2NQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481665", "bodyText": "Same fixes as in the docs.", "author": "mjsax", "createdAt": "2020-07-22T01:32:47Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -357,7 +357,7 @@\n     /** {@code commit.interval.ms} */\n     @SuppressWarnings(\"WeakerAccess\")\n     public static final String COMMIT_INTERVAL_MS_CONFIG = \"commit.interval.ms\";\n-    private static final String COMMIT_INTERVAL_MS_DOC = \"The frequency with which to save the position of the processor.\" +\n+    private static final String COMMIT_INTERVAL_MS_DOC = \"The frequency in milliseconds with which to save the position of the processor.\" +", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MTc5NA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458481794", "bodyText": "Added new exception type as requested.", "author": "mjsax", "createdAt": "2020-07-22T01:33:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/errors/RetryableErrorException.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.errors;\n+\n+public class RetryableErrorException extends StreamsException {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjA0NQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458482045", "bodyText": "This PR fixed 3 TODOs form the first PR. (The other two are in the test -- also added a comment to the original PR that links to this PR as reference.)", "author": "mjsax", "createdAt": "2020-07-22T01:34:16Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -58,30 +60,33 @@\n  * of Global State Stores. There is only ever 1 instance of this class per Application Instance.\n  */\n public class GlobalStateManagerImpl implements GlobalStateManager {\n+    private final static long NO_DEADLINE = -1L;\n+\n     private final Logger log;\n+    private final Time time;\n     private final Consumer<byte[], byte[]> globalConsumer;\n     private final File baseDir;\n     private final StateDirectory stateDirectory;\n     private final Set<String> globalStoreNames = new HashSet<>();\n     private final FixedOrderMap<String, Optional<StateStore>> globalStores = new FixedOrderMap<>();\n     private final StateRestoreListener stateRestoreListener;\n     private InternalProcessorContext globalProcessorContext;\n-    private final int retries;\n-    private final long retryBackoffMs;\n     private final Duration pollTime;\n+    private final long taskTimeoutMs;\n     private final Set<String> globalNonPersistentStoresTopics = new HashSet<>();\n     private final OffsetCheckpoint checkpointFile;\n     private final Map<TopicPartition, Long> checkpointFileCache;\n     private final Map<String, String> storeToChangelogTopic;\n     private final List<StateStore> globalStateStores;\n \n-    @SuppressWarnings(\"deprecation\") // TODO: remove in follow up PR when `RETRIES` is removed", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjQwOA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458482408", "bodyText": "Second TODO", "author": "mjsax", "createdAt": "2020-07-22T01:35:21Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -612,72 +617,521 @@ public boolean lockGlobalState() throws IOException {\n         }\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjgwMw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458482803", "bodyText": "If we rethrow, we get rid of the RetryableErrorException and pass in the original root cause, ie, the TimeoutException.", "author": "mjsax", "createdAt": "2020-07-22T01:36:54Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -131,11 +135,40 @@ public void setGlobalProcessorContext(final InternalProcessorContext globalProce\n         }\n \n         final Set<String> changelogTopics = new HashSet<>();\n-        for (final StateStore stateStore : globalStateStores) {\n+\n+        long deadlineMs = NO_DEADLINE;\n+        final List<StateStore> storesToInitialize = new LinkedList<>(globalStateStores);\n+\n+        while (!storesToInitialize.isEmpty()) {\n+            // we remove and add back on failure to round-robin through all stores\n+            final StateStore stateStore = storesToInitialize.remove(0);\n             globalStoreNames.add(stateStore.name());\n             final String sourceTopic = storeToChangelogTopic.get(stateStore.name());\n             changelogTopics.add(sourceTopic);\n-            stateStore.init(globalProcessorContext, stateStore);\n+\n+            try {\n+                stateStore.init(globalProcessorContext, stateStore);\n+                deadlineMs = NO_DEADLINE;\n+            } catch (final RetryableErrorException retryableException) {\n+                if (taskTimeoutMs == 0L) {\n+                    throw new StreamsException(retryableException.getCause());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTcyMzg1OQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459723859", "bodyText": "Why not just preserve the whole story of what happened, like throw new StreamsException(\"Couldn't retry because timeout is set to zero\", retryableException)?", "author": "vvcephei", "createdAt": "2020-07-23T20:57:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjgwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc4ODE3Ng==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459788176", "bodyText": "Ack", "author": "mjsax", "createdAt": "2020-07-23T23:46:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MjgwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4Mjg0Ng==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458482846", "bodyText": "Third TODO", "author": "mjsax", "createdAt": "2020-07-22T01:37:05Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -612,72 +617,521 @@ public boolean lockGlobalState() throws IOException {\n         }\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenEndOffsetsThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldNotRetryWhenEndOffsetsThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<org.apache.kafka.common.TopicPartition> partitions) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MzAyMw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458483023", "bodyText": "This test is new (also added it for partitionFor() case).", "author": "mjsax", "createdAt": "2020-07-22T01:37:46Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -612,72 +617,521 @@ public boolean lockGlobalState() throws IOException {\n         }\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenEndOffsetsThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldNotRetryWhenEndOffsetsThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<org.apache.kafka.common.TopicPartition> partitions) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenPartitionsForThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldRetryAtLeastOnceWhenEndOffsetsThrowsTimeoutException() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized List<PartitionInfo> partitionsFor(final String topic) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 2);\n+    }\n+\n+    @Test\n+    public void shouldRetryWhenEndOffsetsThrowsTimeoutExceptionUntilTaskTimeoutExpired() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1000L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 1100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 12);\n+    }\n+\n+    @Test\n+    public void shouldNotFailOnSlowProgressWhenEndOffsetsThrowsTimeoutException() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ4MzI1OQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458483259", "bodyText": "Replicated the tests from above (endOffset and partitionFor) for the position call.", "author": "mjsax", "createdAt": "2020-07-22T01:38:42Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -612,72 +617,521 @@ public boolean lockGlobalState() throws IOException {\n         }\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenEndOffsetsThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldNotRetryWhenEndOffsetsThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<org.apache.kafka.common.TopicPartition> partitions) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     @Test\n-    public void shouldRetryWhenPartitionsForThrowsTimeoutException() {\n-        final int retries = 2;\n+    public void shouldRetryAtLeastOnceWhenEndOffsetsThrowsTimeoutException() {\n         final AtomicInteger numberOfCalls = new AtomicInteger(0);\n         consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n             @Override\n-            public synchronized List<PartitionInfo> partitionsFor(final String topic) {\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n                 numberOfCalls.incrementAndGet();\n-                throw new TimeoutException();\n+                throw new TimeoutException(\"KABOOM!\");\n             }\n         };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n         streamsConfig = new StreamsConfig(new Properties() {\n             {\n                 put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n                 put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n                 put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n-                put(StreamsConfig.RETRIES_CONFIG, retries);\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n             }\n         });\n \n-        try {\n-            new GlobalStateManagerImpl(\n-                new LogContext(\"mock\"),\n-                topology,\n-                consumer,\n-                stateDirectory,\n-                stateRestoreListener,\n-                streamsConfig);\n-        } catch (final StreamsException expected) {\n-            assertEquals(numberOfCalls.get(), retries);\n-        }\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 2);\n+    }\n+\n+    @Test\n+    public void shouldRetryWhenEndOffsetsThrowsTimeoutExceptionUntilTaskTimeoutExpired() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1000L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 1100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 12);\n+    }\n+\n+    @Test\n+    public void shouldNotFailOnSlowProgressWhenEndOffsetsThrowsTimeoutException() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public synchronized Map<TopicPartition, Long> endOffsets(final Collection<TopicPartition> partitions) {\n+                time.sleep(1L);\n+                if (numberOfCalls.incrementAndGet() % 3 == 0) {\n+                    return super.endOffsets(partitions);\n+                }\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+\n+            @Override\n+            public synchronized long position(final TopicPartition partition) {\n+                return numberOfCalls.incrementAndGet();\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        stateManager.initialize();\n+    }\n+\n+    @Test\n+    public void shouldNotRetryWhenPartitionsForThrowsTimeoutExceptionAndTaskTimeoutIsZero() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public List<PartitionInfo> partitionsFor(final String topic) {\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 0L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final StreamsException expected = assertThrows(\n+            StreamsException.class,\n+            () -> stateManager.initialize()\n+        );\n+        final Throwable cause = expected.getCause();\n+        assertThat(cause, instanceOf(TimeoutException.class));\n+        assertThat(cause.getMessage(), equalTo(\"KABOOM!\"));\n+\n+        assertEquals(numberOfCalls.get(), 1);\n+    }\n+\n+    @Test\n+    public void shouldRetryAtLeastOnceWhenPartitionsForThrowsTimeoutException() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public List<PartitionInfo> partitionsFor(final String topic) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 2);\n+    }\n+\n+    @Test\n+    public void shouldRetryWhenPartitionsForThrowsTimeoutExceptionUntilTaskTimeoutExpires() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public List<PartitionInfo> partitionsFor(final String topic) {\n+                time.sleep(100L);\n+                numberOfCalls.incrementAndGet();\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1000L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        final TimeoutException expected = assertThrows(\n+            TimeoutException.class,\n+            () -> stateManager.initialize()\n+        );\n+        assertThat(expected.getMessage(), equalTo(\"Global task did not make progress to restore state within 1100 ms. Adjust `task.timeout.ms` if needed.\"));\n+\n+        assertEquals(numberOfCalls.get(), 12);\n+    }\n+\n+    @Test\n+    public void shouldNotFailOnSlowProgressWhenPartitionForThrowsTimeoutException() {\n+        final AtomicInteger numberOfCalls = new AtomicInteger(0);\n+        consumer = new MockConsumer<byte[], byte[]>(OffsetResetStrategy.EARLIEST) {\n+            @Override\n+            public List<PartitionInfo> partitionsFor(final String topic) {\n+                time.sleep(1L);\n+                if (numberOfCalls.incrementAndGet() % 3 == 0) {\n+                    return super.partitionsFor(topic);\n+                }\n+                throw new TimeoutException(\"KABOOM!\");\n+            }\n+\n+            @Override\n+            public synchronized long position(final TopicPartition partition) {\n+                return numberOfCalls.incrementAndGet();\n+            }\n+        };\n+        initializeConsumer(0, 0, t1, t2, t3, t4);\n+\n+        streamsConfig = new StreamsConfig(new Properties() {\n+            {\n+                put(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\");\n+                put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\");\n+                put(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath());\n+                put(StreamsConfig.TASK_TIMEOUT_MS_CONFIG, 1L);\n+            }\n+        });\n+\n+        stateManager = new GlobalStateManagerImpl(\n+            new LogContext(\"mock\"),\n+            time,\n+            topology,\n+            consumer,\n+            stateDirectory,\n+            stateRestoreListener,\n+            streamsConfig\n+        );\n+        processorContext.setStateManger(stateManager);\n+        stateManager.setGlobalProcessorContext(processorContext);\n+\n+        stateManager.initialize();\n+    }\n+\n+    @Test\n+    public void shouldNotRetryWhenPositionThrowsTimeoutExceptionAndTaskTimeoutIsZero() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2NTc5OQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r458965799", "bodyText": "@vvcephei I actually had a follow up thought: given that we fetch data for a single partition only, should we trigger a timeout within this loop if records is empty (ie, poll() did not return anything)? Otherwise, this restore loop might \"hang\" forever if we lose the connection to the broker -- IMHO, task.timeout.msshould cover this case? Otherwise, we block on startup as the initial global store loading would never finish and we don't even start the actualStreamThreads`.", "author": "mjsax", "createdAt": "2020-07-22T17:35:21Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately\n+\n+                        // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                        throw new IllegalStateException(error);\n+                    }\n+\n                     stateRestoreAdapter.restoreBatch(restoreRecords);\n                     stateRestoreListener.onBatchRestored(topicPartition, storeName, offset, restoreRecords.size());\n                     restoreCount += restoreRecords.size();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MzI5Ng==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459763296", "bodyText": "Huh, interesting thought. Just to be clear, it looks like it would already block forever in this case today, right?\nYeah, it does seem like we should implement a similar non-progress timeout for this loop in that case.", "author": "vvcephei", "createdAt": "2020-07-23T22:29:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2NTc5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MTc0MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459791741", "bodyText": "Yes, it would block forever today. Curious to hear what @guozhangwang thinks.", "author": "mjsax", "createdAt": "2020-07-23T23:59:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2NTc5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5OTcwOA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459799708", "bodyText": "My understanding is that for non-global state stores, we would also start ticking if we cannot make progress either due to exceptions or poll() returned no data, is that right? If yes, I'm +1 on covering the same for global state store here.", "author": "guozhangwang", "createdAt": "2020-07-24T00:31:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk2NTc5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1ODA5MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459758091", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            log.debug(retryableException.getMessage() + \" Will retry. Remaining time in milliseconds: {}\", deadlineMs - currentWallClockMs);\n          \n          \n            \n                            log.debug(String.format(\"Got an exception in store.init(). Will retry. Remaining time in milliseconds: %d\",  deadlineMs - currentWallClockMs), retryableException);\n          \n      \n    \n    \n  \n\nSorry, my prior feedback was ambiguous. This is what I meant.", "author": "vvcephei", "createdAt": "2020-07-23T22:15:01Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -131,11 +135,40 @@ public void setGlobalProcessorContext(final InternalProcessorContext globalProce\n         }\n \n         final Set<String> changelogTopics = new HashSet<>();\n-        for (final StateStore stateStore : globalStateStores) {\n+\n+        long deadlineMs = NO_DEADLINE;\n+        final List<StateStore> storesToInitialize = new LinkedList<>(globalStateStores);\n+\n+        while (!storesToInitialize.isEmpty()) {\n+            // we remove and add back on failure to round-robin through all stores\n+            final StateStore stateStore = storesToInitialize.remove(0);\n             globalStoreNames.add(stateStore.name());\n             final String sourceTopic = storeToChangelogTopic.get(stateStore.name());\n             changelogTopics.add(sourceTopic);\n-            stateStore.init(globalProcessorContext, stateStore);\n+\n+            try {\n+                stateStore.init(globalProcessorContext, stateStore);\n+                deadlineMs = NO_DEADLINE;\n+            } catch (final RetryableErrorException retryableException) {\n+                if (taskTimeoutMs == 0L) {\n+                    throw new StreamsException(retryableException.getCause());\n+                }\n+\n+                storesToInitialize.add(stateStore);\n+\n+                final long currentWallClockMs = time.milliseconds();\n+                if (deadlineMs == NO_DEADLINE) {\n+                    final long newDeadlineMs = currentWallClockMs + taskTimeoutMs;\n+                    deadlineMs = newDeadlineMs < 0L ? Long.MAX_VALUE : newDeadlineMs;\n+                } else if (currentWallClockMs > deadlineMs) {\n+                    throw new TimeoutException(String.format(\n+                        \"Global task did not make progress to restore state within %d ms. Adjust `task.timeout.ms` if needed.\",\n+                        currentWallClockMs - deadlineMs + taskTimeoutMs\n+                    ));\n+                }\n+\n+                log.debug(retryableException.getMessage() + \" Will retry. Remaining time in milliseconds: {}\", deadlineMs - currentWallClockMs);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MDEwMw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459790103", "bodyText": "I understood what you meant, but I thought that because we actual do retry, it's better/cleaner/less-noisy to not log the full stack trace?", "author": "mjsax", "createdAt": "2020-07-23T23:53:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1ODA5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgyNzY1Mw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459827653", "bodyText": "Ah, good, at least it wasn't lack of clarity. It's your call. I've wasted quite a bit of time trying to track down root causes of things specifically because of stuff like this. It really doesn't seem like saving ten log lines is worth the extra hassle.\nI'm not saying it's \"bad\" the way you proposed. But it is unusual, and unusual code is more often than not a bummer in the long run. Exceptions in java take a \"cause\" for a reason, and they print the stacktraces of those causes in a well understood order and format that integrates well with all kinds of tools from IDEs to analytics and log aggregation. I agree that the stacktrace isn't that useful in this case. Still, specifically breaking this whole ecosystem because we don't think the stacktrace is likely useful seems a poor tradeoff.", "author": "vvcephei", "createdAt": "2020-07-24T02:44:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1ODA5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459762036", "bodyText": "I think this makes sense, but it seems to make some assumptions about the internal implementation of the consumer that doesn't seem necessary here. Is it important to assert that the consumer can't possibly get a timeout exception here?", "author": "vvcephei", "createdAt": "2020-07-23T22:25:39Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MTM3MA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459791370", "bodyText": "I guess strictly speaking, it's not necessary, but I personally prefer this strict style as it surfaces bugs quicker. If we write \"robust\" code, it could hide a bug. -- It's just a personal preference and we have similar code elsewhere. If you feel very strong about it, I am also ok to change it.", "author": "mjsax", "createdAt": "2020-07-23T23:58:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgyNzk1Mg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459827952", "bodyText": "Thanks; yes, this is a very good habit. In this specific case, I wasn't sure what the \"bug\" would be, though. Just that the implementation of the consumer does something different, but equally correct, from our current understanding of how it works?", "author": "vvcephei", "createdAt": "2020-07-24T02:46:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgzNzMxNw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459837317", "bodyText": "The bug would be in the consumer: it forgets its position and needs to fetch it from the broker again (of course, we would only expose this bug, if there is also a broker/network issue and the request actually times out... what makes it a rather weak \"check\").", "author": "mjsax", "createdAt": "2020-07-24T03:36:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5Mjk3Nw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459892977", "bodyText": "We don't need to call retryUntilSuccessOrThrowOnTaskTimeout now, so we actually get cleaner code :)", "author": "mjsax", "createdAt": "2020-07-24T07:28:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzMTYxNw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460231617", "bodyText": "If we do have a valid position from previous position call, do we still need to update the position here again?", "author": "abbccdda", "createdAt": "2020-07-24T18:54:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5MDU0OA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460290548", "bodyText": "It seems like what we're doing here is syncing our offset variable with the internal position cursor of the client. Although @mjsax is claiming the client never needs to update its position from the consumer group, the position would advance as a consequence of polling records earlier in this loop. Right?", "author": "vvcephei", "createdAt": "2020-07-24T21:12:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI5MTQ5NQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460291495", "bodyText": "Hey @mjsax , it sounds like you have an opinion about what would be unexpected internal behavior of the client, based on your knowledge of how it is currently implemented. There doesn't seem to be anything in the contract of the client that says we should rely on this implementation detail, so it seems inappropriate to build in a fatal exception for this case.", "author": "vvcephei", "createdAt": "2020-07-24T21:15:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwODYwMQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460308601", "bodyText": "What John says: We need to track the restore progress to eventually break the outer while loop. We don't use offset to seek(), so it's not about updating the consumer's position but knowing when we are done.", "author": "mjsax", "createdAt": "2020-07-24T22:08:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMDUwNg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460320506", "bodyText": "I guess with the new retryUntilSuccessOrThrowOnTaskTimeout the code is still clean is we just use it here, too.", "author": "mjsax", "createdAt": "2020-07-24T22:52:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjAzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjI3OQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459762279", "bodyText": "I can't comment above, but can the poll call itself throw a timeout exception? Or does it always just return no results in that case?", "author": "vvcephei", "createdAt": "2020-07-23T22:26:14Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -299,7 +318,17 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MDMyMw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459790323", "bodyText": "I can't comment above, but can the poll call itself throw a timeout exception?\n\nNo, it cannot. It would just return an empty result.", "author": "mjsax", "createdAt": "2020-07-23T23:54:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjI3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgyNzk5Nw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459827997", "bodyText": "Thanks!", "author": "vvcephei", "createdAt": "2020-07-24T02:46:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjI3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459890602", "bodyText": "Moved this class into ClientUtils.java", "author": "mjsax", "createdAt": "2020-07-24T07:22:24Z", "path": "streams/src/main/java/org/apache/kafka/streams/internals/QuietStreamsConfig.java", "diffHunk": "@@ -1,33 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.streams.internals;\n-\n-import org.apache.kafka.streams.StreamsConfig;\n-\n-import java.util.Map;\n-\n-/**\n- * A {@link StreamsConfig} that does not log its configuration on construction.\n- *\n- * This producer cleaner output for unit tests using the {@code test-utils},\n- * since logging the config is not really valuable in this context.\n- */\n-public class QuietStreamsConfig extends StreamsConfig {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NzkzNA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460167934", "bodyText": "What's the purpose for this move?", "author": "abbccdda", "createdAt": "2020-07-24T16:43:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwMzIwMw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460303203", "bodyText": "I guessing because there are other \"quiet\" configs there. On the other hand, the \"quiet Streams config\" isn't really a \"client util\"...", "author": "vvcephei", "createdAt": "2020-07-24T21:50:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwNDMyNA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460304324", "bodyText": "Well, KafkaStreams is the \"streams client\" IMHO :)", "author": "mjsax", "createdAt": "2020-07-24T21:53:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMzODc0Nw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460338747", "bodyText": "Haha, that's kind of a stretch, but it's not a big deal :)", "author": "vvcephei", "createdAt": "2020-07-25T00:22:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTQ1NA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460341454", "bodyText": "Is it? KIP-28 suggest to add Kafka Streams -- a processor client :D\nhttps://cwiki.apache.org/confluence/display/KAFKA/KIP-28+-+Add+a+processor+client", "author": "mjsax", "createdAt": "2020-07-25T00:40:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MDYwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MTc2Mg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459891762", "bodyText": "Some side improvement: if we seek base on the checkpoint, there is no reason to call position() because we know what our offset is. -- Only if we seekToBeginning() we need to get the current offset from the consumer itself (instead of position() we could also call beginningOffsets but position it the easer to use API.", "author": "mjsax", "createdAt": "2020-07-24T07:25:18Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r459892544", "bodyText": "For poll(), even if retrying is disabled, we need to retry to give a fetch request (with default request timeout of 30 seconds but only a default pollTime of 100ms) a fair change to actually return.\nAt least I believe this makes sense. Also \\cc @guozhangwang", "author": "mjsax", "createdAt": "2020-07-24T07:27:22Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                final AtomicLong position = new AtomicLong();\n+                retryUntilSuccessOrThrowOnTaskTimeout(\n+                    () -> position.set(globalConsumer.position(topicPartition)),\n+                    String.format(\n+                        \"Failed to get position for partition %s. The broker may be transiently unavailable at the moment.\",\n+                        topicPartition\n+                    )\n+                );\n+                offset = position.get();\n             }\n \n-            long offset = globalConsumer.position(topicPartition);\n             final Long highWatermark = highWatermarks.get(topicPartition);\n             final RecordBatchingStateRestoreCallback stateRestoreAdapter =\n                 StateRestoreCallbackAdapter.adapt(stateRestoreCallback);\n \n             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);\n             long restoreCount = 0L;\n \n+            long deadlineMs = NO_DEADLINE;\n             while (offset < highWatermark) {\n                 try {\n                     final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+                    if (records.isEmpty()) {\n+                        if (taskTimeoutMs == 0L) {\n+                            deadlineMs = maybeUpdateDeadlineOrThrow(", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI4Nzk5MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460287991", "bodyText": "Man, this is confusing. I think I see what you're getting at, but it seems pretty strange to have to go to all that trouble to extract the consumer config so that we can apply a shorter timeout on each poll, but then loop around until the originally configured client timeout passes.\nCan you explain how the outcome is different than just calling globalConsumer.poll(requestTimeoutMs)?\nIt also seems strange to extract a consumer timeout configuration that specifically does not apply to poll and apply it to poll. This seems like it would violate users' expectations when they set that configuration value.\nWhy wouldn't we instead apply the non-progress timeout (taskTimeoutMs), since it seems like that's exactly what it's for? I.e., it seems like globalConsumer.poll(pollTime + taskTimeoutMs) might be the most appropriate choice here?", "author": "vvcephei", "createdAt": "2020-07-24T21:05:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwNzA4Mw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460307083", "bodyText": "Can you explain how the outcome is different than just calling globalConsumer.poll(requestTimeoutMs)?\n\nI did consider it, but was not 100% sure if this might be better. Was also concerned about \"miss using\" request timeout (as you already mentioned) as we have StreamsConfig.POLL_TIMEOUT_MS.\nI like the proposal to use pollTime + taskTimeoutMs though!", "author": "mjsax", "createdAt": "2020-07-24T22:03:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMxOTc0Mg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460319742", "bodyText": "Actually, we need to use all three: pollTime + requestTimeout + taskTimeoutMs\nIf we don't include requestTimeout and taskTimeoutMs is set to 0 (or a smaller value than requestTimeout in general), the first poll() would return no data with very high probability and we would fail what seems not desirable.", "author": "mjsax", "createdAt": "2020-07-24T22:49:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyNDU5MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460324591", "bodyText": "Btw: just for completeness: we will still use pollTime unmodified in globalConsumer.poll(...) during regular processing, so the config has still value. Only in the startup bootstrapping phase, we would use the sum of poll/request/task-timeout to not fail unnecessarily.\nAlso note that during normal processing, we don't apply taskTimeoutMs atm. Not sure if we should, but I would not want to include it in this PR. -- It won't block the \"main\" processing if the global poll() loop would not make progress because the StreamThreads are already running, and thus it's impact is different -- also, during normal processing the global highWatermark may move and thus we need a different strategy anyway compared to the bootstrap phase.", "author": "mjsax", "createdAt": "2020-07-24T23:09:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMzODQxNA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460338414", "bodyText": "Ah, that last point sounds good.\nI'm not opposed, but it still seems strange to grab a random timeout from the client config and apply it to the poll method. It kind of makes me wonder what we're really trying to do here. If we want to give poll at least 30 seconds to return data, then we can just give it at least 30 seconds, right? No reason to abuse the client configuration.\nOn the other hand, the pollTime may not even appropriate for the global thread, right? It seems more like it was meant for StreamThread to make sure we don't block too long and violate the max poll interval. But since the global thread is only assigned and not subscribed, it has no constraint on how long it should block, except for the taskTimeoutMs config, right?\nClearly, we need to set some kind of lower bound on it, though, but it's not clear that it needs to be configurable. Anyway, just food for thought. Feel free to keep the requestTimeout if you really think it's appropriate.", "author": "vvcephei", "createdAt": "2020-07-25T00:20:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTE4Ng==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460341186", "bodyText": "Well, the requestTimeout is no really \"random\" -- if we send a fetch request, it's the maximum time until the producer would abort the request and retry. -- If poll() would throw a TimeoutException, this would be the point when we get a timeout if there are no retries. -- To be fair, maybe using the consumer's default_api_timeout_ms config might be better than using requestTimeout though? -- The point being is, that picking a consumer config seems to be the best thing we can do for this case instead of a hard-coded number (or introducing a new config for this specific corner case).\n\npollTime may not even appropriate for the global thread\n\nI think it does (even if differently). At least for regular processing: (1) we interleave polling and flushing, and also when we stop the client, we want it to responsive and not being blocked in poll() for 5 minutes (taskTimeoutMs default) for this case. (What of course implies that one cannot really \"intercept\" the startup phase atm -- something we might want to address, but maybe not in this PR.)\n\nClearly, we need to set some kind of lower bound on it, though, but it's not clear that it needs to be configurable.\n\nI think the worst we can do is to make it not configurable. :)", "author": "mjsax", "createdAt": "2020-07-25T00:39:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQwNDc0MA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460404740", "bodyText": "Thanks, @mjsax , that's fair.\nI promise I'm not equivocating here; I'm just trying to figure out what my intuition is trying to tell me.\nIt seems like maybe the fundamental problem here is that we can't distinguish among a successful poll that returns no data, a failure to poll, and a pending async fetch request. The one thing we know is that the end offset is beyond our current position, so there should be data to poll, so we can assume that an empty return means either that the fetch failed internally or it hasn't completed yet.\nStepping back, this seems to be related to the problem of task idling, in which it's pointless to \"idle\" for a time so short that we have no chance to actually get a response back from the broker.\nI feel like this is substantially my fault from #4855 / KIP-266. The purpose of making this API completely async was to avoid harming liveness in situations where we might have a relatively strict deadline. But that's not the case here.\nI guess the \"poor man's\" solution we're going for here is to block poll for at least long enough to allow for a complete fetch round-trip from the broker. If we know that there was a round-trip, and we didn't get any data, then we can conclude that there was an error (since we know there is data to get). Since we can't know that there was a round trip, we weaken the condition to: if we know it's been long enough that there should have been a round-trip and we don't get data, we conclude there was probably an error.\nIn your KIP, we specified we would start the task timer after the first error, so it seems like we really want to just block the poll for the round-trip time, and then apply your \"update deadline, etc.\" function. I'm with you now that to get the round-trip time, we have to extract some config(s) from the Consumer. This is a pretty awkward hack, but now that I've thought it through, it seems the best we can do. Maybe we can mull it over and file an improvement jira for the Consumer to improve use cases like this.\nAnyway, it seems like the \"poll time\" config is irrelevant, we just need to know what config to grab that corresponds to completing a fetch request with high probability. It seems like we shouldn't need to update metadata, so we would send a fetch request on the first poll call, and we just need to block for whatever time bounds the fetch response time.\nI'm honestly not sure what timeout would be best here. It looks like the ConsumerNetworkClient will just wait for a response until it gets a \"disconnect\" (L598). Is that a socket timeout? I'm not sure.", "author": "vvcephei", "createdAt": "2020-07-25T13:23:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQ0OTkwMQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460449901", "bodyText": "I agree. The \"issue\" is really that poll() does not throw a TimeoutException... Also, because we do manual assignment, poll() would never return \"early\" as it never need to wait for joining a consumer group. -- However, compare to max.task.idle.ms, we are in a better situation here, because we poll() for only a single partition at a time.\nI also agree, that applying task.timeout.ms should start after we got a first timeout -- this was how the original code worked that you criticized as:\n\nMan, this is confusing.\n\nAnd I agree, that the code was not straightforward to understand. But if we think it's the right thing to do, I am also happy to add it back :)\nI am also not an expert on all consumer internals, but from my understanding, fetch requests are send async in general, and if a fetch request fails, the consumer would actually not retry it but a retry would be triggered by the next poll() call. If there is no data available (ie, fetch request did not return yet) when poll() is called, the consumer would block internally until poll(Duration) timeout expires or until a fetch request returns (whatever comes first).\nFurthermore, before poll() returns, it always check if a fetch request is in-flight or not, and sends one if not.\nThus, on the verify first call to poll() we know that no fetch request can be in-flight and we also know that poll() would send one, and block until it returns or poll(Duration) expires. Thus, if poll() does not block for at least request.timeout.ms, and we get an empty result back we don't know which case holds, however, if we use the request timeout, it seems that we know if the fetch was successful or did time out? We also know, that a fetch request will be inflight after poll() returns. Thus, for any consecutive poll() applying request timeout also ensures that we know if the request was successful or not.\nI guess the only difference to what I just described to my original code was, that I uses pollTime + requestTimeout.\nBottom line: I am not 100% sure what you propose? Should we go with the original design? Or with the new design? -- In the end, I think we don't need a follow up PR, and we can just try to get it right in this PR. I don't see any benefit in splitting it up into 2 PRs (because, as mentioned above, we fetch for a single partitions and thus it's a different case compared to max.task.idle.ms scenario).", "author": "mjsax", "createdAt": "2020-07-25T21:48:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE0Mzk2MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r461143961", "bodyText": "Ok, thanks @mjsax . I just traced though the consumer code again, and have finally been able to see what you already knew: that request.timeout.ms is indeed the correct amount of time to wait.\nNamely, we send a fetch here: https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/KafkaConsumer.java#L1285\nWhich calls through to client.send here: \n  \n    \n      kafka/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java\n    \n    \n         Line 263\n      in\n      659ca8f\n    \n    \n    \n    \n\n        \n          \n           RequestFuture<ClientResponse> future = client.send(fetchTarget, request); \n        \n    \n  \n\n\nWhich fills in the request.timeout.ms config value here: \n  \n    \n      kafka/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerNetworkClient.java\n    \n    \n         Line 106\n      in\n      659ca8f\n    \n    \n    \n    \n\n        \n          \n           return send(node, requestBuilder, requestTimeoutMs); \n        \n    \n  \n\n\nWhich uses it to construct a ClientRequest here: \n  \n    \n      kafka/clients/src/main/java/org/apache/kafka/clients/consumer/internals/ConsumerNetworkClient.java\n    \n    \n        Lines 129 to 130\n      in\n      659ca8f\n    \n    \n    \n    \n\n        \n          \n           ClientRequest clientRequest = client.newClientRequest(node.idString(), requestBuilder, now, true, \n        \n\n        \n          \n                   requestTimeoutMs, completionHandler); \n        \n    \n  \n\n\nWhich then gets used to create an InFlightRequest when it gets sent here: \n  \n    \n      kafka/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java\n    \n    \n         Line 1248\n      in\n      659ca8f\n    \n    \n    \n    \n\n        \n          \n           clientRequest.requestTimeoutMs(), \n        \n    \n  \n\n\nWhich is later used to detect expired requests here: \n  \n    \n      kafka/clients/src/main/java/org/apache/kafka/clients/InFlightRequests.java\n    \n    \n         Line 162\n      in\n      659ca8f\n    \n    \n    \n    \n\n        \n          \n           if (timeSinceSend > request.requestTimeoutMs) \n        \n    \n  \n\n\nWhich is used to list nodes (brokers) for which there is an expired request here: \n  \n    \n      kafka/clients/src/main/java/org/apache/kafka/clients/InFlightRequests.java\n    \n    \n         Line 179\n      in\n      659ca8f\n    \n    \n    \n    \n\n        \n          \n           if (hasExpiredRequest(now, deque)) \n        \n    \n  \n\n\nWhich is then processed as a \"disconnection\" here: \n  \n    \n      kafka/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java\n    \n    \n         Line 803\n      in\n      659ca8f\n    \n    \n    \n    \n\n        \n          \n           processDisconnection(responses, nodeId, now, ChannelState.LOCAL_CLOSE); \n        \n    \n  \n\n\nIt also looks like the KafkaClient just does a tight-loop checking for a network response, so we don't really need any extra time to account for sampling errors. Also, it still seems like using the sum as the poll duration is just as good as using your retry logic, so I think the duration parameter is fine.\nMy only remaining question, which maybe doesn't really matter one way or another, is whether poll.ms really belongs here or not. It seems like the desired semantics are accomplished by just waiting request.timeout.ms for the initial failure, and then an extra task.timeout.ms for any retries.", "author": "vvcephei", "createdAt": "2020-07-27T20:17:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMwMjYyNQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r461302625", "bodyText": "Thanks for digging into it @vvcephei -- The question about pollTimeout is fair. I guess for default configs it might not matter much, as the default is 100ms IIRC.\nAt the same time, we apply the same pollTimeout during regular processing, and as a matter of fact, for this case, a use might want to use a longer poll-timeout, as otherwise, the thread would just \"busy wait\" anyway (only the responsiveness for a shutdown of the app should be considered).\nThus, it might actually make sense to exclude pollTimeout completely and only use requestTimeout + taskTimeout. Again, using taskTimeout in poll() reduces the responsiveness of a shutdown -- however, atm during bootstrapping we ignore a shutdown signal anyway, hence, for now we don't make the situation worse. I create a ticket to fix this: https://issues.apache.org/jira/browse/KAFKA-10317 and will add a comment for now.\nShort related note: actually using requestTimeout seems to be a conservative upper bound for poll(). A request could fail with a different error before requestTimeout hits and would be retried internally for this case -- if this happens, we might want to start the taskTimeout earlier. However, we don't have any means atm to detect this case. Thus, using requestTimeout is the best option we have right now (because triggering taskTimeout too early seems to be worse than triggering it too late). I created a ticket though that might allow us to improve the code later: https://issues.apache.org/jira/browse/KAFKA-10315", "author": "mjsax", "createdAt": "2020-07-28T03:56:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg5MjU0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NTYwMQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460165601", "bodyText": "nit: for a doc clean-up, it is helpful to include a screenshot of updated paragraph. The changes starting at L331 should be suffice.", "author": "abbccdda", "createdAt": "2020-07-24T16:39:43Z", "path": "docs/streams/developer-guide/config-streams.html", "diffHunk": "@@ -326,13 +321,18 @@ <h4><a class=\"toc-backref\" href=\"#id5\">bootstrap.servers</a><a class=\"headerlink\n           <tr class=\"row-even\"><td>state.cleanup.delay.ms</td>\n             <td>Low</td>\n             <td colspan=\"2\">The amount of time in milliseconds to wait before deleting state when a partition has migrated.</td>\n-            <td>600000 milliseconds</td>\n+            <td>600000 milliseconds (10 minutes)</td>\n           </tr>\n           <tr class=\"row-odd\"><td>state.dir</td>\n             <td>High</td>\n             <td colspan=\"2\">Directory location for state stores.</td>\n             <td><code class=\"docutils literal\"><span class=\"pre\">/tmp/kafka-streams</span></code></td>\n           </tr>\n+          <tr class=\"row-odd\"><td>task.timeout.ms</td>\n+            <td>Medium</td>", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc4NjM4Ng==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r461786386", "bodyText": "@mjsax could we do a screenshot to make sure it looks good on the web-page?", "author": "abbccdda", "createdAt": "2020-07-28T18:28:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NTYwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIxNTQ4Nw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r465215487", "bodyText": "Done.\n@guozhangwang @abbccdda -- I am just wondering if we should mark to parameter with priority \"Low\" though?", "author": "mjsax", "createdAt": "2020-08-04T17:32:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NTYwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTkyMzc2OQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r465923769", "bodyText": "\"medium\" looks fine to me. But I'm not feeling strong against it either.", "author": "guozhangwang", "createdAt": "2020-08-05T18:32:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2NTYwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE2OTcxNg==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460169716", "bodyText": "retriableException to be consistent with the defined exception type in AK.", "author": "abbccdda", "createdAt": "2020-07-24T16:47:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -318,6 +341,72 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n         }\n     }\n \n+    private void retryUntilSuccessOrThrowOnTaskTimeout(final Runnable runnable,\n+                                                       final String errorMessage) {\n+        long deadlineMs = NO_DEADLINE;\n+\n+        do {\n+            try {\n+                runnable.run();\n+                return;\n+            } catch (final TimeoutException retryableException) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDE3MDg2OA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460170868", "bodyText": "Should we log warning here instead? At least this is a timeout.", "author": "abbccdda", "createdAt": "2020-07-24T16:49:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -318,6 +341,72 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n         }\n     }\n \n+    private void retryUntilSuccessOrThrowOnTaskTimeout(final Runnable runnable,\n+                                                       final String errorMessage) {\n+        long deadlineMs = NO_DEADLINE;\n+\n+        do {\n+            try {\n+                runnable.run();\n+                return;\n+            } catch (final TimeoutException retryableException) {\n+                if (taskTimeoutMs == 0L) {\n+                    throw new StreamsException(\n+                        String.format(\n+                            \"Retrying is disabled. You can enable it by setting `%s` to a value larger than zero.\",\n+                            StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n+                        ),\n+                        retryableException\n+                    );\n+                }\n+\n+                deadlineMs = maybeUpdateDeadlineOrThrow(deadlineMs);\n+\n+                log.debug(errorMessage, retryableException);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzMTg1MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460231851", "bodyText": "We should add some explanation in the illegal state exception for why such timeout is fatal", "author": "abbccdda", "createdAt": "2020-07-24T18:54:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                final AtomicLong position = new AtomicLong();\n+                retryUntilSuccessOrThrowOnTaskTimeout(\n+                    () -> position.set(globalConsumer.position(topicPartition)),\n+                    String.format(\n+                        \"Failed to get position for partition %s. The broker may be transiently unavailable at the moment.\",\n+                        topicPartition\n+                    )\n+                );\n+                offset = position.get();\n             }\n \n-            long offset = globalConsumer.position(topicPartition);\n             final Long highWatermark = highWatermarks.get(topicPartition);\n             final RecordBatchingStateRestoreCallback stateRestoreAdapter =\n                 StateRestoreCallbackAdapter.adapt(stateRestoreCallback);\n \n             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);\n             long restoreCount = 0L;\n \n+            long deadlineMs = NO_DEADLINE;\n             while (offset < highWatermark) {\n                 try {\n                     final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+                    if (records.isEmpty()) {\n+                        if (taskTimeoutMs == 0L) {\n+                            deadlineMs = maybeUpdateDeadlineOrThrow(\n+                                deadlineMs,\n+                                requestTimeoutMs,\n+                                new StreamsException(String.format(\n+                                    \"Global task did not make progress to restore state. Retrying is disabled. You can enable it by setting `%s` to a value larger than zero.\",\n+                                    StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n+                                ))\n+                            );\n+                        } else {\n+                            deadlineMs = maybeUpdateDeadlineOrThrow(deadlineMs);\n+                        }\n+\n+                        continue;\n+                    }\n+                    deadlineMs = NO_DEADLINE;\n+\n                     final List<ConsumerRecord<byte[], byte[]>> restoreRecords = new ArrayList<>();\n                     for (final ConsumerRecord<byte[], byte[]> record : records.records(topicPartition)) {\n                         if (record.key() != null) {\n                             restoreRecords.add(recordConverter.convert(record));\n                         }\n                     }\n-                    offset = globalConsumer.position(topicPartition);\n+                    try {\n+                        offset = globalConsumer.position(topicPartition);\n+                    } catch (final TimeoutException error) {\n+                        // the `globalConsumer.position()` call should never block, because we know that we did\n+                        // a successful `position()` call above for the requested partition and thus the consumer\n+                        // should have a valid local position that it can return immediately\n+\n+                        // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                        throw new IllegalStateException(error);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwODc5Nw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460308797", "bodyText": "As this would expose a bug, is does not seem useful to users -- and for us, we have the comment in the code.", "author": "mjsax", "createdAt": "2020-07-24T22:09:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzMTg1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMyMDMwMw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460320303", "bodyText": "As requested by John, I'll drop this and just call retryUntilSuccessOrThrowOnTaskTimeout here, too.", "author": "mjsax", "createdAt": "2020-07-24T22:51:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzMTg1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzNTI0Mw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460235243", "bodyText": "Why do we need this?", "author": "abbccdda", "createdAt": "2020-07-24T19:01:56Z", "path": "streams/src/test/java/org/apache/kafka/test/NoOpReadOnlyStore.java", "diffHunk": "@@ -78,6 +78,7 @@ public void init(final ProcessorContext context, final StateStore root) {\n             new File(context.stateDir() + File.separator + name).mkdir();\n         }\n         this.initialized = true;\n+        context.register(root, (k, v) -> { });", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwOTc1MA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460309750", "bodyText": "That is what the real code does, too. Otherwise we need to call register manually in the tests what is annoying.", "author": "mjsax", "createdAt": "2020-07-24T22:12:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzNTI0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzOTI5OA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460239298", "bodyText": "For the above call, was curious why we couldn't seek for all the topic partitions that are missing positions here, instead of doing one by one look-up?", "author": "abbccdda", "createdAt": "2020-07-24T19:10:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -275,31 +259,70 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                final AtomicLong position = new AtomicLong();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwNTk0NQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460305945", "bodyText": "Well, I guess we want to restore partition by partition because the \"restore listener\" callback is easier to handle this way?", "author": "mjsax", "createdAt": "2020-07-24T21:59:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzOTI5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwMDA0MQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460300041", "bodyText": "No need to change anything, just a note: It's mildly concerning to see side-effecting operations inside a retry loop, since there's no guarantee that failed attempts won't leave any garbage in the system, for example leaving a couple of things in highWatermarks on each attempt. I've read through the code, and I don't think this could actually happen right now, but it could after refactoring.\nSince we're really just retrying simple API calls, something like this would be safer:\n    private <R> R retryUntilSuccessOrThrowOnTaskTimeout(final Supplier<R> supplier,\n                                                        final String errorMessage) {\n        long deadlineMs = NO_DEADLINE;\n\n        do {\n            try {\n                return supplier.get();\n            } catch (final TimeoutException retryableException) {\n                if (taskTimeoutMs == 0L) {\n                    throw new StreamsException(\n                        String.format(\n                            \"Retrying is disabled. You can enable it by setting `%s` to a value larger than zero.\",\n                            StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n                        ),\n                        retryableException\n                    );\n                }\n\n                deadlineMs = maybeUpdateDeadlineOrThrow(deadlineMs);\n\n                log.debug(errorMessage, retryableException);\n            }\n        } while (true);\n    }\nWhich would support:\n        final Map<TopicPartition, Long> highWatermarks = new HashMap<>(\n            retryUntilSuccessOrThrowOnTaskTimeout(\n                () -> globalConsumer.endOffsets(topicPartitions),\n                String.format(\n                    \"Failed to get offsets for partitions %s. The broker may be transiently unavailable at the moment.\",\n                    topicPartitions\n                )\n            )\n        );\nIncidentally, this seems to be exactly the same as:\n        final Map<TopicPartition, Long> highWatermarks = new HashMap<>(\n            globalConsumer.endOffsets(topicPartitions, Duration.ofMillis(taskTimeoutMs))\n        );\nright? That might be preferable because we're not implementing any backoff, whereas retrying internally in the client, it can do exponential backoff, etc. (I think).", "author": "vvcephei", "createdAt": "2020-07-24T21:40:14Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -185,32 +200,16 @@ public void registerStore(final StateStore store, final StateRestoreCallback sta\n \n         log.info(\"Restoring state for global store {}\", store.name());\n         final List<TopicPartition> topicPartitions = topicPartitionsForStore(store);\n-        Map<TopicPartition, Long> highWatermarks = null;\n \n-        int attempts = 0;\n-        while (highWatermarks == null) {\n-            try {\n-                highWatermarks = globalConsumer.endOffsets(topicPartitions);\n-            } catch (final TimeoutException retryableException) {\n-                if (++attempts > retries) {\n-                    log.error(\"Failed to get end offsets for topic partitions of global store {} after {} retry attempts. \" +\n-                        \"You can increase the number of retries via configuration parameter `retries`.\",\n-                        store.name(),\n-                        retries,\n-                        retryableException);\n-                    throw new StreamsException(String.format(\"Failed to get end offsets for topic partitions of global store %s after %d retry attempts. \" +\n-                            \"You can increase the number of retries via configuration parameter `retries`.\", store.name(), retries),\n-                        retryableException);\n-                }\n-                log.debug(\"Failed to get end offsets for partitions {}, backing off for {} ms to retry (attempt {} of {})\",\n-                    topicPartitions,\n-                    retryBackoffMs,\n-                    attempts,\n-                    retries,\n-                    retryableException);\n-                Utils.sleep(retryBackoffMs);\n-            }\n-        }\n+        final Map<TopicPartition, Long> highWatermarks = new HashMap<>();\n+        retryUntilSuccessOrThrowOnTaskTimeout(\n+            () -> highWatermarks.putAll(globalConsumer.endOffsets(topicPartitions)),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwNTAzMw==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r460305033", "bodyText": "Correct, we rely on the clients internal backoff behavior here. Happy to switch to a Supplier", "author": "mjsax", "createdAt": "2020-07-24T21:56:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDMwMDA0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNDk0NQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r461114945", "bodyText": "It does seem a bit weird here to add in the request timeout. Not sure I follow the reasoning behind that...", "author": "hachikuji", "createdAt": "2020-07-27T19:21:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -292,21 +278,36 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n \n             while (offset < highWatermark) {\n                 try {\n-                    final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+                    final ConsumerRecords<byte[], byte[]> records =\n+                        globalConsumer.poll(pollTimePlusRequestTimeoutPlusTaskTimeout);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTE0NjU0OQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r461146549", "bodyText": "Unfortunately, Github ate the very extensive thread about this: https://github.com/apache/kafka/pull/9047/files/0e07109bb0cfe87c85e76fbab3b50e9274300388#r460449901", "author": "vvcephei", "createdAt": "2020-07-27T20:22:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTExNDk0NQ=="}], "type": "inlineReview"}, {"oid": "89ae568004fdc04b3d216cec53585fadf55641cc", "url": "https://github.com/apache/kafka/commit/89ae568004fdc04b3d216cec53585fadf55641cc", "message": "KAFKA-9274: remove `retries` for global tasks\n - part of KIP-572\n - removed the usage of `retries` in `GlobalStateManger`\n - instead of retries the new `task.timeout.ms` config is used", "committedDate": "2020-07-28T04:05:45Z", "type": "commit"}, {"oid": "7cecee3b990da57dd0a57ec5e497d1c8c2550955", "url": "https://github.com/apache/kafka/commit/7cecee3b990da57dd0a57ec5e497d1c8c2550955", "message": "Rebased\n\nUpdated poll timeout", "committedDate": "2020-07-28T04:39:47Z", "type": "commit"}, {"oid": "7cecee3b990da57dd0a57ec5e497d1c8c2550955", "url": "https://github.com/apache/kafka/commit/7cecee3b990da57dd0a57ec5e497d1c8c2550955", "message": "Rebased\n\nUpdated poll timeout", "committedDate": "2020-07-28T04:39:47Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA0NzA2OA==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r462047068", "bodyText": "Could we just throw here?", "author": "abbccdda", "createdAt": "2020-07-29T05:28:49Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -274,30 +252,74 @@ private void restoreState(final StateRestoreCallback stateRestoreCallback,\n                               final RecordConverter recordConverter) {\n         for (final TopicPartition topicPartition : topicPartitions) {\n             globalConsumer.assign(Collections.singletonList(topicPartition));\n+            long offset;\n             final Long checkpoint = checkpointFileCache.get(topicPartition);\n             if (checkpoint != null) {\n                 globalConsumer.seek(topicPartition, checkpoint);\n+                offset = checkpoint;\n             } else {\n                 globalConsumer.seekToBeginning(Collections.singletonList(topicPartition));\n+                offset = retryUntilSuccessOrThrowOnTaskTimeout(\n+                    () -> globalConsumer.position(topicPartition),\n+                    String.format(\n+                        \"Failed to get position for partition %s. The broker may be transiently unavailable at the moment.\",\n+                        topicPartition\n+                    )\n+                );\n             }\n \n-            long offset = globalConsumer.position(topicPartition);\n             final Long highWatermark = highWatermarks.get(topicPartition);\n             final RecordBatchingStateRestoreCallback stateRestoreAdapter =\n                 StateRestoreCallbackAdapter.adapt(stateRestoreCallback);\n \n             stateRestoreListener.onRestoreStart(topicPartition, storeName, offset, highWatermark);\n             long restoreCount = 0L;\n \n-            while (offset < highWatermark) {\n-                final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(pollTime);\n+            while (offset < highWatermark) { // when we \"fix\" this loop (KAFKA-7380 / KAFKA-10317)\n+                                             // we should update the `poll()` timeout below\n+\n+                // we ignore `poll.ms` config during bootstrapping phase and\n+                // apply `request.timeout.ms` plus `task.timeout.ms` instead\n+                //\n+                // the reason is, that `poll.ms` might be too short to give a fetch request a fair chance\n+                // to actually complete and we don't want to start `task.timeout.ms` too early\n+                //\n+                // we also pass `task.timeout.ms` into `poll()` directly right now as it simplifies our own code:\n+                // if we don't pass it in, we would just track the timeout ourselves and call `poll()` again\n+                // in our own retry loop; by passing the timeout we can reuse the consumer's internal retry loop instead\n+                //\n+                // note that using `request.timeout.ms` provides a conservative upper bound for the timeout;\n+                // this implies that we might start `task.timeout.ms` \"delayed\" -- however, starting the timeout\n+                // delayed is preferable (as it's more robust) than starting it too early\n+                //\n+                // TODO https://issues.apache.org/jira/browse/KAFKA-10315\n+                //   -> do a more precise timeout handling if `poll` would throw an exception if a fetch request fails\n+                //      (instead of letting the consumer retry fetch requests silently)\n+                //\n+                // TODO https://issues.apache.org/jira/browse/KAFKA-10317 and\n+                //      https://issues.apache.org/jira/browse/KAFKA-7380\n+                //  -> don't pass in `task.timeout.ms` to stay responsive if `KafkaStreams#close` gets called\n+                final ConsumerRecords<byte[], byte[]> records = globalConsumer.poll(requestTimeoutPlusTaskTimeout);\n+                if (records.isEmpty()) {\n+                    // this will always throw\n+                    maybeUpdateDeadlineOrThrow(time.milliseconds());", "originalCommit": "7cecee3b990da57dd0a57ec5e497d1c8c2550955", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NjY0Ng==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r464756646", "bodyText": "We could, but this implies redundant code to \"assemble\" the error message, and I prefer to reuse the existing code for it.", "author": "mjsax", "createdAt": "2020-08-04T02:07:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA0NzA2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA0ODg3OQ==", "url": "https://github.com/apache/kafka/pull/9047#discussion_r462048879", "bodyText": "nit: we could just use Map for startOffsets and endOffsets", "author": "abbccdda", "createdAt": "2020-07-29T05:35:04Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImplTest.java", "diffHunk": "@@ -671,19 +1211,21 @@ private void writeCorruptCheckpoint() throws IOException {\n         }\n     }\n \n-    private void initializeConsumer(final long numRecords, final long startOffset, final TopicPartition topicPartition) {\n+    private void initializeConsumer(final long numRecords, final long startOffset, final TopicPartition... topicPartitions) {\n+        consumer.assign(Arrays.asList(topicPartitions));\n+\n         final HashMap<TopicPartition, Long> startOffsets = new HashMap<>();\n-        startOffsets.put(topicPartition, startOffset);\n         final HashMap<TopicPartition, Long> endOffsets = new HashMap<>();\n-        endOffsets.put(topicPartition, startOffset + numRecords);\n-        consumer.updatePartitions(topicPartition.topic(), Collections.singletonList(new PartitionInfo(topicPartition.topic(), topicPartition.partition(), null, null, null)));\n-        consumer.assign(Collections.singletonList(topicPartition));\n+        for (final TopicPartition topicPartition : topicPartitions) {", "originalCommit": "7cecee3b990da57dd0a57ec5e497d1c8c2550955", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "cf6ee1e774a3a635cb8ac9c134ff3269edaa7357", "url": "https://github.com/apache/kafka/commit/cf6ee1e774a3a635cb8ac9c134ff3269edaa7357", "message": "Github comments", "committedDate": "2020-08-04T02:12:18Z", "type": "commit"}]}