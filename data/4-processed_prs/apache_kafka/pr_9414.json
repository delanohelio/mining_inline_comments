{"pr_number": 9414, "pr_title": "KAFKA-10585: Kafka Streams should clean up the state store directory from cleanup", "pr_createdAt": "2020-10-12T13:36:07Z", "pr_url": "https://github.com/apache/kafka/pull/9414", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDA1MTkxMQ==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r504051911", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertTrue(!appDir.exists());\n          \n          \n            \n                    assertFalse(appDir.exists());\n          \n      \n    \n    \n  \n\n:)", "author": "vvcephei", "createdAt": "2020-10-13T15:33:35Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StateDirectoryTest.java", "diffHunk": "@@ -510,8 +511,8 @@ public void shouldCleanupAllTaskDirectoriesIncludingGlobalOne() {\n \n         directory.clean();\n \n-        assertEquals(Collections.emptySet(), Arrays.stream(\n-            Objects.requireNonNull(appDir.listFiles())).collect(Collectors.toSet()));\n+        // if appDir is empty, it is deleted in StateDirectory#clean process.\n+        assertTrue(!appDir.exists());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDA1NDAyOA==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r504054028", "bodyText": "We shouldn't add unrelated checks to tests in general, it just makes the tests more confusing. If you want to verify that the directory still exists after closing when we don't call clean(), we should just add a new test for it.", "author": "vvcephei", "createdAt": "2020-10-13T15:36:10Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StateDirectoryTest.java", "diffHunk": "@@ -602,6 +606,11 @@ public void shouldLogStateDirCleanerMessage() {\n             directory.cleanRemovedTasks(cleanupDelayMs);\n             assertThat(appender.getMessages(), hasItem(endsWith(\"ms has elapsed (cleanup delay is \" +  cleanupDelayMs + \"ms).\")));\n         }\n+\n+        // if appDir is empty, it is deleted in  process.\n+        // since we did not call StateDirectory#clean, the global state directory is not deleted and appDir also.\n+        assertTrue(appDir.exists());\n+        assertArrayEquals(appDir.list(), new String[]{\"0_0\"});", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDA1NDg0Mg==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r504054842", "bodyText": "Similar feedback here as below. This test is about logging, not cleanup. You've already added a check to the \"shouldCleanup\" test, so we don't need one here.", "author": "vvcephei", "createdAt": "2020-10-13T15:37:11Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StateDirectoryTest.java", "diffHunk": "@@ -586,6 +587,9 @@ public void shouldLogManualUserCallMessage() {\n                 hasItem(endsWith(\"as user calling cleanup.\"))\n             );\n         }\n+\n+        // if appDir is empty, it is deleted in StateDirectory#clean process.\n+        assertTrue(!appDir.exists());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDA1NzI0MA==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r504057240", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        if (hasPersistentStores && stateDir.exists() && !stateDir.delete()) {\n          \n          \n            \n                        if (stateDir.exists() && !stateDir.delete()) {\n          \n      \n    \n    \n  \n\nDo we need to check hasPersistentStores here? It seems sufficient just to check if the directory exists.", "author": "vvcephei", "createdAt": "2020-10-13T15:40:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateDirectory.java", "diffHunk": "@@ -301,6 +301,22 @@ public synchronized void clean() {\n             );\n             throw new StreamsException(exception);\n         }\n+\n+        try {\n+            if (hasPersistentStores && stateDir.exists() && !stateDir.delete()) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTQyNDY2NQ==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r505424665", "bodyText": "Exactly. But I thought keeping symmetry with the Consturctor is better.\nif (this.hasPersistentStores && !stateDir.exists() && !stateDir.mkdir()) {\n    throw new ProcessorStateException(\n        String.format(\"state directory [%s] doesn't exist and couldn't be created\", stateDir.getPath()));\n}", "author": "dongjinleekr", "createdAt": "2020-10-15T10:11:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDA1NzI0MA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5ODg5MQ==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r508798891", "bodyText": "I'd be tempted to give it more time. Experience says that Jenkins will take unreasonably long to perform these operations. How about using the default timeout in IntegrationTestUtils here and below?", "author": "vvcephei", "createdAt": "2020-10-20T19:54:41Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StateDirectoryIntegrationTest.java", "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.apache.kafka.common.utils.Utils.mkProperties;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+@Category({IntegrationTest.class})\n+public class StateDirectoryIntegrationTest {\n+\n+    private static final int NUM_BROKERS = 1;\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(NUM_BROKERS);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    @Test\n+    public void testCleanUpStateDirIfEmpty() throws InterruptedException {\n+        final String uniqueTestName = safeUniqueTestName(getClass(), testName);\n+\n+        // Create Topic\n+        final String input = uniqueTestName + \"-input\";\n+        CLUSTER.createTopic(input);\n+\n+        final Properties producerConfig = mkProperties(mkMap(\n+            mkEntry(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()),\n+            mkEntry(ProducerConfig.ACKS_CONFIG, \"all\"),\n+            mkEntry(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getCanonicalName()),\n+            mkEntry(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getCanonicalName())\n+        ));\n+\n+        try (final KafkaProducer<String, String> producer =\n+                 new KafkaProducer<>(producerConfig, Serdes.String().serializer(), Serdes.String().serializer())) {\n+            // Create Test Records\n+            producer.send(new ProducerRecord<>(input, \"a\"));\n+            producer.send(new ProducerRecord<>(input, \"b\"));\n+            producer.send(new ProducerRecord<>(input, \"c\"));\n+\n+            // Create Topology\n+            final String storeName = uniqueTestName + \"-input-table\";\n+\n+            final StreamsBuilder builder = new StreamsBuilder();\n+            builder.table(\n+                input,\n+                Materialized\n+                    .<String, String, KeyValueStore<Bytes, byte[]>>as(storeName)\n+                    .withKeySerde(Serdes.String())\n+                    .withValueSerde(Serdes.String())\n+            );\n+            final Topology topology = builder.build();\n+\n+            // State Store Directory\n+            final String stateDir = TestUtils.tempDirectory(uniqueTestName).getPath();\n+\n+            // Create KafkaStreams instance\n+            final String applicationId = uniqueTestName + \"-app\";\n+            final Properties streamsConfig = mkProperties(mkMap(\n+                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, applicationId),\n+                mkEntry(StreamsConfig.STATE_DIR_CONFIG, stateDir),\n+                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers())\n+            ));\n+\n+            final KafkaStreams streams = new KafkaStreams(topology, streamsConfig);\n+\n+            // Create StateListener\n+            final CountDownLatch runningLatch = new CountDownLatch(1);\n+            final CountDownLatch notRunningLatch = new CountDownLatch(1);\n+\n+            final KafkaStreams.StateListener stateListener = (newState, oldState) -> {\n+                if (newState == KafkaStreams.State.RUNNING) {\n+                    runningLatch.countDown();\n+                }\n+                if (newState == KafkaStreams.State.NOT_RUNNING) {\n+                    notRunningLatch.countDown();\n+                }\n+            };\n+            streams.setStateListener(stateListener);\n+\n+            // Application state directory\n+            final File appDir = new File(stateDir, applicationId);\n+\n+            // Validate application state directory is created.\n+            streams.start();\n+            try {\n+                runningLatch.await(10 * 1000L, TimeUnit.MILLISECONDS);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQyNjUxNg==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r524426516", "bodyText": "Can you explain why we need to remove this? It seems like the application must have created the state directory by this point, right?", "author": "vvcephei", "createdAt": "2020-11-16T17:04:12Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EOSUncleanShutdownIntegrationTest.java", "diffHunk": "@@ -140,9 +140,6 @@ public void shouldWorkWithUncleanShutdownWipeOutStateStore() throws InterruptedE\n             IntegrationTestUtils.produceSynchronously(producerConfig, false, input, Optional.empty(),\n                 singletonList(new KeyValueTimestamp<>(\"k1\", \"v1\", 0L)));\n \n-            TestUtils.waitForCondition(stateDir::exists,\n-                \"Failed awaiting CreateTopics first request failure\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTM1NA==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r525835354", "bodyText": "Previous: The test asserts that the (empty) StateStore directory is not deleted.\nNow: The empty StateStore directory is deleted in the cleanup process, so this assertion is no longer valid. (wait, would it much better to negate the logical condition instead of removing it?)", "author": "dongjinleekr", "createdAt": "2020-11-18T06:07:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQyNjUxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM3NzM3NQ==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r526377375", "bodyText": "Hmm, I see. Maybe I misread it. I thought we were asserting that Streams actually creates the directory when it starts processing, so that the later assertion (L159) that it cleans up the directory is actually valid.\nThen again, L159 seems to assert the opposite thing that its own comment states, so maybe this whole test is just wacky.\nThe only clue about what we're trying to do here is the name, which almost doesn't make sense at all: shouldWorkWithUncleanShutdownWipeOutStateStore. I guess it's saying that we should delete the state store on unclean shutdown? I think that's not what we do anyway. I think we just guarantee that we write an empty checkpoint file. So maybe we should instead change the assertion to:\n\nthe directory is absent\nOR the directory is present, but the checkpoint file is missing\nOR the directory and checkpoint file are present, but the checkpoint file is empty\n\nAny of those should indicate a successful unclean shutdown.", "author": "vvcephei", "createdAt": "2020-11-18T19:52:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQyNjUxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQzNzEyMQ==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r524437121", "bodyText": "Since you have modified the purpose of this test, maybe we can go ahead and give the test a more specific name as well.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldThrowProcessorStateException() throws IOException {\n          \n          \n            \n                public void shouldThrowProcessorStateExceptionIfTaskDirectoryIsOccupiedByFile() throws IOException {\n          \n      \n    \n    \n  \n\nAlso, I won't dispute the value of checking this condition, but would like to point out that this test was previously verifying a specific error on failure to create the task directory, and now we are no longer checking that failure. In other words, we were previously verifying \"task directory [%s] doesn't exist and couldn't be created\", but now we are only verifying the separate and specific failure reason \"task directory path [%s] is already occupied\".\nIt actually seems like maybe we don't need to check that specific !taskDir.isDirectory() case, since it seems like having this file sitting there should cause a failure to create the task directory, right?", "author": "vvcephei", "createdAt": "2020-11-16T17:16:15Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StateDirectoryTest.java", "diffHunk": "@@ -186,19 +186,29 @@ public void shouldReportDirectoryEmpty() throws IOException {\n \n     @Test\n     public void shouldThrowProcessorStateException() throws IOException {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTg0NTExNw==", "url": "https://github.com/apache/kafka/pull/9414#discussion_r525845117", "bodyText": "Totally agree. \ud83d\ude04", "author": "dongjinleekr", "createdAt": "2020-11-18T06:37:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQzNzEyMQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "4579b4cfcf666cf7420f57e3cd60737fb27b88f5", "url": "https://github.com/apache/kafka/commit/4579b4cfcf666cf7420f57e3cd60737fb27b88f5", "message": "Fix EOSUncleanShutdownIntegrationTest#shouldWorkWithUncleanShutdownWipeOutStateStore", "committedDate": "2020-12-01T06:16:14Z", "type": "forcePushed"}, {"oid": "d3c63894fa73fb1fe0f021f14f715cd3944c9d77", "url": "https://github.com/apache/kafka/commit/d3c63894fa73fb1fe0f021f14f715cd3944c9d77", "message": "Fix EOSUncleanShutdownIntegrationTest#shouldWorkWithUncleanShutdownWipeOutStateStore", "committedDate": "2020-12-05T06:04:11Z", "type": "forcePushed"}, {"oid": "39d582de2fead8483bb273397e3b8fffa290c8f0", "url": "https://github.com/apache/kafka/commit/39d582de2fead8483bb273397e3b8fffa290c8f0", "message": "Fix EOSUncleanShutdownIntegrationTest#shouldWorkWithUncleanShutdownWipeOutStateStore", "committedDate": "2021-01-18T07:17:26Z", "type": "forcePushed"}, {"oid": "2462c990a093b60645fef321a23c3f7b5a2dec0b", "url": "https://github.com/apache/kafka/commit/2462c990a093b60645fef321a23c3f7b5a2dec0b", "message": "Fix EOSUncleanShutdownIntegrationTest#shouldWorkWithUncleanShutdownWipeOutStateStore", "committedDate": "2021-02-11T13:03:39Z", "type": "forcePushed"}, {"oid": "277e434425bffe98a7e3870dc8556de199c37aa1", "url": "https://github.com/apache/kafka/commit/277e434425bffe98a7e3870dc8556de199c37aa1", "message": "Fix EOSUncleanShutdownIntegrationTest#shouldWorkWithUncleanShutdownWipeOutStateStore", "committedDate": "2021-03-23T08:54:36Z", "type": "forcePushed"}, {"oid": "00a622992ba308b4319fd6d61e0ed20df55b19f3", "url": "https://github.com/apache/kafka/commit/00a622992ba308b4319fd6d61e0ed20df55b19f3", "message": "Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.", "committedDate": "2021-03-25T13:19:27Z", "type": "forcePushed"}, {"oid": "396d1421effe0299a400489fd7168215e027ce91", "url": "https://github.com/apache/kafka/commit/396d1421effe0299a400489fd7168215e027ce91", "message": "Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.", "committedDate": "2021-04-11T11:19:51Z", "type": "forcePushed"}, {"oid": "6c13f1fa812a31eb47f0d62e84f601ae31f70a8e", "url": "https://github.com/apache/kafka/commit/6c13f1fa812a31eb47f0d62e84f601ae31f70a8e", "message": "Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.", "committedDate": "2021-04-12T11:57:59Z", "type": "forcePushed"}, {"oid": "b76b5350d87ea3ad56e225d2cccdedbdfe31f4fb", "url": "https://github.com/apache/kafka/commit/b76b5350d87ea3ad56e225d2cccdedbdfe31f4fb", "message": "Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.", "committedDate": "2021-04-20T05:36:00Z", "type": "forcePushed"}, {"oid": "3bd9bc0b5d14a8b7f6b237726f936ea5566f12a5", "url": "https://github.com/apache/kafka/commit/3bd9bc0b5d14a8b7f6b237726f936ea5566f12a5", "message": "Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.", "committedDate": "2021-05-07T12:58:27Z", "type": "forcePushed"}, {"oid": "cc5fdc386ba3c7b7bb78e07de6b34bb673ae6c74", "url": "https://github.com/apache/kafka/commit/cc5fdc386ba3c7b7bb78e07de6b34bb673ae6c74", "message": "Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.", "committedDate": "2021-05-24T03:01:15Z", "type": "forcePushed"}, {"oid": "f1ea64f28eae01af6db6009f2634ca6946da4586", "url": "https://github.com/apache/kafka/commit/f1ea64f28eae01af6db6009f2634ca6946da4586", "message": "Make application's statestore directory is deleted in cleanup process if it is empty\n\n1. Update StateDirectory#clean\n\n  - Delete application's statestore directory in cleanup process if it is empty.\n\n2. Add Tests\n\n  - StateDirectoryTest#shouldDeleteAppDirWhenCleanUpIfEmpty: asserting the empty application directory is deleted with StateDirectory#clean.\n  - StateDirectoryTest#shouldNotDeleteAppDirWhenCleanUpIfNotEmpty: asserting the non-empty application directory is not deleted with StateDirectory#clean and appropriate log message is generated.\n  - Add Integration test: StateDirectoryIntegrationTest\n\n3. Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.", "committedDate": "2021-06-10T07:42:42Z", "type": "commit"}, {"oid": "f1ea64f28eae01af6db6009f2634ca6946da4586", "url": "https://github.com/apache/kafka/commit/f1ea64f28eae01af6db6009f2634ca6946da4586", "message": "Make application's statestore directory is deleted in cleanup process if it is empty\n\n1. Update StateDirectory#clean\n\n  - Delete application's statestore directory in cleanup process if it is empty.\n\n2. Add Tests\n\n  - StateDirectoryTest#shouldDeleteAppDirWhenCleanUpIfEmpty: asserting the empty application directory is deleted with StateDirectory#clean.\n  - StateDirectoryTest#shouldNotDeleteAppDirWhenCleanUpIfNotEmpty: asserting the non-empty application directory is not deleted with StateDirectory#clean and appropriate log message is generated.\n  - Add Integration test: StateDirectoryIntegrationTest\n\n3. Improve EOSUncleanShutdownIntegrationTest: test all available cases regarding cleanup process on unclean shutdown.", "committedDate": "2021-06-10T07:42:42Z", "type": "forcePushed"}]}