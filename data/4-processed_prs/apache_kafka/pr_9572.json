{"pr_number": 9572, "pr_title": "KAFKA-10500: Thread Cache Resizes", "pr_createdAt": "2020-11-06T18:48:33Z", "pr_url": "https://github.com/apache/kafka/pull/9572", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r519049317", "bodyText": "I am not sure if I should just expose cache or pass it along. It is about 4 levels deep", "author": "wcarlson5", "createdAt": "2020-11-06T23:09:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +589,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        taskManager.resizeCache(size);", "originalCommit": "68113b842861d85bda4616ad3d5c2f3a5e4adab9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ5ODU2NA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520498564", "bodyText": "I am in favour of keeping a reference to the thread cache in the StreamThread and do the re-sizing here. I think it makes the code a bit easier to follow.\nYou will need synchronization, because the thread that will add the new stream thread will also resize the thread caches.", "author": "cadonna", "createdAt": "2020-11-10T11:41:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5OTc5Mw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520699793", "bodyText": "Are the thread caches not independent of each other? Also I was not planning on having the new thread resize the cache but the calling thread do so", "author": "wcarlson5", "createdAt": "2020-11-10T16:30:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI1MTMwNA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521251304", "bodyText": "I was not planning on having the new thread resize the cache but the calling thread do so\n\nThat is what I am saying \"the thread that will add the new stream thread\" is the calling thread. The new stream thread cannot resize the caches of the other stream threads because it is not aware of the other stream threads. Still we need synchronization because the calling thread will access and modify the thread caches of all stream threads and all stream threads will access and modify their own thread cache during normal processing.", "author": "cadonna", "createdAt": "2020-11-11T10:10:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ0OTQxOQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521449419", "bodyText": "I'm not sure I follow. If we make it so that each thread is responsible for resizing their own independent cache then why would the method need to synchronized as each call should not affect the others. And if one thread does all the work there should only be one call. Unless you are thinking about multiple threads adding threads at the same time?\nMaybe I don't understand how the cache is set up well enough?", "author": "wcarlson5", "createdAt": "2020-11-11T15:44:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5MjI5NQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r523292295", "bodyText": "Talked about off line. The named cache is already synchronized. Also made max cache size volatile", "author": "wcarlson5", "createdAt": "2020-11-13T23:55:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA0OTMxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NDQyMA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520444420", "bodyText": "I see that this check was there before, but I actually think it is not needed because the configs are validated and there CACHE_MAX_BYTES_BUFFERING_CONFIG is specified as at least 0.", "author": "cadonna", "createdAt": "2020-11-10T10:14:03Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,21 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        if (totalCacheSize < 0) {\n+            totalCacheSize = 0L;\n+            log.warn(\"Negative cache size passed in. Reverting to cache size of 0 bytes.\");\n+        }", "originalCommit": "68113b842861d85bda4616ad3d5c2f3a5e4adab9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4NjMwNw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520686307", "bodyText": "good to know", "author": "wcarlson5", "createdAt": "2020-11-10T16:12:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NDQyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NTc4Nw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520445787", "bodyText": "I think this can be a final long if we remove the check as I proposed below.", "author": "cadonna", "createdAt": "2020-11-10T10:16:03Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -155,6 +155,7 @@\n     private final StreamsMetricsImpl streamsMetrics;\n     private final ProcessorTopology taskTopology;\n     private final ProcessorTopology globalTaskTopology;\n+    private Long totalCacheSize;", "originalCommit": "68113b842861d85bda4616ad3d5c2f3a5e4adab9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4NjQ5NQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520686495", "bodyText": "yes it can", "author": "wcarlson5", "createdAt": "2020-11-10T16:13:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ0NTc4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUwNDcyOQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520504729", "bodyText": "This loop has the disadvantage that it first evict entries of one named cache, if all entries are evicted and we still need to free space, it starts to evict entries of the next named cache etc. I guess it would be better to avoid such a skewed emission of records to downstream by continuously iterating over the named caches and evict one entry at a time from each named cache until enough space is freed.", "author": "cadonna", "createdAt": "2020-11-10T11:52:37Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +71,16 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            for (final NamedCache cache : caches.values()) {\n+                maybeEvict(cache.name());\n+            }", "originalCommit": "68113b842861d85bda4616ad3d5c2f3a5e4adab9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5MzEzMg==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r520693132", "bodyText": "I would expect it to take a bit to repopulate the cache to be balanced but you are right it probably better to do so evenly", "author": "wcarlson5", "createdAt": "2020-11-10T16:22:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUwNDcyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0NzkwNg==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521247906", "bodyText": "Why does this need to be a Long instead of a long? The numerical value of the variable is only immutable if we use a long here.", "author": "cadonna", "createdAt": "2020-11-11T10:04:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -155,6 +155,7 @@\n     private final StreamsMetricsImpl streamsMetrics;\n     private final ProcessorTopology taskTopology;\n     private final ProcessorTopology globalTaskTopology;\n+    private final Long totalCacheSize;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ0OTUxOA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521449518", "bodyText": "I think that its just what the ide defaulted to. Ill change it.", "author": "wcarlson5", "createdAt": "2020-11-11T15:44:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0NzkwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0OTA3NA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521249074", "bodyText": "IMO, the code would be easier navigable if you inline this method. Without the removed check, there is not really a reason to have a method here.", "author": "cadonna", "createdAt": "2020-11-11T10:06:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,17 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQ0OTU4Mg==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r521449582", "bodyText": "I think I agree with you. fixed", "author": "wcarlson5", "createdAt": "2020-11-11T15:44:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI0OTA3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTAzOA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525399038", "bodyText": "Why do we remove this guard?", "author": "mjsax", "createdAt": "2020-11-17T18:41:19Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -728,12 +729,8 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 \"must subscribe to at least one source topic or global table.\");\n         }\n \n-        long totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n-        if (totalCacheSize < 0) {\n-            totalCacheSize = 0;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyNTY1MA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525425650", "bodyText": "#9572 (comment)\nIt seems it was not necessary", "author": "wcarlson5", "createdAt": "2020-11-17T19:21:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTM5Ng==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525399396", "bodyText": "Why move off using hasGlobalTopology?", "author": "mjsax", "createdAt": "2020-11-17T18:41:53Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -728,12 +729,8 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n                 \"must subscribe to at least one source topic or global table.\");\n         }\n \n-        long totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n-        if (totalCacheSize < 0) {\n-            totalCacheSize = 0;\n-            log.warn(\"Negative cache size passed in. Reverting to cache size of 0 bytes.\");\n-        }\n-        final long cacheSizePerThread = totalCacheSize / (numStreamThreads + (hasGlobalTopology ? 1 : 0));\n+        totalCacheSize = config.getLong(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG);\n+        final long cacheSizePerThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyNzI0OQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525427249", "bodyText": "It was in a separate method without access to hasGlobalTopology. I supposes if it stays we can move it back", "author": "wcarlson5", "createdAt": "2020-11-17T19:24:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM5OTM5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525404296", "bodyText": "Seems this duplicates L733. Might be good to extract into a small helper method.", "author": "mjsax", "createdAt": "2020-11-17T18:49:40Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,13 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private void resizeThreadCache(final int numStreamThreads) {\n+        final long cacheSizePreThread = totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyNjMxNw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525426317", "bodyText": "I did have it in a separate method but helper but when removing the totalCacheSize < 0  check @cadonna thought it would be more readable inline", "author": "wcarlson5", "createdAt": "2020-11-17T19:22:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQzNTQ1Mg==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525435452", "bodyText": "Not sure why the totalCacheSize check is relevant for avoiding code duplication?", "author": "mjsax", "createdAt": "2020-11-17T19:35:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ1OTM1Mg==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525459352", "bodyText": "I think it was about readability. I might be misremembering though, as it was a conversation we had last week", "author": "wcarlson5", "createdAt": "2020-11-17T19:55:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ2MzY0NQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525463645", "bodyText": "If this line is duplicated, it should go in a method. When I proposed to move it inline, I was apparently not aware that the same line was used somewhere else.", "author": "cadonna", "createdAt": "2020-11-17T19:58:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ4ODY2NA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525488664", "bodyText": "Moved to a new method. Glad we got that cleared up. LGTM?", "author": "wcarlson5", "createdAt": "2020-11-17T20:19:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMjMwMA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525532300", "bodyText": "LGTM?\n\nIf this is a question, should it be LGTY? \ud83d\ude02", "author": "mjsax", "createdAt": "2020-11-17T21:21:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNDI5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525405615", "bodyText": "Why do we need the cacheResizer? Can't we just call cache.resize(size) here?", "author": "mjsax", "createdAt": "2020-11-17T18:51:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -589,6 +593,10 @@ private void subscribeConsumer() {\n         }\n     }\n \n+    public void resizeCache(final long size) {\n+        cacheResizer.accept(size);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyNzk0Mw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525427943", "bodyText": "The cache is not exposed in stream thread. Since I was only using one method I thought it best to only expose that.", "author": "wcarlson5", "createdAt": "2020-11-17T19:25:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQzNzY0Nw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525437647", "bodyText": "Ah. I see. -- Should we pass java.util.function.Consumer<Long> cacheResizer into StreamThread constructor for this case instead?", "author": "mjsax", "createdAt": "2020-11-17T19:37:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ2MzE2NQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525463165", "bodyText": "I think we can, thats probably a good idea.", "author": "wcarlson5", "createdAt": "2020-11-17T19:58:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNTYxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNjUxNQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525406515", "bodyText": "nit: newCachSizeBytes ? (To avoid the \"clash\" with this.maxCachSizeBytes.)", "author": "mjsax", "createdAt": "2020-11-17T18:53:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQyODEwMg==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525428102", "bodyText": "sure, that works", "author": "wcarlson5", "createdAt": "2020-11-17T19:25:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNjUxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525407677", "bodyText": "Could this ever happen? If we the max cache size is smaller than a single entry, would we not evict the entry and the used cache size would always shrink to zero?", "author": "mjsax", "createdAt": "2020-11-17T18:55:00Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,26 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long maxCacheSizeBytes) {\n+        final boolean shrink = maxCacheSizeBytes < this.maxCacheSizeBytes;\n+        this.maxCacheSizeBytes = maxCacheSizeBytes;\n+        if (shrink) {\n+            final CircularIterator<NamedCache> circularIterator = new CircularIterator<>(caches.values());\n+            while (sizeBytes() > maxCacheSizeBytes) {\n+                if (!circularIterator.hasNext()) {\n+                    log.error(\"Unable to remove any more entries as all caches are empty\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQzMDI1MQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525430251", "bodyText": "If we add a check to make sure the number of threads is positive then probably not. Ill add that check then remove this one", "author": "wcarlson5", "createdAt": "2020-11-17T19:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQzOTgxOQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525439819", "bodyText": "I see. -- I guess the miss-leading fact was, that this check was done inside the while-loop.", "author": "mjsax", "createdAt": "2020-11-17T19:39:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ2NDQ5NQ==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525464495", "bodyText": "Yeah, in retrospect it was not very clear. Hopefully its better this way now", "author": "wcarlson5", "createdAt": "2020-11-17T19:59:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQwNzY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525533593", "bodyText": "Can it be smaller than 0 ? Should the test be <= 0 or < 1 instead?", "author": "mjsax", "createdAt": "2020-11-17T21:23:54Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -806,6 +803,20 @@ private KafkaStreams(final InternalTopologyBuilder internalTopologyBuilder,\n         rocksDBMetricsRecordingService = maybeCreateRocksDBMetricsRecordingService(clientId, config);\n     }\n \n+    private long getCacheSizePerThread(final int numStreamThreads) {\n+        return totalCacheSize / (numStreamThreads + ((globalTaskTopology != null) ? 1 : 0));\n+    }\n+\n+    private void resizeThreadCache(final int numStreamThreads) {\n+        if (numStreamThreads < 0) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzNjk0NA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525536944", "bodyText": "It can be zero if you have a global thread, but since this is internal the check might not be entirely necessary", "author": "wcarlson5", "createdAt": "2020-11-17T21:29:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0MDQxOA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525540418", "bodyText": "Yes, it can be zero, but the check says < 0, so it would always evaluate to false?\nAnd if we have zero threads, we should not resize the cache as we might end up in an infinite loop? But we would only call this method if we \"shrink\", ie, if the thread count grows, but it can never grow from negative to zero, right?", "author": "mjsax", "createdAt": "2020-11-17T21:36:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2MTE3OA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525561178", "bodyText": "That is a good point. Maybe what we need to do it put a minimum size of cache to limit how many stream threads an instance can have?", "author": "wcarlson5", "createdAt": "2020-11-17T22:16:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2MjE1Ng==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525562156", "bodyText": "Well, getCacheSizePerThread would eventually return zero (with growing number of threads), what means that every put() into the cache would result in an immediate eviction. So I don't think we need to do anything for this corner case.", "author": "mjsax", "createdAt": "2020-11-17T22:18:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4MjI5OA==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525582298", "bodyText": "that is a good point", "author": "wcarlson5", "createdAt": "2020-11-17T23:00:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMzU5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzNDE2Nw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525534167", "bodyText": "nit: we can remove this. now (same next line)", "author": "mjsax", "createdAt": "2020-11-17T21:24:49Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ThreadCache.java", "diffHunk": "@@ -71,6 +72,22 @@ public long flushes() {\n         return numFlushes;\n     }\n \n+    public void resize(final long newCacheSizeBytes) {\n+        final boolean shrink = newCacheSizeBytes < this.maxCacheSizeBytes;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0MTUyMw==", "url": "https://github.com/apache/kafka/pull/9572#discussion_r525541523", "bodyText": "yep", "author": "wcarlson5", "createdAt": "2020-11-17T21:38:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzNDE2Nw=="}], "type": "inlineReview"}, {"oid": "ecb17f434fc6c08e5810e14ff668d9ef0c67f9f5", "url": "https://github.com/apache/kafka/commit/ecb17f434fc6c08e5810e14ff668d9ef0c67f9f5", "message": "ThreadCache Resizes", "committedDate": "2020-11-18T17:12:30Z", "type": "commit"}, {"oid": "41c9dca704b5541b267692dac07c033ba119dfa4", "url": "https://github.com/apache/kafka/commit/41c9dca704b5541b267692dac07c033ba119dfa4", "message": "fix typo", "committedDate": "2020-11-18T17:12:30Z", "type": "commit"}, {"oid": "a2d3b0fb2f30ba66b13955c80bbc83ce255336bc", "url": "https://github.com/apache/kafka/commit/a2d3b0fb2f30ba66b13955c80bbc83ce255336bc", "message": "address comments and evenly clear cache", "committedDate": "2020-11-18T17:12:30Z", "type": "commit"}, {"oid": "eade1c7ece7a7cc92349a95d69e90ad56696402d", "url": "https://github.com/apache/kafka/commit/eade1c7ece7a7cc92349a95d69e90ad56696402d", "message": "make final", "committedDate": "2020-11-18T17:12:30Z", "type": "commit"}, {"oid": "cb8078f5a018d0d2b49b7282afea9c508f72ae94", "url": "https://github.com/apache/kafka/commit/cb8078f5a018d0d2b49b7282afea9c508f72ae94", "message": "comments", "committedDate": "2020-11-18T17:12:30Z", "type": "commit"}, {"oid": "1ed3914fc618d769fd01d4996b2c2af5e915ca55", "url": "https://github.com/apache/kafka/commit/1ed3914fc618d769fd01d4996b2c2af5e915ca55", "message": "make maxCacheSize volatile and wrapped thread cache", "committedDate": "2020-11-18T17:27:57Z", "type": "commit"}, {"oid": "d7a3edb35789bcd28867a3312bbd2e3656d9a175", "url": "https://github.com/apache/kafka/commit/d7a3edb35789bcd28867a3312bbd2e3656d9a175", "message": "change to consumer", "committedDate": "2020-11-18T17:27:57Z", "type": "commit"}, {"oid": "53d92c5a7faed35d9771434d8d71777a3ceccf31", "url": "https://github.com/apache/kafka/commit/53d92c5a7faed35d9771434d8d71777a3ceccf31", "message": "improved names and checks", "committedDate": "2020-11-18T17:27:57Z", "type": "commit"}, {"oid": "c4b78e59ba44c1f0f84ffa4d5f484e8a07cf4081", "url": "https://github.com/apache/kafka/commit/c4b78e59ba44c1f0f84ffa4d5f484e8a07cf4081", "message": "couple of comments", "committedDate": "2020-11-18T17:29:47Z", "type": "commit"}, {"oid": "2698000507c8e675b247dc7dbbd3a60cbe39bbdf", "url": "https://github.com/apache/kafka/commit/2698000507c8e675b247dc7dbbd3a60cbe39bbdf", "message": "make helper for cache size", "committedDate": "2020-11-18T17:29:47Z", "type": "commit"}, {"oid": "26fb2a9c206178db3a248807c5f8fb114deb844f", "url": "https://github.com/apache/kafka/commit/26fb2a9c206178db3a248807c5f8fb114deb844f", "message": "remove this", "committedDate": "2020-11-18T17:29:47Z", "type": "commit"}, {"oid": "b69b6b256f77448097a144f5f9ef0e14fed1445f", "url": "https://github.com/apache/kafka/commit/b69b6b256f77448097a144f5f9ef0e14fed1445f", "message": "remove redundant check", "committedDate": "2020-11-18T17:29:48Z", "type": "commit"}]}