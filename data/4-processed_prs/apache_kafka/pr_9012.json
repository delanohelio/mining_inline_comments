{"pr_number": 9012, "pr_title": "KAFKA-10270: A broker to controller channel manager", "pr_createdAt": "2020-07-13T05:53:20Z", "pr_url": "https://github.com/apache/kafka/pull/9012", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxNTU4OA==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453815588", "bodyText": "Since take is blocking, do we need the peek call above? Actually, does InterBrokerSendThread expect generateRequests to block like this? Since it returns an iterable, I would guess that it doesn't. Maybe we should do something like:\nval topRequest = requestQueue.poll()\nif (topRequest != null) {\n   // ...\n}", "author": "mumrah", "createdAt": "2020-07-13T17:34:29Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.{BlockingQueue, LinkedBlockingQueue, TimeUnit}\n+\n+import kafka.common.{InterBrokerSendThread, RequestAndCompletionHandler}\n+import kafka.network.RequestChannel\n+import kafka.utils.Logging\n+import org.apache.kafka.clients._\n+import org.apache.kafka.common.requests.AbstractRequest\n+import org.apache.kafka.common.utils.{LogContext, Time}\n+import org.apache.kafka.common.Node\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.AbstractRequest.NoOpRequestBuilder\n+import org.apache.kafka.common.security.JaasContext\n+\n+import scala.collection.mutable\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * This class manages the connection between a broker and the controller. It runs a single\n+ * {@link BrokerToControllerRequestThread} which uses the broker's metadata cache as its own metadata to find\n+ * and connect to the controller. The channel is async and runs the network connection in the background.\n+ * The maximum number of in-flight requests are set to one to ensure orderly response from the controller, therefore\n+ * care must be taken to not block on outstanding requests for too long.\n+ */\n+class BrokerToControllerChannelManager(metadataCache: kafka.server.MetadataCache,\n+                                       time: Time,\n+                                       metrics: Metrics,\n+                                       config: KafkaConfig,\n+                                       threadNamePrefix: Option[String] = None) extends Logging {\n+  private val requestQueue = new LinkedBlockingQueue[BrokerToControllerQueueItem]\n+  private val logContext = new LogContext(s\"[broker-${config.brokerId}-to-controller] \")\n+  private val manualMetadataUpdater = new ManualMetadataUpdater()\n+  private val requestThread = newRequestThread\n+\n+  def start(): Unit = {\n+    requestThread.start()\n+  }\n+\n+  def shutdown(): Unit = {\n+    requestThread.shutdown()\n+    requestThread.awaitShutdown()\n+  }\n+\n+  private[server] def newRequestThread = {\n+    val brokerToControllerListenerName = config.controlPlaneListenerName.getOrElse(config.interBrokerListenerName)\n+    val brokerToControllerSecurityProtocol = config.controlPlaneSecurityProtocol.getOrElse(config.interBrokerSecurityProtocol)\n+\n+    val networkClient = {\n+      val channelBuilder = ChannelBuilders.clientChannelBuilder(\n+        brokerToControllerSecurityProtocol,\n+        JaasContext.Type.SERVER,\n+        config,\n+        brokerToControllerListenerName,\n+        config.saslMechanismInterBrokerProtocol,\n+        time,\n+        config.saslInterBrokerHandshakeRequestEnable,\n+        logContext\n+      )\n+      val selector = new Selector(\n+        NetworkReceive.UNLIMITED,\n+        Selector.NO_IDLE_TIMEOUT_MS,\n+        metrics,\n+        time,\n+        \"BrokerToControllerChannel\",\n+        Map(\"BrokerId\" -> config.brokerId.toString).asJava,\n+        false,\n+        channelBuilder,\n+        logContext\n+      )\n+      new NetworkClient(\n+        selector,\n+        manualMetadataUpdater,\n+        config.brokerId.toString,\n+        1,\n+        0,\n+        0,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        config.requestTimeoutMs,\n+        config.connectionSetupTimeoutMs,\n+        config.connectionSetupTimeoutMaxMs,\n+        ClientDnsLookup.DEFAULT,\n+        time,\n+        false,\n+        new ApiVersions,\n+        logContext\n+      )\n+    }\n+    val threadName = threadNamePrefix match {\n+      case None => s\"broker-${config.brokerId}-to-controller-send-thread\"\n+      case Some(name) => s\"$name:broker-${config.brokerId}-to-controller-send-thread\"\n+    }\n+\n+    new BrokerToControllerRequestThread(networkClient, manualMetadataUpdater, requestQueue, metadataCache, config,\n+      brokerToControllerListenerName, time, threadName)\n+  }\n+\n+  private[server] def sendRequest(request: RequestChannel.Request,\n+                                  callback: RequestCompletionHandler): Unit = {\n+    val requestBuilder = new NoOpRequestBuilder(request.context.header.apiKey, request.body[AbstractRequest])\n+    requestQueue.put(BrokerToControllerQueueItem(requestBuilder, callback, \"\"))\n+  }\n+\n+  private[server] def forwardRequest(originalRequest: RequestChannel.Request,\n+                                     callback: RequestCompletionHandler): Unit = {\n+    val requestBuilder = new NoOpRequestBuilder(originalRequest.context.header.apiKey, originalRequest.body[AbstractRequest])\n+    requestQueue.put(BrokerToControllerQueueItem(requestBuilder, callback, originalRequest.context.principal.getName))\n+  }\n+}\n+\n+case class BrokerToControllerQueueItem(request: AbstractRequest.Builder[_ <: AbstractRequest],\n+                                       callback: RequestCompletionHandler,\n+                                       initialPrincipalName: String)\n+\n+class BrokerToControllerRequestThread(networkClient: KafkaClient,\n+                                      metadataUpdater: ManualMetadataUpdater,\n+                                      requestQueue: BlockingQueue[BrokerToControllerQueueItem],\n+                                      metadataCache: kafka.server.MetadataCache,\n+                                      config: KafkaConfig,\n+                                      listenerName: ListenerName,\n+                                      time: Time,\n+                                      threadName: String)\n+  extends InterBrokerSendThread(threadName, networkClient, time, isInterruptible = false) {\n+\n+  private var activeController: Option[Node] = None\n+\n+  override def requestTimeoutMs: Int = config.controllerSocketTimeoutMs\n+\n+  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n+    val requestsToSend = new mutable.Queue[RequestAndCompletionHandler]\n+    if (requestQueue.peek() != null) {\n+      val topRequest = requestQueue.take()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4NTk4NA==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453885984", "bodyText": "@mumrah : I think you're right that we should not block here.\n@abbccdda: I don't think a blocking queue is the right abstraction here since we don't want to block.  How about just a lock and a list?", "author": "cmccabe", "createdAt": "2020-07-13T19:37:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxNTU4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU2MzExNw==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r457563117", "bodyText": "I think changing to poll should be suffice?", "author": "abbccdda", "createdAt": "2020-07-20T17:08:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxNTU4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxODk2Mg==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453818962", "bodyText": "Do we need anything in the broker to controller connection to be reconfigurable? Just wondering if we need a way to recreate this thread in cases where config changes", "author": "mumrah", "createdAt": "2020-07-13T17:40:20Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.{BlockingQueue, LinkedBlockingQueue, TimeUnit}\n+\n+import kafka.common.{InterBrokerSendThread, RequestAndCompletionHandler}\n+import kafka.network.RequestChannel\n+import kafka.utils.Logging\n+import org.apache.kafka.clients._\n+import org.apache.kafka.common.requests.AbstractRequest\n+import org.apache.kafka.common.utils.{LogContext, Time}\n+import org.apache.kafka.common.Node\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.AbstractRequest.NoOpRequestBuilder\n+import org.apache.kafka.common.security.JaasContext\n+\n+import scala.collection.mutable\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * This class manages the connection between a broker and the controller. It runs a single\n+ * {@link BrokerToControllerRequestThread} which uses the broker's metadata cache as its own metadata to find\n+ * and connect to the controller. The channel is async and runs the network connection in the background.\n+ * The maximum number of in-flight requests are set to one to ensure orderly response from the controller, therefore\n+ * care must be taken to not block on outstanding requests for too long.\n+ */\n+class BrokerToControllerChannelManager(metadataCache: kafka.server.MetadataCache,\n+                                       time: Time,\n+                                       metrics: Metrics,\n+                                       config: KafkaConfig,\n+                                       threadNamePrefix: Option[String] = None) extends Logging {\n+  private val requestQueue = new LinkedBlockingQueue[BrokerToControllerQueueItem]\n+  private val logContext = new LogContext(s\"[broker-${config.brokerId}-to-controller] \")\n+  private val manualMetadataUpdater = new ManualMetadataUpdater()\n+  private val requestThread = newRequestThread\n+\n+  def start(): Unit = {\n+    requestThread.start()\n+  }\n+\n+  def shutdown(): Unit = {\n+    requestThread.shutdown()\n+    requestThread.awaitShutdown()\n+  }\n+\n+  private[server] def newRequestThread = {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4NjE3MQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453886171", "bodyText": "It's a good question, but we can probably defer that until later....", "author": "cmccabe", "createdAt": "2020-07-13T19:37:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxODk2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDMzNDA2OQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r454334069", "bodyText": "sounds good", "author": "mumrah", "createdAt": "2020-07-14T12:54:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxODk2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAxMDk0OA==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r457010948", "bodyText": "+1", "author": "abbccdda", "createdAt": "2020-07-20T03:19:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgxODk2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3NTIxMg==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453875212", "bodyText": "it would be good to use the existing style of periods at the end to avoid a big change here", "author": "cmccabe", "createdAt": "2020-07-13T19:18:02Z", "path": "clients/src/main/java/org/apache/kafka/clients/ClientRequest.java", "diffHunk": "@@ -85,11 +89,12 @@ public ApiKeys apiKey() {\n     public RequestHeader makeHeader(short version) {\n         short requestApiKey = requestBuilder.apiKey().id;\n         return new RequestHeader(\n-            new RequestHeaderData().\n-                setRequestApiKey(requestApiKey).\n-                setRequestApiVersion(version).\n-                setClientId(clientId).\n-                setCorrelationId(correlationId),\n+            new RequestHeaderData()", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3NTMxMw==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453875313", "bodyText": "seems like a whitespace error here", "author": "cmccabe", "createdAt": "2020-07-13T19:18:15Z", "path": "clients/src/main/java/org/apache/kafka/clients/KafkaClient.java", "diffHunk": "@@ -186,16 +186,18 @@ ClientRequest newClientRequest(String nodeId, AbstractRequest.Builder<?> request\n      * @param createdTimeMs the time in milliseconds to use as the creation time of the request\n      * @param expectResponse true iff we expect a response\n      * @param requestTimeoutMs Upper bound time in milliseconds to await a response before disconnecting the socket and\n-     *                         cancelling the request. The request may get cancelled sooner if the socket disconnects\n-     *                         for any reason including if another pending request to the same node timed out first.\n+*                         cancelling the request. The request may get cancelled sooner if the socket disconnects", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3NTY4Mw==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453875683", "bodyText": "It seems like we only want this to be set when forwarding a request to the controller, right?  So the JavaDoc should discuss the fact that this can be null (or whatever the \"not set\" value is)", "author": "cmccabe", "createdAt": "2020-07-13T19:18:58Z", "path": "clients/src/main/java/org/apache/kafka/clients/KafkaClient.java", "diffHunk": "@@ -186,16 +186,18 @@ ClientRequest newClientRequest(String nodeId, AbstractRequest.Builder<?> request\n      * @param createdTimeMs the time in milliseconds to use as the creation time of the request\n      * @param expectResponse true iff we expect a response\n      * @param requestTimeoutMs Upper bound time in milliseconds to await a response before disconnecting the socket and\n-     *                         cancelling the request. The request may get cancelled sooner if the socket disconnects\n-     *                         for any reason including if another pending request to the same node timed out first.\n+*                         cancelling the request. The request may get cancelled sooner if the socket disconnects\n+*                         for any reason including if another pending request to the same node timed out first.\n      * @param callback the callback to invoke when we get a response\n+     * @param initialPrincipalName the initial client principal name, when building a forward request", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3NjU3MQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453876571", "bodyText": "I think it would be best to use null here as the \"not set\" value.  We never clearly articulated that the empty string is not valid for principals.", "author": "cmccabe", "createdAt": "2020-07-13T19:20:27Z", "path": "clients/src/main/java/org/apache/kafka/clients/NetworkClient.java", "diffHunk": "@@ -1199,7 +1199,7 @@ public ClientRequest newClientRequest(String nodeId,\n                                           AbstractRequest.Builder<?> requestBuilder,\n                                           long createdTimeMs,\n                                           boolean expectResponse) {\n-        return newClientRequest(nodeId, requestBuilder, createdTimeMs, expectResponse, defaultRequestTimeoutMs, null);\n+        return newClientRequest(nodeId, requestBuilder, createdTimeMs, expectResponse, defaultRequestTimeoutMs, null, \"\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3NzUyMg==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453877522", "bodyText": "\"NoOp\" doesn't seem quite right here since the builder isn't an operator.  Maybe \"pass through\" or \"simple\" ?", "author": "cmccabe", "createdAt": "2020-07-13T19:22:11Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractRequest.java", "diffHunk": "@@ -75,6 +75,19 @@ public T build() {\n         public abstract T build(short version);\n     }\n \n+    public static class NoOpRequestBuilder extends Builder<AbstractRequest> {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDMzMzI4Nw==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r454333287", "bodyText": "\"delegating\" builder?", "author": "mumrah", "createdAt": "2020-07-14T12:52:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3NzUyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3Nzg1Mg==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453877852", "bodyText": "Let's add an accessor here rather than making data fields public.", "author": "cmccabe", "createdAt": "2020-07-13T19:22:46Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/AlterConfigsResponse.java", "diffHunk": "@@ -29,7 +29,7 @@\n \n public class AlterConfigsResponse extends AbstractResponse {\n \n-    private final AlterConfigsResponseData data;\n+    public final AlterConfigsResponseData data;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3OTA5Mg==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453879092", "bodyText": "Why not just make all versions of the field nullable by setting a nullVersions: \"2+\"?", "author": "cmccabe", "createdAt": "2020-07-13T19:25:03Z", "path": "clients/src/main/resources/common/message/RequestHeader.json", "diffHunk": "@@ -37,6 +37,9 @@\n     // Since the client is sending the ApiVersionsRequest in order to discover what\n     // versions are supported, the client does not know the best version to use.\n     { \"name\": \"ClientId\", \"type\": \"string\", \"versions\": \"1+\", \"nullableVersions\": \"1+\", \"ignorable\": true,\n-      \"flexibleVersions\": \"none\", \"about\": \"The client ID string.\" }\n+      \"flexibleVersions\": \"none\", \"about\": \"The client ID string.\" },\n+    // Could not set default to null, because not all versions of this field are nullable.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5NTIyOQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453895229", "bodyText": "Sg!", "author": "abbccdda", "createdAt": "2020-07-13T19:55:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg3OTA5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4MzM1MA==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453883350", "bodyText": "This seems like a confusing comment.  How about \"forward the request to the controller for handling\"?\nAlso, we usually try to avoid return in KafkaApis unless it's really necessary.  I guess it's a Scala style thing.", "author": "cmccabe", "createdAt": "2020-07-13T19:32:23Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -2425,34 +2427,68 @@ class KafkaApis(val requestChannel: RequestChannel,\n \n   def handleAlterConfigsRequest(request: RequestChannel.Request): Unit = {\n     val alterConfigsRequest = request.body[AlterConfigsRequest]\n-    val (authorizedResources, unauthorizedResources) = alterConfigsRequest.configs.asScala.toMap.partition { case (resource, _) =>\n+    val requestResources = alterConfigsRequest.configs.asScala.toMap\n+\n+    def sendResponseCallback(results: Map[ConfigResource, ApiError]): Unit = {\n+      def responseCallback(requestThrottleMs: Int): AlterConfigsResponse = {\n+        val data = new AlterConfigsResponseData()\n+          .setThrottleTimeMs(requestThrottleMs)\n+        results.foreach { case (resource, error) =>\n+          data.responses().add(new AlterConfigsResourceResponse()\n+            .setErrorCode(error.error.code)\n+            .setErrorMessage(error.message)\n+            .setResourceName(resource.name)\n+            .setResourceType(resource.`type`.id))\n+        }\n+        new AlterConfigsResponse(data)\n+      }\n+      sendResponseMaybeThrottle(request, responseCallback)\n+    }\n+\n+    if (!controller.isActive) {\n+      // This is the original forwarded request which needs the handling.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4NDU4Ng==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453884586", "bodyText": "How about \"ControllerUplinkManager\" ?", "author": "cmccabe", "createdAt": "2020-07-13T19:34:52Z", "path": "core/src/main/scala/kafka/server/KafkaServer.scala", "diffHunk": "@@ -168,6 +168,8 @@ class KafkaServer(val config: KafkaConfig, time: Time = Time.SYSTEM, threadNameP\n \n   var kafkaController: KafkaController = null\n \n+  var brokerToControllerChannelManager: BrokerToControllerChannelManager = null", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5NTc2Nw==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r453895767", "bodyText": "Not sure it would be more self-explanatory than the current name.", "author": "abbccdda", "createdAt": "2020-07-13T19:56:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4NDU4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NTM5MQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r461885391", "bodyText": "ok.", "author": "cmccabe", "createdAt": "2020-07-28T21:18:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4NDU4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0MDQ4NQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r454340485", "bodyText": "If other requests are queued up, I think this could mess up the ordering.\nIf we have requests[A, B, C, D] in the requestQueue, and A popped off is sent out, and the controller channel is disconnected, we will then have a queue like [B, C, D, A]. I think we need strict ordering for controller requests, so we would need to handle this differently.\nMaybe if we used a deque for the request queue, we could fix this by putting a failed item at the head of the queue. That, or the doWork call would need to hold onto a queue item until it had succeeded or failed irrevocably. But, I would guess we shouldn't block too long in the doWork call.", "author": "mumrah", "createdAt": "2020-07-14T13:04:50Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.{BlockingQueue, LinkedBlockingQueue, TimeUnit}\n+\n+import kafka.common.{InterBrokerSendThread, RequestAndCompletionHandler}\n+import kafka.network.RequestChannel\n+import kafka.utils.Logging\n+import org.apache.kafka.clients._\n+import org.apache.kafka.common.requests.AbstractRequest\n+import org.apache.kafka.common.utils.{LogContext, Time}\n+import org.apache.kafka.common.Node\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.AbstractRequest.NoOpRequestBuilder\n+import org.apache.kafka.common.security.JaasContext\n+\n+import scala.collection.mutable\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * This class manages the connection between a broker and the controller. It runs a single\n+ * {@link BrokerToControllerRequestThread} which uses the broker's metadata cache as its own metadata to find\n+ * and connect to the controller. The channel is async and runs the network connection in the background.\n+ * The maximum number of in-flight requests are set to one to ensure orderly response from the controller, therefore\n+ * care must be taken to not block on outstanding requests for too long.\n+ */\n+class BrokerToControllerChannelManager(metadataCache: kafka.server.MetadataCache,\n+                                       time: Time,\n+                                       metrics: Metrics,\n+                                       config: KafkaConfig,\n+                                       threadNamePrefix: Option[String] = None) extends Logging {\n+  private val requestQueue = new LinkedBlockingQueue[BrokerToControllerQueueItem]\n+  private val logContext = new LogContext(s\"[broker-${config.brokerId}-to-controller] \")\n+  private val manualMetadataUpdater = new ManualMetadataUpdater()\n+  private val requestThread = newRequestThread\n+\n+  def start(): Unit = {\n+    requestThread.start()\n+  }\n+\n+  def shutdown(): Unit = {\n+    requestThread.shutdown()\n+    requestThread.awaitShutdown()\n+  }\n+\n+  private[server] def newRequestThread = {\n+    val brokerToControllerListenerName = config.controlPlaneListenerName.getOrElse(config.interBrokerListenerName)\n+    val brokerToControllerSecurityProtocol = config.controlPlaneSecurityProtocol.getOrElse(config.interBrokerSecurityProtocol)\n+\n+    val networkClient = {\n+      val channelBuilder = ChannelBuilders.clientChannelBuilder(\n+        brokerToControllerSecurityProtocol,\n+        JaasContext.Type.SERVER,\n+        config,\n+        brokerToControllerListenerName,\n+        config.saslMechanismInterBrokerProtocol,\n+        time,\n+        config.saslInterBrokerHandshakeRequestEnable,\n+        logContext\n+      )\n+      val selector = new Selector(\n+        NetworkReceive.UNLIMITED,\n+        Selector.NO_IDLE_TIMEOUT_MS,\n+        metrics,\n+        time,\n+        \"BrokerToControllerChannel\",\n+        Map(\"BrokerId\" -> config.brokerId.toString).asJava,\n+        false,\n+        channelBuilder,\n+        logContext\n+      )\n+      new NetworkClient(\n+        selector,\n+        manualMetadataUpdater,\n+        config.brokerId.toString,\n+        1,\n+        0,\n+        0,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        config.requestTimeoutMs,\n+        config.connectionSetupTimeoutMs,\n+        config.connectionSetupTimeoutMaxMs,\n+        ClientDnsLookup.DEFAULT,\n+        time,\n+        false,\n+        new ApiVersions,\n+        logContext\n+      )\n+    }\n+    val threadName = threadNamePrefix match {\n+      case None => s\"broker-${config.brokerId}-to-controller-send-thread\"\n+      case Some(name) => s\"$name:broker-${config.brokerId}-to-controller-send-thread\"\n+    }\n+\n+    new BrokerToControllerRequestThread(networkClient, manualMetadataUpdater, requestQueue, metadataCache, config,\n+      brokerToControllerListenerName, time, threadName)\n+  }\n+\n+  private[server] def sendRequest(request: RequestChannel.Request,\n+                                  callback: RequestCompletionHandler): Unit = {\n+    val requestBuilder = new NoOpRequestBuilder(request.context.header.apiKey, request.body[AbstractRequest])\n+    requestQueue.put(BrokerToControllerQueueItem(requestBuilder, callback, \"\"))\n+  }\n+\n+  private[server] def forwardRequest(originalRequest: RequestChannel.Request,\n+                                     callback: RequestCompletionHandler): Unit = {\n+    val requestBuilder = new NoOpRequestBuilder(originalRequest.context.header.apiKey, originalRequest.body[AbstractRequest])\n+    requestQueue.put(BrokerToControllerQueueItem(requestBuilder, callback, originalRequest.context.principal.getName))\n+  }\n+}\n+\n+case class BrokerToControllerQueueItem(request: AbstractRequest.Builder[_ <: AbstractRequest],\n+                                       callback: RequestCompletionHandler,\n+                                       initialPrincipalName: String)\n+\n+class BrokerToControllerRequestThread(networkClient: KafkaClient,\n+                                      metadataUpdater: ManualMetadataUpdater,\n+                                      requestQueue: BlockingQueue[BrokerToControllerQueueItem],\n+                                      metadataCache: kafka.server.MetadataCache,\n+                                      config: KafkaConfig,\n+                                      listenerName: ListenerName,\n+                                      time: Time,\n+                                      threadName: String)\n+  extends InterBrokerSendThread(threadName, networkClient, time, isInterruptible = false) {\n+\n+  private var activeController: Option[Node] = None\n+\n+  override def requestTimeoutMs: Int = config.controllerSocketTimeoutMs\n+\n+  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n+    val requestsToSend = new mutable.Queue[RequestAndCompletionHandler]\n+    if (requestQueue.peek() != null) {\n+      val topRequest = requestQueue.take()\n+\n+      val request = RequestAndCompletionHandler(\n+        activeController.get,\n+        topRequest.request,\n+        handleResponse(topRequest),\n+        topRequest.initialPrincipalName)\n+      requestsToSend.enqueue(request)\n+    }\n+    requestsToSend\n+  }\n+\n+  private[server] def handleResponse(request: BrokerToControllerQueueItem)(response: ClientResponse): Unit = {\n+    if (response.wasDisconnected()) {\n+      activeController = None\n+      requestQueue.put(request)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU2OTU4MA==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r457569580", "bodyText": "If active controller could not be detected, it also makes sense to block indefinitely I guess.", "author": "abbccdda", "createdAt": "2020-07-20T17:19:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0MDQ4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODM1Njc3Mg==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r458356772", "bodyText": "Replaced with LinkedBlockingDeque", "author": "abbccdda", "createdAt": "2020-07-21T20:07:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0MDQ4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0Mzg1Nw==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r454343857", "bodyText": "What exceptions can actually be captured here? It looks like InterBrokerSendThread will kill the JVM if it encounters any Throwable by throwing a FatalExitError (which won't be caught as an Exception).\nIt looks like IBST will handle disconnects by setting the disconnected flag in the ClientResponse (which we're checking up at L165)", "author": "mumrah", "createdAt": "2020-07-14T13:10:09Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.{BlockingQueue, LinkedBlockingQueue, TimeUnit}\n+\n+import kafka.common.{InterBrokerSendThread, RequestAndCompletionHandler}\n+import kafka.network.RequestChannel\n+import kafka.utils.Logging\n+import org.apache.kafka.clients._\n+import org.apache.kafka.common.requests.AbstractRequest\n+import org.apache.kafka.common.utils.{LogContext, Time}\n+import org.apache.kafka.common.Node\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.AbstractRequest.NoOpRequestBuilder\n+import org.apache.kafka.common.security.JaasContext\n+\n+import scala.collection.mutable\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * This class manages the connection between a broker and the controller. It runs a single\n+ * {@link BrokerToControllerRequestThread} which uses the broker's metadata cache as its own metadata to find\n+ * and connect to the controller. The channel is async and runs the network connection in the background.\n+ * The maximum number of in-flight requests are set to one to ensure orderly response from the controller, therefore\n+ * care must be taken to not block on outstanding requests for too long.\n+ */\n+class BrokerToControllerChannelManager(metadataCache: kafka.server.MetadataCache,\n+                                       time: Time,\n+                                       metrics: Metrics,\n+                                       config: KafkaConfig,\n+                                       threadNamePrefix: Option[String] = None) extends Logging {\n+  private val requestQueue = new LinkedBlockingQueue[BrokerToControllerQueueItem]\n+  private val logContext = new LogContext(s\"[broker-${config.brokerId}-to-controller] \")\n+  private val manualMetadataUpdater = new ManualMetadataUpdater()\n+  private val requestThread = newRequestThread\n+\n+  def start(): Unit = {\n+    requestThread.start()\n+  }\n+\n+  def shutdown(): Unit = {\n+    requestThread.shutdown()\n+    requestThread.awaitShutdown()\n+  }\n+\n+  private[server] def newRequestThread = {\n+    val brokerToControllerListenerName = config.controlPlaneListenerName.getOrElse(config.interBrokerListenerName)\n+    val brokerToControllerSecurityProtocol = config.controlPlaneSecurityProtocol.getOrElse(config.interBrokerSecurityProtocol)\n+\n+    val networkClient = {\n+      val channelBuilder = ChannelBuilders.clientChannelBuilder(\n+        brokerToControllerSecurityProtocol,\n+        JaasContext.Type.SERVER,\n+        config,\n+        brokerToControllerListenerName,\n+        config.saslMechanismInterBrokerProtocol,\n+        time,\n+        config.saslInterBrokerHandshakeRequestEnable,\n+        logContext\n+      )\n+      val selector = new Selector(\n+        NetworkReceive.UNLIMITED,\n+        Selector.NO_IDLE_TIMEOUT_MS,\n+        metrics,\n+        time,\n+        \"BrokerToControllerChannel\",\n+        Map(\"BrokerId\" -> config.brokerId.toString).asJava,\n+        false,\n+        channelBuilder,\n+        logContext\n+      )\n+      new NetworkClient(\n+        selector,\n+        manualMetadataUpdater,\n+        config.brokerId.toString,\n+        1,\n+        0,\n+        0,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        config.requestTimeoutMs,\n+        config.connectionSetupTimeoutMs,\n+        config.connectionSetupTimeoutMaxMs,\n+        ClientDnsLookup.DEFAULT,\n+        time,\n+        false,\n+        new ApiVersions,\n+        logContext\n+      )\n+    }\n+    val threadName = threadNamePrefix match {\n+      case None => s\"broker-${config.brokerId}-to-controller-send-thread\"\n+      case Some(name) => s\"$name:broker-${config.brokerId}-to-controller-send-thread\"\n+    }\n+\n+    new BrokerToControllerRequestThread(networkClient, manualMetadataUpdater, requestQueue, metadataCache, config,\n+      brokerToControllerListenerName, time, threadName)\n+  }\n+\n+  private[server] def sendRequest(request: RequestChannel.Request,\n+                                  callback: RequestCompletionHandler): Unit = {\n+    val requestBuilder = new NoOpRequestBuilder(request.context.header.apiKey, request.body[AbstractRequest])\n+    requestQueue.put(BrokerToControllerQueueItem(requestBuilder, callback, \"\"))\n+  }\n+\n+  private[server] def forwardRequest(originalRequest: RequestChannel.Request,\n+                                     callback: RequestCompletionHandler): Unit = {\n+    val requestBuilder = new NoOpRequestBuilder(originalRequest.context.header.apiKey, originalRequest.body[AbstractRequest])\n+    requestQueue.put(BrokerToControllerQueueItem(requestBuilder, callback, originalRequest.context.principal.getName))\n+  }\n+}\n+\n+case class BrokerToControllerQueueItem(request: AbstractRequest.Builder[_ <: AbstractRequest],\n+                                       callback: RequestCompletionHandler,\n+                                       initialPrincipalName: String)\n+\n+class BrokerToControllerRequestThread(networkClient: KafkaClient,\n+                                      metadataUpdater: ManualMetadataUpdater,\n+                                      requestQueue: BlockingQueue[BrokerToControllerQueueItem],\n+                                      metadataCache: kafka.server.MetadataCache,\n+                                      config: KafkaConfig,\n+                                      listenerName: ListenerName,\n+                                      time: Time,\n+                                      threadName: String)\n+  extends InterBrokerSendThread(threadName, networkClient, time, isInterruptible = false) {\n+\n+  private var activeController: Option[Node] = None\n+\n+  override def requestTimeoutMs: Int = config.controllerSocketTimeoutMs\n+\n+  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n+    val requestsToSend = new mutable.Queue[RequestAndCompletionHandler]\n+    if (requestQueue.peek() != null) {\n+      val topRequest = requestQueue.take()\n+\n+      val request = RequestAndCompletionHandler(\n+        activeController.get,\n+        topRequest.request,\n+        handleResponse(topRequest),\n+        topRequest.initialPrincipalName)\n+      requestsToSend.enqueue(request)\n+    }\n+    requestsToSend\n+  }\n+\n+  private[server] def handleResponse(request: BrokerToControllerQueueItem)(response: ClientResponse): Unit = {\n+    if (response.wasDisconnected()) {\n+      activeController = None\n+      requestQueue.put(request)\n+    } else if (response.responseBody().errorCounts().containsKey(Errors.NOT_CONTROLLER)) {\n+      // just close the controller connection and wait for metadata cache update in doWork\n+      networkClient.close(activeController.get.idString)\n+      activeController = None\n+      requestQueue.put(request)\n+    } else {\n+      request.callback.onComplete(response)\n+    }\n+  }\n+\n+  private[server] def backoff(): Unit = pause(100, TimeUnit.MILLISECONDS)\n+\n+  override def doWork(): Unit = {\n+    try {\n+      if (activeController.isDefined) {\n+        super.doWork()\n+      } else {\n+        debug(\"Controller isn't cached, looking for local metadata changes\")\n+        val controllerOpt = metadataCache.getControllerId.flatMap(metadataCache.getAliveBroker)\n+        if (controllerOpt.isDefined) {\n+          if (activeController.isEmpty || activeController.exists(_.id != controllerOpt.get.id))\n+            info(s\"Recorded new controller, from now on will use broker ${controllerOpt.get.id}\")\n+          activeController = Option(controllerOpt.get.node(listenerName))\n+          metadataUpdater.setNodes(metadataCache.getAliveBrokers.map(_.node(listenerName)).asJava)\n+        } else {\n+          // need to backoff to avoid tight loops\n+          debug(\"No controller defined in metadata cache, retrying after backoff\")\n+          backoff()\n+        }\n+      }\n+    } catch {\n+      case e: Exception =>", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU2OTE1NQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r457569155", "bodyText": "I'm neutral to do a full exception catch here, if the underlying thread was trying to kill the entire broker proactively. The path for undefined controller in the try block should not trigger any exception in theory, so it makes sense to just throw IMHO.", "author": "abbccdda", "createdAt": "2020-07-20T17:18:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0Mzg1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODM1Njg5MQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r458356891", "bodyText": "Removed the try-catch", "author": "abbccdda", "createdAt": "2020-07-21T20:07:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0Mzg1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0NjgxMA==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r454346810", "bodyText": "Maybe an exponential backoff instead of constant?", "author": "mumrah", "createdAt": "2020-07-14T13:14:54Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.{BlockingQueue, LinkedBlockingQueue, TimeUnit}\n+\n+import kafka.common.{InterBrokerSendThread, RequestAndCompletionHandler}\n+import kafka.network.RequestChannel\n+import kafka.utils.Logging\n+import org.apache.kafka.clients._\n+import org.apache.kafka.common.requests.AbstractRequest\n+import org.apache.kafka.common.utils.{LogContext, Time}\n+import org.apache.kafka.common.Node\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.AbstractRequest.NoOpRequestBuilder\n+import org.apache.kafka.common.security.JaasContext\n+\n+import scala.collection.mutable\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * This class manages the connection between a broker and the controller. It runs a single\n+ * {@link BrokerToControllerRequestThread} which uses the broker's metadata cache as its own metadata to find\n+ * and connect to the controller. The channel is async and runs the network connection in the background.\n+ * The maximum number of in-flight requests are set to one to ensure orderly response from the controller, therefore\n+ * care must be taken to not block on outstanding requests for too long.\n+ */\n+class BrokerToControllerChannelManager(metadataCache: kafka.server.MetadataCache,\n+                                       time: Time,\n+                                       metrics: Metrics,\n+                                       config: KafkaConfig,\n+                                       threadNamePrefix: Option[String] = None) extends Logging {\n+  private val requestQueue = new LinkedBlockingQueue[BrokerToControllerQueueItem]\n+  private val logContext = new LogContext(s\"[broker-${config.brokerId}-to-controller] \")\n+  private val manualMetadataUpdater = new ManualMetadataUpdater()\n+  private val requestThread = newRequestThread\n+\n+  def start(): Unit = {\n+    requestThread.start()\n+  }\n+\n+  def shutdown(): Unit = {\n+    requestThread.shutdown()\n+    requestThread.awaitShutdown()\n+  }\n+\n+  private[server] def newRequestThread = {\n+    val brokerToControllerListenerName = config.controlPlaneListenerName.getOrElse(config.interBrokerListenerName)\n+    val brokerToControllerSecurityProtocol = config.controlPlaneSecurityProtocol.getOrElse(config.interBrokerSecurityProtocol)\n+\n+    val networkClient = {\n+      val channelBuilder = ChannelBuilders.clientChannelBuilder(\n+        brokerToControllerSecurityProtocol,\n+        JaasContext.Type.SERVER,\n+        config,\n+        brokerToControllerListenerName,\n+        config.saslMechanismInterBrokerProtocol,\n+        time,\n+        config.saslInterBrokerHandshakeRequestEnable,\n+        logContext\n+      )\n+      val selector = new Selector(\n+        NetworkReceive.UNLIMITED,\n+        Selector.NO_IDLE_TIMEOUT_MS,\n+        metrics,\n+        time,\n+        \"BrokerToControllerChannel\",\n+        Map(\"BrokerId\" -> config.brokerId.toString).asJava,\n+        false,\n+        channelBuilder,\n+        logContext\n+      )\n+      new NetworkClient(\n+        selector,\n+        manualMetadataUpdater,\n+        config.brokerId.toString,\n+        1,\n+        0,\n+        0,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        config.requestTimeoutMs,\n+        config.connectionSetupTimeoutMs,\n+        config.connectionSetupTimeoutMaxMs,\n+        ClientDnsLookup.DEFAULT,\n+        time,\n+        false,\n+        new ApiVersions,\n+        logContext\n+      )\n+    }\n+    val threadName = threadNamePrefix match {\n+      case None => s\"broker-${config.brokerId}-to-controller-send-thread\"\n+      case Some(name) => s\"$name:broker-${config.brokerId}-to-controller-send-thread\"\n+    }\n+\n+    new BrokerToControllerRequestThread(networkClient, manualMetadataUpdater, requestQueue, metadataCache, config,\n+      brokerToControllerListenerName, time, threadName)\n+  }\n+\n+  private[server] def sendRequest(request: RequestChannel.Request,\n+                                  callback: RequestCompletionHandler): Unit = {\n+    val requestBuilder = new NoOpRequestBuilder(request.context.header.apiKey, request.body[AbstractRequest])\n+    requestQueue.put(BrokerToControllerQueueItem(requestBuilder, callback, \"\"))\n+  }\n+\n+  private[server] def forwardRequest(originalRequest: RequestChannel.Request,\n+                                     callback: RequestCompletionHandler): Unit = {\n+    val requestBuilder = new NoOpRequestBuilder(originalRequest.context.header.apiKey, originalRequest.body[AbstractRequest])\n+    requestQueue.put(BrokerToControllerQueueItem(requestBuilder, callback, originalRequest.context.principal.getName))\n+  }\n+}\n+\n+case class BrokerToControllerQueueItem(request: AbstractRequest.Builder[_ <: AbstractRequest],\n+                                       callback: RequestCompletionHandler,\n+                                       initialPrincipalName: String)\n+\n+class BrokerToControllerRequestThread(networkClient: KafkaClient,\n+                                      metadataUpdater: ManualMetadataUpdater,\n+                                      requestQueue: BlockingQueue[BrokerToControllerQueueItem],\n+                                      metadataCache: kafka.server.MetadataCache,\n+                                      config: KafkaConfig,\n+                                      listenerName: ListenerName,\n+                                      time: Time,\n+                                      threadName: String)\n+  extends InterBrokerSendThread(threadName, networkClient, time, isInterruptible = false) {\n+\n+  private var activeController: Option[Node] = None\n+\n+  override def requestTimeoutMs: Int = config.controllerSocketTimeoutMs\n+\n+  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n+    val requestsToSend = new mutable.Queue[RequestAndCompletionHandler]\n+    if (requestQueue.peek() != null) {\n+      val topRequest = requestQueue.take()\n+\n+      val request = RequestAndCompletionHandler(\n+        activeController.get,\n+        topRequest.request,\n+        handleResponse(topRequest),\n+        topRequest.initialPrincipalName)\n+      requestsToSend.enqueue(request)\n+    }\n+    requestsToSend\n+  }\n+\n+  private[server] def handleResponse(request: BrokerToControllerQueueItem)(response: ClientResponse): Unit = {\n+    if (response.wasDisconnected()) {\n+      activeController = None\n+      requestQueue.put(request)\n+    } else if (response.responseBody().errorCounts().containsKey(Errors.NOT_CONTROLLER)) {\n+      // just close the controller connection and wait for metadata cache update in doWork\n+      networkClient.close(activeController.get.idString)\n+      activeController = None\n+      requestQueue.put(request)\n+    } else {\n+      request.callback.onComplete(response)\n+    }\n+  }\n+\n+  private[server] def backoff(): Unit = pause(100, TimeUnit.MILLISECONDS)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAxMDc4OA==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r457010788", "bodyText": "Will consider adding it after #8421 lands", "author": "abbccdda", "createdAt": "2020-07-20T03:18:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM0NjgxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk5OTc3MQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r456999771", "bodyText": "We have switched this default everywhere else, right?", "author": "ijuma", "createdAt": "2020-07-20T02:43:59Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.{BlockingQueue, LinkedBlockingQueue, TimeUnit}\n+\n+import kafka.common.{InterBrokerSendThread, RequestAndCompletionHandler}\n+import kafka.network.RequestChannel\n+import kafka.utils.Logging\n+import org.apache.kafka.clients._\n+import org.apache.kafka.common.requests.AbstractRequest\n+import org.apache.kafka.common.utils.{LogContext, Time}\n+import org.apache.kafka.common.Node\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.AbstractRequest.NoOpRequestBuilder\n+import org.apache.kafka.common.security.JaasContext\n+\n+import scala.collection.mutable\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * This class manages the connection between a broker and the controller. It runs a single\n+ * {@link BrokerToControllerRequestThread} which uses the broker's metadata cache as its own metadata to find\n+ * and connect to the controller. The channel is async and runs the network connection in the background.\n+ * The maximum number of in-flight requests are set to one to ensure orderly response from the controller, therefore\n+ * care must be taken to not block on outstanding requests for too long.\n+ */\n+class BrokerToControllerChannelManager(metadataCache: kafka.server.MetadataCache,\n+                                       time: Time,\n+                                       metrics: Metrics,\n+                                       config: KafkaConfig,\n+                                       threadNamePrefix: Option[String] = None) extends Logging {\n+  private val requestQueue = new LinkedBlockingQueue[BrokerToControllerQueueItem]\n+  private val logContext = new LogContext(s\"[broker-${config.brokerId}-to-controller] \")\n+  private val manualMetadataUpdater = new ManualMetadataUpdater()\n+  private val requestThread = newRequestThread\n+\n+  def start(): Unit = {\n+    requestThread.start()\n+  }\n+\n+  def shutdown(): Unit = {\n+    requestThread.shutdown()\n+    requestThread.awaitShutdown()\n+  }\n+\n+  private[server] def newRequestThread = {\n+    val brokerToControllerListenerName = config.controlPlaneListenerName.getOrElse(config.interBrokerListenerName)\n+    val brokerToControllerSecurityProtocol = config.controlPlaneSecurityProtocol.getOrElse(config.interBrokerSecurityProtocol)\n+\n+    val networkClient = {\n+      val channelBuilder = ChannelBuilders.clientChannelBuilder(\n+        brokerToControllerSecurityProtocol,\n+        JaasContext.Type.SERVER,\n+        config,\n+        brokerToControllerListenerName,\n+        config.saslMechanismInterBrokerProtocol,\n+        time,\n+        config.saslInterBrokerHandshakeRequestEnable,\n+        logContext\n+      )\n+      val selector = new Selector(\n+        NetworkReceive.UNLIMITED,\n+        Selector.NO_IDLE_TIMEOUT_MS,\n+        metrics,\n+        time,\n+        \"BrokerToControllerChannel\",\n+        Map(\"BrokerId\" -> config.brokerId.toString).asJava,\n+        false,\n+        channelBuilder,\n+        logContext\n+      )\n+      new NetworkClient(\n+        selector,\n+        manualMetadataUpdater,\n+        config.brokerId.toString,\n+        1,\n+        0,\n+        0,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        config.requestTimeoutMs,\n+        config.connectionSetupTimeoutMs,\n+        config.connectionSetupTimeoutMaxMs,\n+        ClientDnsLookup.DEFAULT,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzAxNTU1Mg==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r457015552", "bodyText": "Actually I'm not fully aware of a proper value for this field, how do we actually determine it?", "author": "abbccdda", "createdAt": "2020-07-20T03:31:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk5OTc3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NDk2MQ==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r461884961", "bodyText": "@abbccdda : Please switch this to ClientDnsLookup.USE_ALL_DNS_IPS to be consistent with the other NetworkClients, such as the one in ControllerChannelManager, etc.", "author": "cmccabe", "createdAt": "2020-07-28T21:17:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Njk5OTc3MQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "cfc3da339c68ab50bdf390439bef378b84939571", "url": "https://github.com/apache/kafka/commit/cfc3da339c68ab50bdf390439bef378b84939571", "message": "Add a broker to controller channel manager\n\nCo-authored-by: Viktor Somogyi <viktorsomogyi@gmail.com>\nCo-authored-by: Boyang Chen <boyang@confluent.io>", "committedDate": "2020-07-28T22:36:40Z", "type": "commit"}, {"oid": "5178db595a0b2f62db826e7a3c511eb4d28b7d72", "url": "https://github.com/apache/kafka/commit/5178db595a0b2f62db826e7a3c511eb4d28b7d72", "message": "address Colin's comment", "committedDate": "2020-07-28T22:37:38Z", "type": "commit"}, {"oid": "5178db595a0b2f62db826e7a3c511eb4d28b7d72", "url": "https://github.com/apache/kafka/commit/5178db595a0b2f62db826e7a3c511eb4d28b7d72", "message": "address Colin's comment", "committedDate": "2020-07-28T22:37:38Z", "type": "forcePushed"}, {"oid": "1ba296669a410df32b536b63804edf8369f1b96c", "url": "https://github.com/apache/kafka/commit/1ba296669a410df32b536b63804edf8369f1b96c", "message": "remove initial principal name", "committedDate": "2020-07-29T00:30:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM1MjY4Mg==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r462352682", "bodyText": "Even though it won't be hit (since we just have a single thread accessing this queue) there's still a race between peek and poll. I think we should just use poll and do the null test on that result.", "author": "mumrah", "createdAt": "2020-07-29T14:40:40Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.{LinkedBlockingDeque, TimeUnit}\n+\n+import kafka.common.{InterBrokerSendThread, RequestAndCompletionHandler}\n+import kafka.utils.Logging\n+import org.apache.kafka.clients._\n+import org.apache.kafka.common.requests.AbstractRequest\n+import org.apache.kafka.common.utils.{LogContext, Time}\n+import org.apache.kafka.common.Node\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.security.JaasContext\n+\n+import scala.collection.mutable\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * This class manages the connection between a broker and the controller. It runs a single\n+ * {@link BrokerToControllerRequestThread} which uses the broker's metadata cache as its own metadata to find\n+ * and connect to the controller. The channel is async and runs the network connection in the background.\n+ * The maximum number of in-flight requests are set to one to ensure orderly response from the controller, therefore\n+ * care must be taken to not block on outstanding requests for too long.\n+ */\n+class BrokerToControllerChannelManager(metadataCache: kafka.server.MetadataCache,\n+                                       time: Time,\n+                                       metrics: Metrics,\n+                                       config: KafkaConfig,\n+                                       threadNamePrefix: Option[String] = None) extends Logging {\n+  private val requestQueue = new LinkedBlockingDeque[BrokerToControllerQueueItem]\n+  private val logContext = new LogContext(s\"[broker-${config.brokerId}-to-controller] \")\n+  private val manualMetadataUpdater = new ManualMetadataUpdater()\n+  private val requestThread = newRequestThread\n+\n+  def start(): Unit = {\n+    requestThread.start()\n+  }\n+\n+  def shutdown(): Unit = {\n+    requestThread.shutdown()\n+    requestThread.awaitShutdown()\n+  }\n+\n+  private[server] def newRequestThread = {\n+    val brokerToControllerListenerName = config.controlPlaneListenerName.getOrElse(config.interBrokerListenerName)\n+    val brokerToControllerSecurityProtocol = config.controlPlaneSecurityProtocol.getOrElse(config.interBrokerSecurityProtocol)\n+\n+    val networkClient = {\n+      val channelBuilder = ChannelBuilders.clientChannelBuilder(\n+        brokerToControllerSecurityProtocol,\n+        JaasContext.Type.SERVER,\n+        config,\n+        brokerToControllerListenerName,\n+        config.saslMechanismInterBrokerProtocol,\n+        time,\n+        config.saslInterBrokerHandshakeRequestEnable,\n+        logContext\n+      )\n+      val selector = new Selector(\n+        NetworkReceive.UNLIMITED,\n+        Selector.NO_IDLE_TIMEOUT_MS,\n+        metrics,\n+        time,\n+        \"BrokerToControllerChannel\",\n+        Map(\"BrokerId\" -> config.brokerId.toString).asJava,\n+        false,\n+        channelBuilder,\n+        logContext\n+      )\n+      new NetworkClient(\n+        selector,\n+        manualMetadataUpdater,\n+        config.brokerId.toString,\n+        1,\n+        0,\n+        0,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        Selectable.USE_DEFAULT_BUFFER_SIZE,\n+        config.requestTimeoutMs,\n+        config.connectionSetupTimeoutMs,\n+        config.connectionSetupTimeoutMaxMs,\n+        ClientDnsLookup.USE_ALL_DNS_IPS,\n+        time,\n+        false,\n+        new ApiVersions,\n+        logContext\n+      )\n+    }\n+    val threadName = threadNamePrefix match {\n+      case None => s\"broker-${config.brokerId}-to-controller-send-thread\"\n+      case Some(name) => s\"$name:broker-${config.brokerId}-to-controller-send-thread\"\n+    }\n+\n+    new BrokerToControllerRequestThread(networkClient, manualMetadataUpdater, requestQueue, metadataCache, config,\n+      brokerToControllerListenerName, time, threadName)\n+  }\n+\n+  private[server] def sendRequest(request: AbstractRequest.Builder[_ <: AbstractRequest],\n+                                  callback: RequestCompletionHandler): Unit = {\n+    requestQueue.put(BrokerToControllerQueueItem(request, callback))\n+  }\n+}\n+\n+case class BrokerToControllerQueueItem(request: AbstractRequest.Builder[_ <: AbstractRequest],\n+                                       callback: RequestCompletionHandler)\n+\n+class BrokerToControllerRequestThread(networkClient: KafkaClient,\n+                                      metadataUpdater: ManualMetadataUpdater,\n+                                      requestQueue: LinkedBlockingDeque[BrokerToControllerQueueItem],\n+                                      metadataCache: kafka.server.MetadataCache,\n+                                      config: KafkaConfig,\n+                                      listenerName: ListenerName,\n+                                      time: Time,\n+                                      threadName: String)\n+  extends InterBrokerSendThread(threadName, networkClient, time, isInterruptible = false) {\n+\n+  private var activeController: Option[Node] = None\n+\n+  override def requestTimeoutMs: Int = config.controllerSocketTimeoutMs\n+\n+  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n+    val requestsToSend = new mutable.Queue[RequestAndCompletionHandler]\n+    if (requestQueue.peek() != null) {", "originalCommit": "1ba296669a410df32b536b63804edf8369f1b96c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM4NTM2MA==", "url": "https://github.com/apache/kafka/pull/9012#discussion_r462385360", "bodyText": "agreed.", "author": "cmccabe", "createdAt": "2020-07-29T15:24:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM1MjY4Mg=="}], "type": "inlineReview"}, {"oid": "66a3d65dc84f0b98379fc5955201922ce4f01112", "url": "https://github.com/apache/kafka/commit/66a3d65dc84f0b98379fc5955201922ce4f01112", "message": "use pool only", "committedDate": "2020-07-29T16:09:27Z", "type": "commit"}]}