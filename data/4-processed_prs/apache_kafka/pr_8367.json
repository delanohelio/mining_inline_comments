{"pr_number": 8367, "pr_title": "KAFKA-9719: Streams with EOS-beta should fail fast for older brokers", "pr_createdAt": "2020-03-26T20:05:39Z", "pr_url": "https://github.com/apache/kafka/pull/8367", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MTE4OA==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398861188", "bodyText": "Just code cleanup", "author": "mjsax", "createdAt": "2020-03-26T20:11:58Z", "path": "streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java", "diffHunk": "@@ -86,29 +83,21 @@ public static void main(final String[] args) throws IOException {\n         builder.<String, String>stream(SOURCE_TOPIC).groupByKey(Grouped.with(stringSerde, stringSerde))\n             .count()\n             .toStream()\n-            .mapValues(new ValueMapper<Long, String>() {\n-                @Override\n-                public String apply(final Long value) {\n-                    return value.toString();\n-                }\n-            })\n+            .mapValues(Object::toString)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MTIzNA==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398861234", "bodyText": "Just code cleanup", "author": "mjsax", "createdAt": "2020-03-26T20:12:04Z", "path": "streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java", "diffHunk": "@@ -86,29 +83,21 @@ public static void main(final String[] args) throws IOException {\n         builder.<String, String>stream(SOURCE_TOPIC).groupByKey(Grouped.with(stringSerde, stringSerde))\n             .count()\n             .toStream()\n-            .mapValues(new ValueMapper<Long, String>() {\n-                @Override\n-                public String apply(final Long value) {\n-                    return value.toString();\n-                }\n-            })\n+            .mapValues(Object::toString)\n             .to(SINK_TOPIC);\n \n         final KafkaStreams streams = new KafkaStreams(builder.build(), streamsProperties);\n-        streams.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {\n-            @Override\n-            public void uncaughtException(final Thread t, final Throwable e) {\n-                Throwable cause = e;\n-                if (cause instanceof StreamsException) {\n-                    while (cause.getCause() != null) {\n-                        cause = cause.getCause();\n-                    }\n+        streams.setUncaughtExceptionHandler((t, e) -> {\n+            Throwable cause = e;\n+            if (cause instanceof StreamsException) {\n+                while (cause.getCause() != null) {\n+                    cause = cause.getCause();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MTUxMg==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398861512", "bodyText": "Switch from \"boolean\" flag to \"string\"", "author": "mjsax", "createdAt": "2020-03-26T20:12:35Z", "path": "tests/kafkatest/services/streams.py", "diffHunk": "@@ -396,11 +396,11 @@ def __init__(self, test_context, kafka):\n \n \n class StreamsBrokerCompatibilityService(StreamsTestBaseService):\n-    def __init__(self, test_context, kafka, eosEnabled):\n+    def __init__(self, test_context, kafka, processingMode):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4MTMyMw==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398881323", "bodyText": "Good call.", "author": "guozhangwang", "createdAt": "2020-03-26T20:47:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MTUxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MTk1OQ==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398861959", "bodyText": "Two tests overlap and one of them is redundant -- removing the redundant one as side cleanup", "author": "mjsax", "createdAt": "2020-03-26T20:13:29Z", "path": "tests/kafkatest/tests/streams/streams_broker_compatibility_test.py", "diffHunk": "@@ -27,9 +27,10 @@\n class StreamsBrokerCompatibility(Test):\n     \"\"\"\n     These tests validates that\n-    - Streams 0.11+ w/ EOS fails fast for older brokers 0.10.2 and 0.10.1\n-    - Streams 0.11+ w/o EOS works for older brokers 0.10.2 and 0.10.1\n-    - Streams fails fast for 0.10.0 brokers\n+    - Streams works for older brokers 0.11 (or newer)\n+    - Streams w/ EOS-alpha works for older brokers 0.11 (or newer)\n+    - Streams fails fast for older brokers 0.10.0, 0.10.2, and 0.10.1\n+    - Streams w/ EOS-beta fails fast for older brokers 2.4 or older", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg4MTQzNQ==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398881435", "bodyText": "+1", "author": "guozhangwang", "createdAt": "2020-03-26T20:47:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MTk1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MzIxMA==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398863210", "bodyText": "This is covered via test_fail_fast_on_incompatible_brokers that tests against 0.10.0, 0.10.1 and 0.10.2 already\nIn older KS versions, 0.10.1 and 0.10.2 where only not supported if EOS is used, but now those older brokers are not supported at all any longer, and thus, we can merge both tests.", "author": "mjsax", "createdAt": "2020-03-26T20:15:30Z", "path": "tests/kafkatest/tests/streams/streams_broker_compatibility_test.py", "diffHunk": "@@ -55,20 +56,28 @@ def setUp(self):\n         self.zk.start()\n \n    \n-    @parametrize(broker_version=str(LATEST_0_10_2))\n-    @parametrize(broker_version=str(LATEST_0_10_1))\n-    def test_fail_fast_on_incompatible_brokers_if_eos_enabled(self, broker_version):", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MzM3NA==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398863374", "bodyText": "ForEosAlpha", "author": "abbccdda", "createdAt": "2020-03-26T20:15:44Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java", "diffHunk": "@@ -477,7 +476,29 @@ public void testGetGlobalConsumerConfigsWithGlobalConsumerOverridenPrefix() {\n     public void shouldSetInternalLeaveGroupOnCloseConfigToFalseInConsumer() {\n         final StreamsConfig streamsConfig = new StreamsConfig(props);\n         final Map<String, Object> consumerConfigs = streamsConfig.getMainConsumerConfigs(groupId, clientId, threadIdx);\n-        assertThat(consumerConfigs.get(\"internal.leave.group.on.close\"), CoreMatchers.equalTo(false));\n+        assertThat(consumerConfigs.get(\"internal.leave.group.on.close\"), is(false));\n+    }\n+\n+    @Test\n+    public void shouldNotSetInternalThrowOnFetchStableOffsetUnsupportedConfigToFalseInConsumerForEosDisabled() {\n+        final Map<String, Object> consumerConfigs = streamsConfig.getMainConsumerConfigs(groupId, clientId, threadIdx);\n+        assertThat(consumerConfigs.get(\"internal.throw.on.fetch.stable.offset.unsupported\"), is(nullValue()));\n+    }\n+\n+    @Test\n+    public void shouldNotSetInternalThrowOnFetchStableOffsetUnsupportedConfigToFalseInConsumerForEosAlphsa() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2MzUyMw==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398863523", "bodyText": "This is an existing test (the diff is just weird)", "author": "mjsax", "createdAt": "2020-03-26T20:16:02Z", "path": "tests/kafkatest/tests/streams/streams_broker_compatibility_test.py", "diffHunk": "@@ -55,20 +56,28 @@ def setUp(self):\n         self.zk.start()\n \n    \n-    @parametrize(broker_version=str(LATEST_0_10_2))\n-    @parametrize(broker_version=str(LATEST_0_10_1))\n-    def test_fail_fast_on_incompatible_brokers_if_eos_enabled(self, broker_version):\n+    @parametrize(broker_version=str(LATEST_2_4))\n+    @parametrize(broker_version=str(LATEST_2_3))\n+    @parametrize(broker_version=str(LATEST_2_2))\n+    @parametrize(broker_version=str(LATEST_2_1))\n+    @parametrize(broker_version=str(LATEST_2_0))\n+    @parametrize(broker_version=str(LATEST_1_1))\n+    @parametrize(broker_version=str(LATEST_1_0))\n+    @parametrize(broker_version=str(LATEST_0_11_0))\n+    def test_compatible_brokers_eos_disabled(self, broker_version):", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODg2Mzk4Mw==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r398863983", "bodyText": "Add this new test as side cleanup -- not sure why we never tested EOS for older broker but only non-EOS?", "author": "mjsax", "createdAt": "2020-03-26T20:16:53Z", "path": "tests/kafkatest/tests/streams/streams_broker_compatibility_test.py", "diffHunk": "@@ -79,11 +88,11 @@ def test_fail_fast_on_incompatible_brokers_if_eos_enabled(self, broker_version):\n     @parametrize(broker_version=str(LATEST_1_1))\n     @parametrize(broker_version=str(LATEST_1_0))\n     @parametrize(broker_version=str(LATEST_0_11_0))\n-    def test_compatible_brokers_eos_disabled(self, broker_version):\n+    def test_compatible_brokers_eos_enabled(self, broker_version):", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a6d50466e5b0ff924f7c60218ef924139e6d4865", "url": "https://github.com/apache/kafka/commit/a6d50466e5b0ff924f7c60218ef924139e6d4865", "message": "KAFKA-9719: Streams with EOS-beta should fail fast for older brokers", "committedDate": "2020-03-27T19:13:24Z", "type": "commit"}, {"oid": "66a2ca7a22a458aa603cafbe2de930589c97db25", "url": "https://github.com/apache/kafka/commit/66a2ca7a22a458aa603cafbe2de930589c97db25", "message": "Github comments", "committedDate": "2020-03-27T19:13:24Z", "type": "commit"}, {"oid": "ef41d1a1c748b3930b4bf6175a015896eaefe962", "url": "https://github.com/apache/kafka/commit/ef41d1a1c748b3930b4bf6175a015896eaefe962", "message": "Ignore failing sytem test\nFix failing unit tests\nMinor improvement to system test", "committedDate": "2020-03-27T19:13:56Z", "type": "commit"}, {"oid": "ef41d1a1c748b3930b4bf6175a015896eaefe962", "url": "https://github.com/apache/kafka/commit/ef41d1a1c748b3930b4bf6175a015896eaefe962", "message": "Ignore failing sytem test\nFix failing unit tests\nMinor improvement to system test", "committedDate": "2020-03-27T19:13:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ5Mzc3OQ==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r399493779", "bodyText": "@guozhangwang New special log message for old brokers.", "author": "mjsax", "createdAt": "2020-03-27T19:28:48Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -511,6 +512,21 @@ public void run() {\n         } catch (final Exception e) {\n             // we have caught all Kafka related exceptions, and other runtime exceptions\n             // should be due to user application errors\n+\n+            if (e instanceof UnsupportedVersionException) {", "originalCommit": "ef41d1a1c748b3930b4bf6175a015896eaefe962", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ5NDExNg==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r399494116", "bodyText": "Smaller improvement: write input data with transactions, too.", "author": "mjsax", "createdAt": "2020-03-27T19:29:27Z", "path": "streams/src/test/java/org/apache/kafka/streams/tests/BrokerCompatibilityTest.java", "diffHunk": "@@ -86,43 +83,46 @@ public static void main(final String[] args) throws IOException {\n         builder.<String, String>stream(SOURCE_TOPIC).groupByKey(Grouped.with(stringSerde, stringSerde))\n             .count()\n             .toStream()\n-            .mapValues(new ValueMapper<Long, String>() {\n-                @Override\n-                public String apply(final Long value) {\n-                    return value.toString();\n-                }\n-            })\n+            .mapValues(Object::toString)\n             .to(SINK_TOPIC);\n \n         final KafkaStreams streams = new KafkaStreams(builder.build(), streamsProperties);\n-        streams.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {\n-            @Override\n-            public void uncaughtException(final Thread t, final Throwable e) {\n-                Throwable cause = e;\n-                if (cause instanceof StreamsException) {\n-                    while (cause.getCause() != null) {\n-                        cause = cause.getCause();\n-                    }\n+        streams.setUncaughtExceptionHandler((t, e) -> {\n+            Throwable cause = e;\n+            if (cause instanceof StreamsException) {\n+                while (cause.getCause() != null) {\n+                    cause = cause.getCause();\n                 }\n-                System.err.println(\"FATAL: An unexpected exception \" + cause);\n-                e.printStackTrace(System.err);\n-                System.err.flush();\n-                streams.close(Duration.ofSeconds(30));\n             }\n+            System.err.println(\"FATAL: An unexpected exception \" + cause);\n+            e.printStackTrace(System.err);\n+            System.err.flush();\n+            streams.close(Duration.ofSeconds(30));\n         });\n         System.out.println(\"start Kafka Streams\");\n         streams.start();\n \n+        final boolean eosEnabled = processingMode.startsWith(StreamsConfig.EXACTLY_ONCE);\n \n         System.out.println(\"send data\");\n         final Properties producerProperties = new Properties();\n         producerProperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafka);\n         producerProperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n         producerProperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n+        if (eosEnabled) {\n+            producerProperties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"broker-compatibility-producer-tx\");\n+        }", "originalCommit": "ef41d1a1c748b3930b4bf6175a015896eaefe962", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ5NDQ0Ng==", "url": "https://github.com/apache/kafka/pull/8367#discussion_r399494446", "bodyText": "We have only one broker in this test and want to test with EOS", "author": "mjsax", "createdAt": "2020-03-27T19:30:08Z", "path": "tests/kafkatest/tests/streams/streams_broker_compatibility_test.py", "diffHunk": "@@ -44,7 +46,11 @@ def __init__(self, test_context):\n                                   topics={\n                                       self.input: {'partitions': 1, 'replication-factor': 1},\n                                       self.output: {'partitions': 1, 'replication-factor': 1}\n-                                  })\n+                                  },\n+                                  server_prop_overides=[\n+                                      [\"transaction.state.log.replication.factor\", \"1\"],\n+                                      [\"transaction.state.log.min.isr\", \"1\"]\n+                                  ])", "originalCommit": "ef41d1a1c748b3930b4bf6175a015896eaefe962", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}