{"pr_number": 9368, "pr_title": "KAFKA-9274: Add timeout handling for state restore and StandbyTasks", "pr_createdAt": "2020-10-03T01:55:21Z", "pr_url": "https://github.com/apache/kafka/pull/9368", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEwNTU0NQ==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499105545", "bodyText": "We got this wrong in the original PR...", "author": "mjsax", "createdAt": "2020-10-03T01:55:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -694,7 +694,7 @@\n                     CommonClientConfigs.SECURITY_PROTOCOL_DOC)\n             .define(TASK_TIMEOUT_MS_CONFIG,\n                     Type.LONG,\n-                    Duration.ofSeconds(5L).toMillis(),\n+                    Duration.ofMinutes(5L).toMillis(),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcwMDEyMQ==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499700121", "bodyText": "Oops! Good catch.", "author": "vvcephei", "createdAt": "2020-10-05T15:50:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEwNTU0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEwNTYwNw==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499105607", "bodyText": "We want to use the logger of StreamTask or StandbyTask to get the proper log prefix; thus, we just pass it into this method.", "author": "mjsax", "createdAt": "2020-10-03T01:56:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -137,4 +146,48 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n         this.inputPartitions = topicPartitions;\n         topology.updateSourceTopics(nodeToSourceTopics);\n     }\n+\n+    @Override\n+    public void maybeInitTaskTimeoutOrThrow(final long currentWallClockMs,\n+                                            final TimeoutException timeoutException,\n+                                            final Logger log) throws StreamsException {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcwNzY4Nw==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499707687", "bodyText": "Sounds good. An alternative is to add an abstract Logger log() to AbstractTask's interface, which would make it clearer that the logger is still going to have the appropriate class name.", "author": "vvcephei", "createdAt": "2020-10-05T16:01:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEwNTYwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEwNTc0MA==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499105740", "bodyText": "I added this, as for poll() we would not get a TimeoutException atm (even if I hold off to tackle poll() already)\nWe could also change this and assume that timeoutException is never null.", "author": "mjsax", "createdAt": "2020-10-03T01:57:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -137,4 +146,48 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n         this.inputPartitions = topicPartitions;\n         topology.updateSourceTopics(nodeToSourceTopics);\n     }\n+\n+    @Override\n+    public void maybeInitTaskTimeoutOrThrow(final long currentWallClockMs,\n+                                            final TimeoutException timeoutException,\n+                                            final Logger log) throws StreamsException {\n+        if (deadlineMs == NO_DEADLINE) {\n+            deadlineMs = currentWallClockMs + taskTimeoutMs;\n+        } else if (currentWallClockMs > deadlineMs) {\n+            final String errorMessage = String.format(\n+                \"Task %s did not make progress within %d ms. Adjust `%s` if needed.\",\n+                id,\n+                currentWallClockMs - deadlineMs + taskTimeoutMs,\n+                StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n+            );\n+\n+            if (timeoutException != null) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEwNTc1OQ==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499105759", "bodyText": "As we call this reset logic \"blindly\" we put this guard to avoid spamming the logs.", "author": "mjsax", "createdAt": "2020-10-03T01:58:27Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -137,4 +146,48 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n         this.inputPartitions = topicPartitions;\n         topology.updateSourceTopics(nodeToSourceTopics);\n     }\n+\n+    @Override\n+    public void maybeInitTaskTimeoutOrThrow(final long currentWallClockMs,\n+                                            final TimeoutException timeoutException,\n+                                            final Logger log) throws StreamsException {\n+        if (deadlineMs == NO_DEADLINE) {\n+            deadlineMs = currentWallClockMs + taskTimeoutMs;\n+        } else if (currentWallClockMs > deadlineMs) {\n+            final String errorMessage = String.format(\n+                \"Task %s did not make progress within %d ms. Adjust `%s` if needed.\",\n+                id,\n+                currentWallClockMs - deadlineMs + taskTimeoutMs,\n+                StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n+            );\n+\n+            if (timeoutException != null) {\n+                throw new TimeoutException(errorMessage, timeoutException);\n+            } else {\n+                throw new TimeoutException(errorMessage);\n+            }\n+        }\n+\n+        if (timeoutException != null) {\n+            log.debug(\n+                \"Timeout exception. Remaining time to deadline {}; retrying.\",\n+                deadlineMs - currentWallClockMs,\n+                timeoutException\n+            );\n+        } else {\n+            log.debug(\n+                \"Task did not make progress. Remaining time to deadline {}; retrying.\",\n+                deadlineMs - currentWallClockMs\n+            );\n+        }\n+\n+    }\n+\n+    @Override\n+    public void clearTaskTimeout(final Logger log) {\n+        if (deadlineMs != NO_DEADLINE) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEwNjEzNw==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499106137", "bodyText": "For the global-thread, we also consider the case that poll() returns nothing. For the global-thread it's a little simper though, as we restore on a per-partition basis.\nFor the StoreChangelogReader it's more complicated:\n\nfor StandbyTasks, there might be nothing to be restored and thus getting no records might be fine (however, the \"metadata\" is not easily available as it's encapsulated in other classes...\nfor active restoring tasks, it might be simpler...\n\nWas holding off, as I am not sure how important this case is, with regard to robustness. We would not crash for this case. I would still like to get this done, but not necessarily for 2.7 release though.", "author": "mjsax", "createdAt": "2020-10-03T02:03:19Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java", "diffHunk": "@@ -431,6 +432,9 @@ public void restore() {\n                 // in order to make sure we call the main consumer#poll in time.\n                 // TODO: once we move ChangelogReader to a separate thread this may no longer be a concern\n                 polledRecords = restoreConsumer.poll(state == ChangelogReaderState.STANDBY_UPDATING ? Duration.ZERO : pollTime);\n+\n+                // TODO (?) If we cannot fetch records during restore, should we trigger `task.timeout.ms` ?\n+                // TODO (?) If we cannot fetch records for standby task, should we trigger `task.timeout.ms` ?", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxNzIxOA==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499717218", "bodyText": "Thanks. I agree we can afford to leave this for future improvements.\nIt does seem like we should have some kind of improvement in the future, though. Having a restore or standby-update fail indefinitely would be just as damaging to an application's robustness as having the main consumer fail indefinitely.\nPerhaps we can make some improvements to the Consumer first, though, so that we don't have to do so much guesswork to distinguish between \"no records\" and \"no fetch\".", "author": "vvcephei", "createdAt": "2020-10-05T16:16:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTEwNjEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTcxMDIzMw==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499710233", "bodyText": "This is the wrong format for this log message. The exception won't be logged. You have to format the string first:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        log.debug(\n          \n          \n            \n                            \"Timeout exception. Remaining time to deadline {}; retrying.\",\n          \n          \n            \n                            deadlineMs - currentWallClockMs,\n          \n          \n            \n                            timeoutException\n          \n          \n            \n                        );\n          \n          \n            \n                        log.debug(\n          \n          \n            \n                            String.format(\"Timeout exception. Remaining time to deadline %d; retrying.\",\n          \n          \n            \n                            deadlineMs - currentWallClockMs),\n          \n          \n            \n                            timeoutException\n          \n          \n            \n                        );", "author": "vvcephei", "createdAt": "2020-10-05T16:05:13Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -137,4 +146,48 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n         this.inputPartitions = topicPartitions;\n         topology.updateSourceTopics(nodeToSourceTopics);\n     }\n+\n+    @Override\n+    public void maybeInitTaskTimeoutOrThrow(final long currentWallClockMs,\n+                                            final TimeoutException timeoutException,\n+                                            final Logger log) throws StreamsException {\n+        if (deadlineMs == NO_DEADLINE) {\n+            deadlineMs = currentWallClockMs + taskTimeoutMs;\n+        } else if (currentWallClockMs > deadlineMs) {\n+            final String errorMessage = String.format(\n+                \"Task %s did not make progress within %d ms. Adjust `%s` if needed.\",\n+                id,\n+                currentWallClockMs - deadlineMs + taskTimeoutMs,\n+                StreamsConfig.TASK_TIMEOUT_MS_CONFIG\n+            );\n+\n+            if (timeoutException != null) {\n+                throw new TimeoutException(errorMessage, timeoutException);\n+            } else {\n+                throw new TimeoutException(errorMessage);\n+            }\n+        }\n+\n+        if (timeoutException != null) {\n+            log.debug(\n+                \"Timeout exception. Remaining time to deadline {}; retrying.\",\n+                deadlineMs - currentWallClockMs,\n+                timeoutException\n+            );", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTgxMjU2NQ==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r499812565", "bodyText": "StreamsException is unchecked, right?\nIt's better to document unchecked exceptions in the @throws javadoc tag. The throws keyword is for telling the compiler that you want callers instead of yourself to handle a checked exception. I honestly have no idea why the java team chose to say \"this is poor style\" instead of just making it a compiler error, but that's the rationale. https://www.oracle.com/technical-resources/articles/java/javadoc-tool.html#throwstag", "author": "vvcephei", "createdAt": "2020-10-05T19:09:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -205,4 +207,9 @@ default boolean maybePunctuateSystemTime() {\n         return false;\n     }\n \n+    void maybeInitTaskTimeoutOrThrow(final long currentWallClockMs,\n+                                     final TimeoutException timeoutException,\n+                                     final Logger log) throws StreamsException;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMwNjA1NQ==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r501306055", "bodyText": "While the KIP itself only talks about TimeoutException there could be other causes for not making progress and thus we should be a little bit more general here.", "author": "mjsax", "createdAt": "2020-10-07T20:58:39Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -148,7 +148,7 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n     }\n \n     void maybeInitTaskTimeoutOrThrow(final long currentWallClockMs,\n-                                     final TimeoutException timeoutException,\n+                                     final Exception cause,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MjIyMA==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r504782220", "bodyText": "Sounds good!", "author": "vvcephei", "createdAt": "2020-10-14T15:42:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMwNjA1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMwNzc0Mw==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r501307743", "bodyText": "Here, we could also get different exceptions in addition to TimeoutException that we should just handle in the same way?\nNot sure about InterruptedException? Should this ever be thrown? Would it indicate a bug and we should just die?", "author": "mjsax", "createdAt": "2020-10-07T21:01:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java", "diffHunk": "@@ -625,11 +670,16 @@ private void restoreChangelog(final ChangelogMetadata changelogMetadata) {\n                     partitions.stream().collect(Collectors.toMap(Function.identity(), tp -> OffsetSpec.latest())),\n                     new ListOffsetsOptions(IsolationLevel.READ_UNCOMMITTED)\n             );\n-            return result.all().get().entrySet().stream().collect(\n-                    Collectors.toMap(Map.Entry::getKey, entry -> entry.getValue().offset()));\n-        } catch (final TimeoutException | InterruptedException | ExecutionException e) {\n-            // if timeout exception gets thrown we just give up this time and retry in the next run loop\n+\n+            final Map<TopicPartition,  ListOffsetsResult.ListOffsetsResultInfo> resultPerPartition = result.all().get();\n+            clearTaskTimeout(getTasksFromPartitions(tasks, partitions));\n+\n+            return resultPerPartition.entrySet().stream().collect(\n+                    Collectors.toMap(Map.Entry::getKey, entry -> entry.getValue().offset())\n+            );\n+        } catch (final TimeoutException | InterruptedException | ExecutionException retriableException) {\n             log.debug(\"Could not fetch all end offsets for {}, will retry in the next run loop\", partitions);\n+            maybeInitTaskTimeoutOrThrow(getTasksFromPartitions(tasks, partitions), retriableException);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e9246df2bf829e8bee4180bdd7498c674c50c832", "url": "https://github.com/apache/kafka/commit/e9246df2bf829e8bee4180bdd7498c674c50c832", "message": "KAFKA-9274: Add timeout handling for state restore and StandbyTasks\n - part of KIP-572", "committedDate": "2020-10-14T01:37:44Z", "type": "commit"}, {"oid": "e9246df2bf829e8bee4180bdd7498c674c50c832", "url": "https://github.com/apache/kafka/commit/e9246df2bf829e8bee4180bdd7498c674c50c832", "message": "KAFKA-9274: Add timeout handling for state restore and StandbyTasks\n - part of KIP-572", "committedDate": "2020-10-14T01:37:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc4MTY5OQ==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r504781699", "bodyText": "It seems like we ought to just define log at the AbstractTask level and avoid having two almost identical maybeInitTaskTimeoutOrThrow method definitions.", "author": "vvcephei", "createdAt": "2020-10-14T15:42:11Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -147,9 +147,12 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n         topology.updateSourceTopics(nodeToSourceTopics);\n     }\n \n+    /**\n+     * @throws TimeoutException if {@code currentWallClockMs > task-timeout-deadline}\n+     */\n     void maybeInitTaskTimeoutOrThrow(final long currentWallClockMs,\n-                                     final TimeoutException timeoutException,\n-                                     final Logger log) throws StreamsException {\n+                                     final Exception cause,\n+                                     final Logger log) {", "originalCommit": "e9246df2bf829e8bee4180bdd7498c674c50c832", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc5MjM2NA==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r504792364", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    log.debug(\"Could not complete restoration for {} due to {}; will retry\", task.id(), timeoutException);\n          \n          \n            \n                                    log.debug(String.format(\"Could not complete restoration for %s; will retry\", task.id()), timeoutException);\n          \n      \n    \n    \n  \n\nIt might be a good idea to add tests for the log messages so we can tell if they're actually properly formatted or not. Hopefully, the log4j upgrade makes it easier to detect these logging bugs.", "author": "vvcephei", "createdAt": "2020-10-14T15:56:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -482,8 +486,10 @@ boolean tryToCompleteRestoration() {\n                 if (restored.containsAll(task.changelogPartitions())) {\n                     try {\n                         task.completeRestoration();\n-                    } catch (final TimeoutException e) {\n-                        log.debug(\"Could not complete restoration for {} due to {}; will retry\", task.id(), e);\n+                        task.clearTaskTimeout();\n+                    } catch (final TimeoutException timeoutException) {\n+                        task.maybeInitTaskTimeoutOrThrow(now, timeoutException);\n+                        log.debug(\"Could not complete restoration for {} due to {}; will retry\", task.id(), timeoutException);", "originalCommit": "e9246df2bf829e8bee4180bdd7498c674c50c832", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDc5MjY1MQ==", "url": "https://github.com/apache/kafka/pull/9368#discussion_r504792651", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            log.debug(\"Could not initialize {} due to the following exception; will retry\", task.id(), retriableException);\n          \n          \n            \n                            log.debug(String.format(\"Could not initialize %s due to the following exception; will retry\", task.id()), retriableException);", "author": "vvcephei", "createdAt": "2020-10-14T15:57:13Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -454,18 +454,22 @@ private void addNewTask(final Task task) {\n      * @throws StreamsException if the store's change log does not contain the partition\n      * @return {@code true} if all tasks are fully restored\n      */\n-    boolean tryToCompleteRestoration() {\n+    boolean tryToCompleteRestoration(final long now) {\n         boolean allRunning = true;\n \n         final List<Task> activeTasks = new LinkedList<>();\n         for (final Task task : tasks.values()) {\n             try {\n                 task.initializeIfNeeded();\n-            } catch (final LockException | TimeoutException e) {\n+                task.clearTaskTimeout();\n+            } catch (final LockException retriableException) {\n                 // it is possible that if there are multiple threads within the instance that one thread\n                 // trying to grab the task from the other, while the other has not released the lock since\n                 // it did not participate in the rebalance. In this case we can just retry in the next iteration\n-                log.debug(\"Could not initialize {} due to the following exception; will retry\", task.id(), e);\n+                log.debug(\"Could not initialize {} due to the following exception; will retry\", task.id(), retriableException);", "originalCommit": "e9246df2bf829e8bee4180bdd7498c674c50c832", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6a30537a3e13f3885a8310ec7d250176ee5138bf", "url": "https://github.com/apache/kafka/commit/6a30537a3e13f3885a8310ec7d250176ee5138bf", "message": "Github comments", "committedDate": "2020-10-15T23:18:45Z", "type": "commit"}, {"oid": "4cf09b100409650258fa5db6c62d5d7cead397fb", "url": "https://github.com/apache/kafka/commit/4cf09b100409650258fa5db6c62d5d7cead397fb", "message": "Add `final` modifiers", "committedDate": "2020-10-15T23:24:30Z", "type": "commit"}, {"oid": "8af6ae506768e6563ba5504b5dc4bc8634b2eddf", "url": "https://github.com/apache/kafka/commit/8af6ae506768e6563ba5504b5dc4bc8634b2eddf", "message": "Fix compile errors", "committedDate": "2020-10-16T17:07:14Z", "type": "commit"}, {"oid": "6ff9abd682674971e8e04d8e867caa4e19d1d319", "url": "https://github.com/apache/kafka/commit/6ff9abd682674971e8e04d8e867caa4e19d1d319", "message": "Change logger setup", "committedDate": "2020-10-16T21:52:53Z", "type": "commit"}]}