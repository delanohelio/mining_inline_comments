{"pr_number": 9148, "pr_title": "KAFKA-10379: Implement the KIP-478 StreamBuilder#addGlobalStore()", "pr_createdAt": "2020-08-10T03:19:03Z", "pr_url": "https://github.com/apache/kafka/pull/9148", "timeline": [{"oid": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "url": "https://github.com/apache/kafka/commit/38caa4bacf909e0930445dfa27a0fb9076b3f981", "message": "KAFKA-10379: Implement the KIP-478 StreamBuilder#addGlobalStore()", "committedDate": "2020-08-10T03:26:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3MTc3NA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467671774", "bodyText": "Adapt the old API to the new one.", "author": "vvcephei", "createdAt": "2020-08-10T03:19:30Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsBuilder.java", "diffHunk": "@@ -499,7 +500,7 @@ public synchronized StreamsBuilder addStateStore(final StoreBuilder<?> builder)\n             topic,\n             new ConsumedInternal<>(consumed),\n             processorName,\n-            stateUpdateSupplier\n+            () -> ProcessorAdapter.adapt(stateUpdateSupplier.get())", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3Mjg4Ng==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467672886", "bodyText": "Also here, adapting the old API to the new one.", "author": "vvcephei", "createdAt": "2020-08-10T03:26:38Z", "path": "streams/src/main/java/org/apache/kafka/streams/Topology.java", "diffHunk": "@@ -721,7 +722,7 @@ public synchronized Topology addStateStore(final StoreBuilder<?> storeBuilder,\n             valueDeserializer,\n             topic,\n             processorName,\n-            stateUpdateSupplier\n+            () -> ProcessorAdapter.adapt(stateUpdateSupplier.get())", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3MzAwNA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467673004", "bodyText": "For the internal builder, just directly change to the new API.", "author": "vvcephei", "createdAt": "2020-08-10T03:27:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java", "diffHunk": "@@ -201,12 +200,12 @@ public synchronized void addStateStore(final StoreBuilder<?> builder) {\n         addGraphNode(root, new StateStoreNode<>(builder));\n     }\n \n-    public synchronized <K, V> void addGlobalStore(final StoreBuilder<?> storeBuilder,\n-                                                   final String sourceName,\n-                                                   final String topic,\n-                                                   final ConsumedInternal<K, V> consumed,\n-                                                   final String processorName,\n-                                                   final ProcessorSupplier<K, V> stateUpdateSupplier) {\n+    public synchronized <KIn, VIn> void addGlobalStore(final StoreBuilder<?> storeBuilder,\n+                                                       final String sourceName,\n+                                                       final String topic,\n+                                                       final ConsumedInternal<KIn, VIn> consumed,\n+                                                       final String processorName,\n+                                                       final org.apache.kafka.streams.processor.api.ProcessorSupplier<KIn, VIn, Void, Void> stateUpdateSupplier) {", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3MzE2NA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467673164", "bodyText": "For now, just adapt. Later this whole node will get converted to the new API.", "author": "vvcephei", "createdAt": "2020-08-10T03:28:24Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/TableSourceNode.java", "diffHunk": "@@ -89,14 +90,16 @@ public void writeToTopology(final InternalTopologyBuilder topologyBuilder) {\n             new TimestampedKeyValueStoreMaterializer<>((MaterializedInternal<K, V, KeyValueStore<Bytes, byte[]>>) materializedInternal).materialize();\n \n         if (isGlobalKTable) {\n-            topologyBuilder.addGlobalStore(storeBuilder,\n-                                           sourceName,\n-                                           consumedInternal().timestampExtractor(),\n-                                           consumedInternal().keyDeserializer(),\n-                                           consumedInternal().valueDeserializer(),\n-                                           topicName,\n-                                           processorParameters.processorName(),\n-                                           processorParameters.processorSupplier());\n+            topologyBuilder.addGlobalStore(\n+                storeBuilder,\n+                sourceName,\n+                consumedInternal().timestampExtractor(),\n+                consumedInternal().keyDeserializer(),\n+                consumedInternal().valueDeserializer(),\n+                topicName,\n+                processorParameters.processorName(),\n+                () -> ProcessorAdapter.adapt(processorParameters.processorSupplier().get())", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3MzU4NQ==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467673585", "bodyText": "We need to create a factory for the global node, so I'm adding the constructor for the new API, and also converting the internals here.", "author": "vvcephei", "createdAt": "2020-08-10T03:30:59Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -192,16 +192,23 @@ private boolean isWindowStore() {\n     }\n \n     private static class ProcessorNodeFactory<KIn, VIn, KOut, VOut> extends NodeFactory<KIn, VIn, KOut, VOut> {\n-        private final ProcessorSupplier<KIn, VIn> supplier;\n+        private final org.apache.kafka.streams.processor.api.ProcessorSupplier<KIn, VIn, KOut, VOut> supplier;\n         private final Set<String> stateStoreNames = new HashSet<>();\n \n         ProcessorNodeFactory(final String name,\n                              final String[] predecessors,\n-                             final ProcessorSupplier<KIn, VIn> supplier) {\n+                             final org.apache.kafka.streams.processor.api.ProcessorSupplier<KIn, VIn, KOut, VOut> supplier) {", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3Mzg4Nw==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467673887", "bodyText": "Adding the constructor for the new API. The old constructor still exists and still functions to adapt the old API. Eventually, the old constructor will become unused.", "author": "vvcephei", "createdAt": "2020-08-10T03:32:48Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorNode.java", "diffHunk": "@@ -54,7 +54,19 @@\n     private Sensor createSensor;\n \n     public ProcessorNode(final String name) {\n-        this(name, null, null);\n+        this(name, (Processor<KIn, VIn, KOut, VOut>) null, null);\n+    }\n+\n+    public ProcessorNode(final String name,\n+                         final Processor<KIn, VIn, KOut, VOut> processor,\n+                         final Set<String> stateStores) {\n+\n+        this.name = name;\n+        this.processor = processor;\n+        this.children = new ArrayList<>();\n+        this.childByName = new HashMap<>();\n+        this.stateStores = stateStores;\n+        this.time = new SystemTime();", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDA2NQ==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467674065", "bodyText": "I went ahead and just converted the mock processor to the new API. I gave it a temporary name. Eventually, the old one will be unused, and we can delete the old one and rename the new one back to MockProcessorSupplier.", "author": "vvcephei", "createdAt": "2020-08-10T03:34:09Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/GlobalThreadShutDownOrderTest.java", "diffHunk": "@@ -36,9 +36,8 @@\n import org.apache.kafka.streams.state.Stores;\n import org.apache.kafka.streams.state.internals.KeyValueStoreBuilder;\n import org.apache.kafka.test.IntegrationTest;\n-import org.apache.kafka.test.MockProcessorSupplier;\n+import org.apache.kafka.test.MockApiProcessorSupplier;", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDE2MQ==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467674161", "bodyText": "Adapting for now. Once the Source is converted, this line will revert to the original.", "author": "vvcephei", "createdAt": "2020-08-10T03:34:56Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStreamThreadTest.java", "diffHunk": "@@ -96,7 +96,7 @@ public String newStoreName(final String prefix) {\n             null,\n             GLOBAL_STORE_TOPIC_NAME,\n             \"processorName\",\n-            new KTableSource<>(GLOBAL_STORE_NAME, GLOBAL_STORE_NAME));\n+            () -> ProcessorAdapter.adapt(new KTableSource<>(GLOBAL_STORE_NAME, GLOBAL_STORE_NAME).get()));", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDI5MA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467674290", "bodyText": "Using the new API. some extra lines changed when I cleaned up the indentation formatting.", "author": "vvcephei", "createdAt": "2020-08-10T03:35:41Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilderTest.java", "diffHunk": "@@ -270,14 +271,15 @@ public void testPatternSourceTopicsWithGlobalTopics() {\n         builder.addSource(null, \"source-1\", null, null, null, Pattern.compile(\"topic-1\"));\n         builder.addSource(null, \"source-2\", null, null, null, Pattern.compile(\"topic-2\"));\n         builder.addGlobalStore(\n-                new MockKeyValueStoreBuilder(\"global-store\", false).withLoggingDisabled(),\n-                \"globalSource\",\n-                null,\n-                null,\n-                null,\n-                \"globalTopic\",\n-                \"global-processor\",\n-                new MockProcessorSupplier<>());\n+            new MockKeyValueStoreBuilder(\"global-store\", false).withLoggingDisabled(),\n+            \"globalSource\",\n+            null,\n+            null,\n+            null,\n+            \"globalTopic\",\n+            \"global-processor\",\n+            new MockApiProcessorSupplier<>()", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDM5Mg==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467674392", "bodyText": "This is all that changed. I had to cast the null to resolve the right overload.", "author": "vvcephei", "createdAt": "2020-08-10T03:36:35Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorContextImplTest.java", "diffHunk": "@@ -150,13 +149,21 @@ public void setup() {\n         ((InternalProcessorContext) context).transitionToActive(task, null, null);\n         EasyMock.expect(task.recordCollector()).andStubReturn(recordCollector);\n \n-        context.setCurrentNode(new ProcessorNode<String, Long, Object, Object>(\"fake\", null,\n-            new HashSet<>(asList(\n-                \"LocalKeyValueStore\",\n-                \"LocalTimestampedKeyValueStore\",\n-                \"LocalWindowStore\",\n-                \"LocalTimestampedWindowStore\",\n-                \"LocalSessionStore\"))));\n+        context.setCurrentNode(\n+            new ProcessorNode<>(\n+                \"fake\",\n+                (org.apache.kafka.streams.processor.api.Processor<String, Long, Object, Object>) null,", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDU1OA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467674558", "bodyText": "As noted earlier, I'm copying this class from MockProcesor to convert it to the new API (to avoid disturbing too much code at once).", "author": "vvcephei", "createdAt": "2020-08-10T03:37:48Z", "path": "streams/src/test/java/org/apache/kafka/test/MockApiProcessor.java", "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.test;\n+\n+import org.apache.kafka.streams.KeyValueTimestamp;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.api.Processor;\n+import org.apache.kafka.streams.processor.api.ProcessorContext;\n+import org.apache.kafka.streams.state.ValueAndTimestamp;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+public class MockApiProcessor<KIn, VIn, KOut, VOut> implements Processor<KIn, VIn, KOut, VOut> {", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDU5Ng==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467674596", "bodyText": "As noted earlier, I'm copying this class from MockProcesorSupplier to convert it to the new API (to avoid disturbing too much code at once).", "author": "vvcephei", "createdAt": "2020-08-10T03:38:06Z", "path": "streams/src/test/java/org/apache/kafka/test/MockApiProcessorSupplier.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.test;\n+\n+import org.apache.kafka.streams.processor.api.Processor;\n+import org.apache.kafka.streams.processor.api.ProcessorSupplier;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class MockApiProcessorSupplier<KIn, VIn, KOut, VOut> implements ProcessorSupplier<KIn, VIn, KOut, VOut> {", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAyOTQ0OA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r469029448", "bodyText": "Same question for ProcessorSupplier for using a delegate, but is minor to me.", "author": "abbccdda", "createdAt": "2020-08-12T06:19:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDU5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM2ODYxMw==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r472368613", "bodyText": "This one isn't so straightforward. Although the supplied processors can be adapted, theCapturedProcessor() and capturedProcessors(expectedNumberOfProcessors) return MockProcessor specifically, so we'd need a whole new adapter to convert a MockApiProcessor into a MockProcessor. I'd rather leave it alone for now. These delegating classes will go away in a couple more PRs anyway.", "author": "vvcephei", "createdAt": "2020-08-18T17:36:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDU5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NDcwMQ==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r467674701", "bodyText": "Keeping the Scala API in sync with the Java one.", "author": "vvcephei", "createdAt": "2020-08-10T03:39:01Z", "path": "streams/streams-scala/src/main/scala/org/apache/kafka/streams/scala/StreamsBuilder.scala", "diffHunk": "@@ -176,12 +176,33 @@ class StreamsBuilder(inner: StreamsBuilderJ = new StreamsBuilderJ) {\n    *\n    * @see `org.apache.kafka.streams.StreamsBuilder#addGlobalStore`\n    */\n+  @deprecated(\n+    \"Use #addGlobalStore(StoreBuilder, String, Consumed, org.apache.kafka.streams.processor.api.ProcessorSupplier) instead.\",\n+    \"2.7.0\"\n+  )\n   def addGlobalStore[K, V](storeBuilder: StoreBuilder[_ <: StateStore],\n                            topic: String,\n                            consumed: Consumed[K, V],\n                            stateUpdateSupplier: ProcessorSupplier[K, V]): StreamsBuilderJ =\n     inner.addGlobalStore(storeBuilder, topic, consumed, stateUpdateSupplier)\n \n+  /**\n+   * Adds a global `StateStore` to the topology. Global stores should not be added to `Processor`, `Transformer`,\n+   * or `ValueTransformer` (in contrast to regular stores).\n+   * <p>\n+   * It is not required to connect a global store to `Processor`, `Transformer`, or `ValueTransformer`;\n+   * those have read-only access to all global stores by default.\n+   *\n+   * @see `org.apache.kafka.streams.StreamsBuilder#addGlobalStore`\n+   */\n+  def addGlobalStore[K, V](", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzNDk3Mw==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468834973", "bodyText": "format", "author": "abbccdda", "createdAt": "2020-08-11T20:08:30Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsBuilder.java", "diffHunk": "@@ -528,13 +529,56 @@ public synchronized StreamsBuilder addStateStore(final StoreBuilder<?> builder)\n      * @param stateUpdateSupplier   the instance of {@link ProcessorSupplier}\n      * @return itself\n      * @throws TopologyException if the processor of state is already registered\n+     * @deprecated Since 2.7.0; use {@link #addGlobalStore(StoreBuilder, String, Consumed, org.apache.kafka.streams.processor.api.ProcessorSupplier)} instead.\n      */\n+    @Deprecated\n     public synchronized <K, V> StreamsBuilder addGlobalStore(final StoreBuilder<?> storeBuilder,\n                                                              final String topic,\n                                                              final Consumed<K, V> consumed,\n                                                              final ProcessorSupplier<K, V> stateUpdateSupplier) {\n         Objects.requireNonNull(storeBuilder, \"storeBuilder can't be null\");\n         Objects.requireNonNull(consumed, \"consumed can't be null\");\n+        internalStreamsBuilder.addGlobalStore(\n+            storeBuilder,\n+            topic,\n+            new ConsumedInternal<>(consumed),\n+            () -> ProcessorAdapter.adapt(stateUpdateSupplier.get())\n+        );\n+        return this;\n+    }\n+\n+    /**\n+     * Adds a global {@link StateStore} to the topology.\n+     * The {@link StateStore} sources its data from all partitions of the provided input topic.\n+     * There will be exactly one instance of this {@link StateStore} per Kafka Streams instance.\n+     * <p>\n+     * A {@link SourceNode} with the provided sourceName will be added to consume the data arriving from the partitions\n+     * of the input topic.\n+     * <p>\n+     * The provided {@link org.apache.kafka.streams.processor.api.ProcessorSupplier}} will be used to create an\n+     * {@link org.apache.kafka.streams.processor.api.Processor} that will receive all records forwarded from the {@link SourceNode}.\n+     * NOTE: you should not use the {@link org.apache.kafka.streams.processor.api.Processor} to insert transformed records into\n+     * the global state store. This store uses the source topic as changelog and during restore will insert records directly\n+     * from the source.\n+     * This {@link org.apache.kafka.streams.processor.api.Processor} should be used to keep the {@link StateStore} up-to-date.\n+     * The default {@link TimestampExtractor} as specified in the {@link StreamsConfig config} is used.\n+     * <p>\n+     * It is not required to connect a global store to the {@link org.apache.kafka.streams.processor.api.Processor Processors},\n+     * {@link Transformer Transformers}, or {@link ValueTransformer ValueTransformer}; those have read-only access to all global stores by default.\n+     *\n+     * @param storeBuilder          user defined {@link StoreBuilder}; can't be {@code null}\n+     * @param topic                 the topic to source the data from\n+     * @param consumed              the instance of {@link Consumed} used to define optional parameters; can't be {@code null}\n+     * @param stateUpdateSupplier   the instance of {@link org.apache.kafka.streams.processor.api.ProcessorSupplier}\n+     * @return itself\n+     * @throws TopologyException if the processor of state is already registered\n+     */\n+    public synchronized <KIn, VIn> StreamsBuilder addGlobalStore(final StoreBuilder<?> storeBuilder,\n+                                                             final String topic,", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzNTgzOA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468835838", "bodyText": "Could we reverse the import to use org.apache.kafka.streams.processor.api.ProcessorSupplier as default instead?", "author": "abbccdda", "createdAt": "2020-08-11T20:10:16Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsBuilder.java", "diffHunk": "@@ -528,13 +529,56 @@ public synchronized StreamsBuilder addStateStore(final StoreBuilder<?> builder)\n      * @param stateUpdateSupplier   the instance of {@link ProcessorSupplier}\n      * @return itself\n      * @throws TopologyException if the processor of state is already registered\n+     * @deprecated Since 2.7.0; use {@link #addGlobalStore(StoreBuilder, String, Consumed, org.apache.kafka.streams.processor.api.ProcessorSupplier)} instead.\n      */\n+    @Deprecated\n     public synchronized <K, V> StreamsBuilder addGlobalStore(final StoreBuilder<?> storeBuilder,\n                                                              final String topic,\n                                                              final Consumed<K, V> consumed,\n                                                              final ProcessorSupplier<K, V> stateUpdateSupplier) {\n         Objects.requireNonNull(storeBuilder, \"storeBuilder can't be null\");\n         Objects.requireNonNull(consumed, \"consumed can't be null\");\n+        internalStreamsBuilder.addGlobalStore(\n+            storeBuilder,\n+            topic,\n+            new ConsumedInternal<>(consumed),\n+            () -> ProcessorAdapter.adapt(stateUpdateSupplier.get())\n+        );\n+        return this;\n+    }\n+\n+    /**\n+     * Adds a global {@link StateStore} to the topology.\n+     * The {@link StateStore} sources its data from all partitions of the provided input topic.\n+     * There will be exactly one instance of this {@link StateStore} per Kafka Streams instance.\n+     * <p>\n+     * A {@link SourceNode} with the provided sourceName will be added to consume the data arriving from the partitions\n+     * of the input topic.\n+     * <p>\n+     * The provided {@link org.apache.kafka.streams.processor.api.ProcessorSupplier}} will be used to create an\n+     * {@link org.apache.kafka.streams.processor.api.Processor} that will receive all records forwarded from the {@link SourceNode}.\n+     * NOTE: you should not use the {@link org.apache.kafka.streams.processor.api.Processor} to insert transformed records into\n+     * the global state store. This store uses the source topic as changelog and during restore will insert records directly\n+     * from the source.\n+     * This {@link org.apache.kafka.streams.processor.api.Processor} should be used to keep the {@link StateStore} up-to-date.\n+     * The default {@link TimestampExtractor} as specified in the {@link StreamsConfig config} is used.\n+     * <p>\n+     * It is not required to connect a global store to the {@link org.apache.kafka.streams.processor.api.Processor Processors},\n+     * {@link Transformer Transformers}, or {@link ValueTransformer ValueTransformer}; those have read-only access to all global stores by default.\n+     *\n+     * @param storeBuilder          user defined {@link StoreBuilder}; can't be {@code null}\n+     * @param topic                 the topic to source the data from\n+     * @param consumed              the instance of {@link Consumed} used to define optional parameters; can't be {@code null}\n+     * @param stateUpdateSupplier   the instance of {@link org.apache.kafka.streams.processor.api.ProcessorSupplier}", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MTIyNQ==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468871225", "bodyText": "Sure can! I was on the fence about which one is \"better\". Maybe I'll just stick with always importing the new one from now on.", "author": "vvcephei", "createdAt": "2020-08-11T21:19:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzNTgzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODk2Nzk5Mg==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468967992", "bodyText": "Yea, that's probably easier when we eventually cleanup the deprecated stuff \ud83d\udc4d", "author": "abbccdda", "createdAt": "2020-08-12T02:25:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzNTgzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzNzM1NA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468837354", "bodyText": "format", "author": "abbccdda", "createdAt": "2020-08-11T20:13:19Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -532,14 +539,14 @@ public final void addStateStore(final StoreBuilder<?> storeBuilder,\n         nodeGroups = null;\n     }\n \n-    public final <KIn, VIn, KOut, VOut> void addGlobalStore(final StoreBuilder<?> storeBuilder,\n+    public final <KIn, VIn> void addGlobalStore(final StoreBuilder<?> storeBuilder,", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzOTEzMA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468839130", "bodyText": "Why do we drop KOut/VOut?", "author": "abbccdda", "createdAt": "2020-08-11T20:16:53Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -532,14 +539,14 @@ public final void addStateStore(final StoreBuilder<?> storeBuilder,\n         nodeGroups = null;\n     }\n \n-    public final <KIn, VIn, KOut, VOut> void addGlobalStore(final StoreBuilder<?> storeBuilder,\n+    public final <KIn, VIn> void addGlobalStore(final StoreBuilder<?> storeBuilder,", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MjI5NQ==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468872295", "bodyText": "I didn't realize it in the last PR, but the output types for the stateUpdate processor is always Void, Void (ie., you can't forward anything, since the only function of that processor is to update the store itself). So we don't need the parameters; I've just expanded them to Void, Void below.", "author": "vvcephei", "createdAt": "2020-08-11T21:21:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzOTEzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzOTY3NA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468839674", "bodyText": "Could we deprecate the old constructor?", "author": "abbccdda", "createdAt": "2020-08-11T20:18:01Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorNode.java", "diffHunk": "@@ -54,7 +54,19 @@\n     private Sensor createSensor;\n \n     public ProcessorNode(final String name) {\n-        this(name, null, null);\n+        this(name, (Processor<KIn, VIn, KOut, VOut>) null, null);\n+    }\n+\n+    public ProcessorNode(final String name,\n+                         final Processor<KIn, VIn, KOut, VOut> processor,\n+                         final Set<String> stateStores) {\n+\n+        this.name = name;\n+        this.processor = processor;\n+        this.children = new ArrayList<>();\n+        this.childByName = new HashMap<>();\n+        this.stateStores = stateStores;\n+        this.time = new SystemTime();\n     }\n \n     public ProcessorNode(final String name,", "originalCommit": "38caa4bacf909e0930445dfa27a0fb9076b3f981", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3MzQ2NA==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r468873464", "bodyText": "It will actually get removed later on in the KIP-478 implementation. What will happen is that the DSL and the PAPI will adapt the deprecated Processors to the new ones, and we can completely remove all mentions of the deprecated Processors in the internals.\nBut for now, if we deprecate this constructor, it'll just obligate us to suppress the deprecation warning in a bunch of other places.", "author": "vvcephei", "createdAt": "2020-08-11T21:24:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzOTY3NA=="}], "type": "inlineReview"}, {"oid": "e90ad7634853ee6a896787cc16f13ea4a47c4499", "url": "https://github.com/apache/kafka/commit/e90ad7634853ee6a896787cc16f13ea4a47c4499", "message": "CR: invert import and fix formatting", "committedDate": "2020-08-11T21:40:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAyNTg0Mw==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r469025843", "bodyText": "Could we use Void, Void instead?", "author": "abbccdda", "createdAt": "2020-08-12T06:09:32Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -667,7 +674,7 @@ public void validateCopartition() {\n     private void validateGlobalStoreArguments(final String sourceName,\n                                               final String topic,\n                                               final String processorName,\n-                                              final ProcessorSupplier<?, ?> stateUpdateSupplier,\n+                                              final ProcessorSupplier<?, ?, ?, ?> stateUpdateSupplier,", "originalCommit": "e90ad7634853ee6a896787cc16f13ea4a47c4499", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMyNzA4NQ==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r472327085", "bodyText": "Sure; all we do it verify it's not null, but it doesn't hurt.", "author": "vvcephei", "createdAt": "2020-08-18T16:30:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAyNTg0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAyNzU3NQ==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r469027575", "bodyText": "Do we want to add test coverage for this function?", "author": "abbccdda", "createdAt": "2020-08-12T06:14:38Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsBuilder.java", "diffHunk": "@@ -512,27 +513,70 @@ public synchronized StreamsBuilder addStateStore(final StoreBuilder<?> builder)\n      * A {@link SourceNode} with the provided sourceName will be added to consume the data arriving from the partitions\n      * of the input topic.\n      * <p>\n-     * The provided {@link ProcessorSupplier} will be used to create an {@link ProcessorNode} that will receive all\n+     * The provided {@link org.apache.kafka.streams.processor.ProcessorSupplier} will be used to create an {@link ProcessorNode} that will receive all\n      * records forwarded from the {@link SourceNode}. NOTE: you should not use the {@code Processor} to insert transformed records into\n      * the global state store. This store uses the source topic as changelog and during restore will insert records directly\n      * from the source.\n      * This {@link ProcessorNode} should be used to keep the {@link StateStore} up-to-date.\n      * The default {@link TimestampExtractor} as specified in the {@link StreamsConfig config} is used.\n      * <p>\n-     * It is not required to connect a global store to {@link Processor Processors}, {@link Transformer Transformers},\n+     * It is not required to connect a global store to {@link org.apache.kafka.streams.processor.Processor Processors}, {@link Transformer Transformers},\n      * or {@link ValueTransformer ValueTransformer}; those have read-only access to all global stores by default.\n      *\n      * @param storeBuilder          user defined {@link StoreBuilder}; can't be {@code null}\n      * @param topic                 the topic to source the data from\n      * @param consumed              the instance of {@link Consumed} used to define optional parameters; can't be {@code null}\n-     * @param stateUpdateSupplier   the instance of {@link ProcessorSupplier}\n+     * @param stateUpdateSupplier   the instance of {@link org.apache.kafka.streams.processor.ProcessorSupplier}\n      * @return itself\n      * @throws TopologyException if the processor of state is already registered\n+     * @deprecated Since 2.7.0; use {@link #addGlobalStore(StoreBuilder, String, Consumed, ProcessorSupplier)} instead.\n      */\n+    @Deprecated\n     public synchronized <K, V> StreamsBuilder addGlobalStore(final StoreBuilder<?> storeBuilder,\n                                                              final String topic,\n                                                              final Consumed<K, V> consumed,\n-                                                             final ProcessorSupplier<K, V> stateUpdateSupplier) {\n+                                                             final org.apache.kafka.streams.processor.ProcessorSupplier<K, V> stateUpdateSupplier) {\n+        Objects.requireNonNull(storeBuilder, \"storeBuilder can't be null\");\n+        Objects.requireNonNull(consumed, \"consumed can't be null\");\n+        internalStreamsBuilder.addGlobalStore(\n+            storeBuilder,\n+            topic,\n+            new ConsumedInternal<>(consumed),\n+            () -> ProcessorAdapter.adapt(stateUpdateSupplier.get())\n+        );\n+        return this;\n+    }\n+\n+    /**\n+     * Adds a global {@link StateStore} to the topology.\n+     * The {@link StateStore} sources its data from all partitions of the provided input topic.\n+     * There will be exactly one instance of this {@link StateStore} per Kafka Streams instance.\n+     * <p>\n+     * A {@link SourceNode} with the provided sourceName will be added to consume the data arriving from the partitions\n+     * of the input topic.\n+     * <p>\n+     * The provided {@link ProcessorSupplier}} will be used to create an\n+     * {@link Processor} that will receive all records forwarded from the {@link SourceNode}.\n+     * NOTE: you should not use the {@link Processor} to insert transformed records into\n+     * the global state store. This store uses the source topic as changelog and during restore will insert records directly\n+     * from the source.\n+     * This {@link Processor} should be used to keep the {@link StateStore} up-to-date.\n+     * The default {@link TimestampExtractor} as specified in the {@link StreamsConfig config} is used.\n+     * <p>\n+     * It is not required to connect a global store to the {@link Processor Processors},\n+     * {@link Transformer Transformers}, or {@link ValueTransformer ValueTransformer}; those have read-only access to all global stores by default.\n+     *\n+     * @param storeBuilder          user defined {@link StoreBuilder}; can't be {@code null}\n+     * @param topic                 the topic to source the data from\n+     * @param consumed              the instance of {@link Consumed} used to define optional parameters; can't be {@code null}\n+     * @param stateUpdateSupplier   the instance of {@link ProcessorSupplier}\n+     * @return itself\n+     * @throws TopologyException if the processor of state is already registered\n+     */\n+    public synchronized <KIn, VIn> StreamsBuilder addGlobalStore(final StoreBuilder<?> storeBuilder,", "originalCommit": "e90ad7634853ee6a896787cc16f13ea4a47c4499", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAyODg2Nw==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r469028867", "bodyText": "I'm thinking whether it makes more sense to let MockProcessor encapsulate a delegate MockApiProcessor so that we could also use existing tests to verify the correctness of the migration.", "author": "abbccdda", "createdAt": "2020-08-12T06:18:18Z", "path": "streams/src/test/java/org/apache/kafka/test/MockApiProcessor.java", "diffHunk": "@@ -0,0 +1,174 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.test;\n+\n+import org.apache.kafka.streams.KeyValueTimestamp;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.api.Processor;\n+import org.apache.kafka.streams.processor.api.ProcessorContext;\n+import org.apache.kafka.streams.state.ValueAndTimestamp;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+public class MockApiProcessor<KIn, VIn, KOut, VOut> implements Processor<KIn, VIn, KOut, VOut> {", "originalCommit": "e90ad7634853ee6a896787cc16f13ea4a47c4499", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM0ODQ4Mg==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r472348482", "bodyText": "Ah, yeah, this is a good idea. I'll have to migrate all the field references to method references so they can be delegated, but I wanted to do that anyway.", "author": "vvcephei", "createdAt": "2020-08-18T17:05:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAyODg2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAyOTE0Mg==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r469029142", "bodyText": "comment format.", "author": "abbccdda", "createdAt": "2020-08-12T06:19:06Z", "path": "streams/src/test/java/org/apache/kafka/test/MockApiProcessorSupplier.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.test;\n+\n+import org.apache.kafka.streams.processor.api.Processor;\n+import org.apache.kafka.streams.processor.api.ProcessorSupplier;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class MockApiProcessorSupplier<KIn, VIn, KOut, VOut> implements ProcessorSupplier<KIn, VIn, KOut, VOut> {\n+\n+    private final long scheduleInterval;\n+    private final PunctuationType punctuationType;\n+    private final List<MockApiProcessor<KIn, VIn, KOut, VOut>> processors = new ArrayList<>();\n+\n+    public MockApiProcessorSupplier() {\n+        this(-1L);\n+    }\n+\n+    public MockApiProcessorSupplier(final long scheduleInterval) {\n+        this(scheduleInterval, PunctuationType.STREAM_TIME);\n+    }\n+\n+    public MockApiProcessorSupplier(final long scheduleInterval, final PunctuationType punctuationType) {\n+        this.scheduleInterval = scheduleInterval;\n+        this.punctuationType = punctuationType;\n+    }\n+\n+    @Override\n+    public Processor<KIn, VIn, KOut, VOut> get() {\n+        final MockApiProcessor<KIn, VIn, KOut, VOut> processor = new MockApiProcessor<>(punctuationType, scheduleInterval);\n+        processors.add(processor);\n+        return processor;\n+    }\n+\n+    // get the captured processor assuming that only one processor gets returned from this supplier\n+    public MockApiProcessor<KIn, VIn, KOut, VOut> theCapturedProcessor() {\n+        return capturedProcessors(1).get(0);\n+    }\n+\n+    public int capturedProcessorsCount() {\n+        return processors.size();\n+    }\n+\n+        // get the captured processors with the expected number", "originalCommit": "e90ad7634853ee6a896787cc16f13ea4a47c4499", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTAyOTUyMw==", "url": "https://github.com/apache/kafka/pull/9148#discussion_r469029523", "bodyText": "We could port this function when it is actually needed.", "author": "abbccdda", "createdAt": "2020-08-12T06:20:10Z", "path": "streams/src/test/java/org/apache/kafka/test/MockApiProcessorSupplier.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.test;\n+\n+import org.apache.kafka.streams.processor.api.Processor;\n+import org.apache.kafka.streams.processor.api.ProcessorSupplier;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class MockApiProcessorSupplier<KIn, VIn, KOut, VOut> implements ProcessorSupplier<KIn, VIn, KOut, VOut> {\n+\n+    private final long scheduleInterval;\n+    private final PunctuationType punctuationType;\n+    private final List<MockApiProcessor<KIn, VIn, KOut, VOut>> processors = new ArrayList<>();\n+\n+    public MockApiProcessorSupplier() {\n+        this(-1L);\n+    }\n+\n+    public MockApiProcessorSupplier(final long scheduleInterval) {\n+        this(scheduleInterval, PunctuationType.STREAM_TIME);\n+    }\n+\n+    public MockApiProcessorSupplier(final long scheduleInterval, final PunctuationType punctuationType) {\n+        this.scheduleInterval = scheduleInterval;\n+        this.punctuationType = punctuationType;\n+    }\n+\n+    @Override\n+    public Processor<KIn, VIn, KOut, VOut> get() {\n+        final MockApiProcessor<KIn, VIn, KOut, VOut> processor = new MockApiProcessor<>(punctuationType, scheduleInterval);\n+        processors.add(processor);\n+        return processor;\n+    }\n+\n+    // get the captured processor assuming that only one processor gets returned from this supplier\n+    public MockApiProcessor<KIn, VIn, KOut, VOut> theCapturedProcessor() {\n+        return capturedProcessors(1).get(0);\n+    }\n+\n+    public int capturedProcessorsCount() {", "originalCommit": "e90ad7634853ee6a896787cc16f13ea4a47c4499", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e8718628b670171cdc01fc20e7fe59284c3a5b9b", "url": "https://github.com/apache/kafka/commit/e8718628b670171cdc01fc20e7fe59284c3a5b9b", "message": "cr feedback", "committedDate": "2020-08-18T17:42:46Z", "type": "commit"}]}