{"pr_number": 8037, "pr_title": "KAFKA-9491; Increment high watermark after full log truncation", "pr_createdAt": "2020-02-04T06:19:51Z", "pr_url": "https://github.com/apache/kafka/pull/8037", "timeline": [{"oid": "8c5b977813084661c071ad823e3e7e5555c0ca5a", "url": "https://github.com/apache/kafka/commit/8c5b977813084661c071ad823e3e7e5555c0ca5a", "message": "KAFKA-9491; Increment high watermark after full log truncation", "committedDate": "2020-02-04T06:15:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDUyMzQyNA==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374523424", "bodyText": "Is there a case that recoveryPoint gets smaller than logStartOffset? If yes, is it ok to just move the recoveryPoint without flush? If not, is it worthy to throw exception or log this weird case?", "author": "chia7712", "createdAt": "2020-02-04T08:10:07Z", "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -721,14 +721,30 @@ class Log(@volatile var dir: File,\n     }\n   }\n \n-  private def updateLogEndOffset(messageOffset: Long): Unit = {\n-    nextOffsetMetadata = LogOffsetMetadata(messageOffset, activeSegment.baseOffset, activeSegment.size)\n+  private def updateLogEndOffset(offset: Long): Unit = {\n+    nextOffsetMetadata = LogOffsetMetadata(offset, activeSegment.baseOffset, activeSegment.size)\n \n     // Update the high watermark in case it has gotten ahead of the log end offset following a truncation\n     // or if a new segment has been rolled and the offset metadata needs to be updated.\n-    if (highWatermark >= messageOffset) {\n+    if (highWatermark >= offset) {\n       updateHighWatermarkMetadata(nextOffsetMetadata)\n     }\n+\n+    if (this.recoveryPoint > offset) {\n+      this.recoveryPoint = offset\n+    }\n+  }\n+\n+  private def updateLogStartOffset(offset: Long): Unit = {\n+    logStartOffset = offset\n+\n+    if (highWatermark < offset) {\n+      updateHighWatermark(offset)\n+    }\n+\n+    if (this.recoveryPoint < offset) {", "originalCommit": "8c5b977813084661c071ad823e3e7e5555c0ca5a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDgxMjEyMw==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374812123", "bodyText": "Is a recovery point lower than the log start offset useful? All data below the log start offset is subject to deletion.", "author": "hachikuji", "createdAt": "2020-02-04T17:23:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDUyMzQyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDgxNzUxMA==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374817510", "bodyText": "U are right :)", "author": "chia7712", "createdAt": "2020-02-04T17:33:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDUyMzQyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDcxMzk1Mw==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374713953", "bodyText": "resetLastCaughtUpTime takes curLeaderLogEndOffset, but we are now passing leaderEpochStartOffset. Do we need to update the parameter name of that method?", "author": "ijuma", "createdAt": "2020-02-04T14:48:36Z", "path": "core/src/main/scala/kafka/cluster/Partition.scala", "diffHunk": "@@ -506,12 +507,11 @@ class Partition(val topicPartition: TopicPartition,\n       leaderLog.maybeAssignEpochStartOffset(leaderEpoch, leaderEpochStartOffset)\n \n       val isNewLeader = !isLeader\n-      val curLeaderLogEndOffset = leaderLog.logEndOffset\n       val curTimeMs = time.milliseconds\n       // initialize lastCaughtUpTime of replicas as well as their lastFetchTimeMs and lastFetchLeaderLogEndOffset.\n       remoteReplicas.foreach { replica =>\n         val lastCaughtUpTimeMs = if (inSyncReplicaIds.contains(replica.brokerId)) curTimeMs else 0L\n-        replica.resetLastCaughtUpTime(curLeaderLogEndOffset, curTimeMs, lastCaughtUpTimeMs)\n+        replica.resetLastCaughtUpTime(leaderEpochStartOffset, curTimeMs, lastCaughtUpTimeMs)", "originalCommit": "8c5b977813084661c071ad823e3e7e5555c0ca5a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDgwNDkyNA==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374804924", "bodyText": "They are the same thing. I just got rid of a redundant variable.", "author": "hachikuji", "createdAt": "2020-02-04T17:10:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDcxMzk1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDgxMjI3Nw==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374812277", "bodyText": "Ok, I see.", "author": "ijuma", "createdAt": "2020-02-04T17:23:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDcxMzk1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDgyMjE5OQ==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374822199", "bodyText": "Previous behavior is recoveryPoint = math.min(newOffset, recoveryPoint)) but this patch changes it to\nif (this.recoveryPoint < offset) {\n  this.recoveryPoint = offset\n}\n\nwhich is equal to recoveryPoint = math.max(newOffset, recoveryPoint)). Is it a bug?", "author": "chia7712", "createdAt": "2020-02-04T17:43:20Z", "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -2081,9 +2096,7 @@ class Log(@volatile var dir: File,\n         producerStateManager.truncate()\n         producerStateManager.updateMapEndOffset(newOffset)\n         maybeIncrementFirstUnstableOffset()\n-\n-        this.recoveryPoint = math.min(newOffset, this.recoveryPoint)\n-        this.logStartOffset = newOffset\n+        updateLogStartOffset(newOffset)", "originalCommit": "8c5b977813084661c071ad823e3e7e5555c0ca5a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDg0NTgzNw==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374845837", "bodyText": "I have also updated updateLogEndOffset to set the recovery point. In truncateFully where we delete all segments and set the log start offset to be equal to the log end offset, this ensures recovery point is also set consistently.", "author": "hachikuji", "createdAt": "2020-02-04T18:29:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDgyMjE5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDg1NzA0Mg==", "url": "https://github.com/apache/kafka/pull/8037#discussion_r374857042", "bodyText": "Thanks for the explanation!", "author": "chia7712", "createdAt": "2020-02-04T18:51:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDgyMjE5OQ=="}], "type": "inlineReview"}]}