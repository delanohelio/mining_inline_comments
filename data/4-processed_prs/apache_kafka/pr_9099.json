{"pr_number": 9099, "pr_title": "KAFKA-6733: Printing additional ConsumerRecord fields in DefaultMessageFormatter", "pr_createdAt": "2020-07-29T12:56:06Z", "pr_url": "https://github.com/apache/kafka/pull/9099", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMwNjU0MQ==", "url": "https://github.com/apache/kafka/pull/9099#discussion_r462306541", "bodyText": "init(props: Properties) has been deprecated. It would be great if we could keep using configure(configs: Map[String, _]) as before. I think that we should also try to directly extract the values from the Map instead of using a Properties.", "author": "dajac", "createdAt": "2020-07-29T13:40:45Z", "path": "core/src/main/scala/kafka/tools/ConsoleConsumer.scala", "diffHunk": "@@ -459,48 +466,32 @@ class DefaultMessageFormatter extends MessageFormatter {\n   var printKey = false\n   var printValue = true\n   var printPartition = false\n-  var keySeparator = \"\\t\".getBytes(StandardCharsets.UTF_8)\n-  var lineSeparator = \"\\n\".getBytes(StandardCharsets.UTF_8)\n+  var printOffset = false\n+  var printHeaders = false\n+  var keySeparator = utfBytes(\"\\t\")\n+  var lineSeparator = utfBytes(\"\\n\")\n+  var headersSeparator = utfBytes(\",\")\n+  var nullLiteral = utfBytes(\"null\")\n \n   var keyDeserializer: Option[Deserializer[_]] = None\n   var valueDeserializer: Option[Deserializer[_]] = None\n-\n-  override def configure(configs: Map[String, _]): Unit = {\n-    val props = new java.util.Properties()\n-    configs.asScala.foreach { case (key, value) => props.put(key, value.toString) }\n-    if (props.containsKey(\"print.timestamp\"))\n-      printTimestamp = props.getProperty(\"print.timestamp\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.key\"))\n-      printKey = props.getProperty(\"print.key\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.value\"))\n-      printValue = props.getProperty(\"print.value\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"print.partition\"))\n-      printPartition = props.getProperty(\"print.partition\").trim.equalsIgnoreCase(\"true\")\n-    if (props.containsKey(\"key.separator\"))\n-      keySeparator = props.getProperty(\"key.separator\").getBytes(StandardCharsets.UTF_8)\n-    if (props.containsKey(\"line.separator\"))\n-      lineSeparator = props.getProperty(\"line.separator\").getBytes(StandardCharsets.UTF_8)\n-    // Note that `toString` will be called on the instance returned by `Deserializer.deserialize`\n-    if (props.containsKey(\"key.deserializer\")) {\n-      keyDeserializer = Some(Class.forName(props.getProperty(\"key.deserializer\")).getDeclaredConstructor()\n-        .newInstance().asInstanceOf[Deserializer[_]])\n-      keyDeserializer.get.configure(propertiesWithKeyPrefixStripped(\"key.deserializer.\", props).asScala.asJava, true)\n-    }\n-    // Note that `toString` will be called on the instance returned by `Deserializer.deserialize`\n-    if (props.containsKey(\"value.deserializer\")) {\n-      valueDeserializer = Some(Class.forName(props.getProperty(\"value.deserializer\")).getDeclaredConstructor()\n-        .newInstance().asInstanceOf[Deserializer[_]])\n-      valueDeserializer.get.configure(propertiesWithKeyPrefixStripped(\"value.deserializer.\", props).asScala.asJava, false)\n-    }\n-  }\n-\n-  private def propertiesWithKeyPrefixStripped(prefix: String, props: Properties): Properties = {\n-    val newProps = new Properties()\n-    props.asScala.foreach { case (key, value) =>\n-      if (key.startsWith(prefix) && key.length > prefix.length)\n-        newProps.put(key.substring(prefix.length), value)\n-    }\n-    newProps\n+  var headersDeserializer: Option[Deserializer[_]] = None\n+\n+  override def init(props: Properties): Unit = {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTEwNTQ3Ng==", "url": "https://github.com/apache/kafka/pull/9099#discussion_r465105476", "bodyText": "@dajac\nI have replaced init with configure and changed code to extract the values directly from Map. Please review again.", "author": "badaiaqrandista", "createdAt": "2020-08-04T14:44:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMwNjU0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMxMTU0Ng==", "url": "https://github.com/apache/kafka/pull/9099#discussion_r462311546", "bodyText": "nit: Move print.key to next line to remain consistent with the formatting of the other Maps.", "author": "dajac", "createdAt": "2020-07-29T13:47:31Z", "path": "core/src/test/scala/kafka/tools/DefaultMessageFormatterTest.scala", "diffHunk": "@@ -0,0 +1,235 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  * http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package unit.kafka.tools\n+\n+import java.io.{ByteArrayOutputStream, Closeable, PrintStream}\n+import java.nio.charset.StandardCharsets\n+import java.util\n+import java.util.Properties\n+\n+import kafka.tools.DefaultMessageFormatter\n+import org.apache.kafka.clients.consumer.ConsumerRecord\n+import org.apache.kafka.common.header.Header\n+import org.apache.kafka.common.header.internals.{RecordHeader, RecordHeaders}\n+import org.apache.kafka.common.record.TimestampType\n+import org.apache.kafka.common.serialization.Deserializer\n+import org.junit.Assert._\n+import org.junit.Test\n+import org.junit.runner.RunWith\n+import org.junit.runners.Parameterized\n+import org.junit.runners.Parameterized.Parameters\n+\n+import scala.jdk.CollectionConverters._\n+\n+@RunWith(value = classOf[Parameterized])\n+class DefaultMessageFormatterTest(name: String, record: ConsumerRecord[Array[Byte], Array[Byte]], properties: Map[String, String], expected: String) {\n+  import DefaultMessageFormatterTest._\n+\n+  @Test\n+  def testWriteRecord()= {\n+    withResource(new ByteArrayOutputStream()) { baos =>\n+      withResource(new PrintStream(baos)) { ps =>\n+        val formatter = buildFormatter(properties)\n+        formatter.writeTo(record, ps)\n+        val actual = new String(baos.toByteArray(), StandardCharsets.UTF_8)\n+        assertEquals(expected, actual)\n+\n+      }\n+    }\n+  }\n+}\n+\n+object DefaultMessageFormatterTest {\n+  @Parameters(name = \"Test {index} - {0}\")\n+  def parameters: java.util.Collection[Array[Object]] = {\n+    Seq(\n+      Array(\n+        \"print nothing\",\n+        consumerRecord(),\n+        Map(\"print.value\" -> \"false\"),\n+        \"\"),\n+      Array(\n+        \"print key\",\n+        consumerRecord(),\n+        Map(\"print.key\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"someKey\\n\"),\n+      Array(\n+        \"print value\",\n+        consumerRecord(),\n+        Map(),\n+        \"someValue\\n\"),\n+      Array(\n+        \"print empty timestamp\",\n+        consumerRecord(timestampType = TimestampType.NO_TIMESTAMP_TYPE),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"NO_TIMESTAMP\\n\"),\n+      Array(\n+        \"print log append time timestamp\",\n+        consumerRecord(timestampType = TimestampType.LOG_APPEND_TIME),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"LogAppendTime:1234\\n\"),\n+      Array(\n+        \"print create time timestamp\",\n+        consumerRecord(timestampType = TimestampType.CREATE_TIME),\n+        Map(\"print.timestamp\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"CreateTime:1234\\n\"),\n+      Array(\n+        \"print partition\",\n+        consumerRecord(),\n+        Map(\"print.partition\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"Partition:9\\n\"),\n+      Array(\n+        \"print offset\",\n+        consumerRecord(),\n+        Map(\"print.offset\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"Offset:9876\\n\"),\n+      Array(\n+        \"print headers\",\n+        consumerRecord(),\n+        Map(\"print.headers\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"h1:v1,h2:v2\\n\"),\n+      Array(\n+        \"print empty headers\",\n+        consumerRecord(headers = Nil),\n+        Map(\"print.headers\" -> \"true\", \"print.value\" -> \"false\"),\n+        \"NO_HEADERS\\n\"),\n+      Array(\n+        \"print all possible fields with default delimiters\",\n+        consumerRecord(),\n+        Map(\"print.key\" -> \"true\",", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTEwNTg5Nw==", "url": "https://github.com/apache/kafka/pull/9099#discussion_r465105897", "bodyText": "@dajac\nI've re-indent these as well.", "author": "badaiaqrandista", "createdAt": "2020-08-04T14:45:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjMxMTU0Ng=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "c7657fd26f1086287b9bab0ed8aa69ae9f8bf87f", "url": "https://github.com/apache/kafka/commit/c7657fd26f1086287b9bab0ed8aa69ae9f8bf87f", "message": "KAFKA-6733: Support of printing additional ConsumerRecord fields in DefaultMessageFormatter (rebased)", "committedDate": "2020-10-02T12:42:39Z", "type": "commit"}, {"oid": "d49fe77067e545a8d6927821ead08382f9482b5c", "url": "https://github.com/apache/kafka/commit/d49fe77067e545a8d6927821ead08382f9482b5c", "message": "added tag for partition and offset to make them clearer", "committedDate": "2020-10-02T12:42:39Z", "type": "commit"}, {"oid": "7632ac7f70e779db0b32698fa41b22b259b40abf", "url": "https://github.com/apache/kafka/commit/7632ac7f70e779db0b32698fa41b22b259b40abf", "message": "added code and test for null.literal property", "committedDate": "2020-10-02T12:42:39Z", "type": "commit"}, {"oid": "eb015f588de17ee33ee412ecdad9239063ce71c2", "url": "https://github.com/apache/kafka/commit/eb015f588de17ee33ee412ecdad9239063ce71c2", "message": "Changed \"init(props:Properties)\" method to \"configure(configs:Map[String,_])\" method", "committedDate": "2020-10-02T12:42:39Z", "type": "commit"}, {"oid": "1f82b9f53cd5b45b573c15bb1acdce77b7c466fe", "url": "https://github.com/apache/kafka/commit/1f82b9f53cd5b45b573c15bb1acdce77b7c466fe", "message": "Fix style in the test class", "committedDate": "2020-10-02T12:42:39Z", "type": "commit"}, {"oid": "35a759740a0dd95f3ffbbcf1791d7129f9c867ad", "url": "https://github.com/apache/kafka/commit/35a759740a0dd95f3ffbbcf1791d7129f9c867ad", "message": "Modify DefaultMessageFormatter to get configs from Map instead of Properties", "committedDate": "2020-10-02T12:42:39Z", "type": "commit"}, {"oid": "b112a26455e5077f4f3ec411f082533b870faead", "url": "https://github.com/apache/kafka/commit/b112a26455e5077f4f3ec411f082533b870faead", "message": "remove unused props variable", "committedDate": "2020-10-02T12:42:39Z", "type": "commit"}, {"oid": "4f1c2f880ed3eb33e7f5e9b6eb7abe94df94856c", "url": "https://github.com/apache/kafka/commit/4f1c2f880ed3eb33e7f5e9b6eb7abe94df94856c", "message": "Fix error thrown by ConsoleConsumerTest and CustomDeserializerTest", "committedDate": "2020-10-02T12:42:39Z", "type": "commit"}, {"oid": "4f1c2f880ed3eb33e7f5e9b6eb7abe94df94856c", "url": "https://github.com/apache/kafka/commit/4f1c2f880ed3eb33e7f5e9b6eb7abe94df94856c", "message": "Fix error thrown by ConsoleConsumerTest and CustomDeserializerTest", "committedDate": "2020-10-02T12:42:39Z", "type": "forcePushed"}]}