{"pr_number": 8147, "pr_title": "MINOR: don't assign standby tasks with no logged state", "pr_createdAt": "2020-02-21T01:49:49Z", "pr_url": "https://github.com/apache/kafka/pull/8147", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM1Nzk2Mg==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382357962", "bodyText": "This is just a side thing that's been bugging me. There actual changes contained in this PR are pretty small, and I'll point them all out specifically in the comments. But I can remove these method renamings if they create too much noise in the diff to review", "author": "ableegoldman", "createdAt": "2020-02-21T01:51:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -789,7 +789,10 @@ private int putNodeGroupName(final String nodeName,\n         return newNodeGroupId;\n     }\n \n-    public synchronized ProcessorTopology build() {\n+    /**\n+     * @return the full topology minus any global state\n+     */\n+    public synchronized ProcessorTopology buildTopology() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM1ODUzNQ==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382358535", "bodyText": "There was actually a bug in this condition: the storeToChangelogTopic map actually corresponds to the entire topology, not just this task's subtopology. See changes in ProcessorTopology above", "author": "ableegoldman", "createdAt": "2020-02-21T01:54:04Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -456,9 +456,9 @@ StandbyTask createTask(final Consumer<byte[], byte[]> consumer,\n             final String logPrefix = threadIdPrefix + String.format(\"%s [%s] \", \"standby-task\", taskId);\n             final LogContext logContext = new LogContext(logPrefix);\n \n-            final ProcessorTopology topology = builder.build(taskId.topicGroupId);\n+            final ProcessorTopology topology = builder.buildSubtopology(taskId.topicGroupId);\n \n-            if (!topology.stateStores().isEmpty() && !topology.storeToChangelogTopic().isEmpty()) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM1ODc3Mw==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382358773", "bodyText": "This is the main change; only loop over the stateful and changelog-enabled tasks when assigning standbys", "author": "ableegoldman", "createdAt": "2020-02-21T01:55:11Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/StickyTaskAssignor.java", "diffHunk": "@@ -54,7 +60,7 @@ public void assign(final int numStandbyReplicas) {\n     }\n \n     private void assignStandby(final int numStandbyReplicas) {\n-        for (final TaskId taskId : taskIds) {\n+        for (final TaskId taskId : standbyTaskIds) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM1OTQwMA==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382359400", "bodyText": "This is the one line I'd like some feedback on in particular; if I understand the TaskPairs class/purpose correctly, we should change the maxPairs to use the number of (distinct) standby tasks, which will always be smaller than the number of total tasks. ie there may be some \"unpaired\" active tasks, but that's fine since they won't have standbys to begin with", "author": "ableegoldman", "createdAt": "2020-02-21T01:57:39Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/StickyTaskAssignor.java", "diffHunk": "@@ -35,15 +35,21 @@\n \n     private static final Logger log = LoggerFactory.getLogger(StickyTaskAssignor.class);\n     private final Map<ID, ClientState> clients;\n-    private final Set<TaskId> taskIds;\n+    private final Set<TaskId> allTaskIds;\n+    private final Set<TaskId> standbyTaskIds;\n     private final Map<TaskId, ID> previousActiveTaskAssignment = new HashMap<>();\n     private final Map<TaskId, Set<ID>> previousStandbyTaskAssignment = new HashMap<>();\n     private final TaskPairs taskPairs;\n \n-    public StickyTaskAssignor(final Map<ID, ClientState> clients, final Set<TaskId> taskIds) {\n+    public StickyTaskAssignor(final Map<ID, ClientState> clients,\n+                              final Set<TaskId> allTaskIds,\n+                              final Set<TaskId> standbyTaskIds) {\n         this.clients = clients;\n-        this.taskIds = taskIds;\n-        taskPairs = new TaskPairs(taskIds.size() * (taskIds.size() - 1) / 2);\n+        this.allTaskIds = allTaskIds;\n+        this.standbyTaskIds = standbyTaskIds;\n+\n+        final int maxPairs = standbyTaskIds.size() * (standbyTaskIds.size() - 1) / 2;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjc2MTIyNg==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382761226", "bodyText": "The taskPairs is just use as a heuristic to avoid having (active-1, standby-2) and (active-2, standby-1) since if these two instances failed at the same time we lose both tasks: having as large num.pairs as possible means that such case would not likely happen. So if an active task does not have a corresponding standby, it would still appear in some pairs, not sure if that means your new math is correct or not? E.g. let's say we have three tasks A, B, C and A does not have standby while others do have two (num.replicas == 2). An assignment of\n(active-A, standby-B, standby-C), (active-B, standby-C), (active-C, standby-B)\nwould still generates three pairs AB, AC, BC, right?\nIn any ways, the maxPairs is just used for initializing the hash-set and decide whether we can exit early, so I think setting it to larger values would not matter to much.", "author": "guozhangwang", "createdAt": "2020-02-21T19:21:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM1OTQwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3ODUwOA==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382878508", "bodyText": "Yeah, I think it should still be based off of allTasks.size() -- I thought only active-standby pairs count but it's actually any unique/new pair. I'll put it back", "author": "ableegoldman", "createdAt": "2020-02-22T02:32:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM1OTQwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM5MjkwNw==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382392907", "bodyText": "We need to keep track of which tasks have optimized source tables, since they are marked as loggingDisabled", "author": "ableegoldman", "createdAt": "2020-02-21T04:33:52Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -113,6 +113,9 @@\n \n     private final QuickUnion<String> nodeGrouper = new QuickUnion<>();\n \n+    // state stores whose source topics are reused as their changelog\n+    private final Set<String> optimizedSourceTables = new HashSet<>();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM5NjIxMw==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382396213", "bodyText": "This is a bit misleading, since it will (and should) return true for optimized source KTables, which are technically marked as loggingDisabled -- as always, improved naming suggestions are welcome", "author": "ableegoldman", "createdAt": "2020-02-21T04:50:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorTopology.java", "diffHunk": "@@ -94,6 +92,15 @@ boolean isRepartitionTopic(final String topic) {\n         return repartitionTopics.contains(topic);\n     }\n \n+    boolean hasStateWithLoggingEnabled() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjc1MDcxNg==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382750716", "bodyText": "This is a good find. How about hasStateWithChangelogs?", "author": "guozhangwang", "createdAt": "2020-02-21T18:58:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM5NjIxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjc1NTcyNw==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382755727", "bodyText": "I thought about an alternative idea here and just leave it to your call whether you like it or not: I think we can modify line 1047 above to only if (stateFactory.users().contains(node)), since the storeToChangelogTopic should contain the source-changelog topics already, so we can just add it to the stateChangelogTopics of the TopicsInfo.\nThen, in StreamsPartitionAssignor, before prepareTopic(changelogTopicMetadata); we only prepare the topics as changelog-topics minus source-topics. In this way we do not need this flag either.\nMy rationale is that this is more consistent with the name stateChangelogTopics (a source-changelog topic should be included in this map, as well as in source-topics, we just need to let the partition-assignor to be aware of the possible overlapping).", "author": "guozhangwang", "createdAt": "2020-02-21T19:09:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -1038,6 +1053,9 @@ private void buildProcessorNode(final Map<String, ProcessorNode> processorMap,\n                                 createChangelogTopicConfig(stateFactory, topicName);\n                             stateChangelogTopics.put(topicName, internalTopicConfig);\n                         }\n+                        hasStateToRestore = true;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1MzY4MA==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382853680", "bodyText": "Nice idea, that lets us simplify the special handling for optimized source KTables", "author": "ableegoldman", "createdAt": "2020-02-21T23:32:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjc1NTcyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2OTU4NA==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382869584", "bodyText": "Somehow one of my comment was lost... I also comment that hasStateWithChangelogs can then be implemented as ! stateChangelogTopics.empty().", "author": "guozhangwang", "createdAt": "2020-02-22T01:01:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjc1NTcyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3NzA0OA==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382877048", "bodyText": "No worries, I had the same idea and simplified the whole thing. Decided to add a public method to TopicsInfo to sift out any optimized source tables rather than add that logic directly to the StreamsPartitionAssignor (which is complicated enough as is)", "author": "ableegoldman", "createdAt": "2020-02-22T02:12:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjc1NTcyNw=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk1MTkxOA==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r382951918", "bodyText": "nit: the 20 here means version 2.0, since we mistakenly made a compatible breaking change in 2.0 and this test is specifically for that. So let's just keep the suffix.", "author": "guozhangwang", "createdAt": "2020-02-23T00:17:23Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java", "diffHunk": "@@ -365,13 +365,13 @@ public void shouldNotMaterializeStoresIfNotRequired() {\n         builder.table(topic, Materialized.with(Serdes.Long(), Serdes.String()));\n \n         final ProcessorTopology topology =\n-            builder.internalTopologyBuilder.rewriteTopology(new StreamsConfig(props)).build();\n+            builder.internalTopologyBuilder.rewriteTopology(new StreamsConfig(props)).buildTopology();\n \n         assertThat(topology.stateStores().size(), equalTo(0));\n     }\n \n     @Test\n-    public void shouldReuseSourceTopicAsChangelogsWithOptimization20() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MTA3NQ==", "url": "https://github.com/apache/kafka/pull/8147#discussion_r383481075", "bodyText": "My bad, I thought it was a typo", "author": "ableegoldman", "createdAt": "2020-02-24T19:55:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk1MTkxOA=="}], "type": "inlineReview"}, {"oid": "6f929b389d9ca1340d0f988ab19636bb0f76e4fb", "url": "https://github.com/apache/kafka/commit/6f929b389d9ca1340d0f988ab19636bb0f76e4fb", "message": "only assign stateful and logged standbys, also some renaming..", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "e6ecd70da2a430134eb1dbfd2f584c7225250afc", "url": "https://github.com/apache/kafka/commit/e6ecd70da2a430134eb1dbfd2f584c7225250afc", "message": "refactoring mistakes", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "b344546380694358f0ed25f5b7dce6727d5dd7a2", "url": "https://github.com/apache/kafka/commit/b344546380694358f0ed25f5b7dce6727d5dd7a2", "message": "stickytaskassignortest", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "70017103ecf0b06b7cd8f1bae7f6658d847af61d", "url": "https://github.com/apache/kafka/commit/70017103ecf0b06b7cd8f1bae7f6658d847af61d", "message": "workaround for weird IDEA error", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "134b692e6595eccb936430ea6d0ff16da9c0f645", "url": "https://github.com/apache/kafka/commit/134b692e6595eccb936430ea6d0ff16da9c0f645", "message": "make it work for optimized source tables", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "36f2d47388eec88b3216f8b8c9aed74ff2953b57", "url": "https://github.com/apache/kafka/commit/36f2d47388eec88b3216f8b8c9aed74ff2953b57", "message": "rename method", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "d6e004aea8cbcd055e22aa00cec3e1f5e976043f", "url": "https://github.com/apache/kafka/commit/d6e004aea8cbcd055e22aa00cec3e1f5e976043f", "message": "simplify optimzied source KTable handling", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "bee01b4143307fcea512a7445a199dcf212dbdc9", "url": "https://github.com/apache/kafka/commit/bee01b4143307fcea512a7445a199dcf212dbdc9", "message": "fix test compilation", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "02c83d70809eb94cd29dee57843ef74632b19767", "url": "https://github.com/apache/kafka/commit/02c83d70809eb94cd29dee57843ef74632b19767", "message": "move to method on TopicsInfo", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "a2d2adebd0893ae604584da77bd693cbfd056b5d", "url": "https://github.com/apache/kafka/commit/a2d2adebd0893ae604584da77bd693cbfd056b5d", "message": "return maxPairs calculation", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "fb7b0c53376fe520b42912b01d64272eb7003a5a", "url": "https://github.com/apache/kafka/commit/fb7b0c53376fe520b42912b01d64272eb7003a5a", "message": "update condition", "committedDate": "2020-02-25T02:23:43Z", "type": "commit"}, {"oid": "fb7b0c53376fe520b42912b01d64272eb7003a5a", "url": "https://github.com/apache/kafka/commit/fb7b0c53376fe520b42912b01d64272eb7003a5a", "message": "update condition", "committedDate": "2020-02-25T02:23:43Z", "type": "forcePushed"}]}