{"pr_number": 9191, "pr_title": "KAFKA-10355: Throw error when source topic was deleted", "pr_createdAt": "2020-08-17T14:58:37Z", "pr_url": "https://github.com/apache/kafka/pull/9191", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY5NjE3OQ==", "url": "https://github.com/apache/kafka/pull/9191#discussion_r471696179", "bodyText": "What's this for (or going to be for)?", "author": "ableegoldman", "createdAt": "2020-08-17T18:37:14Z", "path": "streams/src/main/java/org/apache/kafka/streams/errors/MissingSourceTopicException.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.errors;\n+\n+public class MissingSourceTopicException extends StreamsException {\n+\n+    private final static long serialVersionUID = 1L;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjIxNzk4OQ==", "url": "https://github.com/apache/kafka/pull/9191#discussion_r472217989", "bodyText": "That is a good question. I have to admit that I blindly copied it from another exception class. The field has to do with exceptions implementing the Serializable interface. This field tells the JVM whether the serialized object can be deserialized into an object of the class that it is available in the JVM. See https://stackoverflow.com/questions/7187302/what-is-serialversionuid-in-java-normally-in-exception-class", "author": "cadonna", "createdAt": "2020-08-18T13:58:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY5NjE3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTcxMjM1Ng==", "url": "https://github.com/apache/kafka/pull/9191#discussion_r471712356", "bodyText": "I'm not sure this should extend StreamsException, my understanding is that it's generally reserved for Streams internal errors and not user code/setup issues", "author": "ableegoldman", "createdAt": "2020-08-17T18:57:04Z", "path": "streams/src/main/java/org/apache/kafka/streams/errors/MissingSourceTopicException.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.errors;\n+\n+public class MissingSourceTopicException extends StreamsException {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjIyODgxMQ==", "url": "https://github.com/apache/kafka/pull/9191#discussion_r472228811", "bodyText": "That is a good point. I thought all exceptions thrown from inside Streams (except for the IllegalStateException) should be StreamsExceptions. The RecordDeserializer throws a StreamsException when the deserialization exception handler -- which is user code -- throws any exception. Maybe @guozhangwang can help here.", "author": "cadonna", "createdAt": "2020-08-18T14:13:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTcxMjM1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjM2ODc2OA==", "url": "https://github.com/apache/kafka/pull/9191#discussion_r472368768", "bodyText": "I agree with @cadonna here, that all exceptions from inside Streams should be inheriting from StreamsException, and that may include 1) environmental issues like timeout --- note that after @mjsax KIP we would not throw TimeoutException (which is a KafkaException not StreamsException) but a new exception inherited from StreamsException, and IOException which are also wrapped as StateStoreException inherited from StreamsException, and 2) user bug in process etc which get caught by streams code.", "author": "guozhangwang", "createdAt": "2020-08-18T17:37:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTcxMjM1Ng=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjI1MDIwNw==", "url": "https://github.com/apache/kafka/pull/9191#discussion_r482250207", "bodyText": "What do you think about expanding the test to verify that all members really get shut down, not just all the ones in an instance? It seems simple enough: just create and start two instances and then verify they both wind up in ERROR state.\nWDYT?", "author": "vvcephei", "createdAt": "2020-09-02T17:39:26Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/HandlingSourceTopicDeletionTest.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KafkaStreams.State;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.Produced;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+\n+import java.util.Properties;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.safeUniqueTestName;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Category({IntegrationTest.class})\n+public class HandlingSourceTopicDeletionTest {\n+\n+    private static final int NUM_BROKERS = 1;\n+    private static final int NUM_THREADS = 2;\n+    private static final long TIMEOUT = 60000;\n+    private static final String INPUT_TOPIC = \"inputTopic\";\n+    private static final String OUTPUT_TOPIC = \"outputTopic\";\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(NUM_BROKERS);\n+\n+    @Rule\n+    public TestName testName = new TestName();\n+\n+    @Before\n+    public void before() throws InterruptedException {\n+        CLUSTER.createTopics(INPUT_TOPIC, OUTPUT_TOPIC);\n+    }\n+\n+    @After\n+    public void after() throws InterruptedException {\n+        CLUSTER.deleteTopics(INPUT_TOPIC, OUTPUT_TOPIC);\n+    }\n+\n+    @Test\n+    public void shouldThrowErrorAfterSourceTopicDeleted() throws InterruptedException {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        builder.stream(INPUT_TOPIC, Consumed.with(Serdes.Integer(), Serdes.String()))\n+            .to(OUTPUT_TOPIC, Produced.with(Serdes.Integer(), Serdes.String()));\n+\n+        final String safeTestName = safeUniqueTestName(getClass(), testName);\n+        final String appId = \"app-\" + safeTestName;\n+\n+        final Properties streamsConfiguration = new Properties();\n+        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, appId);\n+        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers());\n+        streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n+        streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());\n+        streamsConfiguration.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, NUM_THREADS);\n+        streamsConfiguration.put(StreamsConfig.METADATA_MAX_AGE_CONFIG, 2000);\n+\n+        final Topology topology = builder.build();\n+        final KafkaStreams kafkaStreams = new KafkaStreams(topology, streamsConfiguration);\n+\n+        final AtomicBoolean calledUncaughtExceptionHandler = new AtomicBoolean(false);\n+        kafkaStreams.setUncaughtExceptionHandler((thread, exception) -> calledUncaughtExceptionHandler.set(true));\n+        kafkaStreams.start();\n+        TestUtils.waitForCondition(\n+            () -> kafkaStreams.state() == State.RUNNING,\n+            TIMEOUT,\n+            () -> \"Kafka Streams application did not reach state RUNNING\"\n+        );\n+\n+        CLUSTER.deleteTopicAndWait(INPUT_TOPIC);\n+\n+        TestUtils.waitForCondition(\n+            () -> kafkaStreams.state() == State.ERROR,\n+            TIMEOUT,\n+            () -> \"Kafka Streams application did not reach state ERROR\"\n+        );", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5MTYxNA==", "url": "https://github.com/apache/kafka/pull/9191#discussion_r482791614", "bodyText": "I had that thought, too. But then I thought it is not required to test the code added in this PR. On the other hand, it does not harm to use two Streams clients and broaden the test scope since this is an integration test.", "author": "cadonna", "createdAt": "2020-09-03T08:12:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjI1MDIwNw=="}], "type": "inlineReview"}, {"oid": "3cb34b5db242db88b28213869d6de912d4c1b73b", "url": "https://github.com/apache/kafka/commit/3cb34b5db242db88b28213869d6de912d4c1b73b", "message": "[WIP] KAFKA-10355: PoC", "committedDate": "2020-09-03T10:12:06Z", "type": "commit"}, {"oid": "348a51918a767c752f53a1eb519563aab754ec4b", "url": "https://github.com/apache/kafka/commit/348a51918a767c752f53a1eb519563aab754ec4b", "message": "Add uncaught exception handler verification", "committedDate": "2020-09-03T10:12:06Z", "type": "commit"}, {"oid": "b6640f9f6d269022b63f65c2cfd11dea619a676c", "url": "https://github.com/apache/kafka/commit/b6640f9f6d269022b63f65c2cfd11dea619a676c", "message": "Fix checkstyle issues", "committedDate": "2020-09-03T10:12:06Z", "type": "commit"}, {"oid": "40a90777e0e2112dadfd5fe8aa4d00645b608cfd", "url": "https://github.com/apache/kafka/commit/40a90777e0e2112dadfd5fe8aa4d00645b608cfd", "message": "Fix integration test", "committedDate": "2020-09-03T10:12:06Z", "type": "commit"}, {"oid": "f7a9ac21e20a12b8a45e62466a4169862819c5ff", "url": "https://github.com/apache/kafka/commit/f7a9ac21e20a12b8a45e62466a4169862819c5ff", "message": "Set metadata.max.age.ms to low value in test", "committedDate": "2020-09-03T10:12:06Z", "type": "commit"}, {"oid": "faf7a0e35e44801b60a9a950c7e3a0b0f2f1234d", "url": "https://github.com/apache/kafka/commit/faf7a0e35e44801b60a9a950c7e3a0b0f2f1234d", "message": "Refactor integration test", "committedDate": "2020-09-03T10:12:06Z", "type": "commit"}, {"oid": "6a6cd9a4784b641c1e9877b1b4146a3cff74ccc0", "url": "https://github.com/apache/kafka/commit/6a6cd9a4784b641c1e9877b1b4146a3cff74ccc0", "message": "Improve integration test and add unit tests", "committedDate": "2020-09-03T10:12:06Z", "type": "commit"}, {"oid": "6a6cd9a4784b641c1e9877b1b4146a3cff74ccc0", "url": "https://github.com/apache/kafka/commit/6a6cd9a4784b641c1e9877b1b4146a3cff74ccc0", "message": "Improve integration test and add unit tests", "committedDate": "2020-09-03T10:12:06Z", "type": "forcePushed"}]}