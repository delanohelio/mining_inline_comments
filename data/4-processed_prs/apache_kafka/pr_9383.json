{"pr_number": 9383, "pr_title": "KAFKA-10455: Ensure that probing rebalances always occur", "pr_createdAt": "2020-10-06T16:00:29Z", "pr_url": "https://github.com/apache/kafka/pull/9383", "timeline": [{"oid": "9e919c2354f605b4b0ab6921fed97d4b970be3ab", "url": "https://github.com/apache/kafka/commit/9e919c2354f605b4b0ab6921fed97d4b970be3ab", "message": "Add check to ensure rebalancing", "committedDate": "2020-10-05T19:44:10Z", "type": "commit"}, {"oid": "fb994d83c10d93f53431e04ca462dcf1e61e26ac", "url": "https://github.com/apache/kafka/commit/fb994d83c10d93f53431e04ca462dcf1e61e26ac", "message": "testing udpates", "committedDate": "2020-10-06T15:35:25Z", "type": "commit"}, {"oid": "8fa4be81e42cf5614e045fbe8c1eeeddf394a00c", "url": "https://github.com/apache/kafka/commit/8fa4be81e42cf5614e045fbe8c1eeeddf394a00c", "message": "clean up", "committedDate": "2020-10-06T15:58:21Z", "type": "commit"}, {"oid": "1b2769f8fbd68a47e1d3a2f16d36f411d1f3b8b2", "url": "https://github.com/apache/kafka/commit/1b2769f8fbd68a47e1d3a2f16d36f411d1f3b8b2", "message": "small fixes", "committedDate": "2020-10-07T15:33:25Z", "type": "commit"}, {"oid": "0f0133d5a0aa827eedba89178b29997a48d9028a", "url": "https://github.com/apache/kafka/commit/0f0133d5a0aa827eedba89178b29997a48d9028a", "message": "add testing", "committedDate": "2020-10-07T16:08:04Z", "type": "commit"}, {"oid": "cfadf9d74f856ccedccf03dedcbb6031ccaca54d", "url": "https://github.com/apache/kafka/commit/cfadf9d74f856ccedccf03dedcbb6031ccaca54d", "message": "clean up", "committedDate": "2020-10-07T16:25:48Z", "type": "commit"}, {"oid": "52c6174a4b0c651cda7498feeb5d29347b00a910", "url": "https://github.com/apache/kafka/commit/52c6174a4b0c651cda7498feeb5d29347b00a910", "message": "Comment update", "committedDate": "2020-10-07T18:25:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIyNTc1MQ==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501225751", "bodyText": "This could be moved out to the assignorConfiguration class to match the other fields but the code is fairly straightforward so I left it here for now", "author": "lct45", "createdAt": "2020-10-07T18:30:08Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -212,6 +213,7 @@ public void configure(final Map<String, ?> configs) {\n         rebalanceProtocol = assignorConfiguration.rebalanceProtocol();\n         taskAssignorSupplier = assignorConfiguration::taskAssignor;\n         assignmentListener = assignorConfiguration.assignmentListener();\n+        uniqueField = usedSubscriptionMetadataVersion >= 8 ? new byte[1] : new byte[0];", "originalCommit": "52c6174a4b0c651cda7498feeb5d29347b00a910", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNTU2OA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501315568", "bodyText": "Sounds good. I think it's also fine to just initialize it to new byte[1] regardless of whether the version is high enough to actually need it or not. It's just a single byte, and simpler is better", "author": "ableegoldman", "createdAt": "2020-10-07T21:17:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIyNTc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNjM5OA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501316398", "bodyText": "Also, now that I think about it, the usedSubscriptionMetadataVersion will only ever be >= 8 at this point. It might be set to something lower at some point later on, but it has to be at least 8 when the assignor is just being created/configured", "author": "ableegoldman", "createdAt": "2020-10-07T21:19:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIyNTc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyOTYyMA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501329620", "bodyText": "The autocode generator throws an error if array.length != 0 and the version is < 8. It didn't seem to be a huge problem but there were some tests that used version 1 so initializing to new byte[1] threw errors", "author": "lct45", "createdAt": "2020-10-07T21:49:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIyNTc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMzNjY2Ng==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501336666", "bodyText": "That seems like an indication that the subscription is being encoded incorrectly. If the version is below 8, it shouldn't be trying to encode the uniqueField in the first place -- you shouldn't have to mimic that yourself by forcing it to be empty (and even if it is I worry there might be some additional bytes for metadata that would get stored for that field, when that field should not exist at all for versions < 8)", "author": "ableegoldman", "createdAt": "2020-10-07T22:05:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIyNTc1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNDYwOQ==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501314609", "bodyText": "Instead of hardcoded 8 all over, let's just define a constant for this similar to the MIN_VERSION_OFFSET_SUM_SUBSCRIPTION  in SubscriptionInfo", "author": "ableegoldman", "createdAt": "2020-10-07T21:15:48Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -234,15 +236,20 @@ public ByteBuffer subscriptionUserData(final Set<String> topics) {\n         // Adds the following information to subscription\n         // 1. Client UUID (a unique id assigned to an instance of KafkaStreams)\n         // 2. Map from task id to its overall lag\n+        // 3. Unique Field to ensure a rebalance when a thread rejoins by forcing the user data to be different\n \n         handleRebalanceStart(topics);\n+        if (usedSubscriptionMetadataVersion >= 8) {", "originalCommit": "52c6174a4b0c651cda7498feeb5d29347b00a910", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNzgyMw==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501317823", "bodyText": "If you want, I think it's also fine to just always flip the byte and not even check against the used subscription version.", "author": "ableegoldman", "createdAt": "2020-10-07T21:22:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNDYwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMjMwMA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501322300", "bodyText": "Can you add a test that verifies that it goes back and forth between the two expected values when you call partitionAssignor.subscriptionUserData multiples times (let's say 3) -- also maybe add a verification that the uniqueField has a length of just 1", "author": "ableegoldman", "createdAt": "2020-10-07T21:32:31Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "diffHunk": "@@ -483,7 +485,7 @@ public void testEagerSubscription() {\n         Collections.sort(subscription.topics());\n         assertEquals(asList(\"topic1\", \"topic2\"), subscription.topics());\n \n-        final SubscriptionInfo info = getInfo(UUID_1, prevTasks, standbyTasks);", "originalCommit": "52c6174a4b0c651cda7498feeb5d29347b00a910", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTk1NjkwNQ==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501956905", "bodyText": "goes back and forth between the two expected values\n\nWhat do you mean by expected values? Toggling between the default of 0 and 1 after partitionAssignor.subscriptionUserData is called the first time?", "author": "lct45", "createdAt": "2020-10-08T19:18:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMjMwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjA1MjczMA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r502052730", "bodyText": "Yeah, it should be 0 the first time you call it, then 1 the second time, and then back to 0 again on the third call", "author": "ableegoldman", "createdAt": "2020-10-08T22:43:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMjMwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjU5MjY4NA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r502592684", "bodyText": "I don't think it would go from 0 to 1 to 0 since the partition assigner always increases, so if you're using the same partition assignor it'll go from 0 to 1 to 2 etc", "author": "lct45", "createdAt": "2020-10-09T18:04:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMjMwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEwODc2MA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r504108760", "bodyText": "Oh right duh I was thinking it was just a single bit but it's a byte. In that case we should have a test that verifies it goes from 0 to 1 to 2, etc -- might be good to verify the behavior on overflow as well, if you call subscriptionUserData the max_value number of times", "author": "ableegoldman", "createdAt": "2020-10-13T16:47:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMjMwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDExMTQ1Nw==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r504111457", "bodyText": "Oh, saw that you already added the test for 0 --> 1 --> 2 behavior. In that case can you just add two things to that test: verify the behavior on overflow, and verify that the length is always exactly one byte", "author": "ableegoldman", "createdAt": "2020-10-13T16:52:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMjMwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMjg1MA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501322850", "bodyText": "Can you add a test like this for the new version 8?", "author": "ableegoldman", "createdAt": "2020-10-07T21:33:44Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/SubscriptionInfoTest.java", "diffHunk": "@@ -286,23 +296,23 @@ public void shouldEncodeAndDecodeSmallerLatestSupportedVersion() {\n         final int latestSupportedVersion = LATEST_SUPPORTED_VERSION - 1;\n \n         final SubscriptionInfo info =\n-            new SubscriptionInfo(usedVersion, latestSupportedVersion, UUID_1, \"localhost:80\", TASK_OFFSET_SUMS);\n+            new SubscriptionInfo(usedVersion, latestSupportedVersion, UUID_1, \"localhost:80\", TASK_OFFSET_SUMS, IGNORED_UNIQUE_FIELD);\n         final SubscriptionInfo expectedInfo =\n-            new SubscriptionInfo(usedVersion, latestSupportedVersion, UUID_1, \"localhost:80\", TASK_OFFSET_SUMS);\n+            new SubscriptionInfo(usedVersion, latestSupportedVersion, UUID_1, \"localhost:80\", TASK_OFFSET_SUMS, IGNORED_UNIQUE_FIELD);\n         assertEquals(expectedInfo, SubscriptionInfo.decode(info.encode()));\n     }\n \n     @Test\n     public void shouldEncodeAndDecodeVersion7() {", "originalCommit": "52c6174a4b0c651cda7498feeb5d29347b00a910", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyNjI4Nw==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501326287", "bodyText": "I think we should also add a test to make sure that if you pass in a uniqueField to the SubscriptionInfo but the usedVersion is less than 8, that it does not actually encode this field.", "author": "ableegoldman", "createdAt": "2020-10-07T21:41:13Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/SubscriptionInfoTest.java", "diffHunk": "@@ -313,7 +323,8 @@ public void shouldReturnTaskOffsetSumsMapForDecodedSubscription() {\n             new SubscriptionInfo(MIN_VERSION_OFFSET_SUM_SUBSCRIPTION,\n                                  LATEST_SUPPORTED_VERSION, UUID_1,\n                                  \"localhost:80\",\n-                                 TASK_OFFSET_SUMS)\n+                                 TASK_OFFSET_SUMS,\n+                                 IGNORED_UNIQUE_FIELD)\n                 .encode());\n         assertThat(info.taskOffsetSums(), is(TASK_OFFSET_SUMS));\n     }", "originalCommit": "52c6174a4b0c651cda7498feeb5d29347b00a910", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a1e964f7954c7c1ba5fec99a18a700566d5002d7", "url": "https://github.com/apache/kafka/commit/a1e964f7954c7c1ba5fec99a18a700566d5002d7", "message": "fix unique field", "committedDate": "2020-10-08T16:13:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTg3NTY5MQ==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501875691", "bodyText": "Can we add a comment here explaining why we set the thread count so high? I feel like we'll forget and be really confused when we stumble across this in the future.", "author": "ableegoldman", "createdAt": "2020-10-08T17:04:00Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/HighAvailabilityTaskAssignorIntegrationTest.java", "diffHunk": "@@ -286,7 +286,8 @@ private static Properties streamsProperties(final String appId,\n                 mkEntry(StreamsConfig.PROBING_REBALANCE_INTERVAL_MS_CONFIG, \"60000\"),\n                 mkEntry(StreamsConfig.InternalConfig.ASSIGNMENT_LISTENER, configuredAssignmentListener),\n                 mkEntry(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, \"100\"),\n-                mkEntry(StreamsConfig.InternalConfig.INTERNAL_TASK_ASSIGNOR_CLASS, HighAvailabilityTaskAssignor.class.getName())\n+                mkEntry(StreamsConfig.InternalConfig.INTERNAL_TASK_ASSIGNOR_CLASS, HighAvailabilityTaskAssignor.class.getName()),\n+                mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 40)", "originalCommit": "a1e964f7954c7c1ba5fec99a18a700566d5002d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTg3NjY0Ng==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r501876646", "bodyText": "nit: let's use new byte[1] for this to make sure it's actually being ignored when it should be (since apparently it won't notice if you just pass in empty bytes for this field on a version < 8)", "author": "ableegoldman", "createdAt": "2020-10-08T17:05:37Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/assignment/SubscriptionInfoTest.java", "diffHunk": "@@ -59,6 +60,7 @@\n     );\n \n     private final static String IGNORED_USER_ENDPOINT = \"ignoredUserEndpoint:80\";\n+    private static final byte[] IGNORED_UNIQUE_FIELD = Bytes.EMPTY;", "originalCommit": "a1e964f7954c7c1ba5fec99a18a700566d5002d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8dbb4998db8466dab6065b80c30c6758179eaf0e", "url": "https://github.com/apache/kafka/commit/8dbb4998db8466dab6065b80c30c6758179eaf0e", "message": "Testing updates", "committedDate": "2020-10-08T20:04:16Z", "type": "commit"}, {"oid": "1721a60b5e2c5d6be0a9b3ba3c4b622292c68ae5", "url": "https://github.com/apache/kafka/commit/1721a60b5e2c5d6be0a9b3ba3c4b622292c68ae5", "message": "Fixing tests", "committedDate": "2020-10-09T18:51:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDExMDY1Ng==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r504110656", "bodyText": "We should do the same thing that we do in StreamsPartitionAssignor here, ie a changing byte. This is supposed to be like the same exact thing but for a \"future version\" of the partition assignor, to test version probing and general compatibility.\nIt's a bit annoying that you have to just copy the same exact stuff but that's just how it is for now", "author": "ableegoldman", "createdAt": "2020-10-13T16:50:42Z", "path": "streams/src/test/java/org/apache/kafka/streams/tests/StreamsUpgradeTest.java", "diffHunk": "@@ -158,7 +159,8 @@ public ByteBuffer subscriptionUserData(final Set<String> topics) {\n                     LATEST_SUPPORTED_VERSION + 1,\n                     taskManager.processId(),\n                     userEndPoint(),\n-                    taskManager.getTaskOffsetSums()\n+                    taskManager.getTaskOffsetSums(),\n+                    Bytes.EMPTY", "originalCommit": "1721a60b5e2c5d6be0a9b3ba3c4b622292c68ae5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ed3b7fa44cd5bf836f0e60212f3ae9d31efb42a6", "url": "https://github.com/apache/kafka/commit/ed3b7fa44cd5bf836f0e60212f3ae9d31efb42a6", "message": "Testing fixes", "committedDate": "2020-10-14T19:40:57Z", "type": "commit"}, {"oid": "f286933eed98c42b3dc4c73a278b1145750ad8ae", "url": "https://github.com/apache/kafka/commit/f286933eed98c42b3dc4c73a278b1145750ad8ae", "message": "minor tweaks", "committedDate": "2020-10-14T23:18:02Z", "type": "commit"}, {"oid": "f286933eed98c42b3dc4c73a278b1145750ad8ae", "url": "https://github.com/apache/kafka/commit/f286933eed98c42b3dc4c73a278b1145750ad8ae", "message": "minor tweaks", "committedDate": "2020-10-14T23:18:02Z", "type": "forcePushed"}, {"oid": "abb42de2a843fcaf8b1acb25bfbe408421ba221a", "url": "https://github.com/apache/kafka/commit/abb42de2a843fcaf8b1acb25bfbe408421ba221a", "message": "switching to real byte", "committedDate": "2020-10-16T02:58:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU0MzE3NA==", "url": "https://github.com/apache/kafka/pull/9383#discussion_r506543174", "bodyText": "we probably ought to delete the commented-out assertions.", "author": "vvcephei", "createdAt": "2020-10-16T15:26:09Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignorTest.java", "diffHunk": "@@ -2023,13 +2022,13 @@ public void testUniqueField() {\n         configureDefaultPartitionAssignor();\n         final Set<String> topics = mkSet(\"input\");\n \n-        assertEquals(1, partitionAssignor.uniqueField().length);\n-        assertEquals(0, partitionAssignor.uniqueField()[0]);\n+        //assertEquals(1, partitionAssignor.uniqueField().length);", "originalCommit": "abb42de2a843fcaf8b1acb25bfbe408421ba221a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "382125a3d709568f8d62ac76300e79730e7b64d6", "url": "https://github.com/apache/kafka/commit/382125a3d709568f8d62ac76300e79730e7b64d6", "message": "fix comments", "committedDate": "2020-10-16T15:32:48Z", "type": "commit"}]}