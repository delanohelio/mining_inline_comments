{"pr_number": 8844, "pr_title": "KAFKA-9887 fix failed task or connector count on startup failure", "pr_createdAt": "2020-06-10T05:39:20Z", "pr_url": "https://github.com/apache/kafka/pull/8844", "timeline": [{"oid": "93d8d62d796b87865cb0d8b0fe5762345efd8be8", "url": "https://github.com/apache/kafka/commit/93d8d62d796b87865cb0d8b0fe5762345efd8be8", "message": "KAFKA-9887: Fixing failed startup metrics for connectors and tasks\n\nMoved the responsibility for recording task and connector startup and failure metrics from the invocation code\ninto the status listener.\nThe reason behind this is that the WorkerTasks (and subclasses) were either not propagating exceptions upwards,\nor were unable to do so easily because they were running on completely different threads.\n\nAlso split out WorkerMetricsGroup from being an inner class into being a standard class. This was to make sure\nthe Data Abstraction Count checkStyle rule was not violated.", "committedDate": "2020-06-10T00:47:25Z", "type": "commit"}, {"oid": "51106fa0cc1e313271e2e9d321335e81b75392ff", "url": "https://github.com/apache/kafka/commit/51106fa0cc1e313271e2e9d321335e81b75392ff", "message": "KAFKA-9887: Fixing failed startup metrics for connectors and tasks\n\nCleanup only, Removed commented out code.", "committedDate": "2020-06-10T01:02:58Z", "type": "commit"}, {"oid": "b483e34335f3fedecd3cb1b5bb2d7bedd45f68d0", "url": "https://github.com/apache/kafka/commit/b483e34335f3fedecd3cb1b5bb2d7bedd45f68d0", "message": " KAFKA-9887: Fixing failed startup metrics for connectors and tasks\n\nFix broken unit tests that still assume the Worker class is responsible for updating connector and task startup statistics", "committedDate": "2020-06-10T03:08:16Z", "type": "commit"}, {"oid": "5fc7aa7bda6a761b48d8e3e6ac993fe5bba67597", "url": "https://github.com/apache/kafka/commit/5fc7aa7bda6a761b48d8e3e6ac993fe5bba67597", "message": "Merge branch 'trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure", "committedDate": "2020-06-15T00:17:25Z", "type": "commit"}, {"oid": "5fc7aa7bda6a761b48d8e3e6ac993fe5bba67597", "url": "https://github.com/apache/kafka/commit/5fc7aa7bda6a761b48d8e3e6ac993fe5bba67597", "message": "Merge branch 'trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure", "committedDate": "2020-06-15T00:17:25Z", "type": "forcePushed"}, {"oid": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "url": "https://github.com/apache/kafka/commit/45bb0cef1e6396ab198e3dd3b3be6be13339358e", "message": "Merge remote-tracking branch 'upstream/trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure", "committedDate": "2020-06-17T23:21:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzI5OTgwOA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443299808", "bodyText": "Nit: the name here is a bit verbose. The type signature of the parameter here already tells us that this is for a connector status listener; do you think wrapStatusListener or even just statusListener might convey the necessary information?", "author": "C0urante", "createdAt": "2020-06-22T03:22:49Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapConnectorStatusListener(ConnectorStatus.Listener delegateListener) {", "originalCommit": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4NTkwMQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443385901", "bodyText": "Yep, that sounds fair. I'll rename it (pending the discussion on direction overall)", "author": "michael-carter-instaclustr", "createdAt": "2020-06-22T08:09:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzI5OTgwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzI5OTkwMA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443299900", "bodyText": "Same comment here w/r/t naming; I think wrapStatusListener or statusListener may be warranted.", "author": "C0urante", "createdAt": "2020-06-22T03:23:17Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapTaskStatusListener(TaskStatus.Listener delegateListener) {", "originalCommit": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4NTk3MA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443385970", "bodyText": "Yep, that sounds fair. I'll rename it (pending the discussion on direction overall)", "author": "michael-carter-instaclustr", "createdAt": "2020-06-22T08:09:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzI5OTkwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwMDA2OA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443300068", "bodyText": "Another nit (sorry!): given that this is already an inner class for the WorkerMetricsGroup class, the WorkerMetricsGroup prefix seems redundant. What do you think about just ConnectorStatusListener?", "author": "C0urante", "createdAt": "2020-06-22T03:24:14Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapTaskStatusListener(TaskStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupTaskStatusListener(delegateListener);\n+    }\n+\n+    class WorkerMetricsGroupConnectorStatusListener implements ConnectorStatus.Listener {", "originalCommit": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4NjQxOA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443386418", "bodyText": "It was a little close to ConnectorStatus.Listener for me originally, but yeah i agree the name is cumbersome. I'm happy to rename it.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-22T08:10:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwMDA2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwMDE0Mg==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443300142", "bodyText": "Same (nitty) comment here: maybe just TaskStatusListener?", "author": "C0urante", "createdAt": "2020-06-22T03:24:41Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapTaskStatusListener(TaskStatus.Listener delegateListener) {\n+        return new WorkerMetricsGroupTaskStatusListener(delegateListener);\n+    }\n+\n+    class WorkerMetricsGroupConnectorStatusListener implements ConnectorStatus.Listener {\n+        private final ConnectorStatus.Listener delegateListener;\n+        private boolean startupSucceeded = false;\n+\n+        WorkerMetricsGroupConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+            this.delegateListener = delegateListener;\n+        }\n+\n+        @Override\n+        public void onShutdown(final String connector) {\n+            delegateListener.onShutdown(connector);\n+        }\n+\n+        @Override\n+        public void onFailure(final String connector, final Throwable cause) {\n+            if (!startupSucceeded) {\n+                recordConnectorStartupFailure();\n+            }\n+            delegateListener.onFailure(connector, cause);\n+        }\n+\n+        @Override\n+        public void onPause(final String connector) {\n+            delegateListener.onPause(connector);\n+        }\n+\n+        @Override\n+        public void onResume(final String connector) {\n+            delegateListener.onResume(connector);\n+        }\n+\n+        @Override\n+        public void onStartup(final String connector) {\n+            delegateListener.onStartup(connector);\n+            startupSucceeded = true;\n+            recordConnectorStartupSuccess();\n+        }\n+\n+        @Override\n+        public void onDeletion(final String connector) {\n+            delegateListener.onDeletion(connector);\n+        }\n+    }\n+\n+    class WorkerMetricsGroupTaskStatusListener implements TaskStatus.Listener {", "originalCommit": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4NjU1MQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443386551", "bodyText": "It was a little close to TaskStatus.Listener for me originally, but yeah i agree the name is cumbersome. I'm happy to rename it.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-22T08:10:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwMDE0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODE3NQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443308175", "bodyText": "I think we might want to keep this line here in case we fail somehow before even creating the WorkerConnector instance.", "author": "C0urante", "createdAt": "2020-06-22T04:09:13Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -289,7 +285,6 @@ public void startConnector(\n                 // Can't be put in a finally block because it needs to be swapped before the call on\n                 // statusListener\n                 Plugins.compareAndSwapLoaders(savedLoader);\n-                workerMetricsGroup.recordConnectorStartupFailure();", "originalCommit": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4NTQ5MQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443385491", "bodyText": "Good point. I believe we could achieve the same effect by wrapping the statusListener earlier in the method and using the wrapped listener in the exception handler. That way the only way we could fail without recording a metric would be if the wrapping itself failed (which is a dead simple constructor, so seems unlikely)", "author": "michael-carter-instaclustr", "createdAt": "2020-06-22T08:08:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzc0Mjk0Nw==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443742947", "bodyText": "Oooh, yeah that's neat. \ud83d\udc4d", "author": "C0urante", "createdAt": "2020-06-22T18:17:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODE3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODkxNw==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443308917", "bodyText": "It seems a little unclean to start calling the statusListener from the subclass when it's been used exclusively by the WorkerTask abstract class up to this point. Not the end of the world but I think we might be able to do this more cleanly by decomposing the existing execute method into separate initializeAndStart (name obviously subject to change) and execute methods, with the call to statusListener::onStartup in between them. This way, we can avoid worrying about the status listener in the subclasses and can  encapsulate some shared logic in the abstract superclass. What are your thoughts?", "author": "C0urante", "createdAt": "2020-06-22T04:13:16Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java", "diffHunk": "@@ -56,7 +56,7 @@\n     private static final String THREAD_NAME_PREFIX = \"task-thread-\";\n \n     protected final ConnectorTaskId id;\n-    private final TaskStatus.Listener statusListener;\n+    protected final TaskStatus.Listener statusListener;", "originalCommit": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4NzM2OA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443387368", "bodyText": "Yes, I had the same thought and initially started going down that road. The source of the problem as it appeared to me was that the failure methods inside the WorkerConnector/WorkerTasks were catching any failure and not propagating any exception back up to Worker where it would be able to record metrics. Simply allowing the exception to filter back up seemed the way to go, but since I needed to differentiate between a failure in startup and a failure during regular execution, separating those methods seemed a good way to do it.  This worked very well for the connector at the time, but got a bit more difficult for the tasks because they were being sent to an executor service, so there wan\u2019t an obvious exception handler in the Worker class to handle problems. (I\u2019ve noticed that since I looked at this, you\u2019ve committed a change that makes the connectors use an executor service too, so this probably now applies to connectors as well as tasks). I wasn\u2019t entirely certain whether it was important or not that the startup code run on the same thread as the regular execution, but assumed that it was, so started putting in a chain of CompletableFutures where I could check for exceptions in the other thread and only go on to submit the execute stage if the initialiseAndStart stage completed successfully. But this required there to be two different entry points for execution into the WorkerConnector/WorkerTasks which kind of defeated the point of them implementing the Runnable interface, and the exception checking was a bit ugly anyway. It was at this point that I discovered the statusListener and thought that might be a cleaner way to go. Not the only way of course, but it seemed to me to be a smaller change. Separating those methods would be more easily achieved if the startup phase could run on the same thread as the Worker, but that seems to me like more of a significant change?", "author": "michael-carter-instaclustr", "createdAt": "2020-06-22T08:12:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODkxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzc1NjQyNA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443756424", "bodyText": "Yeah, we definitely don't want to run connector or task code on the same thread as the Worker (or really, the Herder that's calling the Worker). I don't think it's that bad if the startup and recording of metrics happens asynchronously from the call to Worker::startConnector or Worker::startTask; the only potential downside I can think of is that someone might believe they've started a connector/task but the startup metrics for the worker might not yet be incremented if the connector/task is taking a while (or just completely hung) during startup.\nI was just suggesting a small refactoring though, not anything that would affect the actual behavior of the framework. Just something to make the code a little cleaner.\nIn case it helps, I was thinking WorkerTask might look like this:\nabstract class WorkerTask {\n    private final TaskStatus.Listener statusListener;\n\n    protected abstract void initializeAndStart();\n\n    protected abstract void execute();\n\n        private void doRun() throws InterruptedException {\n        try {\n            synchronized (this) {\n                if (stopping)\n                    return;\n\n                if (targetState == TargetState.PAUSED) {\n                    onPause();\n                    if (!awaitUnpause()) return;\n                }\n            }\n\n            // These three lines replace the single call to execute() that's in the WorkerTask class right now\n            initializeAndStart();\n            statusListener.onStartup();\n            execute();\n        } catch (Throwable t) {\n            log.error(\"{} Task threw an uncaught and unrecoverable exception\", this, t);\n            log.error(\"{} Task is being killed and will not recover until manually restarted\", this);\n            throw t;\n        } finally {\n            doClose();\n        }\n    }\n}\n\nWorkerSinkTask might look like this:\nclass WorkerSinkTask extends WorkerTask {\n\n    // This is already a method in the WorkerSinkTask class, but now it overrides an abstract method in the WorkerTask superclass\n    @Override\n    protected void initializeAndStart() {\n        SinkConnectorConfig.validate(taskConfig);\n\n        if (SinkConnectorConfig.hasTopicsConfig(taskConfig)) {\n            List<String> topics = SinkConnectorConfig.parseTopicsList(taskConfig);\n            consumer.subscribe(topics, new HandleRebalance());\n            log.debug(\"{} Initializing and starting task for topics {}\", this, Utils.join(topics, \", \"));\n        } else {\n            String topicsRegexStr = taskConfig.get(SinkTask.TOPICS_REGEX_CONFIG);\n            Pattern pattern = Pattern.compile(topicsRegexStr);\n            consumer.subscribe(pattern, new HandleRebalance());\n            log.debug(\"{} Initializing and starting task for topics regex {}\", this, topicsRegexStr);\n        }\n\n        task.initialize(context);\n        task.start(taskConfig);\n        log.info(\"{} Sink task finished initialization and start\", this);\n    }\n\n    // Remove the call to initializeAndStart() and statusListener.onStartup() here; they'll be called automatically by the superclass\n    @Override\n    public void execute() {\n        // Make sure any uncommitted data has been committed and the task has\n        // a chance to clean up its state\n        try (UncheckedCloseable suppressible = this::closePartitions) {\n            while (!isStopping())\n                iteration();\n        }\n    }\n}\nAnd WorkerSourceTask might look like this:\nclass WorkerSourceTask extends WorkerTask {\n\n    // Technically a new method, but all code has just been cut+pasted from the existing execute() method\n    @Override\n    protected void initializeAndStart() {\n        task.initialize(new WorkerSourceTaskContext(offsetReader, this, configState));\n        task.start(taskConfig);\n        log.info(\"{} Source task finished initialization and start\", this);\n    }\n \n    // Same as the existing execute() method, except for the code removed for initializeAndStart() and the call to statusListener.onStartup\n    @Override\n    public void execute() {\n        synchronized (this) {\n            if (startedShutdownBeforeStartCompleted) {\n                tryStop();\n                return;\n            }\n            finishedStart = true;\n        }\n\n        try {\n            while (!isStopping()) {\n                if (shouldPause()) {\n                    onPause();\n                    if (awaitUnpause()) {\n                        onResume();\n                    }\n                    continue;\n                }\n\n                maybeThrowProducerSendException();\n\n                if (toSend == null) {\n                    log.trace(\"{} Nothing to send to Kafka. Polling source for additional records\", this);\n                    long start = time.milliseconds();\n                    toSend = poll();\n                    if (toSend != null) {\n                        recordPollReturned(toSend.size(), time.milliseconds() - start);\n                    }\n                }\n                if (toSend == null)\n                    continue;\n                log.trace(\"{} About to send {} records to Kafka\", this, toSend.size());\n                if (!sendRecords())\n                    stopRequestedLatch.await(SEND_FAILED_BACKOFF_MS, TimeUnit.MILLISECONDS);\n            }\n        } catch (InterruptedException e) {\n            // Ignore and allow to exit.\n        } finally {\n            // It should still be safe to commit offsets since any exception would have\n            // simply resulted in not getting more records but all the existing records should be ok to flush\n            // and commit offsets. Worst case, task.flush() will also throw an exception causing the offset commit\n            // to fail.\n            commitOffsets();\n        }\n    }\n}", "author": "C0urante", "createdAt": "2020-06-22T18:44:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODkxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkzNTE2MQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443935161", "bodyText": "Ah, of course! Yes that seems better, I'll do that.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-23T03:04:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwODkxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwOTkwNg==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443309906", "bodyText": "I think we might want to keep this line here in case we fail somehow before even creating the WorkerTask instance. This can happen if a Converter, Transformation, etc. throws an exception during startup.", "author": "C0urante", "createdAt": "2020-06-22T04:18:53Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -562,7 +556,6 @@ public boolean startTask(\n                 // statusListener\n                 Plugins.compareAndSwapLoaders(savedLoader);\n                 connectorStatusMetricsGroup.recordTaskRemoved(id);\n-                workerMetricsGroup.recordTaskFailure();", "originalCommit": "45bb0cef1e6396ab198e3dd3b3be6be13339358e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4NTYzOQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443385639", "bodyText": "Good point. I believe we could achieve the same effect by wrapping the statusListener earlier in the method and using the wrapped listener in the exception handler. That way the only way we could fail without recording a metric would be if the wrapping itself failed (which is a dead simple constructor, so seems unlikely)", "author": "michael-carter-instaclustr", "createdAt": "2020-06-22T08:08:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwOTkwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzc1NjUyOQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r443756529", "bodyText": "Sounds good!", "author": "C0urante", "createdAt": "2020-06-22T18:44:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzMwOTkwNg=="}], "type": "inlineReview"}, {"oid": "70b2db9a68ba0c9a86455779344cece99e221ae9", "url": "https://github.com/apache/kafka/commit/70b2db9a68ba0c9a86455779344cece99e221ae9", "message": "KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure\n\nChanges from code review", "committedDate": "2020-06-23T08:42:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQzNzI3Nw==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444437277", "bodyText": "This is going to be modified and accessed on potentially different threads, right? If so, we should add the volatile modifier here.", "author": "C0urante", "createdAt": "2020-06-23T18:52:07Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new ConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapStatusListener(TaskStatus.Listener delegateListener) {\n+        return new TaskStatusListener(delegateListener);\n+    }\n+\n+    class ConnectorStatusListener implements ConnectorStatus.Listener {\n+        private final ConnectorStatus.Listener delegateListener;\n+        private boolean startupSucceeded = false;\n+\n+        ConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+            this.delegateListener = delegateListener;\n+        }\n+\n+        @Override\n+        public void onShutdown(final String connector) {\n+            delegateListener.onShutdown(connector);\n+        }\n+\n+        @Override\n+        public void onFailure(final String connector, final Throwable cause) {\n+            if (!startupSucceeded) {\n+                recordConnectorStartupFailure();\n+            }\n+            delegateListener.onFailure(connector, cause);\n+        }\n+\n+        @Override\n+        public void onPause(final String connector) {\n+            delegateListener.onPause(connector);\n+        }\n+\n+        @Override\n+        public void onResume(final String connector) {\n+            delegateListener.onResume(connector);\n+        }\n+\n+        @Override\n+        public void onStartup(final String connector) {\n+            delegateListener.onStartup(connector);\n+            startupSucceeded = true;\n+            recordConnectorStartupSuccess();\n+        }\n+\n+        @Override\n+        public void onDeletion(final String connector) {\n+            delegateListener.onDeletion(connector);\n+        }\n+    }\n+\n+    class TaskStatusListener implements TaskStatus.Listener {\n+        private final TaskStatus.Listener delegatedListener;\n+        private boolean startupSucceeded = false;", "originalCommit": "70b2db9a68ba0c9a86455779344cece99e221ae9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxNTE0OQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444715149", "bodyText": "Yep, I think there is a possibility of calling this from different threads. I'll add that in.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-24T08:01:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQzNzI3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQzNzMxOQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444437319", "bodyText": "This is going to be modified and accessed on potentially different threads, right? If so, we should add the volatile modifier here.", "author": "C0urante", "createdAt": "2020-06-23T18:52:13Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new ConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapStatusListener(TaskStatus.Listener delegateListener) {\n+        return new TaskStatusListener(delegateListener);\n+    }\n+\n+    class ConnectorStatusListener implements ConnectorStatus.Listener {\n+        private final ConnectorStatus.Listener delegateListener;\n+        private boolean startupSucceeded = false;", "originalCommit": "70b2db9a68ba0c9a86455779344cece99e221ae9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxNTIwNA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444715204", "bodyText": "Yep, I think there is a possibility of calling this from different threads. I'll add that in.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-24T08:01:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQzNzMxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NTA2OQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444445069", "bodyText": "It's a little strange that we're mocking the class that we're testing here. Could we test on a real WorkerMetricsGroup object and mock its dependencies (specifically, the ConnectMetrics object that it takes in its constructor) instead? Might be a bit more work but would give us stronger guarantees about the accuracy and coverage of these tests.", "author": "C0urante", "createdAt": "2020-06-23T19:05:56Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);", "originalCommit": "70b2db9a68ba0c9a86455779344cece99e221ae9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxNTk5OA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444715998", "bodyText": "Yeah I started doing that. It got very messy as the constructor for WorkerMetricsGroup has a lot of dependencies. I'm happy to give it another go though.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-24T08:03:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NTA2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NjM0MA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444446340", "bodyText": "Nit: can probably just use the @Mock annotation and make these instance instead of local variables so that we don't have to repeat this code at the beginning of each test.", "author": "C0urante", "createdAt": "2020-06-23T19:08:15Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);", "originalCommit": "70b2db9a68ba0c9a86455779344cece99e221ae9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1NDQ2Ng==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444454466", "bodyText": "Ahh, I see--we construct a connector status listener for some and a task status listener for others. Honestly, I think it's probably fine if we just make both available as instance variables and @Mock them.", "author": "C0urante", "createdAt": "2020-06-23T19:23:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NjM0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxNjQxMA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444716410", "bodyText": "Yeah, I think it should be fine to do it with annotated class level variables", "author": "michael-carter-instaclustr", "createdAt": "2020-06-24T08:03:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NjM0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MDc0OQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444450749", "bodyText": "Nit: looks like similar calls use eq(connector) instead of connector. I think they both work but we should stick to one or the other.", "author": "C0urante", "createdAt": "2020-06-23T19:16:32Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);\n+        final WorkerMetricsGroup.ConnectorStatusListener connectorListener = mockWorkerMetricsGroup.new ConnectorStatusListener(delegate);\n+\n+        delegate.onStartup(connector);", "originalCommit": "70b2db9a68ba0c9a86455779344cece99e221ae9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxNjUyMg==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444716522", "bodyText": "Good point. Will fix.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-24T08:04:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MDc0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MTg2Nw==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444451867", "bodyText": "Nit: I think it might make more sense if the expectations are set in chronological order instead of grouping by which mocked instance is having expectations set. So in this case, this line would be moved after the expectation for delegate::onStartup and before the one for delegate::onFailure. But not a big deal, if you think this is more readable feel free to leave as-is.", "author": "C0urante", "createdAt": "2020-06-23T19:18:45Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerMetricsGroupTest.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import static org.easymock.EasyMock.eq;\n+import static org.powermock.api.easymock.PowerMock.createStrictMock;\n+import static org.powermock.api.easymock.PowerMock.expectLastCall;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({Sensor.class})\n+public class WorkerMetricsGroupTest {\n+    private final String connector = \"org.FakeConnector\";\n+    private final ConnectorTaskId task = new ConnectorTaskId(connector, 0);\n+    private final RuntimeException exception = new RuntimeException();\n+\n+    @Test\n+    public void testConnectorStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);\n+        final WorkerMetricsGroup.ConnectorStatusListener connectorListener = mockWorkerMetricsGroup.new ConnectorStatusListener(delegate);\n+\n+        delegate.onStartup(connector);\n+        expectLastCall();\n+\n+        mockWorkerMetricsGroup.recordConnectorStartupSuccess();\n+        expectLastCall();\n+\n+        PowerMock.replayAll();\n+\n+        connectorListener.onStartup(connector);\n+\n+        PowerMock.verifyAll();\n+    }\n+\n+    @Test\n+    public void testConnectorFailureAfterStartupRecordedMetrics() {\n+        final WorkerMetricsGroup mockWorkerMetricsGroup = createStrictMock(WorkerMetricsGroup.class);\n+        final ConnectorStatus.Listener delegate = createStrictMock(ConnectorStatus.Listener.class);\n+        final WorkerMetricsGroup.ConnectorStatusListener connectorListener = mockWorkerMetricsGroup.new ConnectorStatusListener(delegate);\n+\n+        delegate.onStartup(eq(connector));\n+        expectLastCall();\n+\n+        delegate.onFailure(eq(connector), eq(exception));\n+        expectLastCall();\n+\n+        mockWorkerMetricsGroup.recordConnectorStartupSuccess();", "originalCommit": "70b2db9a68ba0c9a86455779344cece99e221ae9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxNjY4Mw==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444716683", "bodyText": "No argument from me. I'll change it.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-24T08:04:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MTg2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1NDA0OA==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444454048", "bodyText": "It's unfortunate that we're losing test coverage here, especially since it makes issues like the one that necessitates this PR more likely as we can't prevent regressions. Is there a way we can keep some of this testing logic, either through modifying the WorkerTest or by relocating it to the WorkerMetricsGroupTest?", "author": "C0urante", "createdAt": "2020-06-23T19:22:56Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerTest.java", "diffHunk": "@@ -336,14 +336,11 @@ public void testStartConnectorFailure() throws Exception {\n             assertEquals(exception, e.getCause());\n         }\n \n-        assertStartupStatistics(worker, 1, 1, 0, 0);", "originalCommit": "70b2db9a68ba0c9a86455779344cece99e221ae9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcxODgwMw==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r444718803", "bodyText": "Yes, I understand where you're coming from. I suppose the thing is that it's no longer the Worker's responsibility to record these metrics, so checking for them in the Worker Unit Test doesn't seem the right spot. The WorkerMetricsGroupTest tests the operation of the recording through the new tests. So I think what we're missing is something that checks that the Worker calls the wrapped status listener when we expect it to. I'll have a think about it  some more.", "author": "michael-carter-instaclustr", "createdAt": "2020-06-24T08:08:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1NDA0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQ0OTI4NQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603449285", "bodyText": "Both of you raise good points. But I tend to agree with @C0urante that it's better to keep these checks. @michael-carter-instaclustr is right that the new WorkerMetricsGroupTest is where we should validate that WorkerMetricsGroup works correctly. These assertions, however, serve to verify that the Worker is calling the WorkerMetricsGroup correctly, and they serve to help detect regressions. Besides, there still are lots of places within WorkerTest where the assertStartupStatistics(...) method is still called, so why keep only some of these rather than keep them all?", "author": "rhauch", "createdAt": "2021-03-29T16:43:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1NDA0OA=="}], "type": "inlineReview"}, {"oid": "8bf7d92fe6398dc229ada8bc007fbbbc95c72c8c", "url": "https://github.com/apache/kafka/commit/8bf7d92fe6398dc229ada8bc007fbbbc95c72c8c", "message": "KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure\n\nChanges to unit tests from code review", "committedDate": "2020-06-25T03:19:59Z", "type": "commit"}, {"oid": "f2912c8fd0957c14c6a31db9f85c39239383c491", "url": "https://github.com/apache/kafka/commit/f2912c8fd0957c14c6a31db9f85c39239383c491", "message": "Merge branch 'trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure", "committedDate": "2020-10-08T22:33:26Z", "type": "commit"}, {"oid": "a091df56f455fe598655949268f5e8025ad796da", "url": "https://github.com/apache/kafka/commit/a091df56f455fe598655949268f5e8025ad796da", "message": "Merge branch 'trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure", "committedDate": "2020-11-02T23:09:10Z", "type": "commit"}, {"oid": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "url": "https://github.com/apache/kafka/commit/730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "message": "Fixed unit test that was not using the initializeAndStart() method", "committedDate": "2020-11-03T02:00:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTI2ODI5Ng==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r595268296", "bodyText": "Let's avoid unnecessary changes.", "author": "rhauch", "createdAt": "2021-03-16T15:14:43Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java", "diffHunk": "@@ -191,9 +191,9 @@ public void transitionTo(TargetState state) {\n         consumer.wakeup();\n     }\n \n+", "originalCommit": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQwMDIyMQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603400221", "bodyText": "Nit: the methods of the ConnectorStatusListener and TaskStatusListener classes are in very different orders. It would help readability to have them in the same order. IMO, the order of the TaskStatusListener methods is nice because it follows the lifecycle.", "author": "rhauch", "createdAt": "2021-03-29T15:38:09Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new ConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapStatusListener(TaskStatus.Listener delegateListener) {\n+        return new TaskStatusListener(delegateListener);\n+    }\n+\n+    class ConnectorStatusListener implements ConnectorStatus.Listener {", "originalCommit": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQwMjYwNw==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603402607", "bodyText": "Why is the order of these methods different than in ConnectorStatusListener?\nAlso, the TaskStatusListener methods always forward the method to the delegate last, whereas the methods of the ConnectorStatusListener use a mixture. Let's make them consistent.", "author": "rhauch", "createdAt": "2021-03-29T15:41:14Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerMetricsGroup.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.Sensor;\n+import org.apache.kafka.common.metrics.stats.CumulativeSum;\n+import org.apache.kafka.common.metrics.stats.Frequencies;\n+import org.apache.kafka.connect.util.ConnectorTaskId;\n+\n+import java.util.Map;\n+\n+class WorkerMetricsGroup {\n+    private final ConnectMetrics.MetricGroup metricGroup;\n+    private final Sensor connectorStartupAttempts;\n+    private final Sensor connectorStartupSuccesses;\n+    private final Sensor connectorStartupFailures;\n+    private final Sensor connectorStartupResults;\n+    private final Sensor taskStartupAttempts;\n+    private final Sensor taskStartupSuccesses;\n+    private final Sensor taskStartupFailures;\n+    private final Sensor taskStartupResults;\n+\n+    public WorkerMetricsGroup(final Map<String, WorkerConnector> connectors, Map<ConnectorTaskId, WorkerTask> tasks, ConnectMetrics connectMetrics) {\n+        ConnectMetricsRegistry registry = connectMetrics.registry();\n+        metricGroup = connectMetrics.group(registry.workerGroupName());\n+\n+        metricGroup.addValueMetric(registry.connectorCount, now -> (double) connectors.size());\n+        metricGroup.addValueMetric(registry.taskCount, now -> (double) tasks.size());\n+\n+        MetricName connectorFailurePct = metricGroup.metricName(registry.connectorStartupFailurePercentage);\n+        MetricName connectorSuccessPct = metricGroup.metricName(registry.connectorStartupSuccessPercentage);\n+        Frequencies connectorStartupResultFrequencies = Frequencies.forBooleanValues(connectorFailurePct, connectorSuccessPct);\n+        connectorStartupResults = metricGroup.sensor(\"connector-startup-results\");\n+        connectorStartupResults.add(connectorStartupResultFrequencies);\n+\n+        connectorStartupAttempts = metricGroup.sensor(\"connector-startup-attempts\");\n+        connectorStartupAttempts.add(metricGroup.metricName(registry.connectorStartupAttemptsTotal), new CumulativeSum());\n+\n+        connectorStartupSuccesses = metricGroup.sensor(\"connector-startup-successes\");\n+        connectorStartupSuccesses.add(metricGroup.metricName(registry.connectorStartupSuccessTotal), new CumulativeSum());\n+\n+        connectorStartupFailures = metricGroup.sensor(\"connector-startup-failures\");\n+        connectorStartupFailures.add(metricGroup.metricName(registry.connectorStartupFailureTotal), new CumulativeSum());\n+\n+        MetricName taskFailurePct = metricGroup.metricName(registry.taskStartupFailurePercentage);\n+        MetricName taskSuccessPct = metricGroup.metricName(registry.taskStartupSuccessPercentage);\n+        Frequencies taskStartupResultFrequencies = Frequencies.forBooleanValues(taskFailurePct, taskSuccessPct);\n+        taskStartupResults = metricGroup.sensor(\"task-startup-results\");\n+        taskStartupResults.add(taskStartupResultFrequencies);\n+\n+        taskStartupAttempts = metricGroup.sensor(\"task-startup-attempts\");\n+        taskStartupAttempts.add(metricGroup.metricName(registry.taskStartupAttemptsTotal), new CumulativeSum());\n+\n+        taskStartupSuccesses = metricGroup.sensor(\"task-startup-successes\");\n+        taskStartupSuccesses.add(metricGroup.metricName(registry.taskStartupSuccessTotal), new CumulativeSum());\n+\n+        taskStartupFailures = metricGroup.sensor(\"task-startup-failures\");\n+        taskStartupFailures.add(metricGroup.metricName(registry.taskStartupFailureTotal), new CumulativeSum());\n+    }\n+\n+    void close() {\n+        metricGroup.close();\n+    }\n+\n+    void recordConnectorStartupFailure() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupFailures.record(1.0);\n+        connectorStartupResults.record(0.0);\n+    }\n+\n+    void recordConnectorStartupSuccess() {\n+        connectorStartupAttempts.record(1.0);\n+        connectorStartupSuccesses.record(1.0);\n+        connectorStartupResults.record(1.0);\n+    }\n+\n+    void recordTaskFailure() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupFailures.record(1.0);\n+        taskStartupResults.record(0.0);\n+    }\n+\n+    void recordTaskSuccess() {\n+        taskStartupAttempts.record(1.0);\n+        taskStartupSuccesses.record(1.0);\n+        taskStartupResults.record(1.0);\n+    }\n+\n+    protected ConnectMetrics.MetricGroup metricGroup() {\n+        return metricGroup;\n+    }\n+\n+    ConnectorStatus.Listener wrapStatusListener(ConnectorStatus.Listener delegateListener) {\n+        return new ConnectorStatusListener(delegateListener);\n+    }\n+\n+    TaskStatus.Listener wrapStatusListener(TaskStatus.Listener delegateListener) {\n+        return new TaskStatusListener(delegateListener);\n+    }\n+\n+    class ConnectorStatusListener implements ConnectorStatus.Listener {\n+        private final ConnectorStatus.Listener delegateListener;\n+        private volatile boolean startupSucceeded = false;\n+\n+        ConnectorStatusListener(ConnectorStatus.Listener delegateListener) {\n+            this.delegateListener = delegateListener;\n+        }\n+\n+        @Override\n+        public void onShutdown(final String connector) {\n+            delegateListener.onShutdown(connector);\n+        }\n+\n+        @Override\n+        public void onFailure(final String connector, final Throwable cause) {\n+            if (!startupSucceeded) {\n+                recordConnectorStartupFailure();\n+            }\n+            delegateListener.onFailure(connector, cause);\n+        }\n+\n+        @Override\n+        public void onPause(final String connector) {\n+            delegateListener.onPause(connector);\n+        }\n+\n+        @Override\n+        public void onResume(final String connector) {\n+            delegateListener.onResume(connector);\n+        }\n+\n+        @Override\n+        public void onStartup(final String connector) {\n+            delegateListener.onStartup(connector);\n+            startupSucceeded = true;\n+            recordConnectorStartupSuccess();\n+        }\n+\n+        @Override\n+        public void onDeletion(final String connector) {\n+            delegateListener.onDeletion(connector);\n+        }\n+    }\n+\n+    class TaskStatusListener implements TaskStatus.Listener {\n+        private final TaskStatus.Listener delegatedListener;\n+        private volatile boolean startupSucceeded = false;\n+\n+        TaskStatusListener(TaskStatus.Listener delegatedListener) {\n+            this.delegatedListener = delegatedListener;\n+        }\n+\n+        @Override\n+        public void onStartup(final ConnectorTaskId id) {\n+            recordTaskSuccess();\n+            startupSucceeded = true;\n+            delegatedListener.onStartup(id);", "originalCommit": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQwNTM0MQ==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603405341", "bodyText": "We're removing the INFO-level log message here, which we use to help identify that the worker task entered this method. It might be good to keep an INFO-level log message here, but use something like `{} Executing source task\". WDYT?", "author": "rhauch", "createdAt": "2021-03-29T15:44:44Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java", "diffHunk": "@@ -225,12 +225,16 @@ private synchronized void tryStop() {\n         }\n     }\n \n+    @Override\n+    protected void initializeAndStart() {\n+        task.initialize(new WorkerSourceTaskContext(offsetReader, this, configState));\n+        task.start(taskConfig);\n+        log.info(\"{} Source task finished initialization and start\", this);\n+    }\n+\n     @Override\n     public void execute() {\n         try {\n-            task.initialize(new WorkerSourceTaskContext(offsetReader, this, configState));\n-            task.start(taskConfig);\n-            log.info(\"{} Source task finished initialization and start\", this);", "originalCommit": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQwOTM0Mg==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603409342", "bodyText": "We never really had an INFO-level log message here (unlike WorkerSourceTask.execute(), though we could always tell by the INFO-level log message in initializeAndStart(). Since the latter now does a bit more work, it probably is better to have an INFO-level log message here at the start of execute(). What do you think about adding an INFO-level log message here, using something like {} Executing sink task\" (similar to WorkerSourceTask.execute()`)?", "author": "rhauch", "createdAt": "2021-03-29T15:49:35Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java", "diffHunk": "@@ -191,9 +191,9 @@ public void transitionTo(TargetState state) {\n         consumer.wakeup();\n     }\n \n+\n     @Override\n     public void execute() {\n-        initializeAndStart();", "originalCommit": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzQyMTM0Mw==", "url": "https://github.com/apache/kafka/pull/8844#discussion_r603421343", "bodyText": "I see how you've just pulled the WorkerSinkTask.initializeAndStart() method up to this abstract class (per @C0urante's suggestion. That is a nice clean way to encapsulate that logic into the base class and keep the metrics behavior hidden from the subclasses. Nicely done.\nIt is a tiny bit unfortunate that the tests need to do something like:\n        workerSourceTask.initialize(TASK_CONFIG);   // This just sets the config on the worker task\n        workerSourceTask.initializeAndStart();            // This calls task.initialize(...) and task.start(...)\n        workerSourceTask.execute();\n\nBut the initializeAndStart() method in the WorkerSinkTask has been around since the beginning, and it's probably not worth changing here. After all, using initializeAndStart() still makes sense within the WorkerSinkTask and now also the WorkerTask and WorkerSourceTask classes. So I'm fine with enlisting that method name as-is.", "author": "rhauch", "createdAt": "2021-03-29T16:04:43Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java", "diffHunk": "@@ -151,6 +151,8 @@ public void removeMetrics() {\n         taskMetricsGroup.close();\n     }\n \n+    protected abstract void initializeAndStart();", "originalCommit": "730eb2fb70642ad81f4d30a5bd88c55f1a735be5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bff3bb1e771c5e9ea5d49c27d26b4b16bc385397", "url": "https://github.com/apache/kafka/commit/bff3bb1e771c5e9ea5d49c27d26b4b16bc385397", "message": "Reorder methods and lines in WorkerMetricsGroup\nAdded additional logging in execute() methods of WorkerSinkTask and WorkerSourceTask", "committedDate": "2021-03-31T22:54:31Z", "type": "commit"}, {"oid": "52b0bc4da61b178e6cbc1c1776cddf2891768e49", "url": "https://github.com/apache/kafka/commit/52b0bc4da61b178e6cbc1c1776cddf2891768e49", "message": "Merge remote-tracking branch 'upstream/trunk' into KAFKA-9887-Fix-failed-task-or-connector-count-on-startup-failure", "committedDate": "2021-03-31T23:36:02Z", "type": "commit"}, {"oid": "e9463460c7c90da4cf4d5b2a5bcfde3e1402fed4", "url": "https://github.com/apache/kafka/commit/e9463460c7c90da4cf4d5b2a5bcfde3e1402fed4", "message": "fixed broken unit test", "committedDate": "2021-04-01T01:08:12Z", "type": "commit"}, {"oid": "8875af670b0fc74cef838e4d4fdfaa1615fd1328", "url": "https://github.com/apache/kafka/commit/8875af670b0fc74cef838e4d4fdfaa1615fd1328", "message": "re-deleted already removed files", "committedDate": "2021-04-01T01:30:47Z", "type": "commit"}, {"oid": "ceb246d5b4a8356781af4ced2fbbf82aa7645d4a", "url": "https://github.com/apache/kafka/commit/ceb246d5b4a8356781af4ced2fbbf82aa7645d4a", "message": "added back some asserts", "committedDate": "2021-04-01T05:43:19Z", "type": "commit"}, {"oid": "ccf09d2ae0a017a7469542c27dabe5cb843c2f9f", "url": "https://github.com/apache/kafka/commit/ccf09d2ae0a017a7469542c27dabe5cb843c2f9f", "message": "Merge branch 'trunk' into kafka-9887", "committedDate": "2021-07-20T15:13:55Z", "type": "commit"}, {"oid": "333c985055f3db9a21ad02f270dadadd50536916", "url": "https://github.com/apache/kafka/commit/333c985055f3db9a21ad02f270dadadd50536916", "message": "Added onRestart method to listener implementations. This was recently added in KIP-745 (PR #10822)", "committedDate": "2021-07-20T15:41:56Z", "type": "commit"}]}