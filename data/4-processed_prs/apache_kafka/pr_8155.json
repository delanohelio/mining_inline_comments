{"pr_number": 8155, "pr_title": "KAFKA-9553: Improve measurement for loading groups and transactions", "pr_createdAt": "2020-02-21T22:23:26Z", "pr_url": "https://github.com/apache/kafka/pull/8155", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTI2MQ==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383091261", "bodyText": "not sure that we should default the time to 0. I think we should let the caller pass in value they want.", "author": "soondenana", "createdAt": "2020-02-24T05:35:13Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -520,21 +520,22 @@ class GroupMetadataManager(brokerId: Int,\n   def scheduleLoadGroupAndOffsets(offsetsPartition: Int, onGroupLoaded: GroupMetadata => Unit): Unit = {\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n+      val nowInMs = time.milliseconds()\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, nowInMs))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long = 0L): Unit = {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4OTQwNA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383589404", "bodyText": "Agree, done.", "author": "agam", "createdAt": "2020-02-25T00:12:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTI2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU5Mzk3Ng==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383593976", "bodyText": "(note: the reason I had left it as 0 by default was to avoid the extra dummy parameter in all the test calls, added that now)", "author": "agam", "createdAt": "2020-02-25T00:27:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTI2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTQzOQ==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383091439", "bodyText": "nit: move it after info line. Maybe get rid of variable altogether and put is on the method call itself.", "author": "soondenana", "createdAt": "2020-02-24T05:36:03Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -520,21 +520,22 @@ class GroupMetadataManager(brokerId: Int,\n   def scheduleLoadGroupAndOffsets(offsetsPartition: Int, onGroupLoaded: GroupMetadata => Unit): Unit = {\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n+      val nowInMs = time.milliseconds()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4OTU0NA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383589544", "bodyText": "Makes sense, done.", "author": "agam", "createdAt": "2020-02-25T00:13:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTQzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MjUyNg==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383092526", "bodyText": "no need to have a default value for the parameter.", "author": "soondenana", "createdAt": "2020-02-24T05:43:03Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeInMs: java.lang.Long = 0L): Unit = {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU5MDA0NA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r383590044", "bodyText": "Agree, done.", "author": "agam", "createdAt": "2020-02-25T00:14:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MjUyNg=="}], "type": "inlineReview"}, {"oid": "59ea19d2f4c69c6a90a0c020e9290b09dae59bb4", "url": "https://github.com/apache/kafka/commit/59ea19d2f4c69c6a90a0c020e9290b09dae59bb4", "message": "KAFKA-9553: Improve measurement for loading groups and transactions\n\n- Pull out sensor update to top-level\n- Shifted up the partition-loading sensor measurement for loading transactions\n- Added scheduler-time awareness for loading groups\n- Modified test to reflect new scheduling call", "committedDate": "2020-02-26T21:35:48Z", "type": "commit"}, {"oid": "418493924f9e1b34a0cdbfb15f257d34017ae1f0", "url": "https://github.com/apache/kafka/commit/418493924f9e1b34a0cdbfb15f257d34017ae1f0", "message": "Review: removed default values for parameters", "committedDate": "2020-02-26T21:35:48Z", "type": "commit"}, {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb", "url": "https://github.com/apache/kafka/commit/07d164ec809a6f88738268acf1a070267a3bc0eb", "message": "Fixed build errors due to non-default parameter in tests", "committedDate": "2020-02-26T21:35:48Z", "type": "commit"}, {"oid": "07d164ec809a6f88738268acf1a070267a3bc0eb", "url": "https://github.com/apache/kafka/commit/07d164ec809a6f88738268acf1a070267a3bc0eb", "message": "Fixed build errors due to non-default parameter in tests", "committedDate": "2020-02-26T21:35:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0MDI1MQ==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391140251", "bodyText": "nit: break this into multiple lines.", "author": "hachikuji", "createdAt": "2020-03-11T17:27:41Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeInMs = time.milliseconds() - startTimeInMs\n       doLoadGroupsAndOffsets(topicPartition, onGroupLoaded)\n-      val endMs = time.milliseconds()\n-      val timeLapse = endMs - startMs\n-      partitionLoadSensor.record(timeLapse, endMs, false)\n-      info(s\"Finished loading offsets and group metadata from $topicPartition in $timeLapse milliseconds.\")\n+      val endTimeInMs = time.milliseconds()\n+      val totalLoadingTimeInMs = time.milliseconds() - startTimeInMs\n+      partitionLoadSensor.record(totalLoadingTimeInMs, endTimeInMs, false)\n+      info(s\"Finished loading offsets and group metadata from $topicPartition in $totalLoadingTimeInMs milliseconds, of which $schedulerTimeInMs milliseconds was spent in the scheduler.\")", "originalCommit": "07d164ec809a6f88738268acf1a070267a3bc0eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIwMDg0MQ==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391200841", "bodyText": "Done.", "author": "agam", "createdAt": "2020-03-11T19:09:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0MDI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0MjEyNQ==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391142125", "bodyText": "Hmm.. Does this do what's intended? Wouldn't time.milliseconds only be evaluated when the callback is invoked?", "author": "hachikuji", "createdAt": "2020-03-11T17:30:19Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))", "originalCommit": "07d164ec809a6f88738268acf1a070267a3bc0eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIxNzY5OA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391217698", "bodyText": "True, has to be evaluated before passing in. Done.", "author": "agam", "createdAt": "2020-03-11T19:42:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0MjEyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0Mzc1Ng==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391143756", "bodyText": "nit: Conventionally, we would drop In and make this schedulerTimeMs. A few more of these in the patch.", "author": "hachikuji", "createdAt": "2020-03-11T17:32:33Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,20 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, time.milliseconds()))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeInMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeInMs = time.milliseconds() - startTimeInMs", "originalCommit": "07d164ec809a6f88738268acf1a070267a3bc0eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIwMTgzNQ==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391201835", "bodyText": "Done", "author": "agam", "createdAt": "2020-03-11T19:11:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0Mzc1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0NjI2OA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391146268", "bodyText": "nit: maybe we could call this something more descriptive like scheduleStartMs", "author": "hachikuji", "createdAt": "2020-03-11T17:36:14Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -435,7 +435,8 @@ class TransactionStateManager(brokerId: Int,\n       info(s\"Completed loading transaction metadata from $topicPartition for coordinator epoch $coordinatorEpoch\")\n     }\n \n-    scheduler.schedule(s\"load-txns-for-partition-$topicPartition\", loadTransactions)\n+    val nowInMs = time.milliseconds()", "originalCommit": "07d164ec809a6f88738268acf1a070267a3bc0eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTIwMTc4OA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391201788", "bodyText": "Done", "author": "agam", "createdAt": "2020-03-11T19:11:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTE0NjI2OA=="}], "type": "inlineReview"}, {"oid": "7411b553157984c7b1a0342505b8bc078a42cab0", "url": "https://github.com/apache/kafka/commit/7411b553157984c7b1a0342505b8bc078a42cab0", "message": "Review: variable naming changes", "committedDate": "2020-03-11T19:13:07Z", "type": "commit"}, {"oid": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b", "url": "https://github.com/apache/kafka/commit/3a47e21c8ab182e72bbd8f1f8f7ece71134a205b", "message": "Review: cache the timestamp before passing in to the scheduler callback", "committedDate": "2020-03-11T19:42:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzEwNQ==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391937105", "bodyText": "nit: can we use endTimeMs?", "author": "hachikuji", "createdAt": "2020-03-12T22:21:33Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -521,20 +521,23 @@ class GroupMetadataManager(brokerId: Int,\n     val topicPartition = new TopicPartition(Topic.GROUP_METADATA_TOPIC_NAME, offsetsPartition)\n     if (addLoadingPartition(offsetsPartition)) {\n       info(s\"Scheduling loading of offsets and group metadata from $topicPartition\")\n-      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded))\n+      val startTimeMs = time.milliseconds()\n+      scheduler.schedule(topicPartition.toString, () => loadGroupsAndOffsets(topicPartition, onGroupLoaded, startTimeMs))\n     } else {\n       info(s\"Already loading offsets and group metadata from $topicPartition\")\n     }\n   }\n \n-  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit): Unit = {\n+  private[group] def loadGroupsAndOffsets(topicPartition: TopicPartition, onGroupLoaded: GroupMetadata => Unit, startTimeMs: java.lang.Long): Unit = {\n     try {\n-      val startMs = time.milliseconds()\n+      val schedulerTimeMs = time.milliseconds() - startTimeMs\n       doLoadGroupsAndOffsets(topicPartition, onGroupLoaded)\n-      val endMs = time.milliseconds()\n-      val timeLapse = endMs - startMs\n-      partitionLoadSensor.record(timeLapse, endMs, false)\n-      info(s\"Finished loading offsets and group metadata from $topicPartition in $timeLapse milliseconds.\")\n+      val endTimeMs = time.milliseconds()\n+      val totalLoadingTimeMs = time.milliseconds() - startTimeMs", "originalCommit": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1NjA4Mw==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r392556083", "bodyText": "d'oh, yes of course.", "author": "agam", "createdAt": "2020-03-14T04:34:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzEwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzMwMg==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391937302", "bodyText": "nit: maybe we call this totalLoadingTimeMs for consistency", "author": "hachikuji", "createdAt": "2020-03-12T22:22:07Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeMs: java.lang.Long): Unit = {\n+      val schedulerTime = time.milliseconds() - startTimeMs\n       info(s\"Loading transaction metadata from $topicPartition at epoch $coordinatorEpoch\")\n       validateTransactionTopicPartitionCountIsStable()\n \n       val loadedTransactions = loadTransactionMetadata(topicPartition, coordinatorEpoch)\n+      val endTimeMs = time.milliseconds()\n+      val timeLapse = endTimeMs - startTimeMs", "originalCommit": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1NjEyMw==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r392556123", "bodyText": "Done.", "author": "agam", "createdAt": "2020-03-14T04:35:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzMwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzM3NA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r391937374", "bodyText": "nit: schedulerTimeMs for consistency?", "author": "hachikuji", "createdAt": "2020-03-12T22:22:21Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionStateManager.scala", "diffHunk": "@@ -393,11 +388,16 @@ class TransactionStateManager(brokerId: Int,\n       loadingPartitions.add(partitionAndLeaderEpoch)\n     }\n \n-    def loadTransactions(): Unit = {\n+    def loadTransactions(startTimeMs: java.lang.Long): Unit = {\n+      val schedulerTime = time.milliseconds() - startTimeMs", "originalCommit": "3a47e21c8ab182e72bbd8f1f8f7ece71134a205b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1NjE5Mg==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r392556192", "bodyText": "Done", "author": "agam", "createdAt": "2020-03-14T04:36:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkzNzM3NA=="}], "type": "inlineReview"}, {"oid": "3904e3dea28d8568475599212127df5ba939bb9a", "url": "https://github.com/apache/kafka/commit/3904e3dea28d8568475599212127df5ba939bb9a", "message": "Review: renaming for consistency", "committedDate": "2020-03-14T04:37:40Z", "type": "commit"}, {"oid": "6fec36f2220520f4a241c0b4b0c8d18475bdd284", "url": "https://github.com/apache/kafka/commit/6fec36f2220520f4a241c0b4b0c8d18475bdd284", "message": "Review: updated description of partition-load metric to mention inclusion of \"scheduling time\"", "committedDate": "2020-03-14T18:57:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk5MTg3MA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r393991870", "bodyText": "I think the short description is ok as it was. But maybe we could add something like this to the long description:\n\nmaximum time, in milliseconds, it took to load offsets and group metadata from the consumer offset partitions loaded in the last 30 seconds (including time spent waiting for the loading task to be scheduled)", "author": "hachikuji", "createdAt": "2020-03-17T21:52:01Z", "path": "docs/ops.html", "diffHunk": "@@ -1070,22 +1070,22 @@ <h4><a id=\"remote_jmx\" href=\"#remote_jmx\">Security Considerations for Remote Mon\n             Disconnected|SyncConnected|AuthFailed|ConnectedReadOnly|SaslAuthenticated|Expired.</td>\n       </tr>\n       <tr>\n-        <td>Max time to load group metadata</td>\n+        <td>Max time to load group metadata (including scheduling time)</td>", "originalCommit": "6fec36f2220520f4a241c0b4b0c8d18475bdd284", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDAxNDIyNA==", "url": "https://github.com/apache/kafka/pull/8155#discussion_r394014224", "bodyText": "Ack, added this to all the long-form descriptions.", "author": "agam", "createdAt": "2020-03-17T22:46:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk5MTg3MA=="}], "type": "inlineReview"}, {"oid": "0078f829a93b7933c9e547a3cfed538162fabe3e", "url": "https://github.com/apache/kafka/commit/0078f829a93b7933c9e547a3cfed538162fabe3e", "message": "Review: modify long-form descriptions", "committedDate": "2020-03-17T22:46:35Z", "type": "commit"}, {"oid": "9206296f331c85f55963592d7db48aade809e783", "url": "https://github.com/apache/kafka/commit/9206296f331c85f55963592d7db48aade809e783", "message": "Revert short description changes", "committedDate": "2020-03-18T20:27:44Z", "type": "commit"}]}