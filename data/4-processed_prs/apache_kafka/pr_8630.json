{"pr_number": 8630, "pr_title": "KAFKA-9969: Exclude ConnectorClientConfigRequest from class loading isolation", "pr_createdAt": "2020-05-07T20:07:15Z", "pr_url": "https://github.com/apache/kafka/pull/8630", "timeline": [{"oid": "9c506f3b138b7fa29ae4db3a8eb65f7f23b4a638", "url": "https://github.com/apache/kafka/commit/9c506f3b138b7fa29ae4db3a8eb65f7f23b4a638", "message": "KAFKA-9969: Exclude ConnectorClientConfigRequest from class loading isolation\n\nSigned-off-by: Greg Harris <gregh@confluent.io>", "committedDate": "2020-05-07T20:05:40Z", "type": "commit"}, {"oid": "a8ca3bfeb5ba2d1774f02ada978e286b4e4192aa", "url": "https://github.com/apache/kafka/commit/a8ca3bfeb5ba2d1774f02ada978e286b4e4192aa", "message": "Refactor PluginUtils test and add more isolation test cases\n\nSigned-off-by: Greg Harris <gregh@confluent.io>", "committedDate": "2020-05-07T22:37:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY0MDE0NA==", "url": "https://github.com/apache/kafka/pull/8630#discussion_r433640144", "bodyText": "nit: do you mind using List<String> and Arrays.asList(...)? I don't think array declaration is better if the result is not going to be used as an array. Also, won't work if you try to reinitialize a declared variable.", "author": "kkonstantine", "createdAt": "2020-06-02T06:08:03Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/isolation/PluginUtilsTest.java", "diffHunk": "@@ -114,68 +90,264 @@ public void testConnectFrameworkClasses() {\n         assertFalse(PluginUtils.shouldLoadInIsolation(\n                 \"org.apache.kafka.clients.admin.KafkaAdminClient\")\n         );\n-        assertFalse(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.rest.ConnectRestExtension\")\n-        );\n     }\n \n     @Test\n-    public void testAllowedConnectFrameworkClasses() {\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.transforms.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.transforms.ExtractField\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.transforms.ExtractField$Key\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.json.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.json.JsonConverter\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.json.JsonConverter$21\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.file.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.file.FileStreamSourceTask\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.file.FileStreamSinkConnector\")\n-        );\n+    public void testConnectApiClasses() {\n+        String[] apiClasses = new String[] {", "originalCommit": "a8ca3bfeb5ba2d1774f02ada978e286b4e4192aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY0MDI0Nw==", "url": "https://github.com/apache/kafka/pull/8630#discussion_r433640247", "bodyText": "nit: same as above.", "author": "kkonstantine", "createdAt": "2020-06-02T06:08:19Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/isolation/PluginUtilsTest.java", "diffHunk": "@@ -114,68 +90,264 @@ public void testConnectFrameworkClasses() {\n         assertFalse(PluginUtils.shouldLoadInIsolation(\n                 \"org.apache.kafka.clients.admin.KafkaAdminClient\")\n         );\n-        assertFalse(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.rest.ConnectRestExtension\")\n-        );\n     }\n \n     @Test\n-    public void testAllowedConnectFrameworkClasses() {\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.transforms.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.transforms.ExtractField\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.transforms.ExtractField$Key\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.json.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.json.JsonConverter\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.json.JsonConverter$21\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.file.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.file.FileStreamSourceTask\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.file.FileStreamSinkConnector\")\n-        );\n+    public void testConnectApiClasses() {\n+        String[] apiClasses = new String[] {\n+            // Enumerate all packages and classes\n+            \"org.apache.kafka.connect.\",\n+            \"org.apache.kafka.connect.components.\",\n+            \"org.apache.kafka.connect.components.Versioned\",\n+            //\"org.apache.kafka.connect.connector.policy.\", isolated by default\n+            \"org.apache.kafka.connect.connector.policy.ConnectorClientConfigOverridePolicy\",\n+            \"org.apache.kafka.connect.connector.policy.ConnectorClientConfigRequest\",\n+            \"org.apache.kafka.connect.connector.\",\n+            \"org.apache.kafka.connect.connector.Connector\",\n+            \"org.apache.kafka.connect.connector.ConnectorContext\",\n+            \"org.apache.kafka.connect.connector.ConnectRecord\",\n+            \"org.apache.kafka.connect.connector.Task\",\n+            \"org.apache.kafka.connect.data.\",\n+            \"org.apache.kafka.connect.data.ConnectSchema\",\n+            \"org.apache.kafka.connect.data.Date\",\n+            \"org.apache.kafka.connect.data.Decimal\",\n+            \"org.apache.kafka.connect.data.Field\",\n+            \"org.apache.kafka.connect.data.Schema\",\n+            \"org.apache.kafka.connect.data.SchemaAndValue\",\n+            \"org.apache.kafka.connect.data.SchemaBuilder\",\n+            \"org.apache.kafka.connect.data.SchemaProjector\",\n+            \"org.apache.kafka.connect.data.Struct\",\n+            \"org.apache.kafka.connect.data.Time\",\n+            \"org.apache.kafka.connect.data.Timestamp\",\n+            \"org.apache.kafka.connect.data.Values\",\n+            \"org.apache.kafka.connect.errors.\",\n+            \"org.apache.kafka.connect.errors.AlreadyExistsException\",\n+            \"org.apache.kafka.connect.errors.ConnectException\",\n+            \"org.apache.kafka.connect.errors.DataException\",\n+            \"org.apache.kafka.connect.errors.IllegalWorkerStateException\",\n+            \"org.apache.kafka.connect.errors.NotFoundException\",\n+            \"org.apache.kafka.connect.errors.RetriableException\",\n+            \"org.apache.kafka.connect.errors.SchemaBuilderException\",\n+            \"org.apache.kafka.connect.errors.SchemaProjectorException\",\n+            \"org.apache.kafka.connect.header.\",\n+            \"org.apache.kafka.connect.header.ConnectHeader\",\n+            \"org.apache.kafka.connect.header.ConnectHeaders\",\n+            \"org.apache.kafka.connect.header.Header\",\n+            \"org.apache.kafka.connect.header.Headers\",\n+            \"org.apache.kafka.connect.health.\",\n+            \"org.apache.kafka.connect.health.AbstractState\",\n+            \"org.apache.kafka.connect.health.ConnectClusterDetails\",\n+            \"org.apache.kafka.connect.health.ConnectClusterState\",\n+            \"org.apache.kafka.connect.health.ConnectorHealth\",\n+            \"org.apache.kafka.connect.health.ConnectorState\",\n+            \"org.apache.kafka.connect.health.ConnectorType\",\n+            \"org.apache.kafka.connect.health.TaskState\",\n+            \"org.apache.kafka.connect.rest.\",\n+            \"org.apache.kafka.connect.rest.ConnectRestExtension\",\n+            \"org.apache.kafka.connect.rest.ConnectRestExtensionContext\",\n+            \"org.apache.kafka.connect.sink.\",\n+            \"org.apache.kafka.connect.sink.SinkConnector\",\n+            \"org.apache.kafka.connect.sink.SinkRecord\",\n+            \"org.apache.kafka.connect.sink.SinkTask\",\n+            \"org.apache.kafka.connect.sink.SinkTaskContext\",\n+            \"org.apache.kafka.connect.source.\",\n+            \"org.apache.kafka.connect.source.SourceConnector\",\n+            \"org.apache.kafka.connect.source.SourceRecord\",\n+            \"org.apache.kafka.connect.source.SourceTask\",\n+            \"org.apache.kafka.connect.source.SourceTaskContext\",\n+            \"org.apache.kafka.connect.storage.\",\n+            \"org.apache.kafka.connect.storage.Converter\",\n+            \"org.apache.kafka.connect.storage.ConverterConfig\",\n+            \"org.apache.kafka.connect.storage.ConverterType\",\n+            \"org.apache.kafka.connect.storage.HeaderConverter\",\n+            \"org.apache.kafka.connect.storage.OffsetStorageReader\",\n+            //\"org.apache.kafka.connect.storage.SimpleHeaderConverter\", explicitly isolated\n+            //\"org.apache.kafka.connect.storage.StringConverter\", explicitly isolated\n+            \"org.apache.kafka.connect.storage.StringConverterConfig\",\n+            //\"org.apache.kafka.connect.transforms.\", isolated by default\n+            \"org.apache.kafka.connect.transforms.Transformation\",\n+            \"org.apache.kafka.connect.util.\",\n+            \"org.apache.kafka.connect.util.ConnectorUtils\"\n+        };\n+        // Classes in the API should never be loaded in isolation.\n+        for (String clazz : apiClasses) {\n+            assertFalse(\n+                clazz + \" from 'api' is loaded in isolation but should not be\",\n+                PluginUtils.shouldLoadInIsolation(clazz)\n+            );\n+        }\n+    }\n+\n+    @Test\n+    public void testConnectRuntimeClasses() {\n+        // Only list packages, because there are too many classes.\n+        String[] runtimeClasses = new String[]{", "originalCommit": "a8ca3bfeb5ba2d1774f02ada978e286b4e4192aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY0MTU4Mw==", "url": "https://github.com/apache/kafka/pull/8630#discussion_r433641583", "bodyText": "The exhaustive list of classes is unmaintainable and it's highly improbable that new classes will be removed or added.\nCan we instead keep the existing testing based on packages, keep testing the exceptions and then test a few indicative classes that most probably won't be removed any time soon as a way to test the inclusion and exclusion from isolation?", "author": "kkonstantine", "createdAt": "2020-06-02T06:12:12Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/isolation/PluginUtilsTest.java", "diffHunk": "@@ -114,68 +90,264 @@ public void testConnectFrameworkClasses() {\n         assertFalse(PluginUtils.shouldLoadInIsolation(\n                 \"org.apache.kafka.clients.admin.KafkaAdminClient\")\n         );\n-        assertFalse(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.rest.ConnectRestExtension\")\n-        );\n     }\n \n     @Test\n-    public void testAllowedConnectFrameworkClasses() {\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.transforms.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.transforms.ExtractField\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.transforms.ExtractField$Key\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.json.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.json.JsonConverter\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.json.JsonConverter$21\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.file.\"));\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.file.FileStreamSourceTask\")\n-        );\n-        assertTrue(PluginUtils.shouldLoadInIsolation(\n-                \"org.apache.kafka.connect.file.FileStreamSinkConnector\")\n-        );\n+    public void testConnectApiClasses() {\n+        String[] apiClasses = new String[] {\n+            // Enumerate all packages and classes\n+            \"org.apache.kafka.connect.\",\n+            \"org.apache.kafka.connect.components.\",\n+            \"org.apache.kafka.connect.components.Versioned\",\n+            //\"org.apache.kafka.connect.connector.policy.\", isolated by default\n+            \"org.apache.kafka.connect.connector.policy.ConnectorClientConfigOverridePolicy\",\n+            \"org.apache.kafka.connect.connector.policy.ConnectorClientConfigRequest\",\n+            \"org.apache.kafka.connect.connector.\",\n+            \"org.apache.kafka.connect.connector.Connector\",\n+            \"org.apache.kafka.connect.connector.ConnectorContext\",\n+            \"org.apache.kafka.connect.connector.ConnectRecord\",\n+            \"org.apache.kafka.connect.connector.Task\",\n+            \"org.apache.kafka.connect.data.\",\n+            \"org.apache.kafka.connect.data.ConnectSchema\",\n+            \"org.apache.kafka.connect.data.Date\",", "originalCommit": "a8ca3bfeb5ba2d1774f02ada978e286b4e4192aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEzOTk5OA==", "url": "https://github.com/apache/kafka/pull/8630#discussion_r434139998", "bodyText": "The exhaustive list of classes is unmaintainable\n\nYes, it will be difficult to keep this test perfectly up-to-date without due-diligence from reviewers and committers. I think this due-diligence is valuable, and will avoid a bug-fix PR like this being necessary in the future.\n\nit's highly improbable that new classes will be removed or added.\n\nI would say infrequent, but not improbable. This next release includes two KIPs that added classes to the api, and each had to change the whitelist and/or tests (that's why this had merge conflicts earlier).\nI don't think it's significantly more effort to maintain the exhaustive list than it is to maintain a reduced list of classes either. Consider this decision tree:\n\nDid you add an API class?\nIf not -> It's not necessary to change this test, since it's only concerned with API classes.\nIs your new class inside an existing isolated-by-default package?\nIf so -> You'd need to exclude this class, and not doing so introduces a bug.\nOnce you change PluginUtils, you'd naturally update PluginUtilsTest with your class name to verify the fix.\nIs your new class in a new package\nIf so -> You'd need to update this test even if it was a non-exhaustive packages-only test.\n\nOnly if you've fallen through all of those conditions, and added an API class in an existing package that is already whitelisted, would you save the time necessary to update this test. And in this case, the code is already correct, so the test silently diverges from the real class list, without any negative effects.", "author": "gharris1727", "createdAt": "2020-06-02T19:55:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY0MTU4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1NDQxMQ==", "url": "https://github.com/apache/kafka/pull/8630#discussion_r437754411", "bodyText": "Sorry, I wasn't clear. I meant that I think the bookkeeping of specific classes in this test might be hard and that we might miss adding or removing an entry once a class is added or removed in any of the packages. Totally agree that we add classes and interfaces to the API as needed.\nThe basic principles behind classloading isolation was that we exclude everything in the framework from isolation and the users should not expect to package connect classes with their connectors. Yet, we had the need to introduce exceptions because we package some of the Connect plugins (Connectors, SMTs and Converters and etc) with the framework itself. That explains the inclusion and exclusion lists here and why specific classes/interfaces are present. The intention is keep this \"per java package\" approach and add only the necessary exceptions. That's why I suggested that an per class explicit listing here might be a bit tedious and perhaps a bit surprising to developers that contribute a class that is properly isolated but they'd be ask to add it here (e.g. a new SMT).\nHaving said that the benefits of this PR outweigh my concern atm, so I'm happy to move forward and include the test refactoring as well.", "author": "kkonstantine", "createdAt": "2020-06-09T22:20:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY0MTU4Mw=="}], "type": "inlineReview"}, {"oid": "0b90bf1f0b200487fa8248927c0976dee89cdb35", "url": "https://github.com/apache/kafka/commit/0b90bf1f0b200487fa8248927c0976dee89cdb35", "message": "Merge branch 'trunk' into config-request-isolation", "committedDate": "2020-06-02T18:08:21Z", "type": "commit"}, {"oid": "7c3d6486aba8100720f1afee9d7a3e948cd051dd", "url": "https://github.com/apache/kafka/commit/7c3d6486aba8100720f1afee9d7a3e948cd051dd", "message": "Add HasHeaderKey and RecordIsTombstone classes to transforms test\n\nSigned-off-by: Greg Harris <gregh@confluent.io>", "committedDate": "2020-06-02T18:10:17Z", "type": "commit"}, {"oid": "eb81a3979707b6478f212a3b8c8a64e205ef9d7c", "url": "https://github.com/apache/kafka/commit/eb81a3979707b6478f212a3b8c8a64e205ef9d7c", "message": "Whitelist ConnectorClientConfigRequest$ClientType and remove capturing group\n\nSigned-off-by: Greg Harris <gregh@confluent.io>", "committedDate": "2020-06-02T18:41:30Z", "type": "commit"}, {"oid": "df11574f7e5ef013fe349d60b6a953b0d77f9a89", "url": "https://github.com/apache/kafka/commit/df11574f7e5ef013fe349d60b6a953b0d77f9a89", "message": "Replace string arrays with lists of strings in test\n\nSigned-off-by: Greg Harris <gregh@confluent.io>", "committedDate": "2020-06-02T18:48:59Z", "type": "commit"}]}