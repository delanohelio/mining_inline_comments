{"pr_number": 8737, "pr_title": "KAFKA-9945: TopicCommand should support --if-exists and --if-not-exists when --bootstrap-server is used", "pr_createdAt": "2020-05-28T00:30:36Z", "pr_url": "https://github.com/apache/kafka/pull/8737", "timeline": [{"oid": "c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "url": "https://github.com/apache/kafka/commit/c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "message": "KAFKA-9945: TopicCommand should support --if-exists and --if-not-exists when --bootstrap-server is used\n\n - Fixed command line arg checking\n - Added unit test cases", "committedDate": "2020-05-28T00:27:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTkxNjY5OA==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r431916698", "bodyText": "removed this check and instead let the request go to the server and error (we need to handle that anyway)", "author": "vinothchandar", "createdAt": "2020-05-28T15:15:21Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -228,7 +228,7 @@ object TopicCommand extends Logging {\n       if (topic.partitions.exists(partitions => partitions < 1))\n         throw new IllegalArgumentException(s\"The partitions must be greater than 0\")\n \n-      if (!adminClient.listTopics().names().get().contains(topic.name)) {\n+      try {", "originalCommit": "c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1MDgwNA==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r431950804", "bodyText": "Would it be easy to add a for this? (ensure the bootstrap server doesn't throw)", "author": "stanislavkozlovski", "createdAt": "2020-05-28T16:03:06Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -736,8 +743,8 @@ object TopicCommand extends Logging {\n         allTopicLevelOpts -- Set(describeOpt) ++ allReplicationReportOpts - reportUnavailablePartitionsOpt + topicsWithOverridesOpt)\n       CommandLineUtils.checkInvalidArgs(parser, options, topicsWithOverridesOpt,\n         allTopicLevelOpts -- Set(describeOpt) ++ allReplicationReportOpts)\n-      CommandLineUtils.checkInvalidArgs(parser, options, ifExistsOpt, allTopicLevelOpts -- Set(alterOpt, deleteOpt, describeOpt) ++ Set(bootstrapServerOpt))\n-      CommandLineUtils.checkInvalidArgs(parser, options, ifNotExistsOpt, allTopicLevelOpts -- Set(createOpt) ++ Set(bootstrapServerOpt))", "originalCommit": "c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk3NjEwNA==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r431976104", "bodyText": "Sorry... what do you mean by add a for this?", "author": "vinothchandar", "createdAt": "2020-05-28T16:41:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1MDgwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE2MjY2Mw==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432162663", "bodyText": "@stanislavkozlovski : I think a word got left out here :)", "author": "cmccabe", "createdAt": "2020-05-28T22:39:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1MDgwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjU2Njk3Ng==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432566976", "bodyText": "I think you meant a test.. if so, the tests I added already use --bootstrap-server with these options..", "author": "vinothchandar", "createdAt": "2020-05-29T15:34:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1MDgwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1Mzk4Mw==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r431953983", "bodyText": "nit: I had some trouble reading this, since it's two not operators with an OR statement. Would this be easier to read as if e.getCause.isInstanceOf[TopicExistsException] && topic.ifTopicDoesntExist() ? Note that scala doesn't require a null check on the exception before calling isInstanceOf\nI think it's more conventional in Scala to have full if/else branches rather than guard statements", "author": "stanislavkozlovski", "createdAt": "2020-05-28T16:08:08Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -247,8 +247,12 @@ object TopicCommand extends Logging {\n         val createResult = adminClient.createTopics(Collections.singleton(newTopic))\n         createResult.all().get()\n         println(s\"Created topic ${topic.name}.\")\n-      } else {\n-        throw new IllegalArgumentException(s\"Topic ${topic.name} already exists\")\n+      } catch {\n+        case e : ExecutionException =>\n+          if (e.getCause == null)\n+            throw e\n+          if (!e.getCause.isInstanceOf[TopicExistsException] || !topic.ifTopicDoesntExist())", "originalCommit": "c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk3ODA1Mg==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r431978052", "bodyText": "Part of the issue here is I wanted to throw e, if the cause is null.. So I needed to check for that anyway.\nI was debating the || vs && there. With the if you mentioned, I need to return out of the method, instead of throwing.. I prefer to keep this the way it is.", "author": "vinothchandar", "createdAt": "2020-05-28T16:45:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1Mzk4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1NzMyMQ==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432157321", "bodyText": "I interpreted @stanislavkozlovski 's suggestion as being something like this:\n          if (!(e.getCause.isInstanceOf[TopicExistsException] && topic.ifTopicDoesntExist()))\n            throw e.getCause\n\nSo you wouldn't need to return out of the method in this case.\nI do think that using AND here as suggested would be more intuitive.  The reason is because it's basically a special case we're handling here: we got TopicExistsException AND we had --if-not-exists.  Using the OR construct just feels unintuitive since we're basically taking the disjunction of the special case (enumerating all the ways we could not be in the special case.)\nAnyway, I don't feel that strongly about it.  If you really want to keep it as is, that's OK.", "author": "cmccabe", "createdAt": "2020-05-28T22:23:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1Mzk4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE2NDc1Ng==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432164756", "bodyText": "yeah.. I can move the ! outside so its easier to reason.. Personally, I do fine with both, but given we have two similar feedback now. Happy to change.", "author": "vinothchandar", "createdAt": "2020-05-28T22:45:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk1Mzk4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1ODYzNw==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432158637", "bodyText": "I don't think this is really enough to accomplish your goal here.  With this code, if the topic does not exist, we will get past this line but then fail on the next line in describeTopics, with a NoSuchTopicOrPartitionException`.\nI think it would be better to simply catch the NoSuchTopicOrPartitionException and handle it appropriately like we did with topic creation.  This also avoids the redunant calls in ensureTopicExists.", "author": "cmccabe", "createdAt": "2020-05-28T22:27:22Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -259,7 +263,8 @@ object TopicCommand extends Logging {\n     override def alterTopic(opts: TopicCommandOptions): Unit = {\n       val topic = new CommandTopicPartition(opts)\n       val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic)\n+      ensureTopicExists(topics, opts.topic, !opts.ifExists)", "originalCommit": "c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE2Njg5Ng==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432166896", "bodyText": "if the topic does not exist ensureTopicExists() will throw an IllegalArgumentException right? Let me look at this and the other two closely and get back", "author": "vinothchandar", "createdAt": "2020-05-28T22:52:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1ODYzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE3MTA2OQ==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432171069", "bodyText": "Okay.. so I did think about the case where --if-exists is provided and thus ensureTopicExists() will move on without erroring... But I chose to let whatever exception that is thrown like NoSuchTopicOrPartitionException to propagate back to the caller/main() method..\nI guess you are suggesting to go to the server first and then handle the exception..  I am fine changing it, it does seem cleaner.", "author": "vinothchandar", "createdAt": "2020-05-28T23:04:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1ODYzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE3NDg4NQ==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432174885", "bodyText": "So this is an execution of testAlterWhenTopicDoesntExistWithIfExists altering a non-existing topic using -if-exists . As you can see, topics is empty.. The cleaner thing to do here seems to be just place any further calls into a if (topics.nonEmpty) { .. } block..\nIs your intention here, avoiding the call to getTopics() and ensureTopicExists()?  That was the model I was referring to above. if you concern is describeTopics failing, then it does not seem to be happening.. (but this code is on thin-ice, agree. if someone changes behavior of describeTopics, then this will break, but so will the test I added.)", "author": "vinothchandar", "createdAt": "2020-05-28T23:16:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1ODYzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE4NTcxNw==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432185717", "bodyText": "I was wondering about how the tests passed!  I guess I missed something important about getTopics-- the fact that it returns either one or zero topics.  (I forgot that zero was a possibility).\nThe problem with how the code works today is that it's really very wasteful.  It's literally listing every topic in the cluster, (which could be tens of thousands) just to see if the specific one you passed exists. There is also the potential for a TOCTOU issue here (for example, it existed but then was deleted right before you went to use it.)\nSo I would like to see this fixed to avoid doing the getTopics.  I guess think about it and if it seems reasonable to do it in the PR, let's go for it.  Otherwise I can create a follow-up JIRA.\nWe will need to fix stuff like this to scale the Kafka up.  People listing the full set of all topics is bad for scalability.", "author": "cmccabe", "createdAt": "2020-05-28T23:54:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1ODYzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjU5NDQ3Mg==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432594472", "bodyText": "@cmccabe So this is a tad more complicated..\nIn general, we need to do getTopics to deal with wildcard/regex arguments (all of these commands support them, even alter). To fix this, we need to move the resolution of regex to actual topic names further into AdminClient/Server.. This does not seem trivial to me. Specifically for alter we need to pull down the existing partition metadata to add more partitions, so we have a bigger TOCTOU issue here anyway.. Again something that needs better admin client APIs\nThat said, I do like having an eye towards making all these tools more scalable down the line. I can create a parent JIRA and keep filing these issues under there... (please let me know if a JIRA already exists like that)..", "author": "vinothchandar", "createdAt": "2020-05-29T16:19:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1ODYzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgxNDIyMg==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432814222", "bodyText": "Sounds good.  Thanks for digging into this!", "author": "cmccabe", "createdAt": "2020-05-30T05:59:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1ODYzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1OTM2NA==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432159364", "bodyText": "Same issue here as above.  You can get past this line this way, but you still fail when actually calling describeTopics.\nAnother issue with this code is that we should not be listing all partition reassignments.  Admin#listPartitionReassignments has a variant that takes a list of partitions.  We should use that so that we're not fetching a lot of information that we don't need.  I think this should be an easy fix", "author": "cmccabe", "createdAt": "2020-05-28T22:29:20Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -290,6 +295,8 @@ object TopicCommand extends Logging {\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n       val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n+      ensureTopicExists(topics, opts.topic, !opts.ifExists)", "originalCommit": "c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE3MjEwOA==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432172108", "bodyText": "I will look into the new API.. so topics will be empty and I checked that the describeTopics() will actually send an empty topicList.. Let me look into simplifying this more.", "author": "vinothchandar", "createdAt": "2020-05-28T23:08:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1OTM2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyNTY4OA==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432625688", "bodyText": "On avoiding getTopics, same issue.. AdminClient#describeTopics(..) cannot handle regexes. I made the changes for using the trimmed down Admin#listPartitionReassignments", "author": "vinothchandar", "createdAt": "2020-05-29T17:14:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1OTM2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1OTkzNQ==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432159935", "bodyText": "Same issue here as above.  Admin#deleteTopics will fail if the topic doesn't exist, regardless of line 334.", "author": "cmccabe", "createdAt": "2020-05-28T22:31:10Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -324,7 +331,7 @@ object TopicCommand extends Logging {\n \n     override def deleteTopic(opts: TopicCommandOptions): Unit = {\n       val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic)\n+      ensureTopicExists(topics, opts.topic, !opts.ifExists)", "originalCommit": "c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyNjA2Mg==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432626062", "bodyText": "Like we discussed.. getTopics will guard the issue you point out.. avoiding getTopics is again tricky due to regex/wildcard matching", "author": "vinothchandar", "createdAt": "2020-05-29T17:15:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE1OTkzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE2MjEwMA==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432162100", "bodyText": "Hmm.  I don't see why these catch blocks are needed.  All we're doing here is just failing when we get an exception.  But an exception propagating to the top level of the test function fails the test anyway.  What am I missing?", "author": "cmccabe", "createdAt": "2020-05-28T22:37:44Z", "path": "core/src/test/scala/unit/kafka/admin/TopicCommandWithAdminClientTest.scala", "diffHunk": "@@ -223,8 +224,20 @@ class TopicCommandWithAdminClientTest extends KafkaServerTestHarness with Loggin\n     createAndWaitTopic(createOpts)\n \n     // try to re-create the topic\n-    intercept[IllegalArgumentException] {\n+    intercept[TopicExistsException] {\n+      topicService.createTopic(createOpts)\n+    }\n+  }\n+\n+  @Test\n+  def testCreateWhenAlreadyExistsWithIfNotExists(): Unit = {\n+    val createOpts = new TopicCommandOptions(Array(\"--topic\", testTopicName, \"--if-not-exists\"))\n+    createAndWaitTopic(createOpts)\n+\n+    try {\n       topicService.createTopic(createOpts)\n+    } catch {", "originalCommit": "c18de27aa07c0383b832973f1f6b8cd2ed4a298c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE2NjY3NQ==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432166675", "bodyText": "I think the distinction is between whether you want the test to error or fail. Here I wanted the tests to fail with a contextual error by calling fail(). Also makes the test read more explicitly.. i.e it says we only treat the specific caught exception as the expected failure by calling fail(), while any other exception will just error out the test..", "author": "vinothchandar", "createdAt": "2020-05-28T22:51:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE2MjEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgxNDc4Ng==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432814786", "bodyText": "I guess personally I find it confusing since we're catching a particular type of exception specifically, but then just doing what we would have done anyway if we hadn't caught it (failing).  Also the failure message \"Alter topic should not throw exception\" implies that it is catching all exceptions, but actually only catching some that the code could throw.  So doubly confusing.", "author": "cmccabe", "createdAt": "2020-05-30T06:09:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjE2MjEwMA=="}], "type": "inlineReview"}, {"oid": "273c84654f66d6b1f84024115090140b781c1267", "url": "https://github.com/apache/kafka/commit/273c84654f66d6b1f84024115090140b781c1267", "message": "KAFKA-9945: Address CR comments\n\n - Avoid unnecessary RPC to server, if effective topic list is empty\n - Efficient use of AdminClient#listPartitionReassignments()\n - Fix if check style", "committedDate": "2020-05-29T17:47:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgxNDMyNQ==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432814325", "bodyText": "It's not necessary to check this.  AdminClient handles being passed empty lists or sets of topics.", "author": "cmccabe", "createdAt": "2020-05-30T06:00:59Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -290,42 +299,50 @@ object TopicCommand extends Logging {\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n       val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      val allConfigs = adminClient.describeConfigs(topics.map(new ConfigResource(Type.TOPIC, _)).asJavaCollection).values()\n-      val liveBrokers = adminClient.describeCluster().nodes().get().asScala.map(_.id())\n-      val reassignments = listAllReassignments()\n-      val topicDescriptions = adminClient.describeTopics(topics.asJavaCollection).all().get().values().asScala\n-      val describeOptions = new DescribeOptions(opts, liveBrokers.toSet)\n-\n-      for (td <- topicDescriptions) {\n-        val topicName = td.name\n-        val config = allConfigs.get(new ConfigResource(Type.TOPIC, topicName)).get()\n-        val sortedPartitions = td.partitions.asScala.sortBy(_.partition)\n-\n-        if (describeOptions.describeConfigs) {\n-          val hasNonDefault = config.entries().asScala.exists(!_.isDefault)\n-          if (!opts.reportOverriddenConfigs || hasNonDefault) {\n-            val numPartitions = td.partitions().size\n-            val firstPartition = td.partitions.iterator.next()\n-            val reassignment = reassignments.get(new TopicPartition(td.name, firstPartition.partition))\n-            val topicDesc = TopicDescription(topicName, numPartitions, getReplicationFactor(firstPartition, reassignment), config, markedForDeletion = false)\n-            topicDesc.printDescription()\n+      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+\n+      if (topics.nonEmpty) {", "originalCommit": "273c84654f66d6b1f84024115090140b781c1267", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg2ODQzMQ==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432868431", "bodyText": "val liveBrokers = adminClient.describeCluster().nodes().get().asScala.map(_.id())\nThis line still makes an RPC call.", "author": "vinothchandar", "createdAt": "2020-05-30T16:35:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgxNDMyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgxNDM1Mw==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432814353", "bodyText": "It's not necessary to check this.  AdminClient handles being passed empty sets of topics to delete (by doing nothing)", "author": "cmccabe", "createdAt": "2020-05-30T06:01:35Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -290,42 +299,50 @@ object TopicCommand extends Logging {\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n       val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      val allConfigs = adminClient.describeConfigs(topics.map(new ConfigResource(Type.TOPIC, _)).asJavaCollection).values()\n-      val liveBrokers = adminClient.describeCluster().nodes().get().asScala.map(_.id())\n-      val reassignments = listAllReassignments()\n-      val topicDescriptions = adminClient.describeTopics(topics.asJavaCollection).all().get().values().asScala\n-      val describeOptions = new DescribeOptions(opts, liveBrokers.toSet)\n-\n-      for (td <- topicDescriptions) {\n-        val topicName = td.name\n-        val config = allConfigs.get(new ConfigResource(Type.TOPIC, topicName)).get()\n-        val sortedPartitions = td.partitions.asScala.sortBy(_.partition)\n-\n-        if (describeOptions.describeConfigs) {\n-          val hasNonDefault = config.entries().asScala.exists(!_.isDefault)\n-          if (!opts.reportOverriddenConfigs || hasNonDefault) {\n-            val numPartitions = td.partitions().size\n-            val firstPartition = td.partitions.iterator.next()\n-            val reassignment = reassignments.get(new TopicPartition(td.name, firstPartition.partition))\n-            val topicDesc = TopicDescription(topicName, numPartitions, getReplicationFactor(firstPartition, reassignment), config, markedForDeletion = false)\n-            topicDesc.printDescription()\n+      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+\n+      if (topics.nonEmpty) {\n+        val allConfigs = adminClient.describeConfigs(topics.map(new ConfigResource(Type.TOPIC, _)).asJavaCollection).values()\n+        val liveBrokers = adminClient.describeCluster().nodes().get().asScala.map(_.id())\n+        val topicDescriptions = adminClient.describeTopics(topics.asJavaCollection).all().get().values().asScala\n+        val describeOptions = new DescribeOptions(opts, liveBrokers.toSet)\n+        val topicPartitions = topicDescriptions\n+          .flatMap(td => td.partitions.iterator().asScala.map(p => new TopicPartition(td.name(), p.partition())))\n+          .toSet.asJava\n+        val reassignments = listAllReassignments(topicPartitions)\n+\n+        for (td <- topicDescriptions) {\n+          val topicName = td.name\n+          val config = allConfigs.get(new ConfigResource(Type.TOPIC, topicName)).get()\n+          val sortedPartitions = td.partitions.asScala.sortBy(_.partition)\n+\n+          if (describeOptions.describeConfigs) {\n+            val hasNonDefault = config.entries().asScala.exists(!_.isDefault)\n+            if (!opts.reportOverriddenConfigs || hasNonDefault) {\n+              val numPartitions = td.partitions().size\n+              val firstPartition = td.partitions.iterator.next()\n+              val reassignment = reassignments.get(new TopicPartition(td.name, firstPartition.partition))\n+              val topicDesc = TopicDescription(topicName, numPartitions, getReplicationFactor(firstPartition, reassignment), config, markedForDeletion = false)\n+              topicDesc.printDescription()\n+            }\n           }\n-        }\n \n-        if (describeOptions.describePartitions) {\n-          for (partition <- sortedPartitions) {\n-            val reassignment = reassignments.get(new TopicPartition(td.name, partition.partition))\n-            val partitionDesc = PartitionDescription(topicName, partition, Some(config), markedForDeletion = false, reassignment)\n-            describeOptions.maybePrintPartitionDescription(partitionDesc)\n+          if (describeOptions.describePartitions) {\n+            for (partition <- sortedPartitions) {\n+              val reassignment = reassignments.get(new TopicPartition(td.name, partition.partition))\n+              val partitionDesc = PartitionDescription(topicName, partition, Some(config), markedForDeletion = false, reassignment)\n+              describeOptions.maybePrintPartitionDescription(partitionDesc)\n+            }\n           }\n         }\n       }\n     }\n \n     override def deleteTopic(opts: TopicCommandOptions): Unit = {\n       val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic)\n-      adminClient.deleteTopics(topics.asJavaCollection).all().get()\n+      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+      if (topics.nonEmpty)", "originalCommit": "273c84654f66d6b1f84024115090140b781c1267", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgxNDQyMA==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432814420", "bodyText": "Technically yes. Thats why did not have them at first. But they do make rpc calls with an empty topic list.\nGiven we discussed efficiency a fair bit in this PR, i think we can have this check for those reasons", "author": "vinothchandar", "createdAt": "2020-05-30T06:03:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgxNDM1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjg2ODEzMg==", "url": "https://github.com/apache/kafka/pull/8737#discussion_r432868132", "bodyText": "For alter :  we call KafkaAdminClient#createPartitions() which will make the RPC call even if topics at ~L2406 is empty..\nFor describe:  KafkaAdminClient#describeCluster() call is still wasteful. no?\nFor delete: it's actually handled, RPC avoided.. I will remove the check", "author": "vinothchandar", "createdAt": "2020-05-30T16:30:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjgxNDM1Mw=="}], "type": "inlineReview"}, {"oid": "490085d347674a1cd60cc192d6083559620b2f8e", "url": "https://github.com/apache/kafka/commit/490085d347674a1cd60cc192d6083559620b2f8e", "message": "KAFKA-9945:  More CR feedback", "committedDate": "2020-05-30T16:56:02Z", "type": "commit"}]}