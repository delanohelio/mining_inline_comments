{"pr_number": 8215, "pr_title": "KAFKA-9451: Update MockConsumer to support ConsumerGroupMetadata", "pr_createdAt": "2020-03-03T23:43:34Z", "pr_url": "https://github.com/apache/kafka/pull/8215", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjA3MQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362071", "bodyText": "We need this later (not related to this PR, but to follow up PR for KIP-447)", "author": "mjsax", "createdAt": "2020-03-03T23:45:03Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java", "diffHunk": "@@ -563,7 +563,7 @@ private Long getEndOffset(List<Long> offsets) {\n \n     @Override\n     public ConsumerGroupMetadata groupMetadata() {\n-        return null;\n+        return new ConsumerGroupMetadata(\"dummy.group.id\", 1, \"1\", Optional.empty());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjA5MQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362091", "bodyText": "Side cleanup", "author": "mjsax", "createdAt": "2020-03-03T23:45:08Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/MockConsumer.java", "diffHunk": "@@ -461,7 +461,7 @@ public synchronized void close() {\n         close(KafkaConsumer.DEFAULT_CLOSE_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n     }\n \n-    @SuppressWarnings(\"deprecation\")\n+    @Deprecated", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjExMQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362111", "bodyText": "Side cleanup", "author": "mjsax", "createdAt": "2020-03-03T23:45:11Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/MockProducer.java", "diffHunk": "@@ -308,7 +308,7 @@ private void verifyTransactionInFlight() {\n                 0L, 0, 0, Time.SYSTEM);\n         long offset = nextOffset(topicPartition);\n         Completion completion = new Completion(offset, new RecordMetadata(topicPartition, 0, offset,\n-                RecordBatch.NO_TIMESTAMP, Long.valueOf(0L), 0, 0), result, callback);\n+                RecordBatch.NO_TIMESTAMP, 0L, 0, 0), result, callback);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjE3Mg==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362172", "bodyText": "Side cleanup (multiple in the file)", "author": "mjsax", "createdAt": "2020-03-03T23:45:22Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -101,6 +101,7 @@\n     private boolean commitNeeded = false;\n     private boolean commitRequested = false;\n \n+    @SuppressWarnings(\"rawtypes\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjIzOQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362239", "bodyText": "We move this into TaskManager", "author": "mjsax", "createdAt": "2020-03-03T23:45:36Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -247,235 +241,6 @@ int getAssignmentErrorCode() {\n         return assignmentErrorCode.get();\n     }\n \n-    static abstract class AbstractTaskCreator<T extends Task> {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjQyMw==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362423", "bodyText": "This PR addresses this TODO", "author": "mjsax", "createdAt": "2020-03-03T23:46:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -542,43 +305,21 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n             restoreConsumer,\n             userStateRestoreListener);\n \n-        final ThreadCache cache = new ThreadCache(logContext, cacheSizeBytes, streamsMetrics);\n-\n         final Map<TaskId, Producer<byte[], byte[]>> taskProducers = new HashMap<>();\n \n-        // TODO: refactor `TaskCreator` into `TaskManager`;\n-        //  this will allow to reduce the surface area of `taskProducers` that is passed to many classes atm", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MjcwNg==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362706", "bodyText": "We don't need to pass the producers into StreamThread any longer now", "author": "mjsax", "createdAt": "2020-03-03T23:46:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -602,8 +343,6 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n         final StreamThread streamThread = new StreamThread(\n             time,\n             config,\n-            activeTaskCreator.threadProducer,\n-            taskProducers,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2Mjc1Nw==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387362757", "bodyText": "moved to TaskManager (alse method below)", "author": "mjsax", "createdAt": "2020-03-03T23:47:02Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -686,14 +421,6 @@ private InternalConsumerConfig(final Map<String, Object> props) {\n         }\n     }\n \n-    private static String getTaskProducerClientId(final String threadClientId, final TaskId taskId) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2MzczMA==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387363730", "bodyText": "producerClientIds() contains the logic from above now", "author": "mjsax", "createdAt": "2020-03-03T23:50:05Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -1123,13 +850,11 @@ public final ThreadMetadata threadMetadata() {\n     StreamThread updateThreadMetadata(final String adminClientId) {\n \n         threadMetadata = new ThreadMetadata(\n-            this.getName(),\n-            this.state().name(),\n-            getConsumerClientId(this.getName()),\n-            getRestoreConsumerClientId(this.getName()),\n-            threadProducer == null ?\n-                Collections.emptySet() :\n-                Collections.singleton(getThreadProducerClientId(this.getName())),\n+            getName(),\n+            state().name(),\n+            getConsumerClientId(getName()),\n+            getRestoreConsumerClientId(getName()),\n+            taskManager.producerClientIds(getName()),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2Mzg4MA==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387363880", "bodyText": "Getting producerClientIds is not moved into the TaskManager", "author": "mjsax", "createdAt": "2020-03-03T23:50:38Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -1139,11 +864,9 @@ StreamThread updateThreadMetadata(final String adminClientId) {\n \n     private void updateThreadMetadata(final Map<TaskId, Task> activeTasks,\n                                       final Map<TaskId, Task> standbyTasks) {\n-        final Set<String> producerClientIds = new HashSet<>();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2Mzk3MA==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387363970", "bodyText": "Logic move into TaskManager", "author": "mjsax", "createdAt": "2020-03-03T23:50:54Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -1198,22 +919,7 @@ public String toString(final String indent) {\n     }\n \n     public Map<MetricName, Metric> producerMetrics() {\n-        final LinkedHashMap<MetricName, Metric> result = new LinkedHashMap<>();\n-        if (threadProducer != null) {\n-            final Map<MetricName, ? extends Metric> producerMetrics = threadProducer.metrics();\n-            if (producerMetrics != null) {\n-                result.putAll(producerMetrics);\n-            }\n-        } else {\n-            // When EOS is turned on, each task will have its own producer client\n-            // and the producer object passed in here will be null. We would then iterate through\n-            // all the active tasks and add their metrics to the output metrics map.\n-            for (final StreamTask task : taskManager.fixmeStreamTasks().values()) {\n-                final Map<MetricName, ? extends Metric> taskProducerMetrics = taskProducers.get(task.id).metrics();\n-                result.putAll(taskProducerMetrics);\n-            }\n-        }\n-        return result;\n+        return taskManager.producerMetrics();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDI5MQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387364291", "bodyText": "I added this constructor to allow mocking both task creators -- otherwise TaskManagerTest would require complex mocking and major rewrite", "author": "mjsax", "createdAt": "2020-03-03T23:51:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -77,27 +316,127 @@\n \n     private boolean rebalanceInProgress = false;  // if we are in the middle of a rebalance, it is not safe to commit\n \n+    // for testing only", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODAwNzc4Mw==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r388007783", "bodyText": "Not sure I follow here: can we just use easy-mock for the creators here, what are the actual issues that would cause major re-write in the test class?", "author": "guozhangwang", "createdAt": "2020-03-05T00:05:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODAzNTEwMQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r388035101", "bodyText": "If we cannot mock both TaskCreators, we need to mock the InternalTopologyBuilder what is much more complicated -- I tried this originally, but it was quite a mess. Also note, that TaskManagerTest makes a lot of assertions what method the TaskManager calls on the created tasks -- however, we would not be able to easily check this if we don't pass in mocked tasks, and we cannot pass in mock tasks without mocking the TaskCreator.\nIf you think this is too much of a hack, I would recommend to get rid of this constructor in a follow up PR and rewrite the TaskManagerTest their (to keep this PR focused and scoped).", "author": "mjsax", "createdAt": "2020-03-05T01:42:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDI5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDM4Mg==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387364382", "bodyText": "This is the actual constructor now", "author": "mjsax", "createdAt": "2020-03-03T23:52:02Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -77,27 +316,127 @@\n \n     private boolean rebalanceInProgress = false;  // if we are in the middle of a rebalance, it is not safe to commit\n \n+    // for testing only\n     TaskManager(final ChangelogReader changelogReader,\n                 final UUID processId,\n                 final String logPrefix,\n                 final StreamsMetricsImpl streamsMetrics,\n-                final StreamThread.AbstractTaskCreator<? extends Task> activeTaskCreator,\n-                final StreamThread.AbstractTaskCreator<? extends Task> standbyTaskCreator,\n+                final Producer<byte[], byte[]> threadProducer,\n                 final Map<TaskId, Producer<byte[], byte[]>> taskProducers,\n                 final InternalTopologyBuilder builder,\n-                final Admin adminClient) {\n+                final Admin adminClient,\n+                final AbstractTaskCreator<? extends Task> activeTaskCreator,\n+                final AbstractTaskCreator<? extends Task> standbyTaskCreator) {\n         this.changelogReader = changelogReader;\n         this.processId = processId;\n         this.logPrefix = logPrefix;\n         this.streamsMetrics = streamsMetrics;\n+        this.threadProducer = threadProducer;\n+        this.taskProducers = taskProducers;\n+        this.builder = builder;\n+        this.adminClient = adminClient;\n         this.activeTaskCreator = activeTaskCreator;\n         this.standbyTaskCreator = standbyTaskCreator;\n+\n+        final LogContext logContext = new LogContext(logPrefix);\n+        log = logContext.logger(getClass());\n+    }\n+\n+    TaskManager(final ChangelogReader changelogReader,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDUxOA==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387364518", "bodyText": "side cleanup", "author": "mjsax", "createdAt": "2020-03-03T23:52:27Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -155,6 +155,7 @@ public void punctuate(final long timestamp) {\n         }\n     };\n \n+    @SuppressWarnings(\"rawtypes\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NDYwMw==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387364603", "bodyText": "This and the next test are moved to TaskManagerTest", "author": "mjsax", "createdAt": "2020-03-03T23:52:45Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -1827,82 +1811,6 @@ private void verifyLogMessagesForSkippedRecordsForInvalidTimestamps(final LogCap\n         ));\n     }\n \n-    @Test\n-    public void shouldConstructProducerMetricsWithoutEOS() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NTY4Mw==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387365683", "bodyText": "Minor change: We don't pass in threadId any longer but just call Thread.currentThread.getName() instead -- let me know what you think about it -- seems simpler to me to avoid passing around unnecessary parameters", "author": "mjsax", "createdAt": "2020-03-03T23:56:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -49,10 +60,237 @@\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n \n+import static org.apache.kafka.streams.StreamsConfig.EXACTLY_ONCE;\n import static org.apache.kafka.streams.processor.internals.Task.State.CREATED;\n import static org.apache.kafka.streams.processor.internals.Task.State.RESTORING;\n \n public class TaskManager {\n+\n+    static abstract class AbstractTaskCreator<T extends Task> {\n+        final String applicationId;\n+        final InternalTopologyBuilder builder;\n+        final StreamsConfig config;\n+        final StreamsMetricsImpl streamsMetrics;\n+        final StateDirectory stateDirectory;\n+        final ChangelogReader storeChangelogReader;\n+        final Time time;\n+        final Logger log;\n+\n+        AbstractTaskCreator(final InternalTopologyBuilder builder,\n+                            final StreamsConfig config,\n+                            final StreamsMetricsImpl streamsMetrics,\n+                            final StateDirectory stateDirectory,\n+                            final ChangelogReader storeChangelogReader,\n+                            final Time time,\n+                            final Logger log) {\n+            this.applicationId = config.getString(StreamsConfig.APPLICATION_ID_CONFIG);\n+            this.builder = builder;\n+            this.config = config;\n+            this.streamsMetrics = streamsMetrics;\n+            this.stateDirectory = stateDirectory;\n+            this.storeChangelogReader = storeChangelogReader;\n+            this.time = time;\n+            this.log = log;\n+        }\n+\n+        public InternalTopologyBuilder builder() {\n+            return builder;\n+        }\n+\n+        public StateDirectory stateDirectory() {\n+            return stateDirectory;\n+        }\n+\n+        Collection<T> createTasks(final Consumer<byte[], byte[]> consumer,\n+                                  final Map<TaskId, Set<TopicPartition>> tasksToBeCreated) {\n+            final List<T> createdTasks = new ArrayList<>();\n+            for (final Map.Entry<TaskId, Set<TopicPartition>> newTaskAndPartitions : tasksToBeCreated.entrySet()) {\n+                final TaskId taskId = newTaskAndPartitions.getKey();\n+                final Set<TopicPartition> partitions = newTaskAndPartitions.getValue();\n+                final T task = createTask(consumer, taskId, partitions);\n+                if (task != null) {\n+                    log.trace(\"Created task {} with assigned partitions {}\", taskId, partitions);\n+                    createdTasks.add(task);\n+                }\n+\n+            }\n+            return createdTasks;\n+        }\n+\n+        abstract T createTask(final Consumer<byte[], byte[]> consumer, final TaskId id, final Set<TopicPartition> partitions);\n+\n+        void close() {};\n+    }\n+\n+    static class TaskCreator extends AbstractTaskCreator<StreamTask> {\n+        private final ThreadCache cache;\n+        private final Producer<byte[], byte[]> threadProducer;\n+        private final Map<TaskId, Producer<byte[], byte[]>> taskProducers;\n+        private final KafkaClientSupplier clientSupplier;\n+        private final Sensor createTaskSensor;\n+\n+        TaskCreator(final InternalTopologyBuilder builder,\n+                    final StreamsConfig config,\n+                    final StreamsMetricsImpl streamsMetrics,\n+                    final StateDirectory stateDirectory,\n+                    final ChangelogReader storeChangelogReader,\n+                    final ThreadCache cache,\n+                    final Time time,\n+                    final KafkaClientSupplier clientSupplier,\n+                    final Producer<byte[], byte[]> threadProducer,\n+                    final Map<TaskId, Producer<byte[], byte[]>> taskProducers,\n+                    final Logger log) {\n+            super(\n+                builder,\n+                config,\n+                streamsMetrics,\n+                stateDirectory,\n+                storeChangelogReader,\n+                time,\n+                log);\n+\n+            this.threadProducer = threadProducer;\n+            this.taskProducers = taskProducers;\n+\n+            this.cache = cache;\n+            this.clientSupplier = clientSupplier;\n+\n+            this.createTaskSensor = ThreadMetrics.createTaskSensor(Thread.currentThread().getName(), streamsMetrics);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM2NTgzMg==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387365832", "bodyText": "Similar to above: don't pass threadId any longer", "author": "mjsax", "createdAt": "2020-03-03T23:56:39Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -49,10 +60,237 @@\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n \n+import static org.apache.kafka.streams.StreamsConfig.EXACTLY_ONCE;\n import static org.apache.kafka.streams.processor.internals.Task.State.CREATED;\n import static org.apache.kafka.streams.processor.internals.Task.State.RESTORING;\n \n public class TaskManager {\n+\n+    static abstract class AbstractTaskCreator<T extends Task> {\n+        final String applicationId;\n+        final InternalTopologyBuilder builder;\n+        final StreamsConfig config;\n+        final StreamsMetricsImpl streamsMetrics;\n+        final StateDirectory stateDirectory;\n+        final ChangelogReader storeChangelogReader;\n+        final Time time;\n+        final Logger log;\n+\n+        AbstractTaskCreator(final InternalTopologyBuilder builder,\n+                            final StreamsConfig config,\n+                            final StreamsMetricsImpl streamsMetrics,\n+                            final StateDirectory stateDirectory,\n+                            final ChangelogReader storeChangelogReader,\n+                            final Time time,\n+                            final Logger log) {\n+            this.applicationId = config.getString(StreamsConfig.APPLICATION_ID_CONFIG);\n+            this.builder = builder;\n+            this.config = config;\n+            this.streamsMetrics = streamsMetrics;\n+            this.stateDirectory = stateDirectory;\n+            this.storeChangelogReader = storeChangelogReader;\n+            this.time = time;\n+            this.log = log;\n+        }\n+\n+        public InternalTopologyBuilder builder() {\n+            return builder;\n+        }\n+\n+        public StateDirectory stateDirectory() {\n+            return stateDirectory;\n+        }\n+\n+        Collection<T> createTasks(final Consumer<byte[], byte[]> consumer,\n+                                  final Map<TaskId, Set<TopicPartition>> tasksToBeCreated) {\n+            final List<T> createdTasks = new ArrayList<>();\n+            for (final Map.Entry<TaskId, Set<TopicPartition>> newTaskAndPartitions : tasksToBeCreated.entrySet()) {\n+                final TaskId taskId = newTaskAndPartitions.getKey();\n+                final Set<TopicPartition> partitions = newTaskAndPartitions.getValue();\n+                final T task = createTask(consumer, taskId, partitions);\n+                if (task != null) {\n+                    log.trace(\"Created task {} with assigned partitions {}\", taskId, partitions);\n+                    createdTasks.add(task);\n+                }\n+\n+            }\n+            return createdTasks;\n+        }\n+\n+        abstract T createTask(final Consumer<byte[], byte[]> consumer, final TaskId id, final Set<TopicPartition> partitions);\n+\n+        void close() {};\n+    }\n+\n+    static class TaskCreator extends AbstractTaskCreator<StreamTask> {\n+        private final ThreadCache cache;\n+        private final Producer<byte[], byte[]> threadProducer;\n+        private final Map<TaskId, Producer<byte[], byte[]>> taskProducers;\n+        private final KafkaClientSupplier clientSupplier;\n+        private final Sensor createTaskSensor;\n+\n+        TaskCreator(final InternalTopologyBuilder builder,\n+                    final StreamsConfig config,\n+                    final StreamsMetricsImpl streamsMetrics,\n+                    final StateDirectory stateDirectory,\n+                    final ChangelogReader storeChangelogReader,\n+                    final ThreadCache cache,\n+                    final Time time,\n+                    final KafkaClientSupplier clientSupplier,\n+                    final Producer<byte[], byte[]> threadProducer,\n+                    final Map<TaskId, Producer<byte[], byte[]>> taskProducers,\n+                    final Logger log) {\n+            super(\n+                builder,\n+                config,\n+                streamsMetrics,\n+                stateDirectory,\n+                storeChangelogReader,\n+                time,\n+                log);\n+\n+            this.threadProducer = threadProducer;\n+            this.taskProducers = taskProducers;\n+\n+            this.cache = cache;\n+            this.clientSupplier = clientSupplier;\n+\n+            this.createTaskSensor = ThreadMetrics.createTaskSensor(Thread.currentThread().getName(), streamsMetrics);\n+        }\n+\n+        @Override\n+        StreamTask createTask(final Consumer<byte[], byte[]> mainConsumer,\n+                              final TaskId taskId,\n+                              final Set<TopicPartition> partitions) {\n+            createTaskSensor.record();\n+\n+            final String threadIdPrefix = String.format(\"stream-thread [%s] \", Thread.currentThread().getName());\n+            final String logPrefix = threadIdPrefix + String.format(\"%s [%s] \", \"task\", taskId);\n+            final LogContext logContext = new LogContext(logPrefix);\n+\n+            final ProcessorTopology topology = builder.buildSubtopology(taskId.topicGroupId);\n+\n+            final ProcessorStateManager stateManager = new ProcessorStateManager(\n+                taskId,\n+                partitions,\n+                Task.TaskType.ACTIVE,\n+                stateDirectory,\n+                topology.storeToChangelogTopic(),\n+                storeChangelogReader,\n+                logContext);\n+\n+            final StreamsProducer streamsProducer;\n+            if (threadProducer == null) {\n+                // create one producer per task for EOS\n+                // TODO: after KIP-447 this would be removed\n+                final Map<String, Object> producerConfigs = config.getProducerConfigs(getTaskProducerClientId(Thread.currentThread().getName(), taskId));\n+                producerConfigs.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, applicationId + \"-\" + taskId);\n+                log.info(\"Creating producer client for task {}\", taskId);\n+                taskProducers.put(taskId, clientSupplier.getProducer(producerConfigs));\n+                streamsProducer = new StreamsProducer(logContext, taskProducers.get(taskId), applicationId, taskId);\n+            } else {\n+                streamsProducer = new StreamsProducer(logContext, threadProducer);\n+            }\n+\n+            final RecordCollector recordCollector = new RecordCollectorImpl(\n+                logContext,\n+                taskId,\n+                mainConsumer,\n+                streamsProducer,\n+                config.defaultProductionExceptionHandler(),\n+                EXACTLY_ONCE.equals(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG)),\n+                streamsMetrics);\n+\n+            return new StreamTask(\n+                taskId,\n+                partitions,\n+                topology,\n+                mainConsumer,\n+                config,\n+                streamsMetrics,\n+                stateDirectory,\n+                cache,\n+                time,\n+                stateManager,\n+                recordCollector);\n+        }\n+\n+        @Override\n+        public void close() {\n+            if (threadProducer != null) {\n+                try {\n+                    threadProducer.close();\n+                } catch (final Throwable e) {\n+                    log.error(\"Failed to close producer due to the following error:\", e);\n+                }\n+            }\n+        }\n+    }\n+\n+    static class StandbyTaskCreator extends AbstractTaskCreator<StandbyTask> {\n+        private final Sensor createTaskSensor;\n+\n+        StandbyTaskCreator(final InternalTopologyBuilder builder,\n+                           final StreamsConfig config,\n+                           final StreamsMetricsImpl streamsMetrics,\n+                           final StateDirectory stateDirectory,\n+                           final ChangelogReader storeChangelogReader,\n+                           final Time time,\n+                           final Logger log) {\n+            super(\n+                builder,\n+                config,\n+                streamsMetrics,\n+                stateDirectory,\n+                storeChangelogReader,\n+                time,\n+                log);\n+            createTaskSensor = ThreadMetrics.createTaskSensor(Thread.currentThread().getName(), streamsMetrics);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk5MTkxMw==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r387991913", "bodyText": "Need this to make MockConsumerTest pass.", "author": "mjsax", "createdAt": "2020-03-04T23:17:10Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerGroupMetadata.java", "diffHunk": "@@ -72,4 +72,21 @@ public String toString() {\n             memberId,\n             groupInstanceId.orElse(\"\"));\n     }\n+\n+    @Override", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5MjY5OA==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389192698", "bodyText": "I think it's actually a better idea to keep extracting the active / standby task creators out of the constructor of task-manager, since by doing that in the tests we can have mocks for those two, and also we can avoid the extra constructors you added below. Thoughts?\nAlso cc @abbccdda @vvcephei who reviewed / worked on the class cleanups recently.", "author": "guozhangwang", "createdAt": "2020-03-06T23:31:05Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -304,37 +303,20 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n             restoreConsumer,\n             userStateRestoreListener);\n \n-        final ThreadCache cache = new ThreadCache(logContext, cacheSizeBytes, streamsMetrics);\n-\n-        final ActiveTaskCreator activeTaskCreator = new ActiveTaskCreator(", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMTA3MA==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389201070", "bodyText": "I guess @vvcephei refactoring did already the required work to get rid of passing around threadProducer and taskProducers references -- while I see the argument about testing and the second constructor, it still seems weird if the StreamThread that has nothing to do with tasks needs to create both task-creator objects -- it should be encapsulated in TaskManager -- maybe we can have some setters on TaskManager for testing instead of the second constructor (the corresponding members would not be final any longer for this case)", "author": "mjsax", "createdAt": "2020-03-07T00:10:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5MjY5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTI2NTI1OQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389265259", "bodyText": "Logically it is more natural to have the task creation logic inside task-manager, yes; but the tricky part is that task creation involves creating a lot of its modules like state-manager and record-collector, so if we can pass them as parameters it is easier to mock them without creating those modules; so practically speaking I think it's better to always pass in those creators as parameters to task manager so that it's easier to mock, since there's really no real disadvantage of doing so right?", "author": "guozhangwang", "createdAt": "2020-03-07T16:17:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5MjY5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMwMzg3Nw==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389303877", "bodyText": "I also don't feel strong about this refactoring. In the effort of moving task creator towards TaskManager we are also passing in more parameters than what TaskManager needs as well. I would recommend we reduce the PR to address https://issues.apache.org/jira/browse/KAFKA-9676 only, since we do miss unit test coverage for task creators.", "author": "abbccdda", "createdAt": "2020-03-07T18:54:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5MjY5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5MzY2MQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389193661", "bodyText": "Thanks for the added test coverage!!", "author": "guozhangwang", "createdAt": "2020-03-06T23:35:03Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.Metric;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.metrics.KafkaMetric;\n+import org.apache.kafka.common.metrics.Measurable;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.test.MockClientSupplier;\n+import org.easymock.EasyMockRunner;\n+import org.easymock.Mock;\n+import org.easymock.MockType;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.easymock.EasyMock.anyString;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.mock;\n+import static org.easymock.EasyMock.replay;\n+import static org.junit.Assert.assertEquals;\n+\n+@RunWith(EasyMockRunner.class)\n+public class ActiveTaskCreatorTest {\n+\n+    @Mock(type = MockType.NICE)\n+    private InternalTopologyBuilder builder;\n+    @Mock(type = MockType.NICE)\n+    private StreamsConfig config;\n+    @Mock(type = MockType.NICE)\n+    private StateDirectory stateDirectory;\n+    @Mock(type = MockType.NICE)\n+    private ChangelogReader changeLogReader;\n+    @Mock(type = MockType.NICE)\n+    private Consumer<byte[], byte[]> consumer;\n+    @Mock(type = MockType.NICE)\n+    private Admin adminClient;\n+\n+    private final MockClientSupplier mockClientSupplier = new MockClientSupplier();\n+    final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(new Metrics(), \"clientId\", StreamsConfig.METRICS_LATEST);\n+\n+    private ActiveTaskCreator activeTaskCreator;\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithoutEOS() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5Mzc5NQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389193795", "bodyText": "This seems not used.", "author": "guozhangwang", "createdAt": "2020-03-06T23:35:46Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -105,6 +105,8 @@\n     private final TopicPartition t1p2 = new TopicPartition(topic1, 2);\n     private final Set<TopicPartition> taskId02Partitions = mkSet(t1p2);\n \n+    private final MockClientSupplier mockClientSupplier = new MockClientSupplier();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMDIxMw==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389200213", "bodyText": "Good catch -- missed to remove it after rebasing and moving the tests to ActiveTaskCreatorTest", "author": "mjsax", "createdAt": "2020-03-07T00:06:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5Mzc5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTI2NDgyMA==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389264820", "bodyText": "Since we did this, could we also add test for StandbyTaskCreator to resolve https://issues.apache.org/jira/browse/KAFKA-9676?", "author": "abbccdda", "createdAt": "2020-03-07T16:10:36Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.Metric;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.metrics.KafkaMetric;\n+import org.apache.kafka.common.metrics.Measurable;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.test.MockClientSupplier;\n+import org.easymock.EasyMockRunner;\n+import org.easymock.Mock;\n+import org.easymock.MockType;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.easymock.EasyMock.anyString;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.mock;\n+import static org.easymock.EasyMock.replay;\n+import static org.junit.Assert.assertEquals;\n+\n+@RunWith(EasyMockRunner.class)\n+public class ActiveTaskCreatorTest {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMxNjE5NQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389316195", "bodyText": "Could we add a test for standby?", "author": "abbccdda", "createdAt": "2020-03-07T22:16:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTI2NDgyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMxNjIyNQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389316225", "bodyText": "Could we use verify on mocks for both test cases?", "author": "abbccdda", "createdAt": "2020-03-07T22:16:39Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.clients.admin.Admin;\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.Metric;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.metrics.KafkaMetric;\n+import org.apache.kafka.common.metrics.Measurable;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.test.MockClientSupplier;\n+import org.easymock.EasyMockRunner;\n+import org.easymock.Mock;\n+import org.easymock.MockType;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.apache.kafka.common.utils.Utils.mkEntry;\n+import static org.apache.kafka.common.utils.Utils.mkMap;\n+import static org.easymock.EasyMock.anyString;\n+import static org.easymock.EasyMock.expect;\n+import static org.easymock.EasyMock.mock;\n+import static org.easymock.EasyMock.replay;\n+import static org.junit.Assert.assertEquals;\n+\n+@RunWith(EasyMockRunner.class)\n+public class ActiveTaskCreatorTest {\n+\n+    @Mock(type = MockType.NICE)\n+    private InternalTopologyBuilder builder;\n+    @Mock(type = MockType.NICE)\n+    private StreamsConfig config;\n+    @Mock(type = MockType.NICE)\n+    private StateDirectory stateDirectory;\n+    @Mock(type = MockType.NICE)\n+    private ChangelogReader changeLogReader;\n+    @Mock(type = MockType.NICE)\n+    private Consumer<byte[], byte[]> consumer;\n+    @Mock(type = MockType.NICE)\n+    private Admin adminClient;\n+\n+    private final MockClientSupplier mockClientSupplier = new MockClientSupplier();\n+    final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(new Metrics(), \"clientId\", StreamsConfig.METRICS_LATEST);\n+\n+    private ActiveTaskCreator activeTaskCreator;\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithoutEOS() {\n+        expect(config.getString(StreamsConfig.APPLICATION_ID_CONFIG)).andReturn(\"appId\");\n+        expect(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG)).andReturn(StreamsConfig.AT_LEAST_ONCE);\n+        expect(config.getProducerConfigs(anyString())).andReturn(Collections.emptyMap());\n+        replay(config);\n+\n+        activeTaskCreator = new ActiveTaskCreator(\n+            builder,\n+            config,\n+            streamsMetrics,\n+            stateDirectory,\n+            changeLogReader,\n+            new ThreadCache(new LogContext(), 0L, streamsMetrics),\n+            new MockTime(),\n+            mockClientSupplier,\n+            \"threadId\",\n+            new LogContext().logger(ActiveTaskCreator.class)\n+        );\n+\n+        final MetricName testMetricName = new MetricName(\"test_metric\", \"\", \"\", new HashMap<>());\n+        final Metric testMetric = new KafkaMetric(\n+            new Object(),\n+            testMetricName,\n+            (Measurable) (config, now) -> 0,\n+            null,\n+            new MockTime());\n+\n+        mockClientSupplier.producers.get(0).setMockMetrics(testMetricName, testMetric);\n+        final Map<MetricName, Metric> producerMetrics = activeTaskCreator.producerMetrics();\n+        assertEquals(testMetricName, producerMetrics.get(testMetricName).metricName());\n+    }\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithEOS() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMyMjEzNQ==", "url": "https://github.com/apache/kafka/pull/8215#discussion_r389322135", "bodyText": "We don't really care what methods get called, do we? We are only interesting in the result of the method call -- if the internal implementation on how we build the metric change, the test should still pass.", "author": "mjsax", "createdAt": "2020-03-08T00:06:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMxNjIyNQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "fc7e21a4c2388b501616e01da11f047844d34246", "url": "https://github.com/apache/kafka/commit/fc7e21a4c2388b501616e01da11f047844d34246", "message": "KAFKA-9441: Refactor TaskManager", "committedDate": "2020-03-10T23:52:09Z", "type": "commit"}, {"oid": "fc7e21a4c2388b501616e01da11f047844d34246", "url": "https://github.com/apache/kafka/commit/fc7e21a4c2388b501616e01da11f047844d34246", "message": "KAFKA-9441: Refactor TaskManager", "committedDate": "2020-03-10T23:52:09Z", "type": "forcePushed"}]}