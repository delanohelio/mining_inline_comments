{"pr_number": 9318, "pr_title": "KAFKA-10497 Convert group coordinator metadata schemas to use generat\u2026", "pr_createdAt": "2020-09-22T10:54:05Z", "pr_url": "https://github.com/apache/kafka/pull/9318", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjY2MTQzNw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r492661437", "bodyText": "Should we try avoiding the conversion to the Struct? We can directly serialize the OffsetCommitKey and the others like this: https://github.com/apache/kafka/pull/8897/files#diff-bad29ccb1aba700e1badeff62f1a86b7R184", "author": "dajac", "createdAt": "2020-09-22T11:31:14Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -997,189 +997,52 @@ object GroupMetadataManager {\n   val MetricsGroup: String = \"group-coordinator-metrics\"\n   val LoadTimeSensor: String = \"GroupPartitionLoadTime\"\n \n-  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = 1.toShort\n-  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = 2.toShort\n-\n-  private val OFFSET_COMMIT_KEY_SCHEMA = new Schema(new Field(\"group\", STRING),\n-    new Field(\"topic\", STRING),\n-    new Field(\"partition\", INT32))\n-  private val OFFSET_KEY_GROUP_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"group\")\n-  private val OFFSET_KEY_TOPIC_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"topic\")\n-  private val OFFSET_KEY_PARTITION_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"partition\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V0 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"metadata\")\n-  private val OFFSET_VALUE_TIMESTAMP_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V1 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64),\n-    new Field(\"expire_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"commit_timestamp\")\n-  private val OFFSET_VALUE_EXPIRE_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"expire_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V2 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"commit_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(\"offset\", INT64),\n-    new Field(\"leader_epoch\", INT32),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"offset\")\n-  private val OFFSET_VALUE_LEADER_EPOCH_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"leader_epoch\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"commit_timestamp\")\n-\n-  private val GROUP_METADATA_KEY_SCHEMA = new Schema(new Field(\"group\", STRING))\n-  private val GROUP_KEY_GROUP_FIELD = GROUP_METADATA_KEY_SCHEMA.get(\"group\")\n-\n-  private val MEMBER_ID_KEY = \"member_id\"\n-  private val GROUP_INSTANCE_ID_KEY = \"group_instance_id\"\n-  private val CLIENT_ID_KEY = \"client_id\"\n-  private val CLIENT_HOST_KEY = \"client_host\"\n-  private val REBALANCE_TIMEOUT_KEY = \"rebalance_timeout\"\n-  private val SESSION_TIMEOUT_KEY = \"session_timeout\"\n-  private val SUBSCRIPTION_KEY = \"subscription\"\n-  private val ASSIGNMENT_KEY = \"assignment\"\n-\n-  private val MEMBER_METADATA_V0 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V1 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V2 = MEMBER_METADATA_V1\n-\n-  private val MEMBER_METADATA_V3 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(GROUP_INSTANCE_ID_KEY, NULLABLE_STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val PROTOCOL_TYPE_KEY = \"protocol_type\"\n-  private val GENERATION_KEY = \"generation\"\n-  private val PROTOCOL_KEY = \"protocol\"\n-  private val LEADER_KEY = \"leader\"\n-  private val CURRENT_STATE_TIMESTAMP_KEY = \"current_state_timestamp\"\n-  private val MEMBERS_KEY = \"members\"\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V0 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V0)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V1 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V1)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V2 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V2)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V3)))\n-\n-  // map of versions to key schemas as data types\n-  private val MESSAGE_TYPE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    1 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    2 -> GROUP_METADATA_KEY_SCHEMA)\n-\n-  // map of version of offset value schemas\n-  private val OFFSET_VALUE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_VALUE_SCHEMA_V0,\n-    1 -> OFFSET_COMMIT_VALUE_SCHEMA_V1,\n-    2 -> OFFSET_COMMIT_VALUE_SCHEMA_V2,\n-    3 -> OFFSET_COMMIT_VALUE_SCHEMA_V3)\n-\n-  // map of version of group metadata value schemas\n-  private val GROUP_VALUE_SCHEMAS = Map(\n-    0 -> GROUP_METADATA_VALUE_SCHEMA_V0,\n-    1 -> GROUP_METADATA_VALUE_SCHEMA_V1,\n-    2 -> GROUP_METADATA_VALUE_SCHEMA_V2,\n-    3 -> GROUP_METADATA_VALUE_SCHEMA_V3)\n-\n-  private val CURRENT_OFFSET_KEY_SCHEMA = schemaForKey(CURRENT_OFFSET_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_KEY_SCHEMA = schemaForKey(CURRENT_GROUP_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = GROUP_VALUE_SCHEMAS.keySet.max\n-\n-  private def schemaForKey(version: Int) = {\n-    val schemaOpt = MESSAGE_TYPE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown message key schema version \" + version)\n-    }\n-  }\n-\n-  private def schemaForOffsetValue(version: Int) = {\n-    val schemaOpt = OFFSET_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown offset schema version \" + version)\n+  /**\n+   *\n+   * Statically check to make sure that the generated code always stays in sync with the overall protocol\n+   * @param clz generated class\n+   * @param actual actual version\n+   * @param expected expected version\n+   * @return correct version\n+   */\n+  private def checkVersionOfGeneratedCode(clz: Class[_], actual: Short, expected: Short): Short = {\n+    if (actual != expected) {\n+      throw new IllegalArgumentException(\n+        s\"core/src/main/resources/common/message/${clz.getSimpleName}.json needs to be updated to match the \" +\n+          s\"latest assignment protocol version. ${clz.getSimpleName} only supports up to  [\"\n+          + actual + \"] but needs to support up to [\" + expected + \"].\");\n     }\n+    expected\n   }\n \n-  private def schemaForGroupValue(version: Int) = {\n-    val schemaOpt = GROUP_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown group metadata version \" + version)\n-    }\n-  }\n+  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[OffsetCommitKey],\n+    actual = (OffsetCommitKey.SCHEMAS.length - 1).toShort,\n+    expected = 1.toShort)\n+  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[generated.GroupMetadataKey],\n+    actual = (generated.GroupMetadataKey.SCHEMAS.length -1).toShort,\n+    expected = 2.toShort)\n+  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[GroupMetadataValue],\n+    actual = (GroupMetadataValue.SCHEMAS.length - 1).toShort,\n+    expected = 3.toShort)\n \n   /**\n    * Generates the key for offset commit message for given (group, topic, partition)\n    *\n    * @return key for offset commit message\n    */\n   def offsetCommitKey(group: String, topicPartition: TopicPartition): Array[Byte] = {\n-    val key = new Struct(CURRENT_OFFSET_KEY_SCHEMA)\n-    key.set(OFFSET_KEY_GROUP_FIELD, group)\n-    key.set(OFFSET_KEY_TOPIC_FIELD, topicPartition.topic)\n-    key.set(OFFSET_KEY_PARTITION_FIELD, topicPartition.partition)\n+    val key = new OffsetCommitKey()\n+      .setGroup(group)\n+      .setTopic(topicPartition.topic())\n+      .setPartition(topicPartition.partition())\n+    val struct = key.toStruct(CURRENT_OFFSET_KEY_SCHEMA_VERSION)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjY5NjA2Ng==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r492696066", "bodyText": "Great idea. Please let me copy your code :)", "author": "chia7712", "createdAt": "2020-09-22T12:34:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjY2MTQzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjY2MjgwMQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r492662801", "bodyText": "Could we use the same formatting as the request/response? I know that the formatting that we use is a bit weird but I think that we should remain consistent.", "author": "dajac", "createdAt": "2020-09-22T11:34:00Z", "path": "core/src/main/resources/common/message/GroupMetadataValue.json", "diffHunk": "@@ -0,0 +1,103 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"GroupMetadataValue\",", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjY5NjQxNg==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r492696416", "bodyText": "copy that", "author": "chia7712", "createdAt": "2020-09-22T12:34:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjY2MjgwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjY2MzA4Ng==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r492663086", "bodyText": "nit: Missing space after -.", "author": "dajac", "createdAt": "2020-09-22T11:34:39Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -997,189 +997,52 @@ object GroupMetadataManager {\n   val MetricsGroup: String = \"group-coordinator-metrics\"\n   val LoadTimeSensor: String = \"GroupPartitionLoadTime\"\n \n-  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = 1.toShort\n-  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = 2.toShort\n-\n-  private val OFFSET_COMMIT_KEY_SCHEMA = new Schema(new Field(\"group\", STRING),\n-    new Field(\"topic\", STRING),\n-    new Field(\"partition\", INT32))\n-  private val OFFSET_KEY_GROUP_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"group\")\n-  private val OFFSET_KEY_TOPIC_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"topic\")\n-  private val OFFSET_KEY_PARTITION_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"partition\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V0 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"metadata\")\n-  private val OFFSET_VALUE_TIMESTAMP_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V1 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64),\n-    new Field(\"expire_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"commit_timestamp\")\n-  private val OFFSET_VALUE_EXPIRE_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"expire_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V2 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"commit_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(\"offset\", INT64),\n-    new Field(\"leader_epoch\", INT32),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"offset\")\n-  private val OFFSET_VALUE_LEADER_EPOCH_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"leader_epoch\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"commit_timestamp\")\n-\n-  private val GROUP_METADATA_KEY_SCHEMA = new Schema(new Field(\"group\", STRING))\n-  private val GROUP_KEY_GROUP_FIELD = GROUP_METADATA_KEY_SCHEMA.get(\"group\")\n-\n-  private val MEMBER_ID_KEY = \"member_id\"\n-  private val GROUP_INSTANCE_ID_KEY = \"group_instance_id\"\n-  private val CLIENT_ID_KEY = \"client_id\"\n-  private val CLIENT_HOST_KEY = \"client_host\"\n-  private val REBALANCE_TIMEOUT_KEY = \"rebalance_timeout\"\n-  private val SESSION_TIMEOUT_KEY = \"session_timeout\"\n-  private val SUBSCRIPTION_KEY = \"subscription\"\n-  private val ASSIGNMENT_KEY = \"assignment\"\n-\n-  private val MEMBER_METADATA_V0 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V1 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V2 = MEMBER_METADATA_V1\n-\n-  private val MEMBER_METADATA_V3 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(GROUP_INSTANCE_ID_KEY, NULLABLE_STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val PROTOCOL_TYPE_KEY = \"protocol_type\"\n-  private val GENERATION_KEY = \"generation\"\n-  private val PROTOCOL_KEY = \"protocol\"\n-  private val LEADER_KEY = \"leader\"\n-  private val CURRENT_STATE_TIMESTAMP_KEY = \"current_state_timestamp\"\n-  private val MEMBERS_KEY = \"members\"\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V0 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V0)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V1 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V1)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V2 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V2)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V3)))\n-\n-  // map of versions to key schemas as data types\n-  private val MESSAGE_TYPE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    1 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    2 -> GROUP_METADATA_KEY_SCHEMA)\n-\n-  // map of version of offset value schemas\n-  private val OFFSET_VALUE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_VALUE_SCHEMA_V0,\n-    1 -> OFFSET_COMMIT_VALUE_SCHEMA_V1,\n-    2 -> OFFSET_COMMIT_VALUE_SCHEMA_V2,\n-    3 -> OFFSET_COMMIT_VALUE_SCHEMA_V3)\n-\n-  // map of version of group metadata value schemas\n-  private val GROUP_VALUE_SCHEMAS = Map(\n-    0 -> GROUP_METADATA_VALUE_SCHEMA_V0,\n-    1 -> GROUP_METADATA_VALUE_SCHEMA_V1,\n-    2 -> GROUP_METADATA_VALUE_SCHEMA_V2,\n-    3 -> GROUP_METADATA_VALUE_SCHEMA_V3)\n-\n-  private val CURRENT_OFFSET_KEY_SCHEMA = schemaForKey(CURRENT_OFFSET_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_KEY_SCHEMA = schemaForKey(CURRENT_GROUP_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = GROUP_VALUE_SCHEMAS.keySet.max\n-\n-  private def schemaForKey(version: Int) = {\n-    val schemaOpt = MESSAGE_TYPE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown message key schema version \" + version)\n-    }\n-  }\n-\n-  private def schemaForOffsetValue(version: Int) = {\n-    val schemaOpt = OFFSET_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown offset schema version \" + version)\n+  /**\n+   *\n+   * Statically check to make sure that the generated code always stays in sync with the overall protocol\n+   * @param clz generated class\n+   * @param actual actual version\n+   * @param expected expected version\n+   * @return correct version\n+   */\n+  private def checkVersionOfGeneratedCode(clz: Class[_], actual: Short, expected: Short): Short = {\n+    if (actual != expected) {\n+      throw new IllegalArgumentException(\n+        s\"core/src/main/resources/common/message/${clz.getSimpleName}.json needs to be updated to match the \" +\n+          s\"latest assignment protocol version. ${clz.getSimpleName} only supports up to  [\"\n+          + actual + \"] but needs to support up to [\" + expected + \"].\");\n     }\n+    expected\n   }\n \n-  private def schemaForGroupValue(version: Int) = {\n-    val schemaOpt = GROUP_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown group metadata version \" + version)\n-    }\n-  }\n+  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[OffsetCommitKey],\n+    actual = (OffsetCommitKey.SCHEMAS.length - 1).toShort,\n+    expected = 1.toShort)\n+  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[generated.GroupMetadataKey],\n+    actual = (generated.GroupMetadataKey.SCHEMAS.length -1).toShort,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg3MjEyNw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495872127", "bodyText": "I believe that your previous naming (*Key and *Value) was actually correct. I am sorry if my previous comment was misleading. I was actually referring to the overall formatting of the json document which is not inline with what we are used to do.\nWe usually put type in the beginning and also format fields differently. You can see an example here: https://github.com/apache/kafka/blob/trunk/clients/src/main/resources/common/message/ConsumerProtocolAssignment.json", "author": "dajac", "createdAt": "2020-09-28T11:33:17Z", "path": "core/src/main/resources/common/message/GroupMetadataRequest.json", "diffHunk": "@@ -0,0 +1,27 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"GroupMetadataRequest\",", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkxODM0OQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495918349", "bodyText": "Sorry for misleading your comment :(\nwill follow the format in next commit", "author": "chia7712", "createdAt": "2020-09-28T12:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg3MjEyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4MjU0NA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495882544", "bodyText": "I think that we should keep currentStateTimestamp before members as we can't reorder fields.\n  private val GROUP_METADATA_VALUE_SCHEMA_V2 = new Schema(\n    new Field(PROTOCOL_TYPE_KEY, STRING),\n    new Field(GENERATION_KEY, INT32),\n    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n    new Field(LEADER_KEY, NULLABLE_STRING),\n    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V2)))", "author": "dajac", "createdAt": "2020-09-28T11:54:54Z", "path": "core/src/main/resources/common/message/GroupMetadataResponse.json", "diffHunk": "@@ -0,0 +1,103 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"GroupMetadataResponse\",\n+  \"validVersions\": \"0-3\",\n+  \"fields\": [\n+    {\n+      \"name\": \"protocolType\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\"\n+    },\n+    {\n+      \"name\": \"generation\",\n+      \"versions\": \"0+\",\n+      \"type\": \"int32\"\n+    },\n+    {\n+      \"name\": \"protocol\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\",\n+      \"nullableVersions\": \"0+\"\n+    },\n+    {\n+      \"name\": \"leader\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\",\n+      \"nullableVersions\": \"0+\"\n+    },\n+    {\n+      \"name\": \"members\",\n+      \"versions\": \"0+\",\n+      \"type\": \"[]MemberMetadata\"\n+    },\n+    {\n+      \"name\": \"currentStateTimestamp\",", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4MzE3Nw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495883177", "bodyText": "It seems that rebalanceTimeout should be before sessionTimeout.\n  private val MEMBER_METADATA_V3 = new Schema(\n    new Field(MEMBER_ID_KEY, STRING),\n    new Field(GROUP_INSTANCE_ID_KEY, NULLABLE_STRING),\n    new Field(CLIENT_ID_KEY, STRING),\n    new Field(CLIENT_HOST_KEY, STRING),\n    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n    new Field(SESSION_TIMEOUT_KEY, INT32),\n    new Field(SUBSCRIPTION_KEY, BYTES),\n    new Field(ASSIGNMENT_KEY, BYTES))", "author": "dajac", "createdAt": "2020-09-28T11:56:16Z", "path": "core/src/main/resources/common/message/GroupMetadataResponse.json", "diffHunk": "@@ -0,0 +1,103 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"GroupMetadataResponse\",\n+  \"validVersions\": \"0-3\",\n+  \"fields\": [\n+    {\n+      \"name\": \"protocolType\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\"\n+    },\n+    {\n+      \"name\": \"generation\",\n+      \"versions\": \"0+\",\n+      \"type\": \"int32\"\n+    },\n+    {\n+      \"name\": \"protocol\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\",\n+      \"nullableVersions\": \"0+\"\n+    },\n+    {\n+      \"name\": \"leader\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\",\n+      \"nullableVersions\": \"0+\"\n+    },\n+    {\n+      \"name\": \"members\",\n+      \"versions\": \"0+\",\n+      \"type\": \"[]MemberMetadata\"\n+    },\n+    {\n+      \"name\": \"currentStateTimestamp\",\n+      \"versions\": \"2+\",\n+      \"type\": \"int64\"\n+    }\n+  ],\n+  \"commonStructs\": [\n+    {\n+      \"name\": \"MemberMetadata\",\n+      \"versions\": \"0-3\",\n+      \"fields\": [\n+        {\n+          \"name\": \"memberId\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"clientId\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"clientHost\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"sessionTimeout\",\n+          \"versions\": \"0+\",\n+          \"type\": \"int32\"\n+        },\n+        {\n+          \"name\": \"subscription\",\n+          \"versions\": \"0+\",\n+          \"type\": \"bytes\"\n+        },\n+        {\n+          \"name\": \"assignment\",\n+          \"versions\": \"0+\",\n+          \"type\": \"bytes\"\n+        },\n+        {\n+          \"name\": \"rebalanceTimeout\",", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4MzQ0OQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495883449", "bodyText": "groupInstanceId should be before clientId.", "author": "dajac", "createdAt": "2020-09-28T11:56:46Z", "path": "core/src/main/resources/common/message/GroupMetadataResponse.json", "diffHunk": "@@ -0,0 +1,103 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"GroupMetadataResponse\",\n+  \"validVersions\": \"0-3\",\n+  \"fields\": [\n+    {\n+      \"name\": \"protocolType\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\"\n+    },\n+    {\n+      \"name\": \"generation\",\n+      \"versions\": \"0+\",\n+      \"type\": \"int32\"\n+    },\n+    {\n+      \"name\": \"protocol\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\",\n+      \"nullableVersions\": \"0+\"\n+    },\n+    {\n+      \"name\": \"leader\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\",\n+      \"nullableVersions\": \"0+\"\n+    },\n+    {\n+      \"name\": \"members\",\n+      \"versions\": \"0+\",\n+      \"type\": \"[]MemberMetadata\"\n+    },\n+    {\n+      \"name\": \"currentStateTimestamp\",\n+      \"versions\": \"2+\",\n+      \"type\": \"int64\"\n+    }\n+  ],\n+  \"commonStructs\": [\n+    {\n+      \"name\": \"MemberMetadata\",\n+      \"versions\": \"0-3\",\n+      \"fields\": [\n+        {\n+          \"name\": \"memberId\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"clientId\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"clientHost\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"sessionTimeout\",\n+          \"versions\": \"0+\",\n+          \"type\": \"int32\"\n+        },\n+        {\n+          \"name\": \"subscription\",\n+          \"versions\": \"0+\",\n+          \"type\": \"bytes\"\n+        },\n+        {\n+          \"name\": \"assignment\",\n+          \"versions\": \"0+\",\n+          \"type\": \"bytes\"\n+        },\n+        {\n+          \"name\": \"rebalanceTimeout\",\n+          \"versions\": \"1+\",\n+          \"type\": \"int32\"\n+        },\n+        {\n+          \"name\": \"groupInstanceId\",", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4NjEzMg==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495886132", "bodyText": "I think that we can combine these two together. The field was only renamed in V1. Having commitTimestamp with versions 0+ and dropping timestamp entirely should be fine.", "author": "dajac", "createdAt": "2020-09-28T12:02:07Z", "path": "core/src/main/resources/common/message/OffsetCommitResponse.json", "diffHunk": "@@ -0,0 +1,52 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"OffsetCommitResponse\",\n+  \"validVersions\": \"0-3\",\n+  \"fields\": [\n+    {\n+      \"name\": \"offset\",\n+      \"versions\": \"0+\",\n+      \"type\": \"int64\"\n+    },\n+    {\n+      \"name\": \"metadata\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\"\n+    },\n+    {\n+      \"name\": \"timestamp\",\n+      \"versions\": \"0\",\n+      \"type\": \"int64\"\n+    },\n+    {\n+      \"name\": \"commitTimestamp\",\n+      \"versions\": \"1+\",\n+      \"type\": \"int64\"\n+    },", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkxOTkxMA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495919910", "bodyText": "good idea!", "author": "chia7712", "createdAt": "2020-09-28T13:01:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4NjEzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4NjQzNg==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495886436", "bodyText": "leaderEpoch should be before metadata.", "author": "dajac", "createdAt": "2020-09-28T12:02:43Z", "path": "core/src/main/resources/common/message/OffsetCommitResponse.json", "diffHunk": "@@ -0,0 +1,52 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"OffsetCommitResponse\",\n+  \"validVersions\": \"0-3\",\n+  \"fields\": [\n+    {\n+      \"name\": \"offset\",\n+      \"versions\": \"0+\",\n+      \"type\": \"int64\"\n+    },\n+    {\n+      \"name\": \"metadata\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\"\n+    },\n+    {\n+      \"name\": \"timestamp\",\n+      \"versions\": \"0\",\n+      \"type\": \"int64\"\n+    },\n+    {\n+      \"name\": \"commitTimestamp\",\n+      \"versions\": \"1+\",\n+      \"type\": \"int64\"\n+    },\n+    {\n+      \"name\": \"expireTimestamp\",\n+      \"versions\": \"1\",\n+      \"type\": \"int64\"\n+    },\n+    {\n+      \"name\": \"leaderEpoch\",", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MDI5MQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495890291", "bodyText": "I suggest to fix the versions to 0-1 for all fields. OffsetCommitRequest and GroupMetadataRequest are in the same topic and we use the version to differentiate the two so it sounds better to use fix ranges here for the time being. The same for GroupMetadataRequest.\nA meta comment about this. At the moment, the spec only supports ranges such as A-B or A+. In this case, I wonder how we will involve this schema as the version 2 is used by the other schema. This is not an issue for now but we may need to extend the spec to support discontinuous ranges in the future.", "author": "dajac", "createdAt": "2020-09-28T12:10:26Z", "path": "core/src/main/resources/common/message/OffsetCommitRequest.json", "diffHunk": "@@ -0,0 +1,37 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"OffsetCommitRequest\",\n+  \"validVersions\": \"0-1\",\n+  \"fields\": [\n+    {\n+      \"name\": \"group\",\n+      \"versions\": \"0+\",", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTk0MDQyMA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495940420", "bodyText": "I suggest to fix the versions to 0-1 for all fields. OffsetCommitRequest and GroupMetadataRequest are in the same topic and we use the version to differentiate the two so it sounds better to use fix ranges here for the time being. The same for GroupMetadataRequest.\n\nI'd like to merge GroupMetadataRequest and OffsetCommitRequest so we can fix the version issue in generated code. WDYT?", "author": "chia7712", "createdAt": "2020-09-28T13:30:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MDI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM3NTg0NA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r497375844", "bodyText": "I have though about doing this as well and I am not fully convinced by it. What do we gain by doing so? It sounds a bit confusing and error prone as one without the historical context may do mistakes while evolving the two schemas in the future. Moreover, as we still have logic in the code which relies on the version to build up the correct object, we don't gain that much there neither.\nAs an example, let imagine that we want to add new field foo to GroupMetadata part of the schema and a new field bar to OffsetCommit part. We would end up with the following:\n{\n  \"type\": \"data\",\n  \"name\": \"OffsetCommitKey\",\n  \"validVersions\": \"0-4\",\n  \"fields\": [\n    { \"name\": \"group\", \"type\": \"string\", \"versions\": \"0-4\" },\n    { \"name\": \"topic\", \"type\": \"string\", \"versions\": \"0-1, 4\" },\n    { \"name\": \"partition\", \"type\": \"int32\", \"versions\": \"0-1, 4\" }\n    { \"name\": \"foo\", \"type\": \"int32\", \"versions\": \"3\" }\n    { \"name\": \"bar\", \"type\": \"int32\", \"versions\": \"0-1, 4\" }\n  ]\n}\n\nv3 would be the new version of the GroupMetadata part and v4 the new version of the OffsetCommit.\nPersonally, I find this hard to reason about because it is not easy to see that there are in fact two distinct-overlapping schemas in there which shares the group field. I lean towards keeping two separate schemas for the time being. I think that we can revise this when we will have to evolve them.", "author": "dajac", "createdAt": "2020-09-30T09:37:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MDI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM5MTUzMA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r497391530", "bodyText": "you are right. I will keep two separate schemas.", "author": "chia7712", "createdAt": "2020-09-30T10:03:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MDI5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MjMxNQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495892315", "bodyText": "We have merged my PR that contains this piece of code as well: 466f8fd#diff-bad29ccb1aba700e1badeff62f1a86b7R178. I think that we should find a common place where we could put that piece in order to avoid having it twice.\norg.apache.kafka.common.protocol.MessageUtil may be a good place. What do you think?", "author": "dajac", "createdAt": "2020-09-28T12:14:20Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -997,173 +996,45 @@ object GroupMetadataManager {\n   val MetricsGroup: String = \"group-coordinator-metrics\"\n   val LoadTimeSensor: String = \"GroupPartitionLoadTime\"\n \n-  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = 1.toShort\n-  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = 2.toShort\n-\n-  private val OFFSET_COMMIT_KEY_SCHEMA = new Schema(new Field(\"group\", STRING),\n-    new Field(\"topic\", STRING),\n-    new Field(\"partition\", INT32))\n-  private val OFFSET_KEY_GROUP_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"group\")\n-  private val OFFSET_KEY_TOPIC_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"topic\")\n-  private val OFFSET_KEY_PARTITION_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"partition\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V0 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"metadata\")\n-  private val OFFSET_VALUE_TIMESTAMP_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V1 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64),\n-    new Field(\"expire_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"commit_timestamp\")\n-  private val OFFSET_VALUE_EXPIRE_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"expire_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V2 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"commit_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(\"offset\", INT64),\n-    new Field(\"leader_epoch\", INT32),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"offset\")\n-  private val OFFSET_VALUE_LEADER_EPOCH_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"leader_epoch\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"commit_timestamp\")\n-\n-  private val GROUP_METADATA_KEY_SCHEMA = new Schema(new Field(\"group\", STRING))\n-  private val GROUP_KEY_GROUP_FIELD = GROUP_METADATA_KEY_SCHEMA.get(\"group\")\n-\n-  private val MEMBER_ID_KEY = \"member_id\"\n-  private val GROUP_INSTANCE_ID_KEY = \"group_instance_id\"\n-  private val CLIENT_ID_KEY = \"client_id\"\n-  private val CLIENT_HOST_KEY = \"client_host\"\n-  private val REBALANCE_TIMEOUT_KEY = \"rebalance_timeout\"\n-  private val SESSION_TIMEOUT_KEY = \"session_timeout\"\n-  private val SUBSCRIPTION_KEY = \"subscription\"\n-  private val ASSIGNMENT_KEY = \"assignment\"\n-\n-  private val MEMBER_METADATA_V0 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V1 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V2 = MEMBER_METADATA_V1\n-\n-  private val MEMBER_METADATA_V3 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(GROUP_INSTANCE_ID_KEY, NULLABLE_STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val PROTOCOL_TYPE_KEY = \"protocol_type\"\n-  private val GENERATION_KEY = \"generation\"\n-  private val PROTOCOL_KEY = \"protocol\"\n-  private val LEADER_KEY = \"leader\"\n-  private val CURRENT_STATE_TIMESTAMP_KEY = \"current_state_timestamp\"\n-  private val MEMBERS_KEY = \"members\"\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V0 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V0)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V1 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V1)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V2 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V2)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V3)))\n-\n-  // map of versions to key schemas as data types\n-  private val MESSAGE_TYPE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    1 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    2 -> GROUP_METADATA_KEY_SCHEMA)\n-\n-  // map of version of offset value schemas\n-  private val OFFSET_VALUE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_VALUE_SCHEMA_V0,\n-    1 -> OFFSET_COMMIT_VALUE_SCHEMA_V1,\n-    2 -> OFFSET_COMMIT_VALUE_SCHEMA_V2,\n-    3 -> OFFSET_COMMIT_VALUE_SCHEMA_V3)\n-\n-  // map of version of group metadata value schemas\n-  private val GROUP_VALUE_SCHEMAS = Map(\n-    0 -> GROUP_METADATA_VALUE_SCHEMA_V0,\n-    1 -> GROUP_METADATA_VALUE_SCHEMA_V1,\n-    2 -> GROUP_METADATA_VALUE_SCHEMA_V2,\n-    3 -> GROUP_METADATA_VALUE_SCHEMA_V3)\n-\n-  private val CURRENT_OFFSET_KEY_SCHEMA = schemaForKey(CURRENT_OFFSET_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_KEY_SCHEMA = schemaForKey(CURRENT_GROUP_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = GROUP_VALUE_SCHEMAS.keySet.max\n-\n-  private def schemaForKey(version: Int) = {\n-    val schemaOpt = MESSAGE_TYPE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown message key schema version \" + version)\n-    }\n-  }\n-\n-  private def schemaForOffsetValue(version: Int) = {\n-    val schemaOpt = OFFSET_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown offset schema version \" + version)\n+  /**\n+   *\n+   * Statically check to make sure that the generated code always stays in sync with the overall protocol\n+   * @param clz generated class\n+   * @param actual actual version\n+   * @param expected expected version\n+   * @return correct version\n+   */\n+  private def checkVersionOfGeneratedCode(clz: Class[_], actual: Short, expected: Short): Short = {\n+    if (actual != expected) {\n+      throw new IllegalArgumentException(\n+        s\"core/src/main/resources/common/message/${clz.getSimpleName}.json needs to be updated to match the \" +\n+          s\"latest assignment protocol version. ${clz.getSimpleName} only supports up to  [\"\n+          + actual + \"] but needs to support up to [\" + expected + \"].\");\n     }\n+    expected\n   }\n \n-  private def schemaForGroupValue(version: Int) = {\n-    val schemaOpt = GROUP_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown group metadata version \" + version)\n-    }\n+  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[GenOffsetCommitRequest],\n+    actual = (GenOffsetCommitRequest.SCHEMAS.length - 1).toShort,\n+    expected = 1.toShort)\n+  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[GroupMetadataRequest],\n+    actual = (GroupMetadataRequest.SCHEMAS.length - 1).toShort,\n+    expected = 2.toShort)\n+  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[GroupMetadataResponse],\n+    actual = (GroupMetadataResponse.SCHEMAS.length - 1).toShort,\n+    expected = 3.toShort)\n+\n+  private def serializeMessage(version: Short, message: Message): Array[Byte] = {\n+    val cache = new ObjectSerializationCache()\n+    val size = message.size(cache, version)\n+    val bytes = ByteBuffer.allocate(2 + size)\n+    val accessor = new ByteBufferAccessor(bytes)\n+    accessor.writeShort(version)\n+    message.write(accessor, cache, version)\n+    bytes.array()", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5NDA3OQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495894079", "bodyText": "We can use GenOffsetCommitRequest. HIGHEST_SUPPORTED_VERSION here. The same applies to the other below.", "author": "dajac", "createdAt": "2020-09-28T12:17:34Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -997,173 +996,45 @@ object GroupMetadataManager {\n   val MetricsGroup: String = \"group-coordinator-metrics\"\n   val LoadTimeSensor: String = \"GroupPartitionLoadTime\"\n \n-  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = 1.toShort\n-  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = 2.toShort\n-\n-  private val OFFSET_COMMIT_KEY_SCHEMA = new Schema(new Field(\"group\", STRING),\n-    new Field(\"topic\", STRING),\n-    new Field(\"partition\", INT32))\n-  private val OFFSET_KEY_GROUP_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"group\")\n-  private val OFFSET_KEY_TOPIC_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"topic\")\n-  private val OFFSET_KEY_PARTITION_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"partition\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V0 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"metadata\")\n-  private val OFFSET_VALUE_TIMESTAMP_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V1 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64),\n-    new Field(\"expire_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"commit_timestamp\")\n-  private val OFFSET_VALUE_EXPIRE_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"expire_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V2 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"commit_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(\"offset\", INT64),\n-    new Field(\"leader_epoch\", INT32),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"offset\")\n-  private val OFFSET_VALUE_LEADER_EPOCH_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"leader_epoch\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"commit_timestamp\")\n-\n-  private val GROUP_METADATA_KEY_SCHEMA = new Schema(new Field(\"group\", STRING))\n-  private val GROUP_KEY_GROUP_FIELD = GROUP_METADATA_KEY_SCHEMA.get(\"group\")\n-\n-  private val MEMBER_ID_KEY = \"member_id\"\n-  private val GROUP_INSTANCE_ID_KEY = \"group_instance_id\"\n-  private val CLIENT_ID_KEY = \"client_id\"\n-  private val CLIENT_HOST_KEY = \"client_host\"\n-  private val REBALANCE_TIMEOUT_KEY = \"rebalance_timeout\"\n-  private val SESSION_TIMEOUT_KEY = \"session_timeout\"\n-  private val SUBSCRIPTION_KEY = \"subscription\"\n-  private val ASSIGNMENT_KEY = \"assignment\"\n-\n-  private val MEMBER_METADATA_V0 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V1 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V2 = MEMBER_METADATA_V1\n-\n-  private val MEMBER_METADATA_V3 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(GROUP_INSTANCE_ID_KEY, NULLABLE_STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val PROTOCOL_TYPE_KEY = \"protocol_type\"\n-  private val GENERATION_KEY = \"generation\"\n-  private val PROTOCOL_KEY = \"protocol\"\n-  private val LEADER_KEY = \"leader\"\n-  private val CURRENT_STATE_TIMESTAMP_KEY = \"current_state_timestamp\"\n-  private val MEMBERS_KEY = \"members\"\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V0 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V0)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V1 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V1)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V2 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V2)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V3)))\n-\n-  // map of versions to key schemas as data types\n-  private val MESSAGE_TYPE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    1 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    2 -> GROUP_METADATA_KEY_SCHEMA)\n-\n-  // map of version of offset value schemas\n-  private val OFFSET_VALUE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_VALUE_SCHEMA_V0,\n-    1 -> OFFSET_COMMIT_VALUE_SCHEMA_V1,\n-    2 -> OFFSET_COMMIT_VALUE_SCHEMA_V2,\n-    3 -> OFFSET_COMMIT_VALUE_SCHEMA_V3)\n-\n-  // map of version of group metadata value schemas\n-  private val GROUP_VALUE_SCHEMAS = Map(\n-    0 -> GROUP_METADATA_VALUE_SCHEMA_V0,\n-    1 -> GROUP_METADATA_VALUE_SCHEMA_V1,\n-    2 -> GROUP_METADATA_VALUE_SCHEMA_V2,\n-    3 -> GROUP_METADATA_VALUE_SCHEMA_V3)\n-\n-  private val CURRENT_OFFSET_KEY_SCHEMA = schemaForKey(CURRENT_OFFSET_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_KEY_SCHEMA = schemaForKey(CURRENT_GROUP_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = GROUP_VALUE_SCHEMAS.keySet.max\n-\n-  private def schemaForKey(version: Int) = {\n-    val schemaOpt = MESSAGE_TYPE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown message key schema version \" + version)\n-    }\n-  }\n-\n-  private def schemaForOffsetValue(version: Int) = {\n-    val schemaOpt = OFFSET_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown offset schema version \" + version)\n+  /**\n+   *\n+   * Statically check to make sure that the generated code always stays in sync with the overall protocol\n+   * @param clz generated class\n+   * @param actual actual version\n+   * @param expected expected version\n+   * @return correct version\n+   */\n+  private def checkVersionOfGeneratedCode(clz: Class[_], actual: Short, expected: Short): Short = {\n+    if (actual != expected) {\n+      throw new IllegalArgumentException(\n+        s\"core/src/main/resources/common/message/${clz.getSimpleName}.json needs to be updated to match the \" +\n+          s\"latest assignment protocol version. ${clz.getSimpleName} only supports up to  [\"\n+          + actual + \"] but needs to support up to [\" + expected + \"].\");\n     }\n+    expected\n   }\n \n-  private def schemaForGroupValue(version: Int) = {\n-    val schemaOpt = GROUP_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown group metadata version \" + version)\n-    }\n+  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[GenOffsetCommitRequest],\n+    actual = (GenOffsetCommitRequest.SCHEMAS.length - 1).toShort,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5NTY1Mw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495895653", "bodyText": "It seems that we don't check the version of OffsetCommitResponse. Is it intentional? Also, I wonder if doing these checks is really necessary. Having to maintain the versions in the spec and the expected version here sounds quite painful to me.", "author": "dajac", "createdAt": "2020-09-28T12:20:34Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -997,173 +996,45 @@ object GroupMetadataManager {\n   val MetricsGroup: String = \"group-coordinator-metrics\"\n   val LoadTimeSensor: String = \"GroupPartitionLoadTime\"\n \n-  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = 1.toShort\n-  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = 2.toShort\n-\n-  private val OFFSET_COMMIT_KEY_SCHEMA = new Schema(new Field(\"group\", STRING),\n-    new Field(\"topic\", STRING),\n-    new Field(\"partition\", INT32))\n-  private val OFFSET_KEY_GROUP_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"group\")\n-  private val OFFSET_KEY_TOPIC_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"topic\")\n-  private val OFFSET_KEY_PARTITION_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"partition\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V0 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"metadata\")\n-  private val OFFSET_VALUE_TIMESTAMP_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V1 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64),\n-    new Field(\"expire_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"commit_timestamp\")\n-  private val OFFSET_VALUE_EXPIRE_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"expire_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V2 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"commit_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(\"offset\", INT64),\n-    new Field(\"leader_epoch\", INT32),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"offset\")\n-  private val OFFSET_VALUE_LEADER_EPOCH_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"leader_epoch\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"commit_timestamp\")\n-\n-  private val GROUP_METADATA_KEY_SCHEMA = new Schema(new Field(\"group\", STRING))\n-  private val GROUP_KEY_GROUP_FIELD = GROUP_METADATA_KEY_SCHEMA.get(\"group\")\n-\n-  private val MEMBER_ID_KEY = \"member_id\"\n-  private val GROUP_INSTANCE_ID_KEY = \"group_instance_id\"\n-  private val CLIENT_ID_KEY = \"client_id\"\n-  private val CLIENT_HOST_KEY = \"client_host\"\n-  private val REBALANCE_TIMEOUT_KEY = \"rebalance_timeout\"\n-  private val SESSION_TIMEOUT_KEY = \"session_timeout\"\n-  private val SUBSCRIPTION_KEY = \"subscription\"\n-  private val ASSIGNMENT_KEY = \"assignment\"\n-\n-  private val MEMBER_METADATA_V0 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V1 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V2 = MEMBER_METADATA_V1\n-\n-  private val MEMBER_METADATA_V3 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(GROUP_INSTANCE_ID_KEY, NULLABLE_STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val PROTOCOL_TYPE_KEY = \"protocol_type\"\n-  private val GENERATION_KEY = \"generation\"\n-  private val PROTOCOL_KEY = \"protocol\"\n-  private val LEADER_KEY = \"leader\"\n-  private val CURRENT_STATE_TIMESTAMP_KEY = \"current_state_timestamp\"\n-  private val MEMBERS_KEY = \"members\"\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V0 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V0)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V1 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V1)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V2 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V2)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V3)))\n-\n-  // map of versions to key schemas as data types\n-  private val MESSAGE_TYPE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    1 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    2 -> GROUP_METADATA_KEY_SCHEMA)\n-\n-  // map of version of offset value schemas\n-  private val OFFSET_VALUE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_VALUE_SCHEMA_V0,\n-    1 -> OFFSET_COMMIT_VALUE_SCHEMA_V1,\n-    2 -> OFFSET_COMMIT_VALUE_SCHEMA_V2,\n-    3 -> OFFSET_COMMIT_VALUE_SCHEMA_V3)\n-\n-  // map of version of group metadata value schemas\n-  private val GROUP_VALUE_SCHEMAS = Map(\n-    0 -> GROUP_METADATA_VALUE_SCHEMA_V0,\n-    1 -> GROUP_METADATA_VALUE_SCHEMA_V1,\n-    2 -> GROUP_METADATA_VALUE_SCHEMA_V2,\n-    3 -> GROUP_METADATA_VALUE_SCHEMA_V3)\n-\n-  private val CURRENT_OFFSET_KEY_SCHEMA = schemaForKey(CURRENT_OFFSET_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_KEY_SCHEMA = schemaForKey(CURRENT_GROUP_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = GROUP_VALUE_SCHEMAS.keySet.max\n-\n-  private def schemaForKey(version: Int) = {\n-    val schemaOpt = MESSAGE_TYPE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown message key schema version \" + version)\n-    }\n-  }\n-\n-  private def schemaForOffsetValue(version: Int) = {\n-    val schemaOpt = OFFSET_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown offset schema version \" + version)\n+  /**\n+   *\n+   * Statically check to make sure that the generated code always stays in sync with the overall protocol\n+   * @param clz generated class\n+   * @param actual actual version\n+   * @param expected expected version\n+   * @return correct version\n+   */\n+  private def checkVersionOfGeneratedCode(clz: Class[_], actual: Short, expected: Short): Short = {\n+    if (actual != expected) {\n+      throw new IllegalArgumentException(\n+        s\"core/src/main/resources/common/message/${clz.getSimpleName}.json needs to be updated to match the \" +\n+          s\"latest assignment protocol version. ${clz.getSimpleName} only supports up to  [\"\n+          + actual + \"] but needs to support up to [\" + expected + \"].\");\n     }\n+    expected\n   }\n \n-  private def schemaForGroupValue(version: Int) = {\n-    val schemaOpt = GROUP_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown group metadata version \" + version)\n-    }\n+  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[GenOffsetCommitRequest],\n+    actual = (GenOffsetCommitRequest.SCHEMAS.length - 1).toShort,\n+    expected = 1.toShort)\n+  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = checkVersionOfGeneratedCode(\n+    clz = classOf[GroupMetadataRequest],\n+    actual = (GroupMetadataRequest.SCHEMAS.length - 1).toShort,\n+    expected = 2.toShort)\n+  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = checkVersionOfGeneratedCode(", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkzMjU4MQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495932581", "bodyText": "Also, I wonder if doing these checks is really necessary. Having to maintain the versions in the spec and the expected version here sounds quite painful to me.\n\nThis check makes sure the code always stays in sync. However, if we can make great code reviews (like yours), this static check should be unnecessary :)\nI will remove this painful check (to me also) in next commit.", "author": "chia7712", "createdAt": "2020-09-28T13:19:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5NTY1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5NjM4MA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495896380", "bodyText": "nit: Could we break this line? Having each setYXZ on a new line would improve the readability.", "author": "dajac", "createdAt": "2020-09-28T12:21:50Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1174,15 +1045,8 @@ object GroupMetadataManager {\n    * @return key for offset commit message\n    */\n   def offsetCommitKey(groupId: String, topicPartition: TopicPartition): Array[Byte] = {\n-    val key = new Struct(CURRENT_OFFSET_KEY_SCHEMA)\n-    key.set(OFFSET_KEY_GROUP_FIELD, groupId)\n-    key.set(OFFSET_KEY_TOPIC_FIELD, topicPartition.topic)\n-    key.set(OFFSET_KEY_PARTITION_FIELD, topicPartition.partition)\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + key.sizeOf)\n-    byteBuffer.putShort(CURRENT_OFFSET_KEY_SCHEMA_VERSION)\n-    key.writeTo(byteBuffer)\n-    byteBuffer.array()\n+    serializeMessage(CURRENT_OFFSET_KEY_SCHEMA_VERSION,\n+      new GenOffsetCommitRequest().setGroup(groupId).setTopic(topicPartition.topic()).setPartition(topicPartition.partition()))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5OTA0Nw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495899047", "bodyText": "nit: The parenthesis may not be necessary for all the getters. It is worth checking the other cases below as well.", "author": "dajac", "createdAt": "2020-09-28T12:26:32Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1321,22 +1159,15 @@ object GroupMetadataManager {\n    */\n   def readMessageKey(buffer: ByteBuffer): BaseKey = {\n     val version = buffer.getShort\n-    val keySchema = schemaForKey(version)\n-    val key = keySchema.read(buffer)\n \n     if (version <= CURRENT_OFFSET_KEY_SCHEMA_VERSION) {\n       // version 0 and 1 refer to offset\n-      val group = key.get(OFFSET_KEY_GROUP_FIELD).asInstanceOf[String]\n-      val topic = key.get(OFFSET_KEY_TOPIC_FIELD).asInstanceOf[String]\n-      val partition = key.get(OFFSET_KEY_PARTITION_FIELD).asInstanceOf[Int]\n-\n-      OffsetKey(version, GroupTopicPartition(group, new TopicPartition(topic, partition)))\n-\n+      val key = new GenOffsetCommitRequest(new ByteBufferAccessor(buffer), version)\n+      OffsetKey(version, GroupTopicPartition(key.group(), new TopicPartition(key.topic(), key.partition())))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkwMTE3Mw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495901173", "bodyText": "We may want to use \"zeroCopy\": true for both subscription and assignment like we did for the consumer protocol.", "author": "dajac", "createdAt": "2020-09-28T12:30:26Z", "path": "core/src/main/resources/common/message/GroupMetadataResponse.json", "diffHunk": "@@ -0,0 +1,103 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"name\": \"GroupMetadataResponse\",\n+  \"validVersions\": \"0-3\",\n+  \"fields\": [\n+    {\n+      \"name\": \"protocolType\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\"\n+    },\n+    {\n+      \"name\": \"generation\",\n+      \"versions\": \"0+\",\n+      \"type\": \"int32\"\n+    },\n+    {\n+      \"name\": \"protocol\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\",\n+      \"nullableVersions\": \"0+\"\n+    },\n+    {\n+      \"name\": \"leader\",\n+      \"versions\": \"0+\",\n+      \"type\": \"string\",\n+      \"nullableVersions\": \"0+\"\n+    },\n+    {\n+      \"name\": \"members\",\n+      \"versions\": \"0+\",\n+      \"type\": \"[]MemberMetadata\"\n+    },\n+    {\n+      \"name\": \"currentStateTimestamp\",\n+      \"versions\": \"2+\",\n+      \"type\": \"int64\"\n+    }\n+  ],\n+  \"commonStructs\": [\n+    {\n+      \"name\": \"MemberMetadata\",\n+      \"versions\": \"0-3\",\n+      \"fields\": [\n+        {\n+          \"name\": \"memberId\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"clientId\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"clientHost\",\n+          \"versions\": \"0+\",\n+          \"type\": \"string\"\n+        },\n+        {\n+          \"name\": \"sessionTimeout\",\n+          \"versions\": \"0+\",\n+          \"type\": \"int32\"\n+        },\n+        {\n+          \"name\": \"subscription\",\n+          \"versions\": \"0+\",\n+          \"type\": \"bytes\"", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTk2NjYwMA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r495966600", "bodyText": "Could I address it in a separate PR? The true used type is byte[] rather than ByteBuffer so it may bring a lot changes.", "author": "chia7712", "createdAt": "2020-09-28T14:06:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkwMTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM4MjY4NA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r497382684", "bodyText": "I am not sure if we gain much by using \"zeroCopy\": true in the end. I suggested this because the Struct based schemas were using ByteBuffer. Using bytes should be ok here, isn't it?", "author": "dajac", "createdAt": "2020-09-30T09:48:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkwMTE3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM5MTExMA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r497391110", "bodyText": "Using bytes should be ok here, isn't it?\n\nIt would be better to use bytes currently since MemberMetadata.scala is using bytes rather than ByteBuffer(https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/coordinator/group/MemberMetadata.scala#L64). The previous code make deep copy of ByteBuffer from struct to get bytes\nmember.assignment = Utils.toArray(memberMetadata.get(ASSIGNMENT_KEY).asInstanceOf[ByteBuffer])", "author": "chia7712", "createdAt": "2020-09-30T10:02:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTkwMTE3Mw=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcxNzc0NQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498717745", "bodyText": "0-1?", "author": "dajac", "createdAt": "2020-10-02T09:35:37Z", "path": "core/src/main/resources/common/message/OffsetCommitKey.json", "diffHunk": "@@ -0,0 +1,25 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"type\": \"data\",\n+  \"name\": \"OffsetCommitKey\",\n+  \"validVersions\": \"0-2\",", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcxNzgxNA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498717814", "bodyText": "0-1?", "author": "dajac", "createdAt": "2020-10-02T09:35:45Z", "path": "core/src/main/resources/common/message/OffsetCommitKey.json", "diffHunk": "@@ -0,0 +1,25 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"type\": \"data\",\n+  \"name\": \"OffsetCommitKey\",\n+  \"validVersions\": \"0-2\",\n+  \"fields\": [\n+    { \"name\": \"group\", \"type\": \"string\", \"versions\": \"0-2\" },", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyMDE2NA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498720164", "bodyText": "nit: I think that the parenthesis after topic and partition could be removed in both cases.", "author": "dajac", "createdAt": "2020-10-02T09:40:58Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1174,15 +1013,11 @@ object GroupMetadataManager {\n    * @return key for offset commit message\n    */\n   def offsetCommitKey(groupId: String, topicPartition: TopicPartition): Array[Byte] = {\n-    val key = new Struct(CURRENT_OFFSET_KEY_SCHEMA)\n-    key.set(OFFSET_KEY_GROUP_FIELD, groupId)\n-    key.set(OFFSET_KEY_TOPIC_FIELD, topicPartition.topic)\n-    key.set(OFFSET_KEY_PARTITION_FIELD, topicPartition.partition)\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + key.sizeOf)\n-    byteBuffer.putShort(CURRENT_OFFSET_KEY_SCHEMA_VERSION)\n-    key.writeTo(byteBuffer)\n-    byteBuffer.array()\n+    serializeMessage(CURRENT_OFFSET_KEY_SCHEMA_VERSION,\n+      new OffsetCommitKey()\n+        .setGroup(groupId)\n+        .setTopic(topicPartition.topic())\n+        .setPartition(topicPartition.partition()))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNDY1OA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498724658", "bodyText": "nit: Here we could use GroupMetadataValue.LOWEST_SUPPORTED_VERSION and GroupMetadataValue.HIGHEST_SUPPORTED_VERSION.", "author": "dajac", "createdAt": "2020-10-02T09:50:26Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1405,39 +1189,36 @@ object GroupMetadataManager {\n       null\n     } else {\n       val version = buffer.getShort\n-      val valueSchema = schemaForGroupValue(version)\n-      val value = valueSchema.read(buffer)\n-\n       if (version >= 0 && version <= CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNTU5Nw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498725597", "bodyText": "Could we also add a comment for this one like you did for the other?", "author": "dajac", "createdAt": "2020-10-02T09:52:31Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -998,173 +997,13 @@ object GroupMetadataManager {\n   val LoadTimeSensor: String = \"GroupPartitionLoadTime\"\n \n   private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = 1.toShort", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODkzNjEzOA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498936138", "bodyText": "I remove those constants and replacement is LOWEST_SUPPORTED_VERSION/HIGHEST_SUPPORTED_VERSION", "author": "chia7712", "createdAt": "2020-10-02T16:50:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODcyNTU5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc2MzQ0OQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498763449", "bodyText": "I am not sure if this is worth it but we could avoid checking the version by putting -1 as default value for currentStateTimestamp in the schema.", "author": "dajac", "createdAt": "2020-10-02T11:23:43Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1405,39 +1189,36 @@ object GroupMetadataManager {\n       null\n     } else {\n       val version = buffer.getShort\n-      val valueSchema = schemaForGroupValue(version)\n-      val value = valueSchema.read(buffer)\n-\n       if (version >= 0 && version <= CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION) {\n-        val generationId = value.get(GENERATION_KEY).asInstanceOf[Int]\n-        val protocolType = value.get(PROTOCOL_TYPE_KEY).asInstanceOf[String]\n-        val protocol = value.get(PROTOCOL_KEY).asInstanceOf[String]\n-        val leaderId = value.get(LEADER_KEY).asInstanceOf[String]\n-        val memberMetadataArray = value.getArray(MEMBERS_KEY)\n+        val value = new GroupMetadataValue(new ByteBufferAccessor(buffer), version)\n+        val generationId = value.generation\n+        val protocolType = value.protocolType\n+        val protocol = value.protocol\n+        val leaderId = value.leader\n+        val memberMetadataArray = value.members.asScala\n         val initialState = if (memberMetadataArray.isEmpty) Empty else Stable\n         val currentStateTimestamp: Option[Long] =\n-          if (version >= 2 && value.hasField(CURRENT_STATE_TIMESTAMP_KEY)) {\n-            val timestamp = value.getLong(CURRENT_STATE_TIMESTAMP_KEY)\n+          if (version >= 2) {\n+            val timestamp = value.currentStateTimestamp", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc2MzY4MA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498763680", "bodyText": "Same here. We could have groupInstanceId be null by default in the schema.", "author": "dajac", "createdAt": "2020-10-02T11:24:19Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1405,39 +1189,36 @@ object GroupMetadataManager {\n       null\n     } else {\n       val version = buffer.getShort\n-      val valueSchema = schemaForGroupValue(version)\n-      val value = valueSchema.read(buffer)\n-\n       if (version >= 0 && version <= CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION) {\n-        val generationId = value.get(GENERATION_KEY).asInstanceOf[Int]\n-        val protocolType = value.get(PROTOCOL_TYPE_KEY).asInstanceOf[String]\n-        val protocol = value.get(PROTOCOL_KEY).asInstanceOf[String]\n-        val leaderId = value.get(LEADER_KEY).asInstanceOf[String]\n-        val memberMetadataArray = value.getArray(MEMBERS_KEY)\n+        val value = new GroupMetadataValue(new ByteBufferAccessor(buffer), version)\n+        val generationId = value.generation\n+        val protocolType = value.protocolType\n+        val protocol = value.protocol\n+        val leaderId = value.leader\n+        val memberMetadataArray = value.members.asScala\n         val initialState = if (memberMetadataArray.isEmpty) Empty else Stable\n         val currentStateTimestamp: Option[Long] =\n-          if (version >= 2 && value.hasField(CURRENT_STATE_TIMESTAMP_KEY)) {\n-            val timestamp = value.getLong(CURRENT_STATE_TIMESTAMP_KEY)\n+          if (version >= 2) {\n+            val timestamp = value.currentStateTimestamp\n             if (timestamp == -1) None else Some(timestamp)\n           } else None\n \n         val members = memberMetadataArray.map { memberMetadataObj =>\n-          val memberMetadata = memberMetadataObj.asInstanceOf[Struct]\n-          val memberId = memberMetadata.get(MEMBER_ID_KEY).asInstanceOf[String]\n+          val memberId = memberMetadataObj.memberId\n           val groupInstanceId =\n             if (version >= 3)\n-              Some(memberMetadata.get(GROUP_INSTANCE_ID_KEY).asInstanceOf[String])\n+              Some(memberMetadataObj.groupInstanceId)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk1Nzg3NA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r498957874", "bodyText": "used by testing only so I remove it", "author": "chia7712", "createdAt": "2020-10-02T17:35:45Z", "path": "core/src/main/scala/kafka/common/OffsetAndMetadata.scala", "diffHunk": "@@ -45,8 +45,4 @@ object OffsetAndMetadata {\n   def apply(offset: Long, metadata: String, commitTimestamp: Long, expireTimestamp: Long): OffsetAndMetadata = {\n     OffsetAndMetadata(offset, Optional.empty(), metadata, commitTimestamp, Some(expireTimestamp))\n   }\n-\n-  def apply(offset: Long, leaderEpoch: Optional[Integer], metadata: String, commitTimestamp: Long): OffsetAndMetadata = {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4MzQ0OQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r499283449", "bodyText": "I wonder if we could simplify the whole logic by marking the ExpireTimestamp and LeaderEpoch as optional in the schema. That would allow to always set them here. The auto-generated protocol would then use it only for the supported versions. The logic to choose the version would remain identical:\nval version = \n  if (apiVersion < KAFKA_2_1_IV0 || offsetAndMetadata.expireTimestamp.nonEmpty) 1.toShort\n  else if (apiVersion < KAFKA_2_1_IV1) 2.toShort\n  else 3.toShort", "author": "dajac", "createdAt": "2020-10-04T20:03:33Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1211,37 +1033,30 @@ object GroupMetadataManager {\n   def offsetCommitValue(offsetAndMetadata: OffsetAndMetadata,\n                         apiVersion: ApiVersion): Array[Byte] = {\n     // generate commit value according to schema version\n-    val (version, value) = {\n+    val (version, value) =", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTM0ODAzMg==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r499348032", "bodyText": "great idea!", "author": "chia7712", "createdAt": "2020-10-05T05:07:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4MzQ0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4MzY4Nw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r499283687", "bodyText": "We could mark CurrentStateTimestamp as ignorable as well and let the auto-generated protocol do the version handling.", "author": "dajac", "createdAt": "2020-10-04T20:05:43Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1257,60 +1072,47 @@ object GroupMetadataManager {\n                          assignment: Map[String, Array[Byte]],\n                          apiVersion: ApiVersion): Array[Byte] = {\n \n-    val (version, value) = {\n-      if (apiVersion < KAFKA_0_10_1_IV0)\n-        (0.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V0))\n-      else if (apiVersion < KAFKA_2_1_IV0)\n-        (1.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V1))\n-      else if (apiVersion < KAFKA_2_3_IV0)\n-        (2.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V2))\n-      else\n-        (3.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V3))\n-    }\n+    val value = new GroupMetadataValue()\n+    val version =\n+      if (apiVersion < KAFKA_0_10_1_IV0) 0.toShort\n+      else if (apiVersion < KAFKA_2_1_IV0) 1.toShort\n+      else if (apiVersion < KAFKA_2_3_IV0) 2.toShort\n+      else 3.toShort\n \n-    value.set(PROTOCOL_TYPE_KEY, groupMetadata.protocolType.getOrElse(\"\"))\n-    value.set(GENERATION_KEY, groupMetadata.generationId)\n-    value.set(PROTOCOL_KEY, groupMetadata.protocolName.orNull)\n-    value.set(LEADER_KEY, groupMetadata.leaderOrNull)\n+    value.setProtocolType(groupMetadata.protocolType.getOrElse(\"\"))\n+      .setGeneration(groupMetadata.generationId)\n+      .setProtocol(groupMetadata.protocolName.orNull)\n+      .setLeader(groupMetadata.leaderOrNull)\n \n-    if (version >= 2)\n-      value.set(CURRENT_STATE_TIMESTAMP_KEY, groupMetadata.currentStateTimestampOrDefault)\n+    if (version >= 2) value.setCurrentStateTimestamp(groupMetadata.currentStateTimestampOrDefault)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4MzczMw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r499283733", "bodyText": "We could mark RebalanceTimeout as ignorable as well.", "author": "dajac", "createdAt": "2020-10-04T20:06:16Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1257,60 +1072,47 @@ object GroupMetadataManager {\n                          assignment: Map[String, Array[Byte]],\n                          apiVersion: ApiVersion): Array[Byte] = {\n \n-    val (version, value) = {\n-      if (apiVersion < KAFKA_0_10_1_IV0)\n-        (0.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V0))\n-      else if (apiVersion < KAFKA_2_1_IV0)\n-        (1.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V1))\n-      else if (apiVersion < KAFKA_2_3_IV0)\n-        (2.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V2))\n-      else\n-        (3.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V3))\n-    }\n+    val value = new GroupMetadataValue()\n+    val version =\n+      if (apiVersion < KAFKA_0_10_1_IV0) 0.toShort\n+      else if (apiVersion < KAFKA_2_1_IV0) 1.toShort\n+      else if (apiVersion < KAFKA_2_3_IV0) 2.toShort\n+      else 3.toShort\n \n-    value.set(PROTOCOL_TYPE_KEY, groupMetadata.protocolType.getOrElse(\"\"))\n-    value.set(GENERATION_KEY, groupMetadata.generationId)\n-    value.set(PROTOCOL_KEY, groupMetadata.protocolName.orNull)\n-    value.set(LEADER_KEY, groupMetadata.leaderOrNull)\n+    value.setProtocolType(groupMetadata.protocolType.getOrElse(\"\"))\n+      .setGeneration(groupMetadata.generationId)\n+      .setProtocol(groupMetadata.protocolName.orNull)\n+      .setLeader(groupMetadata.leaderOrNull)\n \n-    if (version >= 2)\n-      value.set(CURRENT_STATE_TIMESTAMP_KEY, groupMetadata.currentStateTimestampOrDefault)\n+    if (version >= 2) value.setCurrentStateTimestamp(groupMetadata.currentStateTimestampOrDefault)\n \n     val memberArray = groupMetadata.allMemberMetadata.map { memberMetadata =>\n-      val memberStruct = value.instance(MEMBERS_KEY)\n-      memberStruct.set(MEMBER_ID_KEY, memberMetadata.memberId)\n-      memberStruct.set(CLIENT_ID_KEY, memberMetadata.clientId)\n-      memberStruct.set(CLIENT_HOST_KEY, memberMetadata.clientHost)\n-      memberStruct.set(SESSION_TIMEOUT_KEY, memberMetadata.sessionTimeoutMs)\n+      val member = new GroupMetadataValue.MemberMetadata()\n+        .setMemberId(memberMetadata.memberId)\n+        .setClientId(memberMetadata.clientId)\n+        .setClientHost(memberMetadata.clientHost)\n+        .setSessionTimeout(memberMetadata.sessionTimeoutMs)\n \n-      if (version > 0)\n-        memberStruct.set(REBALANCE_TIMEOUT_KEY, memberMetadata.rebalanceTimeoutMs)\n+      if (version > 0) member.setRebalanceTimeout(memberMetadata.rebalanceTimeoutMs)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4Mzc2Ng==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r499283766", "bodyText": "We could mark GroupInstanceId as ignorable as well.", "author": "dajac", "createdAt": "2020-10-04T20:06:40Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1257,60 +1072,47 @@ object GroupMetadataManager {\n                          assignment: Map[String, Array[Byte]],\n                          apiVersion: ApiVersion): Array[Byte] = {\n \n-    val (version, value) = {\n-      if (apiVersion < KAFKA_0_10_1_IV0)\n-        (0.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V0))\n-      else if (apiVersion < KAFKA_2_1_IV0)\n-        (1.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V1))\n-      else if (apiVersion < KAFKA_2_3_IV0)\n-        (2.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V2))\n-      else\n-        (3.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V3))\n-    }\n+    val value = new GroupMetadataValue()\n+    val version =\n+      if (apiVersion < KAFKA_0_10_1_IV0) 0.toShort\n+      else if (apiVersion < KAFKA_2_1_IV0) 1.toShort\n+      else if (apiVersion < KAFKA_2_3_IV0) 2.toShort\n+      else 3.toShort\n \n-    value.set(PROTOCOL_TYPE_KEY, groupMetadata.protocolType.getOrElse(\"\"))\n-    value.set(GENERATION_KEY, groupMetadata.generationId)\n-    value.set(PROTOCOL_KEY, groupMetadata.protocolName.orNull)\n-    value.set(LEADER_KEY, groupMetadata.leaderOrNull)\n+    value.setProtocolType(groupMetadata.protocolType.getOrElse(\"\"))\n+      .setGeneration(groupMetadata.generationId)\n+      .setProtocol(groupMetadata.protocolName.orNull)\n+      .setLeader(groupMetadata.leaderOrNull)\n \n-    if (version >= 2)\n-      value.set(CURRENT_STATE_TIMESTAMP_KEY, groupMetadata.currentStateTimestampOrDefault)\n+    if (version >= 2) value.setCurrentStateTimestamp(groupMetadata.currentStateTimestampOrDefault)\n \n     val memberArray = groupMetadata.allMemberMetadata.map { memberMetadata =>\n-      val memberStruct = value.instance(MEMBERS_KEY)\n-      memberStruct.set(MEMBER_ID_KEY, memberMetadata.memberId)\n-      memberStruct.set(CLIENT_ID_KEY, memberMetadata.clientId)\n-      memberStruct.set(CLIENT_HOST_KEY, memberMetadata.clientHost)\n-      memberStruct.set(SESSION_TIMEOUT_KEY, memberMetadata.sessionTimeoutMs)\n+      val member = new GroupMetadataValue.MemberMetadata()\n+        .setMemberId(memberMetadata.memberId)\n+        .setClientId(memberMetadata.clientId)\n+        .setClientHost(memberMetadata.clientHost)\n+        .setSessionTimeout(memberMetadata.sessionTimeoutMs)\n \n-      if (version > 0)\n-        memberStruct.set(REBALANCE_TIMEOUT_KEY, memberMetadata.rebalanceTimeoutMs)\n+      if (version > 0) member.setRebalanceTimeout(memberMetadata.rebalanceTimeoutMs)\n \n-      if (version >= 3)\n-        memberStruct.set(GROUP_INSTANCE_ID_KEY, memberMetadata.groupInstanceId.orNull)\n+      if (version >= 3) member.setGroupInstanceId(memberMetadata.groupInstanceId.orNull)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTI4NDA5NQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r499284095", "bodyText": "We may be able to consolidate this entire logic by defining default values in the schema for leaderEpoch and expireTimestamp.", "author": "dajac", "createdAt": "2020-10-04T20:10:33Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1349,46 +1142,30 @@ object GroupMetadataManager {\n    * @return an offset-metadata object from the message\n    */\n   def readOffsetMessageValue(buffer: ByteBuffer): OffsetAndMetadata = {\n-    if (buffer == null) { // tombstone\n-      null\n-    } else {\n+    // tombstone\n+    if (buffer == null) null\n+    else {\n       val version = buffer.getShort\n-      val valueSchema = schemaForOffsetValue(version)\n-      val value = valueSchema.read(buffer)\n-\n-      if (version == 0) {\n-        val offset = value.get(OFFSET_VALUE_OFFSET_FIELD_V0).asInstanceOf[Long]\n-        val metadata = value.get(OFFSET_VALUE_METADATA_FIELD_V0).asInstanceOf[String]\n-        val timestamp = value.get(OFFSET_VALUE_TIMESTAMP_FIELD_V0).asInstanceOf[Long]\n-\n-        OffsetAndMetadata(offset, metadata, timestamp)\n-      } else if (version == 1) {\n-        val offset = value.get(OFFSET_VALUE_OFFSET_FIELD_V1).asInstanceOf[Long]\n-        val metadata = value.get(OFFSET_VALUE_METADATA_FIELD_V1).asInstanceOf[String]\n-        val commitTimestamp = value.get(OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V1).asInstanceOf[Long]\n-        val expireTimestamp = value.get(OFFSET_VALUE_EXPIRE_TIMESTAMP_FIELD_V1).asInstanceOf[Long]\n-\n-        if (expireTimestamp == OffsetCommitRequest.DEFAULT_TIMESTAMP)\n-          OffsetAndMetadata(offset, metadata, commitTimestamp)\n-        else\n-          OffsetAndMetadata(offset, metadata, commitTimestamp, expireTimestamp)\n-      } else if (version == 2) {\n-        val offset = value.get(OFFSET_VALUE_OFFSET_FIELD_V2).asInstanceOf[Long]\n-        val metadata = value.get(OFFSET_VALUE_METADATA_FIELD_V2).asInstanceOf[String]\n-        val commitTimestamp = value.get(OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V2).asInstanceOf[Long]\n-\n-        OffsetAndMetadata(offset, metadata, commitTimestamp)\n-      } else if (version == 3) {\n-        val offset = value.get(OFFSET_VALUE_OFFSET_FIELD_V3).asInstanceOf[Long]\n-        val leaderEpoch = value.get(OFFSET_VALUE_LEADER_EPOCH_FIELD_V3).asInstanceOf[Int]\n-        val metadata = value.get(OFFSET_VALUE_METADATA_FIELD_V3).asInstanceOf[String]\n-        val commitTimestamp = value.get(OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3).asInstanceOf[Long]\n-\n-        val leaderEpochOpt: Optional[Integer] = if (leaderEpoch < 0) Optional.empty() else Optional.of(leaderEpoch)\n-        OffsetAndMetadata(offset, leaderEpochOpt, metadata, commitTimestamp)\n-      } else {\n-        throw new IllegalStateException(s\"Unknown offset message version: $version\")\n-      }\n+      val value = new OffsetCommitValue(new ByteBufferAccessor(buffer), version)\n+      if (version == 0)\n+        OffsetAndMetadata(value.offset, value.metadata, value.commitTimestamp)\n+      else if (version == 1)\n+        OffsetAndMetadata(\n+          offset = value.offset,\n+          leaderEpoch = Optional.empty(),\n+          metadata = value.metadata,\n+          commitTimestamp = value.commitTimestamp,\n+          expireTimestamp = if (value.expireTimestamp == OffsetCommitRequest.DEFAULT_TIMESTAMP) None else Some(value.expireTimestamp))\n+      else if (version == 2)\n+        OffsetAndMetadata(value.offset, value.metadata, value.commitTimestamp)\n+      else if (version == 3)\n+        OffsetAndMetadata(\n+          offset = value.offset,\n+          leaderEpoch = if (value.leaderEpoch == RecordBatch.NO_PARTITION_LEADER_EPOCH) Optional.empty() else Optional.of(value.leaderEpoch),\n+          metadata = value.metadata,\n+          commitTimestamp = value.commitTimestamp,\n+          expireTimestamp = None)\n+      else throw new IllegalStateException(s\"Unknown offset message version: $version\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDI5MzU1Mw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500293553", "bodyText": "nit: We tend to use curly braces when the lambda does not fit on the same line.", "author": "dajac", "createdAt": "2020-10-06T13:47:50Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1257,60 +1059,31 @@ object GroupMetadataManager {\n                          assignment: Map[String, Array[Byte]],\n                          apiVersion: ApiVersion): Array[Byte] = {\n \n-    val (version, value) = {\n-      if (apiVersion < KAFKA_0_10_1_IV0)\n-        (0.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V0))\n-      else if (apiVersion < KAFKA_2_1_IV0)\n-        (1.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V1))\n-      else if (apiVersion < KAFKA_2_3_IV0)\n-        (2.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V2))\n-      else\n-        (3.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V3))\n-    }\n-\n-    value.set(PROTOCOL_TYPE_KEY, groupMetadata.protocolType.getOrElse(\"\"))\n-    value.set(GENERATION_KEY, groupMetadata.generationId)\n-    value.set(PROTOCOL_KEY, groupMetadata.protocolName.orNull)\n-    value.set(LEADER_KEY, groupMetadata.leaderOrNull)\n-\n-    if (version >= 2)\n-      value.set(CURRENT_STATE_TIMESTAMP_KEY, groupMetadata.currentStateTimestampOrDefault)\n-\n-    val memberArray = groupMetadata.allMemberMetadata.map { memberMetadata =>\n-      val memberStruct = value.instance(MEMBERS_KEY)\n-      memberStruct.set(MEMBER_ID_KEY, memberMetadata.memberId)\n-      memberStruct.set(CLIENT_ID_KEY, memberMetadata.clientId)\n-      memberStruct.set(CLIENT_HOST_KEY, memberMetadata.clientHost)\n-      memberStruct.set(SESSION_TIMEOUT_KEY, memberMetadata.sessionTimeoutMs)\n-\n-      if (version > 0)\n-        memberStruct.set(REBALANCE_TIMEOUT_KEY, memberMetadata.rebalanceTimeoutMs)\n-\n-      if (version >= 3)\n-        memberStruct.set(GROUP_INSTANCE_ID_KEY, memberMetadata.groupInstanceId.orNull)\n-\n-      // The group is non-empty, so the current protocol must be defined\n-      val protocol = groupMetadata.protocolName.orNull\n-      if (protocol == null)\n-        throw new IllegalStateException(\"Attempted to write non-empty group metadata with no defined protocol\")\n-\n-      val metadata = memberMetadata.metadata(protocol)\n-      memberStruct.set(SUBSCRIPTION_KEY, ByteBuffer.wrap(metadata))\n-\n-      val memberAssignment = assignment(memberMetadata.memberId)\n-      assert(memberAssignment != null)\n-\n-      memberStruct.set(ASSIGNMENT_KEY, ByteBuffer.wrap(memberAssignment))\n-\n-      memberStruct\n-    }\n-\n-    value.set(MEMBERS_KEY, memberArray.toArray)\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(version)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+    val version =\n+      if (apiVersion < KAFKA_0_10_1_IV0) 0.toShort\n+      else if (apiVersion < KAFKA_2_1_IV0) 1.toShort\n+      else if (apiVersion < KAFKA_2_3_IV0) 2.toShort\n+      else 3.toShort\n+\n+    serializeMessage(version, new GroupMetadataValue()\n+      .setProtocolType(groupMetadata.protocolType.getOrElse(\"\"))\n+      .setGeneration(groupMetadata.generationId)\n+      .setProtocol(groupMetadata.protocolName.orNull)\n+      .setLeader(groupMetadata.leaderOrNull)\n+      .setCurrentStateTimestamp(groupMetadata.currentStateTimestampOrDefault)\n+      .setMembers(groupMetadata.allMemberMetadata.map(memberMetadata =>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDI5NTYzMg==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500295632", "bodyText": "nit: I personally prefer the previous error message. Could we add the groupId in the message as well?", "author": "dajac", "createdAt": "2020-10-06T13:49:56Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1257,60 +1059,31 @@ object GroupMetadataManager {\n                          assignment: Map[String, Array[Byte]],\n                          apiVersion: ApiVersion): Array[Byte] = {\n \n-    val (version, value) = {\n-      if (apiVersion < KAFKA_0_10_1_IV0)\n-        (0.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V0))\n-      else if (apiVersion < KAFKA_2_1_IV0)\n-        (1.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V1))\n-      else if (apiVersion < KAFKA_2_3_IV0)\n-        (2.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V2))\n-      else\n-        (3.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V3))\n-    }\n-\n-    value.set(PROTOCOL_TYPE_KEY, groupMetadata.protocolType.getOrElse(\"\"))\n-    value.set(GENERATION_KEY, groupMetadata.generationId)\n-    value.set(PROTOCOL_KEY, groupMetadata.protocolName.orNull)\n-    value.set(LEADER_KEY, groupMetadata.leaderOrNull)\n-\n-    if (version >= 2)\n-      value.set(CURRENT_STATE_TIMESTAMP_KEY, groupMetadata.currentStateTimestampOrDefault)\n-\n-    val memberArray = groupMetadata.allMemberMetadata.map { memberMetadata =>\n-      val memberStruct = value.instance(MEMBERS_KEY)\n-      memberStruct.set(MEMBER_ID_KEY, memberMetadata.memberId)\n-      memberStruct.set(CLIENT_ID_KEY, memberMetadata.clientId)\n-      memberStruct.set(CLIENT_HOST_KEY, memberMetadata.clientHost)\n-      memberStruct.set(SESSION_TIMEOUT_KEY, memberMetadata.sessionTimeoutMs)\n-\n-      if (version > 0)\n-        memberStruct.set(REBALANCE_TIMEOUT_KEY, memberMetadata.rebalanceTimeoutMs)\n-\n-      if (version >= 3)\n-        memberStruct.set(GROUP_INSTANCE_ID_KEY, memberMetadata.groupInstanceId.orNull)\n-\n-      // The group is non-empty, so the current protocol must be defined\n-      val protocol = groupMetadata.protocolName.orNull\n-      if (protocol == null)\n-        throw new IllegalStateException(\"Attempted to write non-empty group metadata with no defined protocol\")\n-\n-      val metadata = memberMetadata.metadata(protocol)\n-      memberStruct.set(SUBSCRIPTION_KEY, ByteBuffer.wrap(metadata))\n-\n-      val memberAssignment = assignment(memberMetadata.memberId)\n-      assert(memberAssignment != null)\n-\n-      memberStruct.set(ASSIGNMENT_KEY, ByteBuffer.wrap(memberAssignment))\n-\n-      memberStruct\n-    }\n-\n-    value.set(MEMBERS_KEY, memberArray.toArray)\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(version)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+    val version =\n+      if (apiVersion < KAFKA_0_10_1_IV0) 0.toShort\n+      else if (apiVersion < KAFKA_2_1_IV0) 1.toShort\n+      else if (apiVersion < KAFKA_2_3_IV0) 2.toShort\n+      else 3.toShort\n+\n+    serializeMessage(version, new GroupMetadataValue()\n+      .setProtocolType(groupMetadata.protocolType.getOrElse(\"\"))\n+      .setGeneration(groupMetadata.generationId)\n+      .setProtocol(groupMetadata.protocolName.orNull)\n+      .setLeader(groupMetadata.leaderOrNull)\n+      .setCurrentStateTimestamp(groupMetadata.currentStateTimestampOrDefault)\n+      .setMembers(groupMetadata.allMemberMetadata.map(memberMetadata =>\n+        new GroupMetadataValue.MemberMetadata()\n+          .setMemberId(memberMetadata.memberId)\n+          .setClientId(memberMetadata.clientId)\n+          .setClientHost(memberMetadata.clientHost)\n+          .setSessionTimeout(memberMetadata.sessionTimeoutMs)\n+          .setRebalanceTimeout(memberMetadata.rebalanceTimeoutMs)\n+          .setGroupInstanceId(memberMetadata.groupInstanceId.orNull)\n+          .setSubscription(groupMetadata.protocolName.map(memberMetadata.metadata)\n+            .getOrElse(throw new IllegalStateException(\"The group is non-empty so the current protocol must be defined\")))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDM1MjQ5Nw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500352497", "bodyText": "ok. keep previous error message", "author": "chia7712", "createdAt": "2020-10-06T14:48:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDI5NTYzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDI5NzgyMA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500297820", "bodyText": "nit: Could we also add the group id in the message? I thinking about something like this if we keep the previous version of the message above: Attempted to write member $memberId of group $groupId with no assignment.", "author": "dajac", "createdAt": "2020-10-06T13:52:14Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1257,60 +1059,31 @@ object GroupMetadataManager {\n                          assignment: Map[String, Array[Byte]],\n                          apiVersion: ApiVersion): Array[Byte] = {\n \n-    val (version, value) = {\n-      if (apiVersion < KAFKA_0_10_1_IV0)\n-        (0.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V0))\n-      else if (apiVersion < KAFKA_2_1_IV0)\n-        (1.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V1))\n-      else if (apiVersion < KAFKA_2_3_IV0)\n-        (2.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V2))\n-      else\n-        (3.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V3))\n-    }\n-\n-    value.set(PROTOCOL_TYPE_KEY, groupMetadata.protocolType.getOrElse(\"\"))\n-    value.set(GENERATION_KEY, groupMetadata.generationId)\n-    value.set(PROTOCOL_KEY, groupMetadata.protocolName.orNull)\n-    value.set(LEADER_KEY, groupMetadata.leaderOrNull)\n-\n-    if (version >= 2)\n-      value.set(CURRENT_STATE_TIMESTAMP_KEY, groupMetadata.currentStateTimestampOrDefault)\n-\n-    val memberArray = groupMetadata.allMemberMetadata.map { memberMetadata =>\n-      val memberStruct = value.instance(MEMBERS_KEY)\n-      memberStruct.set(MEMBER_ID_KEY, memberMetadata.memberId)\n-      memberStruct.set(CLIENT_ID_KEY, memberMetadata.clientId)\n-      memberStruct.set(CLIENT_HOST_KEY, memberMetadata.clientHost)\n-      memberStruct.set(SESSION_TIMEOUT_KEY, memberMetadata.sessionTimeoutMs)\n-\n-      if (version > 0)\n-        memberStruct.set(REBALANCE_TIMEOUT_KEY, memberMetadata.rebalanceTimeoutMs)\n-\n-      if (version >= 3)\n-        memberStruct.set(GROUP_INSTANCE_ID_KEY, memberMetadata.groupInstanceId.orNull)\n-\n-      // The group is non-empty, so the current protocol must be defined\n-      val protocol = groupMetadata.protocolName.orNull\n-      if (protocol == null)\n-        throw new IllegalStateException(\"Attempted to write non-empty group metadata with no defined protocol\")\n-\n-      val metadata = memberMetadata.metadata(protocol)\n-      memberStruct.set(SUBSCRIPTION_KEY, ByteBuffer.wrap(metadata))\n-\n-      val memberAssignment = assignment(memberMetadata.memberId)\n-      assert(memberAssignment != null)\n-\n-      memberStruct.set(ASSIGNMENT_KEY, ByteBuffer.wrap(memberAssignment))\n-\n-      memberStruct\n-    }\n-\n-    value.set(MEMBERS_KEY, memberArray.toArray)\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(version)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+    val version =\n+      if (apiVersion < KAFKA_0_10_1_IV0) 0.toShort\n+      else if (apiVersion < KAFKA_2_1_IV0) 1.toShort\n+      else if (apiVersion < KAFKA_2_3_IV0) 2.toShort\n+      else 3.toShort\n+\n+    serializeMessage(version, new GroupMetadataValue()\n+      .setProtocolType(groupMetadata.protocolType.getOrElse(\"\"))\n+      .setGeneration(groupMetadata.generationId)\n+      .setProtocol(groupMetadata.protocolName.orNull)\n+      .setLeader(groupMetadata.leaderOrNull)\n+      .setCurrentStateTimestamp(groupMetadata.currentStateTimestampOrDefault)\n+      .setMembers(groupMetadata.allMemberMetadata.map(memberMetadata =>\n+        new GroupMetadataValue.MemberMetadata()\n+          .setMemberId(memberMetadata.memberId)\n+          .setClientId(memberMetadata.clientId)\n+          .setClientHost(memberMetadata.clientHost)\n+          .setSessionTimeout(memberMetadata.sessionTimeoutMs)\n+          .setRebalanceTimeout(memberMetadata.rebalanceTimeoutMs)\n+          .setGroupInstanceId(memberMetadata.groupInstanceId.orNull)\n+          .setSubscription(groupMetadata.protocolName.map(memberMetadata.metadata)\n+            .getOrElse(throw new IllegalStateException(\"The group is non-empty so the current protocol must be defined\")))\n+          .setAssignment(assignment.getOrElse(memberMetadata.memberId,\n+            throw new IllegalStateException(s\"member: ${memberMetadata.memberId} has no assignment\")))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDI5ODI1OQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500298259", "bodyText": "nit: memberMetadataObj => memberMetadata?", "author": "dajac", "createdAt": "2020-10-06T13:52:42Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1401,49 +1137,36 @@ object GroupMetadataManager {\n    * @return a group metadata object from the message\n    */\n   def readGroupMessageValue(groupId: String, buffer: ByteBuffer, time: Time): GroupMetadata = {\n-    if (buffer == null) { // tombstone\n-      null\n-    } else {\n+    // tombstone\n+    if (buffer == null) null\n+    else {\n       val version = buffer.getShort\n-      val valueSchema = schemaForGroupValue(version)\n-      val value = valueSchema.read(buffer)\n-\n-      if (version >= 0 && version <= CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION) {\n-        val generationId = value.get(GENERATION_KEY).asInstanceOf[Int]\n-        val protocolType = value.get(PROTOCOL_TYPE_KEY).asInstanceOf[String]\n-        val protocol = value.get(PROTOCOL_KEY).asInstanceOf[String]\n-        val leaderId = value.get(LEADER_KEY).asInstanceOf[String]\n-        val memberMetadataArray = value.getArray(MEMBERS_KEY)\n-        val initialState = if (memberMetadataArray.isEmpty) Empty else Stable\n-        val currentStateTimestamp: Option[Long] =\n-          if (version >= 2 && value.hasField(CURRENT_STATE_TIMESTAMP_KEY)) {\n-            val timestamp = value.getLong(CURRENT_STATE_TIMESTAMP_KEY)\n-            if (timestamp == -1) None else Some(timestamp)\n-          } else None\n-\n-        val members = memberMetadataArray.map { memberMetadataObj =>\n-          val memberMetadata = memberMetadataObj.asInstanceOf[Struct]\n-          val memberId = memberMetadata.get(MEMBER_ID_KEY).asInstanceOf[String]\n-          val groupInstanceId =\n-            if (version >= 3)\n-              Some(memberMetadata.get(GROUP_INSTANCE_ID_KEY).asInstanceOf[String])\n-            else\n-              None\n-          val clientId = memberMetadata.get(CLIENT_ID_KEY).asInstanceOf[String]\n-          val clientHost = memberMetadata.get(CLIENT_HOST_KEY).asInstanceOf[String]\n-          val sessionTimeout = memberMetadata.get(SESSION_TIMEOUT_KEY).asInstanceOf[Int]\n-          val rebalanceTimeout = if (version == 0) sessionTimeout else memberMetadata.get(REBALANCE_TIMEOUT_KEY).asInstanceOf[Int]\n-          val subscription = Utils.toArray(memberMetadata.get(SUBSCRIPTION_KEY).asInstanceOf[ByteBuffer])\n-\n-          val member = new MemberMetadata(memberId, groupId, groupInstanceId, clientId, clientHost, rebalanceTimeout, sessionTimeout,\n-            protocolType, List((protocol, subscription)))\n-          member.assignment = Utils.toArray(memberMetadata.get(ASSIGNMENT_KEY).asInstanceOf[ByteBuffer])\n-          member\n+      if (version >= GroupMetadataValue.LOWEST_SUPPORTED_VERSION && version <= GroupMetadataValue.HIGHEST_SUPPORTED_VERSION) {\n+        val value = new GroupMetadataValue(new ByteBufferAccessor(buffer), version)\n+        val members = value.members.asScala.map { memberMetadataObj =>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDMwNzA0Mw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500307043", "bodyText": "nit: In all the other usage of serializeMessage, you have always put the closing parenthesis on the previous line, together with the other closing parenthesises. I would do the same here to remain consistent.", "author": "dajac", "createdAt": "2020-10-06T14:01:44Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1210,38 +1032,18 @@ object GroupMetadataManager {\n    */\n   def offsetCommitValue(offsetAndMetadata: OffsetAndMetadata,\n                         apiVersion: ApiVersion): Array[Byte] = {\n-    // generate commit value according to schema version\n-    val (version, value) = {\n-      if (apiVersion < KAFKA_2_1_IV0 || offsetAndMetadata.expireTimestamp.nonEmpty) {\n-        val value = new Struct(OFFSET_COMMIT_VALUE_SCHEMA_V1)\n-        value.set(OFFSET_VALUE_OFFSET_FIELD_V1, offsetAndMetadata.offset)\n-        value.set(OFFSET_VALUE_METADATA_FIELD_V1, offsetAndMetadata.metadata)\n-        value.set(OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V1, offsetAndMetadata.commitTimestamp)\n-        // version 1 has a non empty expireTimestamp field\n-        value.set(OFFSET_VALUE_EXPIRE_TIMESTAMP_FIELD_V1,\n-          offsetAndMetadata.expireTimestamp.getOrElse(OffsetCommitRequest.DEFAULT_TIMESTAMP))\n-        (1, value)\n-      } else if (apiVersion < KAFKA_2_1_IV1) {\n-        val value = new Struct(OFFSET_COMMIT_VALUE_SCHEMA_V2)\n-        value.set(OFFSET_VALUE_OFFSET_FIELD_V2, offsetAndMetadata.offset)\n-        value.set(OFFSET_VALUE_METADATA_FIELD_V2, offsetAndMetadata.metadata)\n-        value.set(OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V2, offsetAndMetadata.commitTimestamp)\n-        (2, value)\n-      } else {\n-        val value = new Struct(OFFSET_COMMIT_VALUE_SCHEMA_V3)\n-        value.set(OFFSET_VALUE_OFFSET_FIELD_V3, offsetAndMetadata.offset)\n-        value.set(OFFSET_VALUE_LEADER_EPOCH_FIELD_V3,\n-          offsetAndMetadata.leaderEpoch.orElse(RecordBatch.NO_PARTITION_LEADER_EPOCH))\n-        value.set(OFFSET_VALUE_METADATA_FIELD_V3, offsetAndMetadata.metadata)\n-        value.set(OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3, offsetAndMetadata.commitTimestamp)\n-        (3, value)\n-      }\n-    }\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(version.toShort)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+    val version =\n+      if (apiVersion < KAFKA_2_1_IV0 || offsetAndMetadata.expireTimestamp.nonEmpty) 1.toShort\n+      else if (apiVersion < KAFKA_2_1_IV1) 2.toShort\n+      else 3.toShort\n+    serializeMessage(version, new OffsetCommitValue()\n+      .setOffset(offsetAndMetadata.offset)\n+      .setMetadata(offsetAndMetadata.metadata)\n+      .setCommitTimestamp(offsetAndMetadata.commitTimestamp)\n+      .setLeaderEpoch(offsetAndMetadata.leaderEpoch.orElse(RecordBatch.NO_PARTITION_LEADER_EPOCH))\n+      // version 1 has a non empty expireTimestamp field\n+      .setExpireTimestamp(offsetAndMetadata.expireTimestamp.getOrElse(OffsetCommitRequest.DEFAULT_TIMESTAMP))\n+    )", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDMxMjczOA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500312738", "bodyText": "small nit: For the requests/responses, we have added Data as a suffix to avoid collisions with internal classes. Perhaps, we could use GroupMetadataKeyData instead of GenGroupMetadataKey here.", "author": "dajac", "createdAt": "2020-10-06T14:07:41Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -28,6 +28,7 @@ import java.util.concurrent.locks.ReentrantLock\n import com.yammer.metrics.core.Gauge\n import kafka.api.{ApiVersion, KAFKA_0_10_1_IV0, KAFKA_2_1_IV0, KAFKA_2_1_IV1, KAFKA_2_3_IV0}\n import kafka.common.OffsetAndMetadata\n+import kafka.internals.generated.{GroupMetadataKey => GenGroupMetadataKey, GroupMetadataValue, OffsetCommitKey, OffsetCommitValue}", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDM0NTk4OA==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500345988", "bodyText": "Calling array may not be safe all the time. It works here because the ByteBuffer allocated by MessageUtil.serializeMessage has a backing array. Should we use Utils.toArray to be safe? What do you think?", "author": "dajac", "createdAt": "2020-10-06T14:41:43Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -997,174 +996,7 @@ object GroupMetadataManager {\n   val MetricsGroup: String = \"group-coordinator-metrics\"\n   val LoadTimeSensor: String = \"GroupPartitionLoadTime\"\n \n-  private val CURRENT_OFFSET_KEY_SCHEMA_VERSION = 1.toShort\n-  private val CURRENT_GROUP_KEY_SCHEMA_VERSION = 2.toShort\n-\n-  private val OFFSET_COMMIT_KEY_SCHEMA = new Schema(new Field(\"group\", STRING),\n-    new Field(\"topic\", STRING),\n-    new Field(\"partition\", INT32))\n-  private val OFFSET_KEY_GROUP_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"group\")\n-  private val OFFSET_KEY_TOPIC_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"topic\")\n-  private val OFFSET_KEY_PARTITION_FIELD = OFFSET_COMMIT_KEY_SCHEMA.get(\"partition\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V0 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"metadata\")\n-  private val OFFSET_VALUE_TIMESTAMP_FIELD_V0 = OFFSET_COMMIT_VALUE_SCHEMA_V0.get(\"timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V1 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64),\n-    new Field(\"expire_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"commit_timestamp\")\n-  private val OFFSET_VALUE_EXPIRE_TIMESTAMP_FIELD_V1 = OFFSET_COMMIT_VALUE_SCHEMA_V1.get(\"expire_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V2 = new Schema(new Field(\"offset\", INT64),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"offset\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V2 = OFFSET_COMMIT_VALUE_SCHEMA_V2.get(\"commit_timestamp\")\n-\n-  private val OFFSET_COMMIT_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(\"offset\", INT64),\n-    new Field(\"leader_epoch\", INT32),\n-    new Field(\"metadata\", STRING, \"Associated metadata.\", \"\"),\n-    new Field(\"commit_timestamp\", INT64))\n-  private val OFFSET_VALUE_OFFSET_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"offset\")\n-  private val OFFSET_VALUE_LEADER_EPOCH_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"leader_epoch\")\n-  private val OFFSET_VALUE_METADATA_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"metadata\")\n-  private val OFFSET_VALUE_COMMIT_TIMESTAMP_FIELD_V3 = OFFSET_COMMIT_VALUE_SCHEMA_V3.get(\"commit_timestamp\")\n-\n-  private val GROUP_METADATA_KEY_SCHEMA = new Schema(new Field(\"group\", STRING))\n-  private val GROUP_KEY_GROUP_FIELD = GROUP_METADATA_KEY_SCHEMA.get(\"group\")\n-\n-  private val MEMBER_ID_KEY = \"member_id\"\n-  private val GROUP_INSTANCE_ID_KEY = \"group_instance_id\"\n-  private val CLIENT_ID_KEY = \"client_id\"\n-  private val CLIENT_HOST_KEY = \"client_host\"\n-  private val REBALANCE_TIMEOUT_KEY = \"rebalance_timeout\"\n-  private val SESSION_TIMEOUT_KEY = \"session_timeout\"\n-  private val SUBSCRIPTION_KEY = \"subscription\"\n-  private val ASSIGNMENT_KEY = \"assignment\"\n-\n-  private val MEMBER_METADATA_V0 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V1 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val MEMBER_METADATA_V2 = MEMBER_METADATA_V1\n-\n-  private val MEMBER_METADATA_V3 = new Schema(\n-    new Field(MEMBER_ID_KEY, STRING),\n-    new Field(GROUP_INSTANCE_ID_KEY, NULLABLE_STRING),\n-    new Field(CLIENT_ID_KEY, STRING),\n-    new Field(CLIENT_HOST_KEY, STRING),\n-    new Field(REBALANCE_TIMEOUT_KEY, INT32),\n-    new Field(SESSION_TIMEOUT_KEY, INT32),\n-    new Field(SUBSCRIPTION_KEY, BYTES),\n-    new Field(ASSIGNMENT_KEY, BYTES))\n-\n-  private val PROTOCOL_TYPE_KEY = \"protocol_type\"\n-  private val GENERATION_KEY = \"generation\"\n-  private val PROTOCOL_KEY = \"protocol\"\n-  private val LEADER_KEY = \"leader\"\n-  private val CURRENT_STATE_TIMESTAMP_KEY = \"current_state_timestamp\"\n-  private val MEMBERS_KEY = \"members\"\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V0 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V0)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V1 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V1)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V2 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V2)))\n-\n-  private val GROUP_METADATA_VALUE_SCHEMA_V3 = new Schema(\n-    new Field(PROTOCOL_TYPE_KEY, STRING),\n-    new Field(GENERATION_KEY, INT32),\n-    new Field(PROTOCOL_KEY, NULLABLE_STRING),\n-    new Field(LEADER_KEY, NULLABLE_STRING),\n-    new Field(CURRENT_STATE_TIMESTAMP_KEY, INT64),\n-    new Field(MEMBERS_KEY, new ArrayOf(MEMBER_METADATA_V3)))\n-\n-  // map of versions to key schemas as data types\n-  private val MESSAGE_TYPE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    1 -> OFFSET_COMMIT_KEY_SCHEMA,\n-    2 -> GROUP_METADATA_KEY_SCHEMA)\n-\n-  // map of version of offset value schemas\n-  private val OFFSET_VALUE_SCHEMAS = Map(\n-    0 -> OFFSET_COMMIT_VALUE_SCHEMA_V0,\n-    1 -> OFFSET_COMMIT_VALUE_SCHEMA_V1,\n-    2 -> OFFSET_COMMIT_VALUE_SCHEMA_V2,\n-    3 -> OFFSET_COMMIT_VALUE_SCHEMA_V3)\n-\n-  // map of version of group metadata value schemas\n-  private val GROUP_VALUE_SCHEMAS = Map(\n-    0 -> GROUP_METADATA_VALUE_SCHEMA_V0,\n-    1 -> GROUP_METADATA_VALUE_SCHEMA_V1,\n-    2 -> GROUP_METADATA_VALUE_SCHEMA_V2,\n-    3 -> GROUP_METADATA_VALUE_SCHEMA_V3)\n-\n-  private val CURRENT_OFFSET_KEY_SCHEMA = schemaForKey(CURRENT_OFFSET_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_KEY_SCHEMA = schemaForKey(CURRENT_GROUP_KEY_SCHEMA_VERSION)\n-  private val CURRENT_GROUP_METADATA_VALUE_SCHEMA_VERSION = GROUP_VALUE_SCHEMAS.keySet.max\n-\n-  private def schemaForKey(version: Int) = {\n-    val schemaOpt = MESSAGE_TYPE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown message key schema version \" + version)\n-    }\n-  }\n-\n-  private def schemaForOffsetValue(version: Int) = {\n-    val schemaOpt = OFFSET_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown offset schema version \" + version)\n-    }\n-  }\n-\n-  private def schemaForGroupValue(version: Int) = {\n-    val schemaOpt = GROUP_VALUE_SCHEMAS.get(version)\n-    schemaOpt match {\n-      case Some(schema) => schema\n-      case _ => throw new KafkaException(\"Unknown group metadata version \" + version)\n-    }\n-  }\n+  private def serializeMessage(version: Short, message: Message): Array[Byte] = MessageUtil.serializeMessage(version, message).array", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDM2MTQ4Nw==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500361487", "bodyText": "We can do deep copy if the returned ByteBuffer is NOT backed by an accessible byte array. Otherwise, we take the byte array directly.", "author": "chia7712", "createdAt": "2020-10-06T14:57:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDM0NTk4OA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDU0NDU4Mg==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500544582", "bodyText": "nit: Not related to your changes but could fix this comment? refers to offset => refers to group metadata?", "author": "dajac", "createdAt": "2020-10-06T19:29:17Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1321,25 +1106,15 @@ object GroupMetadataManager {\n    */\n   def readMessageKey(buffer: ByteBuffer): BaseKey = {\n     val version = buffer.getShort\n-    val keySchema = schemaForKey(version)\n-    val key = keySchema.read(buffer)\n-\n-    if (version <= CURRENT_OFFSET_KEY_SCHEMA_VERSION) {\n+    if (version >= OffsetCommitKey.LOWEST_SUPPORTED_VERSION && version <= OffsetCommitKey.HIGHEST_SUPPORTED_VERSION) {\n       // version 0 and 1 refer to offset\n-      val group = key.get(OFFSET_KEY_GROUP_FIELD).asInstanceOf[String]\n-      val topic = key.get(OFFSET_KEY_TOPIC_FIELD).asInstanceOf[String]\n-      val partition = key.get(OFFSET_KEY_PARTITION_FIELD).asInstanceOf[Int]\n-\n-      OffsetKey(version, GroupTopicPartition(group, new TopicPartition(topic, partition)))\n-\n-    } else if (version == CURRENT_GROUP_KEY_SCHEMA_VERSION) {\n+      val key = new OffsetCommitKey(new ByteBufferAccessor(buffer), version)\n+      OffsetKey(version, GroupTopicPartition(key.group, new TopicPartition(key.topic, key.partition)))\n+    } else if (version >= GroupMetadataKeyData.LOWEST_SUPPORTED_VERSION && version <= GroupMetadataKeyData.HIGHEST_SUPPORTED_VERSION) {\n       // version 2 refers to offset", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDU0ODk3NQ==", "url": "https://github.com/apache/kafka/pull/9318#discussion_r500548975", "bodyText": "The message sounds a bit weird to me cause it is the group which does not have a defined protocol, not the member. I would just keep the previous message here and also add a . as you put one in the other message.", "author": "dajac", "createdAt": "2020-10-06T19:37:36Z", "path": "core/src/main/scala/kafka/coordinator/group/GroupMetadataManager.scala", "diffHunk": "@@ -1257,60 +1070,32 @@ object GroupMetadataManager {\n                          assignment: Map[String, Array[Byte]],\n                          apiVersion: ApiVersion): Array[Byte] = {\n \n-    val (version, value) = {\n-      if (apiVersion < KAFKA_0_10_1_IV0)\n-        (0.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V0))\n-      else if (apiVersion < KAFKA_2_1_IV0)\n-        (1.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V1))\n-      else if (apiVersion < KAFKA_2_3_IV0)\n-        (2.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V2))\n-      else\n-        (3.toShort, new Struct(GROUP_METADATA_VALUE_SCHEMA_V3))\n-    }\n-\n-    value.set(PROTOCOL_TYPE_KEY, groupMetadata.protocolType.getOrElse(\"\"))\n-    value.set(GENERATION_KEY, groupMetadata.generationId)\n-    value.set(PROTOCOL_KEY, groupMetadata.protocolName.orNull)\n-    value.set(LEADER_KEY, groupMetadata.leaderOrNull)\n-\n-    if (version >= 2)\n-      value.set(CURRENT_STATE_TIMESTAMP_KEY, groupMetadata.currentStateTimestampOrDefault)\n-\n-    val memberArray = groupMetadata.allMemberMetadata.map { memberMetadata =>\n-      val memberStruct = value.instance(MEMBERS_KEY)\n-      memberStruct.set(MEMBER_ID_KEY, memberMetadata.memberId)\n-      memberStruct.set(CLIENT_ID_KEY, memberMetadata.clientId)\n-      memberStruct.set(CLIENT_HOST_KEY, memberMetadata.clientHost)\n-      memberStruct.set(SESSION_TIMEOUT_KEY, memberMetadata.sessionTimeoutMs)\n-\n-      if (version > 0)\n-        memberStruct.set(REBALANCE_TIMEOUT_KEY, memberMetadata.rebalanceTimeoutMs)\n-\n-      if (version >= 3)\n-        memberStruct.set(GROUP_INSTANCE_ID_KEY, memberMetadata.groupInstanceId.orNull)\n-\n-      // The group is non-empty, so the current protocol must be defined\n-      val protocol = groupMetadata.protocolName.orNull\n-      if (protocol == null)\n-        throw new IllegalStateException(\"Attempted to write non-empty group metadata with no defined protocol\")\n-\n-      val metadata = memberMetadata.metadata(protocol)\n-      memberStruct.set(SUBSCRIPTION_KEY, ByteBuffer.wrap(metadata))\n-\n-      val memberAssignment = assignment(memberMetadata.memberId)\n-      assert(memberAssignment != null)\n-\n-      memberStruct.set(ASSIGNMENT_KEY, ByteBuffer.wrap(memberAssignment))\n-\n-      memberStruct\n-    }\n-\n-    value.set(MEMBERS_KEY, memberArray.toArray)\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(version)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+    val version =\n+      if (apiVersion < KAFKA_0_10_1_IV0) 0.toShort\n+      else if (apiVersion < KAFKA_2_1_IV0) 1.toShort\n+      else if (apiVersion < KAFKA_2_3_IV0) 2.toShort\n+      else 3.toShort\n+\n+    serializeMessage(version, new GroupMetadataValue()\n+      .setProtocolType(groupMetadata.protocolType.getOrElse(\"\"))\n+      .setGeneration(groupMetadata.generationId)\n+      .setProtocol(groupMetadata.protocolName.orNull)\n+      .setLeader(groupMetadata.leaderOrNull)\n+      .setCurrentStateTimestamp(groupMetadata.currentStateTimestampOrDefault)\n+      .setMembers(groupMetadata.allMemberMetadata.map { memberMetadata =>\n+        new GroupMetadataValue.MemberMetadata()\n+          .setMemberId(memberMetadata.memberId)\n+          .setClientId(memberMetadata.clientId)\n+          .setClientHost(memberMetadata.clientHost)\n+          .setSessionTimeout(memberMetadata.sessionTimeoutMs)\n+          .setRebalanceTimeout(memberMetadata.rebalanceTimeoutMs)\n+          .setGroupInstanceId(memberMetadata.groupInstanceId.orNull)\n+          // The group is non-empty, so the current protocol must be defined\n+          .setSubscription(groupMetadata.protocolName.map(memberMetadata.metadata)\n+            .getOrElse(throw new IllegalStateException(s\"Attempted to write member ${memberMetadata.memberId} of group ${groupMetadata.groupId} with no defined protocol\")))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "18588a249cae97c6e4bdf2b3dd21eb5cb034293f", "url": "https://github.com/apache/kafka/commit/18588a249cae97c6e4bdf2b3dd21eb5cb034293f", "message": "KAFKA-10497 Convert group coordinator metadata schemas to use generated protocol", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "868680323405133fbea8801982975971283946f8", "url": "https://github.com/apache/kafka/commit/868680323405133fbea8801982975971283946f8", "message": "KAFKA-10497-1 directly serialize message", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "88ca0ae21ee9171073766b2172d1d72cc7421500", "url": "https://github.com/apache/kafka/commit/88ca0ae21ee9171073766b2172d1d72cc7421500", "message": "KAFKA-10497-1 apply request/response pattern", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "3cc85028e0e8e3a0536233eb7c301ccde2d4fa12", "url": "https://github.com/apache/kafka/commit/3cc85028e0e8e3a0536233eb7c301ccde2d4fa12", "message": "Revert \"KAFKA-10497-1 apply request/response pattern\"\n\nThis reverts commit fd0ecc51b5de999e8e5451010f549e4bf2ca7028.", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "48ecb8b38409f5f553d91ca5cb76da98edc1b6c2", "url": "https://github.com/apache/kafka/commit/48ecb8b38409f5f553d91ca5cb76da98edc1b6c2", "message": "correct the serialization order; reuse code; remove parenthesis", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "3daf979078e6d1a01ef4443617e732c9b5767f6d", "url": "https://github.com/apache/kafka/commit/3daf979078e6d1a01ef4443617e732c9b5767f6d", "message": "add GroupMetadataKey back", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "18d143e59572ec519c4be4ce4923ed4c8ffdc39b", "url": "https://github.com/apache/kafka/commit/18d143e59572ec519c4be4ce4923ed4c8ffdc39b", "message": "fix version of OffsetCommitKey; remove unnecessary constants; adjust code style", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "1554586da33963e5d8c2b7eea69eb1814d2af20f", "url": "https://github.com/apache/kafka/commit/1554586da33963e5d8c2b7eea69eb1814d2af20f", "message": "using ignorable to replace version checking", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "f6ab6075778b12c69d2e7cfbaf989cad6029bae2", "url": "https://github.com/apache/kafka/commit/f6ab6075778b12c69d2e7cfbaf989cad6029bae2", "message": "remove useless comment", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "3c7413f07caa3aca908c695fa777320176fe835e", "url": "https://github.com/apache/kafka/commit/3c7413f07caa3aca908c695fa777320176fe835e", "message": "format code; copy buffer if necessary", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "df39a8fa229dd99de623b96d8aae154a1735d8ae", "url": "https://github.com/apache/kafka/commit/df39a8fa229dd99de623b96d8aae154a1735d8ae", "message": "tweak comment", "committedDate": "2020-11-18T03:05:41Z", "type": "commit"}, {"oid": "df39a8fa229dd99de623b96d8aae154a1735d8ae", "url": "https://github.com/apache/kafka/commit/df39a8fa229dd99de623b96d8aae154a1735d8ae", "message": "tweak comment", "committedDate": "2020-11-18T03:05:41Z", "type": "forcePushed"}]}