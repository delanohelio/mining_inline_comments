{"pr_number": 9611, "pr_title": "KAFKA-10736 Convert transaction coordinator metadata schemas to use g\u2026", "pr_createdAt": "2020-11-18T10:03:55Z", "pr_url": "https://github.com/apache/kafka/pull/9611", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEwOTA3Mw==", "url": "https://github.com/apache/kafka/pull/9611#discussion_r531109073", "bodyText": "nit: We usually capitalize the first letter. We should do it in both schemas.", "author": "dajac", "createdAt": "2020-11-26T15:40:39Z", "path": "core/src/main/resources/common/message/TransactionLogKey.json", "diffHunk": "@@ -0,0 +1,23 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+{\n+  \"type\": \"data\",\n+  \"name\": \"TransactionLogKey\",\n+  \"validVersions\": \"0\",\n+  \"fields\": [\n+    { \"name\": \"transactionalId\", \"type\": \"string\", \"versions\": \"0\"}", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTExMjc0MA==", "url": "https://github.com/apache/kafka/pull/9611#discussion_r531112740", "bodyText": "nit: We usually have a space after case.", "author": "dajac", "createdAt": "2020-11-26T15:47:20Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionLog.scala", "diffHunk": "@@ -146,38 +70,27 @@ object TransactionLog {\n     * @return value payload bytes\n     */\n   private[transaction] def valueToBytes(txnMetadata: TxnTransitMetadata): Array[Byte] = {\n-    import ValueSchema._\n-    val value = new Struct(Current)\n-    value.set(ProducerIdField, txnMetadata.producerId)\n-    value.set(ProducerEpochField, txnMetadata.producerEpoch)\n-    value.set(TxnTimeoutField, txnMetadata.txnTimeoutMs)\n-    value.set(TxnStatusField, txnMetadata.txnState.byte)\n-    value.set(TxnEntryTimestampField, txnMetadata.txnLastUpdateTimestamp)\n-    value.set(TxnStartTimestampField, txnMetadata.txnStartTimestamp)\n-\n-    if (txnMetadata.txnState == Empty) {\n-      if (txnMetadata.topicPartitions.nonEmpty)\n+    if (txnMetadata.txnState == Empty && txnMetadata.topicPartitions.nonEmpty)\n         throw new IllegalStateException(s\"Transaction is not expected to have any partitions since its state is ${txnMetadata.txnState}: $txnMetadata\")\n \n-      value.set(TxnPartitionsField, null)\n-    } else {\n-      // first group the topic partitions by their topic names\n-      val topicAndPartitions = txnMetadata.topicPartitions.groupBy(_.topic())\n-\n-      val partitionArray = topicAndPartitions.map { case(topic, partitions) =>\n-        val topicPartitionsStruct = value.instance(TxnPartitionsField)\n-        val partitionIds: Array[Integer] = partitions.map(topicPartition => Integer.valueOf(topicPartition.partition())).toArray\n-        topicPartitionsStruct.set(PartitionsTopicField, topic)\n-        topicPartitionsStruct.set(PartitionIdsField, partitionIds)\n-        topicPartitionsStruct\n-      }\n-      value.set(TxnPartitionsField, partitionArray.toArray)\n-    }\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(CurrentVersion)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+      val transactionPartition = if (txnMetadata.txnState == Empty) null\n+      else txnMetadata.topicPartitions\n+        .groupBy(_.topic())\n+        .map { case(topic, partitions) =>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTExMzQxOQ==", "url": "https://github.com/apache/kafka/pull/9611#discussion_r531113419", "bodyText": "nit: Parentheses are not required when accessing an accessor. We could remove them here and in few other places in this file.", "author": "dajac", "createdAt": "2020-11-26T15:48:33Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionLog.scala", "diffHunk": "@@ -146,38 +70,27 @@ object TransactionLog {\n     * @return value payload bytes\n     */\n   private[transaction] def valueToBytes(txnMetadata: TxnTransitMetadata): Array[Byte] = {\n-    import ValueSchema._\n-    val value = new Struct(Current)\n-    value.set(ProducerIdField, txnMetadata.producerId)\n-    value.set(ProducerEpochField, txnMetadata.producerEpoch)\n-    value.set(TxnTimeoutField, txnMetadata.txnTimeoutMs)\n-    value.set(TxnStatusField, txnMetadata.txnState.byte)\n-    value.set(TxnEntryTimestampField, txnMetadata.txnLastUpdateTimestamp)\n-    value.set(TxnStartTimestampField, txnMetadata.txnStartTimestamp)\n-\n-    if (txnMetadata.txnState == Empty) {\n-      if (txnMetadata.topicPartitions.nonEmpty)\n+    if (txnMetadata.txnState == Empty && txnMetadata.topicPartitions.nonEmpty)\n         throw new IllegalStateException(s\"Transaction is not expected to have any partitions since its state is ${txnMetadata.txnState}: $txnMetadata\")\n \n-      value.set(TxnPartitionsField, null)\n-    } else {\n-      // first group the topic partitions by their topic names\n-      val topicAndPartitions = txnMetadata.topicPartitions.groupBy(_.topic())\n-\n-      val partitionArray = topicAndPartitions.map { case(topic, partitions) =>\n-        val topicPartitionsStruct = value.instance(TxnPartitionsField)\n-        val partitionIds: Array[Integer] = partitions.map(topicPartition => Integer.valueOf(topicPartition.partition())).toArray\n-        topicPartitionsStruct.set(PartitionsTopicField, topic)\n-        topicPartitionsStruct.set(PartitionIdsField, partitionIds)\n-        topicPartitionsStruct\n-      }\n-      value.set(TxnPartitionsField, partitionArray.toArray)\n-    }\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(CurrentVersion)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+      val transactionPartition = if (txnMetadata.txnState == Empty) null\n+      else txnMetadata.topicPartitions\n+        .groupBy(_.topic())", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTExNTk4NQ==", "url": "https://github.com/apache/kafka/pull/9611#discussion_r531115985", "bodyText": "nit: It may be better to combine map(_.partition()).map(Integer.valueOf) in one map to avoid intermediate collection.", "author": "dajac", "createdAt": "2020-11-26T15:52:57Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionLog.scala", "diffHunk": "@@ -146,38 +70,27 @@ object TransactionLog {\n     * @return value payload bytes\n     */\n   private[transaction] def valueToBytes(txnMetadata: TxnTransitMetadata): Array[Byte] = {\n-    import ValueSchema._\n-    val value = new Struct(Current)\n-    value.set(ProducerIdField, txnMetadata.producerId)\n-    value.set(ProducerEpochField, txnMetadata.producerEpoch)\n-    value.set(TxnTimeoutField, txnMetadata.txnTimeoutMs)\n-    value.set(TxnStatusField, txnMetadata.txnState.byte)\n-    value.set(TxnEntryTimestampField, txnMetadata.txnLastUpdateTimestamp)\n-    value.set(TxnStartTimestampField, txnMetadata.txnStartTimestamp)\n-\n-    if (txnMetadata.txnState == Empty) {\n-      if (txnMetadata.topicPartitions.nonEmpty)\n+    if (txnMetadata.txnState == Empty && txnMetadata.topicPartitions.nonEmpty)\n         throw new IllegalStateException(s\"Transaction is not expected to have any partitions since its state is ${txnMetadata.txnState}: $txnMetadata\")\n \n-      value.set(TxnPartitionsField, null)\n-    } else {\n-      // first group the topic partitions by their topic names\n-      val topicAndPartitions = txnMetadata.topicPartitions.groupBy(_.topic())\n-\n-      val partitionArray = topicAndPartitions.map { case(topic, partitions) =>\n-        val topicPartitionsStruct = value.instance(TxnPartitionsField)\n-        val partitionIds: Array[Integer] = partitions.map(topicPartition => Integer.valueOf(topicPartition.partition())).toArray\n-        topicPartitionsStruct.set(PartitionsTopicField, topic)\n-        topicPartitionsStruct.set(PartitionIdsField, partitionIds)\n-        topicPartitionsStruct\n-      }\n-      value.set(TxnPartitionsField, partitionArray.toArray)\n-    }\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(CurrentVersion)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+      val transactionPartition = if (txnMetadata.txnState == Empty) null\n+      else txnMetadata.topicPartitions\n+        .groupBy(_.topic())\n+        .map { case(topic, partitions) =>\n+          new TransactionLogValue.PartitionsSchema()\n+            .setTopic(topic)\n+            .setPartitionIds(partitions.map(_.partition()).map(Integer.valueOf).toList.asJava)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTExNzAxNQ==", "url": "https://github.com/apache/kafka/pull/9611#discussion_r531117015", "bodyText": "nit: transactionPartition -> transactionPartitions?", "author": "dajac", "createdAt": "2020-11-26T15:54:46Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionLog.scala", "diffHunk": "@@ -146,38 +70,27 @@ object TransactionLog {\n     * @return value payload bytes\n     */\n   private[transaction] def valueToBytes(txnMetadata: TxnTransitMetadata): Array[Byte] = {\n-    import ValueSchema._\n-    val value = new Struct(Current)\n-    value.set(ProducerIdField, txnMetadata.producerId)\n-    value.set(ProducerEpochField, txnMetadata.producerEpoch)\n-    value.set(TxnTimeoutField, txnMetadata.txnTimeoutMs)\n-    value.set(TxnStatusField, txnMetadata.txnState.byte)\n-    value.set(TxnEntryTimestampField, txnMetadata.txnLastUpdateTimestamp)\n-    value.set(TxnStartTimestampField, txnMetadata.txnStartTimestamp)\n-\n-    if (txnMetadata.txnState == Empty) {\n-      if (txnMetadata.topicPartitions.nonEmpty)\n+    if (txnMetadata.txnState == Empty && txnMetadata.topicPartitions.nonEmpty)\n         throw new IllegalStateException(s\"Transaction is not expected to have any partitions since its state is ${txnMetadata.txnState}: $txnMetadata\")\n \n-      value.set(TxnPartitionsField, null)\n-    } else {\n-      // first group the topic partitions by their topic names\n-      val topicAndPartitions = txnMetadata.topicPartitions.groupBy(_.topic())\n-\n-      val partitionArray = topicAndPartitions.map { case(topic, partitions) =>\n-        val topicPartitionsStruct = value.instance(TxnPartitionsField)\n-        val partitionIds: Array[Integer] = partitions.map(topicPartition => Integer.valueOf(topicPartition.partition())).toArray\n-        topicPartitionsStruct.set(PartitionsTopicField, topic)\n-        topicPartitionsStruct.set(PartitionIdsField, partitionIds)\n-        topicPartitionsStruct\n-      }\n-      value.set(TxnPartitionsField, partitionArray.toArray)\n-    }\n-\n-    val byteBuffer = ByteBuffer.allocate(2 /* version */ + value.sizeOf)\n-    byteBuffer.putShort(CurrentVersion)\n-    value.writeTo(byteBuffer)\n-    byteBuffer.array()\n+      val transactionPartition = if (txnMetadata.txnState == Empty) null\n+      else txnMetadata.topicPartitions\n+        .groupBy(_.topic())\n+        .map { case(topic, partitions) =>\n+          new TransactionLogValue.PartitionsSchema()\n+            .setTopic(topic)\n+            .setPartitionIds(partitions.map(_.partition()).map(Integer.valueOf).toList.asJava)\n+        }.toList.asJava\n+\n+    MessageUtil.toBytes(TransactionLogValue.HIGHEST_SUPPORTED_VERSION,\n+      new TransactionLogValue()\n+        .setProducerId(txnMetadata.producerId)\n+        .setProducerEpoch(txnMetadata.producerEpoch)\n+        .setTransactionTimeoutMs(txnMetadata.txnTimeoutMs)\n+        .setTransactionStatus(txnMetadata.txnState.byte)\n+        .setTransactionLastUpdateTimestampMs(txnMetadata.txnLastUpdateTimestamp)\n+        .setTransactionStartTimestampMs(txnMetadata.txnStartTimestamp)\n+        .setTransactionPartitions(transactionPartition))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "40fd8980aee5737e465781b25e21ece9ec16a215", "url": "https://github.com/apache/kafka/commit/40fd8980aee5737e465781b25e21ece9ec16a215", "message": "KAFKA-10736 Convert transaction coordinator metadata schemas to use generated protocol", "committedDate": "2020-11-26T16:34:15Z", "type": "commit"}, {"oid": "52b0dd17380529cef1d8277614707acf5dad42f7", "url": "https://github.com/apache/kafka/commit/52b0dd17380529cef1d8277614707acf5dad42f7", "message": "review comments", "committedDate": "2020-11-26T16:39:52Z", "type": "commit"}, {"oid": "52b0dd17380529cef1d8277614707acf5dad42f7", "url": "https://github.com/apache/kafka/commit/52b0dd17380529cef1d8277614707acf5dad42f7", "message": "review comments", "committedDate": "2020-11-26T16:39:52Z", "type": "forcePushed"}]}