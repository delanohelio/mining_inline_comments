{"pr_number": 7926, "pr_title": "MINOR: Improve AuthorizerIntegrationTest", "pr_createdAt": "2020-01-10T00:24:49Z", "pr_url": "https://github.com/apache/kafka/pull/7926", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4Njg1OQ==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370386859", "bodyText": "Probably a good idea to mention the motivation for this in the PR description.", "author": "ijuma", "createdAt": "2020-01-23T22:23:09Z", "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1113,8 +1113,8 @@ class KafkaController(val config: KafkaConfig,\n     // so we will keep the previous behavior and don't reject the request\n     if (brokerEpoch != AbstractControlRequest.UNKNOWN_BROKER_EPOCH) {\n       val cachedBrokerEpoch = controllerContext.liveBrokerIdAndEpochs(id)\n-      if (brokerEpoch < cachedBrokerEpoch) {\n-        val stateBrokerEpochErrorMessage = \"Received controlled shutdown request from an old broker epoch \" +\n+      if (brokerEpoch != cachedBrokerEpoch) {\n+        val stateBrokerEpochErrorMessage = \"Received controlled shutdown request from an invalid broker epoch \" +", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4MzE1Mg==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r375983152", "bodyText": "I may revert this change. Just need to remember why I added it...", "author": "hachikuji", "createdAt": "2020-02-06T17:41:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4Njg1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4NzI0Mg==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370387242", "bodyText": "Why do we have to pass this?", "author": "ijuma", "createdAt": "2020-01-23T22:24:12Z", "path": "core/src/test/scala/unit/kafka/utils/TestUtils.scala", "diffHunk": "@@ -1192,21 +1199,26 @@ object TestUtils extends Logging {\n     trustManager\n   }\n \n-  def waitAndVerifyAcls(expected: Set[AccessControlEntry], authorizer: JAuthorizer, resource: ResourcePattern) = {\n+  def waitAndVerifyAcls(expected: Set[AccessControlEntry],\n+                        authorizer: JAuthorizer,\n+                        resource: ResourcePattern,\n+                        accessControlEntryFilter: AccessControlEntryFilter = AccessControlEntryFilter.ANY): Unit = {\n     val newLine = scala.util.Properties.lineSeparator\n \n-    val filter = new AclBindingFilter(resource.toFilter, AccessControlEntryFilter.ANY)\n+    val filter = new AclBindingFilter(resource.toFilter, accessControlEntryFilter)\n     waitUntilTrue(() => authorizer.acls(filter).asScala.map(_.entry).toSet == expected,\n       s\"expected acls:${expected.mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\" +\n-        s\"but got:${authorizer.acls(filter).asScala.map(_.entry).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\", waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)\n+        s\"but got:${authorizer.acls(filter).asScala.map(_.entry).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\",\n+      waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4NzQ0MQ==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370387441", "bodyText": "Why do we have to pass this?", "author": "ijuma", "createdAt": "2020-01-23T22:24:42Z", "path": "core/src/test/scala/unit/kafka/utils/TestUtils.scala", "diffHunk": "@@ -1192,21 +1199,26 @@ object TestUtils extends Logging {\n     trustManager\n   }\n \n-  def waitAndVerifyAcls(expected: Set[AccessControlEntry], authorizer: JAuthorizer, resource: ResourcePattern) = {\n+  def waitAndVerifyAcls(expected: Set[AccessControlEntry],\n+                        authorizer: JAuthorizer,\n+                        resource: ResourcePattern,\n+                        accessControlEntryFilter: AccessControlEntryFilter = AccessControlEntryFilter.ANY): Unit = {\n     val newLine = scala.util.Properties.lineSeparator\n \n-    val filter = new AclBindingFilter(resource.toFilter, AccessControlEntryFilter.ANY)\n+    val filter = new AclBindingFilter(resource.toFilter, accessControlEntryFilter)\n     waitUntilTrue(() => authorizer.acls(filter).asScala.map(_.entry).toSet == expected,\n       s\"expected acls:${expected.mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\" +\n-        s\"but got:${authorizer.acls(filter).asScala.map(_.entry).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\", waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)\n+        s\"but got:${authorizer.acls(filter).asScala.map(_.entry).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\",\n+      waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)\n   }\n \n   def waitAndVerifyAcls(expected: Set[Acl], authorizer: Authorizer, resource: Resource) = {\n     val newLine = scala.util.Properties.lineSeparator\n \n     waitUntilTrue(() => authorizer.getAcls(resource) == expected,\n       s\"expected acls:${expected.mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\" +\n-        s\"but got:${authorizer.getAcls(resource).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\", waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)\n+        s\"but got:${authorizer.getAcls(resource).mkString(newLine + \"\\t\", newLine + \"\\t\", newLine)}\",\n+      waitTimeMs = JTestUtils.DEFAULT_MAX_WAIT_MS)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4ODE4Ng==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370388186", "bodyText": "How is this different from bootstrapServers() below?", "author": "ijuma", "createdAt": "2020-01-23T22:26:43Z", "path": "core/src/test/scala/unit/kafka/utils/TestUtils.scala", "diffHunk": "@@ -208,6 +207,14 @@ object TestUtils extends Logging {\n     }.mkString(\",\")\n   }\n \n+  def getBrokerListStrFromServers(servers: Seq[KafkaServer], listenerName: ListenerName): String = {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4ODY0Nw==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370388647", "bodyText": "Nit: maybe store the authorizer in a val since it's used many times.", "author": "ijuma", "createdAt": "2020-01-23T22:27:56Z", "path": "core/src/test/scala/unit/kafka/utils/TestUtils.scala", "diffHunk": "@@ -1715,4 +1727,17 @@ object TestUtils extends Logging {\n     waitUntilTrue(() => adminClient.listPartitionReassignments().reassignments().get().isEmpty,\n       s\"There still are ongoing reassignments\", pause = pause)\n   }\n+\n+  def addAndVerifyAcls(server: KafkaServer, acls: Set[AccessControlEntry], resource: ResourcePattern): Unit = {\n+    val aclBindings = acls.map { acl => new AclBinding(resource, acl) }\n+    server.dataPlaneRequestProcessor.authorizer.get", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM4OTM1OA==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370389358", "bodyText": "Do we need these methods?", "author": "ijuma", "createdAt": "2020-01-23T22:29:51Z", "path": "core/src/test/scala/integration/kafka/api/EndToEndAuthorizationTest.scala", "diffHunk": "@@ -90,8 +89,12 @@ abstract class EndToEndAuthorizationTest extends IntegrationTestHarness with Sas\n   val prefixedGroupResource =  new ResourcePattern(GROUP, groupPrefix, PREFIXED)\n   val wildcardTopicResource =  new ResourcePattern(TOPIC, wildcard, LITERAL)\n   val wildcardGroupResource =  new ResourcePattern(GROUP, wildcard, LITERAL)\n-  def kafkaPrincipalStr = s\"$kafkaPrincipalType:$kafkaPrincipal\"\n-  def clientPrincipalStr = s\"$kafkaPrincipalType:$clientPrincipal\"\n+\n+  def clientPrincipal: KafkaPrincipal\n+  def kafkaPrincipal: KafkaPrincipal\n+\n+  def kafkaPrincipalStr: String = kafkaPrincipal.toString\n+  def clientPrincipalStr: String = clientPrincipal.toString", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM5MDMyOQ==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370390329", "bodyText": "We can't use one of the utility methods in TestUtils?", "author": "ijuma", "createdAt": "2020-01-23T22:32:28Z", "path": "core/src/test/scala/integration/kafka/api/GroupAuthorizerIntegrationTest.scala", "diffHunk": "@@ -12,30 +12,139 @@\n  */\n package kafka.api\n \n-import java.util.Properties\n+import java.util.{Collections, Properties}\n+import java.util.concurrent.ExecutionException\n \n import kafka.api.GroupAuthorizerIntegrationTest._\n+import kafka.security.auth.SimpleAclAuthorizer\n+import kafka.security.authorizer.AuthorizerUtils.WildcardHost\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import org.apache.kafka.clients.consumer.ConsumerConfig\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord}\n+import org.apache.kafka.common.TopicPartition\n+import org.apache.kafka.common.acl.{AccessControlEntry, AclOperation, AclPermissionType}\n import org.apache.kafka.common.config.internals.BrokerSecurityConfigs\n+import org.apache.kafka.common.errors.TopicAuthorizationException\n+import org.apache.kafka.common.network.ListenerName\n+import org.apache.kafka.common.resource.{PatternType, Resource, ResourcePattern, ResourceType}\n import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+import org.scalatest.Assertions.intercept\n \n+import scala.collection.JavaConverters._\n \n object GroupAuthorizerIntegrationTest {\n-  val GroupPrincipalType = \"Group\"\n-  val TestGroupPrincipal = new KafkaPrincipal(GroupPrincipalType, \"testGroup\")\n+  val BrokerPrincipal = new KafkaPrincipal(\"Group\", \"broker\")\n+  val ClientPrincipal = new KafkaPrincipal(\"Group\", \"client\")\n+\n+  val BrokerListenerName = \"BROKER\"\n+  val ClientListenerName = \"CLIENT\"\n+\n   class GroupPrincipalBuilder extends KafkaPrincipalBuilder {\n     override def build(context: AuthenticationContext): KafkaPrincipal = {\n-      TestGroupPrincipal\n+      context.listenerName match {\n+        case BrokerListenerName => BrokerPrincipal\n+        case ClientListenerName => ClientPrincipal\n+        case listenerName => throw new IllegalArgumentException(s\"No principal mapped to listener $listenerName\")\n+      }\n     }\n   }\n }\n \n-class GroupAuthorizerIntegrationTest extends AuthorizerIntegrationTest {\n-  override val kafkaPrincipalType = GroupPrincipalType\n-  override def userPrincipal = TestGroupPrincipal\n+class GroupAuthorizerIntegrationTest extends BaseRequestTest {\n+\n+  val brokerId: Integer = 0\n+\n+  override def brokerCount: Int = 1\n+  override def interBrokerListenerName: ListenerName = new ListenerName(BrokerListenerName)\n+  override def listenerName: ListenerName = new ListenerName(ClientListenerName)\n+\n+  def brokerPrincipal: KafkaPrincipal = BrokerPrincipal\n+  def clientPrincipal: KafkaPrincipal = ClientPrincipal\n \n   override def brokerPropertyOverrides(properties: Properties): Unit = {\n-    properties.setProperty(BrokerSecurityConfigs.PRINCIPAL_BUILDER_CLASS_CONFIG,\n-      classOf[GroupPrincipalBuilder].getName)\n-    super.brokerPropertyOverrides(properties)\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[SimpleAclAuthorizer].getName)\n+    properties.put(KafkaConfig.BrokerIdProp, brokerId.toString)\n+    properties.put(KafkaConfig.OffsetsTopicPartitionsProp, \"1\")\n+    properties.put(KafkaConfig.OffsetsTopicReplicationFactorProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicPartitionsProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicReplicationFactorProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicMinISRProp, \"1\")\n+    properties.put(BrokerSecurityConfigs.PRINCIPAL_BUILDER_CLASS_CONFIG, classOf[GroupPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    doSetup(createOffsetsTopic = false)\n+\n+    // Allow inter-broker communication\n+    TestUtils.addAndVerifyAcls(servers.head,\n+      Set(createAcl(AclOperation.CLUSTER_ACTION, AclPermissionType.ALLOW, principal = BrokerPrincipal)),\n+      new ResourcePattern(ResourceType.CLUSTER, Resource.CLUSTER_NAME, PatternType.LITERAL))\n+\n+    TestUtils.createOffsetsTopic(zkClient, servers)\n+  }\n+\n+  private def createAcl(aclOperation: AclOperation,\n+                        aclPermissionType: AclPermissionType,\n+                        principal: KafkaPrincipal = ClientPrincipal): AccessControlEntry = {\n+    new AccessControlEntry(principal.toString, WildcardHost, aclOperation, aclPermissionType)\n+  }\n+\n+  @Test\n+  def testUnauthorizedProduceAndConsume(): Unit = {\n+    val topic = \"topic\"\n+    val topicPartition = new TopicPartition(\"topic\", 0)\n+\n+    createTopic(topic)\n+\n+    val producer = createProducer()\n+    intercept[TopicAuthorizationException] {\n+      sendRecords(producer, numRecords = 10, topicPartition)\n+    }\n+\n+    val consumer = createConsumer(configsToRemove = List(ConsumerConfig.GROUP_ID_CONFIG))\n+    consumer.assign(List(topicPartition).asJava)\n+    val e = intercept[TopicAuthorizationException] {\n+      TestUtils.pollUntilAtLeastNumRecords(consumer, numRecords = 10)\n+    }\n+    assertEquals(Collections.singleton(topic), e.unauthorizedTopics())\n+  }\n+\n+  @Test\n+  def testAuthorizedProduceAndConsume(): Unit = {\n+    val topic = \"topic\"\n+    val topicPartition = new TopicPartition(\"topic\", 0)\n+\n+    createTopic(topic)\n+\n+    TestUtils.addAndVerifyAcls(servers.head,\n+      Set(createAcl(AclOperation.WRITE, AclPermissionType.ALLOW)),\n+      new ResourcePattern(ResourceType.TOPIC, topic, PatternType.LITERAL))\n+    val producer = createProducer()\n+    sendRecords(producer, numRecords = 10, topicPartition)\n+\n+    TestUtils.addAndVerifyAcls(servers.head,\n+      Set(createAcl(AclOperation.READ, AclPermissionType.ALLOW)),\n+      new ResourcePattern(ResourceType.TOPIC, topic, PatternType.LITERAL))\n+    val consumer = createConsumer(configsToRemove = List(ConsumerConfig.GROUP_ID_CONFIG))\n+    consumer.assign(List(topicPartition).asJava)\n+    TestUtils.pollUntilAtLeastNumRecords(consumer, numRecords = 10)\n   }\n+\n+  private def sendRecords(producer: KafkaProducer[Array[Byte], Array[Byte]],", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM5MDU3OQ==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370390579", "bodyText": "Nit: no () needed for the second parameter.", "author": "ijuma", "createdAt": "2020-01-23T22:33:09Z", "path": "core/src/test/scala/integration/kafka/api/GroupAuthorizerIntegrationTest.scala", "diffHunk": "@@ -12,30 +12,139 @@\n  */\n package kafka.api\n \n-import java.util.Properties\n+import java.util.{Collections, Properties}\n+import java.util.concurrent.ExecutionException\n \n import kafka.api.GroupAuthorizerIntegrationTest._\n+import kafka.security.auth.SimpleAclAuthorizer\n+import kafka.security.authorizer.AuthorizerUtils.WildcardHost\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import org.apache.kafka.clients.consumer.ConsumerConfig\n+import org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord}\n+import org.apache.kafka.common.TopicPartition\n+import org.apache.kafka.common.acl.{AccessControlEntry, AclOperation, AclPermissionType}\n import org.apache.kafka.common.config.internals.BrokerSecurityConfigs\n+import org.apache.kafka.common.errors.TopicAuthorizationException\n+import org.apache.kafka.common.network.ListenerName\n+import org.apache.kafka.common.resource.{PatternType, Resource, ResourcePattern, ResourceType}\n import org.apache.kafka.common.security.auth.{AuthenticationContext, KafkaPrincipal, KafkaPrincipalBuilder}\n+import org.junit.Assert._\n+import org.junit.{Before, Test}\n+import org.scalatest.Assertions.intercept\n \n+import scala.collection.JavaConverters._\n \n object GroupAuthorizerIntegrationTest {\n-  val GroupPrincipalType = \"Group\"\n-  val TestGroupPrincipal = new KafkaPrincipal(GroupPrincipalType, \"testGroup\")\n+  val BrokerPrincipal = new KafkaPrincipal(\"Group\", \"broker\")\n+  val ClientPrincipal = new KafkaPrincipal(\"Group\", \"client\")\n+\n+  val BrokerListenerName = \"BROKER\"\n+  val ClientListenerName = \"CLIENT\"\n+\n   class GroupPrincipalBuilder extends KafkaPrincipalBuilder {\n     override def build(context: AuthenticationContext): KafkaPrincipal = {\n-      TestGroupPrincipal\n+      context.listenerName match {\n+        case BrokerListenerName => BrokerPrincipal\n+        case ClientListenerName => ClientPrincipal\n+        case listenerName => throw new IllegalArgumentException(s\"No principal mapped to listener $listenerName\")\n+      }\n     }\n   }\n }\n \n-class GroupAuthorizerIntegrationTest extends AuthorizerIntegrationTest {\n-  override val kafkaPrincipalType = GroupPrincipalType\n-  override def userPrincipal = TestGroupPrincipal\n+class GroupAuthorizerIntegrationTest extends BaseRequestTest {\n+\n+  val brokerId: Integer = 0\n+\n+  override def brokerCount: Int = 1\n+  override def interBrokerListenerName: ListenerName = new ListenerName(BrokerListenerName)\n+  override def listenerName: ListenerName = new ListenerName(ClientListenerName)\n+\n+  def brokerPrincipal: KafkaPrincipal = BrokerPrincipal\n+  def clientPrincipal: KafkaPrincipal = ClientPrincipal\n \n   override def brokerPropertyOverrides(properties: Properties): Unit = {\n-    properties.setProperty(BrokerSecurityConfigs.PRINCIPAL_BUILDER_CLASS_CONFIG,\n-      classOf[GroupPrincipalBuilder].getName)\n-    super.brokerPropertyOverrides(properties)\n+    properties.put(KafkaConfig.AuthorizerClassNameProp, classOf[SimpleAclAuthorizer].getName)\n+    properties.put(KafkaConfig.BrokerIdProp, brokerId.toString)\n+    properties.put(KafkaConfig.OffsetsTopicPartitionsProp, \"1\")\n+    properties.put(KafkaConfig.OffsetsTopicReplicationFactorProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicPartitionsProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicReplicationFactorProp, \"1\")\n+    properties.put(KafkaConfig.TransactionsTopicMinISRProp, \"1\")\n+    properties.put(BrokerSecurityConfigs.PRINCIPAL_BUILDER_CLASS_CONFIG, classOf[GroupPrincipalBuilder].getName)\n+  }\n+\n+  @Before\n+  override def setUp(): Unit = {\n+    doSetup(createOffsetsTopic = false)\n+\n+    // Allow inter-broker communication\n+    TestUtils.addAndVerifyAcls(servers.head,\n+      Set(createAcl(AclOperation.CLUSTER_ACTION, AclPermissionType.ALLOW, principal = BrokerPrincipal)),\n+      new ResourcePattern(ResourceType.CLUSTER, Resource.CLUSTER_NAME, PatternType.LITERAL))\n+\n+    TestUtils.createOffsetsTopic(zkClient, servers)\n+  }\n+\n+  private def createAcl(aclOperation: AclOperation,\n+                        aclPermissionType: AclPermissionType,\n+                        principal: KafkaPrincipal = ClientPrincipal): AccessControlEntry = {\n+    new AccessControlEntry(principal.toString, WildcardHost, aclOperation, aclPermissionType)\n+  }\n+\n+  @Test\n+  def testUnauthorizedProduceAndConsume(): Unit = {\n+    val topic = \"topic\"\n+    val topicPartition = new TopicPartition(\"topic\", 0)\n+\n+    createTopic(topic)\n+\n+    val producer = createProducer()\n+    intercept[TopicAuthorizationException] {\n+      sendRecords(producer, numRecords = 10, topicPartition)\n+    }\n+\n+    val consumer = createConsumer(configsToRemove = List(ConsumerConfig.GROUP_ID_CONFIG))\n+    consumer.assign(List(topicPartition).asJava)\n+    val e = intercept[TopicAuthorizationException] {\n+      TestUtils.pollUntilAtLeastNumRecords(consumer, numRecords = 10)\n+    }\n+    assertEquals(Collections.singleton(topic), e.unauthorizedTopics())", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM5MDg2Mg==", "url": "https://github.com/apache/kafka/pull/7926#discussion_r370390862", "bodyText": "Would it make sense to change this method to take a KafkaPrincipal?", "author": "ijuma", "createdAt": "2020-01-23T22:33:47Z", "path": "core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala", "diffHunk": "@@ -51,15 +51,15 @@ class DelegationTokenEndToEndAuthorizationTest extends EndToEndAuthorizationTest\n     super.configureSecurityBeforeServersStart()\n     zkClient.makeSurePersistentPathExists(ConfigEntityChangeNotificationZNode.path)\n     // Create broker admin credentials before starting brokers\n-    createScramCredentials(zkConnect, kafkaPrincipal, kafkaPassword)\n+    createScramCredentials(zkConnect, kafkaPrincipal.getName, kafkaPassword)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "a4f7faf8badc0629a09ad88031d1d3a9a295ed56", "url": "https://github.com/apache/kafka/commit/a4f7faf8badc0629a09ad88031d1d3a9a295ed56", "message": "MINOR: Fix AuthorizerIntegrationTest", "committedDate": "2020-02-19T05:35:48Z", "type": "commit"}, {"oid": "512722a8556f50f604294d649cd04e208441de86", "url": "https://github.com/apache/kafka/commit/512722a8556f50f604294d649cd04e208441de86", "message": "Fix failing end to end tests", "committedDate": "2020-02-19T05:35:48Z", "type": "commit"}, {"oid": "35ea2e51a7a2c5ae023f7873ca4701acc2d94c1a", "url": "https://github.com/apache/kafka/commit/35ea2e51a7a2c5ae023f7873ca4701acc2d94c1a", "message": "Fix failing tests", "committedDate": "2020-02-19T05:35:48Z", "type": "commit"}, {"oid": "80582d538456bda78a4585b7c41b3ab83951385c", "url": "https://github.com/apache/kafka/commit/80582d538456bda78a4585b7c41b3ab83951385c", "message": "Address review comments", "committedDate": "2020-02-19T05:35:48Z", "type": "commit"}, {"oid": "f420573957635f7746bbb144293edbcef6f9a8a1", "url": "https://github.com/apache/kafka/commit/f420573957635f7746bbb144293edbcef6f9a8a1", "message": "Revert change in controller epoch change", "committedDate": "2020-02-19T05:35:48Z", "type": "commit"}, {"oid": "f420573957635f7746bbb144293edbcef6f9a8a1", "url": "https://github.com/apache/kafka/commit/f420573957635f7746bbb144293edbcef6f9a8a1", "message": "Revert change in controller epoch change", "committedDate": "2020-02-19T05:35:48Z", "type": "forcePushed"}]}