{"pr_number": 9136, "pr_title": "KAFKA-10211: Add DirectoryConfigProvider", "pr_createdAt": "2020-08-07T09:57:56Z", "pr_url": "https://github.com/apache/kafka/pull/9136", "timeline": [{"oid": "88e3c00fd1e3886db9c71b1fa050372d01b3eceb", "url": "https://github.com/apache/kafka/commit/88e3c00fd1e3886db9c71b1fa050372d01b3eceb", "message": "KAFKA-10211: Add DirectoryConfigProvider\n\nSee KIP-632.", "committedDate": "2020-08-07T09:56:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNjcyNQ==", "url": "https://github.com/apache/kafka/pull/9136#discussion_r467206725", "bodyText": "Should we use java.nio.Files here instead? That will also give us an Exception if an IO error happens instead of null.", "author": "mimaison", "createdAt": "2020-08-07T18:37:17Z", "path": "clients/src/main/java/org/apache/kafka/common/config/provider/DirectoryConfigProvider.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.config.provider;\n+\n+import org.apache.kafka.common.config.ConfigData;\n+import org.apache.kafka.common.config.ConfigException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.FileFilter;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * An implementation of {@link ConfigProvider} based on a directory of files.\n+ * Property keys correspond to the names of the regular (i.e. non-directory)\n+ * files in a directory given by the path parameter.\n+ * Property values are taken from the file contents corresponding to each key.\n+ */\n+public class DirectoryConfigProvider implements ConfigProvider {\n+\n+    private final Logger log = LoggerFactory.getLogger(getClass());\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) { }\n+\n+    @Override\n+    public void close() throws IOException { }\n+\n+    /**\n+     * Retrieves the data contained in regular files in the directory given by {@code path}.\n+     * Non-regular files (such as directories) in the given directory are silently ignored.\n+     * @param path the directory where data files reside.\n+     * @return the configuration data.\n+     */\n+    @Override\n+    public ConfigData get(String path) {\n+        return get(path, File::isFile);\n+    }\n+\n+    /**\n+     * Retrieves the data contained in the regular files named by {@code keys} in the directory given by {@code path}.\n+     * Non-regular files (such as directories) in the given directory are silently ignored.\n+     * @param path the directory where data files reside.\n+     * @param keys the keys whose values will be retrieved.\n+     * @return the configuration data.\n+     */\n+    @Override\n+    public ConfigData get(String path, Set<String> keys) {\n+        return get(path, pathname ->\n+                pathname.isFile()\n+                        && keys.contains(pathname.getName()));\n+    }\n+\n+    private ConfigData get(String path, FileFilter fileFilter) {\n+        Map<String, String> map = new HashMap<>();\n+        if (path != null && !path.isEmpty()) {\n+            File dir = new File(path);\n+            if (!dir.isDirectory()) {\n+                log.warn(\"The path {} is not a directory\", path);\n+            } else {\n+                for (File file : dir.listFiles(fileFilter)) {", "originalCommit": "88e3c00fd1e3886db9c71b1fa050372d01b3eceb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNzU2NA==", "url": "https://github.com/apache/kafka/pull/9136#discussion_r467207564", "bodyText": "Actually it's worth checking if we can fully switch to java.nio classes.", "author": "mimaison", "createdAt": "2020-08-07T18:39:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNjcyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDg3OQ==", "url": "https://github.com/apache/kafka/pull/9136#discussion_r467984879", "bodyText": "That's a good point about null being used for the error case as well as the directory case. Thanks.", "author": "tombentley", "createdAt": "2020-08-10T15:28:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNjcyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwOTcxMA==", "url": "https://github.com/apache/kafka/pull/9136#discussion_r467209710", "bodyText": "This can be static", "author": "mimaison", "createdAt": "2020-08-07T18:43:56Z", "path": "clients/src/main/java/org/apache/kafka/common/config/provider/DirectoryConfigProvider.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.config.provider;\n+\n+import org.apache.kafka.common.config.ConfigData;\n+import org.apache.kafka.common.config.ConfigException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.FileFilter;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * An implementation of {@link ConfigProvider} based on a directory of files.\n+ * Property keys correspond to the names of the regular (i.e. non-directory)\n+ * files in a directory given by the path parameter.\n+ * Property values are taken from the file contents corresponding to each key.\n+ */\n+public class DirectoryConfigProvider implements ConfigProvider {\n+\n+    private final Logger log = LoggerFactory.getLogger(getClass());\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) { }\n+\n+    @Override\n+    public void close() throws IOException { }\n+\n+    /**\n+     * Retrieves the data contained in regular files in the directory given by {@code path}.\n+     * Non-regular files (such as directories) in the given directory are silently ignored.\n+     * @param path the directory where data files reside.\n+     * @return the configuration data.\n+     */\n+    @Override\n+    public ConfigData get(String path) {\n+        return get(path, File::isFile);\n+    }\n+\n+    /**\n+     * Retrieves the data contained in the regular files named by {@code keys} in the directory given by {@code path}.\n+     * Non-regular files (such as directories) in the given directory are silently ignored.\n+     * @param path the directory where data files reside.\n+     * @param keys the keys whose values will be retrieved.\n+     * @return the configuration data.\n+     */\n+    @Override\n+    public ConfigData get(String path, Set<String> keys) {\n+        return get(path, pathname ->\n+                pathname.isFile()\n+                        && keys.contains(pathname.getName()));\n+    }\n+\n+    private ConfigData get(String path, FileFilter fileFilter) {\n+        Map<String, String> map = new HashMap<>();\n+        if (path != null && !path.isEmpty()) {\n+            File dir = new File(path);\n+            if (!dir.isDirectory()) {\n+                log.warn(\"The path {} is not a directory\", path);\n+            } else {\n+                for (File file : dir.listFiles(fileFilter)) {\n+                    try {\n+                        map.put(file.getName(), read(file.toPath()));\n+                    } catch (IOException e) {\n+                        throw new ConfigException(\"Could not read file \" + file.getAbsolutePath() + \" for property \" + file.getName(), e);\n+                    }\n+                }\n+            }\n+        }\n+        return new ConfigData(map);\n+    }\n+\n+    private String read(Path path) throws IOException {", "originalCommit": "88e3c00fd1e3886db9c71b1fa050372d01b3eceb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIxMTEyMw==", "url": "https://github.com/apache/kafka/pull/9136#discussion_r467211123", "bodyText": "If we make log static, this can be static too", "author": "mimaison", "createdAt": "2020-08-07T18:47:09Z", "path": "clients/src/main/java/org/apache/kafka/common/config/provider/DirectoryConfigProvider.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.config.provider;\n+\n+import org.apache.kafka.common.config.ConfigData;\n+import org.apache.kafka.common.config.ConfigException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.FileFilter;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * An implementation of {@link ConfigProvider} based on a directory of files.\n+ * Property keys correspond to the names of the regular (i.e. non-directory)\n+ * files in a directory given by the path parameter.\n+ * Property values are taken from the file contents corresponding to each key.\n+ */\n+public class DirectoryConfigProvider implements ConfigProvider {\n+\n+    private final Logger log = LoggerFactory.getLogger(getClass());\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) { }\n+\n+    @Override\n+    public void close() throws IOException { }\n+\n+    /**\n+     * Retrieves the data contained in regular files in the directory given by {@code path}.\n+     * Non-regular files (such as directories) in the given directory are silently ignored.\n+     * @param path the directory where data files reside.\n+     * @return the configuration data.\n+     */\n+    @Override\n+    public ConfigData get(String path) {\n+        return get(path, File::isFile);\n+    }\n+\n+    /**\n+     * Retrieves the data contained in the regular files named by {@code keys} in the directory given by {@code path}.\n+     * Non-regular files (such as directories) in the given directory are silently ignored.\n+     * @param path the directory where data files reside.\n+     * @param keys the keys whose values will be retrieved.\n+     * @return the configuration data.\n+     */\n+    @Override\n+    public ConfigData get(String path, Set<String> keys) {\n+        return get(path, pathname ->\n+                pathname.isFile()\n+                        && keys.contains(pathname.getName()));\n+    }\n+\n+    private ConfigData get(String path, FileFilter fileFilter) {", "originalCommit": "88e3c00fd1e3886db9c71b1fa050372d01b3eceb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIxMjU0Mg==", "url": "https://github.com/apache/kafka/pull/9136#discussion_r467212542", "bodyText": "Should we delete anything that gets created in this directory?", "author": "mimaison", "createdAt": "2020-08-07T18:50:23Z", "path": "clients/src/test/java/org/apache/kafka/common/config/provider/DirectoryConfigProviderTest.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.config.provider;\n+\n+import org.apache.kafka.common.config.ConfigData;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.Collections;\n+import java.util.Locale;\n+import java.util.Set;\n+\n+import static java.util.Arrays.asList;\n+import static org.apache.kafka.test.TestUtils.toSet;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+public class DirectoryConfigProviderTest {\n+\n+    private DirectoryConfigProvider provider;\n+    private File parent;\n+    private File dir;\n+    private File bar;\n+    private File foo;\n+    private File subdir;\n+    private File subdirFile;\n+    private File siblingDir;\n+    private File siblingDirFile;\n+    private File siblingFile;\n+\n+    private static File writeFile(File file) throws IOException {\n+        Files.write(file.toPath(), file.getName().toUpperCase(Locale.ENGLISH).getBytes(StandardCharsets.UTF_8));\n+        return file;\n+    }\n+\n+    @Before\n+    public void setup() throws IOException {\n+        provider = new DirectoryConfigProvider();\n+        provider.configure(Collections.emptyMap());\n+        parent = TestUtils.tempDirectory();", "originalCommit": "88e3c00fd1e3886db9c71b1fa050372d01b3eceb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7203ddca022519875efcdeacc773bbb5a085ada5", "url": "https://github.com/apache/kafka/commit/7203ddca022519875efcdeacc773bbb5a085ada5", "message": "Review comments", "committedDate": "2020-08-10T15:27:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA5Mzc4OA==", "url": "https://github.com/apache/kafka/pull/9136#discussion_r468093788", "bodyText": "nit: Could we push the try catch block into the read method? That would streamline the code a little bit.", "author": "dajac", "createdAt": "2020-08-10T18:22:40Z", "path": "clients/src/main/java/org/apache/kafka/common/config/provider/DirectoryConfigProvider.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.config.provider;\n+\n+import org.apache.kafka.common.config.ConfigData;\n+import org.apache.kafka.common.config.ConfigException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+\n+import static java.util.Collections.emptyMap;\n+\n+/**\n+ * An implementation of {@link ConfigProvider} based on a directory of files.\n+ * Property keys correspond to the names of the regular (i.e. non-directory)\n+ * files in a directory given by the path parameter.\n+ * Property values are taken from the file contents corresponding to each key.\n+ */\n+public class DirectoryConfigProvider implements ConfigProvider {\n+\n+    private static final Logger log = LoggerFactory.getLogger(DirectoryConfigProvider.class);\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) { }\n+\n+    @Override\n+    public void close() throws IOException { }\n+\n+    /**\n+     * Retrieves the data contained in regular files in the directory given by {@code path}.\n+     * Non-regular files (such as directories) in the given directory are silently ignored.\n+     * @param path the directory where data files reside.\n+     * @return the configuration data.\n+     */\n+    @Override\n+    public ConfigData get(String path) {\n+        return get(path, Files::isRegularFile);\n+    }\n+\n+    /**\n+     * Retrieves the data contained in the regular files named by {@code keys} in the directory given by {@code path}.\n+     * Non-regular files (such as directories) in the given directory are silently ignored.\n+     * @param path the directory where data files reside.\n+     * @param keys the keys whose values will be retrieved.\n+     * @return the configuration data.\n+     */\n+    @Override\n+    public ConfigData get(String path, Set<String> keys) {\n+        return get(path, pathname ->\n+                Files.isRegularFile(pathname)\n+                        && keys.contains(pathname.getFileName().toString()));\n+    }\n+\n+    private static ConfigData get(String path, Predicate<Path> fileFilter) {\n+        Map<String, String> map = emptyMap();\n+        if (path != null && !path.isEmpty()) {\n+            Path dir = new File(path).toPath();\n+            if (!Files.isDirectory(dir)) {\n+                log.warn(\"The path {} is not a directory\", path);\n+            } else {\n+                try {\n+                    map = Files.list(dir)\n+                        .filter(fileFilter)\n+                        .collect(Collectors.toMap(\n+                            p -> p.getFileName().toString(),\n+                            p -> {\n+                                try {\n+                                    return read(p);\n+                                } catch (IOException e) {\n+                                    throw new ConfigException(\"Could not read file \" + p + \" for property \" + p.getFileName(), e);\n+                                }", "originalCommit": "7203ddca022519875efcdeacc773bbb5a085ada5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODM4OTg1MQ==", "url": "https://github.com/apache/kafka/pull/9136#discussion_r468389851", "bodyText": "Yes, good point. Done.", "author": "tombentley", "createdAt": "2020-08-11T07:46:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODA5Mzc4OA=="}], "type": "inlineReview"}, {"oid": "cb63f043f2adf289f9e557ee416bd99a1a3dd879", "url": "https://github.com/apache/kafka/commit/cb63f043f2adf289f9e557ee416bd99a1a3dd879", "message": "Review comment", "committedDate": "2020-08-11T07:46:25Z", "type": "commit"}, {"oid": "3f43bec123cb5d5327798c9826635d3e52c9b58d", "url": "https://github.com/apache/kafka/commit/3f43bec123cb5d5327798c9826635d3e52c9b58d", "message": "Checkstyle", "committedDate": "2020-08-21T08:04:17Z", "type": "commit"}]}