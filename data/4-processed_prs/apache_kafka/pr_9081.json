{"pr_number": 9081, "pr_title": "KAFKA-10309: KafkaProducer's sendOffsetsToTransaction should not block infinitively", "pr_createdAt": "2020-07-26T15:55:24Z", "pr_url": "https://github.com/apache/kafka/pull/9081", "timeline": [{"oid": "25a7cebe917889cb645ff87c6effc869cfc51a95", "url": "https://github.com/apache/kafka/commit/25a7cebe917889cb645ff87c6effc869cfc51a95", "message": "Modified KafkaProducer.sendOffsetsToTransaction() to be affected with max.block.ms.", "committedDate": "2020-07-26T15:24:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDYwODIyOA==", "url": "https://github.com/apache/kafka/pull/9081#discussion_r460608228", "bodyText": "javadoc for this method should be updated as well.", "author": "huxihx", "createdAt": "2020-07-27T01:52:53Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -687,7 +687,7 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n         throwIfProducerClosed();\n         TransactionalRequestResult result = transactionManager.sendOffsetsToTransaction(offsets, groupMetadata);\n         sender.wakeup();\n-        result.await();\n+        result.await(maxBlockTimeMs, TimeUnit.MILLISECONDS);", "originalCommit": "25a7cebe917889cb645ff87c6effc869cfc51a95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI2NTEyNQ==", "url": "https://github.com/apache/kafka/pull/9081#discussion_r461265125", "bodyText": "I wrote some description related to TimeoutException and InterruptedException", "author": "sasakitoa", "createdAt": "2020-07-28T01:34:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDYwODIyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDYwOTg3Ng==", "url": "https://github.com/apache/kafka/pull/9081#discussion_r460609876", "bodyText": "Using Map(new TopicPartition(topic1, 0) -> new OffsetAndMetadata(0)).asJava is better. No need to import scala.collection.mutable package.", "author": "huxihx", "createdAt": "2020-07-27T02:00:27Z", "path": "core/src/test/scala/integration/kafka/api/TransactionsTest.scala", "diffHunk": "@@ -406,6 +406,26 @@ class TransactionsTest extends KafkaServerTestHarness {\n     TestUtils.waitUntilTrue(() => offsetAndMetadata.equals(consumer.committed(Set(tp).asJava).get(tp)), \"cannot read committed offset\")\n   }\n \n+  @Test(expected = classOf[TimeoutException])\n+  def testSendOffsetsToTransactionTimeout(): Unit = {\n+    val producer = createTransactionalProducer(\"transactionProducer\", maxBlockMs = 1000)\n+    producer.initTransactions()\n+    producer.beginTransaction()\n+    producer.send(new ProducerRecord[Array[Byte], Array[Byte]](topic1, \"foo\".getBytes, \"bar\".getBytes))\n+\n+    for (i <- 0 until servers.size)\n+      killBroker(i)\n+\n+    val offsets = new mutable.HashMap[TopicPartition, OffsetAndMetadata]().asJava\n+    offsets.put(new TopicPartition(topic1, 0), new OffsetAndMetadata(0))\n+    try {\n+      producer.sendOffsetsToTransaction(offsets, \"test-group\")", "originalCommit": "25a7cebe917889cb645ff87c6effc869cfc51a95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI2NDgzMw==", "url": "https://github.com/apache/kafka/pull/9081#discussion_r461264833", "bodyText": "Replaced from mutable.HashMap to Map", "author": "sasakitoa", "createdAt": "2020-07-28T01:33:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDYwOTg3Ng=="}], "type": "inlineReview"}, {"oid": "3d5e4984f4c5287513b47ddecf6ccb7de9e90268", "url": "https://github.com/apache/kafka/commit/3d5e4984f4c5287513b47ddecf6ccb7de9e90268", "message": "Improved java doc and related test code (adapt review comments from @huxihx)", "committedDate": "2020-07-28T01:31:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMxMzM3Nw==", "url": "https://github.com/apache/kafka/pull/9081#discussion_r461313377", "bodyText": "nit: could use servers.indices", "author": "abbccdda", "createdAt": "2020-07-28T04:39:53Z", "path": "core/src/test/scala/integration/kafka/api/TransactionsTest.scala", "diffHunk": "@@ -406,6 +406,26 @@ class TransactionsTest extends KafkaServerTestHarness {\n     TestUtils.waitUntilTrue(() => offsetAndMetadata.equals(consumer.committed(Set(tp).asJava).get(tp)), \"cannot read committed offset\")\n   }\n \n+  @Test(expected = classOf[TimeoutException])\n+  def testSendOffsetsToTransactionTimeout(): Unit = {\n+    val producer = createTransactionalProducer(\"transactionProducer\", maxBlockMs = 1000)\n+    producer.initTransactions()\n+    producer.beginTransaction()\n+    producer.send(new ProducerRecord[Array[Byte], Array[Byte]](topic1, \"foo\".getBytes, \"bar\".getBytes))\n+\n+    for (i <- 0 until servers.size)", "originalCommit": "3d5e4984f4c5287513b47ddecf6ccb7de9e90268", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY5Nzc0Nw==", "url": "https://github.com/apache/kafka/pull/9081#discussion_r461697747", "bodyText": "Modified from size to indices, thanks.", "author": "sasakitoa", "createdAt": "2020-07-28T16:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMxMzM3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMxMzU5Nw==", "url": "https://github.com/apache/kafka/pull/9081#discussion_r461313597", "bodyText": "Do we have unit test coverage for other transaction API max blocking as well? Do you mind adding them as separate tests and share the same module?", "author": "abbccdda", "createdAt": "2020-07-28T04:40:49Z", "path": "core/src/test/scala/integration/kafka/api/TransactionsTest.scala", "diffHunk": "@@ -406,6 +406,26 @@ class TransactionsTest extends KafkaServerTestHarness {\n     TestUtils.waitUntilTrue(() => offsetAndMetadata.equals(consumer.committed(Set(tp).asJava).get(tp)), \"cannot read committed offset\")\n   }\n \n+  @Test(expected = classOf[TimeoutException])\n+  def testSendOffsetsToTransactionTimeout(): Unit = {\n+    val producer = createTransactionalProducer(\"transactionProducer\", maxBlockMs = 1000)\n+    producer.initTransactions()\n+    producer.beginTransaction()\n+    producer.send(new ProducerRecord[Array[Byte], Array[Byte]](topic1, \"foo\".getBytes, \"bar\".getBytes))\n+\n+    for (i <- 0 until servers.size)\n+      killBroker(i)\n+\n+    try {\n+      producer.sendOffsetsToTransaction(Map(", "originalCommit": "3d5e4984f4c5287513b47ddecf6ccb7de9e90268", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTcwMjQ3Mg==", "url": "https://github.com/apache/kafka/pull/9081#discussion_r461702472", "bodyText": "I added some timeout tests for initTransaction, commitTransction, abortTransaction using same base method.\nIs this implementation correct what you intended?", "author": "sasakitoa", "createdAt": "2020-07-28T16:11:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMxMzU5Nw=="}], "type": "inlineReview"}, {"oid": "e5675d44a5e1eb618eafe8cba43cb6417e8be2e1", "url": "https://github.com/apache/kafka/commit/e5675d44a5e1eb618eafe8cba43cb6417e8be2e1", "message": "Change how to get broker indices from size to indices.", "committedDate": "2020-07-28T14:21:06Z", "type": "commit"}, {"oid": "8c20bcab28c5f75d8d380e4f7008e0282f790b49", "url": "https://github.com/apache/kafka/commit/8c20bcab28c5f75d8d380e4f7008e0282f790b49", "message": "Add timeout test for initTransactions, commitTransaction, abortTransaction using same method.", "committedDate": "2020-07-28T16:02:51Z", "type": "commit"}]}