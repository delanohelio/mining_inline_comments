{"pr_number": 8015, "pr_title": "KAFKA-9500: Fix topology bug in foreign key joins", "pr_createdAt": "2020-01-29T00:11:35Z", "pr_url": "https://github.com/apache/kafka/pull/8015", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzMzg1OQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372133859", "bodyText": "We're creating the store builder, even though we might not use it, since we'd otherwise have to push the Materialized into the topology builder layer.", "author": "vvcephei", "createdAt": "2020-01-29T00:30:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java", "diffHunk": "@@ -1107,9 +1107,8 @@ boolean sendingOldValueEnabled() {\n         );\n \n         final StoreBuilder<TimestampedKeyValueStore<K, VR>> resultStore =\n-            materializedInternal.queryableStoreName() == null\n-                ? null\n-                : new TimestampedKeyValueStoreMaterializer<>(materializedInternal).materialize();\n+            new TimestampedKeyValueStoreMaterializer<>(materializedInternal).materialize();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzNDUwOA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374434508", "bodyText": "It might be easier to create the store within TableProcessorNode#writeToTopology() and encapsulate the decision if we need to materialize on not there?", "author": "mjsax", "createdAt": "2020-02-04T01:36:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzMzg1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY1ODA0MQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r376658041", "bodyText": "I took your other advice, which cleaned up this PR a lot. For this one, though, I think it's better this way. Note that materialize doesn't really \"materialize\" anything, it just converts the Materialized config object into a StoreBuilder topology object. It should be harmless to create a StoreBuilder that we never actually use.\nThis approach lets us keep Materialized in the DSL \"parsing\" layer, which is otherwise universally where it lives.", "author": "vvcephei", "createdAt": "2020-02-07T23:44:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzMzg1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzc4NjU2NQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r377786565", "bodyText": "SG", "author": "guozhangwang", "createdAt": "2020-02-11T17:30:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzMzg1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNDM0NA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372134344", "bodyText": "Since we passed in a store builder, TableProcessorNode will assume that we actually want to use it, but we're only sure we need it if it's queryable.", "author": "vvcephei", "createdAt": "2020-01-29T00:32:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java", "diffHunk": "@@ -1118,6 +1117,9 @@ boolean sendingOldValueEnabled() {\n             ),\n             resultStore\n         );\n+        resultNode.setStoreNeeded(materializedInternal.queryableStoreName() != null);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNDg5Nw==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372134897", "bodyText": "We're actually passing the TableProcessorNode into the KTableSource, so that later on, if the downsteam operation requests materialization, we can let the TableProcessorNode know we do need the store, even if it's not queriable. This is accomplished with setStoreNeeded from within the KTableSource#materialize()", "author": "vvcephei", "createdAt": "2020-01-29T00:34:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java", "diffHunk": "@@ -1118,6 +1117,9 @@ boolean sendingOldValueEnabled() {\n             ),\n             resultStore\n         );\n+        resultNode.setStoreNeeded(materializedInternal.queryableStoreName() != null);\n+        resultProcessorSupplier.setTableProcessorNode(resultNode);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzNjE3NQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374436175", "bodyText": "KTableSource#materialize() should be good enough -- it will set the queryableName (AFAIK, this won't make the store really queryable, but it's just a proxy to enforce materialization).", "author": "mjsax", "createdAt": "2020-02-04T01:44:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNDg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDg1MDI2OQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374850269", "bodyText": "+1.", "author": "guozhangwang", "createdAt": "2020-02-04T18:38:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNDg5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNTE0MQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372135141", "bodyText": "This is where we force registration of the store builder, even if it wasn't otherwise required.", "author": "vvcephei", "createdAt": "2020-01-29T00:35:39Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableSource.java", "diffHunk": "@@ -66,6 +73,9 @@ public void enableSendingOldValues() {\n     // need to set the queryable name as the store name to enforce materialization\n     public void materialize() {\n         this.queryableName = storeName;\n+        if (tableProcessorNode != null) {\n+            tableProcessorNode.setStoreNeeded(true);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzNjMyMw==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374436323", "bodyText": "I don't think we need all this, if we delay adding the store to writeToTopology()", "author": "mjsax", "createdAt": "2020-02-04T01:44:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNTE0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNTg5Nw==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372135897", "bodyText": "This is what allows us to register the store builder \"optimistically\" in the foreign key join, but still control later whether it really gets registered and used.", "author": "vvcephei", "createdAt": "2020-01-29T00:38:30Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/TableProcessorNode.java", "diffHunk": "@@ -65,8 +72,9 @@ public void writeToTopology(final InternalTopologyBuilder topologyBuilder) {\n         }\n \n         // TODO: we are enforcing this as a keyvalue store, but it should go beyond any type of stores\n-        if (storeBuilder != null) {\n-            topologyBuilder.addStateStore(storeBuilder, processorName);\n+        if (storeNeeded) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzNjcwOA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374436708", "bodyText": "We can just use ktableSource.queryableName() != null to do this check (we can get the source ktable node via:\nfinal KTableSource<K, V> ktableSource = (KTableSource<K, V>) processorParameters.processorSupplier();", "author": "mjsax", "createdAt": "2020-02-04T01:46:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNTg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY1NzI1NA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r376657254", "bodyText": "Nice!", "author": "vvcephei", "createdAt": "2020-02-07T23:40:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNTg5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNTk3NQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372135975", "bodyText": "I found this handy while debugging, so I figured I'd leave it in.", "author": "vvcephei", "createdAt": "2020-01-29T00:38:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordQueue.java", "diffHunk": "@@ -208,4 +208,9 @@ private void updateHead() {\n     long partitionTime() {\n         return partitionTime;\n     }\n+\n+    @Override\n+    public String toString() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQ2NDIwNQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372464205", "bodyText": "Previously, we would just directly process a record, and then iterate over the outputs, directly processing each of those as we get them...\nIf the first record R1 outputs R2 and R3, and R2 outputs R4, and R3 outputs R5, the correct observation order of outputs would be R2, R3, R4, R5, but the prior algorithm results in R2, R4, R3, R5.\nThe new algorithm is queue-based. We enqueue the first record, then we \"drain the queue\". \"Drain the queue\" means we repeatedly pull the head record, process it, and append its outputs to the end of the queue.", "author": "vvcephei", "createdAt": "2020-01-29T15:47:30Z", "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java", "diffHunk": "@@ -447,27 +443,50 @@ private void pipeRecord(final String topicName,\n         if (!internalTopologyBuilder.sourceTopicNames().isEmpty()) {\n             validateSourceTopicNameRegexPattern(topicName);\n         }\n+        enqueue(topicName, timestamp, key, value, headers);\n+\n+        drainProcessingQueue();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDg1MTE3OA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374851178", "bodyText": "Thanks for the great catch!", "author": "guozhangwang", "createdAt": "2020-02-04T18:39:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQ2NDIwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQ2OTQ3OA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372469478", "bodyText": "This \"processed\" boolean loop condition is a bit awkward, but there's otherwise no easy way to ask \"is the queue empty\", since the partition group is encapsulated in the task, and the record queue is encapsulated in the partition group.\nI think this algorithm is correct, but if the reviewers are uncomfortable with it, I'd propose to just add an \"isEmpty\" method to all of the record queue, partition group, and task interfaces so that we can just say \"keep processing until inputs are empty\" here.", "author": "vvcephei", "createdAt": "2020-01-29T15:55:42Z", "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java", "diffHunk": "@@ -447,27 +443,50 @@ private void pipeRecord(final String topicName,\n         if (!internalTopologyBuilder.sourceTopicNames().isEmpty()) {\n             validateSourceTopicNameRegexPattern(topicName);\n         }\n+        enqueue(topicName, timestamp, key, value, headers);\n+\n+        drainProcessingQueue();\n+    }\n+\n+    private void drainProcessingQueue() {\n+        boolean keepProcessing = true;\n+        while (keepProcessing) {\n+            // Since we can't directly inspect the enqueued records, we're using an indirect approach of\n+            // just continuing to process as long as either process() actually processed a record or\n+            // we enqueued some work while capturing output.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDg1MjA1OQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374852059", "bodyText": "Hmm if we continue processing if captureOutputRecordsAndEnqueueInternalForwards returns true would that be a stack-like behavior as well? To mimic Stream thread's behavior, if draining the current queue generates new records to the queue, they would not be processed immediately but only be processed in the next iteration.", "author": "guozhangwang", "createdAt": "2020-02-04T18:41:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQ2OTQ3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjQ3MjE1NQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r372472155", "bodyText": "Two main changes in this class:\n\nnew test parameter for explicitly materialized  or not\nnew test parameter for whether to add an extra equi-join after the FK join (aka rejoin). This is primarily just a way to verify if the \"upstream value getter enforced materialization\" mechanism actually works.\n\nI think it makes sense to verify that the FK join works on all the permutations of how the feature might be used.", "author": "vvcephei", "createdAt": "2020-01-29T15:59:42Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/KTableKTableForeignKeyJoinIntegrationTest.java", "diffHunk": "@@ -58,36 +60,66 @@\n     private static final String LEFT_TABLE = \"left_table\";\n     private static final String RIGHT_TABLE = \"right_table\";\n     private static final String OUTPUT = \"output-topic\";\n+    private static final String REJOIN_OUTPUT = \"rejoin-output-topic\";\n     private final Properties streamsConfig;\n     private final boolean leftJoin;\n+    private final boolean materialized;\n+    private final boolean rejoin;\n \n-    public KTableKTableForeignKeyJoinIntegrationTest(final boolean leftJoin, final String optimization) {\n+    public KTableKTableForeignKeyJoinIntegrationTest(final boolean leftJoin,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzODc0NA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374438744", "bodyText": "This fix seems rather complex. Why not just loop over output twice? In the first loop, we only remove output records that don't need further processing, and in the second loop, we call pipeRecord() directly for each?", "author": "mjsax", "createdAt": "2020-02-04T01:55:35Z", "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/TopologyTestDriver.java", "diffHunk": "@@ -513,24 +532,33 @@ private TopicPartition getTopicPartition(final String topicName) {\n         return topicPartition;\n     }\n \n-    private void captureOutputRecords() {\n+    private boolean captureOutputRecordsAndEnqueueInternalForwards() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc1NzczNg==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374757736", "bodyText": "Thanks for the review. At a glance, that does seem like it would result in the right output for this particular topology, but it seems like this would still process intermediate results in LIFO order instead of FIFO.\nI agree that the current fix is a bit complex, mostly because we can't actually query whether the task's priority queue is empty. I can explore adding that capability, which would simplify this algorithm.\nI'll give that a shot after I factor out the TTD change as a separate PR.", "author": "vvcephei", "createdAt": "2020-02-04T15:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzODc0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTQ5MDE0MA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r375490140", "bodyText": "but it seems like this would still process intermediate results in LIFO order instead of FIFO\n\nWhy that?", "author": "mjsax", "createdAt": "2020-02-05T20:27:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzODc0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDg1MDcxMg==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r374850712", "bodyText": "nit: not related to this PR, but the above TODO can be renamed as TODO KIP-300 to be more specific.", "author": "guozhangwang", "createdAt": "2020-02-04T18:39:11Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/TableProcessorNode.java", "diffHunk": "@@ -65,8 +72,9 @@ public void writeToTopology(final InternalTopologyBuilder topologyBuilder) {\n         }\n \n         // TODO: we are enforcing this as a keyvalue store, but it should go beyond any type of stores\n-        if (storeBuilder != null) {\n-            topologyBuilder.addStateStore(storeBuilder, processorName);\n+        if (storeNeeded) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY1ODQ1OA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r376658458", "bodyText": "changed the TODO at @guozhangwang 's request.", "author": "vvcephei", "createdAt": "2020-02-07T23:45:59Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/TableProcessorNode.java", "diffHunk": "@@ -64,9 +66,10 @@ public void writeToTopology(final InternalTopologyBuilder topologyBuilder) {\n             topologyBuilder.connectProcessorAndStateStores(processorName, storeNames);\n         }\n \n-        // TODO: we are enforcing this as a keyvalue store, but it should go beyond any type of stores\n-        if (storeBuilder != null) {\n-            topologyBuilder.addStateStore(storeBuilder, processorName);\n+        // TODO KIP-300: we are enforcing this as a keyvalue store, but it should go beyond any type of stores", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY1ODY0NQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r376658645", "bodyText": "Either Git or IDEA is inserting this change, and I can't get it to stop.", "author": "vvcephei", "createdAt": "2020-02-07T23:46:56Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordQueue.java", "diffHunk": "@@ -75,7 +75,7 @@\n         );\n         this.log = logContext.logger(RecordQueue.class);\n     }\n- \n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4OTc0OA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r376689748", "bodyText": "Ok, I figured out how to implement @mjsax 's suggestion specifically for KTableSource nodes, without affecting all the other kinds of KTable nodes.", "author": "vvcephei", "createdAt": "2020-02-08T05:43:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/TableProcessorNode.java", "diffHunk": "@@ -64,8 +67,12 @@ public void writeToTopology(final InternalTopologyBuilder topologyBuilder) {\n             topologyBuilder.connectProcessorAndStateStores(processorName, storeNames);\n         }\n \n-        // TODO: we are enforcing this as a keyvalue store, but it should go beyond any type of stores\n-        if (storeBuilder != null) {\n+        if (processorParameters.processorSupplier() instanceof KTableSource) {\n+            if (((KTableSource<?, ?>) processorParameters.processorSupplier()).materialized()) {\n+                topologyBuilder.addStateStore(Objects.requireNonNull(storeBuilder, \"storeBuilder was null\"),\n+                                              processorName);\n+            }\n+        } else if (storeBuilder != null) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY5MDI0MQ==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r376690241", "bodyText": "In retrospect, that might have been what you meant all along. Sorry if I misunderstood.", "author": "vvcephei", "createdAt": "2020-02-08T05:54:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4OTc0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzc4ODYyMg==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r377788622", "bodyText": "As a further thought, I think TableProcessorNode should be used for KTableSource as well (today they are only used in filter, map, transformValues and joinForeignKey that results in a KTable), so that we do not need this extra condition. But we can do this cleanup later (our current internal representation has a few such gaps already so some refactoring might be in request in future anyways).", "author": "guozhangwang", "createdAt": "2020-02-11T17:34:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4OTc0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg3OTIyMA==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r377879220", "bodyText": "I agree with you, and I actually tried to do it at some point. There's a problem with the types because (IIRC) TableProcessorNodes are processors over Change<V>, but TableSourceNodes are processors over <V>. I wanted to revisit it after KIP-478, but never managed to get around to actually implementing it (yet).", "author": "vvcephei", "createdAt": "2020-02-11T20:27:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY4OTc0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzgxMjQ5Ng==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r377812496", "bodyText": "In TableSourceNode and StreamToTableNode we use if (ktableSource. queryableName() != null) to make a decision about materialization -- given this new method, can we update both to also use this new method?\nNit: should the method be called needsMaterialization() ? The flag does not indicate that the table is materialized but that it must be materialized?", "author": "mjsax", "createdAt": "2020-02-11T18:19:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableSource.java", "diffHunk": "@@ -68,6 +68,10 @@ public void materialize() {\n         this.queryableName = storeName;\n     }\n \n+    public boolean materialized() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk4MDkyMg==", "url": "https://github.com/apache/kafka/pull/8015#discussion_r377980922", "bodyText": "Good idea! I've added that in the latest commit. I decided not to change the method name because it gets into whether materialize() should be like requestMaterialization(), etc, but that's a bigger change. void materialize() and boolean materialized() seem like a good pair.", "author": "vvcephei", "createdAt": "2020-02-12T00:32:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzgxMjQ5Ng=="}], "type": "inlineReview"}, {"oid": "25b37c9c0e86158aba583ca42ae751d954e981f1", "url": "https://github.com/apache/kafka/commit/25b37c9c0e86158aba583ca42ae751d954e981f1", "message": "KAFKA-9500: Fix FK Join Topology", "committedDate": "2020-02-12T04:28:07Z", "type": "commit"}]}