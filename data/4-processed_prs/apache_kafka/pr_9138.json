{"pr_number": 9138, "pr_title": "KAFKA-9929: Support backward iterator on WindowStore", "pr_createdAt": "2020-08-07T16:22:27Z", "pr_url": "https://github.com/apache/kafka/pull/9138", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4NTk5Nw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r474985997", "bodyText": "Do you know why we have all these ReadOnlyWindowStore methods also declared here in WindowStore? We don't need reverse variations of these I guess? \ud83e\udd14", "author": "ableegoldman", "createdAt": "2020-08-21T21:53:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/WindowStore.java", "diffHunk": "@@ -119,15 +118,16 @@\n      * <p>\n      * This iterator must be closed after use.\n      *\n-     * @param from      the first key in the range\n-     * @param to        the last key in the range\n-     * @param timeFrom  time range start (inclusive)\n-     * @param timeTo    time range end (inclusive)\n+     * @param from     the first key in the range\n+     * @param to       the last key in the range\n+     * @param timeFrom time range start (inclusive)\n+     * @param timeTo   time range end (inclusive)\n      * @return an iterator over windowed key-value pairs {@code <Windowed<K>, value>}\n      * @throws InvalidStateStoreException if the store is not initialized\n-     * @throws NullPointerException if one of the given keys is {@code null}\n+     * @throws NullPointerException       if one of the given keys is {@code null}\n      */\n-    @SuppressWarnings(\"deprecation\") // note, this method must be kept if super#fetch(...) is removed\n+    // note, this method must be kept if super#fetch(...) is removed\n+    @SuppressWarnings(\"deprecation\")\n     KeyValueIterator<Windowed<K>, V> fetch(K from, K to, long timeFrom, long timeTo);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkxMDY4OQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475910689", "bodyText": "These methods were introduced when adding Duration/Instant support #5682.\nI don't think these are needed, we can do a similar change as for SessionStore read operations. wdyt?", "author": "jeqo", "createdAt": "2020-08-24T21:41:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4NTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjAwMTE2Ng==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r476001166", "bodyText": "I guess the note, this method must be kept if super#fetch(...) is removed comments are making me nervous, but they could be out of date. Anyways I don't think you need to clean all this up right now, just wondering what's going on here", "author": "ableegoldman", "createdAt": "2020-08-25T00:31:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4NTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njg0OTc4Ng==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r476849786", "bodyText": "Ok, given @mjsax 's response on KAFKA-10434 it seems like we actually need to add the reverse variation of these long-based methods to the WindowStore API", "author": "ableegoldman", "createdAt": "2020-08-25T23:22:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4NTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM0MDAzMQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r478340031", "bodyText": "\ud83d\udc4d I've added the long-based methods to WindowStore to align this.", "author": "jeqo", "createdAt": "2020-08-27T11:16:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4NTk5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTQ0Mw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r474989443", "bodyText": "Just noticed that we use == instead of .equals down on line 437, can you fix that on the side?", "author": "ableegoldman", "createdAt": "2020-08-21T22:04:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java", "diffHunk": "@@ -426,7 +558,12 @@ private void getNextSegmentIterator() {\n             setCacheKeyRange(currentSegmentBeginTime(), currentSegmentLastTime());\n \n             current.close();\n-            current = context.cache().range(cacheName, cacheKeyFrom, cacheKeyTo);\n+\n+            if (forward) {\n+                current = context.cache().range(cacheName, cacheKeyFrom, cacheKeyTo);\n+            } else {\n+                current = context.cache().reverseRange(cacheName, cacheKeyFrom, cacheKeyTo);\n+            }\n         }\n \n         private void setCacheKeyRange(final long lowerRangeEndTime, final long upperRangeEndTime) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5MTIxNw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r474991217", "bodyText": "Github won't let me comment up there but on line 418, shouldn't we should have to decrement the currentSegmentId for the reverse case? I'm a little confused because it looks like you have test coverage for the multi-segment case and it seems to pass. Maybe I'm just tired and missing something obvious here..\nFor example in CachingWindowStoreTest#shouldFetchAndIterateOverKeyBackwardRange the results seem to go across multiple segments, but it looks like we actually do return the record from the largest segment first?", "author": "ableegoldman", "createdAt": "2020-08-21T22:11:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java", "diffHunk": "@@ -426,7 +558,12 @@ private void getNextSegmentIterator() {\n             setCacheKeyRange(currentSegmentBeginTime(), currentSegmentLastTime());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTk4NDQyOQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475984429", "bodyText": "Will have to double check this. I have inverted the current/last segment for backwards use-case though.", "author": "jeqo", "createdAt": "2020-08-25T00:06:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5MTIxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NTYwNg==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r474995606", "bodyText": "I feel like it's a little awkward to have the reverse variations accept time parameters as an Instant while the forward versions just use a long. I would have thought we could migrate the long methods to Instant at some point but I see all these  note, this method must be kept if super#fetch(...) is removed comments littered throughout the code...so maybe there's a reason for sticking with the long overrides in the innermost store layer?\nDid you come across anything that suggested a reason for keeping the long flavors? cc @guozhangwang or @mjsax -- why can't we remove these?", "author": "ableegoldman", "createdAt": "2020-08-21T22:27:20Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/InMemoryWindowStore.java", "diffHunk": "@@ -163,7 +164,17 @@ public void put(final Bytes key, final byte[] value, final long windowStartTimes\n     @Deprecated\n     @Override\n     public WindowStoreIterator<byte[]> fetch(final Bytes key, final long timeFrom, final long timeTo) {\n+        return fetch(key, timeFrom, timeTo, true);\n+    }\n+\n+    @Override\n+    public WindowStoreIterator<byte[]> backwardFetch(final Bytes key, final Instant from, final Instant to) {\n+        final long timeFrom = ApiUtils.validateMillisecondInstant(from, prepareMillisCheckFailMsgPrefix(from, \"from\"));\n+        final long timeTo = ApiUtils.validateMillisecondInstant(to, prepareMillisCheckFailMsgPrefix(to, \"to\"));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc5Mjc2MQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475792761", "bodyText": "Only backward compatibility. If it make sense to remove these deprecations as part of this KIP, I'd be happy to help cleaning it.", "author": "jeqo", "createdAt": "2020-08-24T17:53:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NTYwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjAwMzQ3OQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r476003479", "bodyText": "Ok, feel free to just create a followup ticket to see if we can clean things up. No need to block this PR on it", "author": "ableegoldman", "createdAt": "2020-08-25T00:35:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NTYwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc5NjE4Ng==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r476796186", "bodyText": "https://issues.apache.org/jira/browse/KAFKA-10434 created to follow this up.", "author": "jeqo", "createdAt": "2020-08-25T22:22:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NTYwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAwODY0NQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475008645", "bodyText": "As always Github won't let me comment on the line I actually want to (\ud83d\ude1e ) but I think we need a descending iterator for the reverse case in setRecordIterator (lines 411 & 413)", "author": "ableegoldman", "createdAt": "2020-08-21T23:24:27Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/InMemoryWindowStore.java", "diffHunk": "@@ -419,13 +504,13 @@ Long minTime() {\n         }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTk4ODUxNw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475988517", "bodyText": "For windowStore, only time-based index is been iterated backward. The KIP didn't considered reversing key/value stores internally.\nWe would need another flag (apart from backward) to define order of internal keys, which its cumbersome, and the order between keys doesn't matter much or can be calculated by the user.", "author": "jeqo", "createdAt": "2020-08-25T00:12:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAwODY0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTk5OTM1MQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475999351", "bodyText": "I agree that it doesn't matter much, but I think it has to be \"reverse\" for both time and keys for correctness due to CachingWindowStore. The caching layer just puts everything into one byte buffer so when we go in reverse order it's just the opposite of forward, which means both key and time ordering is flipped. And we unfortunately need the ordering to match up between the cache and the underlying store due to that merging iterator guy", "author": "ableegoldman", "createdAt": "2020-08-25T00:28:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAwODY0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc3NDE5NQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r478774195", "bodyText": "@jeqo I saw that you fixed this in ReadOnlyWindowStoreStub, I think InMemoryWindowStore is the only places that's still missing to reverse the key ordering on the backwards fetch methods", "author": "ableegoldman", "createdAt": "2020-08-28T01:00:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAwODY0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAxMzkwNw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475013907", "bodyText": "This doesn't look quite right...shouldn't it be D, C, B, A? I guess in the test we just need to use a descending iterator", "author": "ableegoldman", "createdAt": "2020-08-21T23:50:47Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/SegmentIteratorTest.java", "diffHunk": "@@ -107,26 +109,76 @@ public void shouldIterateOverAllSegments() {\n         assertFalse(iterator.hasNext());\n     }\n \n+    @Test\n+    public void shouldIterateBackwardOverAllSegments() {\n+        iterator = new SegmentIterator<>(\n+            Arrays.asList(segmentOne, segmentTwo).iterator(),\n+            hasNextCondition,\n+            Bytes.wrap(\"a\".getBytes()),\n+            Bytes.wrap(\"z\".getBytes()),\n+            false);\n+\n+        assertTrue(iterator.hasNext());\n+        assertEquals(\"b\", new String(iterator.peekNextKey().get()));\n+        assertEquals(KeyValue.pair(\"b\", \"2\"), toStringKeyValue(iterator.next()));\n+\n+        assertTrue(iterator.hasNext());\n+        assertEquals(\"a\", new String(iterator.peekNextKey().get()));\n+        assertEquals(KeyValue.pair(\"a\", \"1\"), toStringKeyValue(iterator.next()));\n+\n+        assertTrue(iterator.hasNext());\n+        assertEquals(\"d\", new String(iterator.peekNextKey().get()));\n+        assertEquals(KeyValue.pair(\"d\", \"4\"), toStringKeyValue(iterator.next()));\n+\n+        assertTrue(iterator.hasNext());\n+        assertEquals(\"c\", new String(iterator.peekNextKey().get()));\n+        assertEquals(KeyValue.pair(\"c\", \"3\"), toStringKeyValue(iterator.next()));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAxNDEzNQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475014135", "bodyText": "This should be a descending iterator for the reverse case (here and the other reverse methods in this class)", "author": "ableegoldman", "createdAt": "2020-08-21T23:51:52Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/AbstractRocksDBSegmentedBytesStore.java", "diffHunk": "@@ -72,22 +86,40 @@\n             searchSpace.iterator(),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1NzMwMQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475757301", "bodyText": "searchSpace will be reversed based on the forward flag, on AbstractSegments.", "author": "jeqo", "createdAt": "2020-08-24T16:54:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAxNDEzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAxNTg5NQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475015895", "bodyText": "Need to flip the loop", "author": "ableegoldman", "createdAt": "2020-08-22T00:02:07Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/ReadOnlyWindowStoreStub.java", "diffHunk": "@@ -212,17 +316,62 @@ public boolean hasNext() {\n         };\n     }\n \n-    @Override public KeyValueIterator<Windowed<K>, V> fetch(final K from,\n-                                                            final K to,\n-                                                            final Instant fromTime,\n-                                                            final Instant toTime) throws IllegalArgumentException {\n+    @Override\n+    public KeyValueIterator<Windowed<K>, V> fetch(final K from,\n+                                                  final K to,\n+                                                  final Instant fromTime,\n+                                                  final Instant toTime) throws IllegalArgumentException {\n         return fetch(\n             from,\n-            to, \n+            to,\n             ApiUtils.validateMillisecondInstant(fromTime, prepareMillisCheckFailMsgPrefix(fromTime, \"fromTime\")),\n             ApiUtils.validateMillisecondInstant(toTime, prepareMillisCheckFailMsgPrefix(toTime, \"toTime\")));\n     }\n \n+    @Override\n+    public KeyValueIterator<Windowed<K>, V> backwardFetch(final K from,\n+                                                          final K to,\n+                                                          final Instant fromTimeInstant,\n+                                                          final Instant toTimeInstant) throws IllegalArgumentException {\n+        final long timeFrom = ApiUtils.validateMillisecondInstant(fromTimeInstant, prepareMillisCheckFailMsgPrefix(fromTimeInstant, \"fromTimeInstant\"));\n+        final long timeTo = ApiUtils.validateMillisecondInstant(toTimeInstant, prepareMillisCheckFailMsgPrefix(toTimeInstant, \"toTimeInstant\"));\n+        if (!open) {\n+            throw new InvalidStateStoreException(\"Store is not open\");\n+        }\n+        final List<KeyValue<Windowed<K>, V>> results = new ArrayList<>();\n+        for (long now = timeFrom; now <= timeTo; now++) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAxNzE0OQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475017149", "bodyText": "nit: the existing style here is  inconsistent with the rest of Streams, should have 1st parameter on same line as method declaration (and everything else aligned to that)", "author": "ableegoldman", "createdAt": "2020-08-22T00:10:13Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/MergedSortedCacheWrappedWindowStoreKeyValueIteratorTest.java", "diffHunk": "@@ -123,7 +173,8 @@ public void shouldIterateBothStoreAndCache() {\n \n     private MergedSortedCacheWindowStoreKeyValueIterator createIterator(\n         final Iterator<KeyValue<Windowed<Bytes>, byte[]>> storeKvs,\n-        final Iterator<KeyValue<Bytes, LRUCacheEntry>> cacheKvs\n+        final Iterator<KeyValue<Bytes, LRUCacheEntry>> cacheKvs,\n+        final boolean forward", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAxOTExMw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475019113", "bodyText": "nit: use assertThrows", "author": "ableegoldman", "createdAt": "2020-08-22T00:17:02Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/CompositeReadOnlyWindowStoreTest.java", "diffHunk": "@@ -135,24 +188,74 @@ public void shouldThrowInvalidStateStoreExceptionOnRebalance() {\n         store.fetch(\"key\", ofEpochMilli(1), ofEpochMilli(10));\n     }\n \n+    @Test(expected = InvalidStateStoreException.class)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAyMDg4NQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475020885", "bodyText": "We should start on the largest segment I think (largest segment == farthest advanced in time)", "author": "ableegoldman", "createdAt": "2020-08-22T00:29:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java", "diffHunk": "@@ -337,25 +462,32 @@ public synchronized void close() {\n \n         private CacheIteratorWrapper(final Bytes key,\n                                      final long timeFrom,\n-                                     final long timeTo) {\n-            this(key, key, timeFrom, timeTo);\n+                                     final long timeTo,\n+                                     final boolean forward) {\n+            this(key, key, timeFrom, timeTo, forward);\n         }\n \n         private CacheIteratorWrapper(final Bytes keyFrom,\n                                      final Bytes keyTo,\n                                      final long timeFrom,\n-                                     final long timeTo) {\n+                                     final long timeTo,\n+                                     final boolean forward) {\n             this.keyFrom = keyFrom;\n             this.keyTo = keyTo;\n             this.timeTo = timeTo;\n             this.lastSegmentId = cacheFunction.segmentId(Math.min(timeTo, maxObservedTimestamp.get()));\n+            this.forward = forward;\n \n             this.segmentInterval = cacheFunction.getSegmentInterval();\n             this.currentSegmentId = cacheFunction.segmentId(timeFrom);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTk2NjI1OA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r475966258", "bodyText": "great catch! I think this hasn't pop up yet in the tests as all tests may be using the same segment.\nWill double check to add more tests to validate this.", "author": "jeqo", "createdAt": "2020-08-24T23:39:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAyMDg4NQ=="}], "type": "inlineReview"}, {"oid": "900639bf632cb5dd9ca3568f312a3e6159014db1", "url": "https://github.com/apache/kafka/commit/900639bf632cb5dd9ca3568f312a3e6159014db1", "message": "key/value reverse operations", "committedDate": "2020-08-22T16:47:53Z", "type": "commit"}, {"oid": "37c340e81494e396fbf7d052654c3bd3f9aff580", "url": "https://github.com/apache/kafka/commit/37c340e81494e396fbf7d052654c3bd3f9aff580", "message": "improve ordering docs", "committedDate": "2020-08-22T16:49:31Z", "type": "commit"}, {"oid": "92dcec1b20248ef0647323471892f711ad5c7b71", "url": "https://github.com/apache/kafka/commit/92dcec1b20248ef0647323471892f711ad5c7b71", "message": "fix range validator not needed", "committedDate": "2020-08-22T16:53:15Z", "type": "commit"}, {"oid": "26048cf65d3f8f5552d774e3c735233c76462a90", "url": "https://github.com/apache/kafka/commit/26048cf65d3f8f5552d774e3c735233c76462a90", "message": "improve tests", "committedDate": "2020-08-22T17:00:06Z", "type": "commit"}, {"oid": "07530e91e9913e6ecc0fe9995a25594a4fbb3a26", "url": "https://github.com/apache/kafka/commit/07530e91e9913e6ecc0fe9995a25594a4fbb3a26", "message": "improve range wrong order warning", "committedDate": "2020-08-22T17:06:19Z", "type": "commit"}, {"oid": "a733d3fe6056c44e11c6e7a5a0b40873f570aca3", "url": "https://github.com/apache/kafka/commit/a733d3fe6056c44e11c6e7a5a0b40873f570aca3", "message": "key/value reverse operation", "committedDate": "2020-08-22T17:06:20Z", "type": "commit"}, {"oid": "843980ba4eb35e67409f759f8af3be3991e8e4c1", "url": "https://github.com/apache/kafka/commit/843980ba4eb35e67409f759f8af3be3991e8e4c1", "message": "window backward operations", "committedDate": "2020-08-22T17:06:20Z", "type": "commit"}, {"oid": "a8fc3a44eb0f225a40ae8a2f5385397285697253", "url": "https://github.com/apache/kafka/commit/a8fc3a44eb0f225a40ae8a2f5385397285697253", "message": "small additions", "committedDate": "2020-08-22T17:06:20Z", "type": "commit"}, {"oid": "39405c6adfc0d330ee80c2ac1659365ec411fb82", "url": "https://github.com/apache/kafka/commit/39405c6adfc0d330ee80c2ac1659365ec411fb82", "message": "rearrange code", "committedDate": "2020-08-22T17:06:21Z", "type": "commit"}, {"oid": "1893fc1eaaa8792478b5ef11e4fe2412e6e73dec", "url": "https://github.com/apache/kafka/commit/1893fc1eaaa8792478b5ef11e4fe2412e6e73dec", "message": "improve time range comments", "committedDate": "2020-08-22T17:06:21Z", "type": "commit"}, {"oid": "f24e38ba26b5fd945df04e36afba12df08005783", "url": "https://github.com/apache/kafka/commit/f24e38ba26b5fd945df04e36afba12df08005783", "message": "fix bytes range validator not needed", "committedDate": "2020-08-22T17:06:21Z", "type": "commit"}, {"oid": "2cf2297e96bed7d5af34983b5445fca9c7d7d35e", "url": "https://github.com/apache/kafka/commit/2cf2297e96bed7d5af34983b5445fca9c7d7d35e", "message": "fix cache iterator", "committedDate": "2020-08-22T17:06:21Z", "type": "commit"}, {"oid": "24b6e71cddcebb96645f7e7ba36f64403d9cc3fe", "url": "https://github.com/apache/kafka/commit/24b6e71cddcebb96645f7e7ba36f64403d9cc3fe", "message": "fix syntax", "committedDate": "2020-08-22T17:06:22Z", "type": "commit"}, {"oid": "56630d2a81cd4731382ebc1c12c971a3115c2620", "url": "https://github.com/apache/kafka/commit/56630d2a81cd4731382ebc1c12c971a3115c2620", "message": "improve tests exception handling", "committedDate": "2020-08-22T17:06:22Z", "type": "commit"}, {"oid": "92e39ff2375e0b4ebd7aca9eeacfb208b34ef0da", "url": "https://github.com/apache/kafka/commit/92e39ff2375e0b4ebd7aca9eeacfb208b34ef0da", "message": "fix ordered set", "committedDate": "2020-08-22T17:06:22Z", "type": "commit"}, {"oid": "2a428d3d6abc5c2bc4f8210950269cd3a1f65941", "url": "https://github.com/apache/kafka/commit/2a428d3d6abc5c2bc4f8210950269cd3a1f65941", "message": "replace reverse with forward", "committedDate": "2020-08-22T17:06:23Z", "type": "commit"}, {"oid": "0871d19e1ef14a5fd56a56c8ec9725cb8fcbd29a", "url": "https://github.com/apache/kafka/commit/0871d19e1ef14a5fd56a56c8ec9725cb8fcbd29a", "message": "replace backward with forward flag", "committedDate": "2020-08-22T17:06:23Z", "type": "commit"}, {"oid": "0871d19e1ef14a5fd56a56c8ec9725cb8fcbd29a", "url": "https://github.com/apache/kafka/commit/0871d19e1ef14a5fd56a56c8ec9725cb8fcbd29a", "message": "replace backward with forward flag", "committedDate": "2020-08-22T17:06:23Z", "type": "forcePushed"}, {"oid": "07557b40127cfbb457686dc1bc262492546bface", "url": "https://github.com/apache/kafka/commit/07557b40127cfbb457686dc1bc262492546bface", "message": "apply suggestions", "committedDate": "2020-08-24T21:18:01Z", "type": "commit"}, {"oid": "33ee2a1039d922fb91af8b9d75c94be8fdbbbb5e", "url": "https://github.com/apache/kafka/commit/33ee2a1039d922fb91af8b9d75c94be8fdbbbb5e", "message": "fix: iterate segments backwards", "committedDate": "2020-08-24T23:38:27Z", "type": "commit"}, {"oid": "8725a7ea27db07273e9c19ec196f5b66c2d69f83", "url": "https://github.com/apache/kafka/commit/8725a7ea27db07273e9c19ec196f5b66c2d69f83", "message": "fix iteration", "committedDate": "2020-08-25T08:50:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NjY0NA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r476956644", "bodyText": "I guess we should use the long signature here too, and do the conversion from Instant to long in a default implementation on the WindowStore interface?", "author": "ableegoldman", "createdAt": "2020-08-26T01:36:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java", "diffHunk": "@@ -201,18 +203,48 @@ public synchronized void put(final Bytes key,\n         }\n \n         final PeekingKeyValueIterator<Bytes, LRUCacheEntry> cacheIterator = wrapped().persistent() ?\n-            new CacheIteratorWrapper(key, timeFrom, timeTo) :\n-            context.cache().range(cacheName,\n-                        cacheFunction.cacheKey(keySchema.lowerRangeFixedSize(key, timeFrom)),\n-                        cacheFunction.cacheKey(keySchema.upperRangeFixedSize(key, timeTo))\n+            new CacheIteratorWrapper(key, timeFrom, timeTo, true) :\n+            context.cache().range(\n+                cacheName,\n+                cacheFunction.cacheKey(keySchema.lowerRangeFixedSize(key, timeFrom)),\n+                cacheFunction.cacheKey(keySchema.upperRangeFixedSize(key, timeTo))\n             );\n \n         final HasNextCondition hasNextCondition = keySchema.hasNextCondition(key, key, timeFrom, timeTo);\n-        final PeekingKeyValueIterator<Bytes, LRUCacheEntry> filteredCacheIterator = new FilteredCacheIterator(\n-            cacheIterator, hasNextCondition, cacheFunction\n-        );\n+        final PeekingKeyValueIterator<Bytes, LRUCacheEntry> filteredCacheIterator =\n+            new FilteredCacheIterator(cacheIterator, hasNextCondition, cacheFunction);\n \n-        return new MergedSortedCacheWindowStoreIterator(filteredCacheIterator, underlyingIterator);\n+        return new MergedSortedCacheWindowStoreIterator(filteredCacheIterator, underlyingIterator, true);\n+    }\n+\n+    @Override\n+    public synchronized WindowStoreIterator<byte[]> backwardFetch(final Bytes key,\n+                                                                  final Instant from,\n+                                                                  final Instant to) {", "originalCommit": "8725a7ea27db07273e9c19ec196f5b66c2d69f83", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MjA3NQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r476962075", "bodyText": "Guessing this is not actually meant to be commented out \ud83d\ude42", "author": "ableegoldman", "createdAt": "2020-08-26T01:44:13Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java", "diffHunk": "@@ -416,26 +552,43 @@ private long currentSegmentLastTime() {\n         }\n \n         private void getNextSegmentIterator() {\n-            ++currentSegmentId;\n-            lastSegmentId = cacheFunction.segmentId(Math.min(timeTo, maxObservedTimestamp.get()));\n+            if (forward) {\n+                ++currentSegmentId;\n+                lastSegmentId = cacheFunction.segmentId(Math.min(timeTo, maxObservedTimestamp.get()));\n \n-            if (currentSegmentId > lastSegmentId) {\n-                current = null;\n-                return;\n-            }\n+                if (currentSegmentId > lastSegmentId) {\n+                    current = null;\n+                    return;\n+                }\n \n-            setCacheKeyRange(currentSegmentBeginTime(), currentSegmentLastTime());\n+                setCacheKeyRange(currentSegmentBeginTime(), currentSegmentLastTime());\n \n-            current.close();\n-            current = context.cache().range(cacheName, cacheKeyFrom, cacheKeyTo);\n+                current.close();\n+\n+                current = context.cache().range(cacheName, cacheKeyFrom, cacheKeyTo);\n+            } else {\n+                --currentSegmentId;\n+//                lastSegmentId = cacheFunction.segmentId(Math.min(timeTo, maxObservedTimestamp.get()));", "originalCommit": "8725a7ea27db07273e9c19ec196f5b66c2d69f83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQzNjg4Mg==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r477436882", "bodyText": "actually it could be removed: lastSegmentId should be stable going backwards based on timeFrom.\nOn the if branch, I assume that lastSegmentId could change in between iterations if maxObservedTimestamp is updated right?", "author": "jeqo", "createdAt": "2020-08-26T16:37:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MjA3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc3MDAwOQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r478770009", "bodyText": "Ah, good catch. That sounds right, the ending segment shouldn't change when you iterate backwards", "author": "ableegoldman", "createdAt": "2020-08-28T00:45:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MjA3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2NTM5Nw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r476965397", "bodyText": "It feels kind of ridiculous to convert this from a list to a set to an array all in one line. Maybe we can use assertThat(result, equalTo(expectedResult)) here like we've started to do elsewhere in Streams?", "author": "ableegoldman", "createdAt": "2020-08-26T01:49:05Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/AbstractWindowBytesStoreTest.java", "diffHunk": "@@ -287,17 +308,43 @@ public void shouldFetchAllInTimeRange() {\n         final KeyValue<Windowed<Integer>, String> four = windowedPair(4, \"four\", startTime + 4);\n         final KeyValue<Windowed<Integer>, String> five = windowedPair(5, \"five\", startTime + 5);\n \n-        assertEquals(\n-            new HashSet<>(asList(one, two, four)),\n-            toSet(windowStore.fetchAll(ofEpochMilli(startTime + 1), ofEpochMilli(startTime + 4)))\n+        assertArrayEquals(\n+            new LinkedHashSet<>(asList(one, two, four)).toArray(),\n+            toSet(windowStore.fetchAll(ofEpochMilli(startTime + 1), ofEpochMilli(startTime + 4))).toArray()\n         );\n-        assertEquals(\n-            new HashSet<>(asList(zero, one, two)),\n-            toSet(windowStore.fetchAll(ofEpochMilli(startTime + 0), ofEpochMilli(startTime + 3)))\n+        assertArrayEquals(\n+            new LinkedHashSet<>(asList(zero, one, two)).toArray(),\n+            toSet(windowStore.fetchAll(ofEpochMilli(startTime + 0), ofEpochMilli(startTime + 3))).toArray()\n         );\n-        assertEquals(\n-            new HashSet<>(asList(one, two, four, five)),\n-            toSet(windowStore.fetchAll(ofEpochMilli(startTime + 1), ofEpochMilli(startTime + 5)))\n+        assertArrayEquals(\n+            new LinkedHashSet<>(asList(one, two, four, five)).toArray(),", "originalCommit": "8725a7ea27db07273e9c19ec196f5b66c2d69f83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM0OTgwNA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r478349804", "bodyText": "Wow this is embarrasing haha, looks like I was trying to get tests green without much thinking \ud83d\ude05", "author": "jeqo", "createdAt": "2020-08-27T11:35:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2NTM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODc2OTQ5Mw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r478769493", "bodyText": "Haha actually I think I was the one who added the initial conversion from list to set to begin with, so I was clearly asking for trouble", "author": "ableegoldman", "createdAt": "2020-08-28T00:43:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2NTM5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2OTg0Nw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r476969847", "bodyText": "Same here (and all the backwards ReadOnlyWindowStoreStub methods): I think we are kind of forced to invert the key ordering for the backwards fetch methods as well, even if we don't necessarily want to. Probably users shouldn't be relying on a strict ordering of the keys anyway but we do have to match the ordering of the cache", "author": "ableegoldman", "createdAt": "2020-08-26T01:55:18Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/ReadOnlyWindowStoreStub.java", "diffHunk": "@@ -104,7 +121,47 @@ public V fetch(final K key, final long time) {\n \n         return new KeyValueIterator<Windowed<K>, V>() {\n             @Override\n-            public void close() {}\n+            public void close() {\n+            }\n+\n+            @Override\n+            public Windowed<K> peekNextKey() {\n+                throw new UnsupportedOperationException(\"peekNextKey() not supported in \" + getClass().getName());\n+            }\n+\n+            @Override\n+            public boolean hasNext() {\n+                return iterator.hasNext();\n+            }\n+\n+            @Override\n+            public KeyValue<Windowed<K>, V> next() {\n+                return iterator.next();\n+            }\n+\n+        };\n+    }\n+\n+    @Override\n+    public KeyValueIterator<Windowed<K>, V> backwardAll() {\n+        if (!open) {\n+            throw new InvalidStateStoreException(\"Store is not open\");\n+        }\n+        final List<KeyValue<Windowed<K>, V>> results = new ArrayList<>();\n+        for (final long now : data.keySet()) {", "originalCommit": "8725a7ea27db07273e9c19ec196f5b66c2d69f83", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "86932775070f2c33eedacbb9341c5f819bdd0cf1", "url": "https://github.com/apache/kafka/commit/86932775070f2c33eedacbb9341c5f819bdd0cf1", "message": "remove commented code", "committedDate": "2020-08-26T16:32:07Z", "type": "commit"}, {"oid": "4f81ba3985722efb1469dd653c44e8a2c17d1d8d", "url": "https://github.com/apache/kafka/commit/4f81ba3985722efb1469dd653c44e8a2c17d1d8d", "message": "adding long variant to backward methods.", "committedDate": "2020-08-27T09:50:11Z", "type": "commit"}, {"oid": "a98827659a461e32641ea9781476b829f41e1c14", "url": "https://github.com/apache/kafka/commit/a98827659a461e32641ea9781476b829f41e1c14", "message": "fix: remove redundant array/set/list equals assertions", "committedDate": "2020-08-27T14:18:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2MjQ5MA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480462490", "bodyText": "nit: is this intentional? Also I'd suggest we do not use capitalized If to be consistent with the above line, ditto elsewhere below.", "author": "guozhangwang", "createdAt": "2020-08-31T23:10:23Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/ReadOnlyWindowStore.java", "diffHunk": "@@ -33,11 +33,11 @@\n     /**\n      * Get the value of key from a window.\n      *\n-     * @param key       the key to fetch\n-     * @param time      start timestamp (inclusive) of the window\n+     * @param key  the key to fetch\n+     * @param time start timestamp (inclusive) of the window\n      * @return The value or {@code null} if no value is found in the window\n      * @throws InvalidStateStoreException if the store is not initialized\n-     * @throws NullPointerException If {@code null} is used for any key.\n+     * @throws NullPointerException       If {@code null} is used for any key.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTkyMDU3Mg==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r481920572", "bodyText": "yes, IDE reformatting. I've fixed the capitalized If", "author": "jeqo", "createdAt": "2020-09-02T09:09:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2MjQ5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2NTE1MA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480465150", "bodyText": "Since we are going to remove deprecated overloads with primitive long in the future, I think we do not need to expose a default function here, but just provide a default impl of the function in 204 below as UnsupportedOperation?", "author": "guozhangwang", "createdAt": "2020-08-31T23:14:27Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/WindowStore.java", "diffHunk": "@@ -150,13 +185,25 @@\n      * @return an iterator over windowed key-value pairs {@code <Windowed<K>, value>}\n      * @throws InvalidStateStoreException if the store is not initialized\n      */\n-    @SuppressWarnings(\"deprecation\") // note, this method must be kept if super#fetchAll(...) is removed\n+    // note, this method must be kept if super#fetchAll(...) is removed\n+    @SuppressWarnings(\"deprecation\")\n     KeyValueIterator<Windowed<K>, V> fetchAll(long timeFrom, long timeTo);\n \n     @Override\n-    default KeyValueIterator<Windowed<K>, V> fetchAll(final Instant from, final Instant to) {\n+    default KeyValueIterator<Windowed<K>, V> fetchAll(final Instant timeFrom, final Instant timeTo) {\n         return fetchAll(\n-            ApiUtils.validateMillisecondInstant(from, prepareMillisCheckFailMsgPrefix(from, \"from\")),\n-            ApiUtils.validateMillisecondInstant(to, prepareMillisCheckFailMsgPrefix(to, \"to\")));\n+            ApiUtils.validateMillisecondInstant(timeFrom, prepareMillisCheckFailMsgPrefix(timeFrom, \"timeFrom\")),\n+            ApiUtils.validateMillisecondInstant(timeTo, prepareMillisCheckFailMsgPrefix(timeTo, \"timeTo\")));\n+    }\n+\n+    default KeyValueIterator<Windowed<K>, V> backwardFetchAll(final long timeFrom, final long timeTo) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUyMTYzNw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r481521637", "bodyText": "Idk, the current defaults make sense to me. If a user has a custom store and wants to use the new backwardFetchAll with both longs and Instants, all they'd have to do is override the long-based backwardFetchAll method (they have to implement the long version no matter what, since this is what gets used internally to Streams). If we just throw UnsupportedOperationException directly from the default implementation of the Instant-based backwardFetchAll, then they would have to override that as well in their custom store. So we should just let the Instant default to the long method so users only have to implement one method instead of two (plus they would have to do the Instant validation themselves, etc)", "author": "ableegoldman", "createdAt": "2020-09-02T01:16:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2NTE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjE2MDAyMA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r482160020", "bodyText": "@guozhangwang do you mean the changes proposed in KIP-667? In that KIP we are removing long-based methods only from ReadOnlyWindowStore, but will keep it in WindowStore\u2014unless you're referring to a different proposal.\nI do agree with @ableegoldman. Users will have to opt-in to reverse operations when using custom stores, and by default only add implementation for long-based to support both params options.", "author": "jeqo", "createdAt": "2020-09-02T15:24:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2NTE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjUyNDYyMg==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r482524622", "bodyText": "Ah yes, I was thinking about ReadOnlyWindowStore exposed in IQ only. All good.", "author": "guozhangwang", "createdAt": "2020-09-02T22:10:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2NTE1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2OTY4OA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480469688", "bodyText": "This is out of the scope of this PR, but I'd like to point out that the current IQ does not actually obey the ordering when there are multiple local stores hosted on that instance. For example, if there are two stores from two tasks hosting keys {1, 3} and {2,4}, then a range query of key [1,4] would return in the order of 1,3,2,4 but not 1,2,3,4 since it is looping over the stores only. This would be the case for either forward or backward fetches on range-key-range-time.\nFor single key time range fetch, or course, there's no such issue.\nI think it worth documenting this for now until we have a fix (and actually we are going to propose something soon).", "author": "guozhangwang", "createdAt": "2020-08-31T23:23:00Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/ReadOnlyWindowStore.java", "diffHunk": "@@ -136,34 +174,64 @@\n      * <p>\n      * This iterator must be closed after use.\n      *\n-     * @param from      the first key in the range\n-     * @param to        the last key in the range\n-     * @param fromTime  time range start (inclusive)\n-     * @param toTime    time range end (inclusive)\n-     * @return an iterator over windowed key-value pairs {@code <Windowed<K>, value>}\n+     * @param from     the first key in the range\n+     * @param to       the last key in the range\n+     * @param timeFrom time range start (inclusive), where iteration starts.\n+     * @param timeTo   time range end (inclusive), where iteration ends.\n+     * @return an iterator over windowed key-value pairs {@code <Windowed<K>, value>}, from beginning to end of time.\n      * @throws InvalidStateStoreException if the store is not initialized\n-     * @throws NullPointerException If {@code null} is used for any key.\n-     * @throws IllegalArgumentException if duration is negative or can't be represented as {@code long milliseconds}\n+     * @throws NullPointerException       If {@code null} is used for any key.\n+     * @throws IllegalArgumentException   if duration is negative or can't be represented as {@code long milliseconds}\n      */\n-    KeyValueIterator<Windowed<K>, V> fetch(K from, K to, Instant fromTime, Instant toTime)\n+    KeyValueIterator<Windowed<K>, V> fetch(K from, K to, Instant timeFrom, Instant timeTo)\n         throws IllegalArgumentException;\n \n     /**\n-    * Gets all the key-value pairs in the existing windows.\n-    *\n-    * @return an iterator over windowed key-value pairs {@code <Windowed<K>, value>}\n-    * @throws InvalidStateStoreException if the store is not initialized\n-    */\n+     * Get all the key-value pairs in the given key range and time range from all the existing windows\n+     * in backward order with respect to time (from end to beginning of time).\n+     * <p>\n+     * This iterator must be closed after use.\n+     *\n+     * @param from     the first key in the range\n+     * @param to       the last key in the range\n+     * @param timeFrom time range start (inclusive), where iteration ends.\n+     * @param timeTo   time range end (inclusive), where iteration starts.\n+     * @return an iterator over windowed key-value pairs {@code <Windowed<K>, value>}, from end to beginning of time.\n+     * @throws InvalidStateStoreException if the store is not initialized\n+     * @throws NullPointerException       If {@code null} is used for any key.\n+     * @throws IllegalArgumentException   if duration is negative or can't be represented as {@code long milliseconds}\n+     */\n+    KeyValueIterator<Windowed<K>, V> backwardFetch(K from, K to, Instant timeFrom, Instant timeTo)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUxOTc3NA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r481519774", "bodyText": "Yeah, @jeqo noticed that back in the KeyValueStore PR. That's a good point about clarifying this point in the javadocs, not sure if it makes sense to do so on the ReadOnlyWindowStore methods directly vs on some IQ-related method/class? Maybe we can just do a quick followup PR to shore up the documentation here without blocking this PR", "author": "ableegoldman", "createdAt": "2020-09-02T01:08:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2OTY4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjE2MDg1OQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r482160859", "bodyText": "#9137 (comment) old discussion for context.\n@guozhangwang is this scenario only possible with composite stores? or are there other implementations where this is an alternative path?", "author": "jeqo", "createdAt": "2020-09-02T15:26:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2OTY4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjUyNTczNw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r482525737", "bodyText": "The composite stores are the ones used in IQ. So IQ queries would get impacted by this, for processing, since it is always within a single task there should be no problems.", "author": "guozhangwang", "createdAt": "2020-09-02T22:12:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2OTY4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgxMDI5MQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r482810291", "bodyText": "thanks @guozhangwang ! I created https://issues.apache.org/jira/browse/KAFKA-10459 to follow up.", "author": "jeqo", "createdAt": "2020-09-03T08:43:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ2OTY4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MDEzNA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480470134", "bodyText": "Is this intentional? We usually have a newline at file end in case some specific IDEs do not like otherwise.", "author": "guozhangwang", "createdAt": "2020-08-31T23:24:30Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/AbstractMergedSortedCacheStoreIterator.java", "diffHunk": "@@ -192,4 +192,3 @@ public void close() {\n         storeIterator.close();\n     }\n }\n-", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTkzMDM3OA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r481930378", "bodyText": "This looks strange. I can see there is a newline in my IDE. Seems that in trunk it had 2 newlines at the end. I can roll-back this change if needed.", "author": "jeqo", "createdAt": "2020-09-02T09:25:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MDEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MDY0NA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480470644", "bodyText": "nit: we can just call subMap out of the condition and only call descendingMap() based on the condition.", "author": "guozhangwang", "createdAt": "2020-08-31T23:26:01Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/AbstractSegments.java", "diffHunk": "@@ -117,12 +118,20 @@ public void openExisting(final ProcessorContext context, final long streamTime)\n     }\n \n     @Override\n-    public List<S> segments(final long timeFrom, final long timeTo) {\n+    public List<S> segments(final long timeFrom, final long timeTo, final boolean forward) {\n         final List<S> result = new ArrayList<>();\n-        final NavigableMap<Long, S> segmentsInRange = segments.subMap(\n-            segmentId(timeFrom), true,\n-            segmentId(timeTo), true\n-        );\n+        final NavigableMap<Long, S> segmentsInRange;\n+        if (forward) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTkzMTEyNw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r481931127", "bodyText": "I'd prefer this immutable approach as it's the same used in keyValueStore changes, if that's ok.", "author": "jeqo", "createdAt": "2020-09-02T09:26:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MDY0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjUyNjE1OQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r482526159", "bodyText": "SG, nit comments are just suggestions not mandatory.", "author": "guozhangwang", "createdAt": "2020-09-02T22:12:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MDY0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MTE3Ng==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480471176", "bodyText": "See my other comments: I think we do not need to add overloads for primitive types for the newly added APIs?", "author": "guozhangwang", "createdAt": "2020-08-31T23:27:40Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java", "diffHunk": "@@ -271,27 +345,68 @@ public synchronized void put(final Bytes key,\n         final PeekingKeyValueIterator<Bytes, LRUCacheEntry> filteredCacheIterator =\n             new FilteredCacheIterator(cacheIterator, hasNextCondition, cacheFunction);\n         return new MergedSortedCacheWindowStoreKeyValueIterator(\n-                filteredCacheIterator,\n-                underlyingIterator,\n-                bytesSerdes,\n-                windowSize,\n-                cacheFunction\n+            filteredCacheIterator,\n+            underlyingIterator,\n+            bytesSerdes,\n+            windowSize,\n+            cacheFunction,\n+            true\n+        );\n+    }\n+\n+    @Override\n+    public KeyValueIterator<Windowed<Bytes>, byte[]> backwardFetchAll(final long timeFrom,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3OTY3Nw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480479677", "bodyText": "We would still need to keep this method: we're not removing all long-based APIs, just the public/IQ methods in ReadOnlyWindowStore. But we still want to keep the long-based methods on WindowStore and all the internal store interfaces for performance reasons.\nMaybe once we move everything to use Instant all the way down to the serialization then we can remove these long-based methods. I guess we should consider that when discussing KIP-667, but for the time being at least, we should keep them for internal use", "author": "ableegoldman", "createdAt": "2020-08-31T23:55:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MTE3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MjQyNA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480472424", "bodyText": "Why this call is different based on the forward boolean? It's not clear to me. cc @ableegoldman @lct45 could you double check?", "author": "guozhangwang", "createdAt": "2020-08-31T23:31:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingWindowStore.java", "diffHunk": "@@ -338,25 +452,36 @@ public synchronized void close() {\n \n         private CacheIteratorWrapper(final Bytes key,\n                                      final long timeFrom,\n-                                     final long timeTo) {\n-            this(key, key, timeFrom, timeTo);\n+                                     final long timeTo,\n+                                     final boolean forward) {\n+            this(key, key, timeFrom, timeTo, forward);\n         }\n \n         private CacheIteratorWrapper(final Bytes keyFrom,\n                                      final Bytes keyTo,\n                                      final long timeFrom,\n-                                     final long timeTo) {\n+                                     final long timeTo,\n+                                     final boolean forward) {\n             this.keyFrom = keyFrom;\n             this.keyTo = keyTo;\n             this.timeTo = timeTo;\n-            this.lastSegmentId = cacheFunction.segmentId(Math.min(timeTo, maxObservedTimestamp.get()));\n+            this.forward = forward;\n \n             this.segmentInterval = cacheFunction.getSegmentInterval();\n-            this.currentSegmentId = cacheFunction.segmentId(timeFrom);\n \n-            setCacheKeyRange(timeFrom, currentSegmentLastTime());\n+            if (forward) {\n+                this.lastSegmentId = cacheFunction.segmentId(Math.min(timeTo, maxObservedTimestamp.get()));\n+                this.currentSegmentId = cacheFunction.segmentId(timeFrom);\n \n-            this.current = context.cache().range(cacheName, cacheKeyFrom, cacheKeyTo);\n+                setCacheKeyRange(timeFrom, currentSegmentLastTime());\n+                this.current = context.cache().range(cacheName, cacheKeyFrom, cacheKeyTo);\n+            } else {\n+                this.currentSegmentId = cacheFunction.segmentId(Math.min(timeTo, maxObservedTimestamp.get()));\n+                this.lastSegmentId = cacheFunction.segmentId(timeFrom);\n+\n+                setCacheKeyRange(currentSegmentBeginTime(), Math.min(timeTo, maxObservedTimestamp.get()));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ4MTA2MA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480481060", "bodyText": "This looks right to me -- in the iterator constructor, we would normally start from timeFrom (the minimum time) and advance to the end of the current segment (that's what the \"cache key range\" defines, the range of the current segment) When iterating backwards, the current segment is actually the largest segment, so the cache key lower range is the current (largest) segment's beginning timestamp, and the upper range is the maximum timestamp of the backwards fetch. Does that make sense?", "author": "ableegoldman", "createdAt": "2020-09-01T00:00:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MjQyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjUyODYwMQ==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r482528601", "bodyText": "SG", "author": "guozhangwang", "createdAt": "2020-09-02T22:16:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MjQyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MzgzMA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480473830", "bodyText": "This is not directly related to this PR, but it makes me wondering: why do we keep a separate range / all in extended Segment interface? Should we just remove that? Now we've added the reverse ones but only in the parent interface, it makes me feeling the original ones on Segment is not necessary.", "author": "guozhangwang", "createdAt": "2020-08-31T23:36:19Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/SegmentIterator.java", "diffHunk": "@@ -67,14 +70,22 @@ public Bytes peekNextKey() {\n     public boolean hasNext() {\n         boolean hasNext = false;\n         while ((currentIterator == null || !(hasNext = hasNextConditionHasNext()) || !currentSegment.isOpen())\n-                && segments.hasNext()) {\n+            && segments.hasNext()) {\n             close();\n             currentSegment = segments.next();\n             try {\n                 if (from == null || to == null) {\n-                    currentIterator = currentSegment.all();\n+                    if (forward) {\n+                        currentIterator = currentSegment.all();\n+                    } else {\n+                        currentIterator = currentSegment.reverseAll();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ4MjM1MA==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r480482350", "bodyText": "Yeah that's a good question, it does seem like we can just remove the range and all on the Segment interface", "author": "ableegoldman", "createdAt": "2020-09-01T00:05:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MzgzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjEyNzA2Nw==", "url": "https://github.com/apache/kafka/pull/9138#discussion_r482127067", "bodyText": "+1. Applying change.", "author": "jeqo", "createdAt": "2020-09-02T14:46:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDQ3MzgzMA=="}], "type": "inlineReview"}, {"oid": "4ec40063d629db053853b5c77caa535b5644edd9", "url": "https://github.com/apache/kafka/commit/4ec40063d629db053853b5c77caa535b5644edd9", "message": "fix exception comment case", "committedDate": "2020-09-01T18:13:40Z", "type": "commit"}, {"oid": "814ef3bcc82bc1241d5b732c2ce1e00c2308cb73", "url": "https://github.com/apache/kafka/commit/814ef3bcc82bc1241d5b732c2ce1e00c2308cb73", "message": "align var names and exceptions", "committedDate": "2020-09-02T08:59:18Z", "type": "commit"}, {"oid": "814ef3bcc82bc1241d5b732c2ce1e00c2308cb73", "url": "https://github.com/apache/kafka/commit/814ef3bcc82bc1241d5b732c2ce1e00c2308cb73", "message": "align var names and exceptions", "committedDate": "2020-09-02T08:59:18Z", "type": "forcePushed"}, {"oid": "58ce1d2d1eea3757548cd8975fe3213804d16b21", "url": "https://github.com/apache/kafka/commit/58ce1d2d1eea3757548cd8975fe3213804d16b21", "message": "fix check style", "committedDate": "2020-09-02T14:02:39Z", "type": "commit"}, {"oid": "f66f247a7e76907caebb44c33d1e562bd707f51a", "url": "https://github.com/apache/kafka/commit/f66f247a7e76907caebb44c33d1e562bd707f51a", "message": "fix check style", "committedDate": "2020-09-02T14:16:17Z", "type": "commit"}, {"oid": "1ccaa57d3e3e7953619c35933c257c416ecca01b", "url": "https://github.com/apache/kafka/commit/1ccaa57d3e3e7953619c35933c257c416ecca01b", "message": "range and all already available on kvstore", "committedDate": "2020-09-02T14:40:06Z", "type": "commit"}, {"oid": "273f612bfe98c58c40e77ec8a2d77e5eabdd2f18", "url": "https://github.com/apache/kafka/commit/273f612bfe98c58c40e77ec8a2d77e5eabdd2f18", "message": "add default impl", "committedDate": "2020-09-02T15:24:38Z", "type": "commit"}]}