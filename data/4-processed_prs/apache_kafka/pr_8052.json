{"pr_number": 8052, "pr_title": "MINOR: Improve EOS example exception handling", "pr_createdAt": "2020-02-06T18:58:12Z", "pr_url": "https://github.com/apache/kafka/pull/8052", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAyNDA2NQ==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r376024065", "bodyText": "I don't think this is the only case that we can abort a transaction. This only handles offset commit failures, but what about send failures?", "author": "hachikuji", "createdAt": "2020-02-06T19:03:52Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +139,40 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages(int messageProcessed, ConsumerRecords<Integer, String> records)\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            // Begin a new transaction session.\n+            producer.beginTransaction();\n+            for (ConsumerRecord<Integer, String> record : records) {\n+                // Process the record and send to downstream.\n+                ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                producer.send(customizedRecord);\n+            }\n+            Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+            for (TopicPartition topicPartition : consumer.assignment()) {\n+                positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+            }\n+            // Checkpoint the progress by sending offsets to group coordinator broker.\n+            // Under group mode, we must apply consumer group metadata for proper fencing.\n+            if (this.mode.equals(\"groupMode\")) {\n+                producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+            } else {\n+                producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+            }\n+\n+            // Finish the transaction. All sent records should be visible for consumption now.\n+            producer.commitTransaction();\n+            messageProcessed += records.count();\n+        } catch (CommitFailedException e) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTA5MA==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379269090", "bodyText": "Seems like we don't allow a way to set the instanceId in this example, so does it make sense to include FencedInstanceIdException?", "author": "hachikuji", "createdAt": "2020-02-14T06:31:23Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI5MTUxNQ==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379291515", "bodyText": "It should be configured at consumer level, I could add it to the consumer config.", "author": "abbccdda", "createdAt": "2020-02-14T07:56:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTA5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTIwNw==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379269207", "bodyText": "Why is InvalidOffsetException fatal?", "author": "hachikuji", "createdAt": "2020-02-14T06:31:52Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -121,46 +130,15 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         }\n \n         int messageProcessed = 0;\n-        boolean abortPreviousTransaction = false;\n         while (messageRemaining.get() > 0) {\n-            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n-            if (records.count() > 0) {\n-                try {\n-                    // Abort previous transaction if instructed.\n-                    if (abortPreviousTransaction) {\n-                        producer.abortTransaction();\n-                        // The consumer fetch position also needs to be reset.\n-                        resetToLastCommittedPositions(consumer);\n-                        abortPreviousTransaction = false;\n-                    }\n-                    // Begin a new transaction session.\n-                    producer.beginTransaction();\n-                    for (ConsumerRecord<Integer, String> record : records) {\n-                        // Process the record and send to downstream.\n-                        ProducerRecord<Integer, String> customizedRecord = transform(record);\n-                        producer.send(customizedRecord);\n-                    }\n-                    Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n-                    for (TopicPartition topicPartition : consumer.assignment()) {\n-                        positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n-                    }\n-                    // Checkpoint the progress by sending offsets to group coordinator broker.\n-                    // Under group mode, we must apply consumer group metadata for proper fencing.\n-                    if (this.mode.equals(\"groupMode\")) {\n-                        producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n-                    } else {\n-                        producer.sendOffsetsToTransaction(positions, consumerGroupId);\n-                    }\n-\n-                    // Finish the transaction. All sent records should be visible for consumption now.\n-                    producer.commitTransaction();\n-                    messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n-                }\n+            try {\n+                messageProcessed += processMessages();\n+            } catch (ProducerFencedException | FencedInstanceIdException | AuthorizationException |\n+                         AuthenticationException | UnsupportedVersionException |\n+                         UnsupportedForMessageFormatException | InvalidTopicException |\n+                         InvalidOffsetException e) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI5MTI1Ng==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379291256", "bodyText": "I guess it could be retriable.", "author": "abbccdda", "createdAt": "2020-02-14T07:55:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI2OTIwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDEwMg==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379270102", "bodyText": "I think we can leave WakeupException and InterruptException out of this. In both of these cases, we would probably just want the application to close. I think the main thing we want this example to show is the \"normal operating\" exceptions.", "author": "hachikuji", "createdAt": "2020-02-14T06:35:48Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+                } else {\n+                    producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+                }\n+\n+                // Finish the transaction. All sent records should be visible for consumption now.\n+                producer.commitTransaction();\n+                return records.count();\n+            }\n+        } catch (CommitFailedException | WakeupException | InterruptException | TimeoutException e) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTYxNjI1NA==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379616254", "bodyText": "Sounds good", "author": "abbccdda", "createdAt": "2020-02-14T19:53:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDEwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDI5MA==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379270290", "bodyText": "Could we do \"group mode\" only in this example? The example doesn't really extend to multiple instances otherwise.", "author": "hachikuji", "createdAt": "2020-02-14T06:36:39Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTYxNzY4Ng==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379617686", "bodyText": "Not sure I follow, we could manually compute the partitions to assign to for the standalone mode?", "author": "abbccdda", "createdAt": "2020-02-14T19:57:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MDI5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MTUxNg==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379271516", "bodyText": "Hmm.. Is it actually safe to abort following a TimeoutException? I think this would cause an illegal state error in the producer. To handle this correctly, the application should retry the commit.", "author": "hachikuji", "createdAt": "2020-02-14T06:42:05Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -170,6 +148,43 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n         latch.countDown();\n     }\n \n+    private int processMessages()\n+        throws ProducerFencedException, FencedInstanceIdException {\n+        try {\n+            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofMillis(200));\n+            if (records.count() > 0) {\n+                // Begin a new transaction session.\n+                producer.beginTransaction();\n+                for (ConsumerRecord<Integer, String> record : records) {\n+                    // Process the record and send to downstream.\n+                    ProducerRecord<Integer, String> customizedRecord = transform(record);\n+                    producer.send(customizedRecord);\n+                }\n+                Map<TopicPartition, OffsetAndMetadata> positions = new HashMap<>();\n+                for (TopicPartition topicPartition : consumer.assignment()) {\n+                    positions.put(topicPartition, new OffsetAndMetadata(consumer.position(topicPartition), null));\n+                }\n+                // Checkpoint the progress by sending offsets to group coordinator broker.\n+                // Under group mode, we must apply consumer group metadata for proper fencing.\n+                if (this.mode.equals(\"groupMode\")) {\n+                    producer.sendOffsetsToTransaction(positions, consumer.groupMetadata());\n+                } else {\n+                    producer.sendOffsetsToTransaction(positions, consumerGroupId);\n+                }\n+\n+                // Finish the transaction. All sent records should be visible for consumption now.\n+                producer.commitTransaction();\n+                return records.count();\n+            }\n+        } catch (CommitFailedException | WakeupException | InterruptException | TimeoutException e) {\n+            // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n+            producer.abortTransaction();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTYyMzY4NA==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r379623684", "bodyText": "Or we shouldn't handle the timeout, as we always rely on max_block to ensure the request is successful?", "author": "abbccdda", "createdAt": "2020-02-14T20:11:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTI3MTUxNg=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk0MTcwNg==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380941706", "bodyText": "For the purpose of understanding EOS, the main exceptions that are worth calling out are ProducerFencedException and FencedInstanceIdException. I would suggest we write the example like this:\ntry {\n   ...\n   producer.commitTransaction;\n} catch (ProducerFencedException e) {\n  throw KafkaException(\"The transactional.id $transactionalId has been claimed by another process\");\n} catch (FencedInstanceIdException e) {\n  throw KafkaException(\"The group.instance.id $instanceId has been claimed by another process\");\n} catch (KafkaException e) {\n  // If we have not been fenced, try to abort the transaction and continue. This will raise immediately\n  // if the producer has hit a fatal error.\n  producer.abortTransaction();\n}", "author": "hachikuji", "createdAt": "2020-02-18T21:20:55Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,12 +157,19 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n                 }\n+            } catch (CommitFailedException | InvalidOffsetException e) {\n+                // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n+                // Note that abort transaction call could also throw fatal exceptions such as producer fenced.\n+                producer.abortTransaction();\n+\n+                // The consumer fetch position also needs to be reset.\n+                resetToLastCommittedPositions(consumer);\n+            } catch (ProducerFencedException | FencedInstanceIdException | AuthorizationException |", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1OTE4Ng==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380959186", "bodyText": "How about this?\n// The consumer fetch position needs to be restored to the committed offset before the transaction started", "author": "hachikuji", "createdAt": "2020-02-18T21:56:21Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,13 +151,20 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();\n-                } catch (CommitFailedException e) {\n-                    // In case of a retriable exception, suggest aborting the ongoing transaction for correctness.\n-                    abortPreviousTransaction = true;\n-                } catch (ProducerFencedException | FencedInstanceIdException e) {\n-                    throw new KafkaException(\"Encountered fatal error during processing: \" + e.getMessage());\n                 }\n+            } catch (ProducerFencedException e) {\n+                throw new KafkaException(String.format(\"The transactional.id %s has been claimed by another process\", transactionalId));\n+            } catch (FencedInstanceIdException e) {\n+                throw new KafkaException(String.format(\"The group.instance.id %s has been claimed by another process\", groupInstanceId));\n+            } catch (KafkaException e) {\n+                // If we have not been fenced, try to abort the transaction and continue. This will raise immediately\n+                // if the producer has hit a fatal error.\n+                producer.abortTransaction();\n+\n+                // The consumer fetch position also needs to be reset.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2MjQ5OQ==", "url": "https://github.com/apache/kafka/pull/8052#discussion_r380962499", "bodyText": "I had a question before about the \"groupMode.\" Do we need to include this in the example? I think it would be fine to let this example use the latest recommended pattern and include a comment about it.\nAlso, could we have a helper for the boilerplate conversion to Map<TopicPartition, OffsetAndMetadata>` since it clutters up the core logic?", "author": "hachikuji", "createdAt": "2020-02-18T22:03:10Z", "path": "examples/src/main/java/kafka/examples/ExactlyOnceMessageProcessor.java", "diffHunk": "@@ -155,13 +151,20 @@ public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n                     // Finish the transaction. All sent records should be visible for consumption now.\n                     producer.commitTransaction();\n                     messageProcessed += records.count();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "e2903d337010fcd7e2c717343012f1bbc912c0a4", "url": "https://github.com/apache/kafka/commit/e2903d337010fcd7e2c717343012f1bbc912c0a4", "message": "make code clean", "committedDate": "2020-02-19T07:33:05Z", "type": "commit"}, {"oid": "d3053239c3c0ea377c5eed51b4be273e8fca3d43", "url": "https://github.com/apache/kafka/commit/d3053239c3c0ea377c5eed51b4be273e8fca3d43", "message": "add more exception types", "committedDate": "2020-02-19T07:33:05Z", "type": "commit"}, {"oid": "1c01fbe0211de5a19732d19fc4102162a437b76b", "url": "https://github.com/apache/kafka/commit/1c01fbe0211de5a19732d19fc4102162a437b76b", "message": "address comments", "committedDate": "2020-02-19T07:33:05Z", "type": "commit"}, {"oid": "5c1166f7f85393ed8db7732b876e9cea2b02d604", "url": "https://github.com/apache/kafka/commit/5c1166f7f85393ed8db7732b876e9cea2b02d604", "message": "avoid doing the separate func", "committedDate": "2020-02-19T07:33:05Z", "type": "commit"}, {"oid": "eed195dfeb3a10a04b4d33cb26d1e79cfed8b477", "url": "https://github.com/apache/kafka/commit/eed195dfeb3a10a04b4d33cb26d1e79cfed8b477", "message": "simply catch", "committedDate": "2020-02-19T07:33:05Z", "type": "commit"}, {"oid": "5b56d6c0d897b076b0cfefb87485ae9e87e42651", "url": "https://github.com/apache/kafka/commit/5b56d6c0d897b076b0cfefb87485ae9e87e42651", "message": "intellij recommendation", "committedDate": "2020-02-19T07:33:05Z", "type": "commit"}, {"oid": "0bb8234164e8c5cc561456fffbf1345a8e7fcb55", "url": "https://github.com/apache/kafka/commit/0bb8234164e8c5cc561456fffbf1345a8e7fcb55", "message": "remove standalone mode", "committedDate": "2020-02-19T07:33:05Z", "type": "commit"}, {"oid": "b1905ec71d61b8134284881f706306d1f14c122b", "url": "https://github.com/apache/kafka/commit/b1905ec71d61b8134284881f706306d1f14c122b", "message": "fix group mode", "committedDate": "2020-02-19T17:27:54Z", "type": "commit"}, {"oid": "b1905ec71d61b8134284881f706306d1f14c122b", "url": "https://github.com/apache/kafka/commit/b1905ec71d61b8134284881f706306d1f14c122b", "message": "fix group mode", "committedDate": "2020-02-19T17:27:54Z", "type": "forcePushed"}]}