{"pr_number": 8069, "pr_title": "KAFKA-9374: Make connector interactions asynchronous", "pr_createdAt": "2020-02-08T02:36:53Z", "pr_url": "https://github.com/apache/kafka/pull/8069", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzMzODg1MA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377338850", "bodyText": "It looks like you are reusing the executor that currently is used to run the WorkerTask. Since operations are async now, would it be possible to have startTask called on a different thread while connector is still being initialized or is transitioning to started state here?", "author": "ncliang", "createdAt": "2020-02-10T21:53:26Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -270,6 +273,8 @@ public boolean startConnector(\n             if (existing != null)\n                 throw new ConnectException(\"Connector with name \" + connName + \" already exists\");\n \n+            executor.submit(workerConnector);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM1MDIwOA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377350208", "bodyText": "As far as the API provided by the Worker class goes, yes, it is possible and there are no guards in place to prevent that from happening. However, at the moment both herders are well-behaved in that they do not instruct the Worker to start tasks until after the connector has finished starting as well. This is pretty simple to verify, and unlikely to change, since the herders wait for connectors to start before requesting task configurations from them, which in turn are required in order to actually go about starting tasks.", "author": "C0urante", "createdAt": "2020-02-10T22:17:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzMzODg1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzMzOTU0Ng==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377339546", "bodyText": "Probably a good idea to have timeout to not block indefinitely.", "author": "ncliang", "createdAt": "2020-02-10T21:54:56Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/resources/ConnectorPluginsResource.java", "diffHunk": "@@ -78,7 +79,11 @@ public ConfigInfos validateConfigs(\n             );\n         }\n \n-        return herder.validateConnectorConfig(connectorConfig);\n+        FutureCallback<ConfigInfos> validationCallback = new FutureCallback<>();\n+        herder.validateConnectorConfig(connectorConfig, validationCallback);\n+\n+        // TODO: Timeout?\n+        return validationCallback.get();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM1NjI4Mg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377356282", "bodyText": "Ack, addressed", "author": "C0urante", "createdAt": "2020-02-10T22:30:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzMzOTU0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzkwODc5OA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377908798", "bodyText": "It'd be great to minimize the number of changes lines, so maybe put the runnable logic as a separate method to eliminate the indentation-only changes.", "author": "rhauch", "createdAt": "2020-02-11T21:26:54Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/AbstractHerder.java", "diffHunk": "@@ -299,103 +304,115 @@ public StatusBackingStore statusBackingStore() {\n     }\n \n     @Override\n-    public ConfigInfos validateConnectorConfig(Map<String, String> connectorProps) {\n-        if (worker.configTransformer() != null) {\n-            connectorProps = worker.configTransformer().transform(connectorProps);\n-        }\n-        String connType = connectorProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n-        if (connType == null)\n-            throw new BadRequestException(\"Connector config \" + connectorProps + \" contains no connector type\");\n-\n-        Connector connector = getConnector(connType);\n-        org.apache.kafka.connect.health.ConnectorType connectorType;\n-        ClassLoader savedLoader = plugins().compareAndSwapLoaders(connector);\n-        try {\n-            ConfigDef baseConfigDef;\n-            if (connector instanceof SourceConnector) {\n-                baseConfigDef = SourceConnectorConfig.configDef();\n-                connectorType = org.apache.kafka.connect.health.ConnectorType.SOURCE;\n-            } else {\n-                baseConfigDef = SinkConnectorConfig.configDef();\n-                SinkConnectorConfig.validate(connectorProps);\n-                connectorType = org.apache.kafka.connect.health.ConnectorType.SINK;\n-            }\n-            ConfigDef enrichedConfigDef = ConnectorConfig.enrich(plugins(), baseConfigDef, connectorProps, false);\n-            Map<String, ConfigValue> validatedConnectorConfig = validateBasicConnectorConfig(\n-                    connector,\n-                    enrichedConfigDef,\n-                    connectorProps\n-            );\n-            List<ConfigValue> configValues = new ArrayList<>(validatedConnectorConfig.values());\n-            Map<String, ConfigKey> configKeys = new LinkedHashMap<>(enrichedConfigDef.configKeys());\n-            Set<String> allGroups = new LinkedHashSet<>(enrichedConfigDef.groups());\n-\n-            // do custom connector-specific validation\n-            Config config = connector.validate(connectorProps);\n-            if (null == config) {\n-                throw new BadRequestException(\n-                    String.format(\n-                        \"%s.validate() must return a Config that is not null.\",\n-                        connector.getClass().getName()\n-                    )\n-                );\n-            }\n-            ConfigDef configDef = connector.config();\n-            if (null == configDef) {\n-                throw new BadRequestException(\n-                    String.format(\n-                        \"%s.config() must return a ConfigDef that is not null.\",\n-                        connector.getClass().getName()\n-                    )\n-                );\n-            }\n-            configKeys.putAll(configDef.configKeys());\n-            allGroups.addAll(configDef.groups());\n-            configValues.addAll(config.configValues());\n-            ConfigInfos configInfos =  generateResult(connType, configKeys, configValues, new ArrayList<>(allGroups));\n-\n-            AbstractConfig connectorConfig = new AbstractConfig(new ConfigDef(), connectorProps);\n-            String connName = connectorProps.get(ConnectorConfig.NAME_CONFIG);\n-            ConfigInfos producerConfigInfos = null;\n-            ConfigInfos consumerConfigInfos = null;\n-            ConfigInfos adminConfigInfos = null;\n-            if (connectorType.equals(org.apache.kafka.connect.health.ConnectorType.SOURCE)) {\n-                producerConfigInfos = validateClientOverrides(connName,\n-                                                              ConnectorConfig.CONNECTOR_CLIENT_PRODUCER_OVERRIDES_PREFIX,\n-                                                              connectorConfig,\n-                                                              ProducerConfig.configDef(),\n-                                                              connector.getClass(),\n-                                                              connectorType,\n-                                                              ConnectorClientConfigRequest.ClientType.PRODUCER,\n-                                                              connectorClientConfigOverridePolicy);\n-                return mergeConfigInfos(connType, configInfos, producerConfigInfos);\n-            } else {\n-                consumerConfigInfos = validateClientOverrides(connName,\n-                                                              ConnectorConfig.CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX,\n-                                                              connectorConfig,\n-                                                              ProducerConfig.configDef(),\n-                                                              connector.getClass(),\n-                                                              connectorType,\n-                                                              ConnectorClientConfigRequest.ClientType.CONSUMER,\n-                                                              connectorClientConfigOverridePolicy);\n-                // check if topic for dead letter queue exists\n-                String topic = connectorProps.get(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG);\n-                if (topic != null && !topic.isEmpty()) {\n-                    adminConfigInfos = validateClientOverrides(connName,\n-                                                               ConnectorConfig.CONNECTOR_CLIENT_ADMIN_OVERRIDES_PREFIX,\n-                                                               connectorConfig,\n-                                                               ProducerConfig.configDef(),\n-                                                               connector.getClass(),\n-                                                               connectorType,\n-                                                               ConnectorClientConfigRequest.ClientType.ADMIN,\n-                                                               connectorClientConfigOverridePolicy);\n+    public void validateConnectorConfig(Map<String, String> connectorProps, Callback<ConfigInfos> callback) {\n+        connectorExecutor.submit(new Runnable() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzkxNzI5Mw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r377917293", "bodyText": "Ack, addressed within the AbstractHerder class and will see if similar changes can be made elsewhere.", "author": "C0urante", "createdAt": "2020-02-11T21:43:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzkwODc5OA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ5OTcxOA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r413499718", "bodyText": "This part still needs some work; it's in an inconsistent state because I modified Worker::startConnector to have no return value and instead communicate all success or failure of the connector startup through the callback, but haven't taken care of issues like possibly invoking the callback twice (once in this method, and once in the WorkerConnector instance), making sure to swap plugin classloaders at the right times, and preventing a possible race with the check to see if the connector already exists based on whether its name is present as a key in the connectors map.", "author": "C0urante", "createdAt": "2020-04-23T04:28:16Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -263,17 +267,20 @@ public boolean startConnector(\n                 Plugins.compareAndSwapLoaders(savedLoader);\n                 workerMetricsGroup.recordConnectorStartupFailure();\n                 statusListener.onFailure(connName, t);\n-                return false;\n+                onConnectorStateChange.onCompletion(t, null);\n+                return;\n             }\n+            workerConnector.transitionTo(initialState, onConnectorStateChange);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAxNjEyNg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r414016126", "bodyText": "No race is possible; connectors is a ConcurrentHashMap and its putIfAbsent method is atomic.\nWe can just move this line (workerConnector.transitionTo(initialState, onConnectorStateChange);) back into the try block; it may throw an exception, but the callback we pass in will never be invoked until the workerConnector instance is submitted to the executor, so there should be no risk of it being invoked twice.", "author": "C0urante", "createdAt": "2020-04-23T18:11:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ5OTcxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0Mjc0NA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r416342744", "bodyText": "why use locking if the variable is volatile and can change only to true during the lifetime of this object?", "author": "kkonstantine", "createdAt": "2020-04-28T05:45:13Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/HerderConnectorContext.java", "diffHunk": "@@ -16,30 +16,64 @@\n  */\n package org.apache.kafka.connect.runtime;\n \n-import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.errors.ConnectException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n /**\n  * ConnectorContext for use with a Herder\n  */\n-public class HerderConnectorContext implements ConnectorContext {\n+public class HerderConnectorContext implements CloseableConnectorContext {\n+\n+    private static final Logger log = LoggerFactory.getLogger(HerderConnectorContext.class);\n \n     private final AbstractHerder herder;\n     private final String connectorName;\n+    private volatile boolean closed;\n \n     public HerderConnectorContext(AbstractHerder herder, String connectorName) {\n         this.herder = herder;\n         this.connectorName = connectorName;\n+        this.closed = false;\n     }\n \n     @Override\n     public void requestTaskReconfiguration() {\n+        synchronized (this) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4MDY1Mg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r419580652", "bodyText": "Ah, good point. No need, will remove the locking.", "author": "C0urante", "createdAt": "2020-05-04T16:53:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0Mjc0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r416345143", "bodyText": "same question here and below about locking around a volatile variable. Is this the only reason to lock here? One would think so based on previous usage.", "author": "kkonstantine", "createdAt": "2020-04-28T05:51:25Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerConnector.java", "diffHunk": "@@ -266,31 +422,51 @@ public void close() {\n         @Override\n         public void onStartup(String connector) {\n             state = AbstractStatus.State.RUNNING;\n-            delegate.onStartup(connector);\n+            synchronized (this) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU5Mzk0OA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r419593948", "bodyText": "The locking here is to ensure that, upon being cancelled, the very last status update that this connector makes is to set its state to UNASSIGNED.\nThere's a potential race if its status is scheduled to be updated to, e.g., PAUSED and the check for cancelled goes through because it isn't set to true yet, then the task gets cancelled on another thread and its status gets set to UNASSIGNED, then the original thread proceeds with execution and sets the status to PAUSED.", "author": "C0urante", "createdAt": "2020-05-04T17:14:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkxOTcxMA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420919710", "bodyText": "I don't think locking buys you anything w/r/t to that. The producer#send in the status backing store is asynchronous. So what would describe above can happen anyways, regardless of whether you lock this object.\nOf course, if it wasn't asynchronous things would be much worse. A bottleneck would be created by the lock, waiting for the send to finish in every locked block, so that's not an option. Wdyt?\nThat's what I see at the high level without spending to much time on it, but see if you can check this assumption and we can return to this question.", "author": "kkonstantine", "createdAt": "2020-05-06T16:19:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkzMTI3Mw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420931273", "bodyText": "AFAICT the underlying KafkaBasedLog used for the status store does provide ordering guarantees: \n  \n    \n      kafka/connect/runtime/src/main/java/org/apache/kafka/connect/util/KafkaBasedLog.java\n    \n    \n        Lines 242 to 249\n      in\n      1d43803\n    \n    \n    \n    \n\n        \n          \n           private Producer<K, V> createProducer() { \n        \n\n        \n          \n               // Always require producer acks to all to ensure durable writes \n        \n\n        \n          \n               producerConfigs.put(ProducerConfig.ACKS_CONFIG, \"all\"); \n        \n\n        \n          \n            \n        \n\n        \n          \n               // Don't allow more than one in-flight request to prevent reordering on retry (if enabled) \n        \n\n        \n          \n               producerConfigs.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 1); \n        \n\n        \n          \n               return new KafkaProducer<>(producerConfigs); \n        \n\n        \n          \n           }", "author": "C0urante", "createdAt": "2020-05-06T16:36:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5ODU2NA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437798564", "bodyText": "Thanks for checking the underlying implementation @C0urante .\nThat takes us to my earlier concern about this operation potentially blocking for too long to be in a synchronized block. And the potential of blocking does not have to do with acknowledging that the record was written only. The producer call has a metadata update call too.\nGoing over the uses of KafkaBasedLog in Connect, I didn't find an example where we have KafkaBasedLog#send running  in mutual exclusion. Contrary, similar concerns are probably the reason why we call OffsetStorageWriter#doFlush outside the synchronized block in WorkerSourceTask.\nI think we might be able to live with a rare race condition as the one you described, in order to avoid introducing unintended side-effects due to locking.", "author": "kkonstantine", "createdAt": "2020-06-10T00:44:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4MjU5OQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438282599", "bodyText": "I'd rather not knowingly allow a race here if possible, and I think it should be fine to synchronize here, but if we do go that route I can file a pre-emptive jira ticket and link to it in the source code so that anyone who does run into it has at least some chance of understanding what's going on (and possibly refactoring the framework to improve things).\nThe framework does synchronize around all status updates for tasks, as you can see in the WorkerTask class:\nTaskStatus.Listener::onStartup: \n  \n    \n      kafka/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java\n    \n    \n        Lines 172 to 182\n      in\n      0f68dc7\n    \n    \n    \n    \n\n        \n          \n           synchronized (this) { \n        \n\n        \n          \n               if (stopping) \n        \n\n        \n          \n                   return; \n        \n\n        \n          \n            \n        \n\n        \n          \n               if (targetState == TargetState.PAUSED) { \n        \n\n        \n          \n                   onPause(); \n        \n\n        \n          \n                   if (!awaitUnpause()) return; \n        \n\n        \n          \n               } \n        \n\n        \n          \n            \n        \n\n        \n          \n               statusListener.onStartup(id); \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nTaskStatus.Listener::onShutdown: \n  \n    \n      kafka/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java\n    \n    \n        Lines 195 to 202\n      in\n      0f68dc7\n    \n    \n    \n    \n\n        \n          \n           synchronized (this) { \n        \n\n        \n          \n               triggerStop(); \n        \n\n        \n          \n            \n        \n\n        \n          \n               // if we were cancelled, skip the status update since the task may have already been \n        \n\n        \n          \n               // started somewhere else \n        \n\n        \n          \n               if (!cancelled) \n        \n\n        \n          \n                   statusListener.onShutdown(id); \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nTaskStatus.Listener::onFailure: \n  \n    \n      kafka/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java\n    \n    \n        Lines 206 to 213\n      in\n      0f68dc7\n    \n    \n    \n    \n\n        \n          \n           synchronized (this) { \n        \n\n        \n          \n               triggerStop(); \n        \n\n        \n          \n            \n        \n\n        \n          \n               // if we were cancelled, skip the status update since the task may have already been \n        \n\n        \n          \n               // started somewhere else \n        \n\n        \n          \n               if (!cancelled) \n        \n\n        \n          \n                   statusListener.onFailure(id, t); \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nTaskStatus.Listener::onPause: \n  \n    \n      kafka/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java\n    \n    \n        Lines 216 to 218\n      in\n      0f68dc7\n    \n    \n    \n    \n\n        \n          \n           protected synchronized void onPause() { \n        \n\n        \n          \n               statusListener.onPause(id); \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nTaskStatus.Listener::onResume: \n  \n    \n      kafka/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerTask.java\n    \n    \n        Lines 220 to 222\n      in\n      0f68dc7\n    \n    \n    \n    \n\n        \n          \n           protected synchronized void onResume() { \n        \n\n        \n          \n               statusListener.onResume(id); \n        \n\n        \n          \n           }", "author": "C0urante", "createdAt": "2020-06-10T17:12:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI5NzQ3NA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438297474", "bodyText": "Yeah, good point. I've been on the fence here, because the calls might block one way or the other anyway. Good thing is that the locking is per connector instance.\nLet's keep the synchronization. We can always return with some performance benchmarking on the topic and revisit locking for connectors and tasks if we can afford to do that.\nBut let's follow the synchronized method style (e.g. onPause, onResume in your examples above) if the synchronization applies to the whole method.", "author": "kkonstantine", "createdAt": "2020-06-10T17:37:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwNDU5MQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438304591", "bodyText": "Sounds good, will address the synchronization style in the next commit.", "author": "C0urante", "createdAt": "2020-06-10T17:49:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM0NTE0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4NzA0MA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r417687040", "bodyText": "I don't think this is worth backporting before AK 2.0, and maybe not even as far back. Given that, I'd suggest using lambda notation whenever a new Runnable is needed to avoid the Runnable declaration boilerplate.", "author": "kkonstantine", "createdAt": "2020-04-30T00:22:17Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -191,32 +192,71 @@ public synchronized void putConnectorConfig(String connName,\n                                                 boolean allowReplace,\n                                                 final Callback<Created<ConnectorInfo>> callback) {\n         try {\n-            if (maybeAddConfigErrors(validateConnectorConfig(config), callback)) {\n+            validateConnectorConfig(config, new Callback<ConfigInfos>() {\n+                @Override\n+                public void onCompletion(Throwable error, ConfigInfos configInfos) {\n+                    if (error != null) {\n+                        callback.onCompletion(error, null);\n+                        return;\n+                    }\n+\n+                    requestExecutorService.submit(\n+                        () -> putConnectorConfig(connName, config, allowReplace, callback, configInfos)\n+                    );\n+                }\n+            });\n+        } catch (Throwable t) {\n+            callback.onCompletion(t, null);\n+        }\n+    }\n+\n+    private synchronized void putConnectorConfig(String connName,\n+                                                 final Map<String, String> config,\n+                                                 boolean allowReplace,\n+                                                 final Callback<Created<ConnectorInfo>> callback,\n+                                                 ConfigInfos configInfos) {\n+        try {\n+            if (maybeAddConfigErrors(configInfos, callback)) {\n                 return;\n             }\n \n-            boolean created = false;\n+            final boolean created;\n             if (configState.contains(connName)) {\n                 if (!allowReplace) {\n                     callback.onCompletion(new AlreadyExistsException(\"Connector \" + connName + \" already exists\"), null);\n                     return;\n                 }\n-                worker.stopConnector(connName);\n+                worker.stopAndAwaitConnector(connName);\n+                created = false;\n             } else {\n                 created = true;\n             }\n \n             configBackingStore.putConnectorConfig(connName, config);\n \n-            if (!startConnector(connName)) {\n-                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connName), null);\n-                return;\n-            }\n+            Callback<TargetState> onStart = new Callback<TargetState>() {\n+                @Override\n+                public void onCompletion(Throwable error, TargetState result) {\n+                    if (error != null) {\n+                        callback.onCompletion(error, null);\n+                        return;\n+                    }\n+\n+                    requestExecutorService.submit(new Runnable() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4MzM2MA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r419583360", "bodyText": "\ud83d\udc4d Ack, will change", "author": "C0urante", "createdAt": "2020-05-04T16:57:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4NzA0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4NTAwNQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r419585005", "bodyText": "In order to avoid mixing style, do you think it'd be best to replace all instances of Runnable construction with lambda notation in files changed by this PR?", "author": "C0urante", "createdAt": "2020-05-04T17:00:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4NzA0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU0MTgzNg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420541836", "bodyText": "\ud83d\udc4d", "author": "gharris1727", "createdAt": "2020-05-06T04:42:20Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -246,15 +251,16 @@ public boolean startConnector(\n             final WorkerConnector workerConnector;\n             ClassLoader savedLoader = plugins.currentThreadLoader();\n             try {\n+                final String connClass = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1MDc0OA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420550748", "bodyText": "nit: seems unnecessary?\nsimilar for State.FAILED below.", "author": "gharris1727", "createdAt": "2020-05-06T05:21:04Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerConnector.java", "diffHunk": "@@ -166,27 +244,105 @@ private void pause() {\n         }\n     }\n \n+    /**\n+     * Stop this connector. This method does not block, it only triggers shutdown. Use\n+     * #{@link #awaitShutdown} to block until completion.\n+     */\n     public void shutdown() {\n+        synchronized (this) {\n+            log.info(\"Scheduled shutdown for {}\", this);\n+            stopping = true;\n+            notify();\n+        }\n+    }\n+\n+    void doShutdown() {\n         try {\n             if (state == State.STARTED)\n                 connector.stop();\n-            this.state = State.STOPPED;\n+            WorkerConnector.this.state = State.STOPPED;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkwMDQ2Nw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420900467", "bodyText": "Mmm, good catch. Think this might have been left behind from a previous iteration of the PR.", "author": "C0urante", "createdAt": "2020-05-06T15:51:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1MDc0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NTQzNg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420555436", "bodyText": "Is it possible to trigger this log statement now?\nShould this be moved into the callback?", "author": "gharris1727", "createdAt": "2020-05-06T05:40:10Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1182,28 +1251,47 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // newState should be equal to initialState, but use it just in case\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                    new Callable<Void>() {\n+                        @Override\n+                        public Void call() {\n+                            // Request configuration since this could be a brand new connector. However, also only update those\n+                            // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                            // just restoring an existing connector.\n+                            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                            callback.onCompletion(null, null);\n+                            return null;\n+                        }\n+                    },\n+                    forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(connectorName, (error, result) -> { });\n                 } catch (Throwable t) {\n                     log.error(\"Couldn't instantiate connector \" + connectorName + \" because it has an invalid connector \" +", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkwNTczNw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420905737", "bodyText": "Since we're catching Throwable here, yes, I do think it's still technically possible to trigger the log statement. But you're definitely right that the actual content of that message should be moved into the callback; thinking the log message here in the catch block can be made even scarier since if something goes wrong here that's really unexpected.", "author": "C0urante", "createdAt": "2020-05-06T15:58:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NTQzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NjY0OQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420556649", "bodyText": "If only time was mocked.", "author": "gharris1727", "createdAt": "2020-05-06T05:44:42Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/resources/ConnectorsResource.java", "diffHunk": "@@ -82,6 +82,9 @@\n     // we need to consider all possible scenarios this could fail. It might be ok to fail with a timeout in rare cases,\n     // but currently a worker simply leaving the group can take this long as well.\n     public static final long REQUEST_TIMEOUT_MS = 90 * 1000;\n+    // Mutable for integration testing; otherwise, some tests would take at least REQUEST_TIMEOUT_MS", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkxODA3OA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420918078", "bodyText": "I mean, we have stuff to do that (the Time interface and the MockTime and SystemTime implementations of it) but it doesn't seem like it'd be easy to leverage here, since the request timeout is performed by a call to FutureCallback::get, which relies on ShutdownLatch::await under the hood.\nAFAIK we don't have a great way to mock shutdown latch timeouts, but if we do, it might not be so bad to do that instead of this hack here.", "author": "C0urante", "createdAt": "2020-05-06T16:16:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NjY0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4NTAwMw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421085003", "bodyText": "Yeah, I don't think that it's worth changing everything just to mock time, especially if requires us to change the functionality.\nSGTM.", "author": "gharris1727", "createdAt": "2020-05-06T20:53:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NjY0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1Njc0Nw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420556747", "bodyText": "Can this be knocked down to protected / package-private?", "author": "gharris1727", "createdAt": "2020-05-06T05:45:06Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/resources/ConnectorsResource.java", "diffHunk": "@@ -97,6 +100,15 @@ public ConnectorsResource(Herder herder, WorkerConfig config) {\n         isTopicTrackingResetDisabled = !config.getBoolean(TOPIC_TRACKING_ALLOW_RESET_CONFIG);\n     }\n \n+    // For testing purposes only\n+    public static void setRequestTimeout(long requestTimeoutMs) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkyMDE2MQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420920161", "bodyText": "Don't think so :(\nRight now it's really only useful to call this from an integration test, and those all live in a different package. We could move to a different package but it seems a little funky to put one of our integration tests in a different place from all the others, or to move all of our integration tests into the seemingly-arbitrary org.apache.kafka.connect.runtime.rest.resources package.", "author": "C0urante", "createdAt": "2020-05-06T16:19:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1Njc0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NzM3Ng==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420557376", "bodyText": "All of the call sites for this function have synchronization blocks, can you just add the synchronized keyword to the method instead?", "author": "gharris1727", "createdAt": "2020-05-06T05:47:35Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -191,32 +192,61 @@ public synchronized void putConnectorConfig(String connName,\n                                                 boolean allowReplace,\n                                                 final Callback<Created<ConnectorInfo>> callback) {\n         try {\n-            if (maybeAddConfigErrors(validateConnectorConfig(config), callback)) {\n+            validateConnectorConfig(config, (error, configInfos) -> {\n+                if (error != null) {\n+                    callback.onCompletion(error, null);\n+                    return;\n+                }\n+\n+                requestExecutorService.submit(\n+                    () -> putConnectorConfig(connName, config, allowReplace, callback, configInfos)\n+                );\n+            });\n+        } catch (Throwable t) {\n+            callback.onCompletion(t, null);\n+        }\n+    }\n+\n+    private synchronized void putConnectorConfig(String connName,\n+                                                 final Map<String, String> config,\n+                                                 boolean allowReplace,\n+                                                 final Callback<Created<ConnectorInfo>> callback,\n+                                                 ConfigInfos configInfos) {\n+        try {\n+            if (maybeAddConfigErrors(configInfos, callback)) {\n                 return;\n             }\n \n-            boolean created = false;\n+            final boolean created;\n             if (configState.contains(connName)) {\n                 if (!allowReplace) {\n                     callback.onCompletion(new AlreadyExistsException(\"Connector \" + connName + \" already exists\"), null);\n                     return;\n                 }\n-                worker.stopConnector(connName);\n+                worker.stopAndAwaitConnector(connName);\n+                created = false;\n             } else {\n                 created = true;\n             }\n \n             configBackingStore.putConnectorConfig(connName, config);\n \n-            if (!startConnector(connName)) {\n-                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connName), null);\n-                return;\n-            }\n+            // startConnector(connName, onStart);\n+            startConnector(connName, (error, result) -> {\n+                if (error != null) {\n+                    callback.onCompletion(error, null);\n+                    return;\n+                }\n \n-            updateConnectorTasks(connName);\n-            callback.onCompletion(null, new Created<>(created, createConnectorInfo(connName)));\n-        } catch (ConnectException e) {\n-            callback.onCompletion(e, null);\n+                requestExecutorService.submit(() -> {\n+                    synchronized (this) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk2Mzg4MQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r420963881", "bodyText": "Ah yeah, done. Could have sworn I was getting SpotBugs complaints at one point when I tried that, but it seems to work now.", "author": "C0urante", "createdAt": "2020-05-06T17:26:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU1NzM3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA3OTg4OQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421079889", "bodyText": "nit: leftover comments", "author": "gharris1727", "createdAt": "2020-05-06T20:43:49Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -239,9 +236,10 @@ private synchronized void putConnectorConfig(String connName,\n                 }\n \n                 requestExecutorService.submit(() -> {\n-                    synchronized (this) {\n-                        updateConnectorTasks(connName);\n-                    }\n+                    updateConnectorTasks(connName);\n+                    // synchronized (this) {\n+                    //     updateConnectorTasks(connName);\n+                    // }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA5MTAzNQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421091035", "bodyText": "\ud83e\udd26\u200d\u2640\ufe0f thanks", "author": "C0urante", "createdAt": "2020-05-06T21:04:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA3OTg4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4MDE0NQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421080145", "bodyText": "nit: leftover comments", "author": "gharris1727", "createdAt": "2020-05-06T20:44:18Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -412,9 +407,10 @@ public void onConnectorTargetStateChange(String connector) {\n \n                     if (newState == TargetState.STARTED) {\n                         requestExecutorService.submit(() -> {\n-                            synchronized (StandaloneHerder.this) {\n-                                updateConnectorTasks(connector);\n-                            }\n+                            updateConnectorTasks(connector);\n+                            // synchronized (StandaloneHerder.this) {\n+                            //     updateConnectorTasks(connector);\n+                            // }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4MzE2NQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421083165", "bodyText": "The caller of this function doesn't need to block on starting the connector, but I think it should log errors inside of the callback. Otherwise they're going to get swallowed.", "author": "gharris1727", "createdAt": "2020-05-06T20:49:50Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -536,20 +561,37 @@ private void processConnectorConfigUpdates(Set<String> connectorConfigUpdates) {\n         // If we only have connector config updates, we can just bounce the updated connectors that are\n         // currently assigned to this worker.\n         Set<String> localConnectors = assignment == null ? Collections.<String>emptySet() : new HashSet<>(assignment.connectors());\n+        log.trace(\n+            \"Processing connector config updates; \"\n+                + \"currently-owned connectors are {}, and to-be-updated connectors are {}\",\n+            localConnectors,\n+            connectorConfigUpdates\n+        );\n         for (String connectorName : connectorConfigUpdates) {\n-            if (!localConnectors.contains(connectorName))\n+            if (!localConnectors.contains(connectorName)) {\n+                log.trace(\n+                    \"Skipping config update for connector {} as it is not owned by this worker\",\n+                    connectorName\n+                );\n                 continue;\n+            }\n             boolean remains = configState.contains(connectorName);\n             log.info(\"Handling connector-only config update by {} connector {}\",\n                     remains ? \"restarting\" : \"stopping\", connectorName);\n-            worker.stopConnector(connectorName);\n+            worker.stopAndAwaitConnector(connectorName);\n             // The update may be a deletion, so verify we actually need to restart the connector\n             if (remains)\n-                startConnector(connectorName);\n+                startConnector(connectorName, (error, result) -> { });", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA5MTMwNQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421091305", "bodyText": "Agh, you're right. Thought I'd committed that but apparently not. Will add.", "author": "C0urante", "createdAt": "2020-05-06T21:04:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4MzE2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4MzQzMg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r421083432", "bodyText": "This needs a log statement to avoid swallowing the exception silently.", "author": "gharris1727", "createdAt": "2020-05-06T20:50:22Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1182,31 +1245,49 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // Use newState here in case the connector has been paused right after being created\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                    new Callable<Void>() {\n+                        @Override\n+                        public Void call() {\n+                            // Request configuration since this could be a brand new connector. However, also only update those\n+                            // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                            // just restoring an existing connector.\n+                            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                            callback.onCompletion(null, null);\n+                            return null;\n+                        }\n+                    },\n+                    forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(connectorName, (error, result) -> { });", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyMTkxMQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437221911", "bodyText": "Any reason not to use AutoCloseable instead?", "author": "kkonstantine", "createdAt": "2020-06-09T08:18:15Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/CloseableConnectorContext.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime;\n+\n+import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.errors.ConnectException;\n+\n+import java.io.Closeable;\n+\n+public interface CloseableConnectorContext extends ConnectorContext, Closeable {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI3OTU2MA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438279560", "bodyText": "It's not used in a try-with-resources block right now, and it's pretty unlikely that it will be. This also follows the precedent with the CloseableOffsetStorageReader class, which is also not AutoCloseable.\nNot really attached either way, happy to change to AutoCloseable if there's a reason to.", "author": "C0urante", "createdAt": "2020-06-10T17:06:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyMTkxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI5ODk2OQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438298969", "bodyText": "It's more that Closeable is the legacy interface and we don't have strict requirements on throwing IOException or this call being idempotent.", "author": "kkonstantine", "createdAt": "2020-06-10T17:39:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyMTkxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyOTQ3Nw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437229477", "bodyText": "not sure what's the advantage of bringing this log message further down here. Searching the logs for Stopping connector will miss the cases of \"unowned\" connectors, making debugging potentially more challenging.", "author": "kkonstantine", "createdAt": "2020-06-09T08:30:24Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -356,40 +390,96 @@ public boolean isSinkConnector(String connName) {\n         return result;\n     }\n \n-    private void stopConnectors() {\n-        // Herder is responsible for stopping connectors. This is an internal method to sequentially\n-        // stop connectors that have not explicitly been stopped.\n-        for (String connector: connectors.keySet())\n-            stopConnector(connector);\n-    }\n-\n     /**\n      * Stop a connector managed by this worker.\n      *\n      * @param connName the connector name.\n-     * @return true if the connector belonged to this worker and was successfully stopped.\n      */\n-    public boolean stopConnector(String connName) {\n+    private void stopConnector(String connName) {\n         try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n-            log.info(\"Stopping connector {}\", connName);\n-\n-            WorkerConnector workerConnector = connectors.remove(connName);\n+            WorkerConnector workerConnector = connectors.get(connName);\n             if (workerConnector == null) {\n                 log.warn(\"Ignoring stop request for unowned connector {}\", connName);\n-                return false;\n+                return;\n             }\n \n+            log.info(\"Stopping connector {}\", connName);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4NDk3Nw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438284977", "bodyText": "My original thinking was that it doesn't make sense to log that we're stopping a connector, even if we log immediately afterward that we're not actually stopping that connector since we don't own it.\nOn second thought, probably best to keep it as-is just to avoid complicating things for people who are used to reading these log lines in succession. I'll revert this change.", "author": "C0urante", "createdAt": "2020-06-10T17:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyOTQ3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwMDkzNw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438300937", "bodyText": "if/else branching when parsing logs can be tricky. The log indicates that the worker is indeed in the process of stopping a connector that was requested. The next log message will indicate that it didn't actually own the requested connector.", "author": "kkonstantine", "createdAt": "2020-06-10T17:43:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzIyOTQ3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMTkxNQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437911915", "bodyText": "I think I've noticed that you tab size when lines are wrapped is not what we've been using. As you see below, this indentation corresponds to two tabs (8 characters). Only exception I've found that is enforced by checkstyle is when a lambda is wrapped. But other than than we've been using 2 tabs for multiline statements.", "author": "kkonstantine", "createdAt": "2020-06-10T07:24:11Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -239,38 +243,59 @@ public void stop() {\n      * @param ctx the connector runtime context.\n      * @param statusListener a listener for the runtime status transitions of the connector.\n      * @param initialState the initial state of the connector.\n-     * @return true if the connector started successfully.\n+     * @param onConnectorStateChange invoked when the initial state change of the connector is completed\n      */\n-    public boolean startConnector(\n+    public void startConnector(\n             String connName,\n             Map<String, String> connProps,\n-            ConnectorContext ctx,\n+            CloseableConnectorContext ctx,\n             ConnectorStatus.Listener statusListener,\n-            TargetState initialState\n+            TargetState initialState,\n+            Callback<TargetState> onConnectorStateChange\n     ) {\n         try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n-            if (connectors.containsKey(connName))\n-                throw new ConnectException(\"Connector with name \" + connName + \" already exists\");\n+            if (connectors.containsKey(connName)) {\n+                onConnectorStateChange.onCompletion(\n+                    new ConnectException(\"Connector with name \" + connName + \" already exists\"),\n+                    null\n+                );\n+                return;\n+            }\n \n             final WorkerConnector workerConnector;\n             ClassLoader savedLoader = plugins.currentThreadLoader();\n             try {\n                 // By the time we arrive here, CONNECTOR_CLASS_CONFIG has been validated already\n                 // Getting this value from the unparsed map will allow us to instantiate the\n                 // right config (source or sink)\n-                final String connClassProp = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n-                log.info(\"Creating connector {} of type {}\", connName, connClassProp);\n-                final Connector connector = plugins.newConnector(connClassProp);\n+                final String connClass = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n+                ClassLoader connectorLoader = plugins.delegatingLoader().connectorLoader(connClass);\n+                savedLoader = Plugins.compareAndSwapLoaders(connectorLoader);\n+\n+                log.info(\"Creating connector {} of type {}\", connName, connClass);\n+                final Connector connector = plugins.newConnector(connClass);\n+                final ConnectorConfig connConfig = ConnectUtils.isSinkConnector(connector)\n+                    ? new SinkConnectorConfig(plugins, connProps)\n+                    : new SourceConnectorConfig(plugins, connProps, config.topicCreationEnable());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMyMzAzNQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438323035", "bodyText": "Ack, will try to make the adjustment. May miss a few places just due to the size of the PR.", "author": "C0urante", "createdAt": "2020-06-10T18:21:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMTkxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkxMjkzOA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437912938", "bodyText": "nit: keeping the previous format of grouping arguments in a few lines matches what we have in other versions. This change was brought in when the OffsetStorageReader PR was merged but from the diff you can see that it was changed back.", "author": "kkonstantine", "createdAt": "2020-06-10T07:26:05Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -239,38 +243,59 @@ public void stop() {\n      * @param ctx the connector runtime context.\n      * @param statusListener a listener for the runtime status transitions of the connector.\n      * @param initialState the initial state of the connector.\n-     * @return true if the connector started successfully.\n+     * @param onConnectorStateChange invoked when the initial state change of the connector is completed\n      */\n-    public boolean startConnector(\n+    public void startConnector(\n             String connName,\n             Map<String, String> connProps,\n-            ConnectorContext ctx,\n+            CloseableConnectorContext ctx,\n             ConnectorStatus.Listener statusListener,\n-            TargetState initialState\n+            TargetState initialState,\n+            Callback<TargetState> onConnectorStateChange\n     ) {\n         try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n-            if (connectors.containsKey(connName))\n-                throw new ConnectException(\"Connector with name \" + connName + \" already exists\");\n+            if (connectors.containsKey(connName)) {\n+                onConnectorStateChange.onCompletion(\n+                    new ConnectException(\"Connector with name \" + connName + \" already exists\"),\n+                    null\n+                );\n+                return;\n+            }\n \n             final WorkerConnector workerConnector;\n             ClassLoader savedLoader = plugins.currentThreadLoader();\n             try {\n                 // By the time we arrive here, CONNECTOR_CLASS_CONFIG has been validated already\n                 // Getting this value from the unparsed map will allow us to instantiate the\n                 // right config (source or sink)\n-                final String connClassProp = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n-                log.info(\"Creating connector {} of type {}\", connName, connClassProp);\n-                final Connector connector = plugins.newConnector(connClassProp);\n+                final String connClass = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n+                ClassLoader connectorLoader = plugins.delegatingLoader().connectorLoader(connClass);\n+                savedLoader = Plugins.compareAndSwapLoaders(connectorLoader);\n+\n+                log.info(\"Creating connector {} of type {}\", connName, connClass);\n+                final Connector connector = plugins.newConnector(connClass);\n+                final ConnectorConfig connConfig = ConnectUtils.isSinkConnector(connector)\n+                    ? new SinkConnectorConfig(plugins, connProps)\n+                    : new SourceConnectorConfig(plugins, connProps, config.topicCreationEnable());\n+\n                 final OffsetStorageReader offsetReader = new OffsetStorageReaderImpl(\n-                        offsetBackingStore, connName, internalKeyConverter, internalValueConverter);\n-                workerConnector = new WorkerConnector(connName, connector, ctx, metrics, statusListener, offsetReader);\n-                final ConnectorConfig connConfig = workerConnector.isSinkConnector()\n-                        ? new SinkConnectorConfig(plugins, connProps)\n-                        : new SourceConnectorConfig(plugins, connProps, config.topicCreationEnable());\n+                    offsetBackingStore,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyMDYzNg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437920636", "bodyText": "if you endup locking the whole method, there's no reason to use a block, you can use synchronized on the method. Applies here and any similar method.", "author": "kkonstantine", "createdAt": "2020-06-10T07:39:02Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerConnector.java", "diffHunk": "@@ -165,27 +241,115 @@ private void pause() {\n         }\n     }\n \n+    /**\n+     * Stop this connector. This method does not block, it only triggers shutdown. Use\n+     * #{@link #awaitShutdown} to block until completion.\n+     */\n     public void shutdown() {\n+        synchronized (this) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyNTI1Mw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437925253", "bodyText": "I wonder if we should create a jira issue instead", "author": "kkonstantine", "createdAt": "2020-06-10T07:45:10Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -337,6 +340,12 @@ public void tick() {\n         }\n \n         // Process any external requests\n+        // TODO: Some of these can be performed concurrently or even optimized away entirely.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyNjAzNQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437926035", "bodyText": "nit: our style allows the first line to be with the log statement (see your other trace call below)", "author": "kkonstantine", "createdAt": "2020-06-10T07:46:32Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -414,31 +423,44 @@ public void tick() {\n \n         // Let the group take any actions it needs to\n         try {\n+            log.trace(", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyODE1OA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437928158", "bodyText": "do we know how often this message or the one below would be printed?", "author": "kkonstantine", "createdAt": "2020-06-10T07:50:06Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -486,6 +509,10 @@ private synchronized boolean updateConfigsWithEager(AtomicReference<Set<String>>\n                     connectorTargetStateChanges = new HashSet<>();\n                 }\n             }\n+        } else {\n+            log.trace(\"Skipping config updates with eager rebalancing \"", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI5ODM5Mg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438298392", "bodyText": "Not sure how often but I can think of some scenarios that would cause it:\n\nSession key is updated\nThe number of workers in the cluster changes\n\nWhy do you ask?", "author": "C0urante", "createdAt": "2020-06-10T17:38:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyODE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQyNjg4NQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438426885", "bodyText": "I'm trying to understand if it would overwhelm the logs at the TRACE level", "author": "kkonstantine", "createdAt": "2020-06-10T21:47:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyODE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1NTEzNg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438455136", "bodyText": "Ahh, gotcha. It'll definitely make them a bit noisier, but this line will only ever be reached once per herder tick, which already produces several other messages at a higher level.", "author": "C0urante", "createdAt": "2020-06-10T23:07:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyODE1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkyOTg5MQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437929891", "bodyText": "nit; multiline splitting is a bit unusual", "author": "kkonstantine", "createdAt": "2020-06-10T07:53:02Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -540,20 +572,45 @@ private void processConnectorConfigUpdates(Set<String> connectorConfigUpdates) {\n         // If we only have connector config updates, we can just bounce the updated connectors that are\n         // currently assigned to this worker.\n         Set<String> localConnectors = assignment == null ? Collections.<String>emptySet() : new HashSet<>(assignment.connectors());\n+        log.trace(", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzMDcwNA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437930704", "bodyText": "probably the style followed in worker.setTargetState is preferable", "author": "kkonstantine", "createdAt": "2020-06-10T07:54:29Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -540,20 +572,45 @@ private void processConnectorConfigUpdates(Set<String> connectorConfigUpdates) {\n         // If we only have connector config updates, we can just bounce the updated connectors that are\n         // currently assigned to this worker.\n         Set<String> localConnectors = assignment == null ? Collections.<String>emptySet() : new HashSet<>(assignment.connectors());\n+        log.trace(\n+            \"Processing connector config updates; \"\n+                + \"currently-owned connectors are {}, and to-be-updated connectors are {}\",\n+            localConnectors,\n+            connectorConfigUpdates\n+        );\n         for (String connectorName : connectorConfigUpdates) {\n-            if (!localConnectors.contains(connectorName))\n+            if (!localConnectors.contains(connectorName)) {\n+                log.trace(\n+                    \"Skipping config update for connector {} as it is not owned by this worker\",\n+                    connectorName\n+                );\n                 continue;\n+            }\n             boolean remains = configState.contains(connectorName);\n             log.info(\"Handling connector-only config update by {} connector {}\",\n                     remains ? \"restarting\" : \"stopping\", connectorName);\n-            worker.stopConnector(connectorName);\n+            worker.stopAndAwaitConnector(connectorName);\n             // The update may be a deletion, so verify we actually need to restart the connector\n-            if (remains)\n-                startConnector(connectorName);\n+            if (remains) {\n+                startConnector(", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNzA0MA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r437937040", "bodyText": "this can also be written in a less verbose way (see also comment above)", "author": "kkonstantine", "createdAt": "2020-06-10T08:05:36Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1221,31 +1297,56 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // Use newState here in case the connector has been paused right after being created\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                    new Callable<Void>() {\n+                        @Override\n+                        public Void call() {\n+                            // Request configuration since this could be a brand new connector. However, also only update those\n+                            // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                            // just restoring an existing connector.\n+                            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                            callback.onCompletion(null, null);\n+                            return null;\n+                        }\n+                    },\n+                    forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxMzY3MA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438313670", "bodyText": "Not sure what you're referring to with Worker::setTargetState, could you elaborate?", "author": "C0urante", "createdAt": "2020-06-10T18:04:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNzA0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ0ODk5Nw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438448997", "bodyText": "I'm referring to how the lambda was written there as the second argument. I'd be nice to keep a consistent style at least in the changes included in a single commit.", "author": "kkonstantine", "createdAt": "2020-06-10T22:48:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNzA0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1NzA0Nw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438457047", "bodyText": "Ahh, I see. I don't think that's as easy with this part since the if statement requires a new scope and the braces for that scope come with their own requirements about being on new lines.", "author": "C0urante", "createdAt": "2020-06-10T23:13:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNzA0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2NjAzNQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438466035", "bodyText": "I suggested what you've written in StandaloneHerder for the same method. Anyway that's minor.", "author": "kkonstantine", "createdAt": "2020-06-10T23:44:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkzNzA0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMwOTU3Mw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438309573", "bodyText": "this seems to refer to member.wakeup. Best to follow that method.", "author": "kkonstantine", "createdAt": "2020-06-10T17:57:26Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java", "diffHunk": "@@ -240,11 +243,19 @@ public void testJoinAssignment() throws Exception {\n         EasyMock.expect(worker.getPlugins()).andReturn(plugins);\n         expectRebalance(1, Arrays.asList(CONN1), Arrays.asList(TASK1));\n         expectPostRebalanceCatchup(SNAPSHOT);\n-        worker.startConnector(EasyMock.eq(CONN1), EasyMock.<Map<String, String>>anyObject(), EasyMock.<ConnectorContext>anyObject(),\n-                EasyMock.eq(herder), EasyMock.eq(TargetState.STARTED));\n-        PowerMock.expectLastCall().andReturn(true);\n+        Capture<Callback<TargetState>> onStart = newCapture();\n+        worker.startConnector(EasyMock.eq(CONN1), EasyMock.<Map<String, String>>anyObject(), EasyMock.<CloseableConnectorContext>anyObject(),\n+                EasyMock.eq(herder), EasyMock.eq(TargetState.STARTED), capture(onStart));\n+        PowerMock.expectLastCall().andAnswer(new IAnswer<Boolean>() {\n+            @Override\n+            public Boolean answer() throws Throwable {\n+                onStart.getValue().onCompletion(null, TargetState.STARTED);\n+                return true;\n+            }\n+        });\n+        member.wakeup();\n         EasyMock.expect(worker.isRunning(CONN1)).andReturn(true);\n-\n+        PowerMock.expectLastCall();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMxOTM3NQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438319375", "bodyText": "This call is missing an expectLastCall. Here an in a couple other places.", "author": "kkonstantine", "createdAt": "2020-06-10T18:14:30Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java", "diffHunk": "@@ -269,9 +280,17 @@ public void testRebalance() throws Exception {\n         EasyMock.expect(worker.getPlugins()).andReturn(plugins);\n         expectRebalance(1, Arrays.asList(CONN1), Arrays.asList(TASK1));\n         expectPostRebalanceCatchup(SNAPSHOT);\n-        worker.startConnector(EasyMock.eq(CONN1), EasyMock.<Map<String, String>>anyObject(), EasyMock.<ConnectorContext>anyObject(),\n-                EasyMock.eq(herder), EasyMock.eq(TargetState.STARTED));\n-        PowerMock.expectLastCall().andReturn(true);\n+        Capture<Callback<TargetState>> onFirstStart = newCapture();\n+        worker.startConnector(EasyMock.eq(CONN1), EasyMock.<Map<String, String>>anyObject(), EasyMock.<CloseableConnectorContext>anyObject(),\n+                EasyMock.eq(herder), EasyMock.eq(TargetState.STARTED), capture(onFirstStart));\n+        PowerMock.expectLastCall().andAnswer(new IAnswer<Boolean>() {\n+            @Override\n+            public Boolean answer() throws Throwable {\n+                onFirstStart.getValue().onCompletion(null, TargetState.STARTED);\n+                return true;\n+            }\n+        });\n+        member.wakeup();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMzMzk5NQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438333995", "bodyText": "don't we need to verify the expectations ?", "author": "kkonstantine", "createdAt": "2020-06-10T18:41:05Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java", "diffHunk": "@@ -582,86 +658,41 @@ public void testCreateConnectorFailedBasicValidation() throws Exception {\n         member.wakeup();\n         PowerMock.expectLastCall();\n \n-        // config validation\n-        Connector connectorMock = PowerMock.createMock(SourceConnector.class);\n-        EasyMock.expect(worker.configTransformer()).andReturn(transformer).times(2);\n-        final Capture<Map<String, String>> configCapture = newCapture();\n-        EasyMock.expect(transformer.transform(EasyMock.capture(configCapture))).andAnswer(configCapture::getValue);\n-        EasyMock.expect(worker.getPlugins()).andReturn(plugins).times(3);\n-        EasyMock.expect(plugins.compareAndSwapLoaders(connectorMock)).andReturn(delegatingLoader);\n-        EasyMock.expect(plugins.newConnector(EasyMock.anyString())).andReturn(connectorMock);\n-\n-        EasyMock.expect(connectorMock.config()).andStubReturn(new ConfigDef());\n-        ConfigValue validatedValue = new ConfigValue(\"foo.bar\");\n-        EasyMock.expect(connectorMock.validate(config)).andReturn(new Config(singletonList(validatedValue)));\n-\n-        EasyMock.expect(Plugins.compareAndSwapLoaders(delegatingLoader)).andReturn(pluginLoader);\n-\n-        // CONN2 creation should fail\n+        // mock the actual validation since its asynchronous nature is difficult to test and should\n+        // be covered sufficiently by the unit tests for the AbstractHerder class\n+        Capture<Callback<ConfigInfos>> validateCallback = newCapture();\n+        herder.validateConnectorConfig(EasyMock.eq(config), capture(validateCallback));\n+        PowerMock.expectLastCall().andAnswer(new IAnswer<Void>() {\n+            @Override\n+            public Void answer() throws Throwable {\n+                // CONN2 creation should fail\n+                validateCallback.getValue().onCompletion(null, CONN2_INVALID_CONFIG_INFOS);\n+                return null;\n+            }\n+        });\n \n         Capture<Throwable> error = newCapture();\n-        putConnectorCallback.onCompletion(EasyMock.capture(error), EasyMock.<Herder.Created<ConnectorInfo>>isNull());\n+        putConnectorCallback.onCompletion(capture(error), EasyMock.<Herder.Created<ConnectorInfo>>isNull());\n         PowerMock.expectLastCall();\n \n         member.poll(EasyMock.anyInt());\n         PowerMock.expectLastCall();\n-        // No immediate action besides this -- change will be picked up via the config log\n-\n-        PowerMock.replayAll();\n-\n-        herder.putConnectorConfig(CONN2, config, false, putConnectorCallback);\n-        herder.tick();\n-\n-        assertTrue(error.hasCaptured());\n-        assertTrue(error.getValue() instanceof BadRequestException);\n-\n-        time.sleep(1000L);\n-        assertStatistics(3, 1, 100, 1000L);\n-\n-        PowerMock.verifyAll();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2NjQzMQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438366431", "bodyText": "The existing testCreateConnectorFailedBasicValidation and testCreateConnectorFailedCustomValidation tests were refactored into a single testCreateConnectorFailedValidation method, which does make the call to PowerMock.verifyAll().", "author": "C0urante", "createdAt": "2020-06-10T19:43:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMzMzk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMzNDcwMw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438334703", "bodyText": "same question. Not sure if there are not mocks used here.", "author": "kkonstantine", "createdAt": "2020-06-10T18:42:31Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java", "diffHunk": "@@ -676,63 +707,38 @@ public void testCreateConnectorFailedCustomValidation() throws Exception {\n     @SuppressWarnings(\"unchecked\")\n     @Test\n     public void testConnectorNameConflictsWithWorkerGroupId() throws Exception {\n-        EasyMock.expect(member.memberId()).andStubReturn(\"leader\");\n-        EasyMock.expect(member.currentProtocolVersion()).andStubReturn(CONNECT_PROTOCOL_V0);\n-        expectRebalance(1, Collections.<String>emptyList(), Collections.<ConnectorTaskId>emptyList());\n-        expectPostRebalanceCatchup(SNAPSHOT);\n-\n-        member.wakeup();\n-        PowerMock.expectLastCall();\n-\n         Map<String, String> config = new HashMap<>(CONN2_CONFIG);\n         config.put(ConnectorConfig.NAME_CONFIG, \"test-group\");\n \n-        // config validation\n         Connector connectorMock = PowerMock.createMock(SinkConnector.class);\n-        EasyMock.expect(worker.configTransformer()).andReturn(transformer).times(2);\n-        final Capture<Map<String, String>> configCapture = newCapture();\n-        EasyMock.expect(transformer.transform(EasyMock.capture(configCapture))).andAnswer(configCapture::getValue);\n-        EasyMock.expect(worker.getPlugins()).andReturn(plugins).times(3);\n-        EasyMock.expect(plugins.compareAndSwapLoaders(connectorMock)).andReturn(delegatingLoader);\n-        EasyMock.expect(plugins.newConnector(EasyMock.anyString())).andReturn(connectorMock);\n-        EasyMock.expect(connectorMock.config()).andReturn(new ConfigDef());\n-        EasyMock.expect(connectorMock.validate(config)).andReturn(new Config(Collections.<ConfigValue>emptyList()));\n-        EasyMock.expect(Plugins.compareAndSwapLoaders(delegatingLoader)).andReturn(pluginLoader);\n \n         // CONN2 creation should fail because the worker group id (connect-test-group) conflicts with\n         // the consumer group id we would use for this sink\n+        Map<String, ConfigValue> validatedConfigs =\n+            herder.validateBasicConnectorConfig(connectorMock, ConnectorConfig.configDef(), config);\n \n-        Capture<Throwable> error = newCapture();\n-        putConnectorCallback.onCompletion(EasyMock.capture(error), EasyMock.isNull(Herder.Created.class));\n-        PowerMock.expectLastCall();\n-\n-        member.poll(EasyMock.anyInt());\n-        PowerMock.expectLastCall();\n-        // No immediate action besides this -- change will be picked up via the config log\n-\n-        PowerMock.replayAll();\n-\n-        herder.putConnectorConfig(CONN2, config, false, putConnectorCallback);\n-        herder.tick();\n-\n-        assertTrue(error.hasCaptured());\n-        assertTrue(error.getValue() instanceof BadRequestException);\n-\n-        time.sleep(1000L);\n-        assertStatistics(3, 1, 100, 1000L);\n-\n-        PowerMock.verifyAll();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2NzY4Nw==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438367687", "bodyText": "Yeah, the only mock here is connectorMock, and no expectations are set on it. It's just used to trigger the if (connector instanceof SinkConnector) brach in DistributedHerder::validateBasicConnectorConfig.", "author": "C0urante", "createdAt": "2020-06-10T19:45:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODMzNDcwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1ODcxOA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438358718", "bodyText": "I think it's not great to introduce tests that will be ignored by default. As we wouldn't add unused code, maybe we want to skip adding these test cases for now.", "author": "kkonstantine", "createdAt": "2020-06-10T19:28:33Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/BlockingConnectorTest.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.integration;\n+\n+import org.apache.kafka.common.config.AbstractConfig;\n+import org.apache.kafka.common.config.Config;\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.connector.Task;\n+import org.apache.kafka.connect.runtime.Worker;\n+import org.apache.kafka.connect.runtime.rest.errors.ConnectRestException;\n+import org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource;\n+import org.apache.kafka.connect.source.SourceConnector;\n+import org.apache.kafka.connect.source.SourceRecord;\n+import org.apache.kafka.connect.source.SourceTask;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.CONNECTOR_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TASKS_MAX_CONFIG;\n+import static org.apache.kafka.connect.runtime.SinkConnectorConfig.TOPICS_CONFIG;\n+import static org.junit.Assert.assertThrows;\n+\n+public class BlockingConnectorTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(BlockingConnectorTest.class);\n+\n+    private static final int NUM_WORKERS = 1;\n+    private static final String BLOCKING_CONNECTOR_NAME = \"blocking-connector\";\n+    private static final String NORMAL_CONNECTOR_NAME = \"normal-connector\";\n+    private static final long REST_REQUEST_TIMEOUT = Worker.CONNECTOR_GRACEFUL_SHUTDOWN_TIMEOUT_MS * 2;\n+\n+    private EmbeddedConnectCluster connect;\n+\n+    @Before\n+    public void setup() {\n+        // Artificially reduce the REST request timeout so that these don't take forever\n+        ConnectorsResource.setRequestTimeout(REST_REQUEST_TIMEOUT);\n+        // build a Connect cluster backed by Kafka and Zk\n+        connect = new EmbeddedConnectCluster.Builder()\n+                .name(\"connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .workerProps(new HashMap<>())\n+                .brokerProps(new Properties())\n+                .build();\n+\n+        // start the clusters\n+        connect.start();\n+    }\n+\n+    @After\n+    public void close() {\n+        // stop all Connect, Kafka and Zk threads.\n+        connect.stop();\n+        ConnectorsResource.resetRequestTimeout();\n+        BlockingConnector.resetBlockLatch();\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorValidate() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorValidate\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ValidateBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorConfig() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorConfig\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ConfigBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorInitialize() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorInitialize\");\n+        createConnectorWithBlock(InitializeBlockingConnector.class);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStart\");\n+        createConnectorWithBlock(BlockingConnector.START);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStop\");\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.deleteConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStart\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.START);\n+        // First instance of the connector should block on startup\n+        BlockingConnector.waitForBlock();\n+        connect.removeWorker();\n+\n+        connect.addWorker();\n+        // After stopping the only worker and restarting it, a new instance of the blocking\n+        // connector should be created and we can ensure that it blocks again\n+        BlockingConnector.waitForBlock();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStop\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.removeWorker();\n+        BlockingConnector.waitForBlock();\n+\n+        connect.addWorker();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM4MDQ5NA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438380494", "bodyText": "Fair, I'll take them out. Will file a follow-up jira ticket to note the gaps here in case someone runs into problems with the yet-unaddressed connector methods in the future.", "author": "C0urante", "createdAt": "2020-06-10T20:10:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1ODcxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQwNjU1NA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438406554", "bodyText": "Filed https://issues.apache.org/jira/browse/KAFKA-10142 to note the gaps in this fix.", "author": "C0urante", "createdAt": "2020-06-10T21:02:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1ODcxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1OTEzMQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438359131", "bodyText": "Should we create source connectors that actually produce data? Doesn't seem to be any flow of records to this connector.", "author": "kkonstantine", "createdAt": "2020-06-10T19:29:23Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/BlockingConnectorTest.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.integration;\n+\n+import org.apache.kafka.common.config.AbstractConfig;\n+import org.apache.kafka.common.config.Config;\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.connector.Task;\n+import org.apache.kafka.connect.runtime.Worker;\n+import org.apache.kafka.connect.runtime.rest.errors.ConnectRestException;\n+import org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource;\n+import org.apache.kafka.connect.source.SourceConnector;\n+import org.apache.kafka.connect.source.SourceRecord;\n+import org.apache.kafka.connect.source.SourceTask;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.CONNECTOR_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TASKS_MAX_CONFIG;\n+import static org.apache.kafka.connect.runtime.SinkConnectorConfig.TOPICS_CONFIG;\n+import static org.junit.Assert.assertThrows;\n+\n+public class BlockingConnectorTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(BlockingConnectorTest.class);\n+\n+    private static final int NUM_WORKERS = 1;\n+    private static final String BLOCKING_CONNECTOR_NAME = \"blocking-connector\";\n+    private static final String NORMAL_CONNECTOR_NAME = \"normal-connector\";\n+    private static final long REST_REQUEST_TIMEOUT = Worker.CONNECTOR_GRACEFUL_SHUTDOWN_TIMEOUT_MS * 2;\n+\n+    private EmbeddedConnectCluster connect;\n+\n+    @Before\n+    public void setup() {\n+        // Artificially reduce the REST request timeout so that these don't take forever\n+        ConnectorsResource.setRequestTimeout(REST_REQUEST_TIMEOUT);\n+        // build a Connect cluster backed by Kafka and Zk\n+        connect = new EmbeddedConnectCluster.Builder()\n+                .name(\"connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .workerProps(new HashMap<>())\n+                .brokerProps(new Properties())\n+                .build();\n+\n+        // start the clusters\n+        connect.start();\n+    }\n+\n+    @After\n+    public void close() {\n+        // stop all Connect, Kafka and Zk threads.\n+        connect.stop();\n+        ConnectorsResource.resetRequestTimeout();\n+        BlockingConnector.resetBlockLatch();\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorValidate() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorValidate\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ValidateBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorConfig() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorConfig\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ConfigBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorInitialize() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorInitialize\");\n+        createConnectorWithBlock(InitializeBlockingConnector.class);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStart\");\n+        createConnectorWithBlock(BlockingConnector.START);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStop\");\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.deleteConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStart\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.START);\n+        // First instance of the connector should block on startup\n+        BlockingConnector.waitForBlock();\n+        connect.removeWorker();\n+\n+        connect.addWorker();\n+        // After stopping the only worker and restarting it, a new instance of the blocking\n+        // connector should be created and we can ensure that it blocks again\n+        BlockingConnector.waitForBlock();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStop\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.removeWorker();\n+        BlockingConnector.waitForBlock();\n+\n+        connect.addWorker();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testBlockInConnectorTaskClass() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CLASS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testBlockInConnectorTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CONFIGS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testConnectorRestartWithBlockInConnectorTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CONFIGS);\n+        // Test both explicit restart and implicit (pause then resume) restart\n+        connect.restartConnector(BLOCKING_CONNECTOR_NAME);\n+        connect.pauseConnector(BLOCKING_CONNECTOR_NAME);\n+        connect.resumeConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    // TODO: Consider patching plugin scanning to handle connectors that block in their version methods\n+    // @Test\n+    // public void testBlockInConnectorVersion() throws Exception {\n+    //     createConnectorWithBlock(VersionBlockingConnector.class);\n+    //     createNormalConnector();\n+    //     waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    // }\n+\n+    @Test\n+    @Ignore(\"This connector method is never invoked by the framework\")\n+    public void testBlockInConnectorInitializeWithTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.INITIALIZE_WITH_TASK_CONFIGS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"This connector method is never invoked by the framework\")\n+    public void testBlockInConnectorReconfigure() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.RECONFIGURE);\n+        Map<String, String> newProps = baseBlockingConnectorProps();\n+        newProps.put(\"foo\", \"bar\");\n+\n+        connect.configureConnector(BLOCKING_CONNECTOR_NAME, newProps);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    private void createConnectorWithBlock(String block) {\n+        Map<String, String> props = baseBlockingConnectorProps();\n+        props.put(BlockingConnector.BLOCK_CONFIG, block);\n+        log.info(\"Creating connector with block during {}\", block);\n+        try {\n+            connect.configureConnector(BLOCKING_CONNECTOR_NAME, props);\n+        } catch (RuntimeException e) {\n+            log.info(\"Failed to create connector\", e);\n+            throw e;\n+        }\n+    }\n+\n+    private void createConnectorWithBlock(Class<? extends BlockingConnector> connectorClass) {\n+        Map<String, String> props = baseBlockingConnectorProps();\n+        props.put(CONNECTOR_CLASS_CONFIG, connectorClass.getName());\n+        log.info(\"Creating blocking connector of type {}\", connectorClass.getSimpleName());\n+        try {\n+            connect.configureConnector(BLOCKING_CONNECTOR_NAME, props);\n+        } catch (RuntimeException e) {\n+            log.info(\"Failed to create connector\", e);\n+            throw e;\n+        }\n+    }\n+\n+    private Map<String, String> baseBlockingConnectorProps() {\n+        Map<String, String> result = new HashMap<>();\n+        result.put(CONNECTOR_CLASS_CONFIG, BlockingConnector.class.getName());\n+        result.put(TASKS_MAX_CONFIG, \"1\");\n+        return result;\n+    }\n+\n+    private void createNormalConnector() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSinkConnector.class.getName());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM3ODA5MQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438378091", "bodyText": "Yeah, I think we can do that.", "author": "C0urante", "createdAt": "2020-06-10T20:05:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1OTEzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1OTY1NA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438359654", "bodyText": "Code might not be the best way to document this, and it might get stale with time.", "author": "kkonstantine", "createdAt": "2020-06-10T19:30:26Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/BlockingConnectorTest.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.integration;\n+\n+import org.apache.kafka.common.config.AbstractConfig;\n+import org.apache.kafka.common.config.Config;\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectorContext;\n+import org.apache.kafka.connect.connector.Task;\n+import org.apache.kafka.connect.runtime.Worker;\n+import org.apache.kafka.connect.runtime.rest.errors.ConnectRestException;\n+import org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource;\n+import org.apache.kafka.connect.source.SourceConnector;\n+import org.apache.kafka.connect.source.SourceRecord;\n+import org.apache.kafka.connect.source.SourceTask;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.CONNECTOR_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TASKS_MAX_CONFIG;\n+import static org.apache.kafka.connect.runtime.SinkConnectorConfig.TOPICS_CONFIG;\n+import static org.junit.Assert.assertThrows;\n+\n+public class BlockingConnectorTest {\n+\n+    private static final Logger log = LoggerFactory.getLogger(BlockingConnectorTest.class);\n+\n+    private static final int NUM_WORKERS = 1;\n+    private static final String BLOCKING_CONNECTOR_NAME = \"blocking-connector\";\n+    private static final String NORMAL_CONNECTOR_NAME = \"normal-connector\";\n+    private static final long REST_REQUEST_TIMEOUT = Worker.CONNECTOR_GRACEFUL_SHUTDOWN_TIMEOUT_MS * 2;\n+\n+    private EmbeddedConnectCluster connect;\n+\n+    @Before\n+    public void setup() {\n+        // Artificially reduce the REST request timeout so that these don't take forever\n+        ConnectorsResource.setRequestTimeout(REST_REQUEST_TIMEOUT);\n+        // build a Connect cluster backed by Kafka and Zk\n+        connect = new EmbeddedConnectCluster.Builder()\n+                .name(\"connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .workerProps(new HashMap<>())\n+                .brokerProps(new Properties())\n+                .build();\n+\n+        // start the clusters\n+        connect.start();\n+    }\n+\n+    @After\n+    public void close() {\n+        // stop all Connect, Kafka and Zk threads.\n+        connect.stop();\n+        ConnectorsResource.resetRequestTimeout();\n+        BlockingConnector.resetBlockLatch();\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorValidate() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorValidate\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ValidateBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorConfig() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorConfig\");\n+        assertThrows(ConnectRestException.class, () -> createConnectorWithBlock(ConfigBlockingConnector.class));\n+        // Will NOT assert that connector has failed, since the request should fail before it's even created\n+\n+        // Connector should already be blocked so this should return immediately, but check just to\n+        // make sure that it actually did block\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorInitialize() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorInitialize\");\n+        createConnectorWithBlock(InitializeBlockingConnector.class);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStart\");\n+        createConnectorWithBlock(BlockingConnector.START);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testBlockInConnectorStop\");\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.deleteConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStart() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStart\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.START);\n+        // First instance of the connector should block on startup\n+        BlockingConnector.waitForBlock();\n+        connect.removeWorker();\n+\n+        connect.addWorker();\n+        // After stopping the only worker and restarting it, a new instance of the blocking\n+        // connector should be created and we can ensure that it blocks again\n+        BlockingConnector.waitForBlock();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    public void testWorkerRestartWithBlockInConnectorStop() throws Exception {\n+        log.info(\"Starting test testWorkerRestartWithBlockInConnectorStop\");\n+        createNormalConnector();\n+        createConnectorWithBlock(BlockingConnector.STOP);\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+        connect.removeWorker();\n+        BlockingConnector.waitForBlock();\n+\n+        connect.addWorker();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+        waitForConnectorStart(BLOCKING_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testBlockInConnectorTaskClass() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CLASS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testBlockInConnectorTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CONFIGS);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    @Test\n+    @Ignore(\"Interaction with this connector method has not been made asynchronous yet and this test will fail\")\n+    public void testConnectorRestartWithBlockInConnectorTaskConfigs() throws Exception {\n+        createConnectorWithBlock(BlockingConnector.TASK_CONFIGS);\n+        // Test both explicit restart and implicit (pause then resume) restart\n+        connect.restartConnector(BLOCKING_CONNECTOR_NAME);\n+        connect.pauseConnector(BLOCKING_CONNECTOR_NAME);\n+        connect.resumeConnector(BLOCKING_CONNECTOR_NAME);\n+        BlockingConnector.waitForBlock();\n+\n+        createNormalConnector();\n+        waitForConnectorStart(NORMAL_CONNECTOR_NAME);\n+    }\n+\n+    // TODO: Consider patching plugin scanning to handle connectors that block in their version methods", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM4MTIxNg==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438381216", "bodyText": "I'd like to leave some note in here about why Connector::version is a special case to avoid possible headaches in the future if/when someone tries to address it. I'll make it as minimal as possible and won't leave in any commented-out code; if you still think that's unwise I'll remove it, though.", "author": "C0urante", "createdAt": "2020-06-10T20:12:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM1OTY1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQyODM1OA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438428358", "bodyText": "nit: leftover?", "author": "kkonstantine", "createdAt": "2020-06-10T21:51:12Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerder.java", "diffHunk": "@@ -191,32 +189,59 @@ public synchronized void putConnectorConfig(String connName,\n                                                 boolean allowReplace,\n                                                 final Callback<Created<ConnectorInfo>> callback) {\n         try {\n-            if (maybeAddConfigErrors(validateConnectorConfig(config), callback)) {\n+            validateConnectorConfig(config, (error, configInfos) -> {\n+                if (error != null) {\n+                    callback.onCompletion(error, null);\n+                    return;\n+                }\n+\n+                requestExecutorService.submit(\n+                    () -> putConnectorConfig(connName, config, allowReplace, callback, configInfos)\n+                );\n+            });\n+        } catch (Throwable t) {\n+            callback.onCompletion(t, null);\n+        }\n+    }\n+\n+    private synchronized void putConnectorConfig(String connName,\n+                                                 final Map<String, String> config,\n+                                                 boolean allowReplace,\n+                                                 final Callback<Created<ConnectorInfo>> callback,\n+                                                 ConfigInfos configInfos) {\n+        try {\n+            if (maybeAddConfigErrors(configInfos, callback)) {\n                 return;\n             }\n \n-            boolean created = false;\n+            final boolean created;\n             if (configState.contains(connName)) {\n                 if (!allowReplace) {\n                     callback.onCompletion(new AlreadyExistsException(\"Connector \" + connName + \" already exists\"), null);\n                     return;\n                 }\n-                worker.stopConnector(connName);\n+                worker.stopAndAwaitConnector(connName);\n+                created = false;\n             } else {\n                 created = true;\n             }\n \n             configBackingStore.putConnectorConfig(connName, config);\n \n-            if (!startConnector(connName)) {\n-                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connName), null);\n-                return;\n-            }\n+            // startConnector(connName, onStart);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1ODcwOA==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438458708", "bodyText": "Thanks, nice catch!", "author": "C0urante", "createdAt": "2020-06-10T23:19:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQyODM1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2NjU5MQ==", "url": "https://github.com/apache/kafka/pull/8069#discussion_r438466591", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                startConnector(\n          \n          \n            \n                                        connectorName,\n          \n          \n            \n                                        (error, result) -> {\n          \n          \n            \n                                            if (error != null) {\n          \n          \n            \n                                                log.error(\"Failed to start connector '\" + connectorName + \"'\", error);\n          \n          \n            \n                                            }\n          \n          \n            \n                                        }\n          \n          \n            \n                                );\n          \n          \n            \n                                startConnector(connectorName, (error, result) -> {\n          \n          \n            \n                                    if (error != null) {\n          \n          \n            \n                                        log.error(\"Failed to start connector '\" + connectorName + \"'\", error);\n          \n          \n            \n                                    }\n          \n          \n            \n                                });", "author": "kkonstantine", "createdAt": "2020-06-10T23:46:40Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java", "diffHunk": "@@ -1221,31 +1284,56 @@ public Void call() throws Exception {\n \n     // Helper for starting a connector with the given name, which will extract & parse the config, generate connector\n     // context and add to the worker. This needs to be called from within the main worker thread for this herder.\n-    private boolean startConnector(String connectorName) {\n+    // The callback is invoked after the connector has finished startup and generated task configs, or failed in the process.\n+    private void startConnector(String connectorName, Callback<Void> callback) {\n         log.info(\"Starting connector {}\", connectorName);\n         final Map<String, String> configProps = configState.connectorConfig(connectorName);\n-        final ConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n+        final CloseableConnectorContext ctx = new HerderConnectorContext(this, connectorName);\n         final TargetState initialState = configState.targetState(connectorName);\n-        boolean started = worker.startConnector(connectorName, configProps, ctx, this, initialState);\n-\n-        // Immediately request configuration since this could be a brand new connector. However, also only update those\n-        // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n-        // just restoring an existing connector.\n-        if (started && initialState == TargetState.STARTED)\n-            reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+        final Callback<TargetState> onInitialStateChange = (error, newState) -> {\n+            if (error != null) {\n+                callback.onCompletion(new ConnectException(\"Failed to start connector: \" + connectorName), null);\n+                return;\n+            }\n \n-        return started;\n+            // Use newState here in case the connector has been paused right after being created\n+            if (newState == TargetState.STARTED) {\n+                addRequest(\n+                        new Callable<Void>() {\n+                            @Override\n+                            public Void call() {\n+                                // Request configuration since this could be a brand new connector. However, also only update those\n+                                // task configs if they are actually different from the existing ones to avoid unnecessary updates when this is\n+                                // just restoring an existing connector.\n+                                reconfigureConnectorTasksWithRetry(time.milliseconds(), connectorName);\n+                                callback.onCompletion(null, null);\n+                                return null;\n+                            }\n+                        },\n+                        forwardErrorCallback(callback)\n+                );\n+            } else {\n+                callback.onCompletion(null, null);\n+            }\n+        };\n+        worker.startConnector(connectorName, configProps, ctx, this, initialState, onInitialStateChange);\n     }\n \n     private Callable<Void> getConnectorStartingCallable(final String connectorName) {\n         return new Callable<Void>() {\n             @Override\n             public Void call() throws Exception {\n                 try {\n-                    startConnector(connectorName);\n+                    startConnector(\n+                            connectorName,\n+                            (error, result) -> {\n+                                if (error != null) {\n+                                    log.error(\"Failed to start connector '\" + connectorName + \"'\", error);\n+                                }\n+                            }\n+                    );", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ba080d7624e9cedadbf4279fff89c041d2ca811d", "url": "https://github.com/apache/kafka/commit/ba080d7624e9cedadbf4279fff89c041d2ca811d", "message": "KAFKA-9374: Make connector interactions asynchronous\n\nThese changes allow herders to continue to function even when a connector they\nare running hangs in its start, stop, initialize, validate, and/or config\nmethods.", "committedDate": "2020-06-11T03:51:31Z", "type": "commit"}, {"oid": "491cd4036c611ab657a06cf134b78d67c6b6d6d2", "url": "https://github.com/apache/kafka/commit/491cd4036c611ab657a06cf134b78d67c6b6d6d2", "message": "KAFKA-9374: Address review comments", "committedDate": "2020-06-11T03:51:32Z", "type": "commit"}, {"oid": "48e501adc02a685d9ae35a30ad013784f4c4f1f1", "url": "https://github.com/apache/kafka/commit/48e501adc02a685d9ae35a30ad013784f4c4f1f1", "message": "KAFKA-9374: Address review comments on tests", "committedDate": "2020-06-11T03:51:33Z", "type": "commit"}, {"oid": "55acd7c4166004c140429b95d05401511ee52a55", "url": "https://github.com/apache/kafka/commit/55acd7c4166004c140429b95d05401511ee52a55", "message": "KAFKA-9374: Remove commented-out code", "committedDate": "2020-06-11T03:51:33Z", "type": "commit"}, {"oid": "045a5f72f78840bb59a1393af5cd8cd6c7c1a02f", "url": "https://github.com/apache/kafka/commit/045a5f72f78840bb59a1393af5cd8cd6c7c1a02f", "message": "KAFKA-9374: Style improvement", "committedDate": "2020-06-11T03:51:33Z", "type": "commit"}, {"oid": "3adcc1f0551255f20174ca8a107f0fdb3d5401cf", "url": "https://github.com/apache/kafka/commit/3adcc1f0551255f20174ca8a107f0fdb3d5401cf", "message": "KAFKA-9374: Further style improvements", "committedDate": "2020-06-11T03:51:34Z", "type": "commit"}, {"oid": "3adcc1f0551255f20174ca8a107f0fdb3d5401cf", "url": "https://github.com/apache/kafka/commit/3adcc1f0551255f20174ca8a107f0fdb3d5401cf", "message": "KAFKA-9374: Further style improvements", "committedDate": "2020-06-11T03:51:34Z", "type": "forcePushed"}, {"oid": "bfb1bc04832b342e614e891d6da5af1f8ebe30a5", "url": "https://github.com/apache/kafka/commit/bfb1bc04832b342e614e891d6da5af1f8ebe30a5", "message": "KAFKA-9374: Fix race condition in failing unit test", "committedDate": "2020-06-11T04:43:46Z", "type": "commit"}]}