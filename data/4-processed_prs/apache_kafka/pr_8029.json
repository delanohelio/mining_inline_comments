{"pr_number": 8029, "pr_title": "KAFKA-8147: Add changelog topic configuration to KTable suppress", "pr_createdAt": "2020-02-01T05:54:32Z", "pr_url": "https://github.com/apache/kafka/pull/8029", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDMwMjkwNA==", "url": "https://github.com/apache/kafka/pull/8029#discussion_r380302904", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                     * Disable the changelog for store built by this {@link StoreBuilder}.\n          \n          \n            \n                     * Disable the changelog for this suppression's internal buffer.", "author": "vvcephei", "createdAt": "2020-02-17T17:28:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/Suppressed.java", "diffHunk": "@@ -118,6 +119,25 @@ static StrictBufferConfig unbounded() {\n          * duplicate results downstream, but does not promise to eliminate them.\n          */\n         EagerBufferConfig emitEarlyWhenFull();\n+\n+        /**\n+         * Disable the changelog for store built by this {@link StoreBuilder}.", "originalCommit": "08d14a6b742b9f52d642d74bc716c7e96e8e0033", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDMwMzIxNA==", "url": "https://github.com/apache/kafka/pull/8029#discussion_r380303214", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                     * This will turn off fault-tolerance for your store.\n          \n          \n            \n                     * This will turn off fault-tolerance for the suppression, and will result in data loss in the event of a rebalance.\n          \n      \n    \n    \n  \n\nThis isn't a \"store\", but rather a buffer internally used for suppression. Also, it seems appropriate to be a little more dire in our warning here because the internal nature of the buffer may make it less obvious to people what the downside of disabling this changelog is.", "author": "vvcephei", "createdAt": "2020-02-17T17:29:21Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/Suppressed.java", "diffHunk": "@@ -118,6 +119,25 @@ static StrictBufferConfig unbounded() {\n          * duplicate results downstream, but does not promise to eliminate them.\n          */\n         EagerBufferConfig emitEarlyWhenFull();\n+\n+        /**\n+         * Disable the changelog for store built by this {@link StoreBuilder}.\n+         * This will turn off fault-tolerance for your store.", "originalCommit": "08d14a6b742b9f52d642d74bc716c7e96e8e0033", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzODY3Mg==", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381438672", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n          \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster(), contains(changeLog));\n          \n      \n    \n    \n  \n\nEquivalent, but gives a better error message when it fails.", "author": "vvcephei", "createdAt": "2020-02-19T17:46:16Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTQ3NQ==", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381439475", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldWithLoggingEnable() {\n          \n          \n            \n                public void shouldAllowOverridingChangelogConfig() {\n          \n      \n    \n    \n  \n\nNot a big deal, but it's a little nicer when the test methods explain exactly what they are testing.", "author": "vvcephei", "createdAt": "2020-02-19T17:47:36Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTY2Ng==", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381439666", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void shouldWithLoggingDisable() {\n          \n          \n            \n                public void should createChangelogByDefault() {", "author": "vvcephei", "createdAt": "2020-02-19T17:47:56Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MzExMA==", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381443110", "bodyText": "It seems like this test would be more useful just as an assertion of the default behavior.", "author": "vvcephei", "createdAt": "2020-02-19T17:54:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQzOTY2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MDM1Mw==", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381440353", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            .withLoggingEnabled(Collections.emptyMap())))", "author": "vvcephei", "createdAt": "2020-02-19T17:49:06Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {\n+        final String testId = \"-shouldWithLoggingDisable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingDisable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(Collections.emptyMap())))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTQ0MDk4MQ==", "url": "https://github.com/apache/kafka/pull/8029#discussion_r381440981", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        assertThat(config.getProperty(\"retention.ms\"), Matchers.is(nullValue()));\n          \n          \n            \n                        assertThat(CLUSTER.getAllTopicsInCluster(), contains(changeLog));\n          \n      \n    \n    \n  \n\nAnd we can remove line 426, final Properties config = CLUSTER.getLogConfig(changeLog);, since it would be unused.", "author": "vvcephei", "createdAt": "2020-02-19T17:50:21Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/SuppressionIntegrationTest.java", "diffHunk": "@@ -313,6 +316,124 @@ public void shouldShutdownWhenBytesConstraintIsViolated() throws InterruptedExce\n         }\n     }\n \n+    @Test\n+    public void shouldWithLoggingEnable() {\n+        final String testId = \"-shouldWithLoggingEnable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final Map<String, String> logConfig = Collections.singletonMap(\"retention.ms\", \"1000\");\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingEnable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(logConfig)))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), is(logConfig.get(\"retention.ms\")));\n+            assertThat(CLUSTER.getAllTopicsInCluster().contains(changeLog), is(true));\n+            assertThat(rawRecords, Matchers.is(true));\n+            assertThat(suppressedRecords, is(true));\n+        } finally {\n+            driver.close();\n+            cleanStateAfterTest(CLUSTER, driver);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldWithLoggingDisable() {\n+        final String testId = \"-shouldWithLoggingDisable\";\n+        final String appId = getClass().getSimpleName().toLowerCase(Locale.getDefault()) + testId;\n+        final String input = \"input\" + testId;\n+        final String outputSuppressed = \"output-suppressed\" + testId;\n+        final String outputRaw = \"output-raw\" + testId;\n+        final String changeLog = \"suppressionintegrationtest-shouldWithLoggingDisable-KTABLE-SUPPRESS-STATE-STORE-0000000004-changelog\";\n+\n+        cleanStateBeforeTest(CLUSTER, input, outputRaw, outputSuppressed);\n+\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final KStream<String, String> inputStream = builder.stream(input);\n+\n+        final KTable<String, String> valueCounts = inputStream\n+            .groupByKey()\n+            .aggregate(() -> \"()\", (key, value, aggregate) -> aggregate + \",(\" + key + \": \" + value + \")\");\n+\n+        valueCounts\n+            .suppress(untilTimeLimit(ofMillis(MAX_VALUE), maxRecords(1L)\n+                .emitEarlyWhenFull()\n+                .withLoggingEnabled(Collections.emptyMap())))\n+            .toStream()\n+            .to(outputSuppressed);\n+\n+        valueCounts\n+            .toStream()\n+            .to(outputRaw);\n+\n+        final Properties streamsConfig = getStreamsConfig(appId);\n+        streamsConfig.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+        streamsConfig.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);\n+\n+        final KafkaStreams driver = IntegrationTestUtils.getStartedStreams(streamsConfig, builder, true);\n+        try {\n+            produceSynchronously(\n+                input,\n+                asList(\n+                    new KeyValueTimestamp<>(\"k1\", \"v1\", scaledTime(0L)),\n+                    new KeyValueTimestamp<>(\"k1\", \"v2\", scaledTime(1L)),\n+                    new KeyValueTimestamp<>(\"k2\", \"v1\", scaledTime(2L)),\n+                    new KeyValueTimestamp<>(\"x\", \"x\", scaledTime(3L))\n+                )\n+            );\n+            final boolean rawRecords = waitForAnyRecord(outputRaw);\n+            final boolean suppressedRecords = waitForAnyRecord(outputSuppressed);\n+            final Properties config = CLUSTER.getLogConfig(changeLog);\n+\n+            assertThat(config.getProperty(\"retention.ms\"), Matchers.is(nullValue()));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "81ce750f9f9beb835d5026f4a0dd6885c0398b3f", "url": "https://github.com/apache/kafka/commit/81ce750f9f9beb835d5026f4a0dd6885c0398b3f", "message": "KAFKA-8147: Add changelog topic configuration to KTable suppress", "committedDate": "2020-02-22T00:28:27Z", "type": "commit"}, {"oid": "81ce750f9f9beb835d5026f4a0dd6885c0398b3f", "url": "https://github.com/apache/kafka/commit/81ce750f9f9beb835d5026f4a0dd6885c0398b3f", "message": "KAFKA-8147: Add changelog topic configuration to KTable suppress", "committedDate": "2020-02-22T00:28:27Z", "type": "forcePushed"}]}