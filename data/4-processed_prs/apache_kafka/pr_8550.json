{"pr_number": 8550, "pr_title": "KAFKA-9850 Move KStream#repartition operator validation during Topolo\u2026", "pr_createdAt": "2020-04-25T08:47:35Z", "pr_url": "https://github.com/apache/kafka/pull/8550", "timeline": [{"oid": "1817e87769ea16d6635cf7045ca9680ae9f226c4", "url": "https://github.com/apache/kafka/commit/1817e87769ea16d6635cf7045ca9680ae9f226c4", "message": "KAFKA-9850 Move KStream#repartition operator validation during Topology build process", "committedDate": "2020-04-25T08:42:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwOTI1NA==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r415209254", "bodyText": "nit: validateCopartition", "author": "abbccdda", "createdAt": "2020-04-26T04:10:57Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java", "diffHunk": "@@ -312,6 +312,7 @@ public void buildAndOptimizeTopology(final Properties props) {\n                 graphNodePriorityQueue.offer(graphNode);\n             }\n         }\n+        internalTopologyBuilder.validateCoPartition();", "originalCommit": "1817e87769ea16d6635cf7045ca9680ae9f226c4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwOTY2Mg==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r415209662", "bodyText": "Let's try to be consistent to use copartition instead of coPartition", "author": "abbccdda", "createdAt": "2020-04-26T04:13:20Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,45 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCoPartition() {\n+        final List<Set<String>> copartitionGroups =\n+                copartitionSourceGroups\n+                        .stream()\n+                        .map(sourceGroup -> sourceGroup\n+                                .stream()\n+                                .flatMap(node -> nodeToSourceTopics.get(node).stream())\n+                                .collect(Collectors.toSet())\n+                        ).collect(Collectors.toList());\n+        for (final Set<String> coPartition : copartitionGroups) {\n+            final Map<String, InternalTopicProperties> coPartitionProperties = new HashMap<>();", "originalCommit": "1817e87769ea16d6635cf7045ca9680ae9f226c4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwOTkzNQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r415209935", "bodyText": "One question, since we do verification in topology builder, is there any validation code in later stage that could be removed?", "author": "abbccdda", "createdAt": "2020-04-26T04:15:17Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java", "diffHunk": "@@ -312,6 +312,7 @@ public void buildAndOptimizeTopology(final Properties props) {\n                 graphNodePriorityQueue.offer(graphNode);\n             }\n         }\n+        internalTopologyBuilder.validateCoPartition();", "originalCommit": "1817e87769ea16d6635cf7045ca9680ae9f226c4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTMzNTQxMQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r415335411", "bodyText": "I'm not sure if we can remove later stage validation code\n@mjsax @lkokhreidze Can you give some advice?", "author": "zhaohaidao", "createdAt": "2020-04-26T15:29:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwOTkzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4Nzk5Mg==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418787992", "bodyText": "I don't think so. Because the later verification that covers the case if the user specified all partitions, is the same code that verify co-partitioning depending on the input topic partition numbers. And we still need that check anyway.", "author": "mjsax", "createdAt": "2020-05-02T00:24:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwOTkzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIxMDU0Mg==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r415210542", "bodyText": "Since we are only going to verify number of partitions, I think we could just set value as integer", "author": "abbccdda", "createdAt": "2020-04-26T04:19:00Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,45 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCoPartition() {\n+        final List<Set<String>> copartitionGroups =\n+                copartitionSourceGroups\n+                        .stream()\n+                        .map(sourceGroup -> sourceGroup\n+                                .stream()\n+                                .flatMap(node -> nodeToSourceTopics.get(node).stream())\n+                                .collect(Collectors.toSet())\n+                        ).collect(Collectors.toList());\n+        for (final Set<String> coPartition : copartitionGroups) {\n+            final Map<String, InternalTopicProperties> coPartitionProperties = new HashMap<>();", "originalCommit": "1817e87769ea16d6635cf7045ca9680ae9f226c4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIxMTk3NA==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r415211974", "bodyText": "Could you clarify why we need this equality check?", "author": "abbccdda", "createdAt": "2020-04-26T04:28:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,45 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCoPartition() {\n+        final List<Set<String>> copartitionGroups =\n+                copartitionSourceGroups\n+                        .stream()\n+                        .map(sourceGroup -> sourceGroup\n+                                .stream()\n+                                .flatMap(node -> nodeToSourceTopics.get(node).stream())\n+                                .collect(Collectors.toSet())\n+                        ).collect(Collectors.toList());\n+        for (final Set<String> coPartition : copartitionGroups) {\n+            final Map<String, InternalTopicProperties> coPartitionProperties = new HashMap<>();\n+            internalTopicNamesWithProperties.forEach((topic, prop) -> {\n+                if (coPartition.contains(topic) && prop.getNumberOfPartitions().isPresent()) {\n+                    coPartitionProperties.put(topic, prop);\n+                }\n+            });\n+            if (coPartition.size() == coPartitionProperties.size()) {", "originalCommit": "1817e87769ea16d6635cf7045ca9680ae9f226c4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTMzNDc1Nw==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r415334757", "bodyText": "It's my pleasure.\nIt means that not all input topics have correspond internal topic if coPartition.size() != coPartitionProperties.size(), if not equal is true, we can just skip this validation. You can see the original validation in CopartitionedTopicsEnforcer#enforce\nif (copartitionGroup.equals(repartitionTopicConfigs.keySet())) {\n    ...\n    validateAndGetNumOfPartitions\n    ...\n}\n\nIf some of input topics don't have repartition operation, their internal topic partition number can be deducted by others which have repartition operation. You can see KStreamRepartitionIntegrationTest#shouldDeductNumberOfPartitionsFromRepartitionOperation for more details.\nSo we can skip this validation if coPartition.size() != coPartitionProperties.size()", "author": "zhaohaidao", "createdAt": "2020-04-26T15:26:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIxMTk3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzQ0NzM3OQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r417447379", "bodyText": "I see the point, so do we need to cleanup the validations on the CopartitionedTopicsEnforcer to avoid duplicates? WDYT?", "author": "abbccdda", "createdAt": "2020-04-29T16:26:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIxMTk3NA=="}], "type": "inlineReview"}, {"oid": "934c0a2e237e246c0508c64812027076ad1b511f", "url": "https://github.com/apache/kafka/commit/934c0a2e237e246c0508c64812027076ad1b511f", "message": "change CoPartition/coPartition to Copartition/copartition", "committedDate": "2020-04-26T15:07:28Z", "type": "commit"}, {"oid": "d51217944133d168916ef224d19eeb3093991f6a", "url": "https://github.com/apache/kafka/commit/d51217944133d168916ef224d19eeb3093991f6a", "message": "address comments", "committedDate": "2020-04-28T23:55:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NDE4OQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418784189", "bodyText": "It's better to use:\nfinal TopologyException expected = assertThrows(\n  TopologyException.class,\n  () -> builder.build(props)\n);\n// put assertions here", "author": "mjsax", "createdAt": "2020-05-02T00:00:52Z", "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamRepartitionTest.java", "diffHunk": "@@ -104,6 +114,54 @@ public void shouldInvokePartitionerWhenSet() {\n         verify(streamPartitionerMock);\n     }\n \n+    @Test\n+    public void shouldThrowAnExceptionWhenNumberOfPartitionsOfRepartitionOperationsDoNotMatchWhenJoining() {\n+        final String topicB = \"topic-b\";\n+        final String outputTopic = \"topic-output\";\n+        final String topicBRepartitionedName = \"topic-b-scale-up\";\n+        final String inputTopicRepartitionedName = \"input-topic-scale-up\";\n+        final int topicBNumberOfPartitions = 2;\n+        final int inputTopicNumberOfPartitions = 4;\n+        final StreamsBuilder builder = new StreamsBuilder();\n+\n+        final Repartitioned<Integer, String> inputTopicRepartitioned = Repartitioned\n+                .<Integer, String>as(inputTopicRepartitionedName)\n+                .withNumberOfPartitions(inputTopicNumberOfPartitions);\n+\n+        final Repartitioned<Integer, String> topicBRepartitioned = Repartitioned\n+                .<Integer, String>as(topicBRepartitionedName)\n+                .withNumberOfPartitions(topicBNumberOfPartitions);\n+\n+        final KStream<Integer, String> topicBStream = builder\n+                .stream(topicB, Consumed.with(Serdes.Integer(), Serdes.String()))\n+                .repartition(topicBRepartitioned);\n+\n+        builder.stream(inputTopic, Consumed.with(Serdes.Integer(), Serdes.String()))\n+                .repartition(inputTopicRepartitioned)\n+                .join(topicBStream, (value1, value2) -> value2, JoinWindows.of(Duration.ofSeconds(10)))\n+                .to(outputTopic);\n+\n+        final Map<String, Integer> repartitionTopicsWithNumOfPartitions = Utils.mkMap(\n+                Utils.mkEntry(toRepartitionTopicName(topicBRepartitionedName), topicBNumberOfPartitions),\n+                Utils.mkEntry(toRepartitionTopicName(inputTopicRepartitionedName), inputTopicNumberOfPartitions)\n+        );\n+\n+        try {\n+            builder.build(props);\n+            Assert.fail();\n+        } catch (final TopologyException t) {", "originalCommit": "d51217944133d168916ef224d19eeb3093991f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODgxMzk3NQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418813975", "bodyText": "Done", "author": "zhaohaidao", "createdAt": "2020-05-02T01:25:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NDE4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NjE2OQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418786169", "bodyText": "If I understand this code correct, copartitionGroups take the list of co-partitioned nodes (ie, processor names -> copartitionSourceGroups) and replaces each processor name (each processor should be a source-processor?) with the corresponding source topic name?\nIf yes, a comment might be helpful. Also, name rename copartitionGroups -> allCopartitionedSourceTopics ?", "author": "mjsax", "createdAt": "2020-05-02T00:12:40Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,43 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCopartition() {\n+        final List<Set<String>> copartitionGroups =", "originalCommit": "d51217944133d168916ef224d19eeb3093991f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODgxNDk0Mw==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418814943", "bodyText": "Makes total sense. thanks for your advice.", "author": "zhaohaidao", "createdAt": "2020-05-02T01:27:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NjE2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NjI1MQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418786251", "bodyText": "rename node -> sourceNodeName ?", "author": "mjsax", "createdAt": "2020-05-02T00:13:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,43 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCopartition() {\n+        final List<Set<String>> copartitionGroups =\n+                copartitionSourceGroups\n+                        .stream()\n+                        .map(sourceGroup -> sourceGroup\n+                                .stream()\n+                                .flatMap(node -> nodeToSourceTopics.get(node).stream())", "originalCommit": "d51217944133d168916ef224d19eeb3093991f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODgxNTIxNw==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418815217", "bodyText": "Done", "author": "zhaohaidao", "createdAt": "2020-05-02T01:28:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NjI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4Njg2OQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418786869", "bodyText": "What is topicPartNum? Please avoid abbreviation; make the code hard to read?\nShould this be numberOfPartitionsPerTopic ?", "author": "mjsax", "createdAt": "2020-05-02T00:16:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,43 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCopartition() {\n+        final List<Set<String>> copartitionGroups =\n+                copartitionSourceGroups\n+                        .stream()\n+                        .map(sourceGroup -> sourceGroup\n+                                .stream()\n+                                .flatMap(node -> nodeToSourceTopics.get(node).stream())\n+                                .collect(Collectors.toSet())\n+                        ).collect(Collectors.toList());\n+        for (final Set<String> copartition : copartitionGroups) {\n+            final Map<String, Integer> topicPartNum = new HashMap<>();", "originalCommit": "d51217944133d168916ef224d19eeb3093991f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODgxNTQ5MA==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418815490", "bodyText": "Done and thanks for your advice.", "author": "zhaohaidao", "createdAt": "2020-05-02T01:28:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4Njg2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NzA5Mw==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418787093", "bodyText": "Why do we add all the partition numbers for all internal topics here? Seems redundant to the step from above?", "author": "mjsax", "createdAt": "2020-05-02T00:18:37Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,43 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCopartition() {\n+        final List<Set<String>> copartitionGroups =\n+                copartitionSourceGroups\n+                        .stream()\n+                        .map(sourceGroup -> sourceGroup\n+                                .stream()\n+                                .flatMap(node -> nodeToSourceTopics.get(node).stream())\n+                                .collect(Collectors.toSet())\n+                        ).collect(Collectors.toList());\n+        for (final Set<String> copartition : copartitionGroups) {\n+            final Map<String, Integer> topicPartNum = new HashMap<>();\n+            copartition.forEach(topic -> {\n+                final InternalTopicProperties prop = internalTopicNamesWithProperties.get(topic);\n+                if (prop != null && prop.getNumberOfPartitions().isPresent()) {\n+                    topicPartNum.put(topic, prop.getNumberOfPartitions().get());\n+                }\n+            });\n+            internalTopicNamesWithProperties.forEach((topic, prop) -> {\n+                if (copartition.contains(topic) && prop.getNumberOfPartitions().isPresent()) {\n+                    topicPartNum.put(topic, prop.getNumberOfPartitions().get());", "originalCommit": "d51217944133d168916ef224d19eeb3093991f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODgxNjQ3MA==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418816470", "bodyText": "Sorry, this is the side effects of unreasonable rebase operation.\nI have removed this redundant part", "author": "zhaohaidao", "createdAt": "2020-05-02T01:31:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NzA5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NzYzNA==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418787634", "bodyText": "How can we be sure that partNums is not empty? If empty, next() would throw.", "author": "mjsax", "createdAt": "2020-05-02T00:21:47Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,43 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCopartition() {\n+        final List<Set<String>> copartitionGroups =\n+                copartitionSourceGroups\n+                        .stream()\n+                        .map(sourceGroup -> sourceGroup\n+                                .stream()\n+                                .flatMap(node -> nodeToSourceTopics.get(node).stream())\n+                                .collect(Collectors.toSet())\n+                        ).collect(Collectors.toList());\n+        for (final Set<String> copartition : copartitionGroups) {\n+            final Map<String, Integer> topicPartNum = new HashMap<>();\n+            copartition.forEach(topic -> {\n+                final InternalTopicProperties prop = internalTopicNamesWithProperties.get(topic);\n+                if (prop != null && prop.getNumberOfPartitions().isPresent()) {\n+                    topicPartNum.put(topic, prop.getNumberOfPartitions().get());\n+                }\n+            });\n+            internalTopicNamesWithProperties.forEach((topic, prop) -> {\n+                if (copartition.contains(topic) && prop.getNumberOfPartitions().isPresent()) {\n+                    topicPartNum.put(topic, prop.getNumberOfPartitions().get());\n+                }\n+            });\n+            if (copartition.equals(topicPartNum.keySet())) {\n+                final Collection<Integer> partNums = topicPartNum.values();\n+                final Integer first = partNums.iterator().next();", "originalCommit": "d51217944133d168916ef224d19eeb3093991f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODgxNzEwNQ==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418817105", "bodyText": "done", "author": "zhaohaidao", "createdAt": "2020-05-02T01:32:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NzYzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NzY4Nw==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418787687", "bodyText": "Should this be !partNum.equals(first) ?", "author": "mjsax", "createdAt": "2020-05-02T00:22:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -633,6 +634,43 @@ public final void copartitionSources(final Collection<String> sourceNodes) {\n         copartitionSourceGroups.add(Collections.unmodifiableSet(new HashSet<>(sourceNodes)));\n     }\n \n+    public void validateCopartition() {\n+        final List<Set<String>> copartitionGroups =\n+                copartitionSourceGroups\n+                        .stream()\n+                        .map(sourceGroup -> sourceGroup\n+                                .stream()\n+                                .flatMap(node -> nodeToSourceTopics.get(node).stream())\n+                                .collect(Collectors.toSet())\n+                        ).collect(Collectors.toList());\n+        for (final Set<String> copartition : copartitionGroups) {\n+            final Map<String, Integer> topicPartNum = new HashMap<>();\n+            copartition.forEach(topic -> {\n+                final InternalTopicProperties prop = internalTopicNamesWithProperties.get(topic);\n+                if (prop != null && prop.getNumberOfPartitions().isPresent()) {\n+                    topicPartNum.put(topic, prop.getNumberOfPartitions().get());\n+                }\n+            });\n+            internalTopicNamesWithProperties.forEach((topic, prop) -> {\n+                if (copartition.contains(topic) && prop.getNumberOfPartitions().isPresent()) {\n+                    topicPartNum.put(topic, prop.getNumberOfPartitions().get());\n+                }\n+            });\n+            if (copartition.equals(topicPartNum.keySet())) {\n+                final Collection<Integer> partNums = topicPartNum.values();\n+                final Integer first = partNums.iterator().next();\n+                for (final Integer partNum : partNums) {\n+                    if (partNum.equals(first)) {", "originalCommit": "d51217944133d168916ef224d19eeb3093991f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODgyMDUwMA==", "url": "https://github.com/apache/kafka/pull/8550#discussion_r418820500", "bodyText": "Done. Sorry for this low-level mistake.", "author": "zhaohaidao", "createdAt": "2020-05-02T01:41:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODc4NzY4Nw=="}], "type": "inlineReview"}, {"oid": "4029bffd4e5afb61db112482afdb4e65a781db50", "url": "https://github.com/apache/kafka/commit/4029bffd4e5afb61db112482afdb4e65a781db50", "message": "Address comments", "committedDate": "2020-05-02T01:22:15Z", "type": "commit"}, {"oid": "c9f0b5fd8687ed1013d0471f3a148e3fd8bbb544", "url": "https://github.com/apache/kafka/commit/c9f0b5fd8687ed1013d0471f3a148e3fd8bbb544", "message": "resolve failed test", "committedDate": "2020-05-06T16:35:52Z", "type": "commit"}]}