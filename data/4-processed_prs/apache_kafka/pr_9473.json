{"pr_number": 9473, "pr_title": "KAFKA-10545: Create topic IDs in ZooKeeper and Controller", "pr_createdAt": "2020-10-21T17:23:28Z", "pr_url": "https://github.com/apache/kafka/pull/9473", "timeline": [{"oid": "841f99b0390a46df07544f7507dbd16d6d228ec3", "url": "https://github.com/apache/kafka/commit/841f99b0390a46df07544f7507dbd16d6d228ec3", "message": "Added topic IDs to ZK and the controller", "committedDate": "2020-10-21T15:52:12Z", "type": "commit"}, {"oid": "511661007b98a7c3a18b6a670eb0d5c5c736c155", "url": "https://github.com/apache/kafka/commit/511661007b98a7c3a18b6a670eb0d5c5c736c155", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516_Controller_and_ZK", "committedDate": "2020-10-21T15:53:30Z", "type": "commit"}, {"oid": "5197844d55318470cd1cc8f9304ed47d8eea34f1", "url": "https://github.com/apache/kafka/commit/5197844d55318470cd1cc8f9304ed47d8eea34f1", "message": "Minor spacing fix", "committedDate": "2020-10-21T15:56:59Z", "type": "commit"}, {"oid": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "url": "https://github.com/apache/kafka/commit/60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "message": "Removed option for some methods", "committedDate": "2020-10-21T17:16:45Z", "type": "commit"}, {"oid": "d3085425245f22aeca9880d0f43dc6ca1d882cf5", "url": "https://github.com/apache/kafka/commit/d3085425245f22aeca9880d0f43dc6ca1d882cf5", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516_Controller_and_ZK", "committedDate": "2020-10-23T16:43:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg4MDI1Ng==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511880256", "bodyText": "Do we want to do both checks first and update the two maps together at the end? We may also want to check that the topic exists in allTopics.", "author": "rajinisivaram", "createdAt": "2020-10-26T11:07:15Z", "path": "core/src/main/scala/kafka/controller/ControllerContext.scala", "diffHunk": "@@ -126,6 +130,23 @@ class ControllerContext {\n     replicaStates.clear()\n   }\n \n+  def addTopicId(topic: String, id: UUID): Unit = {\n+    topicIds.get(topic).foreach { existingId =>\n+      if (!existingId.equals(id))\n+        throw new IllegalStateException(\"topic ID map already contained ID for topic \"\n+          + topic + \" and new ID \" + id + \" did not match existing ID \"\n+          + existingId)\n+    }\n+    topicIds.put(topic, id)", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA1NDcwMQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r512054701", "bodyText": "Yeah. That makes sense to me.", "author": "jolshan", "createdAt": "2020-10-26T15:33:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg4MDI1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg4MjU2Mw==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511882563", "bodyText": "We could do:\ntopicIds.remove(topic).foreach { topicId =>\n  topicNames.remove(topicId)\n}", "author": "rajinisivaram", "createdAt": "2020-10-26T11:11:32Z", "path": "core/src/main/scala/kafka/controller/ControllerContext.scala", "diffHunk": "@@ -295,6 +316,10 @@ class ControllerContext {\n     topicsToBeDeleted -= topic\n     topicsWithDeletionStarted -= topic\n     allTopics -= topic\n+    if (topicIds.get(topic)!= None) {\n+      topicNames.remove(topicIds.get(topic).get)\n+      topicIds.remove(topic)\n+    }", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA4MTc0NA==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r512081744", "bodyText": "I was thinking about this some more, and I don't think we will have a case where the topic ID is not in the map (the if conditional is not needed.) However, the suggestion you gave is still good because it prevents the extra lookup.", "author": "jolshan", "createdAt": "2020-10-26T16:08:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg4MjU2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg4Njg0Mg==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511886842", "bodyText": "Can use controllerContext.topicIds(topicPartition.topic)", "author": "rajinisivaram", "createdAt": "2020-10-26T11:19:55Z", "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1027,7 +1032,9 @@ class KafkaController(val config: KafkaConfig,\n       controllerContext.partitionFullReplicaAssignmentForTopic(topicPartition.topic) +=\n       (topicPartition -> assignment)\n \n-    val setDataResponse = zkClient.setTopicAssignmentRaw(topicPartition.topic, topicAssignment, controllerContext.epochZkVersion)\n+    val setDataResponse = zkClient.setTopicAssignmentRaw(topicPartition.topic,\n+      controllerContext.topicIds.get(topicPartition.topic).get,", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg4ODE3Mg==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511888172", "bodyText": "As before: controllerContext.topicIds(topic)", "author": "rajinisivaram", "createdAt": "2020-10-26T11:22:19Z", "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1670,6 +1691,7 @@ class KafkaController(val config: KafkaConfig,\n       }.toMap\n \n       zkClient.setTopicAssignment(topic,\n+        controllerContext.topicIds.get(topic).get,", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg4OTgyOQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511889829", "bodyText": "topicIds(topic)", "author": "rajinisivaram", "createdAt": "2020-10-26T11:25:28Z", "path": "core/src/main/scala/kafka/zk/AdminZkClient.scala", "diffHunk": "@@ -158,9 +158,11 @@ class AdminZkClient(zkClient: KafkaZkClient) extends Logging {\n       val assignment = replicaAssignment.map { case (partitionId, replicas) => (new TopicPartition(topic,partitionId), replicas) }.toMap\n \n       if (!isUpdate) {\n-        zkClient.createTopicAssignment(topic, assignment.map { case (k, v) => k -> v.replicas })\n+        val topicId = UUID.randomUUID()\n+        zkClient.createTopicAssignment(topic, topicId, assignment.map { case (k, v) => k -> v.replicas })\n       } else {\n-        zkClient.setTopicAssignment(topic, assignment)\n+        val topicIds = zkClient.getTopicIdsForTopics(Set(topic))\n+        zkClient.setTopicAssignment(topic, topicIds.get(topic).get, assignment)", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5MTEwMQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511891101", "bodyText": "Is topicId optional?", "author": "rajinisivaram", "createdAt": "2020-10-26T11:27:57Z", "path": "core/src/main/scala/kafka/zk/KafkaZkClient.scala", "diffHunk": "@@ -481,43 +482,70 @@ class KafkaZkClient private[zk] (zooKeeperClient: ZooKeeperClient, isSecure: Boo\n     pathExists(TopicZNode.path(topicName))\n   }\n \n+  /**\n+   * Adds a topic ID to existing topic and replica assignments\n+   * @param topicIdReplicaAssignments the TopicIDReplicaAssignments to add a topic ID to\n+   * @return the updated TopicIdReplicaAssigments including the newly created topic IDs\n+   */\n+  def setTopicIds(topicIdReplicaAssignments: collection.Set[TopicIdReplicaAssignment],\n+                  expectedControllerEpochZkVersion: Int): Set[TopicIdReplicaAssignment] = {\n+    val updatedAssignments = topicIdReplicaAssignments.map {\n+      case TopicIdReplicaAssignment(topic, None, assignments) =>\n+        TopicIdReplicaAssignment(topic, Some(UUID.randomUUID()), assignments)\n+      case TopicIdReplicaAssignment(topic, Some(_), _) =>\n+        throw new IllegalArgumentException(\"TopicIdReplicaAssignment for \" + topic + \" already contains a topic ID.\")\n+    }.toSet\n+\n+    val setDataRequests = updatedAssignments.map { case TopicIdReplicaAssignment(topic, topicIdOpt, assignments) =>\n+      SetDataRequest(TopicZNode.path(topic), TopicZNode.encode(topicIdOpt.get, assignments), ZkVersion.MatchAnyVersion)\n+    }.toSeq\n+\n+    retryRequestsUntilConnected(setDataRequests, expectedControllerEpochZkVersion)\n+    updatedAssignments\n+  }\n+\n   /**\n    * Sets the topic znode with the given assignment.\n    * @param topic the topic whose assignment is being set.\n+   * @param topicId optional topic ID if the topic has one\n    * @param assignment the partition to replica mapping to set for the given topic\n    * @param expectedControllerEpochZkVersion expected controller epoch zkVersion.\n    * @return SetDataResponse\n    */\n   def setTopicAssignmentRaw(topic: String,\n+                            topicId: UUID,\n                             assignment: collection.Map[TopicPartition, ReplicaAssignment],\n                             expectedControllerEpochZkVersion: Int): SetDataResponse = {\n-    val setDataRequest = SetDataRequest(TopicZNode.path(topic), TopicZNode.encode(assignment), ZkVersion.MatchAnyVersion)\n+    val setDataRequest = SetDataRequest(TopicZNode.path(topic), TopicZNode.encode(topicId, assignment), ZkVersion.MatchAnyVersion)\n     retryRequestUntilConnected(setDataRequest, expectedControllerEpochZkVersion)\n   }\n \n   /**\n    * Sets the topic znode with the given assignment.\n    * @param topic the topic whose assignment is being set.\n+   * @param topicId optional topic ID if the topic has one", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA1NjU3OA==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r512056578", "bodyText": "I meant to fix this. Thanks for catching.", "author": "jolshan", "createdAt": "2020-10-26T15:36:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5MTEwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5MTIwMQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511891201", "bodyText": "Is topicId optional?", "author": "rajinisivaram", "createdAt": "2020-10-26T11:28:11Z", "path": "core/src/main/scala/kafka/zk/KafkaZkClient.scala", "diffHunk": "@@ -481,43 +482,70 @@ class KafkaZkClient private[zk] (zooKeeperClient: ZooKeeperClient, isSecure: Boo\n     pathExists(TopicZNode.path(topicName))\n   }\n \n+  /**\n+   * Adds a topic ID to existing topic and replica assignments\n+   * @param topicIdReplicaAssignments the TopicIDReplicaAssignments to add a topic ID to\n+   * @return the updated TopicIdReplicaAssigments including the newly created topic IDs\n+   */\n+  def setTopicIds(topicIdReplicaAssignments: collection.Set[TopicIdReplicaAssignment],\n+                  expectedControllerEpochZkVersion: Int): Set[TopicIdReplicaAssignment] = {\n+    val updatedAssignments = topicIdReplicaAssignments.map {\n+      case TopicIdReplicaAssignment(topic, None, assignments) =>\n+        TopicIdReplicaAssignment(topic, Some(UUID.randomUUID()), assignments)\n+      case TopicIdReplicaAssignment(topic, Some(_), _) =>\n+        throw new IllegalArgumentException(\"TopicIdReplicaAssignment for \" + topic + \" already contains a topic ID.\")\n+    }.toSet\n+\n+    val setDataRequests = updatedAssignments.map { case TopicIdReplicaAssignment(topic, topicIdOpt, assignments) =>\n+      SetDataRequest(TopicZNode.path(topic), TopicZNode.encode(topicIdOpt.get, assignments), ZkVersion.MatchAnyVersion)\n+    }.toSeq\n+\n+    retryRequestsUntilConnected(setDataRequests, expectedControllerEpochZkVersion)\n+    updatedAssignments\n+  }\n+\n   /**\n    * Sets the topic znode with the given assignment.\n    * @param topic the topic whose assignment is being set.\n+   * @param topicId optional topic ID if the topic has one\n    * @param assignment the partition to replica mapping to set for the given topic\n    * @param expectedControllerEpochZkVersion expected controller epoch zkVersion.\n    * @return SetDataResponse\n    */\n   def setTopicAssignmentRaw(topic: String,\n+                            topicId: UUID,\n                             assignment: collection.Map[TopicPartition, ReplicaAssignment],\n                             expectedControllerEpochZkVersion: Int): SetDataResponse = {\n-    val setDataRequest = SetDataRequest(TopicZNode.path(topic), TopicZNode.encode(assignment), ZkVersion.MatchAnyVersion)\n+    val setDataRequest = SetDataRequest(TopicZNode.path(topic), TopicZNode.encode(topicId, assignment), ZkVersion.MatchAnyVersion)\n     retryRequestUntilConnected(setDataRequest, expectedControllerEpochZkVersion)\n   }\n \n   /**\n    * Sets the topic znode with the given assignment.\n    * @param topic the topic whose assignment is being set.\n+   * @param topicId optional topic ID if the topic has one\n    * @param assignment the partition to replica mapping to set for the given topic\n    * @param expectedControllerEpochZkVersion expected controller epoch zkVersion.\n    * @throws KeeperException if there is an error while setting assignment\n    */\n   def setTopicAssignment(topic: String,\n+                         topicId: UUID,\n                          assignment: Map[TopicPartition, ReplicaAssignment],\n                          expectedControllerEpochZkVersion: Int = ZkVersion.MatchAnyVersion) = {\n-    val setDataResponse = setTopicAssignmentRaw(topic, assignment, expectedControllerEpochZkVersion)\n+    val setDataResponse = setTopicAssignmentRaw(topic, topicId, assignment, expectedControllerEpochZkVersion)\n     setDataResponse.maybeThrow()\n   }\n \n   /**\n    * Create the topic znode with the given assignment.\n    * @param topic the topic whose assignment is being set.\n+   * @param topicId optional topic ID if the topic has one", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5MzI2Mw==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511893263", "bodyText": "Do we expect cases where topicId is not defined? If so, do we need to distinguish between topics that don't exist and topics that don't have topic ids? Either way, we should update javadoc (unless we throw an IllegalStateException here for topic id not set).", "author": "rajinisivaram", "createdAt": "2020-10-26T11:32:18Z", "path": "core/src/main/scala/kafka/zk/KafkaZkClient.scala", "diffHunk": "@@ -577,6 +605,27 @@ class KafkaZkClient private[zk] (zooKeeperClient: ZooKeeperClient, isSecure: Boo\n     retryRequestsUntilConnected(deleteRequests, expectedControllerEpochZkVersion)\n   }\n \n+  /**\n+   * Gets the topic IDs for the given topics.\n+   * @param topics the topics we wish to retrieve the Topic IDs for\n+   * @return the Topic IDs\n+   */\n+  def getTopicIdsForTopics(topics: Set[String]): Map[String, UUID] = {\n+    val getDataRequests = topics.map(topic => GetDataRequest(TopicZNode.path(topic), ctx = Some(topic)))\n+    val getDataResponses = retryRequestsUntilConnected(getDataRequests.toSeq)\n+    getDataResponses.map { getDataResponse =>\n+      val topic = getDataResponse.ctx.get.asInstanceOf[String]\n+      getDataResponse.resultCode match {\n+        case Code.OK => Some(TopicZNode.decode(topic, getDataResponse.data))\n+        case Code.NONODE => None\n+        case _ => throw getDataResponse.resultException.get\n+      }\n+    }.filter(_.flatMap(_.topicId).isDefined)", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA2ODEyNQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r512068125", "bodyText": "In the case where the topic was created on an older version (where there are no topic IDs yet, we will have the case where topic IDs are not defined. However, I believe in the case where this is used, we should have topic IDs defined. (I'm expecting a topic ID on the following line, so an error would occur there if it was missing.) I'm thinking it would make sense to remove the filter line and maybe throw an error here (earlier) if it is not set.", "author": "jolshan", "createdAt": "2020-10-26T15:50:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5MzI2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5NDQ0NA==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511894444", "bodyText": "nit: indentation - looks like the indentation of the if statement above is off.", "author": "rajinisivaram", "createdAt": "2020-10-26T11:34:44Z", "path": "core/src/main/scala/kafka/zk/KafkaZkClient.scala", "diffHunk": "@@ -616,7 +683,7 @@ class KafkaZkClient private[zk] (zooKeeperClient: ZooKeeperClient, isSecure: Boo\n     getDataResponses.flatMap { getDataResponse =>\n       val topic = getDataResponse.ctx.get.asInstanceOf[String]\n        if (getDataResponse.resultCode == Code.OK) {\n-        val partitionMap = TopicZNode.decode(topic, getDataResponse.data).map { case (k, v) => (k.partition, v) }\n+         val partitionMap = TopicZNode.decode(topic, getDataResponse.data).assignment.map { case (k, v) => (k.partition, v) }", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA2OTMzOQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r512069339", "bodyText": "I've found a few style errors while working on this and I wasn't sure the protocol. I guess it makes sense to fix the style in the block of code I'm working on. (But it's a little confusing when its not the areas of code I'm working on)", "author": "jolshan", "createdAt": "2020-10-26T15:52:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5NDQ0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5NTk0MA==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511895940", "bodyText": "assertNotEquals?", "author": "rajinisivaram", "createdAt": "2020-10-26T11:37:42Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerIntegrationTest.scala", "diffHunk": "@@ -848,6 +848,110 @@ class ControllerIntegrationTest extends ZooKeeperTestHarness {\n     latch.await()\n   }\n \n+  @Test\n+  def testTopicIdsAreAdded(): Unit = {\n+    servers = makeServers(1)\n+    TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp1 = new TopicPartition(\"t1\", 0)\n+    val assignment1 = Map(tp1.partition -> Seq(0))\n+\n+    // Before adding the topic, an attempt to get the ID should result in None.\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") == None)\n+\n+    TestUtils.createTopic(zkClient, tp1.topic(), assignment1, servers)\n+\n+    // Test that the first topic has its ID added correctly\n+    waitForPartitionState(tp1, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") != None)", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5NjM4Ng==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511896386", "bodyText": ".topicIds(\"t1\")", "author": "rajinisivaram", "createdAt": "2020-10-26T11:38:36Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerIntegrationTest.scala", "diffHunk": "@@ -848,6 +848,110 @@ class ControllerIntegrationTest extends ZooKeeperTestHarness {\n     latch.await()\n   }\n \n+  @Test\n+  def testTopicIdsAreAdded(): Unit = {\n+    servers = makeServers(1)\n+    TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp1 = new TopicPartition(\"t1\", 0)\n+    val assignment1 = Map(tp1.partition -> Seq(0))\n+\n+    // Before adding the topic, an attempt to get the ID should result in None.\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") == None)\n+\n+    TestUtils.createTopic(zkClient, tp1.topic(), assignment1, servers)\n+\n+    // Test that the first topic has its ID added correctly\n+    waitForPartitionState(tp1, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") != None)\n+    val topicId1 = controller.controllerContext.topicIds.get(\"t1\").get", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5Njc3MA==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511896770", "bodyText": "Reverse the arguments since expected value comes first?", "author": "rajinisivaram", "createdAt": "2020-10-26T11:39:18Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerIntegrationTest.scala", "diffHunk": "@@ -848,6 +848,110 @@ class ControllerIntegrationTest extends ZooKeeperTestHarness {\n     latch.await()\n   }\n \n+  @Test\n+  def testTopicIdsAreAdded(): Unit = {\n+    servers = makeServers(1)\n+    TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp1 = new TopicPartition(\"t1\", 0)\n+    val assignment1 = Map(tp1.partition -> Seq(0))\n+\n+    // Before adding the topic, an attempt to get the ID should result in None.\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") == None)\n+\n+    TestUtils.createTopic(zkClient, tp1.topic(), assignment1, servers)\n+\n+    // Test that the first topic has its ID added correctly\n+    waitForPartitionState(tp1, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") != None)\n+    val topicId1 = controller.controllerContext.topicIds.get(\"t1\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId1), \"t1\")", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5NzE0MQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511897141", "bodyText": "Same comments as earlier for this block.", "author": "rajinisivaram", "createdAt": "2020-10-26T11:40:02Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerIntegrationTest.scala", "diffHunk": "@@ -848,6 +848,110 @@ class ControllerIntegrationTest extends ZooKeeperTestHarness {\n     latch.await()\n   }\n \n+  @Test\n+  def testTopicIdsAreAdded(): Unit = {\n+    servers = makeServers(1)\n+    TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp1 = new TopicPartition(\"t1\", 0)\n+    val assignment1 = Map(tp1.partition -> Seq(0))\n+\n+    // Before adding the topic, an attempt to get the ID should result in None.\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") == None)\n+\n+    TestUtils.createTopic(zkClient, tp1.topic(), assignment1, servers)\n+\n+    // Test that the first topic has its ID added correctly\n+    waitForPartitionState(tp1, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") != None)\n+    val topicId1 = controller.controllerContext.topicIds.get(\"t1\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId1), \"t1\")\n+\n+    val tp2 = new TopicPartition(\"t2\", 0)\n+    val assignment2 = Map(tp2.partition -> Seq(0))\n+    TestUtils.createTopic(zkClient, tp2.topic(), assignment2, servers)\n+\n+    // Test that the second topic has its ID added correctly\n+    waitForPartitionState(tp2, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t2\") != None)\n+    val topicId2 = controller.controllerContext.topicIds.get(\"t2\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId2), \"t2\")", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5NzI3Nw==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511897277", "bodyText": "assertNotEquals", "author": "rajinisivaram", "createdAt": "2020-10-26T11:40:17Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerIntegrationTest.scala", "diffHunk": "@@ -848,6 +848,110 @@ class ControllerIntegrationTest extends ZooKeeperTestHarness {\n     latch.await()\n   }\n \n+  @Test\n+  def testTopicIdsAreAdded(): Unit = {\n+    servers = makeServers(1)\n+    TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp1 = new TopicPartition(\"t1\", 0)\n+    val assignment1 = Map(tp1.partition -> Seq(0))\n+\n+    // Before adding the topic, an attempt to get the ID should result in None.\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") == None)\n+\n+    TestUtils.createTopic(zkClient, tp1.topic(), assignment1, servers)\n+\n+    // Test that the first topic has its ID added correctly\n+    waitForPartitionState(tp1, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") != None)\n+    val topicId1 = controller.controllerContext.topicIds.get(\"t1\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId1), \"t1\")\n+\n+    val tp2 = new TopicPartition(\"t2\", 0)\n+    val assignment2 = Map(tp2.partition -> Seq(0))\n+    TestUtils.createTopic(zkClient, tp2.topic(), assignment2, servers)\n+\n+    // Test that the second topic has its ID added correctly\n+    waitForPartitionState(tp2, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t2\") != None)\n+    val topicId2 = controller.controllerContext.topicIds.get(\"t2\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId2), \"t2\")\n+\n+    // The first topic ID has not changed\n+    assertEquals(topicId1, controller.controllerContext.topicIds.get(\"t1\").get)\n+    assertTrue(!topicId1.equals(topicId2))", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5ODU4Nw==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511898587", "bodyText": "nit: unnecessary newline", "author": "rajinisivaram", "createdAt": "2020-10-26T11:42:45Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerIntegrationTest.scala", "diffHunk": "@@ -848,6 +848,110 @@ class ControllerIntegrationTest extends ZooKeeperTestHarness {\n     latch.await()\n   }\n \n+  @Test\n+  def testTopicIdsAreAdded(): Unit = {\n+    servers = makeServers(1)\n+    TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp1 = new TopicPartition(\"t1\", 0)\n+    val assignment1 = Map(tp1.partition -> Seq(0))\n+\n+    // Before adding the topic, an attempt to get the ID should result in None.\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") == None)\n+\n+    TestUtils.createTopic(zkClient, tp1.topic(), assignment1, servers)\n+\n+    // Test that the first topic has its ID added correctly\n+    waitForPartitionState(tp1, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") != None)\n+    val topicId1 = controller.controllerContext.topicIds.get(\"t1\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId1), \"t1\")\n+\n+    val tp2 = new TopicPartition(\"t2\", 0)\n+    val assignment2 = Map(tp2.partition -> Seq(0))\n+    TestUtils.createTopic(zkClient, tp2.topic(), assignment2, servers)\n+\n+    // Test that the second topic has its ID added correctly\n+    waitForPartitionState(tp2, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t2\") != None)\n+    val topicId2 = controller.controllerContext.topicIds.get(\"t2\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId2), \"t2\")\n+\n+    // The first topic ID has not changed\n+    assertEquals(topicId1, controller.controllerContext.topicIds.get(\"t1\").get)\n+    assertTrue(!topicId1.equals(topicId2))\n+  }\n+\n+\n+  @Test\n+  def testTopicIdMigrationAndHandling(): Unit = {\n+    val tp = new TopicPartition(\"t\", 0)\n+    val assignment = Map(tp.partition -> ReplicaAssignment(Seq(0), List(), List()))\n+    val adminZkClient = new AdminZkClient(zkClient)\n+\n+    servers = makeServers(1)\n+    adminZkClient.createTopic(tp.topic, 1, 1)\n+    waitForPartitionState(tp, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    val topicIdAfterCreate = zkClient.getTopicIdsForTopics(Set(tp.topic())).get(tp.topic())\n+    assertTrue(topicIdAfterCreate.isDefined)\n+    assertEquals(\"correct topic ID cannot be found in the controller context\",\n+      topicIdAfterCreate, servers.head.kafkaController.controllerContext.topicIds.get(tp.topic))\n+\n+    adminZkClient.addPartitions(tp.topic, assignment, adminZkClient.getBrokerMetadatas(), 2)\n+    val topicIdAfterAddition = zkClient.getTopicIdsForTopics(Set(tp.topic())).get(tp.topic())\n+    assertEquals(topicIdAfterCreate, topicIdAfterAddition)\n+    assertEquals(\"topic ID changed after partition additions\",\n+      topicIdAfterCreate, servers.head.kafkaController.controllerContext.topicIds.get(tp.topic))\n+\n+    adminZkClient.deleteTopic(tp.topic)\n+    TestUtils.waitUntilTrue(() => servers.head.kafkaController.controllerContext.topicIds.get(tp.topic).isEmpty,\n+      \"topic ID for topic should have been removed from controller context after deletion\")\n+  }\n+\n+  @Test\n+  def testTopicIdPersistsThroughControllerReelection(): Unit = {\n+    servers = makeServers(2)\n+    val controllerId = TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp = new TopicPartition(\"t\", 0)\n+    val assignment = Map(tp.partition -> Seq(controllerId))\n+    TestUtils.createTopic(zkClient, tp.topic, partitionReplicaAssignment = assignment, servers = servers)\n+    waitForPartitionState(tp, firstControllerEpoch, controllerId, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    val topicId = controller.controllerContext.topicIds.get(\"t\").get\n+\n+", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5OTExOQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511899119", "bodyText": "nit: unnecessary newline (just one required)?", "author": "rajinisivaram", "createdAt": "2020-10-26T11:43:50Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerIntegrationTest.scala", "diffHunk": "@@ -848,6 +848,110 @@ class ControllerIntegrationTest extends ZooKeeperTestHarness {\n     latch.await()\n   }\n \n+  @Test\n+  def testTopicIdsAreAdded(): Unit = {\n+    servers = makeServers(1)\n+    TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp1 = new TopicPartition(\"t1\", 0)\n+    val assignment1 = Map(tp1.partition -> Seq(0))\n+\n+    // Before adding the topic, an attempt to get the ID should result in None.\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") == None)\n+\n+    TestUtils.createTopic(zkClient, tp1.topic(), assignment1, servers)\n+\n+    // Test that the first topic has its ID added correctly\n+    waitForPartitionState(tp1, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t1\") != None)\n+    val topicId1 = controller.controllerContext.topicIds.get(\"t1\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId1), \"t1\")\n+\n+    val tp2 = new TopicPartition(\"t2\", 0)\n+    val assignment2 = Map(tp2.partition -> Seq(0))\n+    TestUtils.createTopic(zkClient, tp2.topic(), assignment2, servers)\n+\n+    // Test that the second topic has its ID added correctly\n+    waitForPartitionState(tp2, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    assertTrue(controller.controllerContext.topicIds.get(\"t2\") != None)\n+    val topicId2 = controller.controllerContext.topicIds.get(\"t2\").get\n+    assertEquals(controller.controllerContext.topicNames(topicId2), \"t2\")\n+\n+    // The first topic ID has not changed\n+    assertEquals(topicId1, controller.controllerContext.topicIds.get(\"t1\").get)\n+    assertTrue(!topicId1.equals(topicId2))\n+  }\n+\n+\n+  @Test\n+  def testTopicIdMigrationAndHandling(): Unit = {\n+    val tp = new TopicPartition(\"t\", 0)\n+    val assignment = Map(tp.partition -> ReplicaAssignment(Seq(0), List(), List()))\n+    val adminZkClient = new AdminZkClient(zkClient)\n+\n+    servers = makeServers(1)\n+    adminZkClient.createTopic(tp.topic, 1, 1)\n+    waitForPartitionState(tp, firstControllerEpoch, 0, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    val topicIdAfterCreate = zkClient.getTopicIdsForTopics(Set(tp.topic())).get(tp.topic())\n+    assertTrue(topicIdAfterCreate.isDefined)\n+    assertEquals(\"correct topic ID cannot be found in the controller context\",\n+      topicIdAfterCreate, servers.head.kafkaController.controllerContext.topicIds.get(tp.topic))\n+\n+    adminZkClient.addPartitions(tp.topic, assignment, adminZkClient.getBrokerMetadatas(), 2)\n+    val topicIdAfterAddition = zkClient.getTopicIdsForTopics(Set(tp.topic())).get(tp.topic())\n+    assertEquals(topicIdAfterCreate, topicIdAfterAddition)\n+    assertEquals(\"topic ID changed after partition additions\",\n+      topicIdAfterCreate, servers.head.kafkaController.controllerContext.topicIds.get(tp.topic))\n+\n+    adminZkClient.deleteTopic(tp.topic)\n+    TestUtils.waitUntilTrue(() => servers.head.kafkaController.controllerContext.topicIds.get(tp.topic).isEmpty,\n+      \"topic ID for topic should have been removed from controller context after deletion\")\n+  }\n+\n+  @Test\n+  def testTopicIdPersistsThroughControllerReelection(): Unit = {\n+    servers = makeServers(2)\n+    val controllerId = TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp = new TopicPartition(\"t\", 0)\n+    val assignment = Map(tp.partition -> Seq(controllerId))\n+    TestUtils.createTopic(zkClient, tp.topic, partitionReplicaAssignment = assignment, servers = servers)\n+    waitForPartitionState(tp, firstControllerEpoch, controllerId, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    val topicId = controller.controllerContext.topicIds.get(\"t\").get\n+\n+\n+    servers(controllerId).shutdown()\n+    servers(controllerId).awaitShutdown()\n+    TestUtils.waitUntilTrue(() => zkClient.getControllerId.isDefined, \"failed to elect a controller\")\n+    val controller2 = getController().kafkaController\n+    assertEquals(topicId, controller2.controllerContext.topicIds.get(\"t\").get)\n+  }\n+\n+  @Test\n+  def testTopicIdPersistsThroughControllerRestart(): Unit = {\n+    servers = makeServers(1)\n+    val controllerId = TestUtils.waitUntilControllerElected(zkClient)\n+    val controller = getController().kafkaController\n+    val tp = new TopicPartition(\"t\", 0)\n+    val assignment = Map(tp.partition -> Seq(controllerId))\n+    TestUtils.createTopic(zkClient, tp.topic, partitionReplicaAssignment = assignment, servers = servers)\n+    waitForPartitionState(tp, firstControllerEpoch, controllerId, LeaderAndIsr.initialLeaderEpoch,\n+      \"failed to get expected partition state upon topic creation\")\n+    val topicId = controller.controllerContext.topicIds.get(\"t\").get\n+\n+", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg5OTkyNg==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r511899926", "bodyText": "topicIds(topic1) instead of .get().get() - multiple places", "author": "rajinisivaram", "createdAt": "2020-10-26T11:45:20Z", "path": "core/src/test/scala/unit/kafka/zk/KafkaZkClientTest.scala", "diffHunk": "@@ -194,7 +195,7 @@ class KafkaZkClientTest extends ZooKeeperTestHarness {\n     )\n \n     // create a topic assignment\n-    zkClient.createTopicAssignment(topic1, assignment)\n+    zkClient.createTopicAssignment(topic1, topicIds.get(topic1).get, assignment)", "originalCommit": "60954917ea2c6f2ec0dd1000db62cce05d05e5e7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "87d8331dbf47eb149870a4553e7867a6ceb38087", "url": "https://github.com/apache/kafka/commit/87d8331dbf47eb149870a4553e7867a6ceb38087", "message": "Removes some verbose code, fixes comments, and other style fixes. Now getTopicIdsForTopics throws IllegalStateException\nif one of the topics does not have a topic ID.", "committedDate": "2020-10-26T18:05:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDMwMjQ3Mw==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r514302473", "bodyText": "nit: we can use string interpolation with these to make them a little bit neater e.g. s\"topic $topic is not contained in all topics\".", "author": "lbradstreet", "createdAt": "2020-10-29T14:29:17Z", "path": "core/src/main/scala/kafka/controller/ControllerContext.scala", "diffHunk": "@@ -126,6 +130,26 @@ class ControllerContext {\n     replicaStates.clear()\n   }\n \n+  def addTopicId(topic: String, id: UUID): Unit = {\n+    if (!allTopics.contains(topic))\n+      throw new IllegalStateException(\"topic \" + topic +  \" is not contained in all topics.\")", "originalCommit": "87d8331dbf47eb149870a4553e7867a6ceb38087", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "15b170071c1f3202364c7c4ec35e1fb28b0506a9", "url": "https://github.com/apache/kafka/commit/15b170071c1f3202364c7c4ec35e1fb28b0506a9", "message": "Simplified error messages", "committedDate": "2020-10-29T17:03:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjU0OTA1OA==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r516549058", "bodyText": "Should these 2 names be more self-explanatory?", "author": "dengziming", "createdAt": "2020-11-03T10:04:31Z", "path": "core/src/main/scala/kafka/controller/ControllerContext.scala", "diffHunk": "@@ -83,6 +83,8 @@ class ControllerContext {\n   var epochZkVersion: Int = KafkaController.InitialControllerEpochZkVersion\n \n   val allTopics = mutable.Set.empty[String]\n+  var topicIds = mutable.Map.empty[String, UUID]", "originalCommit": "15b170071c1f3202364c7c4ec35e1fb28b0506a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg1NDE4OA==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r516854188", "bodyText": "What part of the names is unclear? The name describes values of the map, so is it not clear what the keys should be?", "author": "jolshan", "createdAt": "2020-11-03T17:55:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjU0OTA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NTM4MA==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r516995380", "bodyText": "Well, topicIds and topicNames may already enough self-explanatory.", "author": "dengziming", "createdAt": "2020-11-03T22:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjU0OTA1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5NzQ3Mw==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r518097473", "bodyText": "Why not bump the version? the version is bumped to 3 according to the KIP", "author": "dengziming", "createdAt": "2020-11-05T14:35:10Z", "path": "core/src/main/scala/kafka/zk/ZkData.scala", "diffHunk": "@@ -293,14 +297,17 @@ object TopicZNode {\n         removingReplicasAssignmentJson += (partition.partition.toString -> replicaAssignment.removingReplicas.asJava)\n     }\n \n-    Json.encodeAsBytes(Map(\n+    val topicAssignment = mutable.Map(\n       \"version\" -> 2,", "originalCommit": "15b170071c1f3202364c7c4ec35e1fb28b0506a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODIyMDE4OQ==", "url": "https://github.com/apache/kafka/pull/9473#discussion_r518220189", "bodyText": "Good catch. I'll fix that.", "author": "jolshan", "createdAt": "2020-11-05T17:16:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5NzQ3Mw=="}], "type": "inlineReview"}, {"oid": "94af4a6d3d1a6c889199c7d51f467af555baf120", "url": "https://github.com/apache/kafka/commit/94af4a6d3d1a6c889199c7d51f467af555baf120", "message": "Updated version on Topic ZNode", "committedDate": "2020-11-05T17:19:50Z", "type": "commit"}, {"oid": "3ba3bbe0283794eb6d9f5a1f54b4272e66deabec", "url": "https://github.com/apache/kafka/commit/3ba3bbe0283794eb6d9f5a1f54b4272e66deabec", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516_Controller_and_ZK", "committedDate": "2020-11-18T16:35:33Z", "type": "commit"}, {"oid": "a77816f2889fd1cc3e369ba87fd0b2af03e9865c", "url": "https://github.com/apache/kafka/commit/a77816f2889fd1cc3e369ba87fd0b2af03e9865c", "message": "Update to use new Uuid class", "committedDate": "2020-11-18T17:22:40Z", "type": "commit"}]}