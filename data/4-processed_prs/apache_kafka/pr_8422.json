{"pr_number": 8422, "pr_title": "KAFKA-9820: validateMessagesAndAssignOffsetsCompressed allocates unused iterator", "pr_createdAt": "2020-04-04T00:06:35Z", "pr_url": "https://github.com/apache/kafka/pull/8422", "timeline": [{"oid": "c89eca6060defa480843b6e93a811f1f0b57ad3d", "url": "https://github.com/apache/kafka/commit/c89eca6060defa480843b6e93a811f1f0b57ad3d", "message": "KAFKA-9820: validateMessagesAndAssignOffsetsCompressed allocates batch iterator which is not used", "committedDate": "2020-04-04T00:03:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5MTI5OA==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403391298", "bodyText": "FIXME", "author": "lbradstreet", "createdAt": "2020-04-04T00:07:52Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/record/RecordBatchIterationBenchmark.java", "diffHunk": "@@ -57,13 +65,13 @@\n         RANDOM, ONES\n     }\n \n-    @Param(value = {\"10\", \"50\", \"200\", \"500\"})\n+    @Param(value = {\"1\", \"2\", \"10\", \"50\", \"200\", \"500\"})\n     private int maxBatchSize = 200;\n \n     @Param(value = {\"LZ4\", \"SNAPPY\", \"GZIP\", \"ZSTD\", \"NONE\"})\n     private CompressionType compressionType = CompressionType.NONE;\n \n-    @Param(value = {\"1\", \"2\"})\n+    @Param(value = {\"2\"})", "originalCommit": "c89eca6060defa480843b6e93a811f1f0b57ad3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5MTU5OA==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403391598", "bodyText": "This should use the correct compression type", "author": "lbradstreet", "createdAt": "2020-04-04T00:09:15Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/record/RecordBatchIterationBenchmark.java", "diffHunk": "@@ -122,6 +144,19 @@ private ByteBuffer createBatch(int batchSize) {\n         return builder.build().buffer();\n     }\n \n+    @Benchmark\n+    public void measureValidation(Blackhole bh) throws IOException {\n+        MemoryRecords records = MemoryRecords.readableRecords(singleBatchBuffer.duplicate());\n+        LogValidator.validateMessagesAndAssignOffsetsCompressed(records, new TopicPartition(\"a\", 0),\n+                new LongRef(startingOffset), Time.SYSTEM, System.currentTimeMillis(),\n+                CompressionCodec.getCompressionCodec(\"GZIP\"),", "originalCommit": "c89eca6060defa480843b6e93a811f1f0b57ad3d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "321fa61d69c02da7fd72314ee4c32d12bb64275f", "url": "https://github.com/apache/kafka/commit/321fa61d69c02da7fd72314ee4c32d12bb64275f", "message": "Benchmark fixes", "committedDate": "2020-04-04T00:10:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5MjE1MQ==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403392151", "bodyText": "Are we using the while loop to try and avoid the tuple allocation or something? Seems like that would be noise compared to the other allocations, no?", "author": "ijuma", "createdAt": "2020-04-04T00:12:20Z", "path": "core/src/main/scala/kafka/log/LogValidator.scala", "diffHunk": "@@ -414,7 +414,9 @@ private[log] object LogValidator extends Logging {\n \n       try {\n         val recordErrors = new ArrayBuffer[ApiRecordError](0)\n-        for ((record, batchIndex) <- batch.asScala.view.zipWithIndex) {\n+        var batchIndex = 0\n+        while (recordsIterator.hasNext) {", "originalCommit": "c89eca6060defa480843b6e93a811f1f0b57ad3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5MzI3Ng==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403393276", "bodyText": "recordsIterator is not an iterable like batches is, so I couldn't figure out how to zip it. I should change this to a scala for at very least.", "author": "lbradstreet", "createdAt": "2020-04-04T00:17:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5MjE1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5NDYzNg==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403394636", "bodyText": "Yeah, asScala.zip.... Anyway, your update seems fine.", "author": "ijuma", "createdAt": "2020-04-04T00:24:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5MjE1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5NTQ5NA==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403395494", "bodyText": "huh, I was trying that but intellij wasn't autocompleting. Not sure what happened.", "author": "lbradstreet", "createdAt": "2020-04-04T00:29:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5MjE1MQ=="}], "type": "inlineReview"}, {"oid": "daba7286f7dbe24f998dee3aeb86f0b34f497a0f", "url": "https://github.com/apache/kafka/commit/daba7286f7dbe24f998dee3aeb86f0b34f497a0f", "message": "Use scala for rather than iterator", "committedDate": "2020-04-04T00:17:56Z", "type": "commit"}, {"oid": "47498014aefffd280aedad9596754bce86d01cb4", "url": "https://github.com/apache/kafka/commit/47498014aefffd280aedad9596754bce86d01cb4", "message": "checkstyle", "committedDate": "2020-04-04T00:43:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ3OTQ0Mg==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403479442", "bodyText": "Why do we want the starting offset to be 0 for message version 2?", "author": "ijuma", "createdAt": "2020-04-04T14:58:49Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/record/RecordBatchIterationBenchmark.java", "diffHunk": "@@ -83,9 +94,20 @@\n     private int[] batchSizes;\n     private BufferSupplier bufferSupplier;\n \n+\n+\n     @Setup\n     public void init() {\n-        bufferSupplier = BufferSupplier.create();\n+        // zero starting offset is much faster for v1 batches, but that will almost never happen\n+        startingOffset = messageVersion == 2 ? 0 : 42;", "originalCommit": "47498014aefffd280aedad9596754bce86d01cb4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4MzE4NQ==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403483185", "bodyText": "That's a good question which I should have discussed. v2 batches should be created with relative offsets/baseOffset 0, and then they should be stamped in validateMessagesAndAssignOffsetsCompressed. If we use a startingOffset of 42 we generate a batch that will not pass validation as the relative offset of its first message is 42. A better solution is to have a startingOffset of 42 in the stamping phase and a starting  offset of 0 as the baseOffset for the builder (all of the LogTest code uses 0 for multiple batches).", "author": "lbradstreet", "createdAt": "2020-04-04T15:35:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ3OTQ0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4NzI2Mg==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403487262", "bodyText": "I adjusted the comment as the benchmark will mutate the batch and causing failures in later iterations. Starting with baseOffset 0 solves this problem in a way which does not require @Setup(Level.Invocation) which has numerous gotchas with respect to accurate measurements.", "author": "lbradstreet", "createdAt": "2020-04-04T16:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ3OTQ0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4ODY1OQ==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403488659", "bodyText": "Did we miss a as after 0?", "author": "ijuma", "createdAt": "2020-04-04T16:30:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ3OTQ0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ5MDc3NQ==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403490775", "bodyText": "Fixed", "author": "lbradstreet", "createdAt": "2020-04-04T16:50:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ3OTQ0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQ4MjgyOA==", "url": "https://github.com/apache/kafka/pull/8422#discussion_r403482828", "bodyText": "why not using zipWithIndex?\n        recordsIterator.asScala.zipWithIndex.foreach {\n          case (record, batchIndex) =>\nThe zipWithIndex on scala iterator is a wrap so it should not cause performance regression too much.", "author": "chia7712", "createdAt": "2020-04-04T15:31:50Z", "path": "core/src/main/scala/kafka/log/LogValidator.scala", "diffHunk": "@@ -414,7 +414,8 @@ private[log] object LogValidator extends Logging {\n \n       try {\n         val recordErrors = new ArrayBuffer[ApiRecordError](0)\n-        for ((record, batchIndex) <- batch.asScala.view.zipWithIndex) {\n+        var batchIndex = 0\n+        for (record <- recordsIterator.asScala) {", "originalCommit": "47498014aefffd280aedad9596754bce86d01cb4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "826c302b0aa43881eda4d1ec434cde86e9129388", "url": "https://github.com/apache/kafka/commit/826c302b0aa43881eda4d1ec434cde86e9129388", "message": "Adjust the comment to describe v2 batches", "committedDate": "2020-04-04T16:13:04Z", "type": "commit"}, {"oid": "2745f6310090d5b327bc88fe9837ab8c415f651e", "url": "https://github.com/apache/kafka/commit/2745f6310090d5b327bc88fe9837ab8c415f651e", "message": "Improve comment", "committedDate": "2020-04-04T16:49:51Z", "type": "commit"}, {"oid": "921fa1c48f0815f971ce40b7280133150d867c6e", "url": "https://github.com/apache/kafka/commit/921fa1c48f0815f971ce40b7280133150d867c6e", "message": "Drop oxford comma", "committedDate": "2020-04-04T16:50:33Z", "type": "commit"}]}