{"pr_number": 8239, "pr_title": "KAFKA-9666: Don't increase transactional epoch when trying to fence if the log append fails", "pr_createdAt": "2020-03-06T16:55:16Z", "pr_url": "https://github.com/apache/kafka/pull/8239", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTExMjA3NQ==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389112075", "bodyText": "nit: period in the end", "author": "abbccdda", "createdAt": "2020-03-06T19:51:52Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -242,10 +242,21 @@ class TransactionCoordinator(brokerId: Int,\n         case Ongoing =>\n           // indicate to abort the current ongoing txn first. Note that this epoch is never returned to the\n           // user. We will abort the ongoing transaction and return CONCURRENT_TRANSACTIONS to the client.\n-          // This forces the client to retry, which will ensure that the epoch is bumped a second time. In\n-          // particular, if fencing the current producer exhausts the available epochs for the current producerId,\n-          // then when the client retries, we will generate a new producerId.\n-          Right(coordinatorEpoch, txnMetadata.prepareFenceProducerEpoch())\n+          // This forces the client to retry, which will ensure that the epoch is bumped a second time. If the\n+          // epoch is exhausted, rotate the producer ID. Subsequent calls from the same producer will return the\n+          // new producer ID and epoch. This defends against cases of frequent retries during periods of persistent\n+          // coordinator unavailability, during which time the abort markers will not be written to the log and the\n+          // repeated fencing may lead to epoch exhaustion", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyMDQ5Mg==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389120492", "bodyText": "This logic is too tricky, could you add some comments on why the above 3 scenarios contribute to the fenced id rotation and why we are going to bypass the error handling? I could have some sense of why this is correct, but would feel very hard to read this path again.", "author": "abbccdda", "createdAt": "2020-03-06T20:10:57Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -363,10 +374,13 @@ class TransactionCoordinator(brokerId: Int,\n           val txnMetadata = epochAndTxnMetadata.transactionMetadata\n           val coordinatorEpoch = epochAndTxnMetadata.coordinatorEpoch\n \n+          val isFencedProducerIdRotation = txnMetadata.isProducerEpochExhausted &&", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNDY2Nw==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389204667", "bodyText": "Added a comment. I also needed to move this inside the lock.", "author": "bob-barrett", "createdAt": "2020-03-07T00:29:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyMDQ5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MDY2OA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389170668", "bodyText": "I want to be clear about the symptom which is we don't handle epoch exhaustion during the fencing right? If yes, we should mention it more specifically as frequent retries just expose the problem, but the fix itself suggests to an error handling gap.", "author": "abbccdda", "createdAt": "2020-03-06T22:16:08Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -242,10 +242,21 @@ class TransactionCoordinator(brokerId: Int,\n         case Ongoing =>\n           // indicate to abort the current ongoing txn first. Note that this epoch is never returned to the\n           // user. We will abort the ongoing transaction and return CONCURRENT_TRANSACTIONS to the client.\n-          // This forces the client to retry, which will ensure that the epoch is bumped a second time. In\n-          // particular, if fencing the current producer exhausts the available epochs for the current producerId,\n-          // then when the client retries, we will generate a new producerId.\n-          Right(coordinatorEpoch, txnMetadata.prepareFenceProducerEpoch())\n+          // This forces the client to retry, which will ensure that the epoch is bumped a second time. If the", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNDY4Ng==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389204686", "bodyText": "Tried to clarify the reasoning a bit better in the comment. I also moved part of it to a separate method where I extracted the fencing logic. Let me know if it's clearer.", "author": "bob-barrett", "createdAt": "2020-03-07T00:29:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MDY2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MTcxNA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389171714", "bodyText": "This could be merged with above else case", "author": "abbccdda", "createdAt": "2020-03-06T22:19:09Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -537,7 +553,13 @@ class TransactionCoordinator(brokerId: Int,\n                 \"pending state transition\")\n               None\n             } else {\n-              Some(txnMetadata.prepareFenceProducerEpoch())\n+              if (txnMetadata.isProducerEpochExhausted) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MzY4MA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389173680", "bodyText": "Could we simplify this logic by just passing epoch as a field?", "author": "abbccdda", "createdAt": "2020-03-06T22:25:20Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionMetadata.scala", "diffHunk": "@@ -259,12 +259,15 @@ private[transaction] class TransactionMetadata(val transactionalId: String,\n   def prepareProducerIdRotation(newProducerId: Long,\n                                 newTxnTimeoutMs: Int,\n                                 updateTimestamp: Long,\n-                                recordLastEpoch: Boolean): TxnTransitMetadata = {\n-    if (hasPendingTransaction)\n+                                recordLastEpoch: Boolean,\n+                                fenceProducer: Boolean): TxnTransitMetadata = {\n+    if (hasPendingTransaction && !fenceProducer)\n       throw new IllegalStateException(\"Cannot rotate producer ids while a transaction is still pending\")\n \n-    prepareTransitionTo(Empty, newProducerId, 0, if (recordLastEpoch) producerEpoch else RecordBatch.NO_PRODUCER_EPOCH,\n-      newTxnTimeoutMs, immutable.Set.empty[TopicPartition], -1, updateTimestamp)\n+    logger.info(s\"Rotating producer ID from $producerId to $newProducerId because the producer epoch was exhausted\")\n+    prepareTransitionTo(if (fenceProducer) PrepareEpochFence else Empty, newProducerId, 0,\n+      if (recordLastEpoch) producerEpoch else RecordBatch.NO_PRODUCER_EPOCH, newTxnTimeoutMs,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3Mzk3Ng==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389173976", "bodyText": "Similarly, let's pass a new state instead of a boolean which needs to be determined again.", "author": "abbccdda", "createdAt": "2020-03-06T22:26:06Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionMetadata.scala", "diffHunk": "@@ -259,12 +259,15 @@ private[transaction] class TransactionMetadata(val transactionalId: String,\n   def prepareProducerIdRotation(newProducerId: Long,\n                                 newTxnTimeoutMs: Int,\n                                 updateTimestamp: Long,\n-                                recordLastEpoch: Boolean): TxnTransitMetadata = {\n-    if (hasPendingTransaction)\n+                                recordLastEpoch: Boolean,\n+                                fenceProducer: Boolean): TxnTransitMetadata = {\n+    if (hasPendingTransaction && !fenceProducer)\n       throw new IllegalStateException(\"Cannot rotate producer ids while a transaction is still pending\")\n \n-    prepareTransitionTo(Empty, newProducerId, 0, if (recordLastEpoch) producerEpoch else RecordBatch.NO_PRODUCER_EPOCH,\n-      newTxnTimeoutMs, immutable.Set.empty[TopicPartition], -1, updateTimestamp)\n+    logger.info(s\"Rotating producer ID from $producerId to $newProducerId because the producer epoch was exhausted\")\n+    prepareTransitionTo(if (fenceProducer) PrepareEpochFence else Empty, newProducerId, 0,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMjE5Ng==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389202196", "bodyText": "The problem I have with that is that there are only two states we should ever transition to in this method. A caller shouldn't be allowed to pass, say, CommitAbort. Keeping the logic in here means that the caller only has to know whether it's a fencing rotation or a normal rotation.", "author": "bob-barrett", "createdAt": "2020-03-07T00:16:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3Mzk3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg1MTAxMw==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r389851013", "bodyText": "Could we also verify other modules like pidManager here?", "author": "abbccdda", "createdAt": "2020-03-09T17:37:34Z", "path": "core/src/test/scala/unit/kafka/coordinator/transaction/TransactionCoordinatorTest.scala", "diffHunk": "@@ -861,6 +862,39 @@ class TransactionCoordinatorTest {\n     EasyMock.verify(transactionManager)\n   }\n \n+  @Test\n+  def shouldAbortExpiredTransactionsInOngoingStateAndRotateProducerIdIfEpochIsExhausted(): Unit = {\n+    val now = time.milliseconds()\n+    val exhaustedProducerEpoch = (Short.MaxValue - 1).toShort\n+    val txnMetadata = new TransactionMetadata(transactionalId, producerId, producerId, exhaustedProducerEpoch,\n+      RecordBatch.NO_PRODUCER_EPOCH, txnTimeoutMs, Ongoing, partitions, now, now)\n+\n+    EasyMock.expect(transactionManager.timedOutTransactions())\n+      .andReturn(List(TransactionalIdAndProducerIdEpoch(transactionalId, producerId, exhaustedProducerEpoch)))\n+    EasyMock.expect(transactionManager.getTransactionState(EasyMock.eq(transactionalId)))\n+      .andReturn(Right(Some(CoordinatorEpochAndTxnMetadata(coordinatorEpoch, txnMetadata))))\n+      .times(2)\n+\n+    val newProducerId = producerId + 1\n+    EasyMock.expect(pidManager.generateProducerId()).andAnswer(() => newProducerId)\n+    val expectedTransition = TxnTransitMetadata(newProducerId, newProducerId, 0, exhaustedProducerEpoch, txnTimeoutMs,\n+      PrepareAbort, partitions.toSet, now, now + TransactionStateManager.DefaultAbortTimedOutTransactionsIntervalMs)\n+\n+    EasyMock.expect(transactionManager.appendTransactionToLog(EasyMock.eq(transactionalId),\n+      EasyMock.eq(coordinatorEpoch),\n+      EasyMock.eq(expectedTransition),\n+      EasyMock.capture(capturedErrorsCallback),\n+      EasyMock.anyObject())\n+    ).andAnswer(() => {}).once()\n+\n+    EasyMock.replay(transactionManager, transactionMarkerChannelManager, pidManager)\n+\n+    coordinator.startup(false)\n+    time.sleep(TransactionStateManager.DefaultAbortTimedOutTransactionsIntervalMs)\n+    scheduler.tick()\n+    EasyMock.verify(transactionManager)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY4MjQ1Nw==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r390682457", "bodyText": "Do all of these checks make sense for an EndTxnRequest from the client? I guess we could get a call to EndTxn from a zombie producer while it is in the middle of being fenced. I think the checks below would result in CONCURRENT_TRANSACTIONS which would cause the zombie to retry until the transition completes. Maybe that's reasonable?", "author": "hachikuji", "createdAt": "2020-03-11T00:16:31Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -364,9 +365,14 @@ class TransactionCoordinator(brokerId: Int,\n           val coordinatorEpoch = epochAndTxnMetadata.coordinatorEpoch\n \n           txnMetadata.inLock {\n-            if (txnMetadata.producerId != producerId)\n+            // If we are ending the transaction due to a fenced producer and we are rotating the producer ID because the\n+            // epoch was exhausted, we need to skip the typical ID and epoch checks because the transaction metadata\n+            // object will already have been changed.\n+            val isFencedProducerRotation = txnMetadata.isProducerEpochExhausted &&", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY4NDQyOA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r390684428", "bodyText": "Is this check equivalent to txnMetadata.pendingState.contains(PrepareEpochFence)?", "author": "hachikuji", "createdAt": "2020-03-11T00:24:00Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -364,9 +365,14 @@ class TransactionCoordinator(brokerId: Int,\n           val coordinatorEpoch = epochAndTxnMetadata.coordinatorEpoch\n \n           txnMetadata.inLock {\n-            if (txnMetadata.producerId != producerId)\n+            // If we are ending the transaction due to a fenced producer and we are rotating the producer ID because the\n+            // epoch was exhausted, we need to skip the typical ID and epoch checks because the transaction metadata\n+            // object will already have been changed.\n+            val isFencedProducerRotation = txnMetadata.isProducerEpochExhausted &&\n+              txnMetadata.pendingState.contains(PrepareEpochFence)\n+            if (txnMetadata.producerId != producerId && !isFencedProducerRotation)\n               Left(Errors.INVALID_PRODUCER_ID_MAPPING)\n-            else if (producerEpoch < txnMetadata.producerEpoch)\n+            else if (producerEpoch < txnMetadata.producerEpoch && !isFencedProducerRotation)\n               Left(Errors.INVALID_PRODUCER_EPOCH)\n             else if (txnMetadata.pendingTransitionInProgress && txnMetadata.pendingState.get != PrepareEpochFence)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5MDk5MQ==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r390690991", "bodyText": "I'm trying to follow the logic here. Suppose we have an ongoing transaction that will be aborted after this call returns. We need to transition to PrepareAbort and we need to send markers using the old producerId and Short.MaxValue as the epoch. Does this logic ensure that that happens?", "author": "hachikuji", "createdAt": "2020-03-11T00:50:14Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -552,6 +560,22 @@ class TransactionCoordinator(brokerId: Int,\n     }\n   }\n \n+  // Fence the producer by either incrementing the producer epoch or, if the epoch is exhausted, rotating the producer ID.\n+  // Rotating the producer ID is necessary because we can't always write the metadata transition to the transaction log\n+  // (such as in the case when there are too few in-sync replicas), but we always reflect the fencing in the transaction\n+  // metadata. If we bump the epoch to the point of exhaustion but fail to write to the log, we would be stuck\n+  // with an Ongoing transaction that couldn't be closed by the coordinator because our epoch is exhausted and couldn't\n+  // be closed by the client because it would be stuck without a valid producer ID and epoch.\n+  private def prepareFenceProducer(txnMetadata: TransactionMetadata): TxnTransitMetadata = {\n+    if (txnMetadata.isProducerEpochExhausted) {\n+      val newProducerId = producerIdManager.generateProducerId()\n+      txnMetadata.prepareProducerIdRotation(newProducerId, txnMetadata.txnTimeoutMs, time.milliseconds(),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTE3NDkzNw==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r395174937", "bodyText": "You're right, it doesn't. This would actually write the abort marker with the new producer ID, which we don't want. After thinking more about that requirement, I don't think there's a good way to do this by rotating the producer ID. We would need to be able to keep the current producer ID around in the metadata until the underlying unavailability cleared, which could even span multiple producer ID rotations. I'm going to push a new approach to this fix that instead rolls the epoch bump back when the write fails.", "author": "bob-barrett", "createdAt": "2020-03-19T16:53:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5MDk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3Mzg4MQ==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r395373881", "bodyText": "Thanks for the updates @bob-barrett . I have another question about the new approach: does that mean the write may be appended locally with the new epoch, and then afterwards we roll back to a smaller epoch. If that's the case, is it possible we may fall into KAFKA-9144 scenario if the isr shrinks and we do not have min.isr > 1?", "author": "guozhangwang", "createdAt": "2020-03-19T23:25:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5MDk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjkwNjA0NA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r396906044", "bodyText": "@guozhangwang If the write succeeds locally, we will never roll the epoch back. This rollback logic only triggers if the local write fails. Once that write succeeds, the epoch has been bumped on disk and it would be unsafe to roll back, as you suggest. And if the write fails, we will never send the marker to the partition, so there is no chance to ever persisting the higher epoch.", "author": "bob-barrett", "createdAt": "2020-03-24T05:13:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDY5MDk5MQ=="}], "type": "inlineReview"}, {"oid": "c979aba51b0732d9bc71c7179003d2a14afeef33", "url": "https://github.com/apache/kafka/commit/c979aba51b0732d9bc71c7179003d2a14afeef33", "message": "KAFKA-9666: Don't increase transactional epoch when trying to fence if the log append fails", "committedDate": "2020-03-19T16:50:24Z", "type": "commit"}, {"oid": "c979aba51b0732d9bc71c7179003d2a14afeef33", "url": "https://github.com/apache/kafka/commit/c979aba51b0732d9bc71c7179003d2a14afeef33", "message": "KAFKA-9666: Don't increase transactional epoch when trying to fence if the log append fails", "committedDate": "2020-03-19T16:50:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk3NDg4Ng==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r420974886", "bodyText": "Took me a while to remember this issue... So basically the coordinator has decided to abort a transaction and has bumped the epoch. However, when it tries to write the updated state to the log, it fails, which leaves us in an inconsistent state. Of course failing to write to the log doesn't necessarily mean that the entry wasn't appended. In fact, it could still become committed. There is no way to take the write back once it gets to the log. Hence I'm a little hesitant about the logic to revert to the previous epoch in this case. Would it still be possible for the fenced producer to make progress with the old epoch after reverting? Perhaps another idea would be to keep the epoch bumped in memory, but remember the fact that the write had failed. So the next time we go to retry the abort, we do not need to bump the epoch again. Does that make sense?", "author": "hachikuji", "createdAt": "2020-05-06T17:43:28Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -487,6 +487,33 @@ class TransactionCoordinator(brokerId: Int,\n               info(s\"Aborting sending of transaction markers and returning $error error to client for $transactionalId's EndTransaction request of $txnMarkerResult, \" +\n                 s\"since appending $newMetadata to transaction log with coordinator epoch $coordinatorEpoch failed\")\n \n+              txnManager.getTransactionState(transactionalId).right.foreach {", "originalCommit": "c979aba51b0732d9bc71c7179003d2a14afeef33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTg1ODEyOA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r421858128", "bodyText": "That's a good point.. the append returning \"fail\" does not mean that the append did not go through. I think the alternative idea would work better: basically, whenever the coordinator decides to abort a txn, it can mark in memory the current epoch as aborting and whenever it (re-)tries to write the prepare-abort entry it always just use the epoch+1 until the write goes through and we can reset that aborting marker.", "author": "guozhangwang", "createdAt": "2020-05-07T23:51:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk3NDg4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA3NzQ1Mg==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r437077452", "bodyText": "Thanks for the suggestion, @hachikuji! I wound up taking that approach.", "author": "bob-barrett", "createdAt": "2020-06-09T00:51:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk3NDg4Ng=="}], "type": "inlineReview"}, {"oid": "7cf16c6479442c53716a89d435291388085a7568", "url": "https://github.com/apache/kafka/commit/7cf16c6479442c53716a89d435291388085a7568", "message": "Merge branch 'trunk' into KAFKA-9666", "committedDate": "2020-06-08T17:23:54Z", "type": "commit"}, {"oid": "1125ae3d46b02bbf39603595e33a53ea27e3c1d6", "url": "https://github.com/apache/kafka/commit/1125ae3d46b02bbf39603595e33a53ea27e3c1d6", "message": "Retain bumped epoch in memory without increasing it until it is successfully written", "committedDate": "2020-06-08T23:11:17Z", "type": "commit"}, {"oid": "6e5b573e9311719da997bb7c890e4de4c311b6d2", "url": "https://github.com/apache/kafka/commit/6e5b573e9311719da997bb7c890e4de4c311b6d2", "message": "Fix flakiness in integration test", "committedDate": "2020-06-09T00:12:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5OTE4MQ==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r453899181", "bodyText": "Looks like this was forgotten.", "author": "hachikuji", "createdAt": "2020-07-13T20:02:58Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -501,6 +502,21 @@ class TransactionCoordinator(brokerId: Int,\n               info(s\"Aborting sending of transaction markers and returning $error error to client for $transactionalId's EndTransaction request of $txnMarkerResult, \" +\n                 s\"since appending $newMetadata to transaction log with coordinator epoch $coordinatorEpoch failed\")\n \n+              if (isEpochFence) {\n+                txnManager.getTransactionState(transactionalId).foreach {\n+                  case None =>\n+                    warn(s\"The coordinator still owns the transaction partition for $transactionalId, but there is \" +\n+                      s\"no metadata in the cache; this is not expected\")\n+\n+                  case Some(epochAndMetadata) =>\n+                    if (epochAndMetadata.coordinatorEpoch == coordinatorEpoch) {\n+                      // This was attempted epoch fence that failed, so mark this state on the metadata\n+                      epochAndMetadata.transactionMetadata.hasFailedEpochFence = true\n+                      warn(\"\")", "originalCommit": "6e5b573e9311719da997bb7c890e4de4c311b6d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxNDkxNA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454914914", "bodyText": "Thanks, fixed", "author": "bob-barrett", "createdAt": "2020-07-15T09:23:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5OTE4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5NjM1Ng==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454596356", "bodyText": "I believe it's accurate to say that if hasFailedEpochFence is set, then the bumped epoch could not have been returned to the client. Is that right? It might be worth a comment emphasizing that.", "author": "hachikuji", "createdAt": "2020-07-14T19:36:10Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionMetadata.scala", "diffHunk": "@@ -210,7 +214,9 @@ private[transaction] class TransactionMetadata(val transactionalId: String,\n     if (producerEpoch == Short.MaxValue)\n       throw new IllegalStateException(s\"Cannot fence producer with epoch equal to Short.MaxValue since this would overflow\")\n \n-    prepareTransitionTo(PrepareEpochFence, producerId, (producerEpoch + 1).toShort, RecordBatch.NO_PRODUCER_EPOCH, txnTimeoutMs,\n+    val bumpedEpoch = if (hasFailedEpochFence) producerEpoch else (producerEpoch + 1).toShort", "originalCommit": "6e5b573e9311719da997bb7c890e4de4c311b6d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxNDg1Nw==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454914857", "bodyText": "Added", "author": "bob-barrett", "createdAt": "2020-07-15T09:23:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5NjM1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5NjY4Mw==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454596683", "bodyText": "Can you explain why we no longer need to set this?", "author": "hachikuji", "createdAt": "2020-07-14T19:36:51Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionCoordinator.scala", "diffHunk": "@@ -394,8 +395,8 @@ class TransactionCoordinator(brokerId: Int,\n                 if (nextState == PrepareAbort && txnMetadata.pendingState.contains(PrepareEpochFence)) {\n                   // We should clear the pending state to make way for the transition to PrepareAbort and also bump\n                   // the epoch in the transaction metadata we are about to append.\n+                  isEpochFence = true\n                   txnMetadata.pendingState = None\n-                  txnMetadata.lastProducerEpoch = txnMetadata.producerEpoch", "originalCommit": "6e5b573e9311719da997bb7c890e4de4c311b6d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyMDc3Nw==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454920777", "bodyText": "So I think this was a small issue with the KIP-360 implementation. When we fence an epoch, we intend to transition to a -1 value for the last epoch (since we only need to save the last epoch when re-initializing, in order to detect retries):\n  def prepareFenceProducerEpoch(): TxnTransitMetadata = {\n    if (producerEpoch == Short.MaxValue)\n      throw new IllegalStateException(s\"Cannot fence producer with epoch equal to Short.MaxValue since this would overflow\")\n\n    // If we've already failed to fence an epoch (because the write to the log failed), we don't increase it again.\n    // This is safe because we never return the epoch to client if we fail to fence the epoch\n    val bumpedEpoch = if (hasFailedEpochFence) producerEpoch else (producerEpoch + 1).toShort\n\n    prepareTransitionTo(PrepareEpochFence, producerId, bumpedEpoch, RecordBatch.NO_PRODUCER_EPOCH, txnTimeoutMs,\n      topicPartitions.toSet, txnStartTimestamp, txnLastUpdateTimestamp)\n  }\n\nBut if we fence a producer as part of an InitProducerId call, we immediately call endTransactions, and we don't pass the new last epoch value. So this line would wind up overwriting the -1 with the epoch that was getting fenced.\nWhen I went back to figure out why I had made this change, I realized that just removing the line isn't quite right either. We should actually set the value explicitly to -1. There's no case when we'd want any value other than -1 as part of ending transactions, since we only need to save the last epoch when we successfully re-initialize a PID, and we'd want to clear the value if it previously existed.", "author": "bob-barrett", "createdAt": "2020-07-15T09:33:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5NjY4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIwNjYyNw==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r455206627", "bodyText": "Thanks, makes sense.", "author": "hachikuji", "createdAt": "2020-07-15T17:15:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5NjY4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5ODAyOA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454598028", "bodyText": "Hmm was this wrong? It seems weird to have last producer epoch set to a value which is 2 less than the producer epoch.", "author": "hachikuji", "createdAt": "2020-07-14T19:39:34Z", "path": "core/src/test/scala/unit/kafka/coordinator/transaction/TransactionCoordinatorTest.scala", "diffHunk": "@@ -564,7 +564,7 @@ class TransactionCoordinatorTest {\n       .anyTimes()\n \n     val originalMetadata = new TransactionMetadata(transactionalId, producerId, producerId, (producerEpoch + 1).toShort,\n-      producerEpoch, txnTimeoutMs, Ongoing, partitions, time.milliseconds(), time.milliseconds())\n+      (producerEpoch - 1).toShort, txnTimeoutMs, Ongoing, partitions, time.milliseconds(), time.milliseconds())", "originalCommit": "6e5b573e9311719da997bb7c890e4de4c311b6d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkyMjI2NA==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454922264", "bodyText": "Yeah, my change here was wrong. This and a couple other weird values were a consequence of that change above to how we set the last epoch in endTransactions. After fixing that and fixing some of the EasyMock returns, all the values make sense now (we don't have any last epoch's that are more than 1 less than the epoch).", "author": "bob-barrett", "createdAt": "2020-07-15T09:36:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5ODAyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5ODIxMQ==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454598211", "bodyText": "nit: did we not need this?", "author": "hachikuji", "createdAt": "2020-07-14T19:39:53Z", "path": "core/src/test/scala/unit/kafka/coordinator/transaction/TransactionCoordinatorTest.scala", "diffHunk": "@@ -614,6 +614,83 @@ class TransactionCoordinatorTest {\n     EasyMock.verify(transactionManager)\n   }\n \n+  @Test\n+  def shouldNotRepeatedlyBumpEpochDueToInitPidDuringOngoingTxnIfAppendToLogFails(): Unit = {\n+    val txnMetadata = new TransactionMetadata(transactionalId, producerId, producerId, producerEpoch,\n+      RecordBatch.NO_PRODUCER_EPOCH, txnTimeoutMs, Ongoing, partitions, time.milliseconds(), time.milliseconds())\n+\n+    EasyMock.expect(transactionManager.validateTransactionTimeoutMs(EasyMock.anyInt()))\n+      .andReturn(true)\n+      .anyTimes()\n+\n+    EasyMock.expect(transactionManager.putTransactionStateIfNotExists(EasyMock.anyObject[TransactionMetadata]()))\n+      .andReturn(Right(CoordinatorEpochAndTxnMetadata(coordinatorEpoch, txnMetadata)))\n+      .anyTimes()\n+\n+    EasyMock.expect(transactionManager.getTransactionState(EasyMock.eq(transactionalId)))\n+      .andAnswer(() => Right(Some(CoordinatorEpochAndTxnMetadata(coordinatorEpoch, txnMetadata))))\n+      .anyTimes()\n+\n+    /* val txnMetadataAfterAppendFailure = new TransactionMetadata(transactionalId, producerId, producerId, (producerEpoch + 1).toShort,", "originalCommit": "6e5b573e9311719da997bb7c890e4de4c311b6d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDkxNTA0OQ==", "url": "https://github.com/apache/kafka/pull/8239#discussion_r454915049", "bodyText": "Removed", "author": "bob-barrett", "createdAt": "2020-07-15T09:23:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU5ODIxMQ=="}], "type": "inlineReview"}, {"oid": "cc22f931854318a4df3cb3f13c9b30c12d0ed9c8", "url": "https://github.com/apache/kafka/commit/cc22f931854318a4df3cb3f13c9b30c12d0ed9c8", "message": "PR feedback", "committedDate": "2020-07-15T09:06:16Z", "type": "commit"}]}