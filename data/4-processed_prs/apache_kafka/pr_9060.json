{"pr_number": 9060, "pr_title": "KAFKA-9274: Remove `retries` from InternalTopicManager", "pr_createdAt": "2020-07-23T04:06:04Z", "pr_url": "https://github.com/apache/kafka/pull/9060", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwNTkzMw==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459205933", "bodyText": "Minor side fix: fetchEndOffset can never throw TimeoutException because it catches all RuntimeException and convert them into StreamsException already", "author": "mjsax", "createdAt": "2020-07-23T04:16:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -1249,11 +1248,7 @@ public void cleanUp() {\n \n         log.debug(\"Current changelog positions: {}\", allChangelogPositions);\n         final Map<TopicPartition, ListOffsetsResultInfo> allEndOffsets;\n-        try {\n-            allEndOffsets = fetchEndOffsets(allPartitions, adminClient);\n-        } catch (final TimeoutException e) {\n-            throw new StreamsException(\"Timed out obtaining end offsets from kafka\", e);\n-        }\n+        allEndOffsets = fetchEndOffsets(allPartitions, adminClient);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwNjA5Mg==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459206092", "bodyText": "first TODO removed", "author": "mjsax", "createdAt": "2020-07-23T04:16:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -46,33 +49,38 @@\n         \"Please report at https://issues.apache.org/jira/projects/KAFKA or dev-mailing list (https://kafka.apache.org/contact).\";\n \n     private final Logger log;\n-    private final long windowChangeLogAdditionalRetention;\n-    private final Map<String, String> defaultTopicConfigs = new HashMap<>();\n \n-    private final short replicationFactor;\n+    private final Time time;\n     private final Admin adminClient;\n \n-    private final int retries;\n+    private final short replicationFactor;\n+    private final long windowChangeLogAdditionalRetention;\n     private final long retryBackOffMs;\n+    private final long retryTimeoutMs;\n+\n+    private final Map<String, String> defaultTopicConfigs = new HashMap<>();\n \n-    @SuppressWarnings(\"deprecation\") // TODO: remove in follow up PR when `RETRIES` is removed", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwNjE2OQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459206169", "bodyText": "Second TODO removed", "author": "mjsax", "createdAt": "2020-07-23T04:17:05Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java", "diffHunk": "@@ -159,7 +159,6 @@ public void testGetGroupInstanceIdConfigs() {\n         assertNull(returnedProps.get(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG));\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwNjMxNQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459206315", "bodyText": "Third TODO removed -- as we don't pass retires and retry.backoff.ms via admin config any longer, this test is not needed any more", "author": "mjsax", "createdAt": "2020-07-23T04:17:51Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java", "diffHunk": "@@ -186,25 +183,9 @@ public void consumerConfigMustContainStreamPartitionAssignorConfig() {\n         );\n         assertEquals(7L, returnedProps.get(StreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG));\n         assertEquals(\"dummy:host\", returnedProps.get(StreamsConfig.APPLICATION_SERVER_CONFIG));\n-        assertNull(returnedProps.get(StreamsConfig.RETRIES_CONFIG));\n-        assertEquals(5, returnedProps.get(StreamsConfig.adminClientPrefix(StreamsConfig.RETRIES_CONFIG)));\n         assertEquals(100, returnedProps.get(StreamsConfig.topicPrefix(TopicConfig.SEGMENT_BYTES_CONFIG)));\n     }\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwNjUwMw==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459206503", "bodyText": "Fourth TODO removed", "author": "mjsax", "createdAt": "2020-07-23T04:18:52Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/InternalTopicManagerTest.java", "diffHunk": "@@ -71,21 +73,20 @@\n     private final String topic2 = \"test_topic_2\";\n     private final String topic3 = \"test_topic_3\";\n     private final List<Node> singleReplica = Collections.singletonList(broker1);\n-    private final int numRetries = 1;\n \n     private String threadName;\n \n     private MockAdminClient mockAdminClient;\n     private InternalTopicManager internalTopicManager;\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwNjc1OQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459206759", "bodyText": "@vvcephei this is an open question\n\\cc @guozhangwang", "author": "mjsax", "createdAt": "2020-07-23T04:19:55Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -154,27 +164,34 @@ public InternalTopicManager(final Admin adminClient, final StreamsConfig streams\n                                 \"Error message was: {}\", topicName, cause.toString());\n                             throw new StreamsException(String.format(\"Could not create topic %s.\", topicName), cause);\n                         }\n+                    } catch (final TimeoutException retryableException) {\n+                        log.error(\"Creating topic {} timed out.\\n\" +\n+                            \"Error message was: {}\", topicName, retryableException.toString());\n                     }\n                 }\n             }\n \n \n             if (!topicsNotReady.isEmpty()) {\n-                log.info(\"Topics {} can not be made ready with {} retries left\", topicsNotReady, remainingRetries);\n+                currentWallClockMs = time.milliseconds();\n \n-                Utils.sleep(retryBackOffMs);\n+                if (currentWallClockMs >= deadlineMs) {\n+                    final String timeoutError = String.format(\"Could not create topics within %d milliseconds. \" +\n+                        \"This can happen if the Kafka cluster is temporary not available.\", retryTimeoutMs);\n+                    log.error(timeoutError);\n+                    // TODO: should we throw a different exception instead and catch it, to return a `INCOMPLETE_SOURCE_TOPIC_METADATA` error code", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwMDIwMg==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459800202", "bodyText": "I'm thinking that moving forward we should try to not create internal topics during rebalance but try pre-create in starting, but for now assuming this is still the case I think letting the whole application to die is fine --- i.e. treat it the same as source topics. Hence I'm leaning towards encoding INCOMPLETE_SOURCE_TOPIC_METADATA to shutdown the whole app, across all clients.", "author": "guozhangwang", "createdAt": "2020-07-24T00:33:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwNjc1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc3NDc3OA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r464774778", "bodyText": "Ack", "author": "mjsax", "createdAt": "2020-08-04T03:18:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIwNjc1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI1ODE3MA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459258170", "bodyText": "If we want to guarantee that the deadlineMs is respected, I think that we must set the timeout of the AdminClient's call accordingly: CreateTopicsOptions.timeoutMs. With the default, I think that the call could be longer than half of MAX_POLL_INTERVAL_MS_CONFIG.", "author": "dajac", "createdAt": "2020-07-23T07:20:38Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -96,13 +104,15 @@ public InternalTopicManager(final Admin adminClient, final StreamsConfig streams\n         // have existed with the expected number of partitions, or some create topic returns fatal errors.\n         log.debug(\"Starting to validate internal topics {} in partition assignor.\", topics);\n \n-        int remainingRetries = retries;\n+        long currentWallClockMs = time.milliseconds();\n+        final long deadlineMs = currentWallClockMs + retryTimeoutMs;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3NzY0Mw==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459577643", "bodyText": "Good question. Default max.poll.interval.ms is 5 minutes (ie, the deadline is set to 2.5 minutes by default) while default api.default.timeout.ms is 1 minutes? Thus we might be ok?", "author": "mjsax", "createdAt": "2020-07-23T16:30:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI1ODE3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4MjcxMA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459582710", "bodyText": "That's right. I misread the default value of max.poll.interval.ms, too many zeros for my eyes ;). The default works fine then. Do we want to protect ourselves if the user changes the default? Or shall we just call out that api.default.timeout.ms should be lower than max.poll.interval.ms somewhere?", "author": "dajac", "createdAt": "2020-07-23T16:38:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI1ODE3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc5MzcxMw==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r459793713", "bodyText": "I am happy to add a check in StreamsConfig and either throw or log a WARN depending how strict we want to be.", "author": "mjsax", "createdAt": "2020-07-24T00:06:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI1ODE3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDA1MzA0OQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r460053049", "bodyText": "Thinking a bit more about this, with the default, you may end up not honouring the deadline. createTopics can take up to 1m so if you invoke one when less than 1m is reaming before the deadline, you may not honour the deadline. It may not be that important though.\nIf we want to strictly enforce it, we could calculate the maximum timeout for each call, something like deadline - now, and set it with CreateTopicsOptions.timeoutMs.", "author": "dajac", "createdAt": "2020-07-24T13:30:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI1ODE3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDA0MDQ4NA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r464040484", "bodyText": "Why do we reduce max poll interval?", "author": "abbccdda", "createdAt": "2020-08-02T06:53:41Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/InternalTopicManagerTest.java", "diffHunk": "@@ -71,21 +73,20 @@\n     private final String topic2 = \"test_topic_2\";\n     private final String topic3 = \"test_topic_3\";\n     private final List<Node> singleReplica = Collections.singletonList(broker1);\n-    private final int numRetries = 1;\n \n     private String threadName;\n \n     private MockAdminClient mockAdminClient;\n     private InternalTopicManager internalTopicManager;\n \n-    @SuppressWarnings(\"deprecation\") // TODO revisit in follow up PR\n     private final Map<String, Object> config = new HashMap<String, Object>() {\n         {\n             put(StreamsConfig.APPLICATION_ID_CONFIG, \"app-id\");\n             put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, broker1.host() + \":\" + broker1.port());\n             put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1);\n             put(StreamsConfig.producerPrefix(ProducerConfig.BATCH_SIZE_CONFIG), 16384);\n-            put(StreamsConfig.adminClientPrefix(StreamsConfig.RETRIES_CONFIG), numRetries);\n+            put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG), 100);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1OTEzMA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r464759130", "bodyText": "In this PR, we change the \"deadline\" in the group leader to create/verify all internal topics from \"counting retries\" to a timeout of max.poll.interval.ms / 2 and we reduce the default of 5 minutes to speed up this test.\ncf https://github.com/apache/kafka/pull/9060/files#diff-d3963e433c59b08688bb4481faa20e97R79", "author": "mjsax", "createdAt": "2020-08-04T02:16:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDA0MDQ4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI0MjIzNA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r465242234", "bodyText": "Is this part of the initiative to throw a different exception? Could we update the summary of this PR?", "author": "abbccdda", "createdAt": "2020-08-04T18:20:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -373,8 +373,15 @@ public GroupAssignment assign(final Cluster metadata, final GroupSubscription gr\n \n         final Set<TaskId> statefulTasks = new HashSet<>();\n \n-        final boolean probingRebalanceNeeded =\n-            assignTasksToClients(fullMetadata, allSourceTopics, topicGroups, clientMetadataMap, partitionsForTask, statefulTasks);\n+        final boolean probingRebalanceNeeded;\n+        try {\n+            probingRebalanceNeeded = assignTasksToClients(fullMetadata, allSourceTopics, topicGroups, clientMetadataMap, partitionsForTask, statefulTasks);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI0MzAwNQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r465243005", "bodyText": "Could we update the meta comment to explain when a TaskAssignmentException is thrown?", "author": "abbccdda", "createdAt": "2020-08-04T18:22:05Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -477,7 +484,7 @@ private boolean checkMetadataVersions(final int minReceivedMetadataVersion,\n      * @return map from repartition topic to its partition info\n      */\n     private Map<TopicPartition, PartitionInfo> prepareRepartitionTopics(final Map<Integer, TopicsInfo> topicGroups,\n-                                                                           final Cluster metadata) {\n+                                                                           final Cluster metadata) throws TaskAssignmentException {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTMyNDYyOQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r465324629", "bodyText": "TaskAssignmentException is not a checked exception and it's just a curtesy declaration... (I can also remove throws TaskAssignmentException if you prefer).\nDon't see any need to document anything further -- the code makes it clear (in fact, this method does not even throw the exception itself, but it just bubbles up from internalTopicManager.makeReady and the code documents itself:\nhttps://github.com/apache/kafka/pull/9060/files#diff-d3963e433c59b08688bb4481faa20e97R179-R184", "author": "mjsax", "createdAt": "2020-08-04T20:55:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI0MzAwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI0MzU3OA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r465243578", "bodyText": "Comments for thrown exception", "author": "abbccdda", "createdAt": "2020-08-04T18:23:05Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -91,18 +100,20 @@ public InternalTopicManager(final Admin adminClient, final StreamsConfig streams\n      * If a topic exists already but has different number of partitions we fail and throw exception requesting user to reset the app before restarting again.\n      * @return the set of topics which had to be newly created\n      */\n-    public Set<String> makeReady(final Map<String, InternalTopicConfig> topics) {\n+    public Set<String> makeReady(final Map<String, InternalTopicConfig> topics) throws TaskAssignmentException {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI0ODQ2Ng==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r465248466", "bodyText": "s/temporary/temporarily", "author": "abbccdda", "createdAt": "2020-08-04T18:31:20Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/InternalTopicManagerTest.java", "diffHunk": "@@ -383,18 +405,25 @@ public void shouldThrowExceptionWhenKeepsTopicLeaderNotAvailable() {\n         EasyMock.expect(admin.describeTopics(Collections.singleton(topic)))\n             .andReturn(new MockDescribeTopicsResult(\n                 Collections.singletonMap(topic, topicDescriptionFailFuture)))\n-            .times(numRetries + 1);\n+            .anyTimes();\n         EasyMock.expect(admin.createTopics(Collections.emptySet()))\n-            .andReturn(new MockCreateTopicsResult(Collections.emptyMap())).once();\n+            .andReturn(new MockCreateTopicsResult(Collections.emptyMap())).anyTimes();\n \n         EasyMock.replay(admin);\n \n         final InternalTopicConfig internalTopicConfig = new RepartitionTopicConfig(topic, Collections.emptyMap());\n         internalTopicConfig.setNumberOfPartitions(1);\n \n-        assertThrows(\n-            StreamsException.class,\n-            () -> topicManager.makeReady(Collections.singletonMap(topic, internalTopicConfig)));\n+        final TaskAssignmentException exception = assertThrows(\n+            TaskAssignmentException.class,\n+            () -> topicManager.makeReady(Collections.singletonMap(topic, internalTopicConfig))\n+        );\n+        assertNull(exception.getCause());\n+        assertThat(\n+            exception.getMessage(),\n+            equalTo(\"Could not create topics within 50 milliseconds.\" +\n+                \" This can happen if the Kafka cluster is temporary not available.\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTY4NQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r465999685", "bodyText": "Since we could throw different exceptions here, would be good to add a log to indicate which type of exception is thrown.", "author": "abbccdda", "createdAt": "2020-08-05T20:58:19Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -373,8 +373,15 @@ public GroupAssignment assign(final Cluster metadata, final GroupSubscription gr\n \n         final Set<TaskId> statefulTasks = new HashSet<>();\n \n-        final boolean probingRebalanceNeeded =\n-            assignTasksToClients(fullMetadata, allSourceTopics, topicGroups, clientMetadataMap, partitionsForTask, statefulTasks);\n+        final boolean probingRebalanceNeeded;\n+        try {\n+            probingRebalanceNeeded = assignTasksToClients(fullMetadata, allSourceTopics, topicGroups, clientMetadataMap, partitionsForTask, statefulTasks);\n+        } catch (final TaskAssignmentException | TimeoutException e) {\n+            return new GroupAssignment(", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwNjU4OQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r466006589", "bodyText": "There are already corresponding log.error statement before those exceptions are thrown. No need to double log IMHO?", "author": "mjsax", "createdAt": "2020-08-05T21:11:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTY4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAzMTQ4Nw==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r466031487", "bodyText": "Cool, sg.", "author": "abbccdda", "createdAt": "2020-08-05T22:07:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5OTY4NQ=="}], "type": "inlineReview"}, {"oid": "ddbfe318a54c068dfc4a9d821f144b935339346c", "url": "https://github.com/apache/kafka/commit/ddbfe318a54c068dfc4a9d821f144b935339346c", "message": "KAFKA-9274: Remove retries from InternalTopicManager\n - part of KIP-572\n - replace `retries` in InternalTopicManager with infinite retires plus\n   a new timeout, based on consumer config MAX_POLL_INTERVAL_MS", "committedDate": "2020-08-05T21:16:59Z", "type": "commit"}, {"oid": "a214111de6c26d59fb40ddefd26b6620c3efca9b", "url": "https://github.com/apache/kafka/commit/a214111de6c26d59fb40ddefd26b6620c3efca9b", "message": "fix tests", "committedDate": "2020-08-05T21:16:59Z", "type": "commit"}, {"oid": "0af6273741d1a9249dc82b99e14f438f69f07f90", "url": "https://github.com/apache/kafka/commit/0af6273741d1a9249dc82b99e14f438f69f07f90", "message": "Github comments", "committedDate": "2020-08-05T21:17:23Z", "type": "commit"}, {"oid": "8d2348406e53099ec79d75c8f0adbbc95aaf7d76", "url": "https://github.com/apache/kafka/commit/8d2348406e53099ec79d75c8f0adbbc95aaf7d76", "message": "Github comments", "committedDate": "2020-08-05T21:17:24Z", "type": "commit"}, {"oid": "05b0faa5a146de6ec33784db87cf24c8ea1b6232", "url": "https://github.com/apache/kafka/commit/05b0faa5a146de6ec33784db87cf24c8ea1b6232", "message": "Rebased", "committedDate": "2020-08-05T21:29:37Z", "type": "commit"}, {"oid": "05b0faa5a146de6ec33784db87cf24c8ea1b6232", "url": "https://github.com/apache/kafka/commit/05b0faa5a146de6ec33784db87cf24c8ea1b6232", "message": "Rebased", "committedDate": "2020-08-05T21:29:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU4MDEwOQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r489580109", "bodyText": "Hey @mjsax , am I reading this PR correctly? Do we now only allow a single member to retry topic creation/validation for up to half of the poll interval, after which we shut down the entire application? That sounds like the opposite of resiliency...what if the brokers are temporarily unavailable? Before this we would just let the single thread die, and the internal topic creation/validation would be retried on the subsequent rebalance. That wasn't ideal, but given the upcoming work to allow reviving/recreating a death thread, that seems to be preferable to permanently ending the application?\nSorry if I'm misreading this, was just going over all the PRs in the last month or so to produce a diff+summary of the important ones, and want to make sure I actually understand all the changes we've made", "author": "ableegoldman", "createdAt": "2020-09-16T16:47:24Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopicManager.java", "diffHunk": "@@ -45,33 +49,38 @@\n         \"Please report at https://issues.apache.org/jira/projects/KAFKA or dev-mailing list (https://kafka.apache.org/contact).\";\n \n     private final Logger log;\n-    private final long windowChangeLogAdditionalRetention;\n-    private final Map<String, String> defaultTopicConfigs = new HashMap<>();\n \n-    private final short replicationFactor;\n+    private final Time time;\n     private final Admin adminClient;\n \n-    private final int retries;\n+    private final short replicationFactor;\n+    private final long windowChangeLogAdditionalRetention;\n     private final long retryBackOffMs;\n+    private final long retryTimeoutMs;\n+\n+    private final Map<String, String> defaultTopicConfigs = new HashMap<>();\n \n-    @SuppressWarnings(\"deprecation\") // TODO: remove in follow up PR when `RETRIES` is removed\n-    public InternalTopicManager(final Admin adminClient, final StreamsConfig streamsConfig) {\n+    public InternalTopicManager(final Time time,\n+                                final Admin adminClient,\n+                                final StreamsConfig streamsConfig) {\n+        this.time = time;\n         this.adminClient = adminClient;\n \n         final LogContext logContext = new LogContext(String.format(\"stream-thread [%s] \", Thread.currentThread().getName()));\n         log = logContext.logger(getClass());\n \n         replicationFactor = streamsConfig.getInt(StreamsConfig.REPLICATION_FACTOR_CONFIG).shortValue();\n         windowChangeLogAdditionalRetention = streamsConfig.getLong(StreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG);\n-        final AdminClientConfig adminConfigs = new ClientUtils.QuietAdminClientConfig(streamsConfig);\n-        retries = adminConfigs.getInt(AdminClientConfig.RETRIES_CONFIG);\n-        retryBackOffMs = adminConfigs.getLong(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG);\n+        retryBackOffMs = streamsConfig.getLong(StreamsConfig.RETRY_BACKOFF_MS_CONFIG);\n+        final Map<String, Object> consumerConfig = streamsConfig.getMainConsumerConfigs(\"dummy\", \"dummy\", -1);\n+        // need to add mandatory configs; otherwise `QuietConsumerConfig` throws\n+        consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class);\n+        consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class);\n+        retryTimeoutMs = new QuietConsumerConfig(consumerConfig).getInt(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG) / 2L;", "originalCommit": "05b0faa5a146de6ec33784db87cf24c8ea1b6232", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU4MDU3Mg==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r489580572", "bodyText": "Apologies if this was touched on in the KIP, it's been a while and the discussion thread was quite long so I may have missed something there", "author": "ableegoldman", "createdAt": "2020-09-16T16:48:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU4MDEwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0NjA1OQ==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r489646059", "bodyText": "Note that the previous default was \"zero retries\" and thus the new default is more resilient with a 5 minute default max.poll.interval. -- But yes, we shutdown the whole app for this case now as proposed by @guozhangwang (IIRC).", "author": "mjsax", "createdAt": "2020-09-16T18:34:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU4MDEwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY0NTc4MA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r491645780", "bodyText": "Today since we do not have ways to partially create tasks we'd have to create all topics to make sure all tasks are \"complete\" within each rebalance, if we cannot successfully create the topics within the poll.interval (i.e. we'd need to complete that rebalance with the poll.interval, and I guess halving it is to be more conservative), then killing that thread is not very useful anyways since we cannot proceed with the initializable tasks anyways.\nThat being said, with the upcoming work I'd agree that just shutdown the thread and allow users to optionally retry rebalance with new threads would be preferrable.", "author": "guozhangwang", "createdAt": "2020-09-20T03:08:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU4MDEwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY0NTgwMA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r491645800", "bodyText": "cc @cadonna @wcarlson5 to bring to your attention.", "author": "guozhangwang", "createdAt": "2020-09-20T03:08:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU4MDEwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzcxNDE4Mw==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r497714183", "bodyText": "Yeah I think we should remove the shutdown error code in case of TimeoutException during internal topic validation before 2.7. I'll create a ticket so we don't lose track -- I think even just letting it kill the one thread is better than killing all of them", "author": "ableegoldman", "createdAt": "2020-09-30T18:25:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU4MDEwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzcxNzIxOA==", "url": "https://github.com/apache/kafka/pull/9060#discussion_r497717218", "bodyText": "SGTM.", "author": "mjsax", "createdAt": "2020-09-30T18:30:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTU4MDEwOQ=="}], "type": "inlineReview"}]}