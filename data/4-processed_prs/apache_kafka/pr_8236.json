{"pr_number": 8236, "pr_title": "KAFKA-9670: Reduce allocations in Metadata Response preparation", "pr_createdAt": "2020-03-06T07:46:38Z", "pr_url": "https://github.com/apache/kafka/pull/8236", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODk1OTgwMw==", "url": "https://github.com/apache/kafka/pull/8236#discussion_r388959803", "bodyText": "Should we remove MetadataResponse.TopicMetadata altogether or does it add value?", "author": "ijuma", "createdAt": "2020-03-06T15:13:53Z", "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -150,11 +165,15 @@ class MetadataCache(brokerId: Int) extends Logging {\n   def getTopicMetadata(topics: Set[String],\n                        listenerName: ListenerName,\n                        errorUnavailableEndpoints: Boolean = false,\n-                       errorUnavailableListeners: Boolean = false): Seq[MetadataResponse.TopicMetadata] = {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc4MTE4MA==", "url": "https://github.com/apache/kafka/pull/8236#discussion_r389781180", "bodyText": "I think, we can continue to use MetadataResponse.TopicMetadata in some of the internal classes and tests. But I open to update/remove the classes the code required.", "author": "omkreddy", "createdAt": "2020-03-09T15:49:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODk1OTgwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTkwNjA3Ng==", "url": "https://github.com/apache/kafka/pull/8236#discussion_r391906076", "bodyText": "nit: I'd suggest changing this to accept Errors so that we don't need all the annoying .code() calls.", "author": "hachikuji", "createdAt": "2020-03-12T21:29:15Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1000,24 +1002,30 @@ class KafkaApis(val requestChannel: RequestChannel,\n   private def createTopic(topic: String,\n                           numPartitions: Int,\n                           replicationFactor: Int,\n-                          properties: util.Properties = new util.Properties()): MetadataResponse.TopicMetadata = {\n+                          properties: util.Properties = new util.Properties()): MetadataResponseTopic = {\n     try {\n       adminZkClient.createTopic(topic, numPartitions, replicationFactor, properties, RackAwareMode.Safe)\n       info(\"Auto creation of topic %s with %d partitions and replication factor %d is successful\"\n         .format(topic, numPartitions, replicationFactor))\n-      new MetadataResponse.TopicMetadata(Errors.LEADER_NOT_AVAILABLE, topic, isInternal(topic),\n-        util.Collections.emptyList())\n+      metadataResponseTopic(Errors.LEADER_NOT_AVAILABLE.code(), topic, isInternal(topic), util.Collections.emptyList())\n     } catch {\n       case _: TopicExistsException => // let it go, possibly another broker created this topic\n-        new MetadataResponse.TopicMetadata(Errors.LEADER_NOT_AVAILABLE, topic, isInternal(topic),\n-          util.Collections.emptyList())\n+        metadataResponseTopic(Errors.LEADER_NOT_AVAILABLE.code(), topic, isInternal(topic), util.Collections.emptyList())\n       case ex: Throwable  => // Catch all to prevent unhandled errors\n-        new MetadataResponse.TopicMetadata(Errors.forException(ex), topic, isInternal(topic),\n-          util.Collections.emptyList())\n+        metadataResponseTopic(Errors.forException(ex).code(), topic, isInternal(topic), util.Collections.emptyList())\n     }\n   }\n \n-  private def createInternalTopic(topic: String): MetadataResponse.TopicMetadata = {\n+  private def metadataResponseTopic(errorCode: Short, topic: String, isInternal: Boolean,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTk0MjQ3NA==", "url": "https://github.com/apache/kafka/pull/8236#discussion_r391942474", "bodyText": "nit: for ra bunch of these accessors, we can drop parenthesis.", "author": "hachikuji", "createdAt": "2020-03-12T22:38:21Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1285,13 +1293,13 @@ class KafkaApis(val requestChannel: RequestChannel,\n                 .setPort(node.port)\n                 .setThrottleTimeMs(requestThrottleMs))\n         }\n-        val responseBody = if (topicMetadata.error != Errors.NONE) {\n+        val responseBody = if (topicMetadata.errorCode() != Errors.NONE.code()) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTk0MjcyNA==", "url": "https://github.com/apache/kafka/pull/8236#discussion_r391942724", "bodyText": "nit: this looks misaligned", "author": "hachikuji", "createdAt": "2020-03-12T22:39:02Z", "path": "core/src/main/scala/kafka/server/MetadataCache.scala", "diffHunk": "@@ -78,9 +80,9 @@ class MetadataCache(brokerId: Int) extends Logging {\n   // If errorUnavailableListeners=true, return LISTENER_NOT_FOUND if listener is missing on the broker.\n   // Otherwise, return LEADER_NOT_AVAILABLE for broker unavailable and missing listener (Metadata response v5 and below).\n   private def getPartitionMetadata(snapshot: MetadataSnapshot, topic: String, listenerName: ListenerName, errorUnavailableEndpoints: Boolean,\n-                                   errorUnavailableListeners: Boolean): Option[Iterable[MetadataResponse.PartitionMetadata]] = {\n+                                   errorUnavailableListeners: Boolean): Option[Iterable[MetadataResponsePartition]] = {\n     snapshot.partitionStates.get(topic).map { partitions =>\n-      partitions.map { case (partitionId, partitionState) =>\n+        partitions.map { case (partitionId, partitionState) =>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c0423531f81aa2a438c7da3edd9e4e8013e7a5da", "url": "https://github.com/apache/kafka/commit/c0423531f81aa2a438c7da3edd9e4e8013e7a5da", "message": "Optimize metadata building", "committedDate": "2020-03-13T06:42:21Z", "type": "commit"}, {"oid": "408f8160f202e3a19bf1d0f3d27879ddc0ec0e78", "url": "https://github.com/apache/kafka/commit/408f8160f202e3a19bf1d0f3d27879ddc0ec0e78", "message": "Cleanups", "committedDate": "2020-03-13T06:42:21Z", "type": "commit"}, {"oid": "745a99309bc7d0a4b949927b58f996286f075495", "url": "https://github.com/apache/kafka/commit/745a99309bc7d0a4b949927b58f996286f075495", "message": "Add MetadataRequestBenchmark", "committedDate": "2020-03-13T06:42:21Z", "type": "commit"}, {"oid": "3a763daddaab1ec60cbdc3e603371199d506845b", "url": "https://github.com/apache/kafka/commit/3a763daddaab1ec60cbdc3e603371199d506845b", "message": "Update MetadataResponse.prepareResponse()", "committedDate": "2020-03-13T06:42:21Z", "type": "commit"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "ddd4825b6cd4da85a5724ecabb3585b066cd4b4f", "url": "https://github.com/apache/kafka/commit/ddd4825b6cd4da85a5724ecabb3585b066cd4b4f", "message": "Address review comments", "committedDate": "2020-03-13T07:59:24Z", "type": "commit"}, {"oid": "ddd4825b6cd4da85a5724ecabb3585b066cd4b4f", "url": "https://github.com/apache/kafka/commit/ddd4825b6cd4da85a5724ecabb3585b066cd4b4f", "message": "Address review comments", "committedDate": "2020-03-13T07:59:24Z", "type": "forcePushed"}]}