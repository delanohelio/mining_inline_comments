{"pr_number": 7969, "pr_title": "KAFKA-7317: Use collections subscription for main consumer to reduce metadata", "pr_createdAt": "2020-01-16T03:45:28Z", "pr_url": "https://github.com/apache/kafka/pull/7969", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxODcwNQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r367218705", "bodyText": "This is just moved since it's only used by a single class", "author": "ableegoldman", "createdAt": "2020-01-16T03:47:14Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -87,10 +85,6 @@\n     // map from sink processor names to sink topic (without application-id prefix for internal topics)\n     private final Map<String, String> nodeToSinkTopic = new HashMap<>();\n \n-    // map from topics to their matched regex patterns, this is to ensure one topic is passed through on source node\n-    // even if it can be matched by multiple regex patterns\n-    private final Map<String, Pattern> topicToPatterns = new HashMap<>();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxODkwNw==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r367218907", "bodyText": "Also update sourceTopicNames to keep in sync with nodeToSourceTopics", "author": "ableegoldman", "createdAt": "2020-01-16T03:48:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -1048,24 +1047,23 @@ private void buildProcessorNode(final Map<String, ProcessorNode> processorMap,\n     }\n \n     private void setRegexMatchedTopicsToSourceNodes() {\n-        if (subscriptionUpdates.hasUpdates()) {\n-            for (final Map.Entry<String, Pattern> stringPatternEntry : nodeToSourcePatterns.entrySet()) {\n-                final SourceNodeFactory sourceNode =\n-                    (SourceNodeFactory) nodeFactories.get(stringPatternEntry.getKey());\n-                //need to update nodeToSourceTopics with topics matched from given regex\n-                nodeToSourceTopics.put(\n-                    stringPatternEntry.getKey(),\n-                    sourceNode.getTopics(subscriptionUpdates.getUpdates()));\n-                log.debug(\"nodeToSourceTopics {}\", nodeToSourceTopics);\n+        if (hasSubscriptionUpdates()) {\n+            for (final String nodeName : nodeToSourcePatterns.keySet()) {\n+                //need to update nodeToSourceTopics and sourceTopicNames with topics matched from given regex\n+                final List<String> sourceTopics = ((SourceNodeFactory) nodeFactories.get(nodeName))\n+                                                      .getTopics(subscriptionUpdates);\n+                nodeToSourceTopics.put(nodeName, sourceTopics);\n+                sourceTopicNames.addAll(sourceTopics);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwNzQ5MA==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r369707490", "bodyText": "Do we need to do this at this point?  I guess so at it makes sense to have sourceTopicNames match what's in nodeToSourceTopics.  I'm only asking as we never had this before and I'm curious as to why.", "author": "bbejeck", "createdAt": "2020-01-22T17:45:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxODkwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTg4MzUwNQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r369883505", "bodyText": "Well I did switch #sourceTopicPattern and the new #sourceTopicCollection to use sourceTopicNames instead of nodeToSourceTopics.values, in which case we do still need to do this.\nIt shouldn't matter, although I will say the hardest part of working with this code/class was figuring out which data structures did/did not contain what contents or updates. I'm inclined to leave this in so that the two similar data structures are kept in sync, but I'm fine with removing it just to keep the changes minimal/necessary", "author": "ableegoldman", "createdAt": "2020-01-23T00:49:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxODkwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxOTE3Mw==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r367219173", "bodyText": "This can be simplified by just using sourceTopicNames, which is identical to nodeToSourceTopics.values() but without the global topics, which we remove", "author": "ableegoldman", "createdAt": "2020-01-16T03:49:39Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -1200,37 +1198,28 @@ private String decorateTopic(final String topic) {\n         return applicationId + \"-\" + topic;\n     }\n \n-    SubscriptionUpdates subscriptionUpdates() {\n-        return subscriptionUpdates;\n+    boolean usesPatternSubscription() {\n+        return (!nodeToSourcePatterns.isEmpty());\n+    }\n+\n+    synchronized Collection<String> sourceTopicCollection() {\n+        log.debug(\"No source topics using pattern subscription found, using regular subscription for the main consumer.\");\n+\n+        return sourceTopicNames;\n     }\n \n     synchronized Pattern sourceTopicPattern() {\n+        log.debug(\"Found pattern subscribed source topics, falling back to pattern subscription for the main consumer.\");\n+\n         if (topicPattern == null) {\n-            final List<String> allSourceTopics = new ArrayList<>();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxOTg2OA==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r367219868", "bodyText": "The SubscriptionUpdates class and various updateXXX methods were unnecessarily complex given they all boiled down to just the 4 lines of actual actions below", "author": "ableegoldman", "createdAt": "2020-01-16T03:53:17Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -1856,42 +1845,25 @@ private static String nodeNames(final Set<TopologyDescription.Node> nodes) {\n         return sb.toString();\n     }\n \n-    /**\n-     * Used to capture subscribed topic via Patterns discovered during the\n-     * partition assignment process.\n-     */\n-    public static class SubscriptionUpdates {\n-\n-        private final Set<String> updatedTopicSubscriptions = new HashSet<>();\n-\n-        private void updateTopics(final Collection<String> topicNames) {\n-            updatedTopicSubscriptions.clear();\n-            updatedTopicSubscriptions.addAll(topicNames);\n-        }\n-\n-        public Collection<String> getUpdates() {\n-            return Collections.unmodifiableSet(updatedTopicSubscriptions);\n-        }\n-\n-        boolean hasUpdates() {\n-            return !updatedTopicSubscriptions.isEmpty();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return String.format(\"SubscriptionUpdates{updatedTopicSubscriptions=%s}\", updatedTopicSubscriptions);\n-        }\n+    Collection<String> subscriptionUpdates() {\n+        return Collections.unmodifiableSet(subscriptionUpdates);\n     }\n \n-    void updateSubscribedTopics(final Set<String> topics,\n-                                final String logPrefix) {\n-        final SubscriptionUpdates subscriptionUpdates = new SubscriptionUpdates();\n-        log.debug(\"{}found {} topics possibly matching regex\", logPrefix, topics);\n-        // update the topic groups with the returned subscription set for regex pattern subscriptions\n-        subscriptionUpdates.updateTopics(topics);\n-        updateSubscriptions(subscriptionUpdates, logPrefix);\n+    boolean hasSubscriptionUpdates() {\n+        return !subscriptionUpdates.isEmpty();\n     }\n \n+    synchronized void updateSubscribedTopics(final Set<String> topics,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIyMDEyMQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r367220121", "bodyText": "This is the actual fix; if the user has not themselves added pattern source topics we will go back to using regular subscription (having safely disabled auto topic creation)", "author": "ableegoldman", "createdAt": "2020-01-16T03:54:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -717,7 +717,15 @@ private void runLoop() {\n \n     private void enforceRebalance() {\n         consumer.unsubscribe();\n-        consumer.subscribe(builder.sourceTopicPattern(), rebalanceListener);\n+        subscribeConsumer();\n+    }\n+\n+    private void subscribeConsumer() {\n+        if (builder.usesPatternSubscription()) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ2NTM3OQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r367465379", "bodyText": "qq - what does this mean for users that have enabled auto topic creation? Although it's not a best practice, this seems it could lead to unexpected behavior.", "author": "bbejeck", "createdAt": "2020-01-16T14:59:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -1064,6 +1064,9 @@ private void checkIfUnexpectedUserSpecifiedConsumerConfig(final Map<String, Obje\n         consumerProps.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, StreamsPartitionAssignor.class.getName());\n         consumerProps.put(WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG, getLong(WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG));\n \n+        // disable auto topic creation\n+        consumerProps.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, \"false\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyMjc5Ng==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r367622796", "bodyText": "Do you mean on the server side or on the client? I agree we should consider checking for this in the user supplied configs before overriding it, but I think the reasonable default behavior is to disable it (by client config, since it's enabled server-side by default).\nIf users really do want it then it's on them to enable it through the main consumer config. On the other hand, prior to this it was effectively disabled  permanently by the workaround of using pattern subscription. WDYT?", "author": "ableegoldman", "createdAt": "2020-01-16T20:03:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ2NTM3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIwMjE3Mg==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r368202172", "bodyText": "Yeah, that SGTM I forgot that auto topic creation is the default server-side.", "author": "bbejeck", "createdAt": "2020-01-18T03:11:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ2NTM3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY4NDY0OA==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r369684648", "bodyText": "Nice to get rid of the use of reflection in the tests here and below", "author": "bbejeck", "createdAt": "2020-01-22T17:01:03Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilderTest.java", "diffHunk": "@@ -667,30 +680,25 @@ public void shouldAddInternalTopicConfigForRepartitionTopics() {\n \n     @SuppressWarnings(\"unchecked\")\n     @Test\n-    public void shouldSetCorrectSourceNodesWithRegexUpdatedTopics() throws Exception {\n+    public void shouldSetCorrectSourceNodesWithRegexUpdatedTopics() {\n         builder.addSource(null, \"source-1\", null, null, null, \"topic-foo\");\n         builder.addSource(null, \"source-2\", null, null, null, Pattern.compile(\"topic-[A-C]\"));\n         builder.addSource(null, \"source-3\", null, null, null, Pattern.compile(\"topic-\\\\d\"));\n \n-        final InternalTopologyBuilder.SubscriptionUpdates subscriptionUpdates = new InternalTopologyBuilder.SubscriptionUpdates();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTg4MzczMQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r369883731", "bodyText": "\ud83d\ude04Agreed!", "author": "ableegoldman", "createdAt": "2020-01-23T00:50:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY4NDY0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTY5NTg4OQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r369695889", "bodyText": "I think in a previous commit this was static and I had concerns that it wouldn't work, so I'm glad to see you changed this.", "author": "bbejeck", "createdAt": "2020-01-22T17:22:09Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -215,6 +212,10 @@ Processor describe() {\n         }\n     }\n \n+    // Map from topics to their matched regex patterns, this is to ensure one topic is passed through on source node\n+    // even if it can be matched by multiple regex patterns. Only used by SourceNodeFactory\n+    private final Map<String, Pattern> topicToPatterns = new HashMap<>();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwMjQyMQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r369702421", "bodyText": "nit: I understand the change here for compactness, but I find it a little hard to follow.  This is subjective however so feel free to keep as is.", "author": "bbejeck", "createdAt": "2020-01-22T17:35:13Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -1048,24 +1049,23 @@ private void buildProcessorNode(final Map<String, ProcessorNode> processorMap,\n     }\n \n     private void setRegexMatchedTopicsToSourceNodes() {\n-        if (subscriptionUpdates.hasUpdates()) {\n-            for (final Map.Entry<String, Pattern> stringPatternEntry : nodeToSourcePatterns.entrySet()) {\n-                final SourceNodeFactory sourceNode =\n-                    (SourceNodeFactory) nodeFactories.get(stringPatternEntry.getKey());\n-                //need to update nodeToSourceTopics with topics matched from given regex\n-                nodeToSourceTopics.put(\n-                    stringPatternEntry.getKey(),\n-                    sourceNode.getTopics(subscriptionUpdates.getUpdates()));\n-                log.debug(\"nodeToSourceTopics {}\", nodeToSourceTopics);\n+        if (hasSubscriptionUpdates()) {\n+            for (final String nodeName : nodeToSourcePatterns.keySet()) {\n+                //need to update nodeToSourceTopics and sourceTopicNames with topics matched from given regex\n+                final List<String> sourceTopics = ((SourceNodeFactory) nodeFactories.get(nodeName))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTg3OTc2NA==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r369879764", "bodyText": "I kind of thought this way was easier to understand, but I did go back and forth on it. I'm happy to change it back", "author": "ableegoldman", "createdAt": "2020-01-23T00:34:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTcwMjQyMQ=="}], "type": "inlineReview"}, {"oid": "c75d3027fca883b4ec4e482656655d080282202a", "url": "https://github.com/apache/kafka/commit/c75d3027fca883b4ec4e482656655d080282202a", "message": "add consumer config and change subscription type", "committedDate": "2020-01-23T22:13:16Z", "type": "commit"}, {"oid": "4bbab82fa3fc19d86e7ba46731007d0fbe857eda", "url": "https://github.com/apache/kafka/commit/4bbab82fa3fc19d86e7ba46731007d0fbe857eda", "message": "side cleanup", "committedDate": "2020-01-23T22:13:16Z", "type": "commit"}, {"oid": "ad55ffc923b0f87f51277519cfebe9ff602a1927", "url": "https://github.com/apache/kafka/commit/ad55ffc923b0f87f51277519cfebe9ff602a1927", "message": "replace null check in other classes with added method", "committedDate": "2020-01-23T22:13:16Z", "type": "commit"}, {"oid": "a9567353de535ee72e9eb82f91e5a47acb0e95a7", "url": "https://github.com/apache/kafka/commit/a9567353de535ee72e9eb82f91e5a47acb0e95a7", "message": "fix up tests, add unit test", "committedDate": "2020-01-23T22:13:16Z", "type": "commit"}, {"oid": "3b52129691c1ced9c1e44656e8df8f7934039890", "url": "https://github.com/apache/kafka/commit/3b52129691c1ced9c1e44656e8df8f7934039890", "message": "fix checkstyle", "committedDate": "2020-01-23T22:13:16Z", "type": "commit"}, {"oid": "9ba3ee4e5849cae6c81d5b229846e0507630647f", "url": "https://github.com/apache/kafka/commit/9ba3ee4e5849cae6c81d5b229846e0507630647f", "message": "github comment", "committedDate": "2020-01-23T22:13:16Z", "type": "commit"}, {"oid": "9ba3ee4e5849cae6c81d5b229846e0507630647f", "url": "https://github.com/apache/kafka/commit/9ba3ee4e5849cae6c81d5b229846e0507630647f", "message": "github comment", "committedDate": "2020-01-23T22:13:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg3ODY2Ng==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r370878666", "bodyText": "nit: missing space between logPrefix and 'found'", "author": "tedyu", "createdAt": "2020-01-24T22:59:16Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -1865,42 +1861,25 @@ private static String nodeNames(final Set<TopologyDescription.Node> nodes) {\n         return sb.toString();\n     }\n \n-    /**\n-     * Used to capture subscribed topic via Patterns discovered during the\n-     * partition assignment process.\n-     */\n-    public static class SubscriptionUpdates {\n-\n-        private final Set<String> updatedTopicSubscriptions = new HashSet<>();\n-\n-        private void updateTopics(final Collection<String> topicNames) {\n-            updatedTopicSubscriptions.clear();\n-            updatedTopicSubscriptions.addAll(topicNames);\n-        }\n-\n-        public Collection<String> getUpdates() {\n-            return Collections.unmodifiableSet(updatedTopicSubscriptions);\n-        }\n-\n-        boolean hasUpdates() {\n-            return !updatedTopicSubscriptions.isEmpty();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return String.format(\"SubscriptionUpdates{updatedTopicSubscriptions=%s}\", updatedTopicSubscriptions);\n-        }\n+    Set<String> subscriptionUpdates() {\n+        return Collections.unmodifiableSet(subscriptionUpdates);\n     }\n \n-    void updateSubscribedTopics(final Set<String> topics,\n-                                final String logPrefix) {\n-        final SubscriptionUpdates subscriptionUpdates = new SubscriptionUpdates();\n-        log.debug(\"{}found {} topics possibly matching regex\", logPrefix, topics);\n-        // update the topic groups with the returned subscription set for regex pattern subscriptions\n-        subscriptionUpdates.updateTopics(topics);\n-        updateSubscriptions(subscriptionUpdates, logPrefix);\n+    boolean hasSubscriptionUpdates() {\n+        return !subscriptionUpdates.isEmpty();\n     }\n \n+    synchronized void updateSubscribedTopics(final Set<String> topics,\n+                                             final String logPrefix) {\n+        log.debug(\"{}found {} topics possibly matching subscription\", logPrefix, topics);", "originalCommit": "9ba3ee4e5849cae6c81d5b229846e0507630647f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg4MDI5OQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r370880299", "bodyText": "topics is a Set.\nWhat's your intention for the second parameter ?\nIf you want the number of topics logged, you should use topics.size().", "author": "tedyu", "createdAt": "2020-01-24T23:06:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg3ODY2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg4NDk3OQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r370884979", "bodyText": "The spacing kept bothering me too but it's actually correct (logPrefix has a space at the end) -- we should actually clean up this class at some point to use log = new LogContext(logPrefix).logger(getClass()); rather than explicitly insert the prefix everywhere.\nI didn't write this log message, just moved things around, but I think the intention was to list the actual topics not just the size. I probably could've improved the wording of it though", "author": "ableegoldman", "createdAt": "2020-01-24T23:26:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg3ODY2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg4ODcwNw==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r370888707", "bodyText": "Since topics Set can be quite large, I doubt the intention was to show the contents.\n'{} topics' reads like the count of entries should be shown.", "author": "tedyu", "createdAt": "2020-01-24T23:45:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg3ODY2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDkwMjMyNw==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r370902327", "bodyText": "Well the topics set should only include the matching topics that the Streams app is actually subscribed to, but I agree the wording suggests it should be the size/count. Since this PR is already merged do you want to submit a quick follow-up PR?", "author": "ableegoldman", "createdAt": "2020-01-25T01:15:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg3ODY2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDkwNTc0MQ==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r370905741", "bodyText": "Created #8005", "author": "tedyu", "createdAt": "2020-01-25T01:51:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg3ODY2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg4MDM1MA==", "url": "https://github.com/apache/kafka/pull/7969#discussion_r370880350", "bodyText": "Similar comment as above two.", "author": "tedyu", "createdAt": "2020-01-24T23:06:19Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -1865,42 +1861,25 @@ private static String nodeNames(final Set<TopologyDescription.Node> nodes) {\n         return sb.toString();\n     }\n \n-    /**\n-     * Used to capture subscribed topic via Patterns discovered during the\n-     * partition assignment process.\n-     */\n-    public static class SubscriptionUpdates {\n-\n-        private final Set<String> updatedTopicSubscriptions = new HashSet<>();\n-\n-        private void updateTopics(final Collection<String> topicNames) {\n-            updatedTopicSubscriptions.clear();\n-            updatedTopicSubscriptions.addAll(topicNames);\n-        }\n-\n-        public Collection<String> getUpdates() {\n-            return Collections.unmodifiableSet(updatedTopicSubscriptions);\n-        }\n-\n-        boolean hasUpdates() {\n-            return !updatedTopicSubscriptions.isEmpty();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return String.format(\"SubscriptionUpdates{updatedTopicSubscriptions=%s}\", updatedTopicSubscriptions);\n-        }\n+    Set<String> subscriptionUpdates() {\n+        return Collections.unmodifiableSet(subscriptionUpdates);\n     }\n \n-    void updateSubscribedTopics(final Set<String> topics,\n-                                final String logPrefix) {\n-        final SubscriptionUpdates subscriptionUpdates = new SubscriptionUpdates();\n-        log.debug(\"{}found {} topics possibly matching regex\", logPrefix, topics);\n-        // update the topic groups with the returned subscription set for regex pattern subscriptions\n-        subscriptionUpdates.updateTopics(topics);\n-        updateSubscriptions(subscriptionUpdates, logPrefix);\n+    boolean hasSubscriptionUpdates() {\n+        return !subscriptionUpdates.isEmpty();\n     }\n \n+    synchronized void updateSubscribedTopics(final Set<String> topics,\n+                                             final String logPrefix) {\n+        log.debug(\"{}found {} topics possibly matching subscription\", logPrefix, topics);\n+        subscriptionUpdates.clear();\n+        subscriptionUpdates.addAll(topics);\n+\n+        log.debug(\"{}updating builder with {} topic(s) with possible matching regex subscription(s)\",", "originalCommit": "9ba3ee4e5849cae6c81d5b229846e0507630647f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}