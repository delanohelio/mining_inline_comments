{"pr_number": 8221, "pr_title": "KAFKA-9561: update task input partitions after rebalance", "pr_createdAt": "2020-03-04T08:43:06Z", "pr_url": "https://github.com/apache/kafka/pull/8221", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMwMjU2Ng==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r389302566", "bodyText": "nit: remove empty line", "author": "abbccdda", "createdAt": "2020-03-07T18:34:41Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -100,4 +105,14 @@ final void transitionTo(final Task.State newState) {\n             throw new IllegalStateException(\"Invalid transition from \" + oldState + \" to \" + newState);\n         }\n     }\n+\n+    @Override\n+    public ProcessorTopology getProcessorTopology() {\n+        return topology;\n+    }\n+\n+    public void setProcessorTopology(final ProcessorTopology topology) {\n+        this.topology = topology;\n+", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDU4NTk3NQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r390585975", "bodyText": "sure. fixed", "author": "avalsa", "createdAt": "2020-03-10T20:19:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMwMjU2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMwMjU4OQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r389302589", "bodyText": "Remove commented out line", "author": "abbccdda", "createdAt": "2020-03-07T18:35:13Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -161,6 +164,7 @@ private Properties configProps(final boolean enableEoS) {\n             mkEntry(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, enableEoS ? StreamsConfig.EXACTLY_ONCE : StreamsConfig.AT_LEAST_ONCE)\n         ));\n     }\n+    //mkEntry(ProducerConfig.TRANSACTIONAL_ID_CONFIG, APPLICATION_ID + \"-1\"),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDU4NTgyOQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r390585829", "bodyText": "I checked - this line no longer in commit Dif", "author": "avalsa", "createdAt": "2020-03-10T20:19:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMwMjU4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwODMxNQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r389808315", "bodyText": "nit: space after //", "author": "abbccdda", "createdAt": "2020-03-09T16:30:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/SourceNode.java", "diffHunk": "@@ -128,4 +129,9 @@ public String toString(final String indent) {\n     public TimestampExtractor getTimestampExtractor() {\n         return timestampExtractor;\n     }\n+\n+    //for test purposes only", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDU4NTQ3NQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r390585475", "bodyText": "fixed", "author": "avalsa", "createdAt": "2020-03-10T20:18:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwODMxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwOTkyMQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r389809921", "bodyText": "We could just call inputPartitions on L170", "author": "abbccdda", "createdAt": "2020-03-09T16:32:23Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -146,15 +148,25 @@ public StreamTask(final TaskId id,\n         // initialize the consumed and committed offset cache\n         consumedOffsets = new HashMap<>();\n \n-        // create queues for each assigned partition and associate them\n-        // to corresponding source nodes in the processor topology\n-        final Map<TopicPartition, RecordQueue> partitionQueues = new HashMap<>();\n+        defaultTimestampExtractor = config.defaultTimestampExtractor();\n+        defaultDeserializationExceptionHandler = config.defaultDeserializationExceptionHandler();\n \n         // initialize the topology with its own context\n         processorContext = new ProcessorContextImpl(id, this, config, this.recordCollector, stateMgr, streamsMetrics, cache);\n \n-        final TimestampExtractor defaultTimestampExtractor = config.defaultTimestampExtractor();\n-        final DeserializationExceptionHandler defaultDeserializationExceptionHandler = config.defaultDeserializationExceptionHandler();\n+        recordInfo = new PartitionGroup.RecordInfo();\n+        partitionGroup = new PartitionGroup(createPartitionQueues(logContext),\n+                                            TaskMetrics.recordLatenessSensor(threadId, taskId, streamsMetrics));\n+\n+        stateMgr.registerGlobalStateStores(topology.globalStateStores());\n+    }\n+\n+    // create queues for each assigned partition and associate them\n+    // to corresponding source nodes in the processor topology\n+    private Map<TopicPartition, RecordQueue> createPartitionQueues(final LogContext logContext) {\n+        final Set<TopicPartition> partitions = inputPartitions();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDU4NTA0Ng==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r390585046", "bodyText": "Yes, inlined this", "author": "avalsa", "createdAt": "2020-03-10T20:17:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgwOTkyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgxMDgyMA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r389810820", "bodyText": "remove", "author": "abbccdda", "createdAt": "2020-03-09T16:33:47Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -284,6 +291,7 @@ public void resume() {\n             case SUSPENDED:\n                 // just transit the state without any logical changes: suspended and restoring states\n                 // are not actually any different for inner modules\n+", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDU4NTE4Ng==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r390585186", "bodyText": "sure, fixed", "author": "avalsa", "createdAt": "2020-03-10T20:17:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgxMDgyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgxNTY5MA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r389815690", "bodyText": "Let's log more context here, for example:\nlog.trace(\"Update task {} inputPartitions: current {}, new {}\", task,  task. inputPartitions(), topicPartitions);", "author": "abbccdda", "createdAt": "2020-03-09T16:41:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -244,14 +247,25 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n             }\n         }\n \n-        builder.addSubscribedTopicsFromAssignment(\n-            activeTasks.values().stream().flatMap(Collection::stream).collect(Collectors.toList()),\n-            logPrefix\n-        );\n-\n         changelogReader.transitToRestoreActive();\n     }\n \n+    private void updateInputPartitionsAndResume(final Task task, final Set<TopicPartition> topicPartitions) {\n+        final boolean requiresUpdate = !task.inputPartitions().equals(topicPartitions);\n+        if (requiresUpdate) {\n+            log.trace(\"update inputPartitions {} {}\", task, topicPartitions);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDU4NTM2OA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r390585368", "bodyText": "Agree. used proposed log format", "author": "avalsa", "createdAt": "2020-03-10T20:18:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgxNTY5MA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwNzY5Nw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r391307697", "bodyText": "We should unit test this function", "author": "abbccdda", "createdAt": "2020-03-11T22:31:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -93,6 +93,11 @@ long partitionTimestamp(final TopicPartition partition) {\n         return queue.partitionTime();\n     }\n \n+    void updatePartitions(final Map<TopicPartition, RecordQueue> partitionQueues) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQyNzcxMA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392427710", "bodyText": "created couple of tests", "author": "avalsa", "createdAt": "2020-03-13T19:27:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwNzY5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTAwNQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r391309005", "bodyText": "Let's move the updatePartitions logic out of initializeTopology, instead just call it inside resume", "author": "abbccdda", "createdAt": "2020-03-11T22:35:24Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -679,10 +689,13 @@ private void initializeTaskTime(final Map<TopicPartition, OffsetAndMetadata> off\n         return purgableConsumedOffsets;\n     }\n \n-    private void initializeTopology() {\n+    private void initializeTopology(final boolean updatePartitionQueues) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQyNzc4OA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392427788", "bodyText": "moved", "author": "avalsa", "createdAt": "2020-03-13T19:28:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTAwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTg0Ng==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r391309846", "bodyText": "Why do we need this helper function? Shouldn't it be protected?", "author": "abbccdda", "createdAt": "2020-03-11T22:37:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractTask.java", "diffHunk": "@@ -116,4 +121,13 @@ static void executeAndMaybeSwallow(final boolean clean,\n             }\n         }\n     }\n+\n+    @Override\n+    public ProcessorTopology getProcessorTopology() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQyODMzNQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392428335", "bodyText": "Idea was that mutable variable should be 'protected' with method calls from external places. But agree protected would work better here.", "author": "avalsa", "createdAt": "2020-03-13T19:29:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTg0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTY1NQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r391311655", "bodyText": "nit: we could put topic2 initialization before L196", "author": "abbccdda", "createdAt": "2020-03-11T22:42:56Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -178,6 +178,44 @@ public void subscribe(final Pattern topics, final ConsumerRebalanceListener list\n \n         TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n+        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+    }\n+\n+    @Test\n+    public void testRegexRecordsAreProcessedAfterReassignment() throws Exception {\n+        final String topic1 = \"TEST-TOPIC-1\";\n+        final String topic2 = \"TEST-TOPIC-2\";", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQyODM4OA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392428388", "bodyText": "agree", "author": "avalsa", "createdAt": "2020-03-13T19:29:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTY1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjQ5OA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r391312498", "bodyText": "Could we also add a test case for when we call task.resume(true)?", "author": "abbccdda", "createdAt": "2020-03-11T22:45:24Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1103,7 +1103,7 @@ public void shouldNotReInitializeTopologyWhenResuming() throws IOException {\n         assertFalse(source1.initialized);\n         assertFalse(source2.initialized);\n \n-        task.resume();\n+        task.resume(false);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQyODUyNQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392428525", "bodyText": "Yes, of course", "author": "avalsa", "createdAt": "2020-03-13T19:29:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjQ5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjk4OA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r391312988", "bodyText": "Could we also verify consumer and changeLogReader?", "author": "abbccdda", "createdAt": "2020-03-11T22:46:48Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -342,6 +343,31 @@ public void shouldAddNonResumedSuspendedTasks() {\n         verify(activeTaskCreator);\n     }\n \n+    @Test\n+    public void shouldAddNonResumedSuspendedTasks2() {\n+        final Task task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+        // expect these calls twice (because we're going to tryToCompleteRestoration twice)\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(taskId00Assignment))).andReturn(singletonList(task00));\n+        replay(activeTaskCreator, consumer, changeLogReader);\n+\n+\n+        taskManager.handleAssignment(taskId00Assignment, emptyMap());\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+\n+        final Set<TopicPartition> newPartitionsSet = mkSet(t1p1);\n+        final Map<TaskId, Set<TopicPartition>> taskIdSetMap = singletonMap(taskId00, newPartitionsSet);\n+        taskManager.handleAssignment(taskIdSetMap, emptyMap());\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertEquals(newPartitionsSet, task00.inputPartitions());\n+        assertEquals(task00, taskManager.taskForInputPartition(t1p1));\n+        verify(activeTaskCreator);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQyOTI2Nw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392429267", "bodyText": "Fixed, just copy-pasted from near test =). In this class they are almost everywhere are not verified. May be should create task for this?", "author": "avalsa", "createdAt": "2020-03-13T19:31:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjk4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxNDA2NA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r391314064", "bodyText": "What does Task2 mean?", "author": "abbccdda", "createdAt": "2020-03-11T22:50:03Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -342,6 +343,31 @@ public void shouldAddNonResumedSuspendedTasks() {\n         verify(activeTaskCreator);\n     }\n \n+    @Test\n+    public void shouldAddNonResumedSuspendedTasks2() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQyOTM0MA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392429340", "bodyText": "gave it meaningful name", "author": "avalsa", "createdAt": "2020-03-13T19:31:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxNDA2NA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ5MDA5NA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392490094", "bodyText": "nit: let's put iterator initialization closer to the start of while loop", "author": "abbccdda", "createdAt": "2020-03-13T21:28:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -93,6 +96,33 @@ long partitionTimestamp(final TopicPartition partition) {\n         return queue.partitionTime();\n     }\n \n+    // creates queues for new partitions, removes old queues, saves cached records for previously assigned partitions\n+    void updatePartitions(final Set<TopicPartition> newInputPartitions, final Function<TopicPartition, RecordQueue> recordQueueCreator) {\n+        final Iterator<Map.Entry<TopicPartition, RecordQueue>> queuesIterator = partitionQueues.entrySet().iterator();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NDczMA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392654730", "bodyText": "fixed", "author": "avalsa", "createdAt": "2020-03-15T09:07:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ5MDA5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ5MjM2OQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392492369", "bodyText": "nit: this seems unnecessary", "author": "abbccdda", "createdAt": "2020-03-13T21:32:18Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -55,6 +55,7 @@\n import java.util.Set;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n+", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NDczNg==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392654736", "bodyText": "fixed", "author": "avalsa", "createdAt": "2020-03-15T09:07:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ5MjM2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ5MzQ1Nw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392493457", "bodyText": "This is nice!", "author": "abbccdda", "createdAt": "2020-03-13T21:34:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -952,4 +952,32 @@ int numBuffered() {\n     long streamTime() {\n         return partitionGroup.streamTime();\n     }\n+\n+    private class RecordQueueCreator {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NDcwNw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392654707", "bodyText": "Thank you", "author": "avalsa", "createdAt": "2020-03-15T09:06:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ5MzQ1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUwMjI1MA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392502250", "bodyText": "What's the reasoning for resetting streamTime here?", "author": "abbccdda", "createdAt": "2020-03-13T21:49:54Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -93,6 +96,33 @@ long partitionTimestamp(final TopicPartition partition) {\n         return queue.partitionTime();\n     }\n \n+    // creates queues for new partitions, removes old queues, saves cached records for previously assigned partitions\n+    void updatePartitions(final Set<TopicPartition> newInputPartitions, final Function<TopicPartition, RecordQueue> recordQueueCreator) {\n+        final Iterator<Map.Entry<TopicPartition, RecordQueue>> queuesIterator = partitionQueues.entrySet().iterator();\n+        final Set<TopicPartition> removedPartitions = new HashSet<>();\n+        streamTime = RecordQueue.UNKNOWN;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY1NDY3MQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r392654671", "bodyText": "def from src: stream-time of this partition group defined as the largest timestamp seen across all partitions. E.g. we removed partition with largest value so we have to update stream-time with new value (max from rest of partitions) or if all of them removed it should be UNKOWN.\nBut I haven't investigate where this property is used so may be it's not very necessary.", "author": "avalsa", "createdAt": "2020-03-15T09:06:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUwMjI1MA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMjE0Nw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r400412147", "bodyText": "Could we move the comment to next line?", "author": "abbccdda", "createdAt": "2020-03-30T18:41:39Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -93,6 +96,33 @@ long partitionTimestamp(final TopicPartition partition) {\n         return queue.partitionTime();\n     }\n \n+    // creates queues for new partitions, removes old queues, saves cached records for previously assigned partitions\n+    void updatePartitions(final Set<TopicPartition> newInputPartitions, final Function<TopicPartition, RecordQueue> recordQueueCreator) {\n+        final Set<TopicPartition> removedPartitions = new HashSet<>();\n+        streamTime = RecordQueue.UNKNOWN;\n+        final Iterator<Map.Entry<TopicPartition, RecordQueue>> queuesIterator = partitionQueues.entrySet().iterator();\n+        while (queuesIterator.hasNext()) {\n+            final Map.Entry<TopicPartition, RecordQueue> queueEntry = queuesIterator.next();\n+            final TopicPartition topicPartition = queueEntry.getKey();\n+            if (newInputPartitions.contains(topicPartition)) { // if partition is left should save it's queue", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjExOTQ5MQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r402119491", "bodyText": "of course", "author": "avalsa", "createdAt": "2020-04-02T07:54:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMjE0Nw=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI5Nzc3Mg==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r409297772", "bodyText": "Thanks for the added tests. Have you verified the test would fail with current trunk?\nAlso this test takes one minute for me on local, could you take a look and see whether it takes so long?", "author": "abbccdda", "createdAt": "2020-04-16T05:51:35Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/RegexSourceIntegrationTest.java", "diffHunk": "@@ -179,6 +179,44 @@ public void subscribe(final Pattern topics, final ConsumerRebalanceListener list\n \n         TestUtils.waitForCondition(() -> assignedTopics.equals(expectedSecondAssignment), STREAM_TASKS_NOT_UPDATED);\n \n+        CLUSTER.deleteTopicsAndWait(\"TEST-TOPIC-1\", \"TEST-TOPIC-2\");\n+    }\n+\n+    @Test\n+    public void testRegexRecordsAreProcessedAfterReassignment() throws Exception {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjE3ODk1Mg==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r412178952", "bodyText": "Yes, it fails on trunk.\nI found reason: here I tried to isolate tests: so we can create same topic in one test, delete it after we are done, do the same in next test, so on. But after each test it calls streams.close() in teardown method. I guess It tries to do smth with removed topics and gets TimeoutException because can't do it. may be it's issue but probably it happens only when close. But it seems to be not related to this task. @abbccdda What do you think? I fixed it easily (may be not best approach): call streams.close in test method body before deleting topics.", "author": "avalsa", "createdAt": "2020-04-21T13:21:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI5Nzc3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTIwMTc0MQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r415201741", "bodyText": "I see, sounds good", "author": "abbccdda", "createdAt": "2020-04-26T03:21:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI5Nzc3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMDMyNA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r409300324", "bodyText": "The map itself should still be final", "author": "abbccdda", "createdAt": "2020-04-16T05:58:53Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -50,7 +53,7 @@\n  */\n public class PartitionGroup {\n \n-    private final Map<TopicPartition, RecordQueue> partitionQueues;\n+    private Map<TopicPartition, RecordQueue> partitionQueues;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAxNTIzNg==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r412015236", "bodyText": "agree", "author": "avalsa", "createdAt": "2020-04-21T09:13:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMDMyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMTMxOQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r409301319", "bodyText": "remove should be a no-op if the topicPartition doesn't exist. Might be able to rephrase:\nif (!newInputPartitions.contains(topicPartition)) {\n   totalBuffered -= queueEntry.getValue().size();\n   queuesIterator.remove();\n   removedPartitions.add(topicPartition);\n}\nnewInputPartitions.remove(topicPartition);", "author": "abbccdda", "createdAt": "2020-04-16T06:02:00Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -93,6 +96,29 @@ long partitionTimestamp(final TopicPartition partition) {\n         return queue.partitionTime();\n     }\n \n+    // creates queues for new partitions, removes old queues, saves cached records for previously assigned partitions\n+    void updatePartitions(final Set<TopicPartition> newInputPartitions, final Function<TopicPartition, RecordQueue> recordQueueCreator) {\n+        final Set<TopicPartition> removedPartitions = new HashSet<>();\n+        final Iterator<Map.Entry<TopicPartition, RecordQueue>> queuesIterator = partitionQueues.entrySet().iterator();\n+        while (queuesIterator.hasNext()) {\n+            final Map.Entry<TopicPartition, RecordQueue> queueEntry = queuesIterator.next();\n+            final TopicPartition topicPartition = queueEntry.getKey();\n+            if (newInputPartitions.contains(topicPartition)) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyMDUxMA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r412020510", "bodyText": "Yes, can rephrase as you offer.", "author": "avalsa", "createdAt": "2020-04-21T09:21:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMTMxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMjQwOA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r409302408", "bodyText": "IIUC we are trying to avoid calling the initializeTopology twice, I'm thinking whether this optimization is necessary, as the guarantee to call  initializeTopology in RESTORING state is weak, which might be implicitly changed in the future, cc @guozhangwang", "author": "abbccdda", "createdAt": "2020-04-16T06:05:06Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -305,6 +297,12 @@ public void resume() {\n             default:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while resuming active task \" + id);\n         }\n+        if (requiresUpdate) {\n+            partitionGroup.updatePartitions(inputPartitions(), recordQueueCreator::createQueue);\n+            if (state() != State.RESTORING) { // if task is RESTORING then topology will be initialized in completeRestoration", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA1NTAwOA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r412055008", "bodyText": "when work on this task it fails some test that ensure that initializeTopology called once here. I thought that it might be important and decided to support this.", "author": "avalsa", "createdAt": "2020-04-21T10:11:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMjQwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMjkyNw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r409302927", "bodyText": "s/WithFalseFlag/WhenRequireUpdate", "author": "abbccdda", "createdAt": "2020-04-16T06:06:33Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1127,7 +1127,7 @@ public void shouldReadCommittedOffsetAndRethrowTimeoutWhenCompleteRestoration()\n     }\n \n     @Test\n-    public void shouldNotReInitializeTopologyWhenResuming() throws IOException {\n+    public void shouldNotReInitializeTopologyWhenResumingWithFalseFlag() throws IOException {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA0OTkyMg==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r412049922", "bodyText": "fixed", "author": "avalsa", "createdAt": "2020-04-21T10:03:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMjkyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMzQ1NA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r409303454", "bodyText": "Why do we use third-person singular instead of calling the flag requireUpdate? I feel updateInputPartitions is more explicit here.", "author": "abbccdda", "createdAt": "2020-04-16T06:08:06Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -115,7 +115,7 @@ public void suspend() {\n     }\n \n     @Override\n-    public void resume() {\n+    public void resume(final boolean requiresUpdate) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjA5OTE2NQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r412099165", "bodyText": "agree. beautified it.", "author": "avalsa", "createdAt": "2020-04-21T11:23:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMwMzQ1NA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU4MzAyMw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r422583023", "bodyText": "If the state was RUNNING then we would effectively call initializeTopology twice. Is that intentional?", "author": "guozhangwang", "createdAt": "2020-05-10T04:33:26Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -429,6 +421,15 @@ public void closeDirty() {\n         log.info(\"Closed dirty\");\n     }\n \n+    @Override\n+    public void updateInputPartitions(final Set<TopicPartition> topicPartitions) {\n+        super.updateInputPartitions(topicPartitions);\n+        partitionGroup.updatePartitions(topicPartitions, recordQueueCreator::createQueue);\n+        if (state() != State.RESTORING) { // if task is RESTORING then topology will be initialized in completeRestoration", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY0NzUzNg==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r423647536", "bodyText": "if I correctly remember if state==RUNNING initializeTopology is called only once in update method. Only if state == RESTORING it will be called later. It's no problem to call this method twice but it's aka optimization.", "author": "avalsa", "createdAt": "2020-05-12T11:03:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU4MzAyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU4MzEyNw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r422583127", "bodyText": "These two newly added functions are always called at the same time, I'd suggest we merge them into a single function, e.g. named update(topicPartitions, topology).", "author": "guozhangwang", "createdAt": "2020-05-10T04:35:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -170,6 +170,8 @@ public boolean isValidTransition(final State newState) {\n      */\n     void closeDirty();\n \n+    void updateInputPartitions(final Set<TopicPartition> topicPartitions);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzY0ODU2Nw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r423648567", "bodyText": "agree. changed to one function call", "author": "avalsa", "createdAt": "2020-05-12T11:05:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU4MzEyNw=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM3Nzg5NA==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r426377894", "bodyText": "nit: could we add some comments for this function?", "author": "abbccdda", "createdAt": "2020-05-18T05:33:26Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -170,6 +170,8 @@ public boolean isValidTransition(final State newState) {\n      */\n     void closeDirty();\n \n+    void update(final Set<TopicPartition> topicPartitions, final ProcessorTopology processorTopology);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5OTE4OQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r426499189", "bodyText": "yes, added short description", "author": "avalsa", "createdAt": "2020-05-18T09:41:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM3Nzg5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM4NjEyOQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r426386129", "bodyText": "nit: allBuffered &= newInputPartitions.isEmpty();", "author": "abbccdda", "createdAt": "2020-05-18T06:03:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -93,6 +96,28 @@ long partitionTimestamp(final TopicPartition partition) {\n         return queue.partitionTime();\n     }\n \n+    // creates queues for new partitions, removes old queues, saves cached records for previously assigned partitions\n+    void updatePartitions(final Set<TopicPartition> newInputPartitions, final Function<TopicPartition, RecordQueue> recordQueueCreator) {\n+        final Set<TopicPartition> removedPartitions = new HashSet<>();\n+        final Iterator<Map.Entry<TopicPartition, RecordQueue>> queuesIterator = partitionQueues.entrySet().iterator();\n+        while (queuesIterator.hasNext()) {\n+            final Map.Entry<TopicPartition, RecordQueue> queueEntry = queuesIterator.next();\n+            final TopicPartition topicPartition = queueEntry.getKey();\n+            if (!newInputPartitions.contains(topicPartition)) {\n+                // if partition is removed should delete it's queue\n+                totalBuffered -= queueEntry.getValue().size();\n+                queuesIterator.remove();\n+                removedPartitions.add(topicPartition);\n+            }\n+            newInputPartitions.remove(topicPartition);\n+        }\n+        for (final TopicPartition newInputPartition : newInputPartitions) {\n+            partitionQueues.put(newInputPartition, recordQueueCreator.apply(newInputPartition));\n+        }\n+        nonEmptyQueuesByTime.removeIf(q -> removedPartitions.contains(q.partition()));\n+        allBuffered = allBuffered && newInputPartitions.isEmpty();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5ODg3Nw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r426498877", "bodyText": "fixed", "author": "avalsa", "createdAt": "2020-05-18T09:41:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM4NjEyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM4NjE5OQ==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r426386199", "bodyText": "s/it's/its", "author": "abbccdda", "createdAt": "2020-05-18T06:03:23Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/PartitionGroup.java", "diffHunk": "@@ -93,6 +96,28 @@ long partitionTimestamp(final TopicPartition partition) {\n         return queue.partitionTime();\n     }\n \n+    // creates queues for new partitions, removes old queues, saves cached records for previously assigned partitions\n+    void updatePartitions(final Set<TopicPartition> newInputPartitions, final Function<TopicPartition, RecordQueue> recordQueueCreator) {\n+        final Set<TopicPartition> removedPartitions = new HashSet<>();\n+        final Iterator<Map.Entry<TopicPartition, RecordQueue>> queuesIterator = partitionQueues.entrySet().iterator();\n+        while (queuesIterator.hasNext()) {\n+            final Map.Entry<TopicPartition, RecordQueue> queueEntry = queuesIterator.next();\n+            final TopicPartition topicPartition = queueEntry.getKey();\n+            if (!newInputPartitions.contains(topicPartition)) {\n+                // if partition is removed should delete it's queue", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjQ5ODc1Mw==", "url": "https://github.com/apache/kafka/pull/8221#discussion_r426498753", "bodyText": "fixed", "author": "avalsa", "createdAt": "2020-05-18T09:41:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjM4NjE5OQ=="}], "type": "inlineReview"}, {"oid": "ecf6ba2c244f181b862a9bcf2f51f829946c490a", "url": "https://github.com/apache/kafka/commit/ecf6ba2c244f181b862a9bcf2f51f829946c490a", "message": "KAFKA-9561: update task input partitions after rebalance", "committedDate": "2020-05-18T09:40:32Z", "type": "commit"}, {"oid": "ecf6ba2c244f181b862a9bcf2f51f829946c490a", "url": "https://github.com/apache/kafka/commit/ecf6ba2c244f181b862a9bcf2f51f829946c490a", "message": "KAFKA-9561: update task input partitions after rebalance", "committedDate": "2020-05-18T09:40:32Z", "type": "forcePushed"}, {"oid": "dc85a4694d663ad13d75681d28398d4b61a4f482", "url": "https://github.com/apache/kafka/commit/dc85a4694d663ad13d75681d28398d4b61a4f482", "message": "fix spotbug", "committedDate": "2020-05-26T16:31:40Z", "type": "commit"}]}