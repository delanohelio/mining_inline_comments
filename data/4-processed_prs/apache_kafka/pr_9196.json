{"pr_number": 9196, "pr_title": "KAFKA-10402: Upgrade system tests to python3", "pr_createdAt": "2020-08-18T10:17:40Z", "pr_url": "https://github.com/apache/kafka/pull/9196", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjQ3MA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086470", "bodyText": "No need to explicit conversion to int (result is already int)", "author": "ivandasch", "createdAt": "2020-08-22T12:40:01Z", "path": "tests/kafkatest/benchmarks/core/benchmark_test.py", "diffHunk": "@@ -88,7 +88,7 @@ def test_producer_throughput(self, acks, topic, num_producers=1, message_size=DE\n         self.validate_versions(client_version, broker_version)\n         self.start_kafka(security_protocol, security_protocol, broker_version, tls_version)\n         # Always generate the same total amount of data\n-        nrecords = int(self.target_data_size / message_size)\n+        nrecords = int(self.target_data_size // message_size)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTMzNw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189337", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:20:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjQ3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU2MQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086561", "bodyText": "redundant conversion to iterator (.items() is already iterable)", "author": "ivandasch", "createdAt": "2020-08-22T12:40:49Z", "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -114,7 +114,7 @@ def metrics(self, host=None, client_id=None, name=None, group=None, tags=None):\n         Get any collected metrics that match the specified parameters, yielding each as a tuple of\n         (key, [<timestamp, value>, ...]) values.\n         \"\"\"\n-        for k, values in self._http_metrics.iteritems():\n+        for k, values in iter(self._http_metrics.items()):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTM0MQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189341", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:21:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU4Mw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086583", "bodyText": "Same as above + tuple can be constructed from generator, no need to create list for that\nJust use tuple(raw_metric['tags'].items())", "author": "ivandasch", "createdAt": "2020-08-22T12:40:59Z", "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -154,7 +154,7 @@ def do_POST(self):\n             name = raw_metric['name']\n             group = raw_metric['group']\n             # Convert to tuple of pairs because dicts & lists are unhashable\n-            tags = tuple([(k, v) for k, v in raw_metric['tags'].iteritems()]),\n+            tags = tuple([(k, v) for k, v in iter(raw_metric['tags'].items())]),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTM1OA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189358", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:21:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjU4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njc3NA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086774", "bodyText": "No need to create iterator from items(), join can accept generator easily, no need to convert it to list.", "author": "ivandasch", "createdAt": "2020-08-22T12:43:11Z", "path": "tests/kafkatest/services/performance/producer_performance.py", "diffHunk": "@@ -78,7 +78,7 @@ def start_cmd(self, node):\n             'bootstrap_servers': self.kafka.bootstrap_servers(self.security_config.security_protocol),\n             'client_id': self.client_id,\n             'kafka_run_class': self.path.script(\"kafka-run-class.sh\", node),\n-            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.iteritems()])\n+            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in iter(self.http_metrics_client_configs.items())])", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjU3Mg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192572", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:53:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njc3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg0MA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086840", "bodyText": "No need to create iterator from iterable", "author": "ivandasch", "createdAt": "2020-08-22T12:44:17Z", "path": "tests/kafkatest/services/security/security_config.py", "diffHunk": "@@ -362,7 +362,7 @@ def props(self, prefix=''):\n             return \"\"\n         if self.has_sasl and not self.static_jaas_conf and 'sasl.jaas.config' not in self.properties:\n             raise Exception(\"JAAS configuration property has not yet been initialized\")\n-        config_lines = (prefix + key + \"=\" + value for key, value in self.properties.iteritems())\n+        config_lines = (prefix + key + \"=\" + value for key, value in iter(self.properties.items()))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODYzNg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188636", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:13:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg4Mg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086882", "bodyText": "No need to create iterator from iterable", "author": "ivandasch", "createdAt": "2020-08-22T12:44:51Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -361,7 +361,7 @@ def clean_node(self, node):\n \n     def current_assignment(self):\n         with self.lock:\n-            return { handler.node: handler.current_assignment() for handler in self.event_handlers.itervalues() }\n+            return { handler.node: handler.current_assignment() for handler in iter(self.event_handlers.values()) }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODYwNg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188606", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:13:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njg4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkwNg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086906", "bodyText": "No need to create iterator from iterable", "author": "ivandasch", "createdAt": "2020-08-22T12:45:05Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -372,7 +372,7 @@ def current_position(self, tp):\n \n     def owner(self, tp):\n         with self.lock:\n-            for handler in self.event_handlers.itervalues():\n+            for handler in iter(self.event_handlers.values()):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODU5OQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188599", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:13:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkyNQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086925", "bodyText": "Same as above.", "author": "ivandasch", "createdAt": "2020-08-22T12:45:13Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODU3NQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188575", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:13:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NjkyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk1MQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086951", "bodyText": "Same as above", "author": "ivandasch", "createdAt": "2020-08-22T12:45:21Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODU1OA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188558", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:13:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk2Nw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086967", "bodyText": "Same as above", "author": "ivandasch", "createdAt": "2020-08-22T12:45:29Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODUwMg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188502", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:12:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk4OQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086989", "bodyText": "Same as above", "author": "ivandasch", "createdAt": "2020-08-22T12:45:40Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODQ5NQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188495", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:12:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk5OQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475086999", "bodyText": "Same as above", "author": "ivandasch", "createdAt": "2020-08-22T12:45:48Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Rebalancing]\n \n     def dead_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODQ4Mg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188482", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:12:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Njk5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzMQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087031", "bodyText": "Same as above", "author": "ivandasch", "createdAt": "2020-08-22T12:45:56Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in iter(self.event_handlers.values()))\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in iter(self.event_handlers.values()))\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in iter(self.event_handlers.values())\n                        if handler.idx <= keep_alive])\n \n     def joined_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Joined]\n \n     def rebalancing_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Rebalancing]\n \n     def dead_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())\n                     if handler.state == ConsumerState.Dead]\n \n     def alive_nodes(self):\n         with self.lock:\n-            return [handler.node for handler in self.event_handlers.itervalues()\n+            return [handler.node for handler in iter(self.event_handlers.values())", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODQ2NQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188465", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:11:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzOA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087038", "bodyText": "No need to create iterator from iterable", "author": "ivandasch", "createdAt": "2020-08-22T12:46:20Z", "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "diffHunk": "@@ -86,14 +88,14 @@ def invoke_compatibility_program(self, features):\n                \"--topic %s \" % (self.zk.path.script(\"kafka-run-class.sh\", node),\n                                self.kafka.bootstrap_servers(),\n                                len(self.kafka.nodes),\n-                               self.topics.keys()[0]))\n-        for k, v in features.iteritems():\n+                               [*self.topics.keys()][0]))\n+        for k, v in iter(features.items()):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODM0Mw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188343", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:10:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzE5MA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087190", "bodyText": "I suppose that next(iter(self.topics.keys())) is more readable, than this mix of brackets and stars", "author": "ivandasch", "createdAt": "2020-08-22T12:48:35Z", "path": "tests/kafkatest/tests/client/client_compatibility_features_test.py", "diffHunk": "@@ -86,14 +88,14 @@ def invoke_compatibility_program(self, features):\n                \"--topic %s \" % (self.zk.path.script(\"kafka-run-class.sh\", node),\n                                self.kafka.bootstrap_servers(),\n                                len(self.kafka.nodes),\n-                               self.topics.keys()[0]))\n-        for k, v in features.iteritems():\n+                               [*self.topics.keys()][0]))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjQ4NA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192484", "bodyText": "I made it list(self.topics.keys())[0] which seems even more readable.", "author": "nizhikov", "createdAt": "2020-08-23T08:53:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzE5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzIxNg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087216", "bodyText": "No need to create iterator", "author": "ivandasch", "createdAt": "2020-08-22T12:48:59Z", "path": "tests/kafkatest/tests/client/quota_test.py", "diffHunk": "@@ -162,7 +162,7 @@ def test_quota(self, quota_type, override_quota=True, producer_num=1, consumer_n\n             jmx_attributes=['bytes-consumed-rate'], version=client_version)\n         consumer.run()\n \n-        for idx, messages in consumer.messages_consumed.iteritems():\n+        for idx, messages in iter(consumer.messages_consumed.items()):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODMwOA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188308", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:10:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzIxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzQwNA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087404", "bodyText": "src_seqno_max = max(src_seqnos) if len(src_seqnos) else 0 is more readable", "author": "ivandasch", "createdAt": "2020-08-22T12:50:53Z", "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,14 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            if len(src_seqnos) == 0:\n+                src_seqno_max = 0\n+            else:\n+                src_seqno_max = max(src_seqnos)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTUxNw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189517", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:23:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzQwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzU1OQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087559", "bodyText": "No need to create list and iterator, just\nsorted(seqno for seqno, count in src_seqno_counts.items() if count > 1)", "author": "ivandasch", "createdAt": "2020-08-22T12:53:20Z", "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,14 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            if len(src_seqnos) == 0:\n+                src_seqno_max = 0\n+            else:\n+                src_seqno_max = max(src_seqnos)\n             self.logger.debug(\"Max source seqno: %d\", src_seqno_max)\n             src_seqno_counts = Counter(src_seqnos)\n             missing_src_seqnos = sorted(set(range(src_seqno_max)).difference(set(src_seqnos)))\n-            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.iteritems() if count > 1])\n+            duplicate_src_seqnos = sorted([seqno for seqno,count in iter(src_seqno_counts.items()) if count > 1])", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjUzMg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192532", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:53:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzU1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzY0Mw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087643", "bodyText": "No need to create iterator", "author": "ivandasch", "createdAt": "2020-08-22T12:54:23Z", "path": "tests/kafkatest/tests/end_to_end.py", "diffHunk": "@@ -87,7 +85,7 @@ def on_record_consumed(self, record, node):\n \n     def await_consumed_offsets(self, last_acked_offsets, timeout_sec):\n         def has_finished_consuming():\n-            for partition, offset in last_acked_offsets.iteritems():\n+            for partition, offset in iter(last_acked_offsets.items()):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4OTU0Nw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475189547", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:23:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4NzY0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc0NA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087744", "bodyText": "list(self.topics.keys())[topic_index] is more readable", "author": "ivandasch", "createdAt": "2020-08-22T12:55:27Z", "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "diffHunk": "@@ -119,7 +119,7 @@ def __init__(self, test_context):\n     def fail_broker_type(self, failure_mode, broker_type):\n         # Pick a random topic and bounce it's leader\n         topic_index = randint(0, len(self.topics.keys()) - 1)\n-        topic = self.topics.keys()[topic_index]\n+        topic = [*self.topics.keys()][topic_index]", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODI4MA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188280", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:10:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc3NA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087774", "bodyText": "No need to create iterator", "author": "ivandasch", "createdAt": "2020-08-22T12:55:42Z", "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "diffHunk": "@@ -40,7 +40,7 @@ def _all_partitions(self, topic, num_partitions):\n \n     def _partitions(self, assignment):\n         partitions = []\n-        for parts in assignment.itervalues():\n+        for parts in iter(assignment.values()):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE4ODI4OA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475188288", "bodyText": "fixed.", "author": "nizhikov", "createdAt": "2020-08-23T08:10:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzc3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzg1OA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475087858", "bodyText": "If you start to refactor this class, may be refactor also call to super constructor? LooseVersion is now normal class (in python3). Just super().__init__(version_string)", "author": "ivandasch", "createdAt": "2020-08-22T12:56:53Z", "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjE1NQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192155", "bodyText": "There is no refactoring here :)\nMy goal is just to make python3 works for current tests.", "author": "nizhikov", "createdAt": "2020-08-23T08:49:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4Nzg1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4ODU3Nw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475088577", "bodyText": "You do not need all these functions above, if you call super method properly super()._cmp(other)", "author": "ivandasch", "createdAt": "2020-08-22T13:06:04Z", "path": "tests/kafkatest/version.py", "diffHunk": "@@ -49,6 +49,34 @@ def __str__(self):\n         else:\n             return LooseVersion.__str__(self)\n \n+    def __eq__(self, other):\n+        return self._cmp(other) == 0\n+\n+    def __lt__(self, other):\n+        return self._cmp(other) < 0\n+\n+    def __le__(self, other):\n+        return self._cmp(other) <= 0\n+\n+    def __gt__(self, other):\n+        return self._cmp(other) > 0\n+\n+    def __ge__(self, other):\n+        return self._cmp(other) >= 0\n+\n+    def _cmp(self, other):", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5MjMxNg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475192316", "bodyText": "Thanks.\nIt seems we can just override _cmp and that's it.\nI will double-check it with the tests run.", "author": "nizhikov", "createdAt": "2020-08-23T08:51:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4ODU3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTEyMA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195120", "bodyText": "Yes, but I don't understand why not call super methods properly, this approach is outdated even for python 2.7", "author": "ivandasch", "createdAt": "2020-08-23T09:19:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTA4ODU3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NDY5Ng==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475194696", "bodyText": "You don't have to create list in order to use join, just\n ' '.join(\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.items())\nOr, even better, just\n ' '.join(\"%s=%s\" % kv for kv in self.http_metrics_client_configs.items())", "author": "ivandasch", "createdAt": "2020-08-23T09:15:13Z", "path": "tests/kafkatest/services/performance/producer_performance.py", "diffHunk": "@@ -78,7 +78,7 @@ def start_cmd(self, node):\n             'bootstrap_servers': self.kafka.bootstrap_servers(self.security_config.security_protocol),\n             'client_id': self.client_id,\n             'kafka_run_class': self.path.script(\"kafka-run-class.sh\", node),\n-            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.iteritems()])\n+            'metrics_props': ' '.join([\"%s=%s\" % (k, v) for k, v in self.http_metrics_client_configs.items()])", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NDkwMw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475194903", "bodyText": "You don't have to create list here, use generator as ctor args :\ntags = tuple(raw_metric['tags'].items())", "author": "ivandasch", "createdAt": "2020-08-23T09:17:03Z", "path": "tests/kafkatest/services/monitor/http.py", "diffHunk": "@@ -154,7 +154,7 @@ def do_POST(self):\n             name = raw_metric['name']\n             group = raw_metric['group']\n             # Convert to tuple of pairs because dicts & lists are unhashable\n-            tags = tuple([(k, v) for k, v in raw_metric['tags'].iteritems()]),\n+            tags = tuple([(k, v) for k, v in raw_metric['tags'].items()]),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTAwNw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195007", "bodyText": "Rewrite please it like this:\nsorted(seqno for seqno,count in sink_seqno_counts.items() if count > 1)", "author": "ivandasch", "createdAt": "2020-08-23T09:18:12Z", "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -440,11 +441,11 @@ def test_bounce(self, clean, connect_protocol):\n             sink_seqnos = [msg['seqno'] for msg in sink_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because\n             # clean bouncing should commit on rebalance.\n-            sink_seqno_max = max(sink_seqnos)\n+            sink_seqno_max = max(sink_seqnos) if len(sink_seqnos) else 0\n             self.logger.debug(\"Max sink seqno: %d\", sink_seqno_max)\n             sink_seqno_counts = Counter(sink_seqnos)\n             missing_sink_seqnos = sorted(set(range(sink_seqno_max)).difference(set(sink_seqnos)))\n-            duplicate_sink_seqnos = sorted([seqno for seqno,count in sink_seqno_counts.iteritems() if count > 1])\n+            duplicate_sink_seqnos = sorted([seqno for seqno,count in iter(sink_seqno_counts.items()) if count > 1])", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTAyOQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195029", "bodyText": "Rewrite please it like this:\nsorted(seqno for seqno,count in iter(sink_seqno_counts.items()) if count > 1)", "author": "ivandasch", "createdAt": "2020-08-23T09:18:28Z", "path": "tests/kafkatest/tests/connect/connect_distributed_test.py", "diffHunk": "@@ -420,11 +421,11 @@ def test_bounce(self, clean, connect_protocol):\n             src_seqnos = [msg['seqno'] for msg in src_messages if msg['task'] == task]\n             # Every seqno up to the largest one we ever saw should appear. Each seqno should only appear once because clean\n             # bouncing should commit on rebalance.\n-            src_seqno_max = max(src_seqnos)\n+            src_seqno_max = max(src_seqnos) if len(src_seqnos) else 0\n             self.logger.debug(\"Max source seqno: %d\", src_seqno_max)\n             src_seqno_counts = Counter(src_seqnos)\n             missing_src_seqnos = sorted(set(range(src_seqno_max)).difference(set(src_seqnos)))\n-            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.iteritems() if count > 1])\n+            duplicate_src_seqnos = sorted([seqno for seqno,count in src_seqno_counts.items() if count > 1])", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NTkyOQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475195929", "bodyText": "Please, remove list creation here also", "author": "ivandasch", "createdAt": "2020-08-23T09:27:35Z", "path": "tests/kafkatest/services/verifiable_consumer.py", "diffHunk": "@@ -386,33 +386,33 @@ def last_commit(self, tp):\n \n     def total_consumed(self):\n         with self.lock:\n-            return sum(handler.total_consumed for handler in self.event_handlers.itervalues())\n+            return sum(handler.total_consumed for handler in self.event_handlers.values())\n \n     def num_rebalances(self):\n         with self.lock:\n-            return max(handler.assigned_count for handler in self.event_handlers.itervalues())\n+            return max(handler.assigned_count for handler in self.event_handlers.values())\n \n     def num_revokes_for_alive(self, keep_alive=1):\n         with self.lock:\n-            return max([handler.revoked_count for handler in self.event_handlers.itervalues()\n+            return max([handler.revoked_count for handler in self.event_handlers.values()", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NjE1Mg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475196152", "bodyText": "You don't fix it, unfortunatelly", "author": "ivandasch", "createdAt": "2020-08-23T09:30:06Z", "path": "tests/kafkatest/tests/verifiable_consumer_test.py", "diffHunk": "@@ -40,7 +40,7 @@ def _all_partitions(self, topic, num_partitions):\n \n     def _partitions(self, assignment):\n         partitions = []\n-        for parts in assignment.itervalues():\n+        for parts in iter(assignment.values()):", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTIyNzE5MA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r475227190", "bodyText": "Oops, forgot new line...", "author": "ivandasch", "createdAt": "2020-08-23T14:36:59Z", "path": "tests/kafkatest/utils/__init__.py", "diffHunk": "@@ -13,4 +13,4 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n-from util import kafkatest_version, is_version, is_int, is_int_with_prefix, node_is_reachable, validate_delivery\n+from .util import kafkatest_version, is_version, is_int, is_int_with_prefix, node_is_reachable, validate_delivery", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5ODc1Mw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482798753", "bodyText": "Add a comment explaining why the hold is necssary.", "author": "edenhill", "createdAt": "2020-09-03T08:24:42Z", "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjkxMDYxNg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482910616", "bodyText": "I tried to prevent python2 packages from install.\nBut, actually, we don't need this line.", "author": "nizhikov", "createdAt": "2020-09-03T11:36:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5ODc1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482799763", "bodyText": "Should ducktape no longer be version pinned? (it probably needs to be to avoid future build breakages of old kafka branches).\nOr is this just during Python3-ification of ducktape itself?", "author": "edenhill", "createdAt": "2020-09-03T08:26:12Z", "path": "tests/docker/Dockerfile", "diffHunk": "@@ -32,9 +32,11 @@ ARG ducker_creator=default\n LABEL ducker.creator=$ducker_creator\n \n # Update Linux and install necessary utilities.\n-RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python-pip python-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute && apt-get -y clean\n-RUN python -m pip install -U pip==9.0.3;\n-RUN pip install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34 && pip install --upgrade ducktape==0.7.9\n+RUN apt-mark hold python2 python2-minimal python2.7 python2.7-minimal libpython2-stdlib libpython2.7-minimal libpython2.7-stdlib\n+RUN apt update && apt install -y sudo netcat iptables rsync unzip wget curl jq coreutils openssh-server net-tools vim python3-pip python3-dev libffi-dev libssl-dev cmake pkg-config libfuse-dev iperf traceroute mc && apt-get -y clean\n+RUN python3 -m pip install -U pip==20.2.2;\n+RUN pip3 install --upgrade cffi virtualenv pyasn1 boto3 pycrypto pywinrm ipaddress enum34\n+RUN pip3 install git+https://github.com/confluentinc/ducktape", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg0NDUwOA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482844508", "bodyText": "Should ducktape no longer be version pinned?\n\nNo. We should continue to use a specific version of the ducktape.\nCurrently, master branch of the ducktape contains unreleased fixes for python3.\nPlease, see the issue for details - confluentinc/ducktape#245\nOnce fixes will be released I will pin PR to a specific version.", "author": "nizhikov", "createdAt": "2020-09-03T09:35:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQzMjQwOA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r483432408", "bodyText": "Great!\nSuggest updating the title of this PR to include [DO NOT MERGE] until the ducktape version is updated.", "author": "edenhill", "createdAt": "2020-09-04T07:14:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQ3NDQ4OA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r483474488", "bodyText": "Agree. Done.", "author": "nizhikov", "createdAt": "2020-09-04T08:38:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgwNDg0OA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r495804848", "bodyText": "A new ducktape version needs to be released, and this line changed to a versioned pypi install, prior to merge, right?", "author": "edenhill", "createdAt": "2020-09-28T09:25:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgyMDc3Mg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r495820772", "bodyText": "Hello, @edenhill\nYes, but I'm a bit confused about ducktape release.\nCan't receive much feedback from maintainers.\nconfluentinc/ducktape#245", "author": "nizhikov", "createdAt": "2020-09-28T09:52:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgzNjM5Nw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r495836397", "bodyText": "I'll see what I can do.", "author": "edenhill", "createdAt": "2020-09-28T10:21:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjY3MDE1OQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r496670159", "bodyText": "Hello! Any news on ducktape release?", "author": "nizhikov", "createdAt": "2020-09-29T12:19:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjc5OTc2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNjc2NA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482806764", "bodyText": "nit: I believe % is a bit deprecated in favour of .format(..) or f\"This means .. {measured_rates}\" (for >=3.6).", "author": "edenhill", "createdAt": "2020-09-03T08:37:41Z", "path": "tests/kafkatest/tests/core/network_degrade_test.py", "diffHunk": "@@ -129,10 +129,10 @@ def test_rate(self, task_name, device_name, latency_ms, rate_limit_kbit):\n         self.logger.info(\"Measured rates: %s\" % measured_rates)\n \n         # We expect to see measured rates within an order of magnitude of our target rate\n-        low_kbps = rate_limit_kbit / 10\n+        low_kbps = rate_limit_kbit // 10\n         high_kbps = rate_limit_kbit * 10\n         acceptable_rates = [r for r in measured_rates if low_kbps < r < high_kbps]\n \n         msg = \"Expected most of the measured rates to be within an order of magnitude of target %d.\" % rate_limit_kbit\n-        msg += \" This means `tc` did not limit the bandwidth as expected.\"\n+        msg += \" This means `tc` did not limit the bandwidth as expected. Measured rates %s\" % str(measured_rates)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg1ODUzMw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482858533", "bodyText": "Actually, this change unrelated. Reverted.\nI just trying to debug this test, because it fails(it fails in the trunk, also).\nAnyway, I think you are right and we can rewrite all usages of \"...\" % param to the new syntax.\nLet's do it in another PR?", "author": "nizhikov", "createdAt": "2020-09-03T09:58:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNjc2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg2MTA4MQ==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482861081", "bodyText": "Until % is officially deprecated we can keep them around, no need for bulk-fixing them, but new code should preferably use f\"\" or format().\nBut that's just my opinion.", "author": "edenhill", "createdAt": "2020-09-03T10:02:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNjc2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNzI0Mw==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482807243", "bodyText": "Since this PR is about upgrading to Python3 it probably shouldn't modify test parameters.", "author": "edenhill", "createdAt": "2020-09-03T08:38:35Z", "path": "tests/kafkatest/tests/core/replica_scale_test.py", "diffHunk": "@@ -48,7 +46,7 @@ def teardown(self):\n         self.zk.stop()\n \n     @cluster(num_nodes=12)\n-    @parametrize(topic_count=500, partition_count=34, replication_factor=3)\n+    @parametrize(topic_count=100, partition_count=34, replication_factor=3)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg0ODUwNg==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482848506", "bodyText": "Sorry, I decrease this variable to be able to run this tests in the Docker, otherwise it just freeze on my machine. Fixed.", "author": "nizhikov", "createdAt": "2020-09-03T09:41:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwNzI0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwODMyMA==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482808320", "bodyText": "alternatively:\ntopic = random.choice(list(self.topics.keys()))", "author": "edenhill", "createdAt": "2020-09-03T08:40:23Z", "path": "tests/kafkatest/tests/streams/streams_broker_bounce_test.py", "diffHunk": "@@ -119,7 +119,7 @@ def __init__(self, test_context):\n     def fail_broker_type(self, failure_mode, broker_type):\n         # Pick a random topic and bounce it's leader\n         topic_index = randint(0, len(self.topics.keys()) - 1)\n-        topic = self.topics.keys()[topic_index]\n+        topic = list(self.topics.keys())[topic_index]", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg2MzE5Ng==", "url": "https://github.com/apache/kafka/pull/9196#discussion_r482863196", "bodyText": "I tried to do minimal changes and just fix the syntax difference between python2 and python3.\nLet's keep it to simplify ongoing reviews?", "author": "nizhikov", "createdAt": "2020-09-03T10:06:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwODMyMA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "931b2737701818da8e898aac00d03ba48489500e", "url": "https://github.com/apache/kafka/commit/931b2737701818da8e898aac00d03ba48489500e", "message": "KAFKA-10402: WIP", "committedDate": "2020-09-23T21:29:16Z", "type": "commit"}, {"oid": "7271e4dc727d8ba778bb375a74ede6e9427832ce", "url": "https://github.com/apache/kafka/commit/7271e4dc727d8ba778bb375a74ede6e9427832ce", "message": "KAFKA-10402: fixing imports.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "5f5ed7100f439a8e4a389cecb97e7aad0a2e0035", "url": "https://github.com/apache/kafka/commit/5f5ed7100f439a8e4a389cecb97e7aad0a2e0035", "message": "KAFKA-10402: has_key -> in, iteritems -> iter(items) fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "9973345959483f3ee9bceafb8d302f192e6e539f", "url": "https://github.com/apache/kafka/commit/9973345959483f3ee9bceafb8d302f192e6e539f", "message": "KAFKA-10402: iteriterms -> iter(dict.items), itervalues -> iter(dict.values).", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "9486c964b0454ac5488a7ca41e9afcbd98e6bd6d", "url": "https://github.com/apache/kafka/commit/9486c964b0454ac5488a7ca41e9afcbd98e6bd6d", "message": "KAFKA-10402: basestring -> str", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "71218d875780acf67ece492aed20a12bf109efdf", "url": "https://github.com/apache/kafka/commit/71218d875780acf67ece492aed20a12bf109efdf", "message": "KAFKA-10402: syntax fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "f0b68c095be8f5604faa19a8084222d77a6071d6", "url": "https://github.com/apache/kafka/commit/f0b68c095be8f5604faa19a8084222d77a6071d6", "message": "KAFKA-10402: reduce topic_count to run tests on small servers.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "a814612a0e30513e70b48eb1a0e8cbe07eb03f93", "url": "https://github.com/apache/kafka/commit/a814612a0e30513e70b48eb1a0e8cbe07eb03f93", "message": "KAFKA-10402: fix usage iterable as array.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "575818b55229196b2c874c97be0587e7f5d0fac1", "url": "https://github.com/apache/kafka/commit/575818b55229196b2c874c97be0587e7f5d0fac1", "message": "KAFKA-10402: fix comparation of str(DEV_BRANCH)", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "8a4ea97fc9fe5f88982ee00a17ffe4c7acff0525", "url": "https://github.com/apache/kafka/commit/8a4ea97fc9fe5f88982ee00a17ffe4c7acff0525", "message": "KAFKA-10402: xrange -> range", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "4522601f3450a163c33d91205af1ca7be881a4e2", "url": "https://github.com/apache/kafka/commit/4522601f3450a163c33d91205af1ca7be881a4e2", "message": "KAFKA-10402: division operator + import http.server", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "b7c6833723960e26e2ec94d7430d37fc4d61d1c4", "url": "https://github.com/apache/kafka/commit/b7c6833723960e26e2ec94d7430d37fc4d61d1c4", "message": "KAFKA-10402: division operator fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "887d4284819bb53f92442b09ea106857b6a6cdfa", "url": "https://github.com/apache/kafka/commit/887d4284819bb53f92442b09ea106857b6a6cdfa", "message": "KAFKA-10402: various syntax fixes based on the tests results.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "975968a98ac1bd3efec429ea1fe1f74d68606b75", "url": "https://github.com/apache/kafka/commit/975968a98ac1bd3efec429ea1fe1f74d68606b75", "message": "KAFKA-10402: final test fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "a9be51f9f9dedf920f272b0c6b8ef42ab373b16f", "url": "https://github.com/apache/kafka/commit/a9be51f9f9dedf920f272b0c6b8ef42ab373b16f", "message": "KAFKA-10402: final test fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "9614020d7b5fb0332fb4e3229bfe6e269454c079", "url": "https://github.com/apache/kafka/commit/9614020d7b5fb0332fb4e3229bfe6e269454c079", "message": "KAFKA-10402: code review fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "e1d523efcefcf47ffd5d1f4b77833bc0f706e817", "url": "https://github.com/apache/kafka/commit/e1d523efcefcf47ffd5d1f4b77833bc0f706e817", "message": "KAFKA-10402: code review fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "18e48af0a67f1b8a8a96455de5092583890e690d", "url": "https://github.com/apache/kafka/commit/18e48af0a67f1b8a8a96455de5092583890e690d", "message": "KAFKA-10402: code review fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "d706fc73d06b4edabd0979dcd2c3f1e75f5736b0", "url": "https://github.com/apache/kafka/commit/d706fc73d06b4edabd0979dcd2c3f1e75f5736b0", "message": "KAFKA-10402: code review fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "14712e64299d700bfd19279cf0ddc878b8d17ab2", "url": "https://github.com/apache/kafka/commit/14712e64299d700bfd19279cf0ddc878b8d17ab2", "message": "KAFKA-10402: code review fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "4bb0f1d7568d56640915ecb49fe47de5e9550c0c", "url": "https://github.com/apache/kafka/commit/4bb0f1d7568d56640915ecb49fe47de5e9550c0c", "message": "KAFKA-10402: code review fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "c31fd72593cb93b0b5785c31bd973f6a12b5c04c", "url": "https://github.com/apache/kafka/commit/c31fd72593cb93b0b5785c31bd973f6a12b5c04c", "message": "KAFKA-10402: code review fixes.", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "316dc95a0dc4ae6d49327a34ea31e2824726bbed", "url": "https://github.com/apache/kafka/commit/316dc95a0dc4ae6d49327a34ea31e2824726bbed", "message": "KAFKA-10402: decreasing topic count to run tests on docker", "committedDate": "2020-09-23T21:30:25Z", "type": "commit"}, {"oid": "316dc95a0dc4ae6d49327a34ea31e2824726bbed", "url": "https://github.com/apache/kafka/commit/316dc95a0dc4ae6d49327a34ea31e2824726bbed", "message": "KAFKA-10402: decreasing topic count to run tests on docker", "committedDate": "2020-09-23T21:30:25Z", "type": "forcePushed"}, {"oid": "2db3aa5fac9579ff595b66a29e83617c8c47d87b", "url": "https://github.com/apache/kafka/commit/2db3aa5fac9579ff595b66a29e83617c8c47d87b", "message": "Merge branch 'trunk' into KAFKA-10402", "committedDate": "2020-10-07T13:26:05Z", "type": "commit"}, {"oid": "2e47ec3772a39983c15ea7ae698915e78429454b", "url": "https://github.com/apache/kafka/commit/2e47ec3772a39983c15ea7ae698915e78429454b", "message": "KAFKA-10402: ducktape 0.8.0", "committedDate": "2020-10-07T13:50:38Z", "type": "commit"}]}