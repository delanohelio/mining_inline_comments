{"pr_number": 9563, "pr_title": "KAFKA-10684; Avoid additional envelope copies during network transmission", "pr_createdAt": "2020-11-05T05:42:02Z", "pr_url": "https://github.com/apache/kafka/pull/9563", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzgyMjQ3OA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r517822478", "bodyText": "Is ```nullableVersions`` required? It seems there is no null handle/check in production for this field.", "author": "chia7712", "createdAt": "2020-11-05T06:42:39Z", "path": "clients/src/main/resources/common/message/EnvelopeRequest.json", "diffHunk": "@@ -23,7 +23,7 @@\n   \"fields\": [\n     { \"name\": \"RequestData\", \"type\": \"bytes\", \"versions\": \"0+\", \"zeroCopy\": true,\n       \"about\": \"The embedded request header and data.\"},\n-    { \"name\": \"RequestPrincipal\", \"type\": \"bytes\", \"versions\": \"0+\", \"zeroCopy\": true, \"nullableVersions\": \"0+\",\n+    { \"name\": \"RequestPrincipal\", \"type\": \"bytes\", \"versions\": \"0+\", \"nullableVersions\": \"0+\",", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQzMzEzNQ==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518433135", "bodyText": "I agree it should not be nullable. Will fix it.", "author": "hachikuji", "createdAt": "2020-11-05T23:29:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzgyMjQ3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzgyNDMyNA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r517824324", "bodyText": "The buffer is used/owned by SendBuilder only. It seems to me this constructor should accept capacity(int type) rather than ByteBuffer. (SendBuilder should create ByteBuffer in construction)", "author": "chia7712", "createdAt": "2020-11-05T06:48:12Z", "path": "clients/src/main/java/org/apache/kafka/common/network/SendBuilder.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.network;\n+\n+import org.apache.kafka.common.protocol.ObjectSerializationCache;\n+import org.apache.kafka.common.protocol.Writable;\n+import org.apache.kafka.common.requests.RequestHeader;\n+import org.apache.kafka.common.utils.ByteUtils;\n+\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * This class provides a way to build {@link Send} objects for network\n+ * transmission from generated {@link org.apache.kafka.common.protocol.ApiMessage}\n+ * types. Its main advantage over direct {@link ByteBuffer} allocation based on\n+ * {@link org.apache.kafka.common.protocol.ApiMessage#size(ObjectSerializationCache, short)}\n+ * is that it avoids copying \"bytes\" fields. The downside is that it is up to the caller\n+ * to allocate a buffer which accounts only for the additional request overhead.\n+ *\n+ * See {@link org.apache.kafka.common.requests.EnvelopeRequest#toSend(String, RequestHeader)}\n+ * for example usage.\n+ */\n+public class SendBuilder implements Writable {\n+    private final List<ByteBuffer> buffers = new ArrayList<>();\n+    private final ByteBuffer buffer;\n+\n+    public SendBuilder(ByteBuffer buffer) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM5NjQwNw==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518396407", "bodyText": "Is this specifically for Envelope case?", "author": "abbccdda", "createdAt": "2020-11-05T22:01:55Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/RequestHeader.java", "diffHunk": "@@ -89,10 +89,11 @@ public ResponseHeader toResponseHeader() {\n     public static RequestHeader parse(ByteBuffer buffer) {\n         short apiKey = -1;\n         try {\n+            int position = buffer.position();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQxNDQwMA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518414400", "bodyText": "This was a bug. This logic assumes that the buffer is at position 0. Let me add a test case.", "author": "hachikuji", "createdAt": "2020-11-05T22:41:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM5NjQwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUxMjgyOA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518512828", "bodyText": "Does it need null check (maybe no-op)?", "author": "chia7712", "createdAt": "2020-11-06T04:10:52Z", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Writable.java", "diffHunk": "@@ -33,6 +35,23 @@\n     void writeVarint(int i);\n     void writeVarlong(long i);\n \n+    default void writeApiMessage(\n+        ApiMessage message,\n+        ObjectSerializationCache serializationCache,\n+        short version\n+    ) {\n+        message.write(this, serializationCache, version);\n+    }\n+\n+    default void writeRecords(BaseRecords records) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUzMjIyOA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518532228", "bodyText": "I was concerned about this also, but the generated code adds its own null check.", "author": "hachikuji", "createdAt": "2020-11-06T05:33:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUxMjgyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUxMzM1MQ==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518513351", "bodyText": "It is used by only SendBuilder. How about moving it to SendBuilder?", "author": "chia7712", "createdAt": "2020-11-06T04:13:05Z", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Writable.java", "diffHunk": "@@ -33,6 +35,23 @@\n     void writeVarint(int i);\n     void writeVarlong(long i);\n \n+    default void writeApiMessage(", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU0OTgwOQ==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518549809", "bodyText": "Fair enough.", "author": "hachikuji", "createdAt": "2020-11-06T06:37:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUxMzM1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUyMDM0NQ==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518520345", "bodyText": "Why it is not addZeroCopyBytes?", "author": "chia7712", "createdAt": "2020-11-06T04:43:42Z", "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "diffHunk": "@@ -1581,56 +1570,56 @@ private void generateVariableLengthFieldSize(FieldSpec field,\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n                         buffer.printf(\"_cache.setArraySizeInBytes(%s, _arraySize);%n\",\n                             field.camelCaseName());\n-                        buffer.printf(\"_size += _arraySize + ByteUtils.sizeOfUnsignedVarint(_arraySize);%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_arraySize.totalSize()));%n\");\n+                        buffer.printf(\"_size.add(_arraySize);%n\");\n                     } else {\n-                        buffer.printf(\"_size += _arraySize;%n\");\n+                        buffer.printf(\"_size.add(_arraySize);%n\");\n                     }\n                 } else if (field.type().isBytes()) {\n+                    buffer.printf(\"MessageSize _bytesSize = new MessageSize();%n\");\n                     if (field.zeroCopy()) {\n-                        buffer.printf(\"int _bytesSize = %s.remaining();%n\", field.camelCaseName());\n+                        buffer.printf(\"_bytesSize.addZeroCopyBytes(%s.remaining());%n\", field.camelCaseName());\n                     } else {\n-                        buffer.printf(\"int _bytesSize = %s.length;%n\", field.camelCaseName());\n+                        buffer.printf(\"_bytesSize.addBytes(%s.length);%n\", field.camelCaseName());\n                     }\n                     VersionConditional.forVersions(fieldFlexibleVersions(field), possibleVersions).\n                         ifMember(__ -> {\n                             headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n                             if (field.zeroCopy()) {\n-                                buffer.printf(\"_bytesSize += \" +\n-                                        \"ByteUtils.sizeOfUnsignedVarint(%s.remaining() + 1);%n\", field.camelCaseName());\n+                                buffer.printf(\"_bytesSize.addBytes(\" +\n+                                        \"ByteUtils.sizeOfUnsignedVarint(%s.remaining() + 1));%n\", field.camelCaseName());\n                             } else {\n-                                buffer.printf(\"_bytesSize += ByteUtils.sizeOfUnsignedVarint(%s.length + 1);%n\",\n+                                buffer.printf(\"_bytesSize.addBytes(ByteUtils.sizeOfUnsignedVarint(%s.length + 1));%n\",\n                                     field.camelCaseName());\n                             }\n                         }).\n                         ifNotMember(__ -> {\n-                            buffer.printf(\"_bytesSize += 4;%n\");\n+                            buffer.printf(\"_bytesSize.addBytes(4);%n\");\n                         }).\n                         generate(buffer);\n                     if (tagged) {\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n-                        buffer.printf(\"_size += _bytesSize + ByteUtils.sizeOfUnsignedVarint(_bytesSize);%n\");\n-                    } else {\n-                        buffer.printf(\"_size += _bytesSize;%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_bytesSize.totalSize()));%n\");\n                     }\n+                    buffer.printf(\"_size.add(_bytesSize);%n\");\n                 } else if (field.type().isRecords()) {\n-                    buffer.printf(\"int _recordsSize = %s.sizeInBytes();%n\", field.camelCaseName());\n+                    buffer.printf(\"_size.addBytes(%s.sizeInBytes());%n\", field.camelCaseName());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUyMzI1Mw==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518523253", "bodyText": "Yeah, my bad. Probably messed this up after renaming.", "author": "hachikuji", "createdAt": "2020-11-06T04:55:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODUyMDM0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU2NDU0Mw==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518564543", "bodyText": "not sure whether it is ok to ignore the version of EnvelopeRequest.", "author": "chia7712", "createdAt": "2020-11-06T07:22:51Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -91,4 +91,14 @@ public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n     public static EnvelopeRequest parse(ByteBuffer buffer, short version) {\n         return new EnvelopeRequest(ApiKeys.ENVELOPE.parseRequest(version, buffer), version);\n     }\n+\n+    public EnvelopeRequestData data() {\n+        return data;\n+    }\n+\n+    @Override\n+    public Send toSend(String destination, RequestHeader header) {\n+        return SendBuilder.buildRequestSend(destination, header, this.data);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg4NTQ5Nw==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r518885497", "bodyText": "The version is contained in RequestHeader. This pattern was probably started before AbstractRequest included the version as well.", "author": "hachikuji", "createdAt": "2020-11-06T17:06:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODU2NDU0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTM0MzQzNA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519343434", "bodyText": "if (tagged) {\n  buffer.printf(\"int _sizeBeforeBytes = _size.totalSize();%n\");\n}", "author": "chia7712", "createdAt": "2020-11-08T10:40:16Z", "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "diffHunk": "@@ -1579,58 +1566,58 @@ private void generateVariableLengthFieldSize(FieldSpec field,\n                     }\n                     if (tagged) {\n                         headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n+                        buffer.printf(\"int _arraySize = _size.totalSize() - _sizeBeforeArray;%n\");\n                         buffer.printf(\"_cache.setArraySizeInBytes(%s, _arraySize);%n\",\n                             field.camelCaseName());\n-                        buffer.printf(\"_size += _arraySize + ByteUtils.sizeOfUnsignedVarint(_arraySize);%n\");\n-                    } else {\n-                        buffer.printf(\"_size += _arraySize;%n\");\n+                        buffer.printf(\"_size.addBytes(ByteUtils.sizeOfUnsignedVarint(_arraySize));%n\");\n                     }\n                 } else if (field.type().isBytes()) {\n+                    buffer.printf(\"int _sizeBeforeBytes = _size.totalSize();%n\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk3MTY4Ng==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519971686", "bodyText": "Good catch", "author": "hachikuji", "createdAt": "2020-11-09T17:01:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTM0MzQzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTQyNzI4Ng==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519427286", "bodyText": "If all requests are using auto-generated data, should this be default implementation of AbstractRequest?", "author": "chia7712", "createdAt": "2020-11-08T15:04:25Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -91,4 +91,14 @@ public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n     public static EnvelopeRequest parse(ByteBuffer buffer, short version) {\n         return new EnvelopeRequest(ApiKeys.ENVELOPE.parseRequest(version, buffer), version);\n     }\n+\n+    public EnvelopeRequestData data() {\n+        return data;\n+    }\n+\n+    @Override\n+    public Send toSend(String destination, RequestHeader header) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk1NTE5OQ==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519955199", "bodyText": "Yeah, I think so. And looks like we're almost there. After your patch for Produce, the only remaining unconverted API that I see is OffsetsForLeaderEpoch.", "author": "hachikuji", "createdAt": "2020-11-09T16:43:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTQyNzI4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTk4MzUxNw==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519983517", "bodyText": "#7409 might be a good opportunity to complete this. What do you think @ijuma ?", "author": "hachikuji", "createdAt": "2020-11-09T17:19:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTQyNzI4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTQzNjQzMQ==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r519436431", "bodyText": "I'm thinking about how to simplify this process.\nCould we reuse the method void write(Writable writable, ObjectSerializationCache cache, short version) ? Maybe we can create a Writable instance but it does not write data to any output. Instead, it calculate the size of buffer according to input data.", "author": "chia7712", "createdAt": "2020-11-08T15:31:26Z", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Message.java", "diffHunk": "@@ -47,7 +47,20 @@\n      *                      If the specified version is too new to be supported\n      *                      by this software.\n      */\n-    int size(ObjectSerializationCache cache, short version);\n+    default int size(ObjectSerializationCache cache, short version) {\n+        MessageSizeAccumulator size = new MessageSizeAccumulator();\n+        addSize(size, cache, version);\n+        return size.totalSize();\n+    }\n+\n+    /**\n+     * Add the size of this message to an accumulator.\n+     *\n+     * @param size          The size accumulator to add to\n+     * @param cache         The serialization size cache to populate.\n+     * @param version       The version to use.\n+     */\n+    void addSize(MessageSizeAccumulator size, ObjectSerializationCache cache, short version);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUzMDIyOA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r520530228", "bodyText": "if (tagged) {\n  buffer.printf(\"int _sizeBeforeArray = _size.totalSize();%n\");\n}", "author": "chia7712", "createdAt": "2020-11-10T12:38:52Z", "path": "generator/src/main/java/org/apache/kafka/message/MessageDataGenerator.java", "diffHunk": "@@ -1529,37 +1516,37 @@ private void generateVariableLengthFieldSize(FieldSpec field,\n                             if (tagged) {\n                                 buffer.printf(\"int _stringPrefixSize = \" +\n                                     \"ByteUtils.sizeOfUnsignedVarint(_stringBytes.length + 1);%n\");\n-                                buffer.printf(\"_size += _stringBytes.length + _stringPrefixSize + \" +\n-                                    \"ByteUtils.sizeOfUnsignedVarint(_stringPrefixSize);%n\");\n+                                buffer.printf(\"_size.addBytes(_stringBytes.length + _stringPrefixSize + \" +\n+                                    \"ByteUtils.sizeOfUnsignedVarint(_stringPrefixSize));%n\");\n                             } else {\n-                                buffer.printf(\"_size += _stringBytes.length + \" +\n-                                    \"ByteUtils.sizeOfUnsignedVarint(_stringBytes.length + 1);%n\");\n+                                buffer.printf(\"_size.addBytes(_stringBytes.length + \" +\n+                                    \"ByteUtils.sizeOfUnsignedVarint(_stringBytes.length + 1));%n\");\n                             }\n                         }).\n                         ifNotMember(__ -> {\n                             if (tagged) {\n                                 throw new RuntimeException(\"Tagged field \" + field.name() +\n                                     \" should not be present in non-flexible versions.\");\n                             }\n-                            buffer.printf(\"_size += _stringBytes.length + 2;%n\");\n+                            buffer.printf(\"_size.addBytes(_stringBytes.length + 2);%n\");\n                         }).\n                         generate(buffer);\n                 } else if (field.type().isArray()) {\n-                    buffer.printf(\"int _arraySize = 0;%n\");\n+                    buffer.printf(\"int _sizeBeforeArray = _size.totalSize();%n\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUzNzYxMw==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r520537613", "bodyText": "Is this method equal to https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java#L727 ?", "author": "chia7712", "createdAt": "2020-11-10T12:51:17Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/AbstractResponse.java", "diffHunk": "@@ -88,16 +80,11 @@ protected void updateErrorCounts(Map<Errors, Integer> errorCounts, Errors error)\n \n     protected abstract Struct toStruct(short version);\n \n-    public ByteBuffer serializeBody(short version) {\n-        Struct dataStruct = toStruct(version);\n-        ByteBuffer buffer = ByteBuffer.allocate(dataStruct.sizeOf());\n-        dataStruct.writeTo(buffer);\n-        buffer.flip();\n-\n-        return buffer;\n-    }\n-\n-    public static AbstractResponse deserializeBody(ByteBuffer byteBuffer, RequestHeader header) {\n+    /**\n+     * Parse a response from the provided buffer. The buffer is expected to hold both\n+     * the {@link ResponseHeader} as well as the response payload.\n+     */\n+    public static AbstractResponse parseResponse(ByteBuffer byteBuffer, RequestHeader header) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTc2MDA4Mw==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r521760083", "bodyText": "If it's ok with you, I'd like to address this in a separate patch. The main difference is the presence of the correlation validation logic in NetworkClient, which has been tailored to a subtle case in SaslClientAuthenticator. I think the envelope parsing logic should also be checking the correlationId, but probably not with the same quirky behavior.", "author": "hachikuji", "createdAt": "2020-11-12T01:26:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUzNzYxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTc2MjU2NA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r521762564", "bodyText": "sure. Open a jira as follow-up :)", "author": "chia7712", "createdAt": "2020-11-12T01:35:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUzNzYxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDU0MTU5Mw==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r520541593", "bodyText": "Is it worth wrapping the byte array to a new ByteBufferSend to avoid array coping?", "author": "chia7712", "createdAt": "2020-11-10T12:57:49Z", "path": "clients/src/main/java/org/apache/kafka/common/protocol/SendBuilder.java", "diffHunk": "@@ -0,0 +1,194 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.protocol;\n+\n+import org.apache.kafka.common.network.ByteBufferSend;\n+import org.apache.kafka.common.network.Send;\n+import org.apache.kafka.common.record.BaseRecords;\n+import org.apache.kafka.common.record.MultiRecordsSend;\n+import org.apache.kafka.common.requests.RequestHeader;\n+import org.apache.kafka.common.requests.ResponseHeader;\n+import org.apache.kafka.common.utils.ByteUtils;\n+\n+import java.nio.ByteBuffer;\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+/**\n+ * This class provides a way to build {@link Send} objects for network transmission\n+ * from generated {@link org.apache.kafka.common.protocol.ApiMessage} types without\n+ * allocating new space for \"zero-copy\" fields (see {@link #writeByteBuffer(ByteBuffer)}\n+ * and {@link #writeRecords(BaseRecords)}).\n+ *\n+ * See {@link org.apache.kafka.common.requests.EnvelopeRequest#toSend(String, RequestHeader)}\n+ * for example usage.\n+ */\n+public class SendBuilder implements Writable {\n+    private final Queue<Send> sends = new ArrayDeque<>();\n+    private final ByteBuffer buffer;\n+    private final String destinationId;\n+\n+    SendBuilder(String destinationId, int size) {\n+        this.destinationId = destinationId;\n+        this.buffer = ByteBuffer.allocate(size);\n+        this.buffer.mark();\n+    }\n+\n+    private void flushCurrentBuffer() {\n+        int latestPosition = buffer.position();\n+        buffer.reset();\n+\n+        if (latestPosition > buffer.position()) {\n+            buffer.limit(latestPosition);\n+            addByteBufferSend(buffer.slice());\n+            buffer.position(latestPosition);\n+            buffer.limit(buffer.capacity());\n+            buffer.mark();\n+        }\n+    }\n+\n+    private void addByteBufferSend(ByteBuffer buffer) {\n+        sends.add(new ByteBufferSend(destinationId, buffer));\n+    }\n+\n+    @Override\n+    public void writeByte(byte val) {\n+        buffer.put(val);\n+    }\n+\n+    @Override\n+    public void writeShort(short val) {\n+        buffer.putShort(val);\n+    }\n+\n+    @Override\n+    public void writeInt(int val) {\n+        buffer.putInt(val);\n+    }\n+\n+    @Override\n+    public void writeLong(long val) {\n+        buffer.putLong(val);\n+    }\n+\n+    @Override\n+    public void writeDouble(double val) {\n+        buffer.putDouble(val);\n+    }\n+\n+    @Override\n+    public void writeByteArray(byte[] arr) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0OTgzMg==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r520849832", "bodyText": "I did that in an earlier iteration, but I wasn't sure if the overhead of the ByteBuffer and ByteBufferSend made it a net win in the end. I also thought about adding a heuristic, such as looking for a minimum size. In the end, it seemed simpler to rely on \"zeroCopy\" to let us know when we are likely to get a benefit.", "author": "hachikuji", "createdAt": "2020-11-10T20:20:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDU0MTU5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTAyMDY5OA==", "url": "https://github.com/apache/kafka/pull/9563#discussion_r521020698", "bodyText": "Thanks for your explanation. make sense to me.", "author": "chia7712", "createdAt": "2020-11-11T02:05:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDU0MTU5Mw=="}], "type": "inlineReview"}, {"oid": "d6212fa26412485caad3c60e3996f1e909d5d429", "url": "https://github.com/apache/kafka/commit/d6212fa26412485caad3c60e3996f1e909d5d429", "message": "KAFKA-10684; Avoid additional envelope copies during network transmission", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "3da0bfb5027eff9763236bb7f1a9e4e0692bda14", "url": "https://github.com/apache/kafka/commit/3da0bfb5027eff9763236bb7f1a9e4e0692bda14", "message": "Generalize `SendBuilder` usage to apply to all generated types", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "ef4723e031237b3949192246fc09b2c62e538e07", "url": "https://github.com/apache/kafka/commit/ef4723e031237b3949192246fc09b2c62e538e07", "message": "Add test cases for a couple buffer offset bugs", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "a471979858f7f6a46eef90c0d75f72d48f1d2082", "url": "https://github.com/apache/kafka/commit/a471979858f7f6a46eef90c0d75f72d48f1d2082", "message": "Fix checkstyle and bug in data generator", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "2f25bf1a0c0e0f679953865c4a1e136394e891bf", "url": "https://github.com/apache/kafka/commit/2f25bf1a0c0e0f679953865c4a1e136394e891bf", "message": "Add `SendBuilderTest` and remove unneeded classes", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "749a679384c7f5ed38ba30b2bbb5977c38a2fb6f", "url": "https://github.com/apache/kafka/commit/749a679384c7f5ed38ba30b2bbb5977c38a2fb6f", "message": "Use accumulator pattern for `MessageSize`", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "8f83f0fdcc48836290f10e84a3190569418ef8bf", "url": "https://github.com/apache/kafka/commit/8f83f0fdcc48836290f10e84a3190569418ef8bf", "message": "Rename `MessageSize` to `MessageAccumulator`", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "c1978e1afb42ff04f681f5edcf92226972d33d2c", "url": "https://github.com/apache/kafka/commit/c1978e1afb42ff04f681f5edcf92226972d33d2c", "message": "Set `_sizeBeforeBytes` only for tagged fields", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "84e0fa2708f927f6d236d94598be0072275f8d1e", "url": "https://github.com/apache/kafka/commit/84e0fa2708f927f6d236d94598be0072275f8d1e", "message": "Create `_sizeBeforeArray` only when needed", "committedDate": "2020-11-13T23:23:52Z", "type": "commit"}, {"oid": "ec0a079e123bad5da0305c63342cc62348ad3a01", "url": "https://github.com/apache/kafka/commit/ec0a079e123bad5da0305c63342cc62348ad3a01", "message": "Remove TODO in `MessageDataGenerator`", "committedDate": "2020-11-13T23:24:22Z", "type": "commit"}, {"oid": "ec0a079e123bad5da0305c63342cc62348ad3a01", "url": "https://github.com/apache/kafka/commit/ec0a079e123bad5da0305c63342cc62348ad3a01", "message": "Remove TODO in `MessageDataGenerator`", "committedDate": "2020-11-13T23:24:22Z", "type": "forcePushed"}]}