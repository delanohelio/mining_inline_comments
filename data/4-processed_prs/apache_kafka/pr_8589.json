{"pr_number": 8589, "pr_title": "KAFKA-9146: KIP-571 Add option to force delete active members in StreamsResetter", "pr_createdAt": "2020-04-30T06:38:57Z", "pr_url": "https://github.com/apache/kafka/pull/8589", "timeline": [{"oid": "8f00c6f47659ee4a2d4b3f7c96e4b77f9124bb58", "url": "https://github.com/apache/kafka/commit/8f00c6f47659ee4a2d4b3f7c96e4b77f9124bb58", "message": "Add option to force delete active members in StreamsResetter", "committedDate": "2020-04-30T06:31:32Z", "type": "commit"}, {"oid": "617dcf6574d5bb18299fc5ab8de72cc3245e9a29", "url": "https://github.com/apache/kafka/commit/617dcf6574d5bb18299fc5ab8de72cc3245e9a29", "message": "merge trunk", "committedDate": "2020-04-30T07:29:26Z", "type": "commit"}, {"oid": "e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55", "url": "https://github.com/apache/kafka/commit/e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55", "message": "update", "committedDate": "2020-04-30T09:01:06Z", "type": "commit"}, {"oid": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed", "url": "https://github.com/apache/kafka/commit/c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed", "message": "fix checkstyle violation", "committedDate": "2020-05-01T14:18:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEwODA5NQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r418108095", "bodyText": "could we pass the members into the context?", "author": "abbccdda", "createdAt": "2020-04-30T15:45:14Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3641,37 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        Call findCoordinatorCall;\n+        if (options.removeAll()) {\n+            List<MemberIdentity> members = getMembersFromGroup(groupId);\n+            findCoordinatorCall = getFindCoordinatorCall(context,\n+                () -> getRemoveMembersFromGroupCall(context, members));", "originalCommit": "e02c3c61d758c6180c4f9a9708b6c8e27b6a3c55", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgyNDI3MQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420824271", "bodyText": "My initial thought was to put the members in the context, but hesitated to do so because the ConsumerGroupOperationContext seems to be for generic usage. So I just refer to KafkaAdminClient#getAlterConsumerGroupOffsetsCall and make the members as a separate input param. Anyway, I'm glad to make the change if we think it's preferred to put the members in context.", "author": "feyman2016", "createdAt": "2020-05-06T14:13:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEwODA5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMDQ4Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424510483", "bodyText": "Yes, I feel this is more consistent for internal calls not to do a second round of interpretation for which members set to use.", "author": "abbccdda", "createdAt": "2020-05-13T15:04:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEwODA5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxODU0MA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424518540", "bodyText": "And to be clear, I'm not suggesting we have to put stuff into the context, just always passing in the intended removal list and do not depend on context.removeAll again inside internal function.", "author": "abbccdda", "createdAt": "2020-05-13T15:14:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEwODA5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMzOTU5Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420339593", "bodyText": "Remove print statements", "author": "abbccdda", "createdAt": "2020-05-05T19:03:29Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,27 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members = new ArrayList<>();\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            System.out.println(\"Encounter exception when trying to get members from group: \" + groupId);", "originalCommit": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgyNDU3Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420824572", "bodyText": "Fixed~", "author": "feyman2016", "createdAt": "2020-05-06T14:13:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMzOTU5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MDIxMQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420340211", "bodyText": "Curious why we are still continuing in this case, as the member lookup already fails.", "author": "abbccdda", "createdAt": "2020-05-05T19:04:30Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,27 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members = new ArrayList<>();\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            System.out.println(\"Encounter exception when trying to get members from group: \" + groupId);\n+            ex.printStackTrace();", "originalCommit": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg0ODIyMw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420848223", "bodyText": "Thanks, will fix this .", "author": "feyman2016", "createdAt": "2020-05-06T14:43:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MDIxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxNjYxNw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r421216617", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-07T03:24:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MDIxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MTg5NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420341894", "bodyText": "Could we just make members to be Optional<Set<MemberToRemove>> so that we don't need a separate removeAll parameter?", "author": "abbccdda", "createdAt": "2020-05-05T19:07:17Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -32,12 +32,23 @@\n public class RemoveMembersFromConsumerGroupOptions extends AbstractOptions<RemoveMembersFromConsumerGroupOptions> {\n \n     private Set<MemberToRemove> members;", "originalCommit": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgwNjIzMg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420806232", "bodyText": "Sure. Taking a step further, can we just keep the the type Set<MemberToRemove> for members unchanged and treat it as removeAll if the members is empty set?", "author": "feyman2016", "createdAt": "2020-05-06T13:50:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MTg5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxNjc0Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r421216746", "bodyText": "Updated~", "author": "feyman2016", "createdAt": "2020-05-07T03:24:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MTg5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0NDk0Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420344946", "bodyText": "style error here.\nI would recommend doing a self style check like:\n./gradlew checkstyleMain checkstyleTest spotbugsMain spotbugsTest spotbugsScoverage compileTestJava otherwise we still need to fix those failures after we do jenkins build.", "author": "abbccdda", "createdAt": "2020-05-05T19:12:50Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,27 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members = new ArrayList<>();\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            System.out.println(\"Encounter exception when trying to get members from group: \" + groupId);\n+            ex.printStackTrace();\n+        }\n+\n+        List<MemberIdentity> memberToRemove = new ArrayList<>();\n+        for (MemberDescription member: members) {", "originalCommit": "c6b4ef359c24a57fe6b9e3f5a57b4d4be6a59fed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDU2ODE5MA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r420568190", "bodyText": "Thanks for the advice, will fix it in the next commit.", "author": "feyman2016", "createdAt": "2020-05-06T06:23:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0NDk0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTIxNjk3Nw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r421216977", "bodyText": "I reran the self style check, but didn't capture any error. I assume the error would be the missed final in for loop, updated.", "author": "feyman2016", "createdAt": "2020-05-07T03:25:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0NDk0Ng=="}], "type": "inlineReview"}, {"oid": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "url": "https://github.com/apache/kafka/commit/6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "message": "fix based on comments", "committedDate": "2020-05-07T03:16:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE5ODA1MA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424198050", "bodyText": "nit: space before :", "author": "abbccdda", "createdAt": "2020-05-13T06:23:08Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,26 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members;\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            throw new KafkaException(\"Encounter exception when trying to get members from group: \" + groupId, ex);\n+        }\n+\n+        List<MemberIdentity> memberToRemove = new ArrayList<>();\n+        for (final MemberDescription member: members) {", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4MDgwNQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428580805", "bodyText": "Fixed~", "author": "feyman2016", "createdAt": "2020-05-21T10:50:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE5ODA1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMjk5Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424512993", "bodyText": "nit: remove extra line", "author": "abbccdda", "createdAt": "2020-05-13T15:07:20Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -37,7 +37,16 @@ public RemoveMembersFromConsumerGroupOptions(Collection<MemberToRemove> members)\n         this.members = new HashSet<>(members);\n     }\n \n+    public RemoveMembersFromConsumerGroupOptions() {\n+        this.members = new HashSet<>();\n+    }\n+\n     public Set<MemberToRemove> members() {\n         return members;\n     }\n+\n+    public boolean removeAll() {\n+        return members.isEmpty();\n+    }\n+", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4MTU3Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428581576", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-21T10:52:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxMjk5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNjA1OA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424516058", "bodyText": "Should be Collection.emptyList()", "author": "abbccdda", "createdAt": "2020-05-13T15:11:24Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3640,37 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        Call findCoordinatorCall;\n+        if (options.removeAll()) {\n+            List<MemberIdentity> members = getMembersFromGroup(groupId);\n+            findCoordinatorCall = getFindCoordinatorCall(context,\n+                () -> getRemoveMembersFromGroupCall(context, members));\n+        } else {\n+            findCoordinatorCall = getFindCoordinatorCall(context,\n+                () -> getRemoveMembersFromGroupCall(context, new ArrayList<>()));", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNzU2NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424517564", "bodyText": "Why do we blindly put  allMembers? I believe we base on context to interpret, but like discussed earlier, this is easy to make mistake, we should rely on one source for members.", "author": "abbccdda", "createdAt": "2020-05-13T15:13:24Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3647,7 +3679,7 @@ void handleResponse(AbstractResponse abstractResponse) {\n \n                 // If coordinator changed since we fetched it, retry\n                 if (ConsumerGroupOperationContext.hasCoordinatorMoved(response)) {\n-                    Call call = getRemoveMembersFromGroupCall(context);\n+                    Call call = getRemoveMembersFromGroupCall(context, allMembers);", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4Mzg4Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428583883", "bodyText": "Fixed, now we explicitly pass in the members to be deleted to the private getRemoveMembersFromGroupCall", "author": "feyman2016", "createdAt": "2020-05-21T10:58:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUxNzU2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjA1Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424522056", "bodyText": "Not necessary change", "author": "abbccdda", "createdAt": "2020-05-13T15:19:18Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -41,7 +41,7 @@ import org.apache.kafka.common.requests.{DeleteRecordsRequest, MetadataResponse}\n import org.apache.kafka.common.resource.{PatternType, ResourcePattern, ResourceType}\n import org.apache.kafka.common.utils.{Time, Utils}\n import org.apache.kafka.common.{ConsumerGroupState, ElectionType, TopicPartition, TopicPartitionInfo, TopicPartitionReplica}\n-import org.junit.Assert._\n+import org.junit.Assert.{assertEquals, _}", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4NTEyMA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428585120", "bodyText": "Reverted", "author": "feyman2016", "createdAt": "2020-05-21T11:01:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjA1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjc5Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424522792", "bodyText": "nit: space after EMPTY_GROUP_INSTANCE_ID", "author": "abbccdda", "createdAt": "2020-05-13T15:20:13Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"\n       val fakeGroupId = \"fake_group_id\"\n-      val newConsumerConfig = new Properties(consumerConfig)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n-      newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, testInstanceId)\n-      val consumer = createConsumer(configOverrides = newConsumerConfig)\n-      val latch = new CountDownLatch(1)\n+\n+\n+      def createConsumerByGroupInstanceId(groupInstanceId: String) = {\n+        val newConsumerConfig = new Properties(consumerConfig)\n+        newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n+        newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n+        if (groupInstanceId != EMPTY_GROUP_INSTANCE_ID ) {", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4NTM3Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428585373", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-21T11:01:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyMjc5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNDE0Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424524146", "bodyText": "Could we specify the return type?", "author": "abbccdda", "createdAt": "2020-05-13T15:22:05Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"\n       val fakeGroupId = \"fake_group_id\"\n-      val newConsumerConfig = new Properties(consumerConfig)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n-      newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, testInstanceId)\n-      val consumer = createConsumer(configOverrides = newConsumerConfig)\n-      val latch = new CountDownLatch(1)\n+\n+\n+      def createConsumerByGroupInstanceId(groupInstanceId: String) = {", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4NTYxNw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428585617", "bodyText": "Refactored", "author": "feyman2016", "createdAt": "2020-05-21T11:02:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNDE0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTE3MQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424525171", "bodyText": "I don't think we really need this struct, could we just put null in groupInstanceSet?", "author": "abbccdda", "createdAt": "2020-05-13T15:23:22Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4NjczMA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428586730", "bodyText": "I feel like this is more informative, so didn't update it, but yeah, I can update if we really not prefer this~", "author": "feyman2016", "createdAt": "2020-05-21T11:05:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTE3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2NDk3Nw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428764977", "bodyText": "Fair enough", "author": "abbccdda", "createdAt": "2020-05-21T16:24:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTE3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTQzNg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424525436", "bodyText": "nit: space", "author": "abbccdda", "createdAt": "2020-05-13T15:23:44Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"\n       val fakeGroupId = \"fake_group_id\"\n-      val newConsumerConfig = new Properties(consumerConfig)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n-      newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, testInstanceId)\n-      val consumer = createConsumer(configOverrides = newConsumerConfig)\n-      val latch = new CountDownLatch(1)\n+\n+\n+      def createConsumerByGroupInstanceId(groupInstanceId: String) = {\n+        val newConsumerConfig = new Properties(consumerConfig)\n+        newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n+        newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n+        if (groupInstanceId != EMPTY_GROUP_INSTANCE_ID ) {\n+          newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, groupInstanceId)\n+        }\n+        createConsumer(configOverrides = newConsumerConfig)\n+      }\n+\n+      // contains two static members and one dynamic member\n+      val groupInstanceSet = Set(testInstanceId, testInstanceId1, EMPTY_GROUP_INSTANCE_ID)\n+      val consumerSet = groupInstanceSet.map(createConsumerByGroupInstanceId(_))\n+      val topicSet = Set(testTopicName, testTopicName1, testTopicName2)\n+\n+      val latch = new CountDownLatch(consumerSet.size)\n       try {\n-        // Start a consumer in a thread that will subscribe to a new group.\n-        val consumerThread = new Thread {\n-          override def run : Unit = {\n-            consumer.subscribe(Collections.singleton(testTopicName))\n-\n-            try {\n-              while (true) {\n-                consumer.poll(JDuration.ofSeconds(5))\n-                if (!consumer.assignment.isEmpty && latch.getCount > 0L)\n-                  latch.countDown()\n-                consumer.commitSync()\n+        def createConsumerThread[K,V](consumer: KafkaConsumer[K,V], topic: String): Thread = {\n+          new Thread {\n+            override def run : Unit = {\n+              consumer.subscribe(Collections.singleton(topic))\n+              try {\n+                while (true) {\n+                  consumer.poll(JDuration.ofSeconds(5))\n+                  if ( !consumer.assignment.isEmpty && latch.getCount > 0L)", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4NzAxOA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428587018", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-21T11:05:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTQzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTc5OA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424525798", "bodyText": "Why do we suppress here?", "author": "abbccdda", "createdAt": "2020-05-13T15:24:16Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,71 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"\n       val fakeGroupId = \"fake_group_id\"\n-      val newConsumerConfig = new Properties(consumerConfig)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n-      newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n-      newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, testInstanceId)\n-      val consumer = createConsumer(configOverrides = newConsumerConfig)\n-      val latch = new CountDownLatch(1)\n+\n+\n+      def createConsumerByGroupInstanceId(groupInstanceId: String) = {\n+        val newConsumerConfig = new Properties(consumerConfig)\n+        newConsumerConfig.setProperty(ConsumerConfig.GROUP_ID_CONFIG, testGroupId)\n+        newConsumerConfig.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, testClientId)\n+        if (groupInstanceId != EMPTY_GROUP_INSTANCE_ID ) {\n+          newConsumerConfig.setProperty(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, groupInstanceId)\n+        }\n+        createConsumer(configOverrides = newConsumerConfig)\n+      }\n+\n+      // contains two static members and one dynamic member\n+      val groupInstanceSet = Set(testInstanceId, testInstanceId1, EMPTY_GROUP_INSTANCE_ID)\n+      val consumerSet = groupInstanceSet.map(createConsumerByGroupInstanceId(_))\n+      val topicSet = Set(testTopicName, testTopicName1, testTopicName2)\n+\n+      val latch = new CountDownLatch(consumerSet.size)\n       try {\n-        // Start a consumer in a thread that will subscribe to a new group.\n-        val consumerThread = new Thread {\n-          override def run : Unit = {\n-            consumer.subscribe(Collections.singleton(testTopicName))\n-\n-            try {\n-              while (true) {\n-                consumer.poll(JDuration.ofSeconds(5))\n-                if (!consumer.assignment.isEmpty && latch.getCount > 0L)\n-                  latch.countDown()\n-                consumer.commitSync()\n+        def createConsumerThread[K,V](consumer: KafkaConsumer[K,V], topic: String): Thread = {\n+          new Thread {\n+            override def run : Unit = {\n+              consumer.subscribe(Collections.singleton(topic))\n+              try {\n+                while (true) {\n+                  consumer.poll(JDuration.ofSeconds(5))\n+                  if ( !consumer.assignment.isEmpty && latch.getCount > 0L)\n+                    latch.countDown()\n+                  consumer.commitSync()\n+                }\n+              } catch {\n+                case _: InterruptException => // Suppress the output to stderr", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4OTM1MA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428589350", "bodyText": "Didn't change the exception handling logic here, just extract the Thread creation logic to reuse~", "author": "feyman2016", "createdAt": "2020-05-21T11:11:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNTc5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNzAyMQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424527021", "bodyText": "remained -> remaining", "author": "abbccdda", "createdAt": "2020-05-13T15:25:51Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1147,6 +1175,16 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n \n           assertEquals(testGroupId, testGroupDescription.groupId)\n           assertFalse(testGroupDescription.isSimpleConsumerGroup)\n+          assertEquals(consumerSet.size -1, testGroupDescription.members().size())\n+\n+          // Delete all active members remained (a static member + a dynamic member)", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU4ODE3Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428588172", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-21T11:08:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNzAyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyOTc2Nw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r424529767", "bodyText": "Do we also want to edit the usage info on top to mention the force delete option?", "author": "abbccdda", "createdAt": "2020-05-13T15:29:16Z", "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -236,6 +244,8 @@ private void parseArguments(final String[] args) {\n             .withRequiredArg()\n             .ofType(String.class)\n             .describedAs(\"file name\");\n+        forceOption = optionParser.accepts(\"force\", \"Force remove members when long session time out has been configured, \" +", "originalCommit": "6a845f3a6d7a5c51c3619ece9ec5092eea74057c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODU3OTM2MQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428579361", "bodyText": "I think so, updated", "author": "feyman2016", "createdAt": "2020-05-21T10:47:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyOTc2Nw=="}], "type": "inlineReview"}, {"oid": "6b15dedb31214162bef4dd7a5996ae0b5450d240", "url": "https://github.com/apache/kafka/commit/6b15dedb31214162bef4dd7a5996ae0b5450d240", "message": "update based on comments", "committedDate": "2020-05-21T08:03:42Z", "type": "commit"}, {"oid": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "url": "https://github.com/apache/kafka/commit/d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "message": "fix comment", "committedDate": "2020-05-21T11:08:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc0NTUxNw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428745517", "bodyText": "I think we should catch Exception here:\nhttps://stackoverflow.com/questions/2274102/difference-between-using-throwable-and-exception-in-a-try-catch", "author": "abbccdda", "createdAt": "2020-05-21T15:51:55Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,26 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members;\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NzQ5Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429087492", "bodyText": "Make sense, fixed~", "author": "feyman2016", "createdAt": "2020-05-22T07:30:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc0NTUxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc0ODkzOA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428748938", "bodyText": "This indentation is a bit weird, let's just merge L3625-3626", "author": "abbccdda", "createdAt": "2020-05-21T15:56:31Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3612,6 +3611,26 @@ private boolean dependsOnSpecificNode(ConfigResource resource) {\n                 || resource.type() == ConfigResource.Type.BROKER_LOGGER;\n     }\n \n+    private List<MemberIdentity> getMembersFromGroup(String groupId) {\n+        Collection<MemberDescription> members;\n+        try {\n+            members = describeConsumerGroups(Collections.singleton(groupId)).describedGroups().get(groupId).get().members();\n+        } catch (Throwable ex) {\n+            throw new KafkaException(\"Encounter exception when trying to get members from group: \" + groupId, ex);\n+        }\n+\n+        List<MemberIdentity> memberToRemove = new ArrayList<>();\n+        for (final MemberDescription member : members) {\n+            if (member.groupInstanceId().isPresent()) {\n+                memberToRemove.add(new MemberIdentity().setGroupInstanceId(member.groupInstanceId().get())\n+                );", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NzI4Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429087282", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-22T07:29:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc0ODkzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MTA0OQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428751049", "bodyText": "Let's get back the original indentation.", "author": "abbccdda", "createdAt": "2020-05-21T16:00:08Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3640,31 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NzIxNg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429087216", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-22T07:29:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MTA0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MjYwMA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428752600", "bodyText": "nit: we could merge L3666-3667", "author": "abbccdda", "createdAt": "2020-05-21T16:02:44Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3640,31 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n+        List<MemberIdentity> members;\n+        if (options.removeAll()) {\n+            members = getMembersFromGroup(groupId);\n+        } else {\n+            members = options.members().stream().map(\n+                    MemberToRemove::toMemberIdentity).collect(Collectors.toList());\n+        }\n         Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+            () -> getRemoveMembersFromGroupCall(context, members));\n         runnable.call(findCoordinatorCall, startFindCoordinatorMs);\n \n         return new RemoveMembersFromConsumerGroupResult(future, options.members());\n     }\n \n-    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context) {\n+    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>,\n+            RemoveMembersFromConsumerGroupOptions> context, List<MemberIdentity> allMembers) {\n         return new Call(\"leaveGroup\",\n                         context.deadline(),\n                         new ConstantNodeIdProvider(context.node().get().id())) {\n             @Override\n             LeaveGroupRequest.Builder createRequest(int timeoutMs) {\n-                return new LeaveGroupRequest.Builder(context.groupId(),\n-                                                     context.options().members().stream().map(\n-                                                         MemberToRemove::toMemberIdentity).collect(Collectors.toList()));\n+                    return new LeaveGroupRequest.Builder(context.groupId(),", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NzEzMw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429087133", "bodyText": "Updated", "author": "feyman2016", "createdAt": "2020-05-22T07:29:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MjYwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MzAxMg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428753012", "bodyText": "nit: we could name it members now", "author": "abbccdda", "createdAt": "2020-05-21T16:03:26Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3621,24 +3640,31 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         KafkaFutureImpl<Map<MemberIdentity, Errors>> future = new KafkaFutureImpl<>();\n \n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n-            new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n+                new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n+        List<MemberIdentity> members;\n+        if (options.removeAll()) {\n+            members = getMembersFromGroup(groupId);\n+        } else {\n+            members = options.members().stream().map(\n+                    MemberToRemove::toMemberIdentity).collect(Collectors.toList());\n+        }\n         Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+            () -> getRemoveMembersFromGroupCall(context, members));\n         runnable.call(findCoordinatorCall, startFindCoordinatorMs);\n \n         return new RemoveMembersFromConsumerGroupResult(future, options.members());\n     }\n \n-    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context) {\n+    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>,\n+            RemoveMembersFromConsumerGroupOptions> context, List<MemberIdentity> allMembers) {", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NzA1MQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429087051", "bodyText": "Yeah, fixed", "author": "feyman2016", "createdAt": "2020-05-22T07:29:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1MzAxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1NjczOA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428756738", "bodyText": "I could see this doesn't hold true for a plain static member removal. Let's discuss why skipping the individual member check in RemoveMembersFromConsumerGroupResult makes sense over there.", "author": "abbccdda", "createdAt": "2020-05-21T16:09:52Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3660,7 +3686,7 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     // We set member.id to empty here explicitly, so that the lookup will succeed as user doesn't\n                     // know the exact member.id.\n                     memberErrors.put(new MemberIdentity()\n-                                         .setMemberId(JoinGroupRequest.UNKNOWN_MEMBER_ID)\n+                                         .setMemberId(memberResponse.memberId())", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTE0NTE4NQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429145185", "bodyText": "For removing static members, this still true because we put memberId as \"\" in the request, and the server will also response with the same request field. (Verified GroupCoordinator#handleLeaveGroup)\nFor removing dynamic members, we need this change to know the memberId for the caller.\nI suppose the individual check here is just to check the response against the members to be removed(for removeAll scenario)? Previously I thought of putting all members got from KafkaAdminClient#getMembersFromGroup in the RemoveMembersFromConsumerGroupResult for checking, but in removeAll scenario, we get members as  MemberIdentity which cannot be converted back to MemberToRemove, so I'm hesitate to do in this way", "author": "feyman2016", "createdAt": "2020-05-22T09:35:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1NjczOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMjAxMA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430832010", "bodyText": "Not sure if I understand the change. Also not sure if I can follow the comments. Can you elaborate?", "author": "mjsax", "createdAt": "2020-05-27T03:05:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1NjczOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1NzY3Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428757676", "bodyText": "Collections.emptySet() makes more sense since it is immutable.", "author": "abbccdda", "createdAt": "2020-05-21T16:11:25Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -37,7 +37,15 @@ public RemoveMembersFromConsumerGroupOptions(Collection<MemberToRemove> members)\n         this.members = new HashSet<>(members);\n     }\n \n+    public RemoveMembersFromConsumerGroupOptions() {\n+        this.members = new HashSet<>();", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NDc4Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429084786", "bodyText": "Make sense, fixed", "author": "feyman2016", "createdAt": "2020-05-22T07:23:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1NzY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1ODY4MQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428758681", "bodyText": "In removeAll() mode, why could we skip the individual member removal results? I guess although we don't need to verify against the original member list (because they don't exist for removeAll), going throw the sub error list is still valuable to make sure there is no unexpected failure.", "author": "abbccdda", "createdAt": "2020-05-21T16:13:16Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -46,26 +46,42 @@\n      * If not, the first member error shall be returned.\n      */\n     public KafkaFuture<Void> all() {\n-        final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n-        this.future.whenComplete((memberErrors, throwable) -> {\n-            if (throwable != null) {\n-                result.completeExceptionally(throwable);\n-            } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+        if (removeAll()) {", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NjkzMw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429086933", "bodyText": "Yeah, just as you surmised, but you are right, we should scan the removal results as well. Slightly updated, followed the convention of non-removeAll scenario, just return with the first exception", "author": "feyman2016", "createdAt": "2020-05-22T07:28:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1ODY4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1ODc5OA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428758798", "bodyText": "Remove print statement.", "author": "abbccdda", "createdAt": "2020-05-21T16:13:27Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -46,26 +46,42 @@\n      * If not, the first member error shall be returned.\n      */\n     public KafkaFuture<Void> all() {\n-        final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n-        this.future.whenComplete((memberErrors, throwable) -> {\n-            if (throwable != null) {\n-                result.completeExceptionally(throwable);\n-            } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+        if (removeAll()) {\n+            final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n+            this.future.whenComplete((memberErrors, throwable) -> {\n+                if (throwable != null) {\n+                    result.completeExceptionally(throwable);\n+                } else {\n+                    System.out.println(\"Remove all active members succeeded, removed \" + memberErrors.size() + \" members: \" + memberErrors.keySet());", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTEzMzQ0Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429133442", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-22T09:11:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc1ODc5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2MjA0Nw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428762047", "bodyText": "This test looks good, but it seems that we didn't test the case where some members get deleted successfully while some are not?", "author": "abbccdda", "createdAt": "2020-05-21T16:19:03Z", "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -2411,6 +2411,50 @@ public void testRemoveMembersFromGroup() throws Exception {\n             assertNull(noErrorResult.all().get());\n             assertNull(noErrorResult.memberResult(memberOne).get());\n             assertNull(noErrorResult.memberResult(memberTwo).get());\n+\n+            // Return with success for \"removeAll\" scenario", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NDU1OQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429084559", "bodyText": "Good catch! Added the test for partial failure", "author": "feyman2016", "createdAt": "2020-05-22T07:23:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2MjA0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2Mzc4NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428763784", "bodyText": "Should we check the member removal result here before proceeding? If that call failed, the whole operation should fail with error message containing the result IMHO.", "author": "abbccdda", "createdAt": "2020-05-21T16:22:10Z", "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -186,9 +190,15 @@ private void validateNoActiveConsumers(final String groupId,\n         final List<MemberDescription> members =\n             new ArrayList<>(describeResult.describedGroups().get(groupId).get().members());\n         if (!members.isEmpty()) {\n-            throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n-                    + \"and has following members: \" + members + \". \"\n-                    + \"Make sure to stop all running application instances before running the reset tool.\");\n+            if (options.has(forceOption)) {\n+                System.out.println(\"Force deleting all active members in the group: \" + groupId);\n+                adminClient.removeMembersFromConsumerGroup(groupId, new RemoveMembersFromConsumerGroupOptions()).all();", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NDIxOQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429084219", "bodyText": "Agreed, fixed", "author": "feyman2016", "createdAt": "2020-05-22T07:22:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2Mzc4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2Nzc3MQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428767771", "bodyText": "Does this check duplicate L1103? Also I think it makes sense to check all the members' clientId as they should all equal to testClientId", "author": "abbccdda", "createdAt": "2020-05-21T16:28:56Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1075,13 +1098,17 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n \n           assertEquals(testGroupId, testGroupDescription.groupId())\n           assertFalse(testGroupDescription.isSimpleConsumerGroup)\n-          assertEquals(1, testGroupDescription.members().size())\n+          assertEquals(groupInstanceSet.size, testGroupDescription.members().size())\n           val member = testGroupDescription.members().iterator().next()\n           assertEquals(testClientId, member.clientId())\n-          val topicPartitions = member.assignment().topicPartitions()\n-          assertEquals(testNumPartitions, topicPartitions.size())\n-          assertEquals(testNumPartitions, topicPartitions.asScala.\n-            count(tp => tp.topic().equals(testTopicName)))\n+          val members = testGroupDescription.members()\n+          assertEquals(testClientId, members.asScala.head.clientId())", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4Mzk2MA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429083960", "bodyText": "Thanks, all members' clientId are checked now", "author": "feyman2016", "createdAt": "2020-05-22T07:21:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2Nzc3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2OTI1NQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428769255", "bodyText": "I prefer testInstanceIdOne = \"test_instance_id_1\" and testInstanceIdTwo = \"test_instance_id_2\"", "author": "abbccdda", "createdAt": "2020-05-21T16:31:25Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,70 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName1, testNumPartitions, 1.toShort),\n+        new NewTopic(testTopicName2, testNumPartitions, 1.toShort)\n+      )).all().get()\n+      waitForTopics(client, List(testTopicName, testTopicName1, testTopicName2), List())\n \n       val producer = createProducer()\n       try {\n         producer.send(new ProducerRecord(testTopicName, 0, null, null)).get()\n       } finally {\n         Utils.closeQuietly(producer, \"producer\")\n       }\n+\n+      val EMPTY_GROUP_INSTANCE_ID = \"\"\n       val testGroupId = \"test_group_id\"\n       val testClientId = \"test_client_id\"\n       val testInstanceId = \"test_instance_id\"\n+      val testInstanceId1 = testInstanceId + \"1\"", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MzY3NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429083674", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-22T07:21:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2OTI1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDAyOA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428770028", "bodyText": "size - 1", "author": "abbccdda", "createdAt": "2020-05-21T16:32:48Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1147,6 +1174,16 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n \n           assertEquals(testGroupId, testGroupDescription.groupId)\n           assertFalse(testGroupDescription.isSimpleConsumerGroup)\n+          assertEquals(consumerSet.size -1, testGroupDescription.members().size())", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MzYxMQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429083611", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-22T07:20:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDAyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDE3Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428770176", "bodyText": "We could remove this comment for now", "author": "abbccdda", "createdAt": "2020-05-21T16:33:09Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1138,7 +1165,7 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n           val validMemberFuture = removeMembersResult.memberResult(new MemberToRemove(testInstanceId))\n           assertNull(validMemberFuture.get())\n \n-          // The group should contain no member now.\n+          // The group's active members number should decrease by 1", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MzU2NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429083564", "bodyText": "Removed, but curious about the reason :)", "author": "feyman2016", "createdAt": "2020-05-22T07:20:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDE3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDYwMQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428770601", "bodyText": "nit: format\nI'm pretty surprised this wasn't caught in my previous template. Let me check how to cover this in style test as well.", "author": "abbccdda", "createdAt": "2020-05-21T16:33:50Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1155,12 +1192,15 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n \n           assertTrue(deleteResult.deletedGroups().containsKey(testGroupId))\n           assertNull(deleteResult.deletedGroups().get(testGroupId).get())\n-        } finally {\n-          consumerThread.interrupt()\n-          consumerThread.join()\n-        }\n       } finally {\n-        Utils.closeQuietly(consumer, \"consumer\")\n+        consumerThreads.foreach {\n+          case consumerThread =>\n+            consumerThread.interrupt()\n+            consumerThread.join()\n+        }\n+      }\n+      }finally {", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjQ4Nw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429082487", "bodyText": "Thanks, but I wonder what does the template refer to here?", "author": "feyman2016", "createdAt": "2020-05-22T07:18:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MDYwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MTM0Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428771346", "bodyText": "What does \"\" +  mean?", "author": "abbccdda", "createdAt": "2020-05-21T16:35:08Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -261,6 +261,43 @@ public void shouldNotAllowToResetWhenIntermediateTopicAbsent() throws Exception\n         Assert.assertEquals(1, exitCode);\n     }\n \n+    public void testResetWhenLongSessionTimeoutConfiguredWithForceOption() throws Exception {\n+        appID = testId + \"-with-force-option\";\n+        streamsConfig.put(StreamsConfig.APPLICATION_ID_CONFIG, appID);\n+        streamsConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + STREAMS_CONSUMER_TIMEOUT * 100);", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjAzOA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429082038", "bodyText": "Without the \"\" + to convert the value to String, we will get exception like: it is because STREAMS_CONSUMER_TIMEOUT = 2000L, \"\"+ is widely used in this test, just follow it here without any change to not enlarge the scope of this PR, I can help to create a Jira to enhance it if we think this workaround is not quite intuitive~\norg.apache.kafka.common.config.ConfigException: Invalid value 200000 for configuration session.timeout.ms: Expected value to be a 32-bit integer, but it was a java.lang.Long\n        at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:672)\n        at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:474)\n        at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:467)\n        at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:108)\n        at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:129)\n        at org.apache.kafka.clients.consumer.ConsumerConfig.<init>(ConsumerConfig.java:606)\n        at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:630)\n        at org.apache.kafka.streams.processor.internals.DefaultKafkaClientSupplier.getRestoreConsumer(DefaultKafkaClientSupplier.java:56)\n        at org.apache.kafka.streams.processor.internals.StreamThread.create(StreamThread.java:313)\n        at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:766)\n        at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:652)\n        at org.apache.kafka.streams.KafkaStreams.<init>(KafkaStreams.java:562)\n        at org.apache.kafka.streams.integration.AbstractResetIntegrationTest.testResetWhenLongSessionTimeoutConfiguredWithForceOption(AbstractResetIntegrationTest.java:270)\n        at org.apache.kafka.streams.integration.ResetIntegrationTest.testResetWhenLongSessionTimeoutConfiguredWithForceOption(ResetIntegrationTest.java:77)", "author": "feyman2016", "createdAt": "2020-05-22T07:16:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MTM0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzODAyNQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429338025", "bodyText": "I see, this is indeed weird, please file a JIRA so that we could clean in a follow-up PR if others feel the same way.", "author": "abbccdda", "createdAt": "2020-05-22T16:20:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MTM0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNzE4OQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429507189", "bodyText": "Created https://issues.apache.org/jira/browse/KAFKA-10035 for tracking, thanks!", "author": "feyman2016", "createdAt": "2020-05-23T02:44:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MTM0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MjA4OQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428772089", "bodyText": "nit: parameters are not aligned.", "author": "abbccdda", "createdAt": "2020-05-21T16:36:25Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -507,7 +544,7 @@ private Topology setupTopologyWithoutIntermediateUserTopic() {\n         return builder.build();\n     }\n \n-    private void cleanGlobal(final boolean withIntermediateTopics,\n+    private int tryCleanGlobal(final boolean withIntermediateTopics,\n                              final String resetScenario,", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA3MTIzMg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429071232", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-22T06:46:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MjA4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MjkzNg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428772936", "bodyText": "Like said earlier, I think we could just return\nreturn new StreamsResetter().run(parameters, cleanUpConfig) == 0", "author": "abbccdda", "createdAt": "2020-05-21T16:37:52Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -547,6 +584,13 @@ private void cleanGlobal(final boolean withIntermediateTopics,\n         cleanUpConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + CLEANUP_CONSUMER_TIMEOUT);\n \n         final int exitCode = new StreamsResetter().run(parameters, cleanUpConfig);\n+        return exitCode;", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA3MDQxMQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429070411", "bodyText": "Updated", "author": "feyman2016", "createdAt": "2020-05-22T06:43:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MjkzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MzE3Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r428773173", "bodyText": "We could add meta comment for the return value here, and instead of returning an exit code, I feel a boolean is suffice to indicate whether the clean operation was successful or not.", "author": "abbccdda", "createdAt": "2020-05-21T16:38:16Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -507,7 +544,7 @@ private Topology setupTopologyWithoutIntermediateUserTopic() {\n         return builder.build();\n     }\n \n-    private void cleanGlobal(final boolean withIntermediateTopics,\n+    private int tryCleanGlobal(final boolean withIntermediateTopics,", "originalCommit": "d43ce29e4b8d7dbd1616e8a1d76852d516efdaca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA3MDMxOQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429070319", "bodyText": "Indeed, updated as suggested", "author": "feyman2016", "createdAt": "2020-05-22T06:43:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc3MzE3Mw=="}], "type": "inlineReview"}, {"oid": "1853cfe65f0a2c638ea179ea445b146b3ecdde16", "url": "https://github.com/apache/kafka/commit/1853cfe65f0a2c638ea179ea445b146b3ecdde16", "message": "fix more comments", "committedDate": "2020-05-22T06:41:59Z", "type": "commit"}, {"oid": "d88ad3303f050162b51052804ffa5fc2bf935704", "url": "https://github.com/apache/kafka/commit/d88ad3303f050162b51052804ffa5fc2bf935704", "message": "enhance exception handling", "committedDate": "2020-05-22T08:52:28Z", "type": "commit"}, {"oid": "4764677591858a1a0bf6a70e8597d0a885e3e265", "url": "https://github.com/apache/kafka/commit/4764677591858a1a0bf6a70e8597d0a885e3e265", "message": "fix test", "committedDate": "2020-05-22T10:54:33Z", "type": "commit"}, {"oid": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "url": "https://github.com/apache/kafka/commit/eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "message": "fix format", "committedDate": "2020-05-22T14:19:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTI3NjYwMA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429276600", "bodyText": "Wrap to let the failed member info available for caller like StreamsResetter. Only capture the first found member error like in the non removeAll scenario.", "author": "feyman2016", "createdAt": "2020-05-22T14:22:23Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -51,9 +52,21 @@\n             if (throwable != null) {\n                 result.completeExceptionally(throwable);\n             } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+                if (removeAll()) {\n+                    for (Map.Entry<MemberIdentity, Errors> entry: memberErrors.entrySet()) {\n+                        Exception exception = entry.getValue().exception();\n+                        if (exception != null) {\n+                            Throwable ex = new KafkaException(\"Encounter exception when trying to remove: \"", "originalCommit": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyOTMxMw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429329313", "bodyText": "nit: extra semi-colon", "author": "abbccdda", "createdAt": "2020-05-22T15:57:04Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -37,7 +38,15 @@ public RemoveMembersFromConsumerGroupOptions(Collection<MemberToRemove> members)\n         this.members = new HashSet<>(members);\n     }\n \n+    public RemoveMembersFromConsumerGroupOptions() {\n+        this.members = Collections.emptySet();;", "originalCommit": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzE5OQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429333199", "bodyText": "Let's put the exception in the cause so that we could verify the cause in KafkaAdminClientTest, as:\nif (exception != null) {\n  result.completeExceptionally(new KafkaException(\n \"Encounter exception when trying to remove: \" + entry.getKey(), exception));\n  return;\n}", "author": "abbccdda", "createdAt": "2020-05-22T16:11:06Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -51,9 +52,21 @@\n             if (throwable != null) {\n                 result.completeExceptionally(throwable);\n             } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+                if (removeAll()) {\n+                    for (Map.Entry<MemberIdentity, Errors> entry: memberErrors.entrySet()) {\n+                        Exception exception = entry.getValue().exception();\n+                        if (exception != null) {\n+                            Throwable ex = new KafkaException(\"Encounter exception when trying to remove: \"", "originalCommit": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDE4NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429504184", "bodyText": "Cool, updated", "author": "feyman2016", "createdAt": "2020-05-23T01:57:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzE5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzM1NQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429333355", "bodyText": "nit: we could set \"0\" to JoinGroupRequest.UNKNOWN_MEMBER_ID if we don't want to test it out. Having all members use the same member.id is a bit weird.", "author": "abbccdda", "createdAt": "2020-05-22T16:11:21Z", "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -379,6 +379,22 @@ private static MetadataResponse prepareMetadataResponse(Cluster cluster, Errors\n             MetadataResponse.AUTHORIZED_OPERATIONS_OMITTED);\n     }\n \n+    private static DescribeGroupsResponseData prepareDescribeGroupsResponseData(String groupId, List<String> groupInstances,\n+                                                                                List<TopicPartition> topicPartitions) {\n+        final ByteBuffer memberAssignment = ConsumerProtocol.serializeAssignment(new ConsumerPartitionAssignor.Assignment(topicPartitions));\n+        byte[] memberAssignmentBytes = new byte[memberAssignment.remaining()];\n+        List<DescribedGroupMember> describedGroupMembers = groupInstances.stream().map(groupInstance -> DescribeGroupsResponse.groupMember(\"0\", groupInstance, \"clientId0\", \"clientHost\", memberAssignmentBytes, null)).collect(Collectors.toList());", "originalCommit": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDcyNQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429504725", "bodyText": "Yeah, updated", "author": "feyman2016", "createdAt": "2020-05-23T02:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzM1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzk5OQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429333999", "bodyText": "nit: space after *. Also I feel we could make the context more concrete by:\nWhen long session timeout has been configured, active members could take longer to get expired on the broker thus blocking the reset job to complete. Use the \\\"--force\\\" option could remove those left-over members immediately. Make sure to stop all stream applications when this option is specified to avoid unexpected disruptions.", "author": "abbccdda", "createdAt": "2020-05-22T16:12:30Z", "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -119,7 +122,9 @@\n             + \"* This tool will not clean up the local state on the stream application instances (the persisted \"\n             + \"stores used to cache aggregation results).\\n\"\n             + \"You need to call KafkaStreams#cleanUp() in your application or manually delete them from the \"\n-            + \"directory specified by \\\"state.dir\\\" configuration (/tmp/kafka-streams/<application.id> by default).\\n\\n\"\n+            + \"directory specified by \\\"state.dir\\\" configuration (/tmp/kafka-streams/<application.id> by default).\\n\"\n+            + \"*Please use the \\\"--force\\\" option to force remove active members in case long session \"", "originalCommit": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDcwNQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429504705", "bodyText": "Indeed, updated", "author": "feyman2016", "createdAt": "2020-05-23T02:04:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzMzk5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQwNDAwNA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429404004", "bodyText": "This is no longer used.", "author": "abbccdda", "createdAt": "2020-05-22T18:50:06Z", "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -27,10 +27,12 @@\n import org.apache.kafka.clients.admin.DescribeConsumerGroupsOptions;\n import org.apache.kafka.clients.admin.DescribeConsumerGroupsResult;\n import org.apache.kafka.clients.admin.MemberDescription;\n+import org.apache.kafka.clients.admin.RemoveMembersFromConsumerGroupOptions;\n import org.apache.kafka.clients.consumer.Consumer;\n import org.apache.kafka.clients.consumer.ConsumerConfig;\n import org.apache.kafka.clients.consumer.KafkaConsumer;\n import org.apache.kafka.clients.consumer.OffsetAndTimestamp;\n+import org.apache.kafka.common.KafkaException;", "originalCommit": "eb50b5d1d8d6b980b7c635645f6372dc275fc01b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDYwMA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429504600", "bodyText": "Removed", "author": "feyman2016", "createdAt": "2020-05-23T02:02:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQwNDAwNA=="}], "type": "inlineReview"}, {"oid": "91c81b6e4e2a0001e74c929087550e428b06dfa2", "url": "https://github.com/apache/kafka/commit/91c81b6e4e2a0001e74c929087550e428b06dfa2", "message": "fix comments", "committedDate": "2020-05-23T01:54:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwNDUzMg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r429504532", "bodyText": "No existing help method to assert the cause of exception throw by all(). Also I think it's more straight forward in this way.", "author": "feyman2016", "createdAt": "2020-05-23T02:01:24Z", "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -2411,6 +2429,57 @@ public void testRemoveMembersFromGroup() throws Exception {\n             assertNull(noErrorResult.all().get());\n             assertNull(noErrorResult.memberResult(memberOne).get());\n             assertNull(noErrorResult.memberResult(memberTwo).get());\n+\n+            // Test the \"removeAll\" scenario\n+            TopicPartition myTopicPartition0 = new TopicPartition(\"my_topic\", 0);\n+            TopicPartition myTopicPartition1 = new TopicPartition(\"my_topic\", 1);\n+            TopicPartition myTopicPartition2 = new TopicPartition(\"my_topic\", 2);\n+\n+            final List<TopicPartition> topicPartitions = new ArrayList<>();\n+            topicPartitions.add(0, myTopicPartition0);\n+            topicPartitions.add(1, myTopicPartition1);\n+            topicPartitions.add(2, myTopicPartition2);\n+\n+            // construct the DescribeGroupsResponse\n+            DescribeGroupsResponseData data = prepareDescribeGroupsResponseData(groupId, Arrays.asList(instanceOne, instanceTwo), topicPartitions);\n+\n+            // Return with partial failure for \"removeAll\" scenario\n+            // 1 prepare response for AdminClient.describeConsumerGroups\n+            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n+            env.kafkaClient().prepareResponse(new DescribeGroupsResponse(data));\n+\n+            // 2 KafkaAdminClient encounter partial failure when trying to delete all members\n+            env.kafkaClient().prepareResponse(prepareFindCoordinatorResponse(Errors.NONE, env.cluster().controller()));\n+            env.kafkaClient().prepareResponse(new LeaveGroupResponse(\n+                    new LeaveGroupResponseData().setErrorCode(Errors.NONE.code()).setMembers(\n+                            Arrays.asList(responseOne, responseTwo))\n+            ));\n+            final RemoveMembersFromConsumerGroupResult partialFailureResults = env.adminClient().removeMembersFromConsumerGroup(\n+                    groupId,\n+                    new RemoveMembersFromConsumerGroupOptions()\n+            );\n+            ExecutionException exception = assertThrows(ExecutionException.class, () -> partialFailureResults.all().get());", "originalCommit": "91c81b6e4e2a0001e74c929087550e428b06dfa2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "url": "https://github.com/apache/kafka/commit/6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "message": "fix style violation", "committedDate": "2020-05-23T05:47:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyNjY0Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430826643", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    \"Try set '--force' in the cmdline to force delete active members.\");\n          \n          \n            \n                                    + \" You can use option '--force' to remove active members from the group.\");", "author": "mjsax", "createdAt": "2020-05-27T02:43:18Z", "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -186,9 +192,19 @@ private void validateNoActiveConsumers(final String groupId,\n         final List<MemberDescription> members =\n             new ArrayList<>(describeResult.describedGroups().get(groupId).get().members());\n         if (!members.isEmpty()) {\n-            throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n-                    + \"and has following members: \" + members + \". \"\n-                    + \"Make sure to stop all running application instances before running the reset tool.\");\n+            if (options.has(forceOption)) {\n+                System.out.println(\"Force deleting all active members in the group: \" + groupId);\n+                try {\n+                    adminClient.removeMembersFromConsumerGroup(groupId, new RemoveMembersFromConsumerGroupOptions()).all().get();\n+                } catch (Exception e) {\n+                    throw e;\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n+                        + \"and has following members: \" + members + \". \"\n+                        + \"Make sure to stop all running application instances before running the reset tool.\" +\n+                        \"Try set '--force' in the cmdline to force delete active members.\");", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyNjc2Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430826763", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    + \"Make sure to stop all running application instances before running the reset tool.\" +\n          \n          \n            \n                                    + \"Make sure to stop all running application instances before running the reset tool.\"", "author": "mjsax", "createdAt": "2020-05-27T02:43:48Z", "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -186,9 +192,19 @@ private void validateNoActiveConsumers(final String groupId,\n         final List<MemberDescription> members =\n             new ArrayList<>(describeResult.describedGroups().get(groupId).get().members());\n         if (!members.isEmpty()) {\n-            throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n-                    + \"and has following members: \" + members + \". \"\n-                    + \"Make sure to stop all running application instances before running the reset tool.\");\n+            if (options.has(forceOption)) {\n+                System.out.println(\"Force deleting all active members in the group: \" + groupId);\n+                try {\n+                    adminClient.removeMembersFromConsumerGroup(groupId, new RemoveMembersFromConsumerGroupOptions()).all().get();\n+                } catch (Exception e) {\n+                    throw e;\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Consumer group '\" + groupId + \"' is still active \"\n+                        + \"and has following members: \" + members + \". \"\n+                        + \"Make sure to stop all running application instances before running the reset tool.\" +", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyNzA2NQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430827065", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    forceOption = optionParser.accepts(\"force\", \"Force remove members when long session time out has been configured, \" +\n          \n          \n            \n                    forceOption = optionParser.accepts(\"force\", \"Force the removal of members of the consumer group (intended to remove stopped members if a long session timeout was used). \" +", "author": "mjsax", "createdAt": "2020-05-27T02:45:05Z", "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -236,6 +252,8 @@ private void parseArguments(final String[] args) {\n             .withRequiredArg()\n             .ofType(String.class)\n             .describedAs(\"file name\");\n+        forceOption = optionParser.accepts(\"force\", \"Force remove members when long session time out has been configured, \" +", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyNzE2NQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430827165", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"please make sure to shut down all stream applications when this option is specified to avoid unexpected rebalances.\");\n          \n          \n            \n                            \"Make sure to shut down all stream applications when this option is specified to avoid unexpected rebalances.\");", "author": "mjsax", "createdAt": "2020-05-27T02:45:32Z", "path": "core/src/main/scala/kafka/tools/StreamsResetter.java", "diffHunk": "@@ -236,6 +252,8 @@ private void parseArguments(final String[] args) {\n             .withRequiredArg()\n             .ofType(String.class)\n             .describedAs(\"file name\");\n+        forceOption = optionParser.accepts(\"force\", \"Force remove members when long session time out has been configured, \" +\n+                \"please make sure to shut down all stream applications when this option is specified to avoid unexpected rebalances.\");", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODY2Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430828662", "bodyText": "Why do we need this part? Seems sufficient to end the test here?", "author": "mjsax", "createdAt": "2020-05-27T02:51:46Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -261,6 +261,42 @@ public void shouldNotAllowToResetWhenIntermediateTopicAbsent() throws Exception\n         Assert.assertEquals(1, exitCode);\n     }\n \n+    public void testResetWhenLongSessionTimeoutConfiguredWithForceOption() throws Exception {\n+        appID = testId + \"-with-force-option\";\n+        streamsConfig.put(StreamsConfig.APPLICATION_ID_CONFIG, appID);\n+        streamsConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + STREAMS_CONSUMER_TIMEOUT * 100);\n+\n+        // Run\n+        streams = new KafkaStreams(setupTopologyWithoutIntermediateUserTopic(), streamsConfig);\n+        streams.start();\n+        final List<KeyValue<Long, Long>> result = IntegrationTestUtils.waitUntilMinKeyValueRecordsReceived(resultConsumerConfig, OUTPUT_TOPIC, 10);\n+\n+        streams.close();\n+\n+        // RESET\n+        streams = new KafkaStreams(setupTopologyWithoutIntermediateUserTopic(), streamsConfig);\n+        streams.cleanUp();\n+\n+        // Reset would fail since long session timeout has been configured\n+        final boolean cleanResult = tryCleanGlobal(false, null, null);\n+        Assert.assertEquals(false, cleanResult);\n+\n+        // Reset will success with --force, it will force delete active members on broker side\n+        cleanGlobal(false, \"--force\", null);\n+\n+        waitForEmptyConsumerGroup(adminClient, appID, TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT);\n+\n+        assertInternalTopicsGotDeleted(null);\n+\n+        // RE-RUN", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI0NzE2OQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431247169", "bodyText": "This is to verify that after the successfully force removal of active members, the stream application re-run can send exactly the same records again to the output topics", "author": "feyman2016", "createdAt": "2020-05-27T15:48:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODY2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMyMjU2MA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431322560", "bodyText": "Seems redundant as tested somewhere else. And the purpose of the test is to verify --force itself. This additional checks have nothing to do with --force IMHO. It seems best to keep test to a \"minimum\".", "author": "mjsax", "createdAt": "2020-05-27T17:37:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODY2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1Mjc4OA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431352788", "bodyText": "Yeah, I totally agree with: It seems best to keep test to a \"minimum\".\nNot sure if my understanding is correct, but I still think the tests for resetter should compare the first run and re-run results, from the test's perspective, it cannot assume that --force option won't do something underneath that make the re-run produce different results.\nBut I'm ok to remove the RE-RUN part if we do think it's redundant.", "author": "feyman2016", "createdAt": "2020-05-27T18:23:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODY2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1NTU3Mw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431355573", "bodyText": "Fair enough. Let's leave it as-is.", "author": "mjsax", "createdAt": "2020-05-27T18:28:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODY2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODkzMw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430828933", "bodyText": "With cleanGlobal and --force the consumer group could be empty when cleanGlobal returns, right? Hence, we should do this assertion without timeout or retries?", "author": "mjsax", "createdAt": "2020-05-27T02:52:49Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/AbstractResetIntegrationTest.java", "diffHunk": "@@ -261,6 +261,42 @@ public void shouldNotAllowToResetWhenIntermediateTopicAbsent() throws Exception\n         Assert.assertEquals(1, exitCode);\n     }\n \n+    public void testResetWhenLongSessionTimeoutConfiguredWithForceOption() throws Exception {\n+        appID = testId + \"-with-force-option\";\n+        streamsConfig.put(StreamsConfig.APPLICATION_ID_CONFIG, appID);\n+        streamsConfig.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, \"\" + STREAMS_CONSUMER_TIMEOUT * 100);\n+\n+        // Run\n+        streams = new KafkaStreams(setupTopologyWithoutIntermediateUserTopic(), streamsConfig);\n+        streams.start();\n+        final List<KeyValue<Long, Long>> result = IntegrationTestUtils.waitUntilMinKeyValueRecordsReceived(resultConsumerConfig, OUTPUT_TOPIC, 10);\n+\n+        streams.close();\n+\n+        // RESET\n+        streams = new KafkaStreams(setupTopologyWithoutIntermediateUserTopic(), streamsConfig);\n+        streams.cleanUp();\n+\n+        // Reset would fail since long session timeout has been configured\n+        final boolean cleanResult = tryCleanGlobal(false, null, null);\n+        Assert.assertEquals(false, cleanResult);\n+\n+        // Reset will success with --force, it will force delete active members on broker side\n+        cleanGlobal(false, \"--force\", null);\n+\n+        waitForEmptyConsumerGroup(adminClient, appID, TIMEOUT_MULTIPLIER * CLEANUP_CONSUMER_TIMEOUT);", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM0MTczMQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431341731", "bodyText": "Yes, updated", "author": "feyman2016", "createdAt": "2020-05-27T18:04:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgyODkzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMDg0MA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430830840", "bodyText": "If option.members() is empty, it implies that we do a removeAll() -- hence, should we pass in members into the RemoveMembersFromConsumerGroupResult instead of options.members() ?", "author": "mjsax", "createdAt": "2020-05-27T03:00:33Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3623,22 +3641,26 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n             new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        List<MemberIdentity> members;\n+        if (options.removeAll()) {\n+            members = getMembersFromGroup(groupId);\n+        } else {\n+            members = options.members().stream().map(MemberToRemove::toMemberIdentity).collect(Collectors.toList());\n+        }\n+        Call findCoordinatorCall = getFindCoordinatorCall(context, () -> getRemoveMembersFromGroupCall(context, members));\n         runnable.call(findCoordinatorCall, startFindCoordinatorMs);\n \n         return new RemoveMembersFromConsumerGroupResult(future, options.members());", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI2NjYyOQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431266629", "bodyText": "--- If option.members() is empty, it implies that we do a removeAll()\n=> Yes, that is correct.\n--- hence, should we pass in members into the RemoveMembersFromConsumerGroupResult instead of options.members()\n=> The members is of type List<MemberIdentity> and MemberIdentity contains field: memberId which supports the removal of dynamic members, while options.members() is of type: Set<MemberToRemove>, MemberToRemove only supports static member removal specification, in RemoveMembersFromConsumerGroupResult we treat similarly like in RemoveMembersFromConsumerGroupOptions, empty members implies removeAll,\nwe handle it in this way because we think in non removeAll scenario we would only remove static members, while in removeAll scenario we may remove both static and dynamic members.", "author": "feyman2016", "createdAt": "2020-05-27T16:11:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMDg0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMyMzM1MA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431323350", "bodyText": "Thanks for clarifying.", "author": "mjsax", "createdAt": "2020-05-27T17:38:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMDg0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMTAzMw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430831033", "bodyText": "nit: fix formatting:\nprivate Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context,\n                                           List<MemberIdentity> members) {", "author": "mjsax", "createdAt": "2020-05-27T03:01:24Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3623,22 +3641,26 @@ public RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroup(Strin\n         ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context =\n             new ConsumerGroupOperationContext<>(groupId, options, deadline, future);\n \n-        Call findCoordinatorCall = getFindCoordinatorCall(context,\n-            () -> getRemoveMembersFromGroupCall(context));\n+        List<MemberIdentity> members;\n+        if (options.removeAll()) {\n+            members = getMembersFromGroup(groupId);\n+        } else {\n+            members = options.members().stream().map(MemberToRemove::toMemberIdentity).collect(Collectors.toList());\n+        }\n+        Call findCoordinatorCall = getFindCoordinatorCall(context, () -> getRemoveMembersFromGroupCall(context, members));\n         runnable.call(findCoordinatorCall, startFindCoordinatorMs);\n \n         return new RemoveMembersFromConsumerGroupResult(future, options.members());\n     }\n \n-    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>, RemoveMembersFromConsumerGroupOptions> context) {\n+    private Call getRemoveMembersFromGroupCall(ConsumerGroupOperationContext<Map<MemberIdentity, Errors>,\n+            RemoveMembersFromConsumerGroupOptions> context, List<MemberIdentity> members) {", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMxMjQ2Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431312462", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-27T17:20:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMTAzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMjQyMw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430832423", "bodyText": "As we have different semantics for an empty collection (it was \"remove nothing\" originally, and we change it to \"remove all\"), I am wondering if we should do a check if members is empty or not and throw an exception if empty? Or at least log a WARNING that empty implies \"remove all\" now?", "author": "mjsax", "createdAt": "2020-05-27T03:07:09Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupOptions.java", "diffHunk": "@@ -37,7 +38,15 @@ public RemoveMembersFromConsumerGroupOptions(Collection<MemberToRemove> members)\n         this.members = new HashSet<>(members);", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMxMzA3NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431313074", "bodyText": "Make sense. It will throw exception if empty members provided now.", "author": "feyman2016", "createdAt": "2020-05-27T17:21:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMjQyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzUyMA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430833520", "bodyText": "Not sure why the removeAll() case needs to be handled differently? Can you elaborate?", "author": "mjsax", "createdAt": "2020-05-27T03:12:09Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -51,9 +52,21 @@\n             if (throwable != null) {\n                 result.completeExceptionally(throwable);\n             } else {\n-                for (MemberToRemove memberToRemove : memberInfos) {\n-                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n-                        return;\n+                if (removeAll()) {", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMwMjM1Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431302352", "bodyText": "Because in non removeAll scenario, we have put the members to be deleted in the RemoveMembersFromConsumerGroupResult#memberInfos, while in the removeAll scenario, we don't do so(members to be deleted are decided in the private method: KafkaAdminClient#getMembersFromGroup of KafkaAdminClient).", "author": "feyman2016", "createdAt": "2020-05-27T17:02:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzUyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMyNzI2NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431327264", "bodyText": "Well, while memberInfo is empty for the removeAll case, I am still wondering if the code for removeAll would not work for the other case, too?", "author": "mjsax", "createdAt": "2020-05-27T17:45:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzUyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM0NTQ2Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431345466", "bodyText": "I'm not sure I understand the question, could you elaborate more?", "author": "feyman2016", "createdAt": "2020-05-27T18:10:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzUyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1NDI4NA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431354284", "bodyText": "Can we just do for both cases?\nfor (Map.Entry<MemberIdentity, Errors> entry: memberErrors.entrySet()) {\n    Exception exception = entry.getValue().exception();\n    if (exception != null) {\n        Throwable ex = new KafkaException(\"Encounter exception when trying to remove: \"\n             + entry.getKey(), exception);\n        result.completeExceptionally(ex);\n        return;\n    }\n}\n\nThe \"issue\" with using memberInfos is, that for the removeAll() case it's empty and we cannot use it. However, memberErrors should have an entry for all members for both cases?", "author": "mjsax", "createdAt": "2020-05-27T18:26:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzUyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM3MjAyNA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431372024", "bodyText": "I'm afraid not because, in the non removeAll scenario, caller specify the members(memberInfos) to be deleted, and according to maybeCompleteExceptionally, the memberInfos is used because it might sometimes happen that certain member in memberInfos cannot be found in memberErrors , that's the reason I didn't use the removeAll logic for all cases.", "author": "feyman2016", "createdAt": "2020-05-27T18:58:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzUyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM3MzYyMQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431373621", "bodyText": "Thanks for explaining!", "author": "mjsax", "createdAt": "2020-05-27T19:00:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzUyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzkyOA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430833928", "bodyText": "Why that? I understand that we expect that users don't know the memberId if the so a \"remove all\"; however, I don't see why we need to disallow this call? Can you elaborate?", "author": "mjsax", "createdAt": "2020-05-27T03:13:55Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/RemoveMembersFromConsumerGroupResult.java", "diffHunk": "@@ -66,6 +79,9 @@\n      * Returns the selected member future.\n      */\n     public KafkaFuture<Void> memberResult(MemberToRemove member) {\n+        if (removeAll()) {\n+            throw new IllegalArgumentException(\"The method: memberResult is not applicable in 'removeAll' mode\");", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMwNTc5NQ==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431305795", "bodyText": "Since in the removeAll scenario, we don't save the members to be deleted in RemoveMembersFromConsumerGroupResult,  so I think calling memberResult doesn't seem applicative.", "author": "feyman2016", "createdAt": "2020-05-27T17:08:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzkyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMyOTE1OA==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431329158", "bodyText": "I see. Makes sense.", "author": "mjsax", "createdAt": "2020-05-27T17:48:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMzkyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzNDIwMw==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430834203", "bodyText": "Nit: formatting\nprivate static DescribeGroupsResponseData prepareDescribeGroupsResponseData(String groupId,\n                                                                            List<String> groupInstances,\n                                                                            List<TopicPartition> topicPartitions) {", "author": "mjsax", "createdAt": "2020-05-27T03:15:16Z", "path": "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java", "diffHunk": "@@ -379,6 +380,22 @@ private static MetadataResponse prepareMetadataResponse(Cluster cluster, Errors\n             MetadataResponse.AUTHORIZED_OPERATIONS_OMITTED);\n     }\n \n+    private static DescribeGroupsResponseData prepareDescribeGroupsResponseData(String groupId, List<String> groupInstances,", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMxMzIzNg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431313236", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-27T17:21:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzNDIwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzNTY1Ng==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r430835656", "bodyText": "nit: formatting: move new NewTopic(...) to next line", "author": "mjsax", "createdAt": "2020-05-27T03:21:36Z", "path": "core/src/test/scala/integration/kafka/api/PlaintextAdminIntegrationTest.scala", "diffHunk": "@@ -1017,47 +1017,70 @@ class PlaintextAdminIntegrationTest extends BaseAdminIntegrationTest {\n       assertTrue(0 == list1.errors().get().size())\n       assertTrue(0 == list1.valid().get().size())\n       val testTopicName = \"test_topic\"\n+      val testTopicName1 = testTopicName + \"1\"\n+      val testTopicName2 = testTopicName + \"2\"\n       val testNumPartitions = 2\n-      client.createTopics(Collections.singleton(\n-        new NewTopic(testTopicName, testNumPartitions, 1.toShort))).all().get()\n-      waitForTopics(client, List(testTopicName), List())\n+\n+      client.createTopics(util.Arrays.asList(new NewTopic(testTopicName, testNumPartitions, 1.toShort),", "originalCommit": "6c5778ac42e8c3942b2ef693079120cfcf7ab62e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMxMzI0Mg==", "url": "https://github.com/apache/kafka/pull/8589#discussion_r431313242", "bodyText": "Fixed", "author": "feyman2016", "createdAt": "2020-05-27T17:21:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzNTY1Ng=="}], "type": "inlineReview"}, {"oid": "6dedd1cea6f5a16f5713ff8811bf52768f96529d", "url": "https://github.com/apache/kafka/commit/6dedd1cea6f5a16f5713ff8811bf52768f96529d", "message": "Update core/src/main/scala/kafka/tools/StreamsResetter.java\n\nCo-authored-by: Matthias J. Sax <mjsax@apache.org>", "committedDate": "2020-05-27T07:26:33Z", "type": "commit"}, {"oid": "f015c228354519937681c262fb10415aee1101ce", "url": "https://github.com/apache/kafka/commit/f015c228354519937681c262fb10415aee1101ce", "message": "Update core/src/main/scala/kafka/tools/StreamsResetter.java\n\nCo-authored-by: Matthias J. Sax <mjsax@apache.org>", "committedDate": "2020-05-27T07:27:44Z", "type": "commit"}, {"oid": "f92a3f686c37c36bd5958b60e12c12aacf3ad7a8", "url": "https://github.com/apache/kafka/commit/f92a3f686c37c36bd5958b60e12c12aacf3ad7a8", "message": "Update core/src/main/scala/kafka/tools/StreamsResetter.java\n\nCo-authored-by: Matthias J. Sax <mjsax@apache.org>", "committedDate": "2020-05-27T07:28:22Z", "type": "commit"}, {"oid": "87346c04fe275b2e539eb64ef1fc4eb4d95a663e", "url": "https://github.com/apache/kafka/commit/87346c04fe275b2e539eb64ef1fc4eb4d95a663e", "message": "Update core/src/main/scala/kafka/tools/StreamsResetter.java\n\nCo-authored-by: Matthias J. Sax <mjsax@apache.org>", "committedDate": "2020-05-27T07:28:37Z", "type": "commit"}, {"oid": "174ba7edc3b5cfdcdea585a7d12480c27eb562bb", "url": "https://github.com/apache/kafka/commit/174ba7edc3b5cfdcdea585a7d12480c27eb562bb", "message": "fix comments", "committedDate": "2020-05-27T17:18:12Z", "type": "commit"}, {"oid": "5329315b0fba569e0ffd1e3c2d8cbea002a684ba", "url": "https://github.com/apache/kafka/commit/5329315b0fba569e0ffd1e3c2d8cbea002a684ba", "message": "refactor IntegrationTestUtils", "committedDate": "2020-05-27T18:01:09Z", "type": "commit"}]}