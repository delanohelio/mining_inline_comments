{"pr_number": 9626, "pr_title": "KAFKA-10545: Create topic IDs and propagate to brokers", "pr_createdAt": "2020-11-19T23:48:46Z", "pr_url": "https://github.com/apache/kafka/pull/9626", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY0MTY2MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r527641660", "bodyText": "can be changed into topics.contains()", "author": "dengziming", "createdAt": "2020-11-20T11:53:14Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1445,15 +1483,38 @@ class ReplicaManager(val config: KafkaConfig,\n           replicaFetcherManager.shutdownIdleFetcherThreads()\n           replicaAlterLogDirsManager.shutdownIdleFetcherThreads()\n           onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)\n-          val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n-            new LeaderAndIsrPartitionError()\n-              .setTopicName(tp.topic)\n-              .setPartitionIndex(tp.partition)\n-              .setErrorCode(error.code)\n-          }.toBuffer\n-          new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n-            .setErrorCode(Errors.NONE.code)\n-            .setPartitionErrors(responsePartitions.asJava))\n+          if (leaderAndIsrRequest.version() < 4) {\n+            val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n+              new LeaderAndIsrPartitionError()\n+                .setTopicName(tp.topic)\n+                .setPartitionIndex(tp.partition)\n+                .setErrorCode(error.code)\n+            }.toBuffer\n+            new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n+              .setErrorCode(Errors.NONE.code)\n+              .setPartitionErrors(responsePartitions.asJava))\n+          } else {\n+            val topics = new mutable.HashMap[String, List[LeaderAndIsrPartitionError]]\n+            responseMap.asJava.forEach { case (tp, error) =>\n+              if (topics.get(tp.topic) == None) {", "originalCommit": "5999b004f0f3931a4cd004f45a1887067d61dab3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY0MzM4MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r527643380", "bodyText": "Should here be version() < 5 ?", "author": "dengziming", "createdAt": "2020-11-20T11:56:36Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1445,15 +1483,38 @@ class ReplicaManager(val config: KafkaConfig,\n           replicaFetcherManager.shutdownIdleFetcherThreads()\n           replicaAlterLogDirsManager.shutdownIdleFetcherThreads()\n           onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)\n-          val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n-            new LeaderAndIsrPartitionError()\n-              .setTopicName(tp.topic)\n-              .setPartitionIndex(tp.partition)\n-              .setErrorCode(error.code)\n-          }.toBuffer\n-          new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n-            .setErrorCode(Errors.NONE.code)\n-            .setPartitionErrors(responsePartitions.asJava))\n+          if (leaderAndIsrRequest.version() < 4) {", "originalCommit": "5999b004f0f3931a4cd004f45a1887067d61dab3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgxMjc3NA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r527812774", "bodyText": "Good catch. Thanks!", "author": "jolshan", "createdAt": "2020-11-20T16:35:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY0MzM4MA=="}], "type": "inlineReview"}, {"oid": "ef2c75b123de53fe64a8fac43a22565824320c92", "url": "https://github.com/apache/kafka/commit/ef2c75b123de53fe64a8fac43a22565824320c92", "message": "First implementation", "committedDate": "2020-11-20T16:39:20Z", "type": "commit"}, {"oid": "0e0a304f464146f2197b91a83cce37bfb3ae7d16", "url": "https://github.com/apache/kafka/commit/0e0a304f464146f2197b91a83cce37bfb3ae7d16", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516", "committedDate": "2020-11-20T16:39:38Z", "type": "commit"}, {"oid": "12e440b89f4939af6c54fd82fdf1e28db1feeee6", "url": "https://github.com/apache/kafka/commit/12e440b89f4939af6c54fd82fdf1e28db1feeee6", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516", "committedDate": "2020-11-20T16:40:19Z", "type": "commit"}, {"oid": "b6b0796b0539549b2ed20d44d319bb56b777ac8d", "url": "https://github.com/apache/kafka/commit/b6b0796b0539549b2ed20d44d319bb56b777ac8d", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516", "committedDate": "2020-11-20T16:40:31Z", "type": "commit"}, {"oid": "0279e2c1d2fd7a2aca494c710f41621b12db2057", "url": "https://github.com/apache/kafka/commit/0279e2c1d2fd7a2aca494c710f41621b12db2057", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516", "committedDate": "2020-11-20T16:40:38Z", "type": "commit"}, {"oid": "0f0e3272266ccee981e73c7a654677a24fe6ec2f", "url": "https://github.com/apache/kafka/commit/0f0e3272266ccee981e73c7a654677a24fe6ec2f", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516", "committedDate": "2020-11-20T16:40:44Z", "type": "commit"}, {"oid": "7fa1e332e3a983ed96331f75963368aa8199a5d3", "url": "https://github.com/apache/kafka/commit/7fa1e332e3a983ed96331f75963368aa8199a5d3", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516LeaderAndIsr", "committedDate": "2020-11-20T16:40:54Z", "type": "commit"}, {"oid": "37cdd626a41f92725e18098c286735d839e442e6", "url": "https://github.com/apache/kafka/commit/37cdd626a41f92725e18098c286735d839e442e6", "message": "Fixes", "committedDate": "2020-11-20T16:40:55Z", "type": "commit"}, {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8", "url": "https://github.com/apache/kafka/commit/1926bf43e6c1b2f293fa6401847794edde5396b8", "message": "Cleaned up Uuid, merge processes", "committedDate": "2020-11-20T19:08:49Z", "type": "commit"}, {"oid": "1926bf43e6c1b2f293fa6401847794edde5396b8", "url": "https://github.com/apache/kafka/commit/1926bf43e6c1b2f293fa6401847794edde5396b8", "message": "Cleaned up Uuid, merge processes", "committedDate": "2020-11-20T19:08:49Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTkwMDAyNA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r539900024", "bodyText": "nit: is the else statement needed all it has is return?", "author": "rite2nikhil", "createdAt": "2020-12-10T06:41:23Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -58,8 +68,17 @@ public Errors error() {\n         Errors error = error();\n         if (error != Errors.NONE)\n             // Minor optimization since the top-level error applies to all partitions\n-            return Collections.singletonMap(error, data.partitionErrors().size());\n-        return errorCounts(data.partitionErrors().stream().map(l -> Errors.forCode(l.errorCode())));\n+            if (data.topics().isEmpty()) {\n+                return Collections.singletonMap(error, data.partitionErrors().size());\n+            } else {", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTkwMzcyMQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r539903721", "bodyText": "may be i missed is there a test checking correctness of versioning ?", "author": "rite2nikhil", "createdAt": "2020-12-10T06:45:59Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrRequest.java", "diffHunk": "@@ -138,14 +145,32 @@ public LeaderAndIsrResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n         Errors error = Errors.forException(e);\n         responseData.setErrorCode(error.code());\n \n-        List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n-        for (LeaderAndIsrPartitionState partition : partitionStates()) {\n-            partitions.add(new LeaderAndIsrPartitionError()\n-                .setTopicName(partition.topicName())\n-                .setPartitionIndex(partition.partitionIndex())\n-                .setErrorCode(error.code()));\n+        if (version() < 5) {", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUxNjUzNQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540516535", "bodyText": "There is LeaderAndIsrResponseTest.java (which doesn't try all versions) and testGetErrorResponse() in LeaderAndIsrRequestTest.java that does test all versions. I will add version tests to the former.", "author": "jolshan", "createdAt": "2020-12-10T21:40:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTkwMzcyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIxODk1Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540218952", "bodyText": "Type field is also added. I would also mention the KIP for reference.", "author": "dajac", "createdAt": "2020-12-10T14:37:11Z", "path": "clients/src/main/resources/common/message/LeaderAndIsrRequest.json", "diffHunk": "@@ -21,8 +21,12 @@\n   //\n   // Version 2 adds broker epoch and reorganizes the partitions by topic.\n   //\n-  // Version 3 adds AddingReplicas and RemovingReplicas\n-  \"validVersions\": \"0-4\",\n+  // Version 3 adds AddingReplicas and RemovingReplicas.\n+  //\n+  // Version 4 is the first flexible version.\n+  //\n+  // Version 5 adds Topic ID to the TopicStates.", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDMxMTEwOA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540311108", "bodyText": "Thanks for catching that. Will add the KIP too.", "author": "jolshan", "createdAt": "2020-12-10T16:28:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIxODk1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIxOTQxNg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540219416", "bodyText": "nit: There are two spaces before Type and int8.", "author": "dajac", "createdAt": "2020-12-10T14:37:46Z", "path": "clients/src/main/resources/common/message/LeaderAndIsrRequest.json", "diffHunk": "@@ -31,6 +35,8 @@\n       \"about\": \"The current controller epoch.\" },\n     { \"name\": \"BrokerEpoch\", \"type\": \"int64\", \"versions\": \"2+\", \"ignorable\": true, \"default\": \"-1\",\n       \"about\": \"The current broker epoch.\" },\n+    { \"name\":  \"Type\", \"type\":  \"int8\", \"versions\": \"5+\",", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIxOTc3OA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540219778", "bodyText": "nit: There are two consecutive and.", "author": "dajac", "createdAt": "2020-12-10T14:38:16Z", "path": "clients/src/main/resources/common/message/LeaderAndIsrResponse.json", "diffHunk": "@@ -22,15 +22,28 @@\n   // Version 2 is the same as version 1.\n   //\n   // Version 3 is the same as version 2.\n-  \"validVersions\": \"0-4\",\n+  //\n+  // Version 4 is the first flexible version.\n+  //\n+  // Version 5 removes TopicName and replaces it with TopicId and and reorganizes the partitions by topic.", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyMDg3NQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540220875", "bodyText": "nit: There are two spaces before Topics and []LeaderAndIsrTopicError. We could also add a space before name to remain consistent with the other fields.", "author": "dajac", "createdAt": "2020-12-10T14:39:42Z", "path": "clients/src/main/resources/common/message/LeaderAndIsrResponse.json", "diffHunk": "@@ -22,15 +22,28 @@\n   // Version 2 is the same as version 1.\n   //\n   // Version 3 is the same as version 2.\n-  \"validVersions\": \"0-4\",\n+  //\n+  // Version 4 is the first flexible version.\n+  //\n+  // Version 5 removes TopicName and replaces it with TopicId and and reorganizes the partitions by topic.\n+  \"validVersions\": \"0-5\",\n   \"flexibleVersions\": \"4+\",\n   \"fields\": [\n     { \"name\": \"ErrorCode\", \"type\": \"int16\", \"versions\": \"0+\",\n       \"about\": \"The error code, or 0 if there was no error.\" },\n-    { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0+\",\n-      \"about\": \"Each partition.\", \"fields\": [\n-      { \"name\": \"TopicName\", \"type\": \"string\", \"versions\": \"0+\", \"entityType\": \"topicName\",\n-        \"about\": \"The topic name.\" },\n+    { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0-4\",\n+      \"about\": \"Each partition in v0 to v4 message.\"},\n+    {\"name\":  \"Topics\", \"type\":  \"[]LeaderAndIsrTopicError\", \"versions\": \"5+\",", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyMTk3MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540221970", "bodyText": "Should the version of PartitionErrors be 5+?", "author": "dajac", "createdAt": "2020-12-10T14:41:02Z", "path": "clients/src/main/resources/common/message/LeaderAndIsrResponse.json", "diffHunk": "@@ -22,15 +22,28 @@\n   // Version 2 is the same as version 1.\n   //\n   // Version 3 is the same as version 2.\n-  \"validVersions\": \"0-4\",\n+  //\n+  // Version 4 is the first flexible version.\n+  //\n+  // Version 5 removes TopicName and replaces it with TopicId and and reorganizes the partitions by topic.\n+  \"validVersions\": \"0-5\",\n   \"flexibleVersions\": \"4+\",\n   \"fields\": [\n     { \"name\": \"ErrorCode\", \"type\": \"int16\", \"versions\": \"0+\",\n       \"about\": \"The error code, or 0 if there was no error.\" },\n-    { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0+\",\n-      \"about\": \"Each partition.\", \"fields\": [\n-      { \"name\": \"TopicName\", \"type\": \"string\", \"versions\": \"0+\", \"entityType\": \"topicName\",\n-        \"about\": \"The topic name.\" },\n+    { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0-4\",\n+      \"about\": \"Each partition in v0 to v4 message.\"},\n+    {\"name\":  \"Topics\", \"type\":  \"[]LeaderAndIsrTopicError\", \"versions\": \"5+\",\n+      \"about\": \"Each topic\", \"fields\": [\n+      { \"name\": \"TopicId\", \"type\": \"uuid\", \"versions\": \"5+\", \"about\": \"The unique topic ID\" },\n+      { \"name\": \"PartitionErrors\", \"type\": \"[]LeaderAndIsrPartitionError\", \"versions\": \"0+\",", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNDY5MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540224690", "bodyText": "topicIds() recomputes the Map so it would be better to keep a local reference to it.", "author": "dajac", "createdAt": "2020-12-10T14:44:27Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrRequest.java", "diffHunk": "@@ -138,14 +145,32 @@ public LeaderAndIsrResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n         Errors error = Errors.forException(e);\n         responseData.setErrorCode(error.code());\n \n-        List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n-        for (LeaderAndIsrPartitionState partition : partitionStates()) {\n-            partitions.add(new LeaderAndIsrPartitionError()\n-                .setTopicName(partition.topicName())\n-                .setPartitionIndex(partition.partitionIndex())\n-                .setErrorCode(error.code()));\n+        if (version() < 5) {\n+            List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n+            for (LeaderAndIsrPartitionState partition : partitionStates()) {\n+                partitions.add(new LeaderAndIsrPartitionError()\n+                        .setTopicName(partition.topicName())\n+                        .setPartitionIndex(partition.partitionIndex())\n+                        .setErrorCode(error.code()));\n+            }\n+            responseData.setPartitionErrors(partitions);\n+            return new LeaderAndIsrResponse(responseData);\n+        }\n+\n+        List<LeaderAndIsrTopicError> topics = new ArrayList<>();\n+        for (LeaderAndIsrTopicState topicState : data.topicStates()) {\n+            LeaderAndIsrTopicError topicError = new LeaderAndIsrTopicError();\n+            topicError.setTopicId(topicIds().get(topicState.topicName()));", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNjAyNQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540226025", "bodyText": "nit: Could we directly allocate the ArrayList with the correct capacity? The same for partitions above and below.", "author": "dajac", "createdAt": "2020-12-10T14:46:04Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrRequest.java", "diffHunk": "@@ -138,14 +145,32 @@ public LeaderAndIsrResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n         Errors error = Errors.forException(e);\n         responseData.setErrorCode(error.code());\n \n-        List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n-        for (LeaderAndIsrPartitionState partition : partitionStates()) {\n-            partitions.add(new LeaderAndIsrPartitionError()\n-                .setTopicName(partition.topicName())\n-                .setPartitionIndex(partition.partitionIndex())\n-                .setErrorCode(error.code()));\n+        if (version() < 5) {\n+            List<LeaderAndIsrPartitionError> partitions = new ArrayList<>();\n+            for (LeaderAndIsrPartitionState partition : partitionStates()) {\n+                partitions.add(new LeaderAndIsrPartitionError()\n+                        .setTopicName(partition.topicName())\n+                        .setPartitionIndex(partition.partitionIndex())\n+                        .setErrorCode(error.code()));\n+            }\n+            responseData.setPartitionErrors(partitions);\n+            return new LeaderAndIsrResponse(responseData);\n+        }\n+\n+        List<LeaderAndIsrTopicError> topics = new ArrayList<>();", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU3Nzc5Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540577792", "bodyText": "So the partition above uses an iterable, and I'm not sure if there is a way to grab the size without iterating through. Let me know if I'm forgetting something.", "author": "jolshan", "createdAt": "2020-12-10T23:31:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNjAyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzMDEzMQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540230131", "bodyText": "It would be better to explicitly handle the version here instead of relying on topics() to be empty or not. It is easier to reason about for the reader and it also makes the handling very explicit instead of being implicit.", "author": "dajac", "createdAt": "2020-12-10T14:51:02Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -45,8 +47,16 @@ public LeaderAndIsrResponse(Struct struct, short version) {\n         this.data = new LeaderAndIsrResponseData(struct, version);\n     }\n \n-    public List<LeaderAndIsrPartitionError> partitions() {\n-        return data.partitionErrors();\n+    public List<LeaderAndIsrTopicError> topics() {\n+        return this.data.topics();\n+    }\n+\n+    public Iterable<LeaderAndIsrPartitionError> partitions() {\n+        if (data.topics().isEmpty()) {\n+            return data.partitionErrors();\n+        }\n+        return () -> new FlattenedIterator<>(data.topics().iterator(),\n+            topic -> topic.partitionErrors().iterator());", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDMwOTc0MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540309740", "bodyText": "I agree. I think I had some problems with defining the version when the constructor only provides the data. Is there a way to get the version with just the data?", "author": "jolshan", "createdAt": "2020-12-10T16:26:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzMDEzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUxMDMwMQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540510301", "bodyText": "I'm thinking that it most cases where I create a LeaderAndIsrResponse with the data object, I have access to the request and can grab the version there. Then I can add it to the constructor.", "author": "jolshan", "createdAt": "2020-12-10T21:29:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzMDEzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzMzU5MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540233590", "bodyText": "ditto here. It would be better to be explicit wrt. the handling of the version.", "author": "dajac", "createdAt": "2020-12-10T14:55:05Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -58,8 +68,17 @@ public Errors error() {\n         Errors error = error();\n         if (error != Errors.NONE)\n             // Minor optimization since the top-level error applies to all partitions\n-            return Collections.singletonMap(error, data.partitionErrors().size());\n-        return errorCounts(data.partitionErrors().stream().map(l -> Errors.forCode(l.errorCode())));\n+            if (data.topics().isEmpty()) {\n+                return Collections.singletonMap(error, data.partitionErrors().size());\n+            } else {\n+                return Collections.singletonMap(error,\n+                        data.topics().stream().mapToInt(t -> t.partitionErrors().size()).sum());\n+            }\n+        if (data.topics().isEmpty()) {\n+            return errorCounts(data.partitionErrors().stream().map(l -> Errors.forCode(l.errorCode())));\n+        }\n+        return errorCounts(data.topics().stream().flatMap(t -> t.partitionErrors().stream()).map(l ->\n+                Errors.forCode(l.errorCode())));", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzNzA0Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540237042", "bodyText": "Shouldn't we verify that topic ids are correctly set in the generated response as well?", "author": "dajac", "createdAt": "2020-12-10T14:59:15Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/LeaderAndIsrRequestTest.java", "diffHunk": "@@ -51,15 +53,15 @@\n     public void testUnsupportedVersion() {\n         LeaderAndIsrRequest.Builder builder = new LeaderAndIsrRequest.Builder(\n                 (short) (LEADER_AND_ISR.latestVersion() + 1), 0, 0, 0,\n-                Collections.emptyList(), Collections.emptySet());\n+                Collections.emptyList(), Collections.emptyMap(), Collections.emptySet());\n         assertThrows(UnsupportedVersionException.class, builder::build);\n     }\n \n     @Test\n     public void testGetErrorResponse() {\n         for (short version = LEADER_AND_ISR.oldestVersion(); version < LEADER_AND_ISR.latestVersion(); version++) {\n             LeaderAndIsrRequest.Builder builder = new LeaderAndIsrRequest.Builder(version, 0, 0, 0,\n-                    Collections.emptyList(), Collections.emptySet());\n+                    Collections.emptyList(), Collections.emptyMap(), Collections.emptySet());", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIzNzc2OA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540237768", "bodyText": "nit: HashMap<String, Uuid> to Map<String, Uuid>. I have seen this in a couple of places.", "author": "dajac", "createdAt": "2020-12-10T15:00:05Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/LeaderAndIsrRequestTest.java", "diffHunk": "@@ -116,8 +118,13 @@ public void testVersionLogic() {\n                 new Node(0, \"host0\", 9090),\n                 new Node(1, \"host1\", 9091)\n             );\n+\n+            HashMap<String, Uuid> topicIds = new HashMap<>();", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI0Mzk0MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540243940", "bodyText": "nit: You could use Collections.singletonMap here.", "author": "dajac", "createdAt": "2020-12-10T15:07:33Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/LeaderAndIsrResponseTest.java", "diffHunk": "@@ -57,29 +60,32 @@ public void testErrorCountsFromGetErrorResponse() {\n             .setZkVersion(20)\n             .setReplicas(Collections.singletonList(10))\n             .setIsNew(false));\n+        HashMap<String, Uuid> topicIds = new HashMap<>();\n+        topicIds.put(\"foo\", Uuid.randomUuid());", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI0NjQ0MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540246440", "bodyText": "Should we keep testing the older version as well? Tests assume the newest version only now.", "author": "dajac", "createdAt": "2020-12-10T15:10:46Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/LeaderAndIsrResponseTest.java", "diffHunk": "@@ -57,29 +60,32 @@ public void testErrorCountsFromGetErrorResponse() {\n             .setZkVersion(20)\n             .setReplicas(Collections.singletonList(10))\n             .setIsNew(false));\n+        HashMap<String, Uuid> topicIds = new HashMap<>();\n+        topicIds.put(\"foo\", Uuid.randomUuid());\n+\n         LeaderAndIsrRequest request = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion(),\n-                15, 20, 0, partitionStates, Collections.emptySet()).build();\n+                15, 20, 0, partitionStates, topicIds, Collections.emptySet()).build();\n         LeaderAndIsrResponse response = request.getErrorResponse(0, Errors.CLUSTER_AUTHORIZATION_FAILED.exception());\n         assertEquals(Collections.singletonMap(Errors.CLUSTER_AUTHORIZATION_FAILED, 2), response.errorCounts());\n     }\n \n     @Test\n     public void testErrorCountsWithTopLevelError() {\n-        List<LeaderAndIsrPartitionError> partitions = createPartitions(\"foo\",\n-            asList(Errors.NONE, Errors.NOT_LEADER_OR_FOLLOWER));\n+        Uuid id = Uuid.randomUuid();\n+        List<LeaderAndIsrTopicError> topics = createTopic(id, asList(Errors.NONE, Errors.NOT_LEADER_OR_FOLLOWER));\n         LeaderAndIsrResponse response = new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n             .setErrorCode(Errors.UNKNOWN_SERVER_ERROR.code())\n-            .setPartitionErrors(partitions));\n+            .setTopics(topics));\n         assertEquals(Collections.singletonMap(Errors.UNKNOWN_SERVER_ERROR, 2), response.errorCounts());", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI0NzY2Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540247662", "bodyText": "It would be good to verify that all versions are tested in testSerialization.", "author": "dajac", "createdAt": "2020-12-10T15:12:09Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -21,6 +21,7 @@\n import org.apache.kafka.common.IsolationLevel;", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI1MjM1MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540252350", "bodyText": "nit: (topic: String) -> topic. We rarely specify the type in lambdas.", "author": "dajac", "createdAt": "2020-12-10T15:17:38Z", "path": "core/src/main/scala/kafka/controller/ControllerChannelManager.scala", "diffHunk": "@@ -482,8 +483,13 @@ abstract class AbstractControllerBrokerRequestBatch(config: KafkaConfig,\n           _.node(config.interBrokerListenerName)\n         }\n         val brokerEpoch = controllerContext.liveBrokerIdAndEpochs(broker)\n+        val topicIds = leaderAndIsrPartitionStates.keys\n+          .map(_.topic)\n+          .toSet\n+          .map((topic: String) => (topic, controllerContext.topicIds(topic)))", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI1OTEzMQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540259131", "bodyText": "nit: We usually put a space before { and } when we use curly braces inline. We could also add a space after the coma.", "author": "dajac", "createdAt": "2020-12-10T15:25:48Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerChannelManagerTest.scala", "diffHunk": "@@ -72,6 +73,8 @@ class ControllerChannelManagerTest {\n     assertEquals(1, updateMetadataRequests.size)\n \n     val leaderAndIsrRequest = leaderAndIsrRequests.head\n+    val topicIds = leaderAndIsrRequest.topicIds();\n+    val topicNames = topicIds.asScala.map{ case (k,v) => (v, k)}", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI2Mjc1OA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540262758", "bodyText": "topicNames.get(t.topicId).get -> topicNames(t.topicId). It is a bit more concise when you know that the Map contains what you are looking up.\nflatMap(f => f) looks weird. I suppose that we could use flatMap instead of the first map.", "author": "dajac", "createdAt": "2020-12-10T15:30:01Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerChannelManagerTest.scala", "diffHunk": "@@ -87,7 +90,10 @@ class ControllerChannelManagerTest {\n     val LeaderAndIsrResponseReceived(leaderAndIsrResponse, brokerId) = batch.sentEvents.head\n     assertEquals(2, brokerId)\n     assertEquals(partitions.keySet,\n-      leaderAndIsrResponse.partitions.asScala.map(p => new TopicPartition(p.topicName, p.partitionIndex)).toSet)\n+      leaderAndIsrResponse.topics.asScala.map(t => t.partitionErrors.asScala.map(p =>\n+        new TopicPartition(topicNames.get(t.topicId).get, p.partitionIndex))).flatMap(f => f).toSet)", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM1NDEwNg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540354106", "bodyText": "I thought I removed most of the get(topic).gets, but I guess I missed a few. Thanks for catching. And I agree about flatMap as well.", "author": "jolshan", "createdAt": "2020-12-10T17:22:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI2Mjc1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI2NTU2MQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540265561", "bodyText": "nit: The parenthesis after topicStates, partitionStates, and partitionIndex are not mandatory. We tend to not put it when they are not.", "author": "dajac", "createdAt": "2020-12-10T15:33:17Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerChannelManagerTest.scala", "diffHunk": "@@ -818,15 +825,18 @@ class ControllerChannelManagerTest {\n   private def applyLeaderAndIsrResponseCallbacks(error: Errors, sentRequests: List[SentRequest]): Unit = {\n     sentRequests.filter(_.request.apiKey == ApiKeys.LEADER_AND_ISR).filter(_.responseCallback != null).foreach { sentRequest =>\n       val leaderAndIsrRequest = sentRequest.request.build().asInstanceOf[LeaderAndIsrRequest]\n-      val partitionErrors = leaderAndIsrRequest.partitionStates.asScala.map(p =>\n-        new LeaderAndIsrPartitionError()\n-          .setTopicName(p.topicName)\n-          .setPartitionIndex(p.partitionIndex)\n-          .setErrorCode(error.code))\n+      val topicIds = leaderAndIsrRequest.topicIds()\n+      val topicErrors = leaderAndIsrRequest.data.topicStates().asScala.map(t =>", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI2Nzc2MQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540267761", "bodyText": "I wonder if we should extend testLeaderAndIsrRequestFollowsInterBrokerProtocolVersion to verifies the topic ids based on the different supported versions. What do you think?", "author": "dajac", "createdAt": "2020-12-10T15:35:57Z", "path": "core/src/test/scala/unit/kafka/controller/ControllerChannelManagerTest.scala", "diffHunk": "@@ -157,7 +163,8 @@ class ControllerChannelManagerTest {\n \n     for (apiVersion <- ApiVersion.allVersions) {\n       val leaderAndIsrRequestVersion: Short =\n-        if (apiVersion >= KAFKA_2_4_IV1) 4\n+        if (apiVersion >= KAFKA_2_8_IV0) 5", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM1NDY3OQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540354679", "bodyText": "That's a good idea", "author": "jolshan", "createdAt": "2020-12-10T17:22:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI2Nzc2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI3MzU2Mw==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540273563", "bodyText": "It may be better to also have an explicit handling of the version here. Alternatively, we could push this into the LeaderAndIsrResponse and provides a method Map<TopicPartition, ...> partitions() which handles the version.", "author": "dajac", "createdAt": "2020-12-10T15:42:52Z", "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1378,12 +1378,26 @@ class KafkaController(val config: KafkaConfig,\n     val offlineReplicas = new ArrayBuffer[TopicPartition]()\n     val onlineReplicas = new ArrayBuffer[TopicPartition]()\n \n-    leaderAndIsrResponse.partitions.forEach { partition =>\n-      val tp = new TopicPartition(partition.topicName, partition.partitionIndex)\n-      if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n-        offlineReplicas += tp\n-      else if (partition.errorCode == Errors.NONE.code)\n-        onlineReplicas += tp\n+    if (leaderAndIsrResponse.topics().isEmpty) {", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDMyMjYzOQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540322639", "bodyText": "Actually, this may not work as we don't have the topic name in the latest version...", "author": "dajac", "createdAt": "2020-12-10T16:40:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI3MzU2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUxMzc2Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540513762", "bodyText": "Yeah. One option I thought of would be to do something like partitions(Map<id, string> topicNames) and handle it inside the response with the version. That might be a little cleaner but I'm not sure.", "author": "jolshan", "createdAt": "2020-12-10T21:35:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI3MzU2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI3NDcwMw==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540274703", "bodyText": "Do we need to handle the case when the topic may not be there anymore when the response is received? If not, we could use controllerContext.topicNames(topic.topicId).", "author": "dajac", "createdAt": "2020-12-10T15:44:17Z", "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1378,12 +1378,26 @@ class KafkaController(val config: KafkaConfig,\n     val offlineReplicas = new ArrayBuffer[TopicPartition]()\n     val onlineReplicas = new ArrayBuffer[TopicPartition]()\n \n-    leaderAndIsrResponse.partitions.forEach { partition =>\n-      val tp = new TopicPartition(partition.topicName, partition.partitionIndex)\n-      if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n-        offlineReplicas += tp\n-      else if (partition.errorCode == Errors.NONE.code)\n-        onlineReplicas += tp\n+    if (leaderAndIsrResponse.topics().isEmpty) {\n+      leaderAndIsrResponse.partitions.forEach { partition =>\n+        val topicName = partition.topicName\n+        val tp = new TopicPartition(topicName, partition.partitionIndex)\n+        if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n+          offlineReplicas += tp\n+        else if (partition.errorCode == Errors.NONE.code)\n+          onlineReplicas += tp\n+      }\n+    }\n+\n+    leaderAndIsrResponse.topics.forEach { topic =>\n+      val topicName = controllerContext.topicNames.get(topic.topicId).get", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUzNzM2Nw==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r540537367", "bodyText": "Oops. Looks like I missed another one.", "author": "jolshan", "createdAt": "2020-12-10T22:16:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDI3NDcwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI0MzkxNg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543243916", "bodyText": "Should be able to replace this with something like:\nreturn data.topicStates().stream()\n  .collect(Collectors.toMap(LeaderAndIsrTopicState::topicName, LeaderAndIsrTopicState::topicId));", "author": "rajinisivaram", "createdAt": "2020-12-15T10:55:47Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrRequest.java", "diffHunk": "@@ -171,6 +196,14 @@ public long brokerEpoch() {\n         return data.ungroupedPartitionStates();\n     }\n \n+    public Map<String, Uuid> topicIds() {\n+        Map<String, Uuid> topicIds = new HashMap<>();\n+        for (LeaderAndIsrTopicState ts : data.topicStates()) {\n+            topicIds.put(ts.topicName(), ts.topicId());\n+        }\n+        return topicIds;", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI0NzMzNQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543247335", "bodyText": "nit: We should add braces here since there are multiple lines inside the if statement", "author": "rajinisivaram", "createdAt": "2020-12-15T11:01:05Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -58,8 +68,17 @@ public Errors error() {\n         Errors error = error();\n         if (error != Errors.NONE)", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI0NzM0Ng==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543247346", "bodyText": "nit: We should add braces here since there are multiple lines inside the if statement", "author": "rajinisivaram", "createdAt": "2020-12-15T11:01:06Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/LeaderAndIsrResponse.java", "diffHunk": "@@ -58,8 +68,17 @@ public Errors error() {\n         Errors error = error();\n         if (error != Errors.NONE)", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI1NjMwNg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543256306", "bodyText": "Should we do controllerContext.topicNames.get(topic.topicId).foreach instead of get to avoid throwing exception if topic is not in the context?", "author": "rajinisivaram", "createdAt": "2020-12-15T11:14:59Z", "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1378,12 +1378,26 @@ class KafkaController(val config: KafkaConfig,\n     val offlineReplicas = new ArrayBuffer[TopicPartition]()\n     val onlineReplicas = new ArrayBuffer[TopicPartition]()\n \n-    leaderAndIsrResponse.partitions.forEach { partition =>\n-      val tp = new TopicPartition(partition.topicName, partition.partitionIndex)\n-      if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n-        offlineReplicas += tp\n-      else if (partition.errorCode == Errors.NONE.code)\n-        onlineReplicas += tp\n+    if (leaderAndIsrResponse.topics().isEmpty) {\n+      leaderAndIsrResponse.partitions.forEach { partition =>\n+        val topicName = partition.topicName\n+        val tp = new TopicPartition(topicName, partition.partitionIndex)\n+        if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n+          offlineReplicas += tp\n+        else if (partition.errorCode == Errors.NONE.code)\n+          onlineReplicas += tp\n+      }\n+    }\n+\n+    leaderAndIsrResponse.topics.forEach { topic =>\n+      val topicName = controllerContext.topicNames.get(topic.topicId).get", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzY5MTE4Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543691182", "bodyText": "I moved this logic to LeaderAndIsrResponse which is java code, so it behaves a bit differently. (We may want to move back though, and if so, I'll do this.) For now I do a null check in the java code.\nOne question I have though is what does it mean to not have a topic in the context? Is it possible to send a leaderAndIsrRequest with an unknown partition/one not in the context? I can only think maybe the topic gets deleted while handling the request. What would the normal error handling case be in that scenario?", "author": "jolshan", "createdAt": "2020-12-15T21:15:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI1NjMwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI1NzM3Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543257372", "bodyText": "We can make an inner method within this method with the common logic.", "author": "rajinisivaram", "createdAt": "2020-12-15T11:16:42Z", "path": "core/src/main/scala/kafka/controller/KafkaController.scala", "diffHunk": "@@ -1378,12 +1378,26 @@ class KafkaController(val config: KafkaConfig,\n     val offlineReplicas = new ArrayBuffer[TopicPartition]()\n     val onlineReplicas = new ArrayBuffer[TopicPartition]()\n \n-    leaderAndIsrResponse.partitions.forEach { partition =>\n-      val tp = new TopicPartition(partition.topicName, partition.partitionIndex)\n-      if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n-        offlineReplicas += tp\n-      else if (partition.errorCode == Errors.NONE.code)\n-        onlineReplicas += tp\n+    if (leaderAndIsrResponse.topics().isEmpty) {\n+      leaderAndIsrResponse.partitions.forEach { partition =>\n+        val topicName = partition.topicName\n+        val tp = new TopicPartition(topicName, partition.partitionIndex)\n+        if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n+          offlineReplicas += tp\n+        else if (partition.errorCode == Errors.NONE.code)\n+          onlineReplicas += tp\n+      }\n+    }\n+\n+    leaderAndIsrResponse.topics.forEach { topic =>\n+      val topicName = controllerContext.topicNames.get(topic.topicId).get\n+      topic.partitionErrors().forEach { partition =>\n+        val tp = new TopicPartition(topicName, partition.partitionIndex)\n+        if (partition.errorCode == Errors.KAFKA_STORAGE_ERROR.code)\n+          offlineReplicas += tp\n+        else if (partition.errorCode == Errors.NONE.code)\n+          onlineReplicas += tp", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NTkwMA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543485900", "bodyText": "I ended up moving some of this to the response class so the duplicate logic is removed. I just haven't pushed yet", "author": "jolshan", "createdAt": "2020-12-15T16:18:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI1NzM3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI1OTY1Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543259652", "bodyText": "Seems neater to use partitionMetadataFile.foreach instead of using .get twice.", "author": "rajinisivaram", "createdAt": "2020-12-15T11:20:42Z", "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -322,6 +327,11 @@ class Log(@volatile private var _dir: File,\n     // deletion.\n     producerStateManager.removeStraySnapshots(segments.values().asScala.map(_.baseOffset).toSeq)\n     loadProducerState(logEndOffset, reloadFromCleanShutdown = hadCleanShutdown)\n+\n+    // Recover topic ID if present\n+    if (!partitionMetadataFile.get.isEmpty()) {\n+      topicId = partitionMetadataFile.get.read().topicId\n+    }", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NDA5OA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543264098", "bodyText": "Why are we reading and writing again?", "author": "rajinisivaram", "createdAt": "2020-12-15T11:28:07Z", "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1021,6 +1036,13 @@ class Log(@volatile private var _dir: File,\n           // re-initialize leader epoch cache so that LeaderEpochCheckpointFile.checkpoint can correctly reference\n           // the checkpoint file in renamed log directory\n           initializeLeaderEpochCache()\n+          if (!partitionMetadataFile.isEmpty && !partitionMetadataFile.get.isEmpty()) {\n+            val partitionMetadata = partitionMetadataFile.get.read()\n+            initializePartitionMetadata()\n+            partitionMetadataFile.get.write(partitionMetadata.topicId)", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4ODY2MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543488660", "bodyText": "Perhaps my understading is wrong, but if we rename the directory, do we need to create the file in the new directory? With the same topic ID and such as before.", "author": "jolshan", "createdAt": "2020-12-15T16:21:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NDA5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzY3OTYwMA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543679600", "bodyText": "Oh I did understand wrong. The file is already in place, so initializePartitionMetadata is all that is needed to get the correct file path.", "author": "jolshan", "createdAt": "2020-12-15T20:55:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NDA5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NDY2Mg==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543264662", "bodyText": "LeaderEpochCheckpointFilename => PartitionMetadataFilename?", "author": "rajinisivaram", "createdAt": "2020-12-15T11:29:05Z", "path": "core/src/main/scala/kafka/server/PartitionMetadataFile.scala", "diffHunk": "@@ -0,0 +1,141 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.io.{BufferedReader, BufferedWriter, File, FileOutputStream, IOException, OutputStreamWriter}\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{FileAlreadyExistsException, Files, Paths}\n+import java.util.regex.Pattern\n+\n+import kafka.utils.Logging\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.errors.KafkaStorageException\n+import org.apache.kafka.common.utils.Utils\n+\n+\n+\n+object PartitionMetadataFile {\n+  private val LeaderEpochCheckpointFilename = \"partition.metadata\"", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NzcwMw==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543487703", "bodyText": "Good catch.", "author": "jolshan", "createdAt": "2020-12-15T16:20:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NDY2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NTkzNA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543265934", "bodyText": ".foreach may be better than lots of .gets", "author": "rajinisivaram", "createdAt": "2020-12-15T11:31:12Z", "path": "core/src/main/scala/kafka/log/Log.scala", "diffHunk": "@@ -1021,6 +1036,13 @@ class Log(@volatile private var _dir: File,\n           // re-initialize leader epoch cache so that LeaderEpochCheckpointFile.checkpoint can correctly reference\n           // the checkpoint file in renamed log directory\n           initializeLeaderEpochCache()\n+          if (!partitionMetadataFile.isEmpty && !partitionMetadataFile.get.isEmpty()) {", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI2NzU4Nw==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543267587", "bodyText": "update error message?", "author": "rajinisivaram", "createdAt": "2020-12-15T11:33:57Z", "path": "core/src/main/scala/kafka/server/PartitionMetadataFile.scala", "diffHunk": "@@ -0,0 +1,141 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.io.{BufferedReader, BufferedWriter, File, FileOutputStream, IOException, OutputStreamWriter}\n+import java.nio.charset.StandardCharsets\n+import java.nio.file.{FileAlreadyExistsException, Files, Paths}\n+import java.util.regex.Pattern\n+\n+import kafka.utils.Logging\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.errors.KafkaStorageException\n+import org.apache.kafka.common.utils.Utils\n+\n+\n+\n+object PartitionMetadataFile {\n+  private val LeaderEpochCheckpointFilename = \"partition.metadata\"\n+  private val WhiteSpacesPattern = Pattern.compile(\":\\\\s+\")\n+  private val CurrentVersion = 0\n+\n+  def newFile(dir: File): File = new File(dir, LeaderEpochCheckpointFilename)\n+\n+  object PartitionMetadataFileFormatter {\n+    def toFile(data: PartitionMetadata): String = {\n+      s\"version: ${data.version}\\ntopic_id: ${data.topicId}\"\n+    }\n+\n+  }\n+\n+  class PartitionMetadataReadBuffer[T](location: String,\n+                                       reader: BufferedReader,\n+                                       version: Int) extends Logging {\n+    def read(): PartitionMetadata = {\n+      def malformedLineException(line: String) =\n+        new IOException(s\"Malformed line in checkpoint file ($location): '$line'\")\n+\n+      var line: String = null\n+      var metadataTopicId: Uuid = null\n+      try {\n+        line = reader.readLine()\n+        WhiteSpacesPattern.split(line) match {\n+          case Array(_, version) =>\n+            if (version.toInt == CurrentVersion) {\n+              line = reader.readLine()\n+              WhiteSpacesPattern.split(line) match {\n+                case Array(_, topicId) => metadataTopicId = Uuid.fromString(topicId)\n+                case _ => throw malformedLineException(line)\n+              }\n+              new PartitionMetadata(CurrentVersion, metadataTopicId)\n+            } else {\n+              throw new IOException(s\"Unrecognized version of the checkpoint file ($location): \" + version)", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MjU3Mw==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543272573", "bodyText": "why is this a warning?", "author": "rajinisivaram", "createdAt": "2020-12-15T11:42:04Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1434,6 +1447,31 @@ class ReplicaManager(val config: KafkaConfig,\n            */\n             if (localLog(topicPartition).isEmpty)\n               markPartitionOffline(topicPartition)\n+            else {\n+              val id = topicIds.get(topicPartition.topic())\n+              // Ensure we have not received a request from an older protocol\n+              if (id != null && !id.equals(Uuid.ZERO_UUID)) {\n+                val log = localLog(topicPartition).get\n+                // Check if the topic ID is in memory, if not, it must be new to the broker.\n+                // If the broker previously wrote it to file, it would be recovered on restart after failure.\n+                // If the topic ID is not the default (ZERO_UUID), a topic ID is being used for the given topic.\n+                // If the topic ID in the log does not match the one in the request, the broker's topic must be stale.\n+                if (!log.topicId.equals(Uuid.ZERO_UUID) && !log.topicId.equals(topicIds.get(topicPartition.topic))) {\n+                  stateChangeLogger.warn(s\"Topic Id in memory: ${log.topicId.toString} does not\" +\n+                    s\" match the topic Id provided in the request: \" +\n+                    s\"${topicIds.get(topicPartition.topic).toString}.\")\n+                } else {\n+                  // There is not yet a topic ID stored in the log.\n+                  // Write the partition metadata file if it is empty.\n+                  if (log.partitionMetadataFile.get.isEmpty()) {\n+                    log.partitionMetadataFile.get.write(topicIds.get(topicPartition.topic))\n+                    log.topicId = topicIds.get(topicPartition.topic)\n+                  } else {\n+                    stateChangeLogger.warn(\"Partition metadata file already contains content.\")", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzY2MzQ4MQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543663481", "bodyText": "I think that if we reach here, we are in an unexpected state. The partitionMetadata file should have loaded in the topic ID if the file already contained content. I left as a warn rather than an exception.", "author": "jolshan", "createdAt": "2020-12-15T20:27:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MjU3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDIwNDQ5MA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r544204490", "bodyText": "Hmm, looking at the conditional statements here, it looks like we would write the file the first time we get here because log.partitionMetadataFile.get.isEmpty() and the second time we would print a warning even if the id in the file matches the expected id. Unless I missed something.", "author": "rajinisivaram", "createdAt": "2020-12-16T10:59:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MjU3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4MzIzOA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r544483238", "bodyText": "Oops. I think I cleaned up this block and deleted something. There should be a check if log.topicId.equals(id). If so, then the file exists and we shouldn't go in to the block that says \"// There is not yet a topic ID stored in the log.\"\nI should also fix the topicIds.get(topicPartition.topic) above and replace with id.", "author": "jolshan", "createdAt": "2020-12-16T17:24:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MjU3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4MzY2NA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r544483664", "bodyText": "I might think about making this code cleaner in general to avoid so many nested if statements", "author": "jolshan", "createdAt": "2020-12-16T17:25:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MjU3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDYzNDYwOA==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r544634608", "bodyText": "So I thought through these cases some more and realized that the metadata file will fail to open if formatted incorrectly. So the only case where there could be data written to the file is if the ID is the zero UUID. So I decided to just fail on reading the file if the zero ID is provided. (We will never write zero ID to file.) The rest of this cleaned up pretty nicely.", "author": "jolshan", "createdAt": "2020-12-16T21:26:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MjU3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MzI0NQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543273245", "bodyText": "we already have the topic id in id.", "author": "rajinisivaram", "createdAt": "2020-12-15T11:43:01Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1434,6 +1447,31 @@ class ReplicaManager(val config: KafkaConfig,\n            */\n             if (localLog(topicPartition).isEmpty)\n               markPartitionOffline(topicPartition)\n+            else {\n+              val id = topicIds.get(topicPartition.topic())\n+              // Ensure we have not received a request from an older protocol\n+              if (id != null && !id.equals(Uuid.ZERO_UUID)) {\n+                val log = localLog(topicPartition).get\n+                // Check if the topic ID is in memory, if not, it must be new to the broker.\n+                // If the broker previously wrote it to file, it would be recovered on restart after failure.\n+                // If the topic ID is not the default (ZERO_UUID), a topic ID is being used for the given topic.\n+                // If the topic ID in the log does not match the one in the request, the broker's topic must be stale.\n+                if (!log.topicId.equals(Uuid.ZERO_UUID) && !log.topicId.equals(topicIds.get(topicPartition.topic))) {\n+                  stateChangeLogger.warn(s\"Topic Id in memory: ${log.topicId.toString} does not\" +\n+                    s\" match the topic Id provided in the request: \" +\n+                    s\"${topicIds.get(topicPartition.topic).toString}.\")\n+                } else {\n+                  // There is not yet a topic ID stored in the log.\n+                  // Write the partition metadata file if it is empty.\n+                  if (log.partitionMetadataFile.get.isEmpty()) {\n+                    log.partitionMetadataFile.get.write(topicIds.get(topicPartition.topic))", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3MzU0MQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543273541", "bodyText": "As above, we can use id", "author": "rajinisivaram", "createdAt": "2020-12-15T11:43:29Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1434,6 +1447,31 @@ class ReplicaManager(val config: KafkaConfig,\n            */\n             if (localLog(topicPartition).isEmpty)\n               markPartitionOffline(topicPartition)\n+            else {\n+              val id = topicIds.get(topicPartition.topic())\n+              // Ensure we have not received a request from an older protocol\n+              if (id != null && !id.equals(Uuid.ZERO_UUID)) {\n+                val log = localLog(topicPartition).get\n+                // Check if the topic ID is in memory, if not, it must be new to the broker.\n+                // If the broker previously wrote it to file, it would be recovered on restart after failure.\n+                // If the topic ID is not the default (ZERO_UUID), a topic ID is being used for the given topic.\n+                // If the topic ID in the log does not match the one in the request, the broker's topic must be stale.\n+                if (!log.topicId.equals(Uuid.ZERO_UUID) && !log.topicId.equals(topicIds.get(topicPartition.topic))) {\n+                  stateChangeLogger.warn(s\"Topic Id in memory: ${log.topicId.toString} does not\" +\n+                    s\" match the topic Id provided in the request: \" +\n+                    s\"${topicIds.get(topicPartition.topic).toString}.\")\n+                } else {\n+                  // There is not yet a topic ID stored in the log.\n+                  // Write the partition metadata file if it is empty.\n+                  if (log.partitionMetadataFile.get.isEmpty()) {\n+                    log.partitionMetadataFile.get.write(topicIds.get(topicPartition.topic))\n+                    log.topicId = topicIds.get(topicPartition.topic)", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzI3NjYxNQ==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r543276615", "bodyText": "Replace topics.get(tp.topic).get with topics(tp.topic)", "author": "rajinisivaram", "createdAt": "2020-12-15T11:48:27Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1445,15 +1483,38 @@ class ReplicaManager(val config: KafkaConfig,\n           replicaFetcherManager.shutdownIdleFetcherThreads()\n           replicaAlterLogDirsManager.shutdownIdleFetcherThreads()\n           onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)\n-          val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n-            new LeaderAndIsrPartitionError()\n-              .setTopicName(tp.topic)\n-              .setPartitionIndex(tp.partition)\n-              .setErrorCode(error.code)\n-          }.toBuffer\n-          new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n-            .setErrorCode(Errors.NONE.code)\n-            .setPartitionErrors(responsePartitions.asJava))\n+          if (leaderAndIsrRequest.version() < 5) {\n+            val responsePartitions = responseMap.iterator.map { case (tp, error) =>\n+              new LeaderAndIsrPartitionError()\n+                .setTopicName(tp.topic)\n+                .setPartitionIndex(tp.partition)\n+                .setErrorCode(error.code)\n+            }.toBuffer\n+            new LeaderAndIsrResponse(new LeaderAndIsrResponseData()\n+              .setErrorCode(Errors.NONE.code)\n+              .setPartitionErrors(responsePartitions.asJava))\n+          } else {\n+            val topics = new mutable.HashMap[String, List[LeaderAndIsrPartitionError]]\n+            responseMap.asJava.forEach { case (tp, error) =>\n+              if (!topics.contains(tp.topic)) {\n+                topics.put(tp.topic, List(new LeaderAndIsrPartitionError()\n+                                                                .setPartitionIndex(tp.partition)\n+                                                                .setErrorCode(error.code)))\n+              } else {\n+                topics.put(tp.topic, new LeaderAndIsrPartitionError()\n+                  .setPartitionIndex(tp.partition)\n+                  .setErrorCode(error.code)::topics.get(tp.topic).get)", "originalCommit": "1926bf43e6c1b2f293fa6401847794edde5396b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5424a1a026649a5270d4593fb2ba920e8abc091a", "url": "https://github.com/apache/kafka/commit/5424a1a026649a5270d4593fb2ba920e8abc091a", "message": "Addressed comments", "committedDate": "2020-12-16T00:57:57Z", "type": "commit"}, {"oid": "6dbdbb80b3c6774e9dc3870976d709d7fe3c217b", "url": "https://github.com/apache/kafka/commit/6dbdbb80b3c6774e9dc3870976d709d7fe3c217b", "message": "Made replicaManager code less complicated.", "committedDate": "2020-12-17T01:20:24Z", "type": "commit"}, {"oid": "53ea8430a75b6e8e81f216ebae1ba27b32ca44b2", "url": "https://github.com/apache/kafka/commit/53ea8430a75b6e8e81f216ebae1ba27b32ca44b2", "message": "Merge branch 'trunk' of github.com:apache/kafka into KIP516LeaderAndIsr", "committedDate": "2020-12-17T03:49:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTAwOTgxMw==", "url": "https://github.com/apache/kafka/pull/9626#discussion_r545009813", "bodyText": "nit: assertFalse instead of assertTrue(!...). There are a few of these below as well.", "author": "rajinisivaram", "createdAt": "2020-12-17T11:16:13Z", "path": "core/src/test/scala/unit/kafka/server/ReplicaManagerTest.scala", "diffHunk": "@@ -2176,4 +2212,84 @@ class ReplicaManagerTest {\n       replicaManager.shutdown(false)\n     }\n   }\n+\n+  @Test\n+  def testPartitionMetadataFile() = {\n+    val replicaManager = setupReplicaManagerWithMockedPurgatories(new MockTimer(time))\n+    try {\n+      val brokerList = Seq[Integer](0, 1).asJava\n+      val topicPartition = new TopicPartition(topic, 0)\n+      replicaManager.createPartition(topicPartition)\n+        .createLogIfNotExists(isNew = false, isFutureReplica = false,\n+          new LazyOffsetCheckpoints(replicaManager.highWatermarkCheckpoints))\n+      val topicIds = Collections.singletonMap(topic, Uuid.randomUuid())\n+\n+      def leaderAndIsrRequest(epoch: Int): LeaderAndIsrRequest = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion, 0, 0, brokerEpoch,\n+        Seq(new LeaderAndIsrPartitionState()\n+          .setTopicName(topic)\n+          .setPartitionIndex(0)\n+          .setControllerEpoch(0)\n+          .setLeader(0)\n+          .setLeaderEpoch(epoch)\n+          .setIsr(brokerList)\n+          .setZkVersion(0)\n+          .setReplicas(brokerList)\n+          .setIsNew(true)).asJava,\n+        topicIds,\n+        Set(new Node(0, \"host1\", 0), new Node(1, \"host2\", 1)).asJava).build()\n+\n+      replicaManager.becomeLeaderOrFollower(0, leaderAndIsrRequest(0), (_, _) => ())\n+      assertTrue(!replicaManager.localLog(topicPartition).isEmpty)\n+      val id = topicIds.get(topicPartition.topic())\n+      val log = replicaManager.localLog(topicPartition).get\n+      assertTrue(!log.partitionMetadataFile.isEmpty)\n+      assertTrue(!log.partitionMetadataFile.get.isEmpty())\n+      val partitionMetadata = log.partitionMetadataFile.get.read()\n+\n+      // Current version of PartitionMetadataFile is 0.\n+      assertEquals(0, partitionMetadata.version)\n+      assertEquals(id, partitionMetadata.topicId)\n+    } finally replicaManager.shutdown(checkpointHW = false)\n+  }\n+\n+  @Test\n+  def testPartitionMetadataFileNotCreated() = {\n+    val replicaManager = setupReplicaManagerWithMockedPurgatories(new MockTimer(time))\n+    try {\n+      val brokerList = Seq[Integer](0, 1).asJava\n+      val topicPartition = new TopicPartition(topic, 0)\n+      replicaManager.createPartition(topicPartition)\n+        .createLogIfNotExists(isNew = false, isFutureReplica = false,\n+          new LazyOffsetCheckpoints(replicaManager.highWatermarkCheckpoints))\n+      val topicIds = Collections.singletonMap(topic, Uuid.ZERO_UUID)\n+\n+      def leaderAndIsrRequest(epoch: Int, name: String): LeaderAndIsrRequest = new LeaderAndIsrRequest.Builder(ApiKeys.LEADER_AND_ISR.latestVersion, 0, 0, brokerEpoch,\n+        Seq(new LeaderAndIsrPartitionState()\n+          .setTopicName(name)\n+          .setPartitionIndex(0)\n+          .setControllerEpoch(0)\n+          .setLeader(0)\n+          .setLeaderEpoch(epoch)\n+          .setIsr(brokerList)\n+          .setZkVersion(0)\n+          .setReplicas(brokerList)\n+          .setIsNew(true)).asJava,\n+        topicIds,\n+        Set(new Node(0, \"host1\", 0), new Node(1, \"host2\", 1)).asJava).build()\n+\n+      // The file has no contents if the topic does not have an associated topic ID.\n+      replicaManager.becomeLeaderOrFollower(0, leaderAndIsrRequest(0, \"fakeTopic\"), (_, _) => ())\n+      assertTrue(!replicaManager.localLog(topicPartition).isEmpty)", "originalCommit": "53ea8430a75b6e8e81f216ebae1ba27b32ca44b2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "919f0ed74008a43deeb39b088d7c63ee56ae6d44", "url": "https://github.com/apache/kafka/commit/919f0ed74008a43deeb39b088d7c63ee56ae6d44", "message": "Fix some issues with propagating partition state", "committedDate": "2020-12-17T23:00:00Z", "type": "commit"}, {"oid": "fcd80938b9c17b46d2395623cca80e12d2b4f6c9", "url": "https://github.com/apache/kafka/commit/fcd80938b9c17b46d2395623cca80e12d2b4f6c9", "message": "Remove extra code", "committedDate": "2020-12-18T15:56:40Z", "type": "commit"}, {"oid": "213143d98480f92cc308e7c082b1a123ff03e821", "url": "https://github.com/apache/kafka/commit/213143d98480f92cc308e7c082b1a123ff03e821", "message": "Merge branch 'trunk' into KIP516LeaderAndIsr", "committedDate": "2020-12-18T18:55:32Z", "type": "commit"}, {"oid": "5ff7840a592464cb18931b27d4ff1d6157a86b93", "url": "https://github.com/apache/kafka/commit/5ff7840a592464cb18931b27d4ff1d6157a86b93", "message": "Merge branch 'trunk' into KIP516LeaderAndIsr", "committedDate": "2020-12-18T21:37:00Z", "type": "commit"}]}