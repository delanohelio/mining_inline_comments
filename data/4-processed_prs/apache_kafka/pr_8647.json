{"pr_number": 8647, "pr_title": "KAFKA-9669; Loosen validation of inner offsets for older message formats", "pr_createdAt": "2020-05-12T00:49:57Z", "pr_url": "https://github.com/apache/kafka/pull/8647", "timeline": [{"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "url": "https://github.com/apache/kafka/commit/3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "message": "KAFKA-9669; Loosen validation of inner offsets for older message format versions", "committedDate": "2020-05-12T00:58:03Z", "type": "commit"}, {"oid": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "url": "https://github.com/apache/kafka/commit/3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "message": "KAFKA-9669; Loosen validation of inner offsets for older message format versions", "committedDate": "2020-05-12T00:58:03Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzQ0MzgyMw==", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423443823", "bodyText": "First, I don't fully understand the different between version 0, 1, and 2. I am concern if this check (if statement) it still accurate.\n\nWhy do we only update the maxTimestamp if the version is not v0?\nWhy do we disallow in place assignment of records with invalid offsets if the version is not v0?\n\nFor 1, is it because we are only allow to update it in v1 and v2? E.g.\nif (toMagic >= RecordBatch.MAGIC_VALUE_V1)\n        batch.setMaxTimestamp(timestampType, maxTimestamp)\n\nFor 2. is it because in place assignment is always false for v0? E.g.:\n    if (firstBatch.magic != toMagic || toMagic == RecordBatch.MAGIC_VALUE_V0)\n      inPlaceAssignment = false", "author": "jsancio", "createdAt": "2020-05-12T03:42:21Z", "path": "core/src/main/scala/kafka/log/LogValidator.scala", "diffHunk": "@@ -423,8 +413,11 @@ private[log] object LogValidator extends Logging {\n               if (batch.magic > RecordBatch.MAGIC_VALUE_V0 && toMagic > RecordBatch.MAGIC_VALUE_V0) {", "originalCommit": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzgzMTYyNg==", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423831626", "bodyText": "For 1), it is because the v0 format has no field for the timestamp. For 2), you are right: we never do in place assignment for v0 because it does not support relative internal offsets.", "author": "hachikuji", "createdAt": "2020-05-12T15:35:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzQ0MzgyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg1MTg1Mw==", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423851853", "bodyText": "I'm a bit nervous about this method being in the public interface. Could we make it package private and then add a test utility method in the same package that calls it, exposing it only for tests?", "author": "ijuma", "createdAt": "2020-05-12T16:02:03Z", "path": "clients/src/main/java/org/apache/kafka/common/record/MemoryRecordsBuilder.java", "diffHunk": "@@ -587,6 +588,35 @@ public void appendUncheckedWithOffset(long offset, LegacyRecord record) {\n         }\n     }\n \n+    /**\n+     * Append a record without doing offset/magic validation (this should only be used in testing).\n+     *\n+     * @param offset The offset of the record\n+     * @param record The record to add\n+     */\n+    public void appendUncheckedWithOffset(long offset, SimpleRecord record) throws IOException {", "originalCommit": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg1MzA5Mw==", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423853093", "bodyText": "Oh, we already have a public appendUncheckedWithOffset for LegacyRecord.", "author": "ijuma", "createdAt": "2020-05-12T16:03:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg1MTg1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg2MjYzOQ==", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423862639", "bodyText": "We could move these methods to a TestMemoryRecordsBuilder or something. I think risk of misuse is probably not high though.", "author": "hachikuji", "createdAt": "2020-05-12T16:17:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg1MTg1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg3OTc1NA==", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423879754", "bodyText": "Makes sense. Since we already had one such method, I'm ok with keeping as is.", "author": "ijuma", "createdAt": "2020-05-12T16:42:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg1MTg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg3MDgwMg==", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423870802", "bodyText": "Can we add a comment here?", "author": "ijuma", "createdAt": "2020-05-12T16:29:07Z", "path": "core/src/main/scala/kafka/log/LogValidator.scala", "diffHunk": "@@ -423,8 +413,11 @@ private[log] object LogValidator extends Logging {\n               if (batch.magic > RecordBatch.MAGIC_VALUE_V0 && toMagic > RecordBatch.MAGIC_VALUE_V0) {\n                 if (record.timestamp > maxTimestamp)\n                   maxTimestamp = record.timestamp\n-                validateOffset(batchIndex, record, expectedOffset)\n-              } else None\n+\n+                if (record.offset != expectedOffset)", "originalCommit": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg3MTQ1MA==", "url": "https://github.com/apache/kafka/pull/8647#discussion_r423871450", "bodyText": "Nit: Replace 20 with numRecords", "author": "ijuma", "createdAt": "2020-05-12T16:30:02Z", "path": "core/src/test/scala/unit/kafka/log/LogValidatorTest.scala", "diffHunk": "@@ -64,6 +64,29 @@ class LogValidatorTest {\n     checkAllowMultiBatch(RecordBatch.MAGIC_VALUE_V1, CompressionType.NONE, CompressionType.GZIP)\n   }\n \n+  @Test\n+  def testValidationOfBatchesWithNonSequentialInnerOffsets(): Unit = {\n+    def testMessageValidation(magicValue: Byte): Unit = {\n+      val numRecords = 20\n+      val invalidRecords = recordsWithNonSequentialInnerOffsets(magicValue, CompressionType.GZIP, numRecords)\n+\n+      // Validation for v2 and above is strict for this case. For older formats, we fix invalid\n+      // internal offsets by rewriting the batch.\n+      if (magicValue >= RecordBatch.MAGIC_VALUE_V2) {\n+        assertThrows[InvalidRecordException] {\n+          validateMessages(invalidRecords, magicValue, CompressionType.GZIP, CompressionType.GZIP)\n+        }\n+      } else {\n+        val result = validateMessages(invalidRecords, magicValue, CompressionType.GZIP, CompressionType.GZIP)\n+        assertEquals(0 until 20, result.validatedRecords.records.asScala.map(_.offset))", "originalCommit": "3bfde0f4eb8910fc81e239a3006a5736ea6bee12", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b174f7c272a0cdec396e613507c612ded7f96044", "url": "https://github.com/apache/kafka/commit/b174f7c272a0cdec396e613507c612ded7f96044", "message": "Add comment about internal offset validation", "committedDate": "2020-05-12T16:45:30Z", "type": "commit"}]}