{"pr_number": 8375, "pr_title": "KAFKA-9776: Downgrade TxnCommit API v3 when broker doesn't support", "pr_createdAt": "2020-03-27T20:10:31Z", "pr_url": "https://github.com/apache/kafka/pull/8375", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUxNjcxNQ==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r399516715", "bodyText": "side cleanups", "author": "abbccdda", "createdAt": "2020-03-27T20:18:04Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/KafkaProducerTest.java", "diffHunk": "@@ -138,8 +142,8 @@ public void testOverwriteAcksAndRetriesForIdempotentProducers() {\n \n         ProducerConfig config = new ProducerConfig(props);\n         assertTrue(config.getBoolean(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG));\n-        assertTrue(Arrays.asList(\"-1\", \"all\").stream().anyMatch(each -> each.equalsIgnoreCase(config.getString(ProducerConfig.ACKS_CONFIG))));\n-        assertTrue(config.getInt(ProducerConfig.RETRIES_CONFIG) == Integer.MAX_VALUE);\n+        assertTrue(Stream.of(\"-1\", \"all\").anyMatch(each -> each.equalsIgnoreCase(config.getString(ProducerConfig.ACKS_CONFIG))));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUxNjYwOA==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r399516608", "bodyText": "which only sends with consumer group id -- seems obvious from the API. Should we remove this part?", "author": "mjsax", "createdAt": "2020-03-27T20:17:49Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -642,17 +642,19 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n      * This method should be used when you need to batch consumed and produced messages\n      * together, typically in a consume-transform-produce pattern. Thus, the specified\n      * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n-     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for stronger fencing than\n+     * {@link #sendOffsetsToTransaction(Map, String)} which only sends with consumer group id.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU0MTk2MA==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r399541960", "bodyText": "I feel keeping it is fine, just a more explicit explanation to the stronger fencing", "author": "abbccdda", "createdAt": "2020-03-27T21:16:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUxNjYwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUxNzU3OA==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r399517578", "bodyText": "missing <p>", "author": "mjsax", "createdAt": "2020-03-27T20:19:54Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -642,17 +642,19 @@ public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offs\n      * This method should be used when you need to batch consumed and produced messages\n      * together, typically in a consume-transform-produce pattern. Thus, the specified\n      * {@code groupMetadata} should be extracted from the used {@link KafkaConsumer consumer} via\n-     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for proper fencing.\n+     * {@link KafkaConsumer#groupMetadata()} to leverage consumer group metadata for stronger fencing than\n+     * {@link #sendOffsetsToTransaction(Map, String)} which only sends with consumer group id.\n+     * If broker doesn't support this new transactional API (i.e. if its version is lower than 2.5.0),\n+     * this call will silently downgrade to the equivalent of {@link #sendOffsetsToTransaction(Map, String)}.\n+     *", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "283d71aae14af024c663f9b7ffc96433953d8264", "url": "https://github.com/apache/kafka/commit/283d71aae14af024c663f9b7ffc96433953d8264", "message": "Fallback group metadata", "committedDate": "2020-03-31T01:24:42Z", "type": "commit"}, {"oid": "3f6e9a6d655461399f51a16947fc7f9197564874", "url": "https://github.com/apache/kafka/commit/3f6e9a6d655461399f51a16947fc7f9197564874", "message": "address comment", "committedDate": "2020-03-31T01:24:42Z", "type": "commit"}, {"oid": "7d7673b03e9dd70749c849fcb26e74b60e7c2909", "url": "https://github.com/apache/kafka/commit/7d7673b03e9dd70749c849fcb26e74b60e7c2909", "message": "reenable system test", "committedDate": "2020-03-31T01:33:50Z", "type": "commit"}, {"oid": "315bd5489fb6e0118011decab3d97d26bc9b4a72", "url": "https://github.com/apache/kafka/commit/315bd5489fb6e0118011decab3d97d26bc9b4a72", "message": "add internal flag for txn commit downgrade", "committedDate": "2020-03-31T03:44:02Z", "type": "commit"}, {"oid": "ad71a05bd31b3983977ea0cff174fd828996f8d4", "url": "https://github.com/apache/kafka/commit/ad71a05bd31b3983977ea0cff174fd828996f8d4", "message": "partially done", "committedDate": "2020-03-31T05:01:24Z", "type": "commit"}, {"oid": "d62d08f05031d391b35d4a216b4751b4f8fe35e1", "url": "https://github.com/apache/kafka/commit/d62d08f05031d391b35d4a216b4751b4f8fe35e1", "message": "replacement", "committedDate": "2020-03-31T05:29:55Z", "type": "commit"}, {"oid": "13311b522f4ef6a38f7f0e5bd327d81bbaac462d", "url": "https://github.com/apache/kafka/commit/13311b522f4ef6a38f7f0e5bd327d81bbaac462d", "message": "fix txn producer test", "committedDate": "2020-03-31T05:41:54Z", "type": "commit"}, {"oid": "13311b522f4ef6a38f7f0e5bd327d81bbaac462d", "url": "https://github.com/apache/kafka/commit/13311b522f4ef6a38f7f0e5bd327d81bbaac462d", "message": "fix txn producer test", "committedDate": "2020-03-31T05:41:54Z", "type": "forcePushed"}, {"oid": "a81cdc482bb8068dd2dd04cb70b2e54d32315d8e", "url": "https://github.com/apache/kafka/commit/a81cdc482bb8068dd2dd04cb70b2e54d32315d8e", "message": "comment revers", "committedDate": "2020-03-31T05:49:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY2ODAzMg==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r400668032", "bodyText": "Extracting all the common parameters for easier test composition, and easier templating for the downgrade test, so that we don't need to carry these redundant messages around.", "author": "abbccdda", "createdAt": "2020-03-31T06:20:16Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -112,12 +112,21 @@\n     private static final int MAX_BLOCK_TIMEOUT = 1000;\n     private static final int REQUEST_TIMEOUT = 1000;\n     private static final long DEFAULT_RETRY_BACKOFF_MS = 100L;\n+\n+\n     private final String transactionalId = \"foobar\";\n     private final int transactionTimeoutMs = 1121;\n \n     private final String topic = \"test\";\n     private final TopicPartition tp0 = new TopicPartition(topic, 0);\n     private final TopicPartition tp1 = new TopicPartition(topic, 1);\n+    private final long producerId = 13131L;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY2ODQ1MA==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r400668450", "bodyText": "Refactor out the common prepareGroupMetadataCommit to simplify the test construction", "author": "abbccdda", "createdAt": "2020-03-31T06:21:31Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/TransactionManagerTest.java", "diffHunk": "@@ -2151,59 +2004,98 @@ public void shouldFailAbortIfAddOffsetsFailsWithFatalError() {\n \n     @Test\n     public void testSendOffsetsWithGroupMetadata() {\n-        final long pid = 13131L;\n-        final short epoch = 1;\n+        Map<TopicPartition, Errors> txnOffsetCommitResponse = new HashMap<>();\n+        txnOffsetCommitResponse.put(tp0, Errors.NONE);\n+        txnOffsetCommitResponse.put(tp1, Errors.COORDINATOR_LOAD_IN_PROGRESS);\n \n-        doInitTransactions(pid, epoch);\n+        TransactionalRequestResult addOffsetsResult = prepareGroupMetadataCommit(", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY2OTc0NQ==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r400669745", "bodyText": "Only side cleanups in this class", "author": "abbccdda", "createdAt": "2020-03-31T06:24:55Z", "path": "core/src/test/scala/unit/kafka/server/RequestQuotaTest.scala", "diffHunk": "@@ -60,7 +60,7 @@ class RequestQuotaTest extends BaseRequestTest {\n   private val smallQuotaProducerClientId = \"small-quota-producer-client\"\n   private val smallQuotaConsumerClientId = \"small-quota-consumer-client\"\n   private val brokerId: Integer = 0\n-  private var leaderNode: KafkaServer = null\n+  private var leaderNode: KafkaServer = _", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY3MjkzMQ==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r400672931", "bodyText": "Maybe I misunderstood this TODO here, but I suppose EOS-beta should only work with broker 2.5 or higher correct? This sentence is a bit weird @mjsax", "author": "abbccdda", "createdAt": "2020-03-31T06:33:23Z", "path": "tests/kafkatest/tests/streams/streams_broker_compatibility_test.py", "diffHunk": "@@ -29,7 +29,7 @@ class StreamsBrokerCompatibility(Test):\n     These tests validates that\n     - Streams works for older brokers 0.11 (or newer)\n     - Streams w/ EOS-alpha works for older brokers 0.11 (or newer)\n-    - (TODO) Streams w/ EOS-beta works for older brokers 2.5 (or newer)\n+    - Streams w/ EOS-beta works for older brokers 2.5 (or newer)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTI4NTAwMw==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r401285003", "bodyText": "Well, I hear you, but it's correct: We test Streams 2.6 against \"old\" broker 2.5 -- also note, that we will extend this test in the future and test Streams 2.7 against 2.5 and 2.6 brokers and so forth, ie, we test the current version against all older brokers that support eos-beta.\nDoes this make sense?", "author": "mjsax", "createdAt": "2020-04-01T00:09:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY3MjkzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMwOTg5NQ==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r401309895", "bodyText": "Oh I see that now.", "author": "abbccdda", "createdAt": "2020-04-01T01:44:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDY3MjkzMQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "098111e82755fa30e1a987a51805a760da011db3", "url": "https://github.com/apache/kafka/commit/098111e82755fa30e1a987a51805a760da011db3", "message": "fix tests", "committedDate": "2020-03-31T15:33:32Z", "type": "commit"}, {"oid": "098111e82755fa30e1a987a51805a760da011db3", "url": "https://github.com/apache/kafka/commit/098111e82755fa30e1a987a51805a760da011db3", "message": "fix tests", "committedDate": "2020-03-31T15:33:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTI4NTE2Nw==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r401285167", "bodyText": "nit: move logContext to its own line", "author": "mjsax", "createdAt": "2020-04-01T00:10:08Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java", "diffHunk": "@@ -510,18 +510,24 @@ private TransactionManager configureTransactionState(ProducerConfig config,\n \n         TransactionManager transactionManager = null;\n \n-        boolean userConfiguredIdempotence = config.originals().containsKey(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG);\n-        boolean userConfiguredTransactions = config.originals().containsKey(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n+        final boolean userConfiguredIdempotence = config.originals().containsKey(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG);\n+        final boolean userConfiguredTransactions = config.originals().containsKey(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n         if (userConfiguredTransactions && !userConfiguredIdempotence)\n             log.info(\"Overriding the default {} to true since {} is specified.\", ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,\n                     ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n \n         if (config.idempotenceEnabled()) {\n-            String transactionalId = config.getString(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n-            int transactionTimeoutMs = config.getInt(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG);\n-            long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);\n-            transactionManager = new TransactionManager(logContext, transactionalId, transactionTimeoutMs,\n-                    retryBackoffMs, apiVersions);\n+            final String transactionalId = config.getString(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n+            final int transactionTimeoutMs = config.getInt(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG);\n+            final long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);\n+            final boolean autoDowngradeTxnCommit = config.getBoolean(ProducerConfig.AUTO_DOWNGRADE_TXN_COMMIT);\n+            transactionManager = new TransactionManager(logContext,", "originalCommit": "098111e82755fa30e1a987a51805a760da011db3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTI4NTU4Mg==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r401285582", "bodyText": "is [not] supported", "author": "mjsax", "createdAt": "2020-04-01T00:11:38Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/ProducerConfig.java", "diffHunk": "@@ -258,6 +258,21 @@\n     public static final String SECURITY_PROVIDERS_CONFIG = SecurityConfig.SECURITY_PROVIDERS_CONFIG;\n     private static final String SECURITY_PROVIDERS_DOC = SecurityConfig.SECURITY_PROVIDERS_DOC;\n \n+    /**\n+     * <code>internal.auto.downgrade.txn.commit</code>\n+     * Whether or not the producer should automatically downgrade the transactional commit request when the new group metadata\n+     * feature is supported by the broker.", "originalCommit": "098111e82755fa30e1a987a51805a760da011db3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b0a4a0a2bf7f08a6f1fb7c1221118246f9180a36", "url": "https://github.com/apache/kafka/commit/b0a4a0a2bf7f08a6f1fb7c1221118246f9180a36", "message": "address comments", "committedDate": "2020-04-01T01:44:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjU0Nzk0MA==", "url": "https://github.com/apache/kafka/pull/8375#discussion_r402547940", "bodyText": "groupInstanceId field should never be null, I think we should check against Optional.empty().", "author": "guozhangwang", "createdAt": "2020-04-02T19:08:21Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/TxnOffsetCommitRequest.java", "diffHunk": "@@ -78,13 +88,36 @@ public Builder(final String transactionalId,\n                             .setMemberId(memberId)\n                             .setGenerationId(generationId)\n                             .setGroupInstanceId(groupInstanceId.orElse(null));\n+            this.autoDowngrade = autoDowngrade;\n         }\n \n         @Override\n         public TxnOffsetCommitRequest build(short version) {\n+            if (version < 3 && groupMetadataSet()) {\n+                if (autoDowngrade) {\n+                    log.trace(\"Downgrade the request by resetting group metadata fields: \" +\n+                                  \"[member.id:{}, generation.id:{}, group.instance.id:{}], because broker \" +\n+                                  \"only supports TxnOffsetCommit version {}. Need \" +\n+                                  \"v3 or newer to enable this feature\",\n+                        data.memberId(), data.generationId(), data.groupInstanceId(), version);\n+\n+                    data.setGenerationId(JoinGroupRequest.UNKNOWN_GENERATION_ID)\n+                        .setMemberId(JoinGroupRequest.UNKNOWN_MEMBER_ID)\n+                        .setGroupInstanceId(null);\n+                } else {\n+                    throw new UnsupportedVersionException(\"Broker unexpectedly \" +\n+                        \"doesn't support group metadata commit API on version \" + version);\n+                }\n+            }\n             return new TxnOffsetCommitRequest(data, version);\n         }\n \n+        private boolean groupMetadataSet() {\n+            return !data.memberId().equals(JoinGroupRequest.UNKNOWN_MEMBER_ID) ||\n+                       data.generationId() != JoinGroupRequest.UNKNOWN_GENERATION_ID ||\n+                       data.groupInstanceId() != null;", "originalCommit": "098111e82755fa30e1a987a51805a760da011db3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}