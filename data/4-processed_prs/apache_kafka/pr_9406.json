{"pr_number": 9406, "pr_title": "KAFKA-10520; Ensure transactional producers poll if leastLoadedNode not available with max.in.flight=1", "pr_createdAt": "2020-10-09T13:42:23Z", "pr_url": "https://github.com/apache/kafka/pull/9406", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r508473537", "bodyText": "Don't we loose the current nextRequestHandler when we end up in this branch?\nFor instance, if nextRequestHandler is a FindCoordinatorHandler and there a no nodes available, targetNode is null and coordinatorType is null as well so we end up here and poll. We don't do anything with nextRequestHandler and return so it is gone. I suppose that it is not an issue for FindCoordinatorHandler as a new one will be enqueued automatically when another TxnRequestHandler handler is processed and the coordinator is unknown.\nWe may want to push back nextRequestHandler to the queue with transactionManager.retry(nextRequestHandler) in oder to handle all the cases.\nI am not sure if that could really happen with any other TxnRequestHandler type though. What do you think?", "author": "dajac", "createdAt": "2020-10-20T12:51:42Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java", "diffHunk": "@@ -444,10 +444,20 @@ private boolean maybeSendAndPollTransactionalRequest() {\n         AbstractRequest.Builder<?> requestBuilder = nextRequestHandler.requestBuilder();\n         Node targetNode = null;\n         try {\n-            targetNode = awaitNodeReady(nextRequestHandler.coordinatorType());\n-            if (targetNode == null) {\n+            FindCoordinatorRequest.CoordinatorType coordinatorType = nextRequestHandler.coordinatorType();\n+            targetNode = coordinatorType != null ?\n+                    transactionManager.coordinator(coordinatorType) :\n+                    client.leastLoadedNode(time.milliseconds());\n+            if (targetNode != null) {\n+                awaitNodeReady(targetNode, coordinatorType);\n+            } else if (coordinatorType != null) {\n+                log.trace(\"Coordinator not known for {}, will retry {} after finding coordinator.\", coordinatorType, requestBuilder.apiKey());\n                 maybeFindCoordinatorAndRetry(nextRequestHandler);\n                 return true;\n+            } else {\n+                log.trace(\"No nodes available to send requests, polling until a node is ready.\");\n+                client.poll(retryBackoffMs, time.milliseconds());\n+                return true;", "originalCommit": "42097e99a84ecc4af8652562c521589679640415", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODU4MzUyOA==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r508583528", "bodyText": "@dajac Thanks for the review. As far as I can tell, nextRequestHandler returned by transactionManager.nextRequest would have retained the request in this case since it does a peek and removes the element only under certain conditions. I was trying to limit the amount of change to the minimal necessary to handle max.in.flight=1, do you think we should do more to look into the other cases?", "author": "rajinisivaram", "createdAt": "2020-10-20T14:58:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODYyNjk3NQ==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r508626975", "bodyText": "@rajinisivaram It seems that a non-null nextRequestHandler would have been removed from the queue: https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L872.\nI've got the impression that InitProducerIdHandler may hit that code path as well as it could have a null coordinatorType when the transaction id is not set (idempotent producer). I think that we could unit test this actually by reusing your testInitProducerIdWithMaxInFlightOne but without setting the transactional id. Should we add this test to be on the safe side?", "author": "dajac", "createdAt": "2020-10-20T15:42:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTA3OTkwNg==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509079906", "bodyText": "@dajac Sorry, that was my mistake. Updated code and added test.", "author": "rajinisivaram", "createdAt": "2020-10-21T08:17:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTIwNzY5Mg==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509207692", "bodyText": "Thanks. I will make another pass now.", "author": "dajac", "createdAt": "2020-10-21T11:41:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTA4MjI0Mw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509082243", "bodyText": "node != null Is this check necessary?", "author": "chia7712", "createdAt": "2020-10-21T08:20:53Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java", "diffHunk": "@@ -512,21 +523,15 @@ public boolean isRunning() {\n         return running;\n     }\n \n-    private Node awaitNodeReady(FindCoordinatorRequest.CoordinatorType coordinatorType) throws IOException {\n-        Node node = coordinatorType != null ?\n-                transactionManager.coordinator(coordinatorType) :\n-                client.leastLoadedNode(time.milliseconds());\n-\n+    private void awaitNodeReady(Node node, FindCoordinatorRequest.CoordinatorType coordinatorType) throws IOException {\n         if (node != null && NetworkClientUtils.awaitReady(client, node, time, requestTimeoutMs)) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE4OTQyOQ==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509189429", "bodyText": "No, we don't need it anymore, removed.", "author": "rajinisivaram", "createdAt": "2020-10-21T11:08:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTA4MjI0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTA5NTQ0NQ==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509095445", "bodyText": "How to deal with the non-ready targetNode after calling awaitNodeReady ?", "author": "chia7712", "createdAt": "2020-10-21T08:39:31Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java", "diffHunk": "@@ -444,10 +444,21 @@ private boolean maybeSendAndPollTransactionalRequest() {\n         AbstractRequest.Builder<?> requestBuilder = nextRequestHandler.requestBuilder();\n         Node targetNode = null;\n         try {\n-            targetNode = awaitNodeReady(nextRequestHandler.coordinatorType());\n-            if (targetNode == null) {\n+            FindCoordinatorRequest.CoordinatorType coordinatorType = nextRequestHandler.coordinatorType();\n+            targetNode = coordinatorType != null ?\n+                    transactionManager.coordinator(coordinatorType) :\n+                    client.leastLoadedNode(time.milliseconds());\n+            if (targetNode != null) {\n+                awaitNodeReady(targetNode, coordinatorType);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE5MDEyNg==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509190126", "bodyText": "@chia7712 Thanks for the review. Good point, added check to retry in that case, also added unit test.", "author": "rajinisivaram", "createdAt": "2020-10-21T11:09:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTA5NTQ0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTExNjg1Mw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509116853", "bodyText": "this new test passes on my local even though I revert the change of Sender.", "author": "chia7712", "createdAt": "2020-10-21T09:10:05Z", "path": "core/src/test/scala/integration/kafka/api/TransactionsWithMaxInFlightOneTest.scala", "diffHunk": "@@ -0,0 +1,131 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.api\n+\n+import java.util.Properties\n+\n+import kafka.integration.KafkaServerTestHarness\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import kafka.utils.TestUtils.consumeRecords\n+import org.apache.kafka.clients.consumer.KafkaConsumer\n+import org.apache.kafka.clients.producer.KafkaProducer\n+import org.junit.{After, Before, Test}\n+import org.junit.Assert.assertEquals\n+\n+import scala.collection.Seq\n+import scala.collection.mutable.Buffer\n+import scala.jdk.CollectionConverters._\n+\n+/**\n+ * This is used to test transactions with one broker and `max.in.flight.requests.per.connection=1`.\n+ * A single broker is used to verify edge cases where different requests are queued on the same connection.\n+ */\n+class TransactionsWithMaxInFlightOneTest extends KafkaServerTestHarness {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE5Mjc1Mg==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509192752", "bodyText": "Yes, the issue this PR fixes is a timing issue that the new unit tests catch, but it is unlikely that we hit it in integration tests. I added this integration test anyway to make sure the fix hasn't broken anything. I was in two minds about whether to check it in, but included anyway since I thought it may help catch regressions with max.in.flight=1 in future. Also, Jenkins builds on slower machines may occasionally hit timing windows we don't usually see otherwise. Don't mind removing if we think it is not worth the maintenance cost.", "author": "rajinisivaram", "createdAt": "2020-10-21T11:14:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTExNjg1Mw=="}], "type": "inlineReview"}, {"oid": "f68ac1adf1d5bc4b41e7c8fca41a700db9b1acc2", "url": "https://github.com/apache/kafka/commit/f68ac1adf1d5bc4b41e7c8fca41a700db9b1acc2", "message": "KAFKA-10520; Ensure transactional producers poll if leastLoadedNode not available with max.in.flight=1", "committedDate": "2020-10-21T11:07:31Z", "type": "commit"}, {"oid": "e8b3446d1edb2eb4069a1dcf4142168d61b241b6", "url": "https://github.com/apache/kafka/commit/e8b3446d1edb2eb4069a1dcf4142168d61b241b6", "message": "Address review comment", "committedDate": "2020-10-21T11:07:31Z", "type": "commit"}, {"oid": "3e36ffe76440f978f99c2a44dd975f90546879f8", "url": "https://github.com/apache/kafka/commit/3e36ffe76440f978f99c2a44dd975f90546879f8", "message": "Address review comments", "committedDate": "2020-10-21T11:07:32Z", "type": "commit"}, {"oid": "3e36ffe76440f978f99c2a44dd975f90546879f8", "url": "https://github.com/apache/kafka/commit/3e36ffe76440f978f99c2a44dd975f90546879f8", "message": "Address review comments", "committedDate": "2020-10-21T11:07:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI1NzI5Mw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509257293", "bodyText": "Looking at this branch again, sorry :). I was comparing it with the previous behavior and I have noticed that we would request a refresh of the metadata when the same conditions were met. That happened here:\n    private void maybeFindCoordinatorAndRetry(TransactionManager.TxnRequestHandler nextRequestHandler) {\n        if (nextRequestHandler.needsCoordinator()) {\n            transactionManager.lookupCoordinator(nextRequestHandler);\n        } else {\n            // For non-coordinator requests, sleep here to prevent a tight loop when no node is available\n            time.sleep(retryBackoffMs);\n            metadata.requestUpdate();\n        }\n\n        transactionManager.retry(nextRequestHandler);\n    }\n\nWhen no node is available and coordinatorType != null, we ended up in the else branch here. I wonder if not doing metadata.requestUpdate() in our new implementation could be problematic and I also wonder if we could just swap that time.sleep(retryBackoffMs) by client.poll(retryBackoffMs, time.milliseconds()) to achieve the same goal. The difference is that another metadata request would be sent in our particular case.\nHave you noticed this small difference?", "author": "dajac", "createdAt": "2020-10-21T13:01:08Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java", "diffHunk": "@@ -444,10 +444,25 @@ private boolean maybeSendAndPollTransactionalRequest() {\n         AbstractRequest.Builder<?> requestBuilder = nextRequestHandler.requestBuilder();\n         Node targetNode = null;\n         try {\n-            targetNode = awaitNodeReady(nextRequestHandler.coordinatorType());\n-            if (targetNode == null) {\n+            FindCoordinatorRequest.CoordinatorType coordinatorType = nextRequestHandler.coordinatorType();\n+            targetNode = coordinatorType != null ?\n+                    transactionManager.coordinator(coordinatorType) :\n+                    client.leastLoadedNode(time.milliseconds());\n+            if (targetNode != null) {\n+                if (!awaitNodeReady(targetNode, coordinatorType)) {\n+                    log.trace(\"Target node {} not ready within request timeout, will retry when node is ready.\", targetNode);\n+                    maybeFindCoordinatorAndRetry(nextRequestHandler);\n+                    return true;\n+                }\n+            } else if (coordinatorType != null) {\n+                log.trace(\"Coordinator not known for {}, will retry {} after finding coordinator.\", coordinatorType, requestBuilder.apiKey());\n                 maybeFindCoordinatorAndRetry(nextRequestHandler);\n                 return true;\n+            } else {\n+                log.trace(\"No nodes available to send requests, will poll and retry when until a node is ready.\");\n+                transactionManager.retry(nextRequestHandler);\n+                client.poll(retryBackoffMs, time.milliseconds());\n+                return true;", "originalCommit": "3e36ffe76440f978f99c2a44dd975f90546879f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI5MzQ0Mw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509293443", "bodyText": "@dajac Yes, I was thinking about this earlier when adding the retry. We get to this else path when leastLoadedNode is null. For the other cases, we would have taken one of the other paths, which retain existing behaviour (unless I missed something, again!) When least loaded node is null, the old behaviour didn't quite work because you have to poll to change that state. And you don't have anywhere to send metadata requests to. So just polling seemed to be sufficient for this case. What do you think?", "author": "rajinisivaram", "createdAt": "2020-10-21T13:42:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI1NzI5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1MzcxMg==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509453712", "bodyText": "I agree polling seems sufficient. We will still have an opportunity to refresh metadata if the current connection fails for some reason.", "author": "hachikuji", "createdAt": "2020-10-21T17:03:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI1NzI5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ5MjQ5Mw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509492493", "bodyText": "@rajinisivaram Yeah, I do agree. Polling seems sufficient in this case. Thanks for the clarification.", "author": "dajac", "createdAt": "2020-10-21T17:43:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI1NzI5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1NjUxNA==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509456514", "bodyText": "Wonder if we should consider adding max inflight behavior directly to MockClient. Seems like a notable difference from NetworkClient.", "author": "hachikuji", "createdAt": "2020-10-21T17:08:13Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java", "diffHunk": "@@ -2667,4 +2760,43 @@ private void assertFutureFailure(Future<?> future, Class<? extends Exception> ex\n         }\n     }\n \n+    private void createMockClientWithMaxFlightOneMetadataPending() {\n+        client = new MockClient(time, metadata) {", "originalCommit": "3e36ffe76440f978f99c2a44dd975f90546879f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAwOTMzMw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r510009333", "bodyText": "@hachikuji Thanks for reviewing and merging! I have opened https://issues.apache.org/jira/browse/KAFKA-10626 to add max.in.flight to MockClient.", "author": "rajinisivaram", "createdAt": "2020-10-22T09:19:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1NjUxNA=="}], "type": "inlineReview"}]}