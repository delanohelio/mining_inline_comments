{"pr_number": 9688, "pr_title": "KAFKA-10017: fix flaky EOS-beta upgrade test", "pr_createdAt": "2020-12-04T09:10:05Z", "pr_url": "https://github.com/apache/kafka/pull/9688", "timeline": [{"oid": "e94ce759a0ea0f9382fecb288cd105af287711eb", "url": "https://github.com/apache/kafka/commit/e94ce759a0ea0f9382fecb288cd105af287711eb", "message": "KAFKA-10017: fix flaky EOS-beta upgrade test", "committedDate": "2020-12-04T09:04:21Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0ODQyNg==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535948426", "bodyText": "Side cleanup", "author": "mjsax", "createdAt": "2020-12-04T09:14:31Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -105,8 +100,8 @@\n     public boolean injectError;\n \n     private static final int NUM_BROKERS = 3;\n-    private static final int MAX_POLL_INTERVAL_MS = 100 * 1000;\n-    private static final int MAX_WAIT_TIME_MS = 60 * 1000;\n+    private static final int MAX_POLL_INTERVAL_MS = (int) Duration.ofSeconds(100L).toMillis();\n+    private static final long MAX_WAIT_TIME_MS = Duration.ofMinutes(1L).toMillis();", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0ODg5MA==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535948890", "bodyText": "This punctuator was an attempt to stabilize the test, but without success. Removing it as this should be a proper fix now.", "author": "mjsax", "createdAt": "2020-12-04T09:15:11Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -152,27 +147,6 @@\n     private final AtomicInteger commitCounterClient2 = new AtomicInteger(-1);\n     private final AtomicInteger commitRequested = new AtomicInteger(0);\n \n-    // Note: this pattern only works when we just have a single instance running with a single thread\n-    // If we want to extend the test or reuse this CommitPunctuator we should tighten it up\n-    private final AtomicBoolean requestCommit = new AtomicBoolean(false);\n-    private static class CommitPunctuator implements Punctuator {", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0OTMxOQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535949319", "bodyText": "Added some more details/explanations and also renames a few variables below", "author": "mjsax", "createdAt": "2020-12-04T09:15:51Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -319,24 +293,26 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             //   p-2: 10 rec + C ---> 5 rec (pending)\n             //   p-3: 10 rec + C ---> 5 rec (pending)\n             // crash case: (we just assumes that we inject the error for p-0; in reality it might be a different partition)\n+            //             (we don't crash right away and write one record less)", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk0OTk2MA==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535949960", "bodyText": "This is the first fix: ie how we compute those keys.", "author": "mjsax", "createdAt": "2020-12-04T09:16:49Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -440,15 +419,18 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             waitForRunning(stateTransitions1);\n             waitForRunning(stateTransitions2);\n \n-            final Set<Long> committedKeys = mkSet(0L, 1L, 2L, 3L);\n+            final Set<Long> newlyCommittedKeys;", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MDUwMQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535950501", "bodyText": "This is the second fix: depending on task movement, we have different set of committed records.", "author": "mjsax", "createdAt": "2020-12-04T09:17:39Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -457,33 +439,46 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             // phase 6: (complete second batch of data; crash: let second client fail on commit)\n             // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n             //\n-            // stop case:\n-            //   p-0: 10 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-1: 10 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + C\n-            // crash case:\n-            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C ---> 5 rec + C\n-            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C ---> 5 rec + C\n-            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n-            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n+            // stop case: (both client commit regularly)\n+            //            (depending on the task movement in phase 5, we may or may not get newly committed data;\n+            //             we show the case for which p-2 and p-3 are newly committed below)\n+            //   p-0: 10 rec + C   +   5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C   +   5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C   +   5 rec     ---> 5 rec + C\n+            //   p-3: 10 rec + C   +   5 rec     ---> 5 rec + C\n+            // crash case: (second/alpha client fails and both TX are aborted)\n+            //             (first/beta client reprocessed the 10 records and commits TX)\n+            //   p-0: 10 rec + C   +   4 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C   +   5 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C   +   5 rec + C             ---> 5 rec + A + 5 rec + C\n+            //   p-3: 10 rec + C   +   5 rec + C             ---> 5 rec + A + 5 rec + C\n             commitCounterClient1.set(0);\n \n             if (!injectError) {\n-                final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade =\n-                    prepareData(15L, 20L, 0L, 1L, 2L, 3L);\n-                writeInputData(committedInputDataDuringUpgrade);\n+                final List<KeyValue<Long, Long>> finishSecondBatch = prepareData(15L, 20L, 0L, 1L, 2L, 3L);\n+                writeInputData(finishSecondBatch);\n \n+                final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = uncommittedInputDataBeforeFirstUpgrade", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODA2MzA5NQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r538063095", "bodyText": "Nice catch.\nReminds me though, why the second rebalance may not be deterministic in migrating tasks back? I thought our algorithm should produce deterministic results? cc @ableegoldman", "author": "guozhangwang", "createdAt": "2020-12-08T06:16:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MDUwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MTA3OQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535951079", "bodyText": "For this, we needed to preserve old uncommittedState further above.", "author": "mjsax", "createdAt": "2020-12-04T09:18:36Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -457,33 +439,46 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             // phase 6: (complete second batch of data; crash: let second client fail on commit)\n             // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n             //\n-            // stop case:\n-            //   p-0: 10 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-1: 10 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + C\n-            // crash case:\n-            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C ---> 5 rec + C\n-            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C ---> 5 rec + C\n-            //   p-2: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n-            //   p-3: 10 rec + C + 5 rec + C ---> 5 rec + A + 5 rec + C\n+            // stop case: (both client commit regularly)\n+            //            (depending on the task movement in phase 5, we may or may not get newly committed data;\n+            //             we show the case for which p-2 and p-3 are newly committed below)\n+            //   p-0: 10 rec + C   +   5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C   +   5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C   +   5 rec     ---> 5 rec + C\n+            //   p-3: 10 rec + C   +   5 rec     ---> 5 rec + C\n+            // crash case: (second/alpha client fails and both TX are aborted)\n+            //             (first/beta client reprocessed the 10 records and commits TX)\n+            //   p-0: 10 rec + C   +   4 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C   +   5 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C   +   5 rec + C             ---> 5 rec + A + 5 rec + C\n+            //   p-3: 10 rec + C   +   5 rec + C             ---> 5 rec + A + 5 rec + C\n             commitCounterClient1.set(0);\n \n             if (!injectError) {\n-                final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade =\n-                    prepareData(15L, 20L, 0L, 1L, 2L, 3L);\n-                writeInputData(committedInputDataDuringUpgrade);\n+                final List<KeyValue<Long, Long>> finishSecondBatch = prepareData(15L, 20L, 0L, 1L, 2L, 3L);\n+                writeInputData(finishSecondBatch);\n \n+                final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = uncommittedInputDataBeforeFirstUpgrade\n+                    .stream()\n+                    .filter(pair -> !keysFirstClientAlpha.contains(pair.key))\n+                    .filter(pair -> !newlyCommittedKeys.contains(pair.key))\n+                    .collect(Collectors.toList());\n+                committedInputDataDuringUpgrade.addAll(\n+                    finishSecondBatch\n+                );\n+\n+                expectedUncommittedResult.addAll(\n+                    computeExpectedResult(finishSecondBatch, uncommittedState)", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MTU5NQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535951595", "bodyText": "Similar fix as above: we compute those keys differently now.", "author": "mjsax", "createdAt": "2020-12-04T09:19:20Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -774,15 +769,18 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             waitForRunning(stateTransitions1);\n             waitForRunning(stateTransitions2);\n \n-            committedKeys.addAll(mkSet(0L, 1L, 2L, 3L));\n+            newlyCommittedKeys.clear();", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MTkzOA==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535951938", "bodyText": "Similar to above: we need to be more flexible (ie, depend on actual task movement)", "author": "mjsax", "createdAt": "2020-12-04T09:19:55Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -792,24 +790,35 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             // expected end state per output partition (C == COMMIT; A == ABORT; ---> indicate the changes):\n             //\n             // stop case:\n-            //   p-0: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-1: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-2: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-3: 10 rec + C + 5 rec + C + 5 rec + C + 5 rec + C ---> 5 rec + C\n+            //   p-0: 10 rec + C   +   5 rec + C + 5 rec + C   +   5 rec + C ---> 5 rec + C\n+            //   p-1: 10 rec + C   +   5 rec + C + 5 rec + C   +   5 rec + C ---> 5 rec + C\n+            //   p-2: 10 rec + C   +   5 rec + C + 5 rec + C   +   5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C   +   5 rec + C + 5 rec + C   +   5 rec + C ---> 5 rec + C\n             // crash case:  (we just assumes that we inject the error for p-2; in reality it might be a different partition)\n-            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C + 10 rec + A + 10 rec + C + 5 rec + C ---> 5 rec + C\n-            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 4 rec + A + 5 rec + C ---> 5 rec + C\n-            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C + 10 rec + C + 5 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-0: 10 rec + C   +   4 rec + A + 5 rec + C + 5 rec + C   +   10 rec + A + 10 rec + C   +   5 rec + C             ---> 5 rec + C\n+            //   p-1: 10 rec + C   +   5 rec + A + 5 rec + C + 5 rec + C   +   10 rec + A + 10 rec + C   +   5 rec + C             ---> 5 rec + C\n+            //   p-2: 10 rec + C   +   5 rec + C + 5 rec + A + 5 rec + C   +   10 rec + C                +   4 rec + A + 5 rec + C ---> 5 rec + C\n+            //   p-3: 10 rec + C   +   5 rec + C + 5 rec + A + 5 rec + C   +   10 rec + C                +   5 rec + A + 5 rec + C ---> 5 rec + C\n             commitCounterClient1.set(-1);\n             commitCounterClient2.set(-1);\n \n-            final List<KeyValue<Long, Long>> committedInputDataAfterUpgrade =\n+            final List<KeyValue<Long, Long>> finishLastBatch =\n                 prepareData(35L, 40L, 0L, 1L, 2L, 3L);\n-            writeInputData(committedInputDataAfterUpgrade);\n+            writeInputData(finishLastBatch);\n+\n+            final Set<Long> uncommittedKeys = mkSet(0L, 1L, 2L, 3L);\n+            uncommittedKeys.removeAll(keysSecondClientAlphaTwo);\n+            uncommittedKeys.removeAll(newlyCommittedKeys);\n+            final List<KeyValue<Long, Long>> committedInputDataDuringUpgrade = uncommittedInputDataBeforeSecondUpgrade", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMxOTA4Mw==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r536319083", "bodyText": "I'm guessing the root source of this all is a bad assumption that the assignment would be stable if a stable CLIENT_ID was used? I remember we discussed that back when you first wrote this test, I'm sorry for any misinformation I supplied based on my own assumption about how the CLIENT_ID would be used :/", "author": "ableegoldman", "createdAt": "2020-12-04T19:11:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MTkzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMzODkxMw==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r536338913", "bodyText": "Yes, the test assumed a more stable task->thread mapping during the assignment. But it turns out, that task assignment may \"flip\" (not sure about details)", "author": "mjsax", "createdAt": "2020-12-04T19:44:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MTkzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODA2MzU5MQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r538063591", "bodyText": "@ableegoldman is it related to the UUID randomness? If yes please ignore my other question above.", "author": "guozhangwang", "createdAt": "2020-12-08T06:17:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MTkzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODc1OTY0MQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r538759641", "bodyText": "Yes, I think so", "author": "ableegoldman", "createdAt": "2020-12-08T19:49:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MTkzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MjQ4MQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535952481", "bodyText": "I also increase the TX timeout from the to low default of 10 seconds, to avoid broker side TX-abort during the test.", "author": "mjsax", "createdAt": "2020-12-04T09:20:47Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -916,11 +917,12 @@ public void close() {\n         properties.put(StreamsConfig.CLIENT_ID_CONFIG, appDir);\n         properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, processingGuarantee);\n         properties.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, Long.MAX_VALUE);\n-        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.METADATA_MAX_AGE_CONFIG), \"1000\");\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.METADATA_MAX_AGE_CONFIG), Duration.ofSeconds(1L).toMillis());\n         properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG), \"earliest\");\n-        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), 5 * 1000);\n-        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG), 5 * 1000 - 1);\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG), (int) Duration.ofSeconds(5L).toMillis());\n+        properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG), (int) Duration.ofSeconds(5L).minusMillis(1L).toMillis());\n         properties.put(StreamsConfig.consumerPrefix(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG), MAX_POLL_INTERVAL_MS);\n+        properties.put(StreamsConfig.producerPrefix(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG), (int) Duration.ofMinutes(5L).toMillis());", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyMTU5NQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r536321595", "bodyText": "5 minutes seems kind of long, the whole test should take only a few minutes and it has 11 phases.  Would 1 minute be more reasonable? Or do we actually need this timeout to cover more than one or two phases?", "author": "ableegoldman", "createdAt": "2020-12-04T19:14:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MjQ4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMzOTQ5OQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r536339499", "bodyText": "Good catch -- I set to to 5 minutes during debugging (ie, setting breakpoints). 1 minutes should be enough.\n\nOr do we actually need this timeout to cover more than one or two phases?\n\nNot sure what you mean by this?", "author": "mjsax", "createdAt": "2020-12-04T19:45:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MjQ4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQwNjA1NQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r536406055", "bodyText": "Was just thinking about how long a. transaction might possibly be open. 1 minute SGTM", "author": "ableegoldman", "createdAt": "2020-12-04T21:55:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MjQ4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MjU5MQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535952591", "bodyText": "Increase wait time here, too.", "author": "mjsax", "createdAt": "2020-12-04T09:20:58Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -1019,7 +1021,8 @@ private void verifyUncommitted(final List<KeyValue<Long, Long>> expectedResult)\n                     )\n                 ),\n                 MULTI_PARTITION_OUTPUT_TOPIC,\n-                numberOfRecords\n+                numberOfRecords,\n+                MAX_WAIT_TIME_MS", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MzA4Mg==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535953082", "bodyText": "This is another fix (we did see some error for getting the state stores, too).", "author": "mjsax", "createdAt": "2020-12-04T09:21:45Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -1074,19 +1077,27 @@ private void addAllKeys(final Set<Long> allKeys, final List<KeyValue<Long, Long>\n     }\n \n     private Set<Long> keysFromInstance(final KafkaStreams streams) throws Exception {\n-        final ReadOnlyKeyValueStore<Long, Long> store = getStore(", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1MzI0Mg==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535953242", "bodyText": "Side cleanup", "author": "mjsax", "createdAt": "2020-12-04T09:21:58Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -1132,7 +1143,7 @@ public ErrorInjector(final Map<String, Object> configs) {\n         }\n \n         @Override\n-        public void commitTransaction() throws ProducerFencedException {\n+        public void commitTransaction() {", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTk1NDIwMQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r535954201", "bodyText": "We have cases when we pass in 0 and for this case, the old code did loop forever until the timeout hits and the test fails. Seems this logic was wrong from the beginning on an we should stop fetching if maxMessages <= 0 instead of looping forever.", "author": "mjsax", "createdAt": "2020-12-04T09:23:22Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java", "diffHunk": "@@ -1161,7 +1161,7 @@ public static void verifyKeyValueTimestamps(final Properties consumerConfig,\n     }\n \n     private static boolean continueConsuming(final int messagesConsumed, final int maxMessages) {\n-        return maxMessages <= 0 || messagesConsumed < maxMessages;\n+        return maxMessages > 0 && messagesConsumed < maxMessages;", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjMyODM0MQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r536328341", "bodyText": "Thanks for cleaning up the variable names \ud83d\ude42", "author": "ableegoldman", "createdAt": "2020-12-04T19:25:11Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -319,24 +293,26 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             //   p-2: 10 rec + C ---> 5 rec (pending)\n             //   p-3: 10 rec + C ---> 5 rec (pending)\n             // crash case: (we just assumes that we inject the error for p-0; in reality it might be a different partition)\n+            //             (we don't crash right away and write one record less)\n             //   p-0: 10 rec + C ---> 4 rec (pending)\n             //   p-1: 10 rec + C ---> 5 rec (pending)\n             //   p-2: 10 rec + C ---> 5 rec (pending)\n             //   p-3: 10 rec + C ---> 5 rec (pending)\n             final Set<Long> cleanKeys = mkSet(0L, 1L, 2L, 3L);\n-            final Set<Long> keyFilterFirstClient = keysFromInstance(streams1Alpha);\n-            final long potentiallyFirstFailingKey = keyFilterFirstClient.iterator().next();\n-            cleanKeys.remove(potentiallyFirstFailingKey);\n+            final Set<Long> keysFirstClientAlpha = keysFromInstance(streams1Alpha);\n+            final long firstFailingKeyForCrashCase = keysFirstClientAlpha.iterator().next();", "originalCommit": "e94ce759a0ea0f9382fecb288cd105af287711eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e64283cbbfbcc569b1cbbd52d936c3836f45fde0", "url": "https://github.com/apache/kafka/commit/e64283cbbfbcc569b1cbbd52d936c3836f45fde0", "message": "Github comment: reduce TX timeout", "committedDate": "2020-12-04T23:36:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODA2MjYxMA==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r538062610", "bodyText": "Are these changes intentional?", "author": "guozhangwang", "createdAt": "2020-12-08T06:14:54Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -540,18 +535,18 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             }\n \n             // 7. only for crash case:\n-            //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+            //     7a. restart the failed second client in eos-alpha mode and wait until rebalance stabilizes\n             //     7b. write third batch of input data\n             //         * fail the first (i.e., eos-beta) client during commit\n             //         * the eos-alpha client should not pickup the pending offsets\n             //         * verify uncommitted and committed result\n             //     7c. restart the first client in eos-beta mode and wait until rebalance stabilizes\n             //\n             // crash case:\n-            //   p-0: 10 rec + C + 4 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C\n-            //   p-1: 10 rec + C + 5 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C\n-            //   p-2: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C ---> 10 rec + C\n-            //   p-3: 10 rec + C + 5 rec + C + 5 rec + A + 5 rec + C ---> 10 rec + C\n+            //   p-0: 10 rec + C   +   4 rec + A + 5 rec + C + 5 rec + C ---> 10 rec + A + 10 rec + C", "originalCommit": "e64283cbbfbcc569b1cbbd52d936c3836f45fde0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODkyNjEyOA==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r538926128", "bodyText": "Yes. I wanted to improve the readability of the comment -- the additional blanks separate the the main phases of the test (each main phase write 10 records per partition that should eventually be committed).", "author": "mjsax", "createdAt": "2020-12-09T01:05:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODA2MjYxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODA2MjY1NA==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r538062654", "bodyText": "nit: second failed client?", "author": "guozhangwang", "createdAt": "2020-12-08T06:15:06Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosBetaUpgradeIntegrationTest.java", "diffHunk": "@@ -540,18 +535,18 @@ public void shouldUpgradeFromEosAlphaToEosBeta() throws Exception {\n             }\n \n             // 7. only for crash case:\n-            //     7a. restart the second client in eos-alpha mode and wait until rebalance stabilizes\n+            //     7a. restart the failed second client in eos-alpha mode and wait until rebalance stabilizes", "originalCommit": "e64283cbbfbcc569b1cbbd52d936c3836f45fde0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODc1Nzc0MQ==", "url": "https://github.com/apache/kafka/pull/9688#discussion_r538757741", "bodyText": "I think \"failed second client\" is correct. It's the 2nd client, which has failed, not the 2nd client to have failed (English is confusing \ud83d\ude23 )", "author": "ableegoldman", "createdAt": "2020-12-08T19:46:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODA2MjY1NA=="}], "type": "inlineReview"}, {"oid": "7e9d366764c808221965bab32abe36ba2a0b475c", "url": "https://github.com/apache/kafka/commit/7e9d366764c808221965bab32abe36ba2a0b475c", "message": "improve error message for debugging", "committedDate": "2020-12-09T01:20:48Z", "type": "commit"}]}