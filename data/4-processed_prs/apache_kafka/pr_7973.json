{"pr_number": 7973, "pr_title": "MINOR: Handle expandIsr in PartitionLockTest and ensure read threads not blocked on write", "pr_createdAt": "2020-01-16T15:29:42Z", "pr_url": "https://github.com/apache/kafka/pull/7973", "timeline": [{"oid": "babce59e894003d2149b9fc0ce2130709d07ce06", "url": "https://github.com/apache/kafka/commit/babce59e894003d2149b9fc0ce2130709d07ce06", "message": "MINOR: Handle expandIsr in PartitionLockTest and ensure read threads not blocked on write", "committedDate": "2020-01-16T15:12:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc5NzQ2OQ==", "url": "https://github.com/apache/kafka/pull/7973#discussion_r367797469", "bodyText": "This is just ensuring there is one call to updateFollowers with every append?", "author": "hachikuji", "createdAt": "2020-01-17T07:19:14Z", "path": "core/src/test/scala/unit/kafka/cluster/PartitionLockTest.scala", "diffHunk": "@@ -111,62 +111,75 @@ class PartitionLockTest extends Logging {\n \n     val future = scheduleShrinkIsr(active, mockTimeSleepMs = 10000)\n     TestUtils.waitUntilTrue(() => shrinkIsrSemaphore.hasQueuedThreads, \"shrinkIsr not invoked\")\n-    concurrentProduceFetch(numProducers, numReplicaFetchers, numRecordsPerProducer, appendSemaphore, Some(shrinkIsrSemaphore))\n+    concurrentProduceFetchWithWriteLock(appendSemaphore, shrinkIsrSemaphore)\n     active.set(false)\n     future.get(15, TimeUnit.SECONDS)\n   }\n \n-  private def concurrentProduceFetch(numProducers: Int,\n-                                     numReplicaFetchers: Int,\n-                                     numRecords: Int,\n-                                     appendSemaphore: Semaphore,\n-                                     shrinkIsrSemaphore: Option[Semaphore]): Unit = {\n-    val followerQueues = (0 until numReplicaFetchers).map(_ => new ArrayBlockingQueue[MemoryRecords](2))\n+  /**\n+   * Perform concurrent appends and replica fetch requests that don't require write lock to\n+   * update follower state. Release sufficient append permits to complete all except one append.\n+   * Verify that follower state updates complete even though an append holding read lock is in progress.\n+   * Then release the permit for the final append and verify that all appends and follower updates complete.\n+   */\n+  private def concurrentProduceFetchWithReadLockOnly(appendSemaphore: Semaphore): Unit = {\n+    val appendFutures = scheduleAppends()\n+    val stateUpdateFutures = scheduleUpdateFollowers(numProducers * numRecordsPerProducer - 1)\n+\n+    appendSemaphore.release(numProducers * numRecordsPerProducer - 1)\n+    stateUpdateFutures.foreach(_.get(15, TimeUnit.SECONDS))\n+\n+    appendSemaphore.release(1)\n+    scheduleUpdateFollowers(1).foreach(_.get(15, TimeUnit.SECONDS))", "originalCommit": "babce59e894003d2149b9fc0ce2130709d07ce06", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzg1NjU4MQ==", "url": "https://github.com/apache/kafka/pull/7973#discussion_r367856581", "bodyText": "yes, it isn't really necessary for the test, but kept it anyway and added a comment.", "author": "rajinisivaram", "createdAt": "2020-01-17T10:04:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc5NzQ2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc5OTI2MQ==", "url": "https://github.com/apache/kafka/pull/7973#discussion_r367799261", "bodyText": "nit: would be nice to be consistent on the usage of class fields. This wouldn't work if the passed semaphore wasn't the class field since that is what we used when building the log. Maybe we can drop the parameter?", "author": "hachikuji", "createdAt": "2020-01-17T07:27:03Z", "path": "core/src/test/scala/unit/kafka/cluster/PartitionLockTest.scala", "diffHunk": "@@ -111,62 +111,75 @@ class PartitionLockTest extends Logging {\n \n     val future = scheduleShrinkIsr(active, mockTimeSleepMs = 10000)\n     TestUtils.waitUntilTrue(() => shrinkIsrSemaphore.hasQueuedThreads, \"shrinkIsr not invoked\")\n-    concurrentProduceFetch(numProducers, numReplicaFetchers, numRecordsPerProducer, appendSemaphore, Some(shrinkIsrSemaphore))\n+    concurrentProduceFetchWithWriteLock(appendSemaphore, shrinkIsrSemaphore)\n     active.set(false)\n     future.get(15, TimeUnit.SECONDS)\n   }\n \n-  private def concurrentProduceFetch(numProducers: Int,\n-                                     numReplicaFetchers: Int,\n-                                     numRecords: Int,\n-                                     appendSemaphore: Semaphore,\n-                                     shrinkIsrSemaphore: Option[Semaphore]): Unit = {\n-    val followerQueues = (0 until numReplicaFetchers).map(_ => new ArrayBlockingQueue[MemoryRecords](2))\n+  /**\n+   * Perform concurrent appends and replica fetch requests that don't require write lock to\n+   * update follower state. Release sufficient append permits to complete all except one append.\n+   * Verify that follower state updates complete even though an append holding read lock is in progress.\n+   * Then release the permit for the final append and verify that all appends and follower updates complete.\n+   */\n+  private def concurrentProduceFetchWithReadLockOnly(appendSemaphore: Semaphore): Unit = {", "originalCommit": "babce59e894003d2149b9fc0ce2130709d07ce06", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzgwMDk2MA==", "url": "https://github.com/apache/kafka/pull/7973#discussion_r367800960", "bodyText": "Just checking my understanding, but it seems there's no need to do this after the shrink semaphore is released. If we did it before, then we could assert that the append futures are blocked just like the update follower futures.", "author": "hachikuji", "createdAt": "2020-01-17T07:34:31Z", "path": "core/src/test/scala/unit/kafka/cluster/PartitionLockTest.scala", "diffHunk": "@@ -111,62 +111,75 @@ class PartitionLockTest extends Logging {\n \n     val future = scheduleShrinkIsr(active, mockTimeSleepMs = 10000)\n     TestUtils.waitUntilTrue(() => shrinkIsrSemaphore.hasQueuedThreads, \"shrinkIsr not invoked\")\n-    concurrentProduceFetch(numProducers, numReplicaFetchers, numRecordsPerProducer, appendSemaphore, Some(shrinkIsrSemaphore))\n+    concurrentProduceFetchWithWriteLock(appendSemaphore, shrinkIsrSemaphore)\n     active.set(false)\n     future.get(15, TimeUnit.SECONDS)\n   }\n \n-  private def concurrentProduceFetch(numProducers: Int,\n-                                     numReplicaFetchers: Int,\n-                                     numRecords: Int,\n-                                     appendSemaphore: Semaphore,\n-                                     shrinkIsrSemaphore: Option[Semaphore]): Unit = {\n-    val followerQueues = (0 until numReplicaFetchers).map(_ => new ArrayBlockingQueue[MemoryRecords](2))\n+  /**\n+   * Perform concurrent appends and replica fetch requests that don't require write lock to\n+   * update follower state. Release sufficient append permits to complete all except one append.\n+   * Verify that follower state updates complete even though an append holding read lock is in progress.\n+   * Then release the permit for the final append and verify that all appends and follower updates complete.\n+   */\n+  private def concurrentProduceFetchWithReadLockOnly(appendSemaphore: Semaphore): Unit = {\n+    val appendFutures = scheduleAppends()\n+    val stateUpdateFutures = scheduleUpdateFollowers(numProducers * numRecordsPerProducer - 1)\n+\n+    appendSemaphore.release(numProducers * numRecordsPerProducer - 1)\n+    stateUpdateFutures.foreach(_.get(15, TimeUnit.SECONDS))\n+\n+    appendSemaphore.release(1)\n+    scheduleUpdateFollowers(1).foreach(_.get(15, TimeUnit.SECONDS))\n+    appendFutures.foreach(_.get(15, TimeUnit.SECONDS))\n+  }\n+\n+  /**\n+   * Perform concurrent appends and replica fetch requests that may require write lock to update\n+   * follower state. Threads waiting for write lock to update follower state while append thread is\n+   * holding read lock will prevent other threads acquiring the read or write lock. So release sufficient\n+   * permits for all appends to complete before verifying state updates.\n+   */\n+  private def concurrentProduceFetchWithWriteLock(appendSemaphore: Semaphore,\n+                                                  shrinkIsrSemaphore: Semaphore): Unit = {\n+\n+    val appendFutures = scheduleAppends()\n+    val stateUpdateFutures = scheduleUpdateFollowers(numProducers * numRecordsPerProducer)\n+\n+    assertFalse(stateUpdateFutures.exists(_.isDone))\n+    shrinkIsrSemaphore.release()\n+    appendSemaphore.release(numProducers * numRecordsPerProducer)", "originalCommit": "babce59e894003d2149b9fc0ce2130709d07ce06", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzg1NjczMA==", "url": "https://github.com/apache/kafka/pull/7973#discussion_r367856730", "bodyText": "Good idea, updated.", "author": "rajinisivaram", "createdAt": "2020-01-17T10:04:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzgwMDk2MA=="}], "type": "inlineReview"}, {"oid": "8edfe93407704a21ce7c286952e6dfe107c448a8", "url": "https://github.com/apache/kafka/commit/8edfe93407704a21ce7c286952e6dfe107c448a8", "message": "Address review comments", "committedDate": "2020-01-17T09:59:30Z", "type": "commit"}]}