{"pr_number": 8691, "pr_title": "KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter", "pr_createdAt": "2020-05-18T23:42:39Z", "pr_url": "https://github.com/apache/kafka/pull/8691", "timeline": [{"oid": "523243313c44438a9b8f0ec44757abf0066e49c0", "url": "https://github.com/apache/kafka/commit/523243313c44438a9b8f0ec44757abf0066e49c0", "message": "KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter", "committedDate": "2020-05-13T01:25:21Z", "type": "commit"}, {"oid": "82c0a0d1cc5e627f7c03e6d56e82697f9424a0a6", "url": "https://github.com/apache/kafka/commit/82c0a0d1cc5e627f7c03e6d56e82697f9424a0a6", "message": "add changes to connect as part of KIP 606 implementation", "committedDate": "2020-05-13T16:21:33Z", "type": "commit"}, {"oid": "5d388cf2244a9877a0bca1c3d843b27a092d99a3", "url": "https://github.com/apache/kafka/commit/5d388cf2244a9877a0bca1c3d843b27a092d99a3", "message": "fix string constant", "committedDate": "2020-05-13T19:09:45Z", "type": "commit"}, {"oid": "92d6389b97652d81ba6d74f5044462ee0172adea", "url": "https://github.com/apache/kafka/commit/92d6389b97652d81ba6d74f5044462ee0172adea", "message": "Changes to address comments", "committedDate": "2020-05-13T23:50:27Z", "type": "commit"}, {"oid": "e8938501520273a42353cddcb30b5a7acb2a0f27", "url": "https://github.com/apache/kafka/commit/e8938501520273a42353cddcb30b5a7acb2a0f27", "message": "Fix a issue when setting group id", "committedDate": "2020-05-14T02:09:10Z", "type": "commit"}, {"oid": "2b36bc6d901f04e4820974ab019a0fa73b8eaf7f", "url": "https://github.com/apache/kafka/commit/2b36bc6d901f04e4820974ab019a0fa73b8eaf7f", "message": "use group.id from original config when pass connect.group.id to client", "committedDate": "2020-05-14T19:14:52Z", "type": "commit"}, {"oid": "24bc78ed7c859ac603884c7bdffb7438f1b96034", "url": "https://github.com/apache/kafka/commit/24bc78ed7c859ac603884c7bdffb7438f1b96034", "message": "remove redundant call, add more unit test", "committedDate": "2020-05-14T21:23:11Z", "type": "commit"}, {"oid": "65195e1592281054bcf8a9e9c4068e9082e58ad6", "url": "https://github.com/apache/kafka/commit/65195e1592281054bcf8a9e9c4068e9082e58ad6", "message": "More changes to address code review comments", "committedDate": "2020-05-15T22:05:08Z", "type": "commit"}, {"oid": "9511de85dddfd619ebb2a65156674c7aca399bba", "url": "https://github.com/apache/kafka/commit/9511de85dddfd619ebb2a65156674c7aca399bba", "message": "More changes to address code review comments", "committedDate": "2020-05-15T22:22:40Z", "type": "commit"}, {"oid": "4964aef267adf0406f4a8982bc95c202b61bc8f4", "url": "https://github.com/apache/kafka/commit/4964aef267adf0406f4a8982bc95c202b61bc8f4", "message": "More changes to address code review coments", "committedDate": "2020-05-16T02:09:30Z", "type": "commit"}, {"oid": "8fd4ef53240a561ec4cbdc5dbd69cb3fc988fe28", "url": "https://github.com/apache/kafka/commit/8fd4ef53240a561ec4cbdc5dbd69cb3fc988fe28", "message": "More changes to address code review coments", "committedDate": "2020-05-16T02:12:09Z", "type": "commit"}, {"oid": "69e4b7c938cae4771a3532d5ed397935f6978665", "url": "https://github.com/apache/kafka/commit/69e4b7c938cae4771a3532d5ed397935f6978665", "message": "add an integration test, strip off metrics.context from metrics context", "committedDate": "2020-05-18T04:01:10Z", "type": "commit"}, {"oid": "0e1a5b6ba37fedf5a5e48256d6a8fb713b888c43", "url": "https://github.com/apache/kafka/commit/0e1a5b6ba37fedf5a5e48256d6a8fb713b888c43", "message": "More changes to address PR review", "committedDate": "2020-05-18T19:49:56Z", "type": "commit"}, {"oid": "386a5da2dad688648ec7843722e8cf683d01fee6", "url": "https://github.com/apache/kafka/commit/386a5da2dad688648ec7843722e8cf683d01fee6", "message": "Remove support of reading metric context properties for broker", "committedDate": "2020-05-18T21:30:09Z", "type": "commit"}, {"oid": "6005c9acb6c6803e41af9cc4bf9a69cfa66b0768", "url": "https://github.com/apache/kafka/commit/6005c9acb6c6803e41af9cc4bf9a69cfa66b0768", "message": "KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter\n\nadd changes to connect as part of KIP 606 implementation", "committedDate": "2020-05-19T16:31:56Z", "type": "commit"}, {"oid": "6005c9acb6c6803e41af9cc4bf9a69cfa66b0768", "url": "https://github.com/apache/kafka/commit/6005c9acb6c6803e41af9cc4bf9a69cfa66b0768", "message": "KAFKA-9960: implement KIP-606 to add metadata context to MetricsReporter\n\nadd changes to connect as part of KIP 606 implementation", "committedDate": "2020-05-19T16:31:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MTI5OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426971298", "bodyText": "I don't think the KIP mentioned this kafka.connect.mirror metrics context. It's probably worthwhile to update the KIP and then notify the vote thread of the minor change noticed during implementation.", "author": "rhauch", "createdAt": "2020-05-19T01:00:50Z", "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorConnectorConfig.java", "diffHunk": "@@ -270,9 +272,15 @@ Duration adminTimeout() {\n     List<MetricsReporter> metricsReporters() {\n         List<MetricsReporter> reporters = getConfiguredInstances(\n                 CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MetricsReporter.class);\n-        JmxReporter jmxReporter = new JmxReporter(\"kafka.connect.mirror\");\n+        JmxReporter jmxReporter = new JmxReporter();\n         jmxReporter.configure(this.originals());\n         reporters.add(jmxReporter);\n+        MetricsContext metricsContext = new KafkaMetricsContext(\"kafka.connect.mirror\");", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM1Mjk1MQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428352951", "bodyText": "the KIP mentions that we are deprecating the jmx prefix directly on the JmxReporter, and instead are passing it via the metrics context as the _namespace parameter. This doesn't change the prefix or how they are exposed in jmx.", "author": "xvrl", "createdAt": "2020-05-20T22:54:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MTI5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MjUzOA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426972538", "bodyText": "Do we need to modify the KafkaOffsetBackingStore() constructor? The ConnectUtils.lookupKafkaClusterId(...) can be called with the WorkerConfig (which is the parent class of DistributedConfig) passed to it via the configure(...) method, so couldn't the configure(...) method call the lookup method?\nThis may seem minor, but it follows the existing pattern for this class.", "author": "rhauch", "createdAt": "2020-05-19T01:05:19Z", "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMaker.java", "diffHunk": "@@ -233,17 +233,18 @@ private void addHerder(SourceAndTarget sourceAndTarget) {\n         plugins.compareAndSwapWithDelegatingLoader();\n         DistributedConfig distributedConfig = new DistributedConfig(workerProps);\n         String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(distributedConfig);\n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(distributedConfig);", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMTczOA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428201738", "bodyText": "Removed clusterId from KafkaOffsetBackingStore constructor.", "author": "xiaodongdu", "createdAt": "2020-05-20T17:55:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MjUzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODI1NTU5OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428255598", "bodyText": "Get kafkaClusterId from ConnectUtils.lookupKafkaClusterId in configure(...) of KafkaOffsetBackingStore", "author": "xiaodongdu", "createdAt": "2020-05-20T19:25:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MjUzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3Mjg5OQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426972899", "bodyText": "Could the KafkaConfigBackingStore(...) get the cluster ID from the distributedConfig? One of the reasons why we pass the whole worker config to the constructor is so that we don't have to always modify the constructor to pass in additional information that can be derived from the worker config.", "author": "rhauch", "createdAt": "2020-05-19T01:06:35Z", "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMaker.java", "diffHunk": "@@ -233,17 +233,18 @@ private void addHerder(SourceAndTarget sourceAndTarget) {\n         plugins.compareAndSwapWithDelegatingLoader();\n         DistributedConfig distributedConfig = new DistributedConfig(workerProps);\n         String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(distributedConfig);\n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(distributedConfig);\n-        Worker worker = new Worker(workerId, time, plugins, distributedConfig, offsetBackingStore, CLIENT_CONFIG_OVERRIDE_POLICY);\n+        Worker worker = new Worker(workerId, time, plugins, distributedConfig, offsetBackingStore, CLIENT_CONFIG_OVERRIDE_POLICY, kafkaClusterId);\n         WorkerConfigTransformer configTransformer = worker.configTransformer();\n         Converter internalValueConverter = worker.getInternalValueConverter();\n-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n+        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter, kafkaClusterId);\n         statusBackingStore.configure(distributedConfig);\n         ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(\n                 internalValueConverter,\n                 distributedConfig,\n-                configTransformer);\n+                configTransformer,\n+                kafkaClusterId);", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMjAxNg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428202016", "bodyText": "Removed clusterId from KafkaConfigBackingStore constructor.", "author": "xiaodongdu", "createdAt": "2020-05-20T17:56:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3Mjg5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzE5Ng==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973196", "bodyText": "Could the KafkaStatusBackingStore(...) get the cluster ID from the distributedConfig passed into the configure(...) method, similar to the KafkaOffsetBackingStore?", "author": "rhauch", "createdAt": "2020-05-19T01:07:45Z", "path": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMaker.java", "diffHunk": "@@ -233,17 +233,18 @@ private void addHerder(SourceAndTarget sourceAndTarget) {\n         plugins.compareAndSwapWithDelegatingLoader();\n         DistributedConfig distributedConfig = new DistributedConfig(workerProps);\n         String kafkaClusterId = ConnectUtils.lookupKafkaClusterId(distributedConfig);\n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(distributedConfig);\n-        Worker worker = new Worker(workerId, time, plugins, distributedConfig, offsetBackingStore, CLIENT_CONFIG_OVERRIDE_POLICY);\n+        Worker worker = new Worker(workerId, time, plugins, distributedConfig, offsetBackingStore, CLIENT_CONFIG_OVERRIDE_POLICY, kafkaClusterId);\n         WorkerConfigTransformer configTransformer = worker.configTransformer();\n         Converter internalValueConverter = worker.getInternalValueConverter();\n-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n+        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter, kafkaClusterId);\n         statusBackingStore.configure(distributedConfig);", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMjI3MA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428202270", "bodyText": "Removed clusterId from KafkaStatusBackingStore constructor", "author": "xiaodongdu", "createdAt": "2020-05-20T17:56:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzE5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzQwNQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973405", "bodyText": "Same comment here as in MirrorMaker: the backing store's configure(...) method could get the Kafka cluster ID directly from the worker config.", "author": "rhauch", "createdAt": "2020-05-19T01:08:37Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java", "diffHunk": "@@ -101,24 +101,25 @@ public Connect startConnect(Map<String, String> workerProps) {\n         URI advertisedUrl = rest.advertisedUrl();\n         String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n \n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMjUzMg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428202532", "bodyText": "Removed clusterId from KafkaOffsetBackingStore constructor", "author": "xiaodongdu", "createdAt": "2020-05-20T17:57:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzQwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzUzOQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973539", "bodyText": "Same comment here as in MirrorMaker: the worker's constructor could get the Kafka cluster ID directly from the worker config.", "author": "rhauch", "createdAt": "2020-05-19T01:09:06Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java", "diffHunk": "@@ -101,24 +101,25 @@ public Connect startConnect(Map<String, String> workerProps) {\n         URI advertisedUrl = rest.advertisedUrl();\n         String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n \n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(config);\n \n         ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                 config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                 config, ConnectorClientConfigOverridePolicy.class);\n \n-        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy);\n+        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy, kafkaClusterId);", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMjc0Mg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428202742", "bodyText": "Removed clusterId from Worker constructor.", "author": "xiaodongdu", "createdAt": "2020-05-20T17:57:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzUzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzYwNQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973605", "bodyText": "Same comment here as in MirrorMaker: the backing store's constructor could get the Kafka cluster ID directly from the worker config.", "author": "rhauch", "createdAt": "2020-05-19T01:09:19Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java", "diffHunk": "@@ -101,24 +101,25 @@ public Connect startConnect(Map<String, String> workerProps) {\n         URI advertisedUrl = rest.advertisedUrl();\n         String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n \n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(config);\n \n         ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                 config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                 config, ConnectorClientConfigOverridePolicy.class);\n \n-        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy);\n+        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy, kafkaClusterId);\n         WorkerConfigTransformer configTransformer = worker.configTransformer();\n \n         Converter internalValueConverter = worker.getInternalValueConverter();\n-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n+        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter, kafkaClusterId);", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMzAwOQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428203009", "bodyText": "Removed clusterId from KafkaStatusBackingStore constructor.", "author": "xiaodongdu", "createdAt": "2020-05-20T17:58:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzYwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzY4Ng==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973686", "bodyText": "Same comment here as in MirrorMaker: the backing store's constructor could get the Kafka cluster ID directly from the worker config.", "author": "rhauch", "createdAt": "2020-05-19T01:09:38Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectDistributed.java", "diffHunk": "@@ -101,24 +101,25 @@ public Connect startConnect(Map<String, String> workerProps) {\n         URI advertisedUrl = rest.advertisedUrl();\n         String workerId = advertisedUrl.getHost() + \":\" + advertisedUrl.getPort();\n \n-        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore();\n+        KafkaOffsetBackingStore offsetBackingStore = new KafkaOffsetBackingStore(kafkaClusterId);\n         offsetBackingStore.configure(config);\n \n         ConnectorClientConfigOverridePolicy connectorClientConfigOverridePolicy = plugins.newPlugin(\n                 config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                 config, ConnectorClientConfigOverridePolicy.class);\n \n-        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy);\n+        Worker worker = new Worker(workerId, time, plugins, config, offsetBackingStore, connectorClientConfigOverridePolicy, kafkaClusterId);\n         WorkerConfigTransformer configTransformer = worker.configTransformer();\n \n         Converter internalValueConverter = worker.getInternalValueConverter();\n-        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter);\n+        StatusBackingStore statusBackingStore = new KafkaStatusBackingStore(time, internalValueConverter, kafkaClusterId);\n         statusBackingStore.configure(config);\n \n         ConfigBackingStore configBackingStore = new KafkaConfigBackingStore(\n                 internalValueConverter,\n                 config,\n-                configTransformer);\n+                configTransformer,\n+                kafkaClusterId);", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMzM2OQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428203369", "bodyText": "Removed clusterId from back store constructor.", "author": "xiaodongdu", "createdAt": "2020-05-20T17:58:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzY4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzczOA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426973738", "bodyText": "Same comment here as in MirrorMaker: the worker's constructor could get the Kafka cluster ID directly from the worker config.", "author": "rhauch", "createdAt": "2020-05-19T01:09:54Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/cli/ConnectStandalone.java", "diffHunk": "@@ -93,7 +93,7 @@ public static void main(String[] args) {\n                 config.getString(WorkerConfig.CONNECTOR_CLIENT_POLICY_CLASS_CONFIG),\n                 config, ConnectorClientConfigOverridePolicy.class);\n             Worker worker = new Worker(workerId, time, plugins, config, new FileOffsetBackingStore(),\n-                                       connectorClientConfigOverridePolicy);\n+                                       connectorClientConfigOverridePolicy, kafkaClusterId);", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMzYwMA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428203600", "bodyText": "Removed clusterId from Worker constructor.", "author": "xiaodongdu", "createdAt": "2020-05-20T17:58:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3MzczOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU2NA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r426974564", "bodyText": "The Kafka cluster ID is passed into the constructor, but is this supposed to represent the Connect cluster ID or the Kafka cluster ID? Since this is in Connect code, without a context we'd assume it was the Connect cluster ID.", "author": "rhauch", "createdAt": "2020-05-19T01:12:46Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/Worker.java", "diffHunk": "@@ -92,6 +93,7 @@\n     private final ExecutorService executor;\n     private final Time time;\n     private final String workerId;\n+    private final String clusterId;", "originalCommit": "386a5da2dad688648ec7843722e8cf683d01fee6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwMzc4NA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428203784", "bodyText": "Removed clusterId from Worker constructor.", "author": "xiaodongdu", "createdAt": "2020-05-20T17:59:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIwNTIzOA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428205238", "bodyText": "I'm still keeping clusterId as a class variable in Worker, since we are using clusterId in other method of this class. We are getting clusterId from ConnectUtils.lookupKafkaClusterId inside Worker constructor and keep it as a class variable value.", "author": "xiaodongdu", "createdAt": "2020-05-20T18:01:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY2ODIyNA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430668224", "bodyText": "@xiaodongdu, I was not suggesting getting rid of the field. It's fine to have a new field, but we should call the field kafkaClusterId rather than clusterId since the latter could be misinterpreted to mean the Connect cluster ID.", "author": "rhauch", "createdAt": "2020-05-26T19:49:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMDgzMA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430700830", "bodyText": "Changed name to kafkaClusterId", "author": "xiaodongdu", "createdAt": "2020-05-26T20:52:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU2NA=="}], "type": "inlineReview"}, {"oid": "d78a1e0e6085353e345e9198058a308a6925bd1d", "url": "https://github.com/apache/kafka/commit/d78a1e0e6085353e345e9198058a308a6925bd1d", "message": "Remove cluster id from a few constructors and use utility method to get cluster id", "committedDate": "2020-05-20T15:51:05Z", "type": "commit"}, {"oid": "2484d7123701499a8abb94d40a6dae8187859718", "url": "https://github.com/apache/kafka/commit/2484d7123701499a8abb94d40a6dae8187859718", "message": "Merge branch 'kafka-9960-kip-606' of github.com:xiaodongdu/kafka into kafka-9960-kip-606", "committedDate": "2020-05-20T17:50:02Z", "type": "commit"}, {"oid": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "url": "https://github.com/apache/kafka/commit/85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "message": "remove clusterId from WorkGroupMember constructor", "committedDate": "2020-05-20T19:22:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2MDU1NQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r428760555", "bodyText": "Use putIfAbsent to avoid silently overwriting over labels set upstream.", "author": "rnpridgeon", "createdAt": "2020-05-21T16:16:23Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/KafkaMetricsContext.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A implementation of MetricsContext, it encapsulates required metrics context properties for Kafka services and clients\n+ */\n+public class KafkaMetricsContext implements MetricsContext {\n+    /**\n+     * Client or Service's metadata map.\n+     */\n+    private Map<String, String> metadata = new HashMap<>();\n+\n+    /**\n+     * Create a MetricsContext with namespace, no service or client properties\n+     * @param namespace value for _namespace key\n+     */\n+    public KafkaMetricsContext(String namespace) {\n+        this(namespace, new HashMap<>());\n+    }\n+\n+    /**\n+     * Create a MetricsContext with namespace, service or client properties\n+     * @param namespace value for _namespace key\n+     * @param metadata  metadata additional entries to add to the context.\n+     *                  values will be converted to string using Object.toString()\n+     */\n+    public KafkaMetricsContext(String namespace, Map<String, ?> metadata) {\n+        this.metadata.put(MetricsContext.NAMESPACE, namespace);\n+        metadata.forEach((key, value) -> this.metadata.put(key, value.toString()));", "originalCommit": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM2NjgzNg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429366836", "bodyText": "I think we it's ok for the component that owns the reporter to take precedence over the labels passed from upstream. We did not specify the behavior in the KIP, so implementations should use namespacing of labels to avoid this. If in practice we find this behavior is less desirable, we can file a follow-on KIP, since the interface is till evolving.", "author": "xvrl", "createdAt": "2020-05-22T17:21:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2MDU1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM3MDg4OQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429370889", "bodyText": "Mostly I'm concerned about the case where some composite may share similar labels to the underlying client it manages. If we allow the downstream client to overwrite such a label we will lose a portion of the upstream components context.", "author": "rnpridgeon", "createdAt": "2020-05-22T17:30:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2MDU1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzMjk5Nw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429432997", "bodyText": "the client currently only injects the labels passed in via client properties, so that wouldn't happen", "author": "xvrl", "createdAt": "2020-05-22T20:06:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc2MDU1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIxNjgxMw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429216813", "bodyText": "Maybe it would be helpful to add CONNECT_VERSION as well.", "author": "rnpridgeon", "createdAt": "2020-05-22T12:27:59Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java", "diffHunk": "@@ -16,19 +16,24 @@\n  */\n package org.apache.kafka.connect.util;\n \n+import org.apache.kafka.clients.CommonClientConfigs;\n import org.apache.kafka.clients.admin.Admin;\n import org.apache.kafka.common.KafkaFuture;\n import org.apache.kafka.common.InvalidRecordException;\n import org.apache.kafka.common.record.RecordBatch;\n import org.apache.kafka.connect.errors.ConnectException;\n import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.runtime.distributed.DistributedConfig;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.util.Map;\n import java.util.concurrent.ExecutionException;\n \n public final class ConnectUtils {\n     private static final Logger log = LoggerFactory.getLogger(ConnectUtils.class);\n+    public static final String CONNECT_KAFKA_CLUSTER_ID = \"connect.kafka.cluster.id\";\n+    public static final String CONNECT_GROUP_ID = \"connect.group.id\";", "originalCommit": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ3NjgyMA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429476820", "bodyText": "Version is added in ce-kafka.", "author": "xiaodongdu", "createdAt": "2020-05-22T22:18:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTIxNjgxMw=="}], "type": "inlineReview"}, {"oid": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "url": "https://github.com/apache/kafka/commit/3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "message": "Merge remote-tracking branch 'origin/trunk' into kafka-9960-kip-606", "committedDate": "2020-05-22T18:34:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4NjM3Nw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429386377", "bodyText": "Can be final", "author": "mumrah", "createdAt": "2020-05-22T18:05:55Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/KafkaMetricsContext.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A implementation of MetricsContext, it encapsulates required metrics context properties for Kafka services and clients\n+ */\n+public class KafkaMetricsContext implements MetricsContext {\n+    /**\n+     * Client or Service's metadata map.\n+     */\n+    private Map<String, String> metadata = new HashMap<>();", "originalCommit": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ5NTc3OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429495778", "bodyText": "Thanks for the patch @xiaodongdu!\nI reviewed the client and broker sections of code as well as the new interface. Comments inline.\nI think the ability to include \"metrics.context.*\" values as config is generally useful. Is it worth doing this for the broker as well?\nAlso, in case you didn't know, you can use Markdown in the PR description to format it and make it a little more readable.\n\nMoved String constants into KafkaConfig. Also change this to be final.", "author": "xiaodongdu", "createdAt": "2020-05-23T00:22:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4NjM3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4NzQ5OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429387498", "bodyText": "nit: just read the value from the Map once", "author": "mumrah", "createdAt": "2020-05-22T18:08:30Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/JmxReporter.java", "diffHunk": "@@ -318,4 +324,15 @@ public AttributeList setAttributes(AttributeList list) {\n                                       + \".(whitelist/blacklist) is not a valid regular expression\");\n         }\n     }\n+\n+    @Override\n+    public void contextChange(MetricsContext metricsContext) {\n+        Objects.requireNonNull(metricsContext.metadata().get(MetricsContext.NAMESPACE));", "originalCommit": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ5NTkxMA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429495910", "bodyText": "Added a variable to save the value.", "author": "xiaodongdu", "createdAt": "2020-05-23T00:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4NzQ5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4Nzc3Mg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429387772", "bodyText": "Should we throw an exception here, or just replace the null value with an empty string?", "author": "mumrah", "createdAt": "2020-05-22T18:09:12Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/JmxReporter.java", "diffHunk": "@@ -71,8 +72,13 @@ public JmxReporter() {\n \n     /**\n      * Create a JMX reporter that prefixes all metrics with the given string.\n+     *  @deprecated Since 2.6.0. Use {@link JmxReporter#JmxReporter()}\n+     *  Initialize JmxReporter with {@link JmxReporter#contextChange(MetricsContext)}\n+     *  Populate prefix by adding _namespace/prefix key value pair to {@link MetricsContext}\n      */\n+    @Deprecated\n     public JmxReporter(String prefix) {\n+        Objects.requireNonNull(prefix);", "originalCommit": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ5NTk0MA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429495940", "bodyText": "Change the logic here: if null, set it to empty string.", "author": "xiaodongdu", "createdAt": "2020-05-23T00:24:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM4Nzc3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM5MTU3Nw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429391577", "bodyText": "Metadata is very overloaded, can we think of a different name here?", "author": "mumrah", "createdAt": "2020-05-22T18:18:58Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsContext.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+\n+/**\n+ * MetricsContext encapsulates additional metadata about metrics exposed via a\n+ * {@link org.apache.kafka.common.metrics.MetricsReporter}\n+ *\n+ * The metadata map provides following information:\n+ * - a <code>_namespace</node> field indicating the component exposing metrics\n+ *   e.g. kafka.server, kafka.consumer\n+ *   {@link JmxReporter} uses this as prefix for mbean names\n+ *\n+ * - for clients and streams libraries: any freeform fields passed in via\n+ *   client properties in the form of `metrics.context.<key>=<value>\n+ *\n+ * - for kafka brokers: kafka.broker.id, kafka.cluster.id\n+ * - for connect workers: connect.kafka.cluster.id, connect.group.id\n+ */\n+@InterfaceStability.Evolving\n+public interface MetricsContext {\n+    /* predefined fields */\n+    String NAMESPACE = \"_namespace\"; // metrics namespace, formerly jmx prefix\n+\n+    /**\n+     * Returns metadata fields\n+     */\n+    Map<String, String> metadata();", "originalCommit": "85f7421d9aad5f149e6b4833f87f0747f4ae7e4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ0Mjc4Nw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429442787", "bodyText": "any suggestions? maybe contextLabels?", "author": "xvrl", "createdAt": "2020-05-22T20:39:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM5MTU3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQ4MzY1Mg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430483652", "bodyText": "That sounds good", "author": "mumrah", "createdAt": "2020-05-26T15:05:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM5MTU3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYwNjcwOA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430606708", "bodyText": "ok, I updated the KIP to reflect this change.", "author": "xvrl", "createdAt": "2020-05-26T18:04:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM5MTU3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMTA2NQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430701065", "bodyText": "Updated code to reflect KIP changes", "author": "xiaodongdu", "createdAt": "2020-05-26T20:52:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM5MTU3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjcwOQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429422709", "bodyText": "Looking through the PR, it seems that MetricsContext is a short lived object used to pass values to the MetricReporters as they are constructed. Since the usage appears to be write-once, it might be better to expose a subset of Map rather than the full thing. E.g., String get(String field) and Iterator<String> fields or something.\nIf we think this might evolve into a mutable long-lived object, then a Map is probably better. Just a thought.", "author": "mumrah", "createdAt": "2020-05-22T19:34:20Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsContext.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+\n+/**\n+ * MetricsContext encapsulates additional metadata about metrics exposed via a\n+ * {@link org.apache.kafka.common.metrics.MetricsReporter}\n+ *\n+ * The metadata map provides following information:\n+ * - a <code>_namespace</node> field indicating the component exposing metrics\n+ *   e.g. kafka.server, kafka.consumer\n+ *   {@link JmxReporter} uses this as prefix for mbean names\n+ *\n+ * - for clients and streams libraries: any freeform fields passed in via\n+ *   client properties in the form of `metrics.context.<key>=<value>\n+ *\n+ * - for kafka brokers: kafka.broker.id, kafka.cluster.id\n+ * - for connect workers: connect.kafka.cluster.id, connect.group.id\n+ */\n+@InterfaceStability.Evolving\n+public interface MetricsContext {", "originalCommit": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ0MDY1NQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429440655", "bodyText": "I think having an interface gives us more flexibility to evolve the API, without breaking backwards compatibility.", "author": "xvrl", "createdAt": "2020-05-22T20:33:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjcwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQ4ODIyNA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430488224", "bodyText": "I wasn't suggesting that we eliminate the interface, I definitely think having one is a good choice (for the reasons you mentioned). What I meant was in this interface, we expose a Map as the collection of metrics tags/labels. But since it appears that the usage is intended to be read-only, maybe a Map isn't the best choice. Here's what I was thinking:\ninterface MetricsContext {\n  String namespace();\n  String get(String field);\n  Collection<String> fields();\n}\n(included the namespace suggestion from my other comment as well).", "author": "mumrah", "createdAt": "2020-05-26T15:11:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjcwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU1NzEyMQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430557121", "bodyText": "I think keeping a Map interface makes it more convenient to work with. It gives you all the helper methods and streaming interfaces rather than having to hand-roll those things for someone consuming the api.", "author": "xvrl", "createdAt": "2020-05-26T16:43:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjcwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjgzNA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429422834", "bodyText": "Should we define this as a field on the interface?", "author": "mumrah", "createdAt": "2020-05-22T19:34:41Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsContext.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+\n+/**\n+ * MetricsContext encapsulates additional metadata about metrics exposed via a\n+ * {@link org.apache.kafka.common.metrics.MetricsReporter}\n+ *\n+ * The metadata map provides following information:\n+ * - a <code>_namespace</node> field indicating the component exposing metrics\n+ *   e.g. kafka.server, kafka.consumer\n+ *   {@link JmxReporter} uses this as prefix for mbean names\n+ *\n+ * - for clients and streams libraries: any freeform fields passed in via\n+ *   client properties in the form of `metrics.context.<key>=<value>\n+ *\n+ * - for kafka brokers: kafka.broker.id, kafka.cluster.id\n+ * - for connect workers: connect.kafka.cluster.id, connect.group.id\n+ */\n+@InterfaceStability.Evolving\n+public interface MetricsContext {\n+    /* predefined fields */\n+    String NAMESPACE = \"_namespace\"; // metrics namespace, formerly jmx prefix", "originalCommit": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ0MjY3MQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429442671", "bodyText": "I think the interface is a natural way to expose predefined constants an API might need. I don't see a need to have a separate class for this yet.", "author": "xvrl", "createdAt": "2020-05-22T20:39:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjgzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQ4OTIyMA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430489220", "bodyText": "Sorry, I shouldn't have said \"field\" since that implies a concrete class. See above comment above for an example of what I meant.", "author": "mumrah", "createdAt": "2020-05-26T15:12:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjgzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU2OTM5MQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430569391", "bodyText": "I'm not convinced we should give namespace a special status over other fields, it just happens to be the only one we currently define by default for backwards compatibility reasons. If we find ourselves adding more of those, I agreee it would be worth revisiting how we expose pre-defined fields.", "author": "xvrl", "createdAt": "2020-05-26T17:02:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyMjgzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429426401", "bodyText": "Should we rename jmxPrefix to metricsPrefix?", "author": "mumrah", "createdAt": "2020-05-22T19:44:30Z", "path": "core/src/main/scala/kafka/server/KafkaServer.scala", "diffHunk": "@@ -129,7 +129,10 @@ class KafkaServer(val config: KafkaConfig, time: Time = Time.SYSTEM, threadNameP\n \n   private var shutdownLatch = new CountDownLatch(1)\n \n+  //properties for MetricsContext", "originalCommit": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ0NDQ1MQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429444451", "bodyText": "jmxPrefix is from existing codebase: \n  \n    \n      kafka/core/src/main/scala/kafka/server/KafkaServer.scala\n    \n    \n         Line 132\n      in\n      ec20517\n    \n    \n    \n    \n\n        \n          \n           private val jmxPrefix: String = \"kafka.server\" \n        \n    \n  \n\n\nWe can move the comments beneath it so it is not confusing", "author": "xiaodongdu", "createdAt": "2020-05-22T20:44:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ5NTk5Mw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429495993", "bodyText": "Moved these definition of kafka.cluster.id and kafka.broker.id to KafkaConfig", "author": "xiaodongdu", "createdAt": "2020-05-23T00:24:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUwMzM0Mg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429503342", "bodyText": "any reason you moved some but not jmxPrefix? I think it would make sense to keep all the metrics context constants in one place. I didn't see any comment from @mumrah suggesting to move them.", "author": "xvrl", "createdAt": "2020-05-23T01:45:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTUxMDkzMQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429510931", "bodyText": "From his comments: \"I think the ability to include \"metrics.context.*\" values as config is generally useful. Is it worth doing this for the broker as well?\"\nLooks like I misunderstood what he meant. Just talked to him on slack. I'll revert that change.", "author": "xiaodongdu", "createdAt": "2020-05-23T03:47:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQ4Mjg3OQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430482879", "bodyText": "This comment was just about the jmxPrefix variable. I realize it's pre-existing code, but now that it's not specific to JMX, I suggested renaming it.", "author": "mumrah", "createdAt": "2020-05-26T15:04:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU4NTQ0Nw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430585447", "bodyText": "@xiaodongdu what @mumrah was saying is that we could add the properties to the kafka broker configuration and pass those values into the context, similar to what we do for client. We can update the KIP and add that.", "author": "xvrl", "createdAt": "2020-05-26T17:30:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5MDQ4OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430590488", "bodyText": "@xvrl  Do you mean add this logic back to KafkaServer.scala:\nmetadata.putAll(config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT_PREFIX, false));", "author": "xiaodongdu", "createdAt": "2020-05-26T17:39:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5MzY2OQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430593669", "bodyText": "yes, I believe that's what @mumrah meant. If we decide to do this, I'll update the KIP and send a follow-up email with some of the other tweaks we discussed in this PR.", "author": "xvrl", "createdAt": "2020-05-26T17:44:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjA3NA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430702074", "bodyText": "renamed jmxPrefix to metricsPrefix and add broker MetricsContext properties", "author": "xiaodongdu", "createdAt": "2020-05-26T20:54:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQyNjQwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzMjE1NA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429432154", "bodyText": "Not really a \"callback\" in the conventional sense. Maybe just \"Provides context metadata for the ...\"", "author": "mumrah", "createdAt": "2020-05-22T20:03:50Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsReporter.java", "diffHunk": "@@ -65,4 +66,13 @@ default void validateReconfiguration(Map<String, ?> configs) throws ConfigExcept\n     default void reconfigure(Map<String, ?> configs) {\n     }\n \n+    /**\n+     * Callback method providing context metadata for the", "originalCommit": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQ5NjAyNw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429496027", "bodyText": "Fixed java doc.", "author": "xiaodongdu", "createdAt": "2020-05-23T00:24:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzMjE1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzNjcyMQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429436721", "bodyText": "@xvrl can we remove the explicit construction of JmxReporter and rely on the plugin loading mechanism after we remove this non-zero-arg constructor? Maybe something for 3.0?", "author": "mumrah", "createdAt": "2020-05-22T20:17:46Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/JmxReporter.java", "diffHunk": "@@ -71,8 +72,13 @@ public JmxReporter() {\n \n     /**\n      * Create a JMX reporter that prefixes all metrics with the given string.\n+     *  @deprecated Since 2.6.0. Use {@link JmxReporter#JmxReporter()}\n+     *  Initialize JmxReporter with {@link JmxReporter#contextChange(MetricsContext)}\n+     *  Populate prefix by adding _namespace/prefix key value pair to {@link MetricsContext}\n      */\n+    @Deprecated", "originalCommit": "3e7cc54cbaab186e24f77d1d4f73b6cdc2e0910b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzOTgxMw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429439813", "bodyText": "yes, I agree. We'll have to decide whether to make the config include this reporter by default or so something else. There are some backwards compatibility implications, but probably better to have a separate discussion for this.", "author": "xvrl", "createdAt": "2020-05-22T20:30:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzNjcyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQ4OTU0Nw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430489547", "bodyText": "Sounds good, thanks \ud83d\udc4d", "author": "mumrah", "createdAt": "2020-05-26T15:13:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTQzNjcyMQ=="}], "type": "inlineReview"}, {"oid": "f30c8f090a518e9ff0d97298ec8ad15d77054386", "url": "https://github.com/apache/kafka/commit/f30c8f090a518e9ff0d97298ec8ad15d77054386", "message": "move string constants to config class", "committedDate": "2020-05-23T00:21:23Z", "type": "commit"}, {"oid": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "url": "https://github.com/apache/kafka/commit/bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "message": "revert changes for KafkaConfig", "committedDate": "2020-05-23T04:02:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTY0MA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429645640", "bodyText": "Standalone does not have a group.id property, since each standalone worker is its own single-node cluster. That means that this line can result in a null value for the metrics.context.connect.group.id entry in the props map.\nUnfortunately, there is no identifier for standalone workers. Is the metrics.context.connect.group.id property really required if the Standalone worker doesn't use any kind of coordination? It seems from other changes in ConnectMetrics that it is not required, in which case we should update the KIP to reflect that this property is only added in Connect distributed mode and we should correct the logic above to only add this property if it is non-null similar to the changes in ConnectMetrics.\nIf it is required, then we'll have to figure out something else.", "author": "rhauch", "createdAt": "2020-05-24T15:02:30Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/util/ConnectUtils.java", "diffHunk": "@@ -65,4 +68,12 @@ static String lookupKafkaClusterId(Admin adminClient) {\n                                        + \"Check worker's broker connection and security properties.\", e);\n         }\n     }\n+\n+    public static void addMetricsContextProperties(Map<String, Object> prop, WorkerConfig config, String clusterId) {\n+        //add all properties predefined with \"metrics.context.\"\n+        prop.putAll(config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT_PREFIX, false));\n+        //add connect properties\n+        prop.put(CommonClientConfigs.METRICS_CONTEXT_PREFIX + WorkerConfig.CONNECT_KAFKA_CLUSTER_ID, clusterId);\n+        prop.put(CommonClientConfigs.METRICS_CONTEXT_PREFIX + WorkerConfig.CONNECT_GROUP_ID, config.originals().get(DistributedConfig.GROUP_ID_CONFIG));", "originalCommit": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTc0NA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429645744", "bodyText": "Speaking of this, it'd probably be worth adding unit tests for this method with both StandaloneConfig and DistributedConfig objects to verify this method adds the right properties to the supplied map.", "author": "rhauch", "createdAt": "2020-05-24T15:03:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY4MzQwOA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429683408", "bodyText": "Added unit test in ConnectUtilsTest for StandAloneConfig and DistributedConfig.", "author": "xiaodongdu", "createdAt": "2020-05-24T22:59:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY4MzQ3NQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429683475", "bodyText": "I'll leave KIP update to @xvrl", "author": "xiaodongdu", "createdAt": "2020-05-24T23:00:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5MjQ0OQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430592449", "bodyText": "@rhauch I've updated the KIP document, will send a follow-up email to announce the changes, once we finalize @mumrah 's feedback", "author": "xvrl", "createdAt": "2020-05-26T17:42:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTY0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTk2Mw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429645963", "bodyText": "This group.id property is not defined in StandaloneConfig. See my earlier comment.", "author": "rhauch", "createdAt": "2020-05-24T15:06:08Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/WorkerTest.java", "diffHunk": "@@ -153,6 +164,7 @@ public void setup() {\n         workerProps.put(\"config.providers.file.class\", MockFileConfigProvider.class.getName());\n         mockFileProviderTestId = UUID.randomUUID().toString();\n         workerProps.put(\"config.providers.file.param.testId\", mockFileProviderTestId);\n+        workerProps.put(\"group.id\", GROUP_ID);", "originalCommit": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY4MzM3MA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429683370", "bodyText": "Removed group.id and related check.", "author": "xiaodongdu", "createdAt": "2020-05-24T22:58:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NTk2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzE1NQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647155", "bodyText": "This is unused.", "author": "rhauch", "createdAt": "2020-05-24T15:19:21Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaStatusBackingStoreFormatTest.java", "diffHunk": "@@ -59,6 +59,7 @@\n     private static final String FOO_TOPIC = \"foo-topic\";\n     private static final String FOO_CONNECTOR = \"foo-source\";\n     private static final String BAR_TOPIC = \"bar-topic\";\n+    private static final String CLUSTER_ID = \"cluster-1\";", "originalCommit": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY4MzM0OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429683348", "bodyText": "Removed.", "author": "xiaodongdu", "createdAt": "2020-05-24T22:58:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzE1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzE2Mw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647163", "bodyText": "This is unused.", "author": "rhauch", "createdAt": "2020-05-24T15:19:30Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/storage/KafkaStatusBackingStoreTest.java", "diffHunk": "@@ -63,6 +63,7 @@\n \n     private static final String STATUS_TOPIC = \"status-topic\";\n     private static final String WORKER_ID = \"localhost:8083\";\n+    private static final String CLUSTER_ID = \"cluster-1\";", "originalCommit": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY4MzUyNw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429683527", "bodyText": "Removed", "author": "xiaodongdu", "createdAt": "2020-05-24T23:00:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzE2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzYyMg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647622", "bodyText": "Nit: this doesn't follow our conventions: we don't use the get* style getters, and if this is only used in unit tests we should make this package protected instead this should be:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * Method for unit tests\n          \n          \n            \n                 * @return\n          \n          \n            \n                 */\n          \n          \n            \n                public Metrics getMetrics() {\n          \n          \n            \n                    return this.metrics;\n          \n          \n            \n                }\n          \n          \n            \n                // Visible for testing\n          \n          \n            \n                Metrics metrics() {\n          \n          \n            \n                    return this.metrics;\n          \n          \n            \n                }\n          \n      \n    \n    \n  \n\nYou'll have to change the WorkerGroupMemberTest accordingly.", "author": "rhauch", "createdAt": "2020-05-24T15:24:30Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMember.java", "diffHunk": "@@ -223,4 +235,12 @@ private void stop(boolean swallowException) {\n         else\n             log.debug(\"The Connect group member has stopped.\");\n     }\n+\n+    /**\n+     * Method for unit tests\n+     * @return\n+     */\n+    public Metrics getMetrics() {\n+        return this.metrics;\n+    }", "originalCommit": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY4MzM0MA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429683340", "bodyText": "Renamed this method to metrics() and make it protected.", "author": "xiaodongdu", "createdAt": "2020-05-24T22:58:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzYyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzY4MQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647681", "bodyText": "Per a previous suggestion:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    MetricName name = member.getMetrics().metricName(\"test.avg\", \"grp1\");\n          \n          \n            \n                    MetricName name = member.metrics().metricName(\"test.avg\", \"grp1\");", "author": "rhauch", "createdAt": "2020-05-24T15:25:10Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"offset.storage.file.filename\", \"/tmp/connect.offsets\");\n+        workerProps.put(\"group.id\", \"group-1\");\n+        workerProps.put(\"offset.storage.topic\", \"topic-1\");\n+        workerProps.put(\"config.storage.topic\", \"topic-1\");\n+        workerProps.put(\"status.storage.topic\", \"topic-1\");\n+        workerProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MockConnectMetrics.MockMetricsReporter.class.getName());\n+        DistributedConfig config = new DistributedConfig(workerProps);\n+\n+\n+        LogContext logContext = new LogContext(\"[Worker clientId=client-1 + groupId= group-1]\");\n+\n+        expectClusterId();\n+\n+        member = new WorkerGroupMember(config, \"\", configBackingStore,\n+        null, Time.SYSTEM, \"client-1\", logContext);\n+\n+        for (MetricsReporter reporter : member.getMetrics().reporters()) {\n+            if (reporter instanceof MockConnectMetrics.MockMetricsReporter) {\n+                MockConnectMetrics.MockMetricsReporter mockMetricsReporter = (MockConnectMetrics.MockMetricsReporter) reporter;\n+                assertEquals(\"cluster-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_KAFKA_CLUSTER_ID));\n+                assertEquals(\"group-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_GROUP_ID));\n+            }\n+        }\n+\n+        MetricName name = member.getMetrics().metricName(\"test.avg\", \"grp1\");", "originalCommit": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0NzcxMw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647713", "bodyText": "Per a previous suggestion:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    for (MetricsReporter reporter : member.getMetrics().reporters()) {\n          \n          \n            \n                    for (MetricsReporter reporter : member.metrics().reporters()) {", "author": "rhauch", "createdAt": "2020-05-24T15:25:28Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"offset.storage.file.filename\", \"/tmp/connect.offsets\");\n+        workerProps.put(\"group.id\", \"group-1\");\n+        workerProps.put(\"offset.storage.topic\", \"topic-1\");\n+        workerProps.put(\"config.storage.topic\", \"topic-1\");\n+        workerProps.put(\"status.storage.topic\", \"topic-1\");\n+        workerProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MockConnectMetrics.MockMetricsReporter.class.getName());\n+        DistributedConfig config = new DistributedConfig(workerProps);\n+\n+\n+        LogContext logContext = new LogContext(\"[Worker clientId=client-1 + groupId= group-1]\");\n+\n+        expectClusterId();\n+\n+        member = new WorkerGroupMember(config, \"\", configBackingStore,\n+        null, Time.SYSTEM, \"client-1\", logContext);\n+\n+        for (MetricsReporter reporter : member.getMetrics().reporters()) {", "originalCommit": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTY0Nzc1OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r429647758", "bodyText": "Per a previous suggestion:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    member.getMetrics().addMetric(name, new Avg());\n          \n          \n            \n                    member.metrics().addMetric(name, new Avg());", "author": "rhauch", "createdAt": "2020-05-24T15:25:53Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"offset.storage.file.filename\", \"/tmp/connect.offsets\");\n+        workerProps.put(\"group.id\", \"group-1\");\n+        workerProps.put(\"offset.storage.topic\", \"topic-1\");\n+        workerProps.put(\"config.storage.topic\", \"topic-1\");\n+        workerProps.put(\"status.storage.topic\", \"topic-1\");\n+        workerProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MockConnectMetrics.MockMetricsReporter.class.getName());\n+        DistributedConfig config = new DistributedConfig(workerProps);\n+\n+\n+        LogContext logContext = new LogContext(\"[Worker clientId=client-1 + groupId= group-1]\");\n+\n+        expectClusterId();\n+\n+        member = new WorkerGroupMember(config, \"\", configBackingStore,\n+        null, Time.SYSTEM, \"client-1\", logContext);\n+\n+        for (MetricsReporter reporter : member.getMetrics().reporters()) {\n+            if (reporter instanceof MockConnectMetrics.MockMetricsReporter) {\n+                MockConnectMetrics.MockMetricsReporter mockMetricsReporter = (MockConnectMetrics.MockMetricsReporter) reporter;\n+                assertEquals(\"cluster-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_KAFKA_CLUSTER_ID));\n+                assertEquals(\"group-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_GROUP_ID));\n+            }\n+        }\n+\n+        MetricName name = member.getMetrics().metricName(\"test.avg\", \"grp1\");\n+        member.getMetrics().addMetric(name, new Avg());", "originalCommit": "bd58373bfadd9c0ad1adf1457d647edfcc8cd7d6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "26a2a761102e05f13449bfa6897cb30b70bf7ee1", "url": "https://github.com/apache/kafka/commit/26a2a761102e05f13449bfa6897cb30b70bf7ee1", "message": "Merge remote-tracking branch 'origin/trunk' into kafka-9960-kip-606", "committedDate": "2020-05-24T20:15:02Z", "type": "commit"}, {"oid": "a40908570dad698874464fe2f1ff3f5520489b0c", "url": "https://github.com/apache/kafka/commit/a40908570dad698874464fe2f1ff3f5520489b0c", "message": "Address code review comments: rename method name, remove unused variable, unit tests for ConnectUtils, add group id only for distributed conenct", "committedDate": "2020-05-24T22:56:24Z", "type": "commit"}, {"oid": "d8c5d2aee1d42260eb5f7567b6328ca475810124", "url": "https://github.com/apache/kafka/commit/d8c5d2aee1d42260eb5f7567b6328ca475810124", "message": "update comment", "committedDate": "2020-05-24T23:01:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY2NzA5Mw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430667093", "bodyText": "Need to add the parameter to the JavaDoc:\n@param clusterId  the Kafka cluster ID", "author": "rhauch", "createdAt": "2020-05-26T19:47:41Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/ConnectMetrics.java", "diffHunk": "@@ -63,7 +67,7 @@\n      * @param config   the worker configuration; may not be null\n      * @param time     the time; may not be null\n      */\n-    public ConnectMetrics(String workerId, WorkerConfig config, Time time) {\n+    public ConnectMetrics(String workerId, WorkerConfig config, Time time, String clusterId) {", "originalCommit": "d8c5d2aee1d42260eb5f7567b6328ca475810124", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMzg3OQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430703879", "bodyText": "Updated javadoc.", "author": "xiaodongdu", "createdAt": "2020-05-26T20:58:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY2NzA5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MTMyNA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430671324", "bodyText": "Should we use ConnectUtils.addMetricsContextProperties(adminProps, config, clusterId) a few lines below this? (See the similar changes you made in KafkaStatusBackingStore and KafkaConfigBackingStore.)", "author": "rhauch", "createdAt": "2020-05-26T19:55:04Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/storage/KafkaOffsetBackingStore.java", "diffHunk": "@@ -66,20 +67,22 @@ public void configure(final WorkerConfig config) {\n         if (topic == null || topic.trim().length() == 0)\n             throw new ConfigException(\"Offset storage topic must be specified\");\n \n+        String clusterId = ConnectUtils.lookupKafkaClusterId(config);\n         data = new HashMap<>();\n \n         Map<String, Object> originals = config.originals();\n         Map<String, Object> producerProps = new HashMap<>(originals);\n         producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n         producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n         producerProps.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, Integer.MAX_VALUE);\n+        ConnectUtils.addMetricsContextProperties(producerProps, config, clusterId);\n \n         Map<String, Object> consumerProps = new HashMap<>(originals);\n         consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());\n         consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName());\n+        ConnectUtils.addMetricsContextProperties(consumerProps, config, clusterId);", "originalCommit": "d8c5d2aee1d42260eb5f7567b6328ca475810124", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjc2OQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430702769", "bodyText": "Nice catch, fixed.", "author": "xiaodongdu", "createdAt": "2020-05-26T20:55:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MTMyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MzY1Mw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430673653", "bodyText": "Let's remove these deprecated configs.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n          \n          \n            \n                    workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n          \n          \n            \n                    workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n          \n          \n            \n                    workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");", "author": "rhauch", "createdAt": "2020-05-26T19:59:17Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");", "originalCommit": "d8c5d2aee1d42260eb5f7567b6328ca475810124", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMzA2Ng==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430703066", "bodyText": "Removed deprecated configs.", "author": "xiaodongdu", "createdAt": "2020-05-26T20:56:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3MzY1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3NDcwMw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430674703", "bodyText": "It might be good to verify that we entered the if (reporter instance Mock...) block at least once. Otherwise, we might have a bug elsewhere that failed to instantiate the MockMetricsReporter class, and this portion of the test would still pass.", "author": "rhauch", "createdAt": "2020-05-26T20:01:18Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/WorkerGroupMemberTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.runtime.distributed;\n+\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.kafka.common.MetricName;\n+import org.apache.kafka.common.metrics.MetricsReporter;\n+import org.apache.kafka.common.metrics.stats.Avg;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.Time;\n+import org.apache.kafka.connect.runtime.MockConnectMetrics;\n+import org.apache.kafka.connect.runtime.WorkerConfig;\n+import org.apache.kafka.connect.storage.ConfigBackingStore;\n+import org.apache.kafka.connect.storage.StatusBackingStore;\n+import org.apache.kafka.connect.util.ConnectUtils;\n+import org.easymock.EasyMock;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.powermock.api.easymock.PowerMock;\n+import org.powermock.api.easymock.annotation.Mock;\n+import org.powermock.core.classloader.annotations.PowerMockIgnore;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import javax.management.MBeanServer;\n+import javax.management.ObjectName;\n+import java.lang.management.ManagementFactory;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest({ConnectUtils.class})\n+@PowerMockIgnore({\"javax.management.*\", \"javax.crypto.*\"})\n+public class WorkerGroupMemberTest {\n+    @Mock\n+    private ConfigBackingStore configBackingStore;\n+    @Mock\n+    private StatusBackingStore statusBackingStore;\n+\n+    @Test\n+    public void testMetrics() throws Exception {\n+        WorkerGroupMember member;\n+        Map<String, String> workerProps = new HashMap<>();\n+        workerProps.put(\"key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.value.converter\", \"org.apache.kafka.connect.json.JsonConverter\");\n+        workerProps.put(\"internal.key.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"internal.value.converter.schemas.enable\", \"false\");\n+        workerProps.put(\"offset.storage.file.filename\", \"/tmp/connect.offsets\");\n+        workerProps.put(\"group.id\", \"group-1\");\n+        workerProps.put(\"offset.storage.topic\", \"topic-1\");\n+        workerProps.put(\"config.storage.topic\", \"topic-1\");\n+        workerProps.put(\"status.storage.topic\", \"topic-1\");\n+        workerProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, MockConnectMetrics.MockMetricsReporter.class.getName());\n+        DistributedConfig config = new DistributedConfig(workerProps);\n+\n+\n+        LogContext logContext = new LogContext(\"[Worker clientId=client-1 + groupId= group-1]\");\n+\n+        expectClusterId();\n+\n+        member = new WorkerGroupMember(config, \"\", configBackingStore,\n+        null, Time.SYSTEM, \"client-1\", logContext);\n+\n+        for (MetricsReporter reporter : member.metrics().reporters()) {\n+            if (reporter instanceof MockConnectMetrics.MockMetricsReporter) {\n+                MockConnectMetrics.MockMetricsReporter mockMetricsReporter = (MockConnectMetrics.MockMetricsReporter) reporter;\n+                assertEquals(\"cluster-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_KAFKA_CLUSTER_ID));\n+                assertEquals(\"group-1\", mockMetricsReporter.getMetricsContext().metadata().get(WorkerConfig.CONNECT_GROUP_ID));\n+            }\n+        }", "originalCommit": "d8c5d2aee1d42260eb5f7567b6328ca475810124", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwMjg5NQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430702895", "bodyText": "Added verification.", "author": "xiaodongdu", "createdAt": "2020-05-26T20:56:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDY3NDcwMw=="}], "type": "inlineReview"}, {"oid": "1a1cf89d14e7631467eae5bb88273653d27fbe9d", "url": "https://github.com/apache/kafka/commit/1a1cf89d14e7631467eae5bb88273653d27fbe9d", "message": "Update MetricsContext based on KIP changes, address more code review comments", "committedDate": "2020-05-26T20:49:03Z", "type": "commit"}, {"oid": "15bdb8d7091f5dc9c4e13dcd9029211893506d9e", "url": "https://github.com/apache/kafka/commit/15bdb8d7091f5dc9c4e13dcd9029211893506d9e", "message": "Update MetricsContext based on KIP changes, address more code review comments", "committedDate": "2020-05-26T20:59:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNTQxNQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430705415", "bodyText": "the prefix should be stripped before adding the fields to the context.", "author": "xvrl", "createdAt": "2020-05-26T21:01:10Z", "path": "core/src/main/scala/kafka/server/KafkaServer.scala", "diffHunk": "@@ -384,6 +390,23 @@ class KafkaServer(val config: KafkaConfig, time: Time = Time.SYSTEM, threadNameP\n     clusterResourceListeners.onUpdate(new ClusterResource(clusterId))\n   }\n \n+  private[server] def notifyMetricsReporters(metricsReporters: Seq[AnyRef]): Unit = {\n+    val metricsContext = createKafkaMetricsContext()\n+    metricsReporters.foreach {\n+      case x: MetricsReporter => x.contextChange(metricsContext)\n+      case _ => //do nothing\n+    }\n+  }\n+\n+  private[server] def createKafkaMetricsContext() : KafkaMetricsContext = {\n+    val contextLabels = new util.HashMap[String, Object]\n+    contextLabels.put(KAFKA_CLUSTER_ID, clusterId)\n+    contextLabels.put(KAFKA_BROKER_ID, config.brokerId.toString)\n+    contextLabels.putAll(config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT_PREFIX, false))", "originalCommit": "1a1cf89d14e7631467eae5bb88273653d27fbe9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMTUwNA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430711504", "bodyText": "Fixed", "author": "xiaodongdu", "createdAt": "2020-05-26T21:14:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcwNTQxNQ=="}], "type": "inlineReview"}, {"oid": "7f5c69a1ff07588355fec4a9019febed85054217", "url": "https://github.com/apache/kafka/commit/7f5c69a1ff07588355fec4a9019febed85054217", "message": "More fix regarding code review", "committedDate": "2020-05-26T21:10:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430710474", "bodyText": "someone on the ML commented that we might want to name this contextChanged (past tense). I don't have a strong feeling either way. Do you have any thoughts @mumrah @rhauch?", "author": "xvrl", "createdAt": "2020-05-26T21:11:58Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsReporter.java", "diffHunk": "@@ -65,4 +66,12 @@ default void validateReconfiguration(Map<String, ?> configs) throws ConfigExcept\n     default void reconfigure(Map<String, ?> configs) {\n     }\n \n+    /**\n+     * Provides context labels for the service or library exposing metrics\n+     *\n+     * @param metricsContext the metric context\n+     */\n+    @InterfaceStability.Evolving\n+    default void contextChange(MetricsContext metricsContext) {", "originalCommit": "1a1cf89d14e7631467eae5bb88273653d27fbe9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDczMTcxNg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430731716", "bodyText": "I really don't have a strong preference. Past tense is a little odd, but I think changeContext(...) or setContext(...) are present-tense and more conventional.", "author": "rhauch", "createdAt": "2020-05-26T22:00:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2NzMzMw==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430767333", "bodyText": "It would also be good to identify when this is called relative to other methods. For example, it is always called before init(...) is called. But can it be called again, or is that the only time this method is called?", "author": "rhauch", "createdAt": "2020-05-26T23:46:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc3NDU0OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430774548", "bodyText": "due to the way jmxreporter is initialized in Kafka today, it already gets called both before and after init()", "author": "xvrl", "createdAt": "2020-05-27T00:11:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg0MDU2OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430840568", "bodyText": "It can be called multiple times.  Not sure if we should mention that in Javadoc, other methods in this class we are not mention if it can be called multiple times even though they can be called multiple times.", "author": "xiaodongdu", "createdAt": "2020-05-27T03:43:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE5NDkxNQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r431194915", "bodyText": "If there is no clear call pattern, then it's fine to not say anything. However, JmxReporter.contextChange(...) seems to assume that contextChange(...) will be called before any metrics are added via init(...).\nIf that call pattern is true, then I think we should document it. If it's also true it can be called later, then mention this as well. For example, the JavaDoc text on contextChange(...) could be something like:\n\nSets the context labels for the service or library that is exposing metrics.\nThis will be called before {@link #init(List)} and may be called anytime after that.\n\nWDYT?", "author": "rhauch", "createdAt": "2020-05-27T14:47:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI2NzA0NA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r431267044", "bodyText": "Sounds good. Updated javadoc.", "author": "xiaodongdu", "createdAt": "2020-05-27T16:11:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxMDQ3NA=="}], "type": "inlineReview"}, {"oid": "5598fa191d445120baaf92cd988ba198f87e5e3b", "url": "https://github.com/apache/kafka/commit/5598fa191d445120baaf92cd988ba198f87e5e3b", "message": "Merge branch 'kafka-9960-kip-606' of github.com:xiaodongdu/kafka into kafka-9960-kip-606", "committedDate": "2020-05-26T21:12:08Z", "type": "commit"}, {"oid": "98371e4c69307da9d627fec97d2bd3361d83b372", "url": "https://github.com/apache/kafka/commit/98371e4c69307da9d627fec97d2bd3361d83b372", "message": "Minor changes for KafkaServer", "committedDate": "2020-05-26T21:39:10Z", "type": "commit"}, {"oid": "1c42644b660fb99daa3018f21b5b98d85b653704", "url": "https://github.com/apache/kafka/commit/1c42644b660fb99daa3018f21b5b98d85b653704", "message": "update variable name", "committedDate": "2020-05-26T22:14:52Z", "type": "commit"}, {"oid": "6f934729fe4db47f609e59d20399707c0a2d2190", "url": "https://github.com/apache/kafka/commit/6f934729fe4db47f609e59d20399707c0a2d2190", "message": "Remove unused variable", "committedDate": "2020-05-26T22:33:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2NTg0Ng==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430765846", "bodyText": "Need an override annotation here:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public Map<String, String> contextLabels() {\n          \n          \n            \n                @Override\n          \n          \n            \n                public Map<String, String> contextLabels() {", "author": "rhauch", "createdAt": "2020-05-26T23:41:39Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/KafkaMetricsContext.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * A implementation of MetricsContext, it encapsulates required metrics context properties for Kafka services and clients\n+ */\n+public class KafkaMetricsContext implements MetricsContext {\n+    /**\n+     * Client or Service's contextLabels map.\n+     */\n+    private final Map<String, String> contextLabels = new HashMap<>();\n+\n+    /**\n+     * Create a MetricsContext with namespace, no service or client properties\n+     * @param namespace value for _namespace key\n+     */\n+    public KafkaMetricsContext(String namespace) {\n+        this(namespace, new HashMap<>());\n+    }\n+\n+    /**\n+     * Create a MetricsContext with namespace, service or client properties\n+     * @param namespace value for _namespace key\n+     * @param contextLabels  contextLabels additional entries to add to the context.\n+     *                  values will be converted to string using Object.toString()\n+     */\n+    public KafkaMetricsContext(String namespace, Map<String, ?> contextLabels) {\n+        this.contextLabels.put(MetricsContext.NAMESPACE, namespace);\n+        contextLabels.forEach((key, value) -> this.contextLabels.put(key, value.toString()));\n+    }\n+\n+    public Map<String, String> contextLabels() {", "originalCommit": "6f934729fe4db47f609e59d20399707c0a2d2190", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc4MzA1OA==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430783058", "bodyText": "Added annotation", "author": "xiaodongdu", "createdAt": "2020-05-27T00:41:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2NTg0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2NjQyNg==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430766426", "bodyText": "This JavaDoc is incomplete. Perhaps something like:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /**\n          \n          \n            \n                 * Returns contextLabels fields\n          \n          \n            \n                 */\n          \n          \n            \n                Map<String, String> contextLabels();\n          \n          \n            \n                /**\n          \n          \n            \n                 * Returns the labels for this metrics context.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @return the map of label keys and values; never null but possibly empty\n          \n          \n            \n                 */\n          \n          \n            \n                Map<String, String> contextLabels();", "author": "rhauch", "createdAt": "2020-05-26T23:43:40Z", "path": "clients/src/main/java/org/apache/kafka/common/metrics/MetricsContext.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.metrics;\n+\n+import org.apache.kafka.common.annotation.InterfaceStability;\n+\n+import java.util.Map;\n+\n+/**\n+ * MetricsContext encapsulates additional contextLabels about metrics exposed via a\n+ * {@link org.apache.kafka.common.metrics.MetricsReporter}\n+ *\n+ * The contextLabels map provides following information:\n+ * - a <code>_namespace</node> field indicating the component exposing metrics\n+ *   e.g. kafka.server, kafka.consumer\n+ *   {@link JmxReporter} uses this as prefix for mbean names\n+ *\n+ * - for clients and streams libraries: any freeform fields passed in via\n+ *   client properties in the form of `metrics.context.<key>=<value>\n+ *\n+ * - for kafka brokers: kafka.broker.id, kafka.cluster.id\n+ * - for connect workers: connect.kafka.cluster.id, connect.group.id\n+ */\n+@InterfaceStability.Evolving\n+public interface MetricsContext {\n+    /* predefined fields */\n+    String NAMESPACE = \"_namespace\"; // metrics namespace, formerly jmx prefix\n+\n+    /**\n+     * Returns contextLabels fields\n+     */\n+    Map<String, String> contextLabels();", "originalCommit": "6f934729fe4db47f609e59d20399707c0a2d2190", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc4MzA5NQ==", "url": "https://github.com/apache/kafka/pull/8691#discussion_r430783095", "bodyText": "Updated javadoc.", "author": "xiaodongdu", "createdAt": "2020-05-27T00:41:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDc2NjQyNg=="}], "type": "inlineReview"}, {"oid": "071872fae4a7c1473b1bd29c68fcf5d8b5f94676", "url": "https://github.com/apache/kafka/commit/071872fae4a7c1473b1bd29c68fcf5d8b5f94676", "message": "Update javadoc and add annotation", "committedDate": "2020-05-27T00:40:25Z", "type": "commit"}, {"oid": "7bcd0577ffe84a18579fb931e7d81e033717d681", "url": "https://github.com/apache/kafka/commit/7bcd0577ffe84a18579fb931e7d81e033717d681", "message": "Update javadoc", "committedDate": "2020-05-27T16:11:06Z", "type": "commit"}, {"oid": "319f5c556715d6733e82b41d7289ab71513ae27b", "url": "https://github.com/apache/kafka/commit/319f5c556715d6733e82b41d7289ab71513ae27b", "message": "Merge remote-tracking branch 'origin/trunk' into kafka-9960-kip-606", "committedDate": "2020-05-27T17:48:06Z", "type": "commit"}]}