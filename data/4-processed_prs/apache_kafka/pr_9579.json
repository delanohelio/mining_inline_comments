{"pr_number": 9579, "pr_title": "KAFKA-9751: Forward CreateTopicsRequest for FindCoordinator/Metadata when topic creation is needed", "pr_createdAt": "2020-11-09T17:52:50Z", "pr_url": "https://github.com/apache/kafka/pull/9579", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "309d45a14e274b1206b6d8c81462b99f40ccc0a5", "url": "https://github.com/apache/kafka/commit/309d45a14e274b1206b6d8c81462b99f40ccc0a5", "message": "fix test", "committedDate": "2020-11-17T02:48:41Z", "type": "forcePushed"}, {"oid": "a1c802a751e45d5afc846f03ea4223700dd2b572", "url": "https://github.com/apache/kafka/commit/a1c802a751e45d5afc846f03ea4223700dd2b572", "message": "rebase fix", "committedDate": "2021-01-19T18:46:34Z", "type": "forcePushed"}, {"oid": "c95723a8e735cb6257e2fad515c7e456e4d3eb2a", "url": "https://github.com/apache/kafka/commit/c95723a8e735cb6257e2fad515c7e456e4d3eb2a", "message": "rebase fix", "committedDate": "2021-01-19T19:11:51Z", "type": "forcePushed"}, {"oid": "ab42e9fda9d5829ba163163052f03a33586c0a85", "url": "https://github.com/apache/kafka/commit/ab42e9fda9d5829ba163163052f03a33586c0a85", "message": "rename class", "committedDate": "2021-01-19T19:40:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ0NDk5OA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r561444998", "bodyText": "An alternative that we have done elsewhere would be to introduce an AbstractMetadataRequestTest which we can pull the common cases up to. A more elegant option might be to figure out how to use @ParameterizedTest so that we can provide config overrides. This would be a little difficult at the moment because we initialize brokers in a @Before method. Probably means we need to move away from this approach long term. For now, the abstract class seems preferable. Similar for CreateTopicsRequestWithForwardingTest.", "author": "hachikuji", "createdAt": "2021-01-21T00:59:34Z", "path": "core/src/test/scala/unit/kafka/server/MetadataRequestWithForwardingTest.scala", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package unit.kafka.server\n+\n+import java.util.Properties\n+\n+import kafka.server.{KafkaConfig, MetadataRequestTest}\n+import org.junit.jupiter.api.Test\n+\n+class MetadataRequestWithForwardingTest extends MetadataRequestTest {\n+\n+  override def brokerPropertyOverrides(properties: Properties): Unit = {\n+    super.brokerPropertyOverrides(properties)\n+    properties.put(KafkaConfig.EnableMetadataQuorumProp, true.toString)\n+  }\n+\n+  @Test\n+  override def testAutoTopicCreation(): Unit = {\n+    super.testAutoTopicCreation()\n+  }\n+\n+  @Test\n+  override def testAutoCreateOfCollidingTopics(): Unit = {\n+    super.testAutoCreateOfCollidingTopics()\n+  }\n+\n+  @Test\n+  override def testAutoCreateTopicWithInvalidReplicationFactor(): Unit = {\n+    super.testAutoCreateTopicWithInvalidReplicationFactor()\n+  }\n+\n+  /* the rest of tests are not enabled */", "originalCommit": "1d626d2bfea3fe6171083404acdaf08ee9779988", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1MDU0NQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r561450545", "bodyText": "The controller should have these configurations as well. Perhaps it is better to use -1 for this and replication factor and let the controller fill them in?", "author": "hachikuji", "createdAt": "2021-01-21T01:16:13Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1370,55 +1345,164 @@ class KafkaApis(val requestChannel: RequestChannel,\n         !authHelper.authorize(request.context, DESCRIBE, TRANSACTIONAL_ID, findCoordinatorRequest.data.key))\n       requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)\n     else {\n-      // get metadata (and create the topic if necessary)\n-      val (partition, topicMetadata) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n+      val (partition, internalTopicName) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n         case CoordinatorType.GROUP =>\n-          val partition = groupCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (groupCoordinator.partitionFor(findCoordinatorRequest.data.key), GROUP_METADATA_TOPIC_NAME)\n \n         case CoordinatorType.TRANSACTION =>\n-          val partition = txnCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(TRANSACTION_STATE_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (txnCoordinator.partitionFor(findCoordinatorRequest.data.key), TRANSACTION_STATE_TOPIC_NAME)\n+      }\n \n-        case _ =>\n-          throw new InvalidRequestException(\"Unknown coordinator type in FindCoordinator request\")\n+      val topicMetadata = metadataCache.getTopicMetadata(Set(internalTopicName), request.context.listenerName)\n+      def createFindCoordinatorResponse(error: Errors,\n+                                        node: Node,\n+                                        requestThrottleMs: Int,\n+                                        errorMessage: Option[String] = None): FindCoordinatorResponse = {\n+        new FindCoordinatorResponse(\n+          new FindCoordinatorResponseData()\n+            .setErrorCode(error.code)\n+            .setErrorMessage(errorMessage.getOrElse(error.message))\n+            .setNodeId(node.id)\n+            .setHost(node.host)\n+            .setPort(node.port)\n+            .setThrottleTimeMs(requestThrottleMs))\n       }\n \n-      def createResponse(requestThrottleMs: Int): AbstractResponse = {\n-        def createFindCoordinatorResponse(error: Errors, node: Node): FindCoordinatorResponse = {\n-          new FindCoordinatorResponse(\n-              new FindCoordinatorResponseData()\n-                .setErrorCode(error.code)\n-                .setErrorMessage(error.message)\n-                .setNodeId(node.id)\n-                .setHost(node.host)\n-                .setPort(node.port)\n-                .setThrottleTimeMs(requestThrottleMs))\n+      val topicCreationNeeded = topicMetadata.headOption.isEmpty\n+      if (topicCreationNeeded) {\n+        if (hasEnoughAliveBrokers(internalTopicName)) {\n+          if (shouldForwardRequest(request)) {\n+            forwardingManager.sendInterBrokerRequest(\n+              getCreateTopicsRequest(Seq(internalTopicName)),\n+              _ => ())\n+          } else {\n+            val controllerMutationQuota = quotas.controllerMutation.newQuotaFor(request, strictSinceVersion = 6)\n+\n+            val topicConfigs = Map(internalTopicName -> getTopicConfigs(internalTopicName))\n+            adminManager.createTopics(\n+              config.requestTimeoutMs,\n+              validateOnly = false,\n+              topicConfigs,\n+              Map.empty,\n+              controllerMutationQuota,\n+              _ => ())\n+          }\n         }\n-        val responseBody = if (topicMetadata.errorCode != Errors.NONE.code) {\n-          createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode)\n-        } else {\n-          val coordinatorEndpoint = topicMetadata.partitions.asScala\n-            .find(_.partitionIndex == partition)\n-            .filter(_.leaderId != MetadataResponse.NO_LEADER_ID)\n-            .flatMap(metadata => metadataCache.getAliveBroker(metadata.leaderId))\n-            .flatMap(_.getNode(request.context.listenerName))\n-            .filterNot(_.isEmpty)\n-\n-          coordinatorEndpoint match {\n-            case Some(endpoint) =>\n-              createFindCoordinatorResponse(Errors.NONE, endpoint)\n-            case _ =>\n-              createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode)\n+\n+        requestHelper.sendResponseMaybeThrottle(request, requestThrottleMs => createFindCoordinatorResponse(\n+          Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs))\n+      } else {\n+        def createResponse(requestThrottleMs: Int): AbstractResponse = {\n+          val responseBody = if (topicMetadata.head.errorCode != Errors.NONE.code) {\n+            createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs)\n+          } else {\n+            val coordinatorEndpoint = topicMetadata.head.partitions.asScala\n+              .find(_.partitionIndex == partition)\n+              .filter(_.leaderId != MetadataResponse.NO_LEADER_ID)\n+              .flatMap(metadata => metadataCache.getAliveBroker(metadata.leaderId))\n+              .flatMap(_.getNode(request.context.listenerName))\n+              .filterNot(_.isEmpty)\n+\n+            coordinatorEndpoint match {\n+              case Some(endpoint) =>\n+                createFindCoordinatorResponse(Errors.NONE, endpoint, requestThrottleMs)\n+              case _ =>\n+                createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs)\n+            }\n           }\n+          trace(\"Sending FindCoordinator response %s for correlation id %d to client %s.\"\n+            .format(responseBody, request.header.correlationId, request.header.clientId))\n+          responseBody\n         }\n-        trace(\"Sending FindCoordinator response %s for correlation id %d to client %s.\"\n-          .format(responseBody, request.header.correlationId, request.header.clientId))\n-        responseBody\n+\n+        requestHelper.sendResponseMaybeThrottle(request, createResponse)\n+      }\n+    }\n+  }\n+\n+  private def getCreateTopicsRequest(topics: Seq[String]): CreateTopicsRequest.Builder = {\n+    val topicCollection = new CreateTopicsRequestData.CreatableTopicCollection\n+    topics.foreach(topic => {\n+      topicCollection.add(getTopicConfigs(topic))\n+    })\n+\n+    new CreateTopicsRequest.Builder(\n+      new CreateTopicsRequestData()\n+        .setTimeoutMs(config.requestTimeoutMs)\n+        .setTopics(topicCollection)\n+    )\n+  }\n+\n+  private def getTopicConfigs(topic: String): CreatableTopic = {\n+    topic match {\n+      case GROUP_METADATA_TOPIC_NAME =>\n+        new CreatableTopic()\n+          .setName(topic)\n+          .setNumPartitions(config.offsetsTopicPartitions)", "originalCommit": "1d626d2bfea3fe6171083404acdaf08ee9779988", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTU5NDc0Mw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r561594743", "bodyText": "I agree it's equivalent, but I think we could be conservative here to keep the logic on broker side for now, to reduce logical change in this PR.", "author": "abbccdda", "createdAt": "2021-01-21T04:27:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1MDU0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA5MzYzNg==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569093636", "bodyText": "I don't think it is equivalent, at least not completely. My thought was to reduce the reliance on the broker's configuration, which is more likely to be stale than the controller. This actually raises an interesting question about the CreateTopic API which I had not thought of before. If we receive a CreateTopic request for an internal topic, which configuration should we use? Currently it looks like we will apply the standard topic defaults, but that does not seem right. I filed https://issues.apache.org/jira/browse/KAFKA-12280, so we can consider this later.", "author": "hachikuji", "createdAt": "2021-02-03T02:45:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1MDU0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1MTYwMg==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r561451602", "bodyText": "In the case of forwarding, maybe we can let the controller decide if there are enough alive brokers.", "author": "hachikuji", "createdAt": "2021-01-21T01:19:00Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1370,55 +1345,164 @@ class KafkaApis(val requestChannel: RequestChannel,\n         !authHelper.authorize(request.context, DESCRIBE, TRANSACTIONAL_ID, findCoordinatorRequest.data.key))\n       requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)\n     else {\n-      // get metadata (and create the topic if necessary)\n-      val (partition, topicMetadata) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n+      val (partition, internalTopicName) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n         case CoordinatorType.GROUP =>\n-          val partition = groupCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (groupCoordinator.partitionFor(findCoordinatorRequest.data.key), GROUP_METADATA_TOPIC_NAME)\n \n         case CoordinatorType.TRANSACTION =>\n-          val partition = txnCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(TRANSACTION_STATE_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (txnCoordinator.partitionFor(findCoordinatorRequest.data.key), TRANSACTION_STATE_TOPIC_NAME)\n+      }\n \n-        case _ =>\n-          throw new InvalidRequestException(\"Unknown coordinator type in FindCoordinator request\")\n+      val topicMetadata = metadataCache.getTopicMetadata(Set(internalTopicName), request.context.listenerName)\n+      def createFindCoordinatorResponse(error: Errors,\n+                                        node: Node,\n+                                        requestThrottleMs: Int,\n+                                        errorMessage: Option[String] = None): FindCoordinatorResponse = {\n+        new FindCoordinatorResponse(\n+          new FindCoordinatorResponseData()\n+            .setErrorCode(error.code)\n+            .setErrorMessage(errorMessage.getOrElse(error.message))\n+            .setNodeId(node.id)\n+            .setHost(node.host)\n+            .setPort(node.port)\n+            .setThrottleTimeMs(requestThrottleMs))\n       }\n \n-      def createResponse(requestThrottleMs: Int): AbstractResponse = {\n-        def createFindCoordinatorResponse(error: Errors, node: Node): FindCoordinatorResponse = {\n-          new FindCoordinatorResponse(\n-              new FindCoordinatorResponseData()\n-                .setErrorCode(error.code)\n-                .setErrorMessage(error.message)\n-                .setNodeId(node.id)\n-                .setHost(node.host)\n-                .setPort(node.port)\n-                .setThrottleTimeMs(requestThrottleMs))\n+      val topicCreationNeeded = topicMetadata.headOption.isEmpty\n+      if (topicCreationNeeded) {\n+        if (hasEnoughAliveBrokers(internalTopicName)) {", "originalCommit": "1d626d2bfea3fe6171083404acdaf08ee9779988", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjc5MjIxNA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r562792214", "bodyText": "I guess the purpose of doing live broker check here is to avoid sending excessive create topic requests.", "author": "abbccdda", "createdAt": "2021-01-22T17:34:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1MTYwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEzMjA4MQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569132081", "bodyText": "Ok. My thought is to reduce the reliance on the broker metadata. We will need the replication factor check on the controller anyway, so I'm not sure it is worth optimizing for the case when the cluster is initializing.\nPerhaps at least we can move this validation into AutoTopicCreationManager to better encapsulate the logic.", "author": "hachikuji", "createdAt": "2021-02-03T04:58:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1MTYwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDY1NDk1Mw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r570654953", "bodyText": "Sounds good", "author": "abbccdda", "createdAt": "2021-02-05T01:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1MTYwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1MjU4Mg==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r561452582", "bodyText": "nit: seems misaligned", "author": "hachikuji", "createdAt": "2021-01-21T01:22:07Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1110,82 +1098,39 @@ class KafkaApis(val requestChannel: RequestChannel,\n       .setPartitions(partitionData)\n   }\n \n-  private def createInternalTopic(topic: String): MetadataResponseTopic = {\n-    if (topic == null)\n-      throw new IllegalArgumentException(\"topic must not be null\")\n-\n-    val aliveBrokers = metadataCache.getAliveBrokers\n-\n-    topic match {\n-      case GROUP_METADATA_TOPIC_NAME =>\n-        if (aliveBrokers.size < config.offsetsTopicReplicationFactor) {\n-          error(s\"Number of alive brokers '${aliveBrokers.size}' does not meet the required replication factor \" +\n-            s\"'${config.offsetsTopicReplicationFactor}' for the offsets topic (configured via \" +\n-            s\"'${KafkaConfig.OffsetsTopicReplicationFactorProp}'). This error can be ignored if the cluster is starting up \" +\n-            s\"and not all brokers are up yet.\")\n-          metadataResponseTopic(Errors.COORDINATOR_NOT_AVAILABLE, topic, true, util.Collections.emptyList())\n-        } else {\n-          createTopic(topic, config.offsetsTopicPartitions, config.offsetsTopicReplicationFactor.toInt,\n-            groupCoordinator.offsetsTopicConfigs)\n-        }\n-      case TRANSACTION_STATE_TOPIC_NAME =>\n-        if (aliveBrokers.size < config.transactionTopicReplicationFactor) {\n-          error(s\"Number of alive brokers '${aliveBrokers.size}' does not meet the required replication factor \" +\n-            s\"'${config.transactionTopicReplicationFactor}' for the transactions state topic (configured via \" +\n-            s\"'${KafkaConfig.TransactionsTopicReplicationFactorProp}'). This error can be ignored if the cluster is starting up \" +\n-            s\"and not all brokers are up yet.\")\n-          metadataResponseTopic(Errors.COORDINATOR_NOT_AVAILABLE, topic, true, util.Collections.emptyList())\n-        } else {\n-          createTopic(topic, config.transactionTopicPartitions, config.transactionTopicReplicationFactor.toInt,\n-            txnCoordinator.transactionTopicConfigs)\n-        }\n-      case _ => throw new IllegalArgumentException(s\"Unexpected internal topic name: $topic\")\n-    }\n-  }\n-\n-  private def getOrCreateInternalTopic(topic: String, listenerName: ListenerName): MetadataResponseData.MetadataResponseTopic = {\n-    val topicMetadata = metadataCache.getTopicMetadata(Set(topic), listenerName)\n-    topicMetadata.headOption.getOrElse(createInternalTopic(topic))\n-  }\n-\n-  private def getTopicMetadata(allowAutoTopicCreation: Boolean, isFetchAllMetadata: Boolean,\n-                               topics: Set[String], listenerName: ListenerName,\n+  private def getTopicMetadata(allowAutoTopicCreation: Boolean,\n+                               isFetchAllMetadata: Boolean,\n+                               topics: Set[String],\n+                               listenerName: ListenerName,\n                                errorUnavailableEndpoints: Boolean,\n-                               errorUnavailableListeners: Boolean): Seq[MetadataResponseTopic] = {\n+                               errorUnavailableListeners: Boolean): (Seq[MetadataResponseTopic], Seq[MetadataResponseTopic]) = {\n     val topicResponses = metadataCache.getTopicMetadata(topics, listenerName,\n         errorUnavailableEndpoints, errorUnavailableListeners)\n \n     if (topics.isEmpty || topicResponses.size == topics.size) {\n-      topicResponses\n+      (topicResponses, Seq.empty[MetadataResponseTopic])\n     } else {\n       val nonExistentTopics = topics.diff(topicResponses.map(_.name).toSet)\n       val responsesForNonExistentTopics = nonExistentTopics.flatMap { topic =>\n-        if (isInternal(topic)) {\n-          val topicMetadata = createInternalTopic(topic)\n-          Some(\n-            if (topicMetadata.errorCode == Errors.COORDINATOR_NOT_AVAILABLE.code)\n-              metadataResponseTopic(Errors.INVALID_REPLICATION_FACTOR, topic, true, util.Collections.emptyList())\n-            else\n-              topicMetadata\n-          )\n-        } else if (isFetchAllMetadata) {\n+       if (isFetchAllMetadata) {\n           // A metadata request for all topics should never result in topic auto creation, but a topic may be deleted\n           // in between the creation of the topics parameter and topicResponses, so make sure to return None for this case.\n           None\n-        } else if (allowAutoTopicCreation && config.autoCreateTopicsEnable) {\n-          Some(createTopic(topic, config.numPartitions, config.defaultReplicationFactor))\n-        } else {\n-          Some(metadataResponseTopic(Errors.UNKNOWN_TOPIC_OR_PARTITION, topic, false, util.Collections.emptyList()))\n+       } else {\n+        Some(metadataResponseTopic(", "originalCommit": "1d626d2bfea3fe6171083404acdaf08ee9779988", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1NTIyMw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r561455223", "bodyText": "We seem to have lost this handling or am I missing something?", "author": "hachikuji", "createdAt": "2021-01-21T01:29:31Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1084,24 +1087,9 @@ class KafkaApis(val requestChannel: RequestChannel,\n     (responseTopics ++ unauthorizedResponseStatus).toList\n   }\n \n-  private def createTopic(topic: String,\n-                          numPartitions: Int,\n-                          replicationFactor: Int,\n-                          properties: util.Properties = new util.Properties()): MetadataResponseTopic = {\n-    try {\n-      adminZkClient.createTopic(topic, numPartitions, replicationFactor, properties, RackAwareMode.Safe)\n-      info(\"Auto creation of topic %s with %d partitions and replication factor %d is successful\"\n-        .format(topic, numPartitions, replicationFactor))\n-      metadataResponseTopic(Errors.LEADER_NOT_AVAILABLE, topic, isInternal(topic), util.Collections.emptyList())\n-    } catch {\n-      case _: TopicExistsException => // let it go, possibly another broker created this topic", "originalCommit": "1d626d2bfea3fe6171083404acdaf08ee9779988", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzAwMjkxMQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r563002911", "bodyText": "We intentionally avoid using adminZkClient so that we could go through topic creation rules through zkAdminManager. TopicExistsException is handled there.", "author": "abbccdda", "createdAt": "2021-01-23T02:17:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1NTIyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEzMDA5OA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569130098", "bodyText": "Inside ZkAdminManager.createTopics, I see that we catch TopicExistsException. However, I do not see any logic to translate it to LEADER_NOT_AVAILABLE. Can you show me where this happens?", "author": "hachikuji", "createdAt": "2021-02-03T04:52:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1NTIyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDU2ODE1MQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r570568151", "bodyText": "The problem we have is that ZkAdminManager.createTopics only takes a callback instead of responding to you in realtime whether we hit TopicExists. Right now we are doing the topic creation async, so unless this is necessary to be fixed (which today we would just return UNKNOWN_PARTITION which seems to be semantically similar to LEADER_NOT_AVAILABLE), I think we could just returning unknown partition immediately without waiting for the async creation?", "author": "abbccdda", "createdAt": "2021-02-04T21:51:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1NTIyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1NTkxNA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r561455914", "bodyText": "Hmm.. In the old logic, we would attempt topic creation through zookeeper first. Then, if the topic was created successfully, we would return LEADER_NOT_AVAILABLE to give time for the controller to elect a leader. Now we return LEADER_NOT_AVAILABLE immediately and we send the CreateTopic request asynchronously. We don't know if the CreateTopic request will ultimately succeed or not. Perhaps it would be better to keep returning UNKNOWN_TOPIC_OR_PARTITION until we see that the topic exists.", "author": "hachikuji", "createdAt": "2021-01-21T01:31:32Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1110,82 +1098,39 @@ class KafkaApis(val requestChannel: RequestChannel,\n       .setPartitions(partitionData)\n   }\n \n-  private def createInternalTopic(topic: String): MetadataResponseTopic = {\n-    if (topic == null)\n-      throw new IllegalArgumentException(\"topic must not be null\")\n-\n-    val aliveBrokers = metadataCache.getAliveBrokers\n-\n-    topic match {\n-      case GROUP_METADATA_TOPIC_NAME =>\n-        if (aliveBrokers.size < config.offsetsTopicReplicationFactor) {\n-          error(s\"Number of alive brokers '${aliveBrokers.size}' does not meet the required replication factor \" +\n-            s\"'${config.offsetsTopicReplicationFactor}' for the offsets topic (configured via \" +\n-            s\"'${KafkaConfig.OffsetsTopicReplicationFactorProp}'). This error can be ignored if the cluster is starting up \" +\n-            s\"and not all brokers are up yet.\")\n-          metadataResponseTopic(Errors.COORDINATOR_NOT_AVAILABLE, topic, true, util.Collections.emptyList())\n-        } else {\n-          createTopic(topic, config.offsetsTopicPartitions, config.offsetsTopicReplicationFactor.toInt,\n-            groupCoordinator.offsetsTopicConfigs)\n-        }\n-      case TRANSACTION_STATE_TOPIC_NAME =>\n-        if (aliveBrokers.size < config.transactionTopicReplicationFactor) {\n-          error(s\"Number of alive brokers '${aliveBrokers.size}' does not meet the required replication factor \" +\n-            s\"'${config.transactionTopicReplicationFactor}' for the transactions state topic (configured via \" +\n-            s\"'${KafkaConfig.TransactionsTopicReplicationFactorProp}'). This error can be ignored if the cluster is starting up \" +\n-            s\"and not all brokers are up yet.\")\n-          metadataResponseTopic(Errors.COORDINATOR_NOT_AVAILABLE, topic, true, util.Collections.emptyList())\n-        } else {\n-          createTopic(topic, config.transactionTopicPartitions, config.transactionTopicReplicationFactor.toInt,\n-            txnCoordinator.transactionTopicConfigs)\n-        }\n-      case _ => throw new IllegalArgumentException(s\"Unexpected internal topic name: $topic\")\n-    }\n-  }\n-\n-  private def getOrCreateInternalTopic(topic: String, listenerName: ListenerName): MetadataResponseData.MetadataResponseTopic = {\n-    val topicMetadata = metadataCache.getTopicMetadata(Set(topic), listenerName)\n-    topicMetadata.headOption.getOrElse(createInternalTopic(topic))\n-  }\n-\n-  private def getTopicMetadata(allowAutoTopicCreation: Boolean, isFetchAllMetadata: Boolean,\n-                               topics: Set[String], listenerName: ListenerName,\n+  private def getTopicMetadata(allowAutoTopicCreation: Boolean,\n+                               isFetchAllMetadata: Boolean,\n+                               topics: Set[String],\n+                               listenerName: ListenerName,\n                                errorUnavailableEndpoints: Boolean,\n-                               errorUnavailableListeners: Boolean): Seq[MetadataResponseTopic] = {\n+                               errorUnavailableListeners: Boolean): (Seq[MetadataResponseTopic], Seq[MetadataResponseTopic]) = {\n     val topicResponses = metadataCache.getTopicMetadata(topics, listenerName,\n         errorUnavailableEndpoints, errorUnavailableListeners)\n \n     if (topics.isEmpty || topicResponses.size == topics.size) {\n-      topicResponses\n+      (topicResponses, Seq.empty[MetadataResponseTopic])\n     } else {\n       val nonExistentTopics = topics.diff(topicResponses.map(_.name).toSet)\n       val responsesForNonExistentTopics = nonExistentTopics.flatMap { topic =>\n-        if (isInternal(topic)) {\n-          val topicMetadata = createInternalTopic(topic)\n-          Some(\n-            if (topicMetadata.errorCode == Errors.COORDINATOR_NOT_AVAILABLE.code)\n-              metadataResponseTopic(Errors.INVALID_REPLICATION_FACTOR, topic, true, util.Collections.emptyList())\n-            else\n-              topicMetadata\n-          )\n-        } else if (isFetchAllMetadata) {\n+       if (isFetchAllMetadata) {\n           // A metadata request for all topics should never result in topic auto creation, but a topic may be deleted\n           // in between the creation of the topics parameter and topicResponses, so make sure to return None for this case.\n           None\n-        } else if (allowAutoTopicCreation && config.autoCreateTopicsEnable) {\n-          Some(createTopic(topic, config.numPartitions, config.defaultReplicationFactor))\n-        } else {\n-          Some(metadataResponseTopic(Errors.UNKNOWN_TOPIC_OR_PARTITION, topic, false, util.Collections.emptyList()))\n+       } else {\n+        Some(metadataResponseTopic(\n+          if (!hasEnoughAliveBrokers(topic))\n+            Errors.INVALID_REPLICATION_FACTOR\n+          else if (allowAutoTopicCreation && config.autoCreateTopicsEnable)\n+            Errors.LEADER_NOT_AVAILABLE", "originalCommit": "1d626d2bfea3fe6171083404acdaf08ee9779988", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzAwMzM4OQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r563003389", "bodyText": "That makes sense", "author": "abbccdda", "createdAt": "2021-01-23T02:20:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ1NTkxNA=="}], "type": "inlineReview"}, {"oid": "0dcd806b2aad55f0aa7bd66cdbe882dc5594ea99", "url": "https://github.com/apache/kafka/commit/0dcd806b2aad55f0aa7bd66cdbe882dc5594ea99", "message": "auto topic manager", "committedDate": "2021-01-25T17:41:29Z", "type": "forcePushed"}, {"oid": "b303f129e4dfe126cec919f952b6196d1fbfe355", "url": "https://github.com/apache/kafka/commit/b303f129e4dfe126cec919f952b6196d1fbfe355", "message": "auto topic manager", "committedDate": "2021-01-27T05:15:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzNTM4Mw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r565035383", "bodyText": "Side cleanup which is called within requestThread.shutdown()", "author": "abbccdda", "createdAt": "2021-01-27T05:20:18Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -61,7 +61,6 @@ class BrokerToControllerChannelManager(\n \n   def shutdown(): Unit = {\n     requestThread.shutdown()\n-    requestThread.awaitShutdown()", "originalCommit": "b303f129e4dfe126cec919f952b6196d1fbfe355", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ed3d1d6cb03c14e75792f87835225a17fe350a86", "url": "https://github.com/apache/kafka/commit/ed3d1d6cb03c14e75792f87835225a17fe350a86", "message": "test fix (no forwarding)", "committedDate": "2021-01-28T04:41:44Z", "type": "forcePushed"}, {"oid": "f6b5586b7e43bf17aac45280b883096c9778a994", "url": "https://github.com/apache/kafka/commit/f6b5586b7e43bf17aac45280b883096c9778a994", "message": "test fix (no forwarding)", "committedDate": "2021-01-28T05:01:49Z", "type": "forcePushed"}, {"oid": "e5e9d624742633139e134e72747dcf1fe5adbca7", "url": "https://github.com/apache/kafka/commit/e5e9d624742633139e134e72747dcf1fe5adbca7", "message": "test fix (no forwarding)", "committedDate": "2021-01-29T03:22:01Z", "type": "forcePushed"}, {"oid": "be8dc498e00d032674447eb7d0a6c749b4ed5e95", "url": "https://github.com/apache/kafka/commit/be8dc498e00d032674447eb7d0a6c749b4ed5e95", "message": "always define auto topic creation manager", "committedDate": "2021-01-29T22:02:57Z", "type": "forcePushed"}, {"oid": "eb0562c4d10fe0f2677c776ee7514167238cc7db", "url": "https://github.com/apache/kafka/commit/eb0562c4d10fe0f2677c776ee7514167238cc7db", "message": "always define auto topic creation manager", "committedDate": "2021-01-30T17:45:19Z", "type": "forcePushed"}, {"oid": "d3124cf11ad8db9cb91bc778fd2c7ca63788c85c", "url": "https://github.com/apache/kafka/commit/d3124cf11ad8db9cb91bc778fd2c7ca63788c85c", "message": "always define auto topic creation manager", "committedDate": "2021-02-02T21:10:46Z", "type": "forcePushed"}, {"oid": "9b4521af2982c477658e286c4ee181416c4f5195", "url": "https://github.com/apache/kafka/commit/9b4521af2982c477658e286c4ee181416c4f5195", "message": "forward FindCoordinator/Metadata request when topic creation is needed\n\nalways define auto topic creation manager", "committedDate": "2021-02-03T00:50:00Z", "type": "forcePushed"}, {"oid": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "url": "https://github.com/apache/kafka/commit/2848e8d7e72e3857f6e8422820f9c5ad13621228", "message": "forward FindCoordinator/Metadata request when topic creation is needed\n\nalways define auto topic creation manager", "committedDate": "2021-02-03T01:25:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA2MDQ1NQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569060455", "bodyText": "nit: do we need default implementations?", "author": "hachikuji", "createdAt": "2021-02-03T01:51:13Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA2MTAzOA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569061038", "bodyText": "Let's leave this for a follow-up, but just want to mention that it is probably better if we can reuse the same BrokerToControllerChannelManager as ForwardingManager. Can you file a JIRA for a follow-up?", "author": "hachikuji", "createdAt": "2021-02-03T01:51:59Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n+}\n+\n+object AutoTopicCreationManager {\n+\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    adminManager: ZkAdminManager,\n+    controller: KafkaController,\n+    enableForwarding: Boolean\n+  ): AutoTopicCreationManager = {\n+\n+    val channelManager =\n+      if (enableForwarding)\n+        Some(new BrokerToControllerChannelManager(", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTkyNjg5Nw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569926897", "bodyText": "Sure, we do have https://issues.apache.org/jira/browse/KAFKA-10348 to track.", "author": "abbccdda", "createdAt": "2021-02-04T03:49:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA2MTAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA3MjM4MQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569072381", "bodyText": "Hmm, I agree the ordering of these checks was weird. So if isFetchAllMetadata is set, then responsesForNonExistentTopics will be empty and we will return (topicResponses, Seq.empty[MetadataResponseTopic]). Does that mean we can add this check to the first clause?\n  if (isFetchAllMetadata || topics.isEmpty || topicResponses.size == topics.size) {\n       (topicResponses, Seq.empty[MetadataResponseTopic])", "author": "hachikuji", "createdAt": "2021-02-03T02:06:38Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1113,82 +1097,36 @@ class KafkaApis(val requestChannel: RequestChannel,\n       .setPartitions(partitionData)\n   }\n \n-  private def createInternalTopic(topic: String): MetadataResponseTopic = {\n-    if (topic == null)\n-      throw new IllegalArgumentException(\"topic must not be null\")\n-\n-    val aliveBrokers = metadataCache.getAliveBrokers\n-\n-    topic match {\n-      case GROUP_METADATA_TOPIC_NAME =>\n-        if (aliveBrokers.size < config.offsetsTopicReplicationFactor) {\n-          error(s\"Number of alive brokers '${aliveBrokers.size}' does not meet the required replication factor \" +\n-            s\"'${config.offsetsTopicReplicationFactor}' for the offsets topic (configured via \" +\n-            s\"'${KafkaConfig.OffsetsTopicReplicationFactorProp}'). This error can be ignored if the cluster is starting up \" +\n-            s\"and not all brokers are up yet.\")\n-          metadataResponseTopic(Errors.COORDINATOR_NOT_AVAILABLE, topic, true, util.Collections.emptyList())\n-        } else {\n-          createTopic(topic, config.offsetsTopicPartitions, config.offsetsTopicReplicationFactor.toInt,\n-            groupCoordinator.offsetsTopicConfigs)\n-        }\n-      case TRANSACTION_STATE_TOPIC_NAME =>\n-        if (aliveBrokers.size < config.transactionTopicReplicationFactor) {\n-          error(s\"Number of alive brokers '${aliveBrokers.size}' does not meet the required replication factor \" +\n-            s\"'${config.transactionTopicReplicationFactor}' for the transactions state topic (configured via \" +\n-            s\"'${KafkaConfig.TransactionsTopicReplicationFactorProp}'). This error can be ignored if the cluster is starting up \" +\n-            s\"and not all brokers are up yet.\")\n-          metadataResponseTopic(Errors.COORDINATOR_NOT_AVAILABLE, topic, true, util.Collections.emptyList())\n-        } else {\n-          createTopic(topic, config.transactionTopicPartitions, config.transactionTopicReplicationFactor.toInt,\n-            txnCoordinator.transactionTopicConfigs)\n-        }\n-      case _ => throw new IllegalArgumentException(s\"Unexpected internal topic name: $topic\")\n-    }\n-  }\n-\n-  private def getOrCreateInternalTopic(topic: String, listenerName: ListenerName): MetadataResponseData.MetadataResponseTopic = {\n-    val topicMetadata = metadataCache.getTopicMetadata(Set(topic), listenerName)\n-    topicMetadata.headOption.getOrElse(createInternalTopic(topic))\n-  }\n-\n-  private def getTopicMetadata(allowAutoTopicCreation: Boolean, isFetchAllMetadata: Boolean,\n-                               topics: Set[String], listenerName: ListenerName,\n+  private def getTopicMetadata(isFetchAllMetadata: Boolean,\n+                               topics: Set[String],\n+                               listenerName: ListenerName,\n                                errorUnavailableEndpoints: Boolean,\n-                               errorUnavailableListeners: Boolean): Seq[MetadataResponseTopic] = {\n+                               errorUnavailableListeners: Boolean): (Seq[MetadataResponseTopic], Seq[MetadataResponseTopic]) = {\n     val topicResponses = metadataCache.getTopicMetadata(topics, listenerName,\n         errorUnavailableEndpoints, errorUnavailableListeners)\n \n     if (topics.isEmpty || topicResponses.size == topics.size) {\n-      topicResponses\n+      (topicResponses, Seq.empty[MetadataResponseTopic])\n     } else {\n       val nonExistentTopics = topics.diff(topicResponses.map(_.name).toSet)\n       val responsesForNonExistentTopics = nonExistentTopics.flatMap { topic =>\n-        if (isInternal(topic)) {\n-          val topicMetadata = createInternalTopic(topic)\n-          Some(\n-            if (topicMetadata.errorCode == Errors.COORDINATOR_NOT_AVAILABLE.code)\n-              metadataResponseTopic(Errors.INVALID_REPLICATION_FACTOR, topic, true, util.Collections.emptyList())\n-            else\n-              topicMetadata\n-          )\n-        } else if (isFetchAllMetadata) {\n+       if (isFetchAllMetadata) {", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDM5NjY3Mw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r570396673", "bodyText": "Yes, I think so.", "author": "abbccdda", "createdAt": "2021-02-04T17:10:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA3MjM4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA3MzE3MA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569073170", "bodyText": "nit: usually we write as\nnonExistTopicMetadata.foreach { metadata =>", "author": "hachikuji", "createdAt": "2021-02-03T02:07:38Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1234,19 +1171,28 @@ class KafkaApis(val requestChannel: RequestChannel,\n     // In versions 5 and below, we returned LEADER_NOT_AVAILABLE if a matching listener was not found on the leader.\n     // From version 6 onwards, we return LISTENER_NOT_FOUND to enable diagnosis of configuration errors.\n     val errorUnavailableListeners = requestVersion >= 6\n-    val topicMetadata =\n+    val (topicMetadata, nonExistTopicMetadata) =\n       if (authorizedTopics.isEmpty)\n-        Seq.empty[MetadataResponseTopic]\n-      else {\n-        getTopicMetadata(\n-          metadataRequest.allowAutoTopicCreation,\n-          metadataRequest.isAllTopics,\n-          authorizedTopics,\n-          request.context.listenerName,\n-          errorUnavailableEndpoints,\n-          errorUnavailableListeners\n-        )\n+        (Seq.empty[MetadataResponseTopic], Seq.empty[MetadataResponseTopic])\n+      else\n+        getTopicMetadata(metadataRequest.isAllTopics, authorizedTopics,\n+          request.context.listenerName, errorUnavailableEndpoints, errorUnavailableListeners)\n+\n+    nonExistTopicMetadata.foreach(metadata =>", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA5NjMwNA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569096304", "bodyText": "Feels to me like we would benefit by moving this logic into AutoTopicCreationManager. The configuration for auto-created topics can always be derived from the broker configuration. Hence we could simplify the interface by letting it take only the topic names. The advantage is that we can move all of this logic out of KafkaApis (which is now up to 3500 LOC).", "author": "hachikuji", "createdAt": "2021-02-03T02:54:18Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1375,55 +1325,137 @@ class KafkaApis(val requestChannel: RequestChannel,\n         !authHelper.authorize(request.context, DESCRIBE, TRANSACTIONAL_ID, findCoordinatorRequest.data.key))\n       requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)\n     else {\n-      // get metadata (and create the topic if necessary)\n-      val (partition, topicMetadata) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n+      val (partition, internalTopicName) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n         case CoordinatorType.GROUP =>\n-          val partition = groupCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (groupCoordinator.partitionFor(findCoordinatorRequest.data.key), GROUP_METADATA_TOPIC_NAME)\n \n         case CoordinatorType.TRANSACTION =>\n-          val partition = txnCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(TRANSACTION_STATE_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (txnCoordinator.partitionFor(findCoordinatorRequest.data.key), TRANSACTION_STATE_TOPIC_NAME)\n+      }\n \n-        case _ =>\n-          throw new InvalidRequestException(\"Unknown coordinator type in FindCoordinator request\")\n+      val topicMetadata = metadataCache.getTopicMetadata(Set(internalTopicName), request.context.listenerName)\n+      def createFindCoordinatorResponse(error: Errors,\n+                                        node: Node,\n+                                        requestThrottleMs: Int,\n+                                        errorMessage: Option[String] = None): FindCoordinatorResponse = {\n+        new FindCoordinatorResponse(\n+          new FindCoordinatorResponseData()\n+            .setErrorCode(error.code)\n+            .setErrorMessage(errorMessage.getOrElse(error.message))\n+            .setNodeId(node.id)\n+            .setHost(node.host)\n+            .setPort(node.port)\n+            .setThrottleTimeMs(requestThrottleMs))\n       }\n \n-      def createResponse(requestThrottleMs: Int): AbstractResponse = {\n-        def createFindCoordinatorResponse(error: Errors, node: Node): FindCoordinatorResponse = {\n-          new FindCoordinatorResponse(\n-              new FindCoordinatorResponseData()\n-                .setErrorCode(error.code)\n-                .setErrorMessage(error.message)\n-                .setNodeId(node.id)\n-                .setHost(node.host)\n-                .setPort(node.port)\n-                .setThrottleTimeMs(requestThrottleMs))\n+      if (topicMetadata.headOption.isEmpty) {\n+        if (hasEnoughAliveBrokers(internalTopicName)) {\n+          val controllerMutationQuota = quotas.controllerMutation.newQuotaFor(request, strictSinceVersion = 6)\n+          autoTopicCreationManager.createTopics(\n+            Seq(getTopicConfigs(internalTopicName)).toSet, controllerMutationQuota)\n         }\n-        val responseBody = if (topicMetadata.errorCode != Errors.NONE.code) {\n-          createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode)\n-        } else {\n-          val coordinatorEndpoint = topicMetadata.partitions.asScala\n-            .find(_.partitionIndex == partition)\n-            .filter(_.leaderId != MetadataResponse.NO_LEADER_ID)\n-            .flatMap(metadata => metadataCache.getAliveBroker(metadata.leaderId))\n-            .flatMap(_.getNode(request.context.listenerName))\n-            .filterNot(_.isEmpty)\n-\n-          coordinatorEndpoint match {\n-            case Some(endpoint) =>\n-              createFindCoordinatorResponse(Errors.NONE, endpoint)\n-            case _ =>\n-              createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode)\n+        requestHelper.sendResponseMaybeThrottle(request, requestThrottleMs => createFindCoordinatorResponse(\n+          Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs))\n+      } else {\n+        def createResponse(requestThrottleMs: Int): AbstractResponse = {\n+          val responseBody = if (topicMetadata.head.errorCode != Errors.NONE.code) {\n+            createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs)\n+          } else {\n+            val coordinatorEndpoint = topicMetadata.head.partitions.asScala\n+              .find(_.partitionIndex == partition)\n+              .filter(_.leaderId != MetadataResponse.NO_LEADER_ID)\n+              .flatMap(metadata => metadataCache.getAliveBroker(metadata.leaderId))\n+              .flatMap(_.getNode(request.context.listenerName))\n+              .filterNot(_.isEmpty)\n+\n+            coordinatorEndpoint match {\n+              case Some(endpoint) =>\n+                createFindCoordinatorResponse(Errors.NONE, endpoint, requestThrottleMs)\n+              case _ =>\n+                createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs)\n+            }\n           }\n+          trace(\"Sending FindCoordinator response %s for correlation id %d to client %s.\"\n+            .format(responseBody, request.header.correlationId, request.header.clientId))\n+          responseBody\n         }\n-        trace(\"Sending FindCoordinator response %s for correlation id %d to client %s.\"\n-          .format(responseBody, request.header.correlationId, request.header.clientId))\n-        responseBody\n+\n+        requestHelper.sendResponseMaybeThrottle(request, createResponse)\n       }\n-      requestHelper.sendResponseMaybeThrottle(request, createResponse)\n+    }\n+  }\n+\n+  private def getTopicConfigs(topic: String): CreatableTopic = {\n+    topic match {\n+      case GROUP_METADATA_TOPIC_NAME =>\n+        new CreatableTopic()\n+          .setName(topic)\n+          .setNumPartitions(config.offsetsTopicPartitions)\n+          .setReplicationFactor(config.offsetsTopicReplicationFactor)\n+          .setConfigs(convertToTopicConfigCollections(groupCoordinator.offsetsTopicConfigs))\n+      case TRANSACTION_STATE_TOPIC_NAME =>\n+        new CreatableTopic()", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEyNTcyMQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569125721", "bodyText": "The differences between these log lines are minor. Can we factor out a helper?", "author": "hachikuji", "createdAt": "2021-02-03T04:36:48Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1375,55 +1325,137 @@ class KafkaApis(val requestChannel: RequestChannel,\n         !authHelper.authorize(request.context, DESCRIBE, TRANSACTIONAL_ID, findCoordinatorRequest.data.key))\n       requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)\n     else {\n-      // get metadata (and create the topic if necessary)\n-      val (partition, topicMetadata) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n+      val (partition, internalTopicName) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n         case CoordinatorType.GROUP =>\n-          val partition = groupCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (groupCoordinator.partitionFor(findCoordinatorRequest.data.key), GROUP_METADATA_TOPIC_NAME)\n \n         case CoordinatorType.TRANSACTION =>\n-          val partition = txnCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(TRANSACTION_STATE_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (txnCoordinator.partitionFor(findCoordinatorRequest.data.key), TRANSACTION_STATE_TOPIC_NAME)\n+      }\n \n-        case _ =>\n-          throw new InvalidRequestException(\"Unknown coordinator type in FindCoordinator request\")\n+      val topicMetadata = metadataCache.getTopicMetadata(Set(internalTopicName), request.context.listenerName)\n+      def createFindCoordinatorResponse(error: Errors,\n+                                        node: Node,\n+                                        requestThrottleMs: Int,\n+                                        errorMessage: Option[String] = None): FindCoordinatorResponse = {\n+        new FindCoordinatorResponse(\n+          new FindCoordinatorResponseData()\n+            .setErrorCode(error.code)\n+            .setErrorMessage(errorMessage.getOrElse(error.message))\n+            .setNodeId(node.id)\n+            .setHost(node.host)\n+            .setPort(node.port)\n+            .setThrottleTimeMs(requestThrottleMs))\n       }\n \n-      def createResponse(requestThrottleMs: Int): AbstractResponse = {\n-        def createFindCoordinatorResponse(error: Errors, node: Node): FindCoordinatorResponse = {\n-          new FindCoordinatorResponse(\n-              new FindCoordinatorResponseData()\n-                .setErrorCode(error.code)\n-                .setErrorMessage(error.message)\n-                .setNodeId(node.id)\n-                .setHost(node.host)\n-                .setPort(node.port)\n-                .setThrottleTimeMs(requestThrottleMs))\n+      if (topicMetadata.headOption.isEmpty) {\n+        if (hasEnoughAliveBrokers(internalTopicName)) {\n+          val controllerMutationQuota = quotas.controllerMutation.newQuotaFor(request, strictSinceVersion = 6)\n+          autoTopicCreationManager.createTopics(\n+            Seq(getTopicConfigs(internalTopicName)).toSet, controllerMutationQuota)\n         }\n-        val responseBody = if (topicMetadata.errorCode != Errors.NONE.code) {\n-          createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode)\n-        } else {\n-          val coordinatorEndpoint = topicMetadata.partitions.asScala\n-            .find(_.partitionIndex == partition)\n-            .filter(_.leaderId != MetadataResponse.NO_LEADER_ID)\n-            .flatMap(metadata => metadataCache.getAliveBroker(metadata.leaderId))\n-            .flatMap(_.getNode(request.context.listenerName))\n-            .filterNot(_.isEmpty)\n-\n-          coordinatorEndpoint match {\n-            case Some(endpoint) =>\n-              createFindCoordinatorResponse(Errors.NONE, endpoint)\n-            case _ =>\n-              createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode)\n+        requestHelper.sendResponseMaybeThrottle(request, requestThrottleMs => createFindCoordinatorResponse(\n+          Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs))\n+      } else {\n+        def createResponse(requestThrottleMs: Int): AbstractResponse = {\n+          val responseBody = if (topicMetadata.head.errorCode != Errors.NONE.code) {\n+            createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs)\n+          } else {\n+            val coordinatorEndpoint = topicMetadata.head.partitions.asScala\n+              .find(_.partitionIndex == partition)\n+              .filter(_.leaderId != MetadataResponse.NO_LEADER_ID)\n+              .flatMap(metadata => metadataCache.getAliveBroker(metadata.leaderId))\n+              .flatMap(_.getNode(request.context.listenerName))\n+              .filterNot(_.isEmpty)\n+\n+            coordinatorEndpoint match {\n+              case Some(endpoint) =>\n+                createFindCoordinatorResponse(Errors.NONE, endpoint, requestThrottleMs)\n+              case _ =>\n+                createFindCoordinatorResponse(Errors.COORDINATOR_NOT_AVAILABLE, Node.noNode, requestThrottleMs)\n+            }\n           }\n+          trace(\"Sending FindCoordinator response %s for correlation id %d to client %s.\"\n+            .format(responseBody, request.header.correlationId, request.header.clientId))\n+          responseBody\n         }\n-        trace(\"Sending FindCoordinator response %s for correlation id %d to client %s.\"\n-          .format(responseBody, request.header.correlationId, request.header.clientId))\n-        responseBody\n+\n+        requestHelper.sendResponseMaybeThrottle(request, createResponse)\n       }\n-      requestHelper.sendResponseMaybeThrottle(request, createResponse)\n+    }\n+  }\n+\n+  private def getTopicConfigs(topic: String): CreatableTopic = {\n+    topic match {\n+      case GROUP_METADATA_TOPIC_NAME =>\n+        new CreatableTopic()\n+          .setName(topic)\n+          .setNumPartitions(config.offsetsTopicPartitions)\n+          .setReplicationFactor(config.offsetsTopicReplicationFactor)\n+          .setConfigs(convertToTopicConfigCollections(groupCoordinator.offsetsTopicConfigs))\n+      case TRANSACTION_STATE_TOPIC_NAME =>\n+        new CreatableTopic()\n+          .setName(topic)\n+          .setNumPartitions(config.transactionTopicPartitions)\n+          .setReplicationFactor(config.transactionTopicReplicationFactor)\n+          .setConfigs(convertToTopicConfigCollections(\n+            txnCoordinator.transactionTopicConfigs))\n+      case topicName =>\n+        new CreatableTopic()\n+          .setName(topicName)\n+          .setNumPartitions(config.numPartitions)\n+          .setReplicationFactor(config.defaultReplicationFactor.shortValue)\n+    }\n+  }\n+\n+  private def convertToTopicConfigCollections(config: Properties): CreateableTopicConfigCollection = {\n+    val topicConfigs = new CreateableTopicConfigCollection()\n+    config.forEach {\n+      case (name, value) =>\n+        topicConfigs.add(new CreateableTopicConfig()\n+          .setName(name.toString)\n+          .setValue(value.toString))\n+    }\n+    topicConfigs\n+  }\n+\n+  private def hasEnoughAliveBrokers(topic: String): Boolean = {\n+    if (topic == null)\n+      throw new IllegalArgumentException(\"topic must not be null\")\n+\n+    val aliveBrokers = metadataCache.getAliveBrokers\n+\n+    topic match {\n+      case GROUP_METADATA_TOPIC_NAME =>\n+        if (aliveBrokers.size < config.offsetsTopicReplicationFactor) {\n+          error(s\"Number of alive brokers '${aliveBrokers.size}' does not meet the required replication factor \" +", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEyNjg4Mg==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569126882", "bodyText": "nit: is error.message actually useful to send back? It doesn't provide any information beyond the error code. Could we just use errorMessage.orNull?", "author": "hachikuji", "createdAt": "2021-02-03T04:40:34Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1375,55 +1325,137 @@ class KafkaApis(val requestChannel: RequestChannel,\n         !authHelper.authorize(request.context, DESCRIBE, TRANSACTIONAL_ID, findCoordinatorRequest.data.key))\n       requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)\n     else {\n-      // get metadata (and create the topic if necessary)\n-      val (partition, topicMetadata) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n+      val (partition, internalTopicName) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n         case CoordinatorType.GROUP =>\n-          val partition = groupCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (groupCoordinator.partitionFor(findCoordinatorRequest.data.key), GROUP_METADATA_TOPIC_NAME)\n \n         case CoordinatorType.TRANSACTION =>\n-          val partition = txnCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(TRANSACTION_STATE_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (txnCoordinator.partitionFor(findCoordinatorRequest.data.key), TRANSACTION_STATE_TOPIC_NAME)\n+      }\n \n-        case _ =>\n-          throw new InvalidRequestException(\"Unknown coordinator type in FindCoordinator request\")\n+      val topicMetadata = metadataCache.getTopicMetadata(Set(internalTopicName), request.context.listenerName)\n+      def createFindCoordinatorResponse(error: Errors,\n+                                        node: Node,\n+                                        requestThrottleMs: Int,\n+                                        errorMessage: Option[String] = None): FindCoordinatorResponse = {\n+        new FindCoordinatorResponse(\n+          new FindCoordinatorResponseData()\n+            .setErrorCode(error.code)\n+            .setErrorMessage(errorMessage.getOrElse(error.message))", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTkxMjkzMQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569912931", "bodyText": "Makes sense", "author": "abbccdda", "createdAt": "2021-02-04T03:03:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEyNjg4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEyNzMyOA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569127328", "bodyText": "Maybe I'm missing it, but where is this argument used?", "author": "hachikuji", "createdAt": "2021-02-03T04:42:16Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1375,55 +1325,137 @@ class KafkaApis(val requestChannel: RequestChannel,\n         !authHelper.authorize(request.context, DESCRIBE, TRANSACTIONAL_ID, findCoordinatorRequest.data.key))\n       requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)\n     else {\n-      // get metadata (and create the topic if necessary)\n-      val (partition, topicMetadata) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n+      val (partition, internalTopicName) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n         case CoordinatorType.GROUP =>\n-          val partition = groupCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(GROUP_METADATA_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (groupCoordinator.partitionFor(findCoordinatorRequest.data.key), GROUP_METADATA_TOPIC_NAME)\n \n         case CoordinatorType.TRANSACTION =>\n-          val partition = txnCoordinator.partitionFor(findCoordinatorRequest.data.key)\n-          val metadata = getOrCreateInternalTopic(TRANSACTION_STATE_TOPIC_NAME, request.context.listenerName)\n-          (partition, metadata)\n+          (txnCoordinator.partitionFor(findCoordinatorRequest.data.key), TRANSACTION_STATE_TOPIC_NAME)\n+      }\n \n-        case _ =>\n-          throw new InvalidRequestException(\"Unknown coordinator type in FindCoordinator request\")\n+      val topicMetadata = metadataCache.getTopicMetadata(Set(internalTopicName), request.context.listenerName)\n+      def createFindCoordinatorResponse(error: Errors,\n+                                        node: Node,\n+                                        requestThrottleMs: Int,\n+                                        errorMessage: Option[String] = None): FindCoordinatorResponse = {", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTkxMzUwNg==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569913506", "bodyText": "Seems no longer in use, will remove and revert back to using error code message.", "author": "abbccdda", "createdAt": "2021-02-04T03:05:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEyNzMyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEyNzU1OA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569127558", "bodyText": "Pre-existing issue. CoordinatorType.forId returns IllegalArgumentException if the key type is unknown. That will get translated to UNKNOWN_SERVER_ERROR. It would be better to return INVALID_REQUEST.", "author": "hachikuji", "createdAt": "2021-02-03T04:43:21Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1375,55 +1325,137 @@ class KafkaApis(val requestChannel: RequestChannel,\n         !authHelper.authorize(request.context, DESCRIBE, TRANSACTIONAL_ID, findCoordinatorRequest.data.key))\n       requestHelper.sendErrorResponseMaybeThrottle(request, Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED.exception)\n     else {\n-      // get metadata (and create the topic if necessary)\n-      val (partition, topicMetadata) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {\n+      val (partition, internalTopicName) = CoordinatorType.forId(findCoordinatorRequest.data.keyType) match {", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEzOTgzMQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569139831", "bodyText": "Is the idea to validate before sending the CreateTopic? Could we move this to AutoTopicManager?", "author": "hachikuji", "createdAt": "2021-02-03T05:25:33Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1234,19 +1171,28 @@ class KafkaApis(val requestChannel: RequestChannel,\n     // In versions 5 and below, we returned LEADER_NOT_AVAILABLE if a matching listener was not found on the leader.\n     // From version 6 onwards, we return LISTENER_NOT_FOUND to enable diagnosis of configuration errors.\n     val errorUnavailableListeners = requestVersion >= 6\n-    val topicMetadata =\n+    val (topicMetadata, nonExistTopicMetadata) =\n       if (authorizedTopics.isEmpty)\n-        Seq.empty[MetadataResponseTopic]\n-      else {\n-        getTopicMetadata(\n-          metadataRequest.allowAutoTopicCreation,\n-          metadataRequest.isAllTopics,\n-          authorizedTopics,\n-          request.context.listenerName,\n-          errorUnavailableEndpoints,\n-          errorUnavailableListeners\n-        )\n+        (Seq.empty[MetadataResponseTopic], Seq.empty[MetadataResponseTopic])\n+      else\n+        getTopicMetadata(metadataRequest.isAllTopics, authorizedTopics,\n+          request.context.listenerName, errorUnavailableEndpoints, errorUnavailableListeners)\n+\n+    nonExistTopicMetadata.foreach(metadata =>\n+      try {\n+        // Validate topic name and propagate error if failed\n+        Topic.validate(metadata.name())", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDQ4MDM5OQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r570480399", "bodyText": "Actually after looking into the zk admin manager logic, I don't think it's necessary to do the topic validation here.", "author": "abbccdda", "createdAt": "2021-02-04T19:16:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTEzOTgzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0MDY0NQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569140645", "bodyText": "Not sure if I am missing something, but doesn't nonExistTopicMetadata include topics which failed the Topic.validate check above?", "author": "hachikuji", "createdAt": "2021-02-03T05:27:35Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1234,19 +1171,28 @@ class KafkaApis(val requestChannel: RequestChannel,\n     // In versions 5 and below, we returned LEADER_NOT_AVAILABLE if a matching listener was not found on the leader.\n     // From version 6 onwards, we return LISTENER_NOT_FOUND to enable diagnosis of configuration errors.\n     val errorUnavailableListeners = requestVersion >= 6\n-    val topicMetadata =\n+    val (topicMetadata, nonExistTopicMetadata) =\n       if (authorizedTopics.isEmpty)\n-        Seq.empty[MetadataResponseTopic]\n-      else {\n-        getTopicMetadata(\n-          metadataRequest.allowAutoTopicCreation,\n-          metadataRequest.isAllTopics,\n-          authorizedTopics,\n-          request.context.listenerName,\n-          errorUnavailableEndpoints,\n-          errorUnavailableListeners\n-        )\n+        (Seq.empty[MetadataResponseTopic], Seq.empty[MetadataResponseTopic])\n+      else\n+        getTopicMetadata(metadataRequest.isAllTopics, authorizedTopics,\n+          request.context.listenerName, errorUnavailableEndpoints, errorUnavailableListeners)\n+\n+    nonExistTopicMetadata.foreach(metadata =>\n+      try {\n+        // Validate topic name and propagate error if failed\n+        Topic.validate(metadata.name())\n+      } catch {\n+        case e: Exception =>\n+          metadata.setErrorCode(Errors.forException(e).code)\n       }\n+    )\n+\n+    if (nonExistTopicMetadata.nonEmpty && metadataRequest.allowAutoTopicCreation && config.autoCreateTopicsEnable) {\n+      val controllerMutationQuota = quotas.controllerMutation.newQuotaFor(request, strictSinceVersion = 6)\n+      autoTopicCreationManager.createTopics(\n+        nonExistTopicMetadata.map(metadata => getTopicConfigs(metadata.name())).toSet, controllerMutationQuota)", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDQ5MjQzMQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r570492431", "bodyText": "I guess we could rely on admin manager to do the validation for us.", "author": "abbccdda", "createdAt": "2021-02-04T19:36:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0MDY0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NTExNw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569145117", "bodyText": "nit: unnecessary braces", "author": "hachikuji", "createdAt": "2021-02-03T05:41:49Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n+}\n+\n+object AutoTopicCreationManager {\n+\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    adminManager: ZkAdminManager,\n+    controller: KafkaController,\n+    enableForwarding: Boolean\n+  ): AutoTopicCreationManager = {\n+\n+    val channelManager =\n+      if (enableForwarding)\n+        Some(new BrokerToControllerChannelManager(\n+          controllerNodeProvider = MetadataCacheControllerNodeProvider(\n+            config, metadataCache),\n+          time = time,\n+          metrics = metrics,\n+          config = config,\n+          channelName = \"autoTopicCreationChannel\",\n+          threadNamePrefix = threadNamePrefix,\n+          retryTimeoutMs = config.requestTimeoutMs.longValue\n+        ))\n+      else\n+        None\n+    new AutoTopicCreationManagerImpl(channelManager, adminManager, controller, config.requestTimeoutMs)\n+  }\n+}\n+\n+class AutoTopicCreationManagerImpl(\n+  channelManager: Option[BrokerToControllerChannelManager],\n+  adminManager: ZkAdminManager,\n+  controller: KafkaController,\n+  requestTimeout: Int\n+) extends AutoTopicCreationManager with Logging {\n+\n+  private val inflightTopics = new ConcurrentHashMap[String, CreatableTopic]\n+\n+  override def start(): Unit = {\n+    channelManager.foreach(_.start())\n+  }\n+\n+  override def shutdown(): Unit = {\n+    channelManager.foreach(_.shutdown())\n+  }\n+\n+  override def createTopics(topics: Set[CreatableTopic],\n+                            controllerMutationQuota: ControllerMutationQuota): Unit = {\n+    val topicConfigs = topics\n+      .filter(topic => !inflightTopics.contains(topic.name()))\n+      .map(topic => {(topic.name(), topic)}).toMap", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NTIzNw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569145237", "bodyText": "nit: there are a few of these throughout, but the parenthesis are unnecessary", "author": "hachikuji", "createdAt": "2021-02-03T05:42:13Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n+}\n+\n+object AutoTopicCreationManager {\n+\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    adminManager: ZkAdminManager,\n+    controller: KafkaController,\n+    enableForwarding: Boolean\n+  ): AutoTopicCreationManager = {\n+\n+    val channelManager =\n+      if (enableForwarding)\n+        Some(new BrokerToControllerChannelManager(\n+          controllerNodeProvider = MetadataCacheControllerNodeProvider(\n+            config, metadataCache),\n+          time = time,\n+          metrics = metrics,\n+          config = config,\n+          channelName = \"autoTopicCreationChannel\",\n+          threadNamePrefix = threadNamePrefix,\n+          retryTimeoutMs = config.requestTimeoutMs.longValue\n+        ))\n+      else\n+        None\n+    new AutoTopicCreationManagerImpl(channelManager, adminManager, controller, config.requestTimeoutMs)\n+  }\n+}\n+\n+class AutoTopicCreationManagerImpl(\n+  channelManager: Option[BrokerToControllerChannelManager],\n+  adminManager: ZkAdminManager,\n+  controller: KafkaController,\n+  requestTimeout: Int\n+) extends AutoTopicCreationManager with Logging {\n+\n+  private val inflightTopics = new ConcurrentHashMap[String, CreatableTopic]\n+\n+  override def start(): Unit = {\n+    channelManager.foreach(_.start())\n+  }\n+\n+  override def shutdown(): Unit = {\n+    channelManager.foreach(_.shutdown())\n+  }\n+\n+  override def createTopics(topics: Set[CreatableTopic],\n+                            controllerMutationQuota: ControllerMutationQuota): Unit = {\n+    val topicConfigs = topics\n+      .filter(topic => !inflightTopics.contains(topic.name()))", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDQ5MjIyMQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r570492221", "bodyText": "You mean omit () for topic.name()?", "author": "abbccdda", "createdAt": "2021-02-04T19:35:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NTIzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NjA1OA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569146058", "bodyText": "We only get this message if all of the topics are already inflight. Perhaps it is still useful if only some of them are inflight?", "author": "hachikuji", "createdAt": "2021-02-03T05:44:56Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n+}\n+\n+object AutoTopicCreationManager {\n+\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    adminManager: ZkAdminManager,\n+    controller: KafkaController,\n+    enableForwarding: Boolean\n+  ): AutoTopicCreationManager = {\n+\n+    val channelManager =\n+      if (enableForwarding)\n+        Some(new BrokerToControllerChannelManager(\n+          controllerNodeProvider = MetadataCacheControllerNodeProvider(\n+            config, metadataCache),\n+          time = time,\n+          metrics = metrics,\n+          config = config,\n+          channelName = \"autoTopicCreationChannel\",\n+          threadNamePrefix = threadNamePrefix,\n+          retryTimeoutMs = config.requestTimeoutMs.longValue\n+        ))\n+      else\n+        None\n+    new AutoTopicCreationManagerImpl(channelManager, adminManager, controller, config.requestTimeoutMs)\n+  }\n+}\n+\n+class AutoTopicCreationManagerImpl(\n+  channelManager: Option[BrokerToControllerChannelManager],\n+  adminManager: ZkAdminManager,\n+  controller: KafkaController,\n+  requestTimeout: Int\n+) extends AutoTopicCreationManager with Logging {\n+\n+  private val inflightTopics = new ConcurrentHashMap[String, CreatableTopic]\n+\n+  override def start(): Unit = {\n+    channelManager.foreach(_.start())\n+  }\n+\n+  override def shutdown(): Unit = {\n+    channelManager.foreach(_.shutdown())\n+  }\n+\n+  override def createTopics(topics: Set[CreatableTopic],\n+                            controllerMutationQuota: ControllerMutationQuota): Unit = {\n+    val topicConfigs = topics\n+      .filter(topic => !inflightTopics.contains(topic.name()))\n+      .map(topic => {(topic.name(), topic)}).toMap\n+\n+    if (topicConfigs.nonEmpty) {\n+      if (!controller.isActive && channelManager.isDefined) {\n+        // Mark the topics as inflight during auto creation through forwarding.\n+        topicConfigs.foreach(config => inflightTopics.put(config._1, config._2))\n+\n+        val topicsToCreate = new CreateTopicsRequestData.CreatableTopicCollection\n+        topicConfigs.foreach(config => topicsToCreate.add(config._2))\n+        val createTopicsRequest = new CreateTopicsRequest.Builder(\n+          new CreateTopicsRequestData()\n+            .setTimeoutMs(requestTimeout)\n+            .setTopics(topicsToCreate)\n+        )\n+\n+        channelManager.get.sendRequest(createTopicsRequest, new ControllerRequestCompletionHandler {\n+          override def onTimeout(): Unit = {\n+            clearInflightRequests(topicConfigs)\n+          }\n+\n+          override def onComplete(response: ClientResponse): Unit = {\n+            clearInflightRequests(topicConfigs)\n+          }\n+        })\n+      } else {\n+        adminManager.createTopics(\n+          requestTimeout,\n+          validateOnly = false,\n+          topicConfigs,\n+          Map.empty,\n+          controllerMutationQuota,\n+          _ => ())\n+      }\n+    } else {\n+      debug(s\"Topics $topics are under creation already, skip sending additional \" +", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTkyOTEzOQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569929139", "bodyText": "Actually I don't think this logging is very useful, will replace it with something more explicit about state change.", "author": "abbccdda", "createdAt": "2021-02-04T03:56:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NjA1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NjgzOQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569146839", "bodyText": "Eventually we need to figure out quota behavior for forwarded requests. I am wondering if it makes sense to apply the quota on each broker separately before sending the CreateTopic to the controller or if we rely on the controller exclusively.\ncc @dajac", "author": "hachikuji", "createdAt": "2021-02-03T05:47:23Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n+}\n+\n+object AutoTopicCreationManager {\n+\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    adminManager: ZkAdminManager,\n+    controller: KafkaController,\n+    enableForwarding: Boolean\n+  ): AutoTopicCreationManager = {\n+\n+    val channelManager =\n+      if (enableForwarding)\n+        Some(new BrokerToControllerChannelManager(\n+          controllerNodeProvider = MetadataCacheControllerNodeProvider(\n+            config, metadataCache),\n+          time = time,\n+          metrics = metrics,\n+          config = config,\n+          channelName = \"autoTopicCreationChannel\",\n+          threadNamePrefix = threadNamePrefix,\n+          retryTimeoutMs = config.requestTimeoutMs.longValue\n+        ))\n+      else\n+        None\n+    new AutoTopicCreationManagerImpl(channelManager, adminManager, controller, config.requestTimeoutMs)\n+  }\n+}\n+\n+class AutoTopicCreationManagerImpl(\n+  channelManager: Option[BrokerToControllerChannelManager],\n+  adminManager: ZkAdminManager,\n+  controller: KafkaController,\n+  requestTimeout: Int\n+) extends AutoTopicCreationManager with Logging {\n+\n+  private val inflightTopics = new ConcurrentHashMap[String, CreatableTopic]\n+\n+  override def start(): Unit = {\n+    channelManager.foreach(_.start())\n+  }\n+\n+  override def shutdown(): Unit = {\n+    channelManager.foreach(_.shutdown())\n+  }\n+\n+  override def createTopics(topics: Set[CreatableTopic],\n+                            controllerMutationQuota: ControllerMutationQuota): Unit = {", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTAwNDc1OQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r571004759", "bodyText": "@hachikuji Sorry for my late reply. I've missed the notification. We have to enforce the quota on the controller exclusively. It is a global quota and we can't really distribute it fairly in the cluster. In this case, it would be great if we could propagate the principal and clientId to the controller to enforce the quota. However, I wonder how we could propagate the error and the delay to the client if the topic creation is throttled. Perhaps, we could reply with UNKNOW_TOPIC_OR_PARTITION until the topic can be created.", "author": "dajac", "createdAt": "2021-02-05T14:28:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NjgzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NzExOQ==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569147119", "bodyText": "Could this be a set? As far as I can tell, we do not rely on the value.", "author": "hachikuji", "createdAt": "2021-02-03T05:48:10Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n+}\n+\n+object AutoTopicCreationManager {\n+\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    adminManager: ZkAdminManager,\n+    controller: KafkaController,\n+    enableForwarding: Boolean\n+  ): AutoTopicCreationManager = {\n+\n+    val channelManager =\n+      if (enableForwarding)\n+        Some(new BrokerToControllerChannelManager(\n+          controllerNodeProvider = MetadataCacheControllerNodeProvider(\n+            config, metadataCache),\n+          time = time,\n+          metrics = metrics,\n+          config = config,\n+          channelName = \"autoTopicCreationChannel\",\n+          threadNamePrefix = threadNamePrefix,\n+          retryTimeoutMs = config.requestTimeoutMs.longValue\n+        ))\n+      else\n+        None\n+    new AutoTopicCreationManagerImpl(channelManager, adminManager, controller, config.requestTimeoutMs)\n+  }\n+}\n+\n+class AutoTopicCreationManagerImpl(\n+  channelManager: Option[BrokerToControllerChannelManager],\n+  adminManager: ZkAdminManager,\n+  controller: KafkaController,\n+  requestTimeout: Int\n+) extends AutoTopicCreationManager with Logging {\n+\n+  private val inflightTopics = new ConcurrentHashMap[String, CreatableTopic]", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTcwNjUxNA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569706514", "bodyText": "Seems I could omit the value here: https://stackoverflow.com/questions/40993683/scala-thread-safe-hashset", "author": "abbccdda", "createdAt": "2021-02-03T19:56:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0NzExOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0ODU3Ng==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569148576", "bodyText": "nit: requestTimeoutMs?", "author": "hachikuji", "createdAt": "2021-02-03T05:53:09Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n+}\n+\n+object AutoTopicCreationManager {\n+\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    adminManager: ZkAdminManager,\n+    controller: KafkaController,\n+    enableForwarding: Boolean\n+  ): AutoTopicCreationManager = {\n+\n+    val channelManager =\n+      if (enableForwarding)\n+        Some(new BrokerToControllerChannelManager(\n+          controllerNodeProvider = MetadataCacheControllerNodeProvider(\n+            config, metadataCache),\n+          time = time,\n+          metrics = metrics,\n+          config = config,\n+          channelName = \"autoTopicCreationChannel\",\n+          threadNamePrefix = threadNamePrefix,\n+          retryTimeoutMs = config.requestTimeoutMs.longValue\n+        ))\n+      else\n+        None\n+    new AutoTopicCreationManagerImpl(channelManager, adminManager, controller, config.requestTimeoutMs)\n+  }\n+}\n+\n+class AutoTopicCreationManagerImpl(\n+  channelManager: Option[BrokerToControllerChannelManager],\n+  adminManager: ZkAdminManager,\n+  controller: KafkaController,\n+  requestTimeout: Int", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE0OTI2Mw==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r569149263", "bodyText": "Probably useful to have some logging when we send the CreateTopic request and in the callbacks.", "author": "hachikuji", "createdAt": "2021-02-03T05:55:29Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.server\n+\n+import java.util.concurrent.ConcurrentHashMap\n+\n+import kafka.controller.KafkaController\n+import kafka.utils.Logging\n+import org.apache.kafka.clients.ClientResponse\n+import org.apache.kafka.common.message.CreateTopicsRequestData\n+import org.apache.kafka.common.message.CreateTopicsRequestData.CreatableTopic\n+import org.apache.kafka.common.metrics.Metrics\n+import org.apache.kafka.common.requests.CreateTopicsRequest\n+import org.apache.kafka.common.utils.Time\n+\n+import scala.collection.Map\n+\n+trait AutoTopicCreationManager {\n+\n+  def createTopics(\n+    topicNames: Set[CreatableTopic],\n+    controllerMutationQuota: ControllerMutationQuota\n+  ): Unit\n+\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n+}\n+\n+object AutoTopicCreationManager {\n+\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    adminManager: ZkAdminManager,\n+    controller: KafkaController,\n+    enableForwarding: Boolean\n+  ): AutoTopicCreationManager = {\n+\n+    val channelManager =\n+      if (enableForwarding)\n+        Some(new BrokerToControllerChannelManager(\n+          controllerNodeProvider = MetadataCacheControllerNodeProvider(\n+            config, metadataCache),\n+          time = time,\n+          metrics = metrics,\n+          config = config,\n+          channelName = \"autoTopicCreationChannel\",\n+          threadNamePrefix = threadNamePrefix,\n+          retryTimeoutMs = config.requestTimeoutMs.longValue\n+        ))\n+      else\n+        None\n+    new AutoTopicCreationManagerImpl(channelManager, adminManager, controller, config.requestTimeoutMs)\n+  }\n+}\n+\n+class AutoTopicCreationManagerImpl(\n+  channelManager: Option[BrokerToControllerChannelManager],\n+  adminManager: ZkAdminManager,\n+  controller: KafkaController,\n+  requestTimeout: Int\n+) extends AutoTopicCreationManager with Logging {\n+\n+  private val inflightTopics = new ConcurrentHashMap[String, CreatableTopic]\n+\n+  override def start(): Unit = {\n+    channelManager.foreach(_.start())\n+  }\n+\n+  override def shutdown(): Unit = {\n+    channelManager.foreach(_.shutdown())\n+  }\n+\n+  override def createTopics(topics: Set[CreatableTopic],\n+                            controllerMutationQuota: ControllerMutationQuota): Unit = {\n+    val topicConfigs = topics\n+      .filter(topic => !inflightTopics.contains(topic.name()))\n+      .map(topic => {(topic.name(), topic)}).toMap\n+\n+    if (topicConfigs.nonEmpty) {\n+      if (!controller.isActive && channelManager.isDefined) {\n+        // Mark the topics as inflight during auto creation through forwarding.\n+        topicConfigs.foreach(config => inflightTopics.put(config._1, config._2))\n+\n+        val topicsToCreate = new CreateTopicsRequestData.CreatableTopicCollection\n+        topicConfigs.foreach(config => topicsToCreate.add(config._2))\n+        val createTopicsRequest = new CreateTopicsRequest.Builder(\n+          new CreateTopicsRequestData()\n+            .setTimeoutMs(requestTimeout)\n+            .setTopics(topicsToCreate)\n+        )\n+\n+        channelManager.get.sendRequest(createTopicsRequest, new ControllerRequestCompletionHandler {", "originalCommit": "2848e8d7e72e3857f6e8422820f9c5ad13621228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2fc0011a1fdd65fd5e5f042228758495d0a9a3d8", "url": "https://github.com/apache/kafka/commit/2fc0011a1fdd65fd5e5f042228758495d0a9a3d8", "message": "forward FindCoordinator/Metadata request when topic creation is needed\n\nalways define auto topic creation manager", "committedDate": "2021-02-05T01:45:52Z", "type": "forcePushed"}, {"oid": "c68c7d02b3a360b0f29722a4db2fbcfbf0a53b0d", "url": "https://github.com/apache/kafka/commit/c68c7d02b3a360b0f29722a4db2fbcfbf0a53b0d", "message": "forward FindCoordinator/Metadata request when topic creation is needed\n\nalways define auto topic creation manager", "committedDate": "2021-02-05T01:49:41Z", "type": "forcePushed"}, {"oid": "85ea8979fab9d9556b92f8124114446bb553c5e0", "url": "https://github.com/apache/kafka/commit/85ea8979fab9d9556b92f8124114446bb553c5e0", "message": "forward FindCoordinator/Metadata request when topic creation is needed\n\nalways define auto topic creation manager", "committedDate": "2021-02-06T00:10:19Z", "type": "forcePushed"}, {"oid": "c68c7d02b3a360b0f29722a4db2fbcfbf0a53b0d", "url": "https://github.com/apache/kafka/commit/c68c7d02b3a360b0f29722a4db2fbcfbf0a53b0d", "message": "forward FindCoordinator/Metadata request when topic creation is needed\n\nalways define auto topic creation manager", "committedDate": "2021-02-05T01:49:41Z", "type": "forcePushed"}, {"oid": "15596477577f07d55175ec81c3bf55270b81352f", "url": "https://github.com/apache/kafka/commit/15596477577f07d55175ec81c3bf55270b81352f", "message": "test fix and logical fix after rebase", "committedDate": "2021-02-06T01:35:21Z", "type": "forcePushed"}, {"oid": "8ef0b5a3312af543480661971473ba106547eed2", "url": "https://github.com/apache/kafka/commit/8ef0b5a3312af543480661971473ba106547eed2", "message": "forward FindCoordinator/Metadata request when topic creation is needed\n\nalways define auto topic creation manager", "committedDate": "2021-02-06T01:46:19Z", "type": "commit"}, {"oid": "cb919e956caea27a388ae78656cfbbbdeac05409", "url": "https://github.com/apache/kafka/commit/cb919e956caea27a388ae78656cfbbbdeac05409", "message": "Fix a few lingering problems", "committedDate": "2021-02-06T01:46:19Z", "type": "commit"}, {"oid": "3bdba7efb738fc3042d9586ddb3e6bff275f2422", "url": "https://github.com/apache/kafka/commit/3bdba7efb738fc3042d9586ddb3e6bff275f2422", "message": "Still need to do topic validation", "committedDate": "2021-02-06T01:46:19Z", "type": "commit"}, {"oid": "6a2df64c9f2e5ff1e322105b3254e87f79bc4baf", "url": "https://github.com/apache/kafka/commit/6a2df64c9f2e5ff1e322105b3254e87f79bc4baf", "message": "CreatTopics request test should not allow auto-creation during validation", "committedDate": "2021-02-06T01:46:19Z", "type": "commit"}, {"oid": "878a4ee93028e833fdacd35cf847ef3a804b8063", "url": "https://github.com/apache/kafka/commit/878a4ee93028e833fdacd35cf847ef3a804b8063", "message": "test fix and logical fix after rebase", "committedDate": "2021-02-06T01:49:30Z", "type": "commit"}, {"oid": "abf30d8746390a54a3752af21032afd7e47b1dc1", "url": "https://github.com/apache/kafka/commit/abf30d8746390a54a3752af21032afd7e47b1dc1", "message": "add topic validation", "committedDate": "2021-02-06T02:26:03Z", "type": "commit"}, {"oid": "abf30d8746390a54a3752af21032afd7e47b1dc1", "url": "https://github.com/apache/kafka/commit/abf30d8746390a54a3752af21032afd7e47b1dc1", "message": "add topic validation", "committedDate": "2021-02-06T02:26:03Z", "type": "forcePushed"}, {"oid": "829cec76398e3d560bc02b63db75f81b6ad3a3c3", "url": "https://github.com/apache/kafka/commit/829cec76398e3d560bc02b63db75f81b6ad3a3c3", "message": "fix scala 2.12 missing API", "committedDate": "2021-02-06T02:43:03Z", "type": "commit"}, {"oid": "65310eb9d9c5cfa7fdd4e51c8c64965a20f78ddb", "url": "https://github.com/apache/kafka/commit/65310eb9d9c5cfa7fdd4e51c8c64965a20f78ddb", "message": "Revert \"KAFKA-9274: handle TimeoutException on task reset (#10000)\"\n\nThis reverts commit 0bc394cc1d19f1e41dd6646e9ac0e09b91fb1398.", "committedDate": "2021-02-06T04:37:46Z", "type": "commit"}, {"oid": "e0dedb3d3a9b2c5c13ef7cc1a5800439810d309f", "url": "https://github.com/apache/kafka/commit/e0dedb3d3a9b2c5c13ef7cc1a5800439810d309f", "message": "clear inflight requests", "committedDate": "2021-02-06T05:14:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTM2MjkyNA==", "url": "https://github.com/apache/kafka/pull/9579#discussion_r571362924", "bodyText": "Can you use a try/finally here?", "author": "hachikuji", "createdAt": "2021-02-06T05:35:10Z", "path": "core/src/main/scala/kafka/server/AutoTopicCreationManager.scala", "diffHunk": "@@ -169,6 +169,8 @@ class DefaultAutoTopicCreationManager(\n         }\n     }\n \n+    clearInflightRequests(creatableTopics)", "originalCommit": "e0dedb3d3a9b2c5c13ef7cc1a5800439810d309f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0796658d5a9408bcbe3467d3fa27dbb292fd22b1", "url": "https://github.com/apache/kafka/commit/0796658d5a9408bcbe3467d3fa27dbb292fd22b1", "message": "try finally for clear topics", "committedDate": "2021-02-06T06:21:19Z", "type": "commit"}, {"oid": "92e5cda9dc9168e0717b7c016a954863c4edd7af", "url": "https://github.com/apache/kafka/commit/92e5cda9dc9168e0717b7c016a954863c4edd7af", "message": "fix seq ordering for scala 2.12", "committedDate": "2021-02-06T08:33:23Z", "type": "commit"}, {"oid": "1d21fc4693b289caeb92dbcfcb9d19d8455d7c0e", "url": "https://github.com/apache/kafka/commit/1d21fc4693b289caeb92dbcfcb9d19d8455d7c0e", "message": "rewrite testAutoCreateOfCollidingTopics to not depend on ordering", "committedDate": "2021-02-06T18:03:53Z", "type": "commit"}]}