{"pr_number": 9732, "pr_title": "KAFKA-10842; Use `InterBrokerSendThread` for raft's outbound network channel", "pr_createdAt": "2020-12-11T05:45:43Z", "pr_url": "https://github.com/apache/kafka/pull/9732", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NzAyMw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541147023", "bodyText": "It seems like there are many classes where direct access to data is not actually needed. How do you feel about having a public method in RequestUtils that exposes data for the raft layer instead? Something like:\npublic static ApiMessage requestData(AbstractRequest req)\npublic static ApiMessage responseData(AbstractResponse resp)\nOr is it not worth it?", "author": "ijuma", "createdAt": "2020-12-11T18:33:43Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/AddOffsetsToTxnRequest.java", "diffHunk": "@@ -53,7 +53,7 @@ public AddOffsetsToTxnRequest(AddOffsetsToTxnRequestData data, short version) {\n     }\n \n     @Override\n-    protected AddOffsetsToTxnRequestData data() {\n+    public AddOffsetsToTxnRequestData data() {", "originalCommit": "6533921245e4f7d858dd186b77e4130703fa2de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE1ODc0NA==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541158744", "bodyText": "Yeah, not sure it's worth it, though I don't feel strongly. I think ultimately we're going to start relying more on the generated classes to avoid unnecessary conversions. We're now entering \"phase 2\" of the request overhaul which means we can start figuring out how to remove the AbstractRequest/AbstractResponse layer. I think it will take more smarts in the generated classes to make a dent here, but if we are agreed on the goal (?), then I do not think preserving the encapsulation here is worthwhile.", "author": "hachikuji", "createdAt": "2020-12-11T18:54:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NzAyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE3MjU2NQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541172565", "bodyText": "I don't quite understand how we would handle versioning well if we only have data classes. Do you have thoughts on that?", "author": "ijuma", "createdAt": "2020-12-11T19:08:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NzAyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE5OTQyMg==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541199422", "bodyText": "Support for optional fields would go a long way I think. I am not sure it will be possible to remove all intermediate representations, but perhaps they can be the exception and not the rule. Some version checks in KafkaApis are probably inevitable.", "author": "hachikuji", "createdAt": "2020-12-11T19:32:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NzAyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTM3ODY1Mw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541378653", "bodyText": "I can see this:\n\nAbstractRequest/AbstractResponse methods become part of the ApiMessage hierarchy.\nFooRequest/FooResponse extends FooDataRequest/FooDataResponse (like Colin suggested before)\n\nBut I don't think you want to eliminate FooRequest/FooResponse in the example above. You don't need to perform conversions for the inner classes, but it's a place where you can normalize the representation. We do that for many of the existing request/response classes.", "author": "ijuma", "createdAt": "2020-12-11T22:44:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NzAyMw=="}], "type": "inlineReview"}, {"oid": "0a8358916e73fdf07a8c79a71956e7905a1f96f0", "url": "https://github.com/apache/kafka/commit/0a8358916e73fdf07a8c79a71956e7905a1f96f0", "message": "Add batch send api to `InterBrokerSendThread`", "committedDate": "2020-12-11T19:38:29Z", "type": "forcePushed"}, {"oid": "b5e476b1a144aa8582b2738260c8ea32c89f71e9", "url": "https://github.com/apache/kafka/commit/b5e476b1a144aa8582b2738260c8ea32c89f71e9", "message": "Add batch send api to `InterBrokerSendThread`", "committedDate": "2020-12-11T19:41:10Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE1NjYzNg==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541156636", "bodyText": "Similar to above comment, either check for null or use remove()", "author": "mumrah", "createdAt": "2020-12-11T18:51:14Z", "path": "core/src/main/scala/kafka/common/InterBrokerSendThread.scala", "diffHunk": "@@ -51,22 +53,30 @@ abstract class InterBrokerSendThread(name: String,\n     awaitShutdown()\n   }\n \n-  override def doWork(): Unit = {\n-    var now = time.milliseconds()\n+  def sendRequest(request: RequestAndCompletionHandler): Unit = {\n+    inboundQueue.offer(request)\n+    wakeup()\n+  }\n \n-    generateRequests().foreach { request =>\n+  private def drainInboundQueue(): Unit = {\n+    while (!inboundQueue.isEmpty) {\n+      val request = inboundQueue.poll()", "originalCommit": "6533921245e4f7d858dd186b77e4130703fa2de1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE2MTQ0MQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541161441", "bodyText": "Just wondering, is there any reason why we might want a bounded queue here? I suspect not since we never expect too many requests to be enqueued at once.", "author": "mumrah", "createdAt": "2020-12-11T18:58:18Z", "path": "core/src/main/scala/kafka/common/InterBrokerSendThread.scala", "diffHunk": "@@ -32,17 +33,18 @@ import scala.jdk.CollectionConverters._\n /**\n  *  Class for inter-broker send thread that utilize a non-blocking network client.\n  */\n-abstract class InterBrokerSendThread(name: String,\n-                                     networkClient: KafkaClient,\n-                                     time: Time,\n-                                     isInterruptible: Boolean = true)\n-  extends ShutdownableThread(name, isInterruptible) {\n-\n-  def generateRequests(): Iterable[RequestAndCompletionHandler]\n-  def requestTimeoutMs: Int\n+class InterBrokerSendThread(\n+  name: String,\n+  networkClient: KafkaClient,\n+  requestTimeoutMs: Int,\n+  time: Time,\n+  isInterruptible: Boolean = true\n+) extends ShutdownableThread(name, isInterruptible) {\n+\n+  private val inboundQueue = new ConcurrentLinkedQueue[RequestAndCompletionHandler]()", "originalCommit": "6533921245e4f7d858dd186b77e4130703fa2de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIyNTA3NQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541225075", "bodyText": "The BrokerToControllerChannelManager is probably the only case where this might be a concern since requests can be forwarded form the client. We wouldn't want to block the request handler if the queue gets too large, but we might want to start failing inbound requests. I'd suggest we create a separate JIRA to think about this. Sound fair?", "author": "hachikuji", "createdAt": "2020-12-11T19:59:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE2MTQ0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzUyOTU5OQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543529599", "bodyText": "Yea, sounds good \ud83d\udc4d", "author": "mumrah", "createdAt": "2020-12-15T17:12:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE2MTQ0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE2NTk2Mw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541165963", "bodyText": "We should probably either check the result of offer or use BlockingQueue#add instead. Since we're using an unbounded queue and never expect this to fail, I would lean towards add", "author": "mumrah", "createdAt": "2020-12-11T19:02:23Z", "path": "core/src/main/scala/kafka/common/InterBrokerSendThread.scala", "diffHunk": "@@ -51,22 +53,30 @@ abstract class InterBrokerSendThread(name: String,\n     awaitShutdown()\n   }\n \n-  override def doWork(): Unit = {\n-    var now = time.milliseconds()\n+  def sendRequest(request: RequestAndCompletionHandler): Unit = {\n+    inboundQueue.offer(request)", "originalCommit": "6533921245e4f7d858dd186b77e4130703fa2de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIyMTk4NA==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541221984", "bodyText": "Haha, yeah, exactly what I was thinking.", "author": "hachikuji", "createdAt": "2020-12-11T19:55:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE2NTk2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE3NzMzNw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541177337", "bodyText": "Previously, all the requests we gathered from generateRequests would have the same timestamp which was also passed to the subsequent call to NetworkClient#ready and send (via sendRequests).\nWhat's the reason for recomputing the timestamp for each request we create?\nShould we get a newer timestamp for the call to NetworkClient?\nSeems a little weird to create requests at t1, t2, etc and then call NetworkClient.send with t0. I wonder if this would have weird throttling side effects.", "author": "mumrah", "createdAt": "2020-12-11T19:11:10Z", "path": "core/src/main/scala/kafka/common/InterBrokerSendThread.scala", "diffHunk": "@@ -51,22 +53,30 @@ abstract class InterBrokerSendThread(name: String,\n     awaitShutdown()\n   }\n \n-  override def doWork(): Unit = {\n-    var now = time.milliseconds()\n+  def sendRequest(request: RequestAndCompletionHandler): Unit = {\n+    inboundQueue.offer(request)\n+    wakeup()\n+  }\n \n-    generateRequests().foreach { request =>\n+  private def drainInboundQueue(): Unit = {\n+    while (!inboundQueue.isEmpty) {\n+      val request = inboundQueue.poll()\n       val completionHandler = request.handler\n       unsentRequests.put(request.destination,\n         networkClient.newClientRequest(\n           request.destination.idString,\n           request.request,\n-          now,\n+          time.milliseconds(),\n           true,\n           requestTimeoutMs,\n           completionHandler))\n     }\n+  }\n \n+  override def doWork(): Unit = {\n     try {\n+      var now = time.milliseconds()", "originalCommit": "6533921245e4f7d858dd186b77e4130703fa2de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIxOTQ3Mg==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541219472", "bodyText": "That's fair. It's probably fine to compute it just once for sendRequests.", "author": "hachikuji", "createdAt": "2020-12-11T19:52:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE3NzMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTM3MDQyMQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541370421", "bodyText": "I ended up moving creation time to RequestAndCompletionHandler.", "author": "hachikuji", "createdAt": "2020-12-11T22:35:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE3NzMzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE4NjU0MA==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541186540", "bodyText": "Is this just for testing?", "author": "mumrah", "createdAt": "2020-12-11T19:18:29Z", "path": "core/src/main/scala/kafka/raft/KafkaNetworkChannel.scala", "diffHunk": "@@ -68,179 +51,93 @@ object KafkaNetworkChannel {\n     }\n   }\n \n-  private[raft] def responseData(response: AbstractResponse): ApiMessage = {\n-    response match {\n-      case voteResponse: VoteResponse => voteResponse.data\n-      case beginEpochResponse: BeginQuorumEpochResponse => beginEpochResponse.data\n-      case endEpochResponse: EndQuorumEpochResponse => endEpochResponse.data\n-      case fetchResponse: FetchResponse[_] => fetchResponse.data\n-      case _ => throw new IllegalArgumentException(s\"Unexpected type for response: $response\")\n-    }\n-  }\n-\n-  private[raft] def requestData(request: AbstractRequest): ApiMessage = {\n-    request match {\n-      case voteRequest: VoteRequest => voteRequest.data\n-      case beginEpochRequest: BeginQuorumEpochRequest => beginEpochRequest.data\n-      case endEpochRequest: EndQuorumEpochRequest => endEpochRequest.data\n-      case fetchRequest: FetchRequest => fetchRequest.data\n-      case _ => throw new IllegalArgumentException(s\"Unexpected type for request: $request\")\n-    }\n-  }\n-\n }\n \n-class KafkaNetworkChannel(time: Time,\n-                          client: KafkaClient,\n-                          clientId: String,\n-                          retryBackoffMs: Int,\n-                          requestTimeoutMs: Int) extends NetworkChannel with Logging {\n+class KafkaNetworkChannel(\n+  time: Time,\n+  client: KafkaClient,\n+  requestTimeoutMs: Int\n+) extends NetworkChannel with Logging {\n   import KafkaNetworkChannel._\n \n   type ResponseHandler = AbstractResponse => Unit\n \n   private val correlationIdCounter = new AtomicInteger(0)\n-  private val pendingInbound = mutable.Map.empty[Long, ResponseHandler]\n-  private val undelivered = new ArrayBlockingQueue[RaftMessage](10)\n-  private val pendingOutbound = new ArrayBlockingQueue[RaftRequest.Outbound](10)\n   private val endpoints = mutable.HashMap.empty[Int, Node]\n \n-  override def newCorrelationId(): Int = correlationIdCounter.getAndIncrement()\n-\n-  private def buildClientRequest(req: RaftRequest.Outbound): ClientRequest = {\n-    val destination = req.destinationId.toString\n-    val request = buildRequest(req.data)\n-    val correlationId = req.correlationId\n-    val createdTimeMs = req.createdTimeMs\n-    new ClientRequest(destination, request, correlationId, clientId, createdTimeMs, true,\n-      requestTimeoutMs, null)\n-  }\n-\n-  override def send(message: RaftMessage): Unit = {\n-    message match {\n-      case request: RaftRequest.Outbound =>\n-        if (!pendingOutbound.offer(request))\n-          throw new KafkaException(\"Pending outbound queue is full\")\n-\n-      case response: RaftResponse.Outbound =>\n-        pendingInbound.remove(response.correlationId).foreach { onResponseReceived: ResponseHandler =>\n-          onResponseReceived(buildResponse(response.data))\n-        }\n-      case _ =>\n-        throw new IllegalArgumentException(\"Unhandled message type \" + message)\n+  private val requestThread = new InterBrokerSendThread(\n+    name = \"raft-outbound-request-thread\",\n+    networkClient = client,\n+    requestTimeoutMs = requestTimeoutMs,\n+    time = time,\n+    isInterruptible = false\n+  )\n+\n+  override def send(request: RaftRequest.Outbound): Unit = {\n+    def completeFuture(message: ApiMessage): Unit = {\n+      val response = new RaftResponse.Inbound(\n+        request.correlationId,\n+        message,\n+        request.destinationId\n+      )\n+      request.completion.complete(response)\n     }\n-  }\n \n-  private def sendOutboundRequests(currentTimeMs: Long): Unit = {\n-    while (!pendingOutbound.isEmpty) {\n-      val request = pendingOutbound.peek()\n-      endpoints.get(request.destinationId) match {\n-        case Some(node) =>\n-          if (client.connectionFailed(node)) {\n-            pendingOutbound.poll()\n-            val apiKey = ApiKeys.forId(request.data.apiKey)\n-            val disconnectResponse = RaftUtil.errorResponse(apiKey, Errors.BROKER_NOT_AVAILABLE)\n-            val success = undelivered.offer(new RaftResponse.Inbound(\n-              request.correlationId, disconnectResponse, request.destinationId))\n-            if (!success) {\n-              throw new KafkaException(\"Undelivered queue is full\")\n-            }\n-\n-            // Make sure to reset the connection state\n-            client.ready(node, currentTimeMs)\n-          } else if (client.ready(node, currentTimeMs)) {\n-            pendingOutbound.poll()\n-            val clientRequest = buildClientRequest(request)\n-            client.send(clientRequest, currentTimeMs)\n-          } else {\n-            // We will retry this request on the next poll\n-            return\n-          }\n-\n-        case None =>\n-          pendingOutbound.poll()\n-          val apiKey = ApiKeys.forId(request.data.apiKey)\n-          val responseData = RaftUtil.errorResponse(apiKey, Errors.BROKER_NOT_AVAILABLE)\n-          val response = new RaftResponse.Inbound(request.correlationId, responseData, request.destinationId)\n-          if (!undelivered.offer(response))\n-            throw new KafkaException(\"Undelivered queue is full\")\n+    def onComplete(clientResponse: ClientResponse): Unit = {\n+      val response = if (clientResponse.authenticationException != null) {\n+        errorResponse(request.data, Errors.CLUSTER_AUTHORIZATION_FAILED)\n+      } else if (clientResponse.wasDisconnected()) {\n+        errorResponse(request.data, Errors.BROKER_NOT_AVAILABLE)\n+      } else {\n+        clientResponse.responseBody.data\n       }\n+      completeFuture(response)\n     }\n-  }\n-\n-  def getConnectionInfo(nodeId: Int): Node = {\n-    if (!endpoints.contains(nodeId))\n-      null\n-    else\n-      endpoints(nodeId)\n-  }\n-\n-  def allConnections(): Set[Node] = {\n-    endpoints.values.toSet\n-  }\n \n-  private def buildInboundRaftResponse(response: ClientResponse): RaftResponse.Inbound = {\n-    val header = response.requestHeader()\n-    val data = if (response.authenticationException != null) {\n-      RaftUtil.errorResponse(header.apiKey, Errors.CLUSTER_AUTHORIZATION_FAILED)\n-    } else if (response.wasDisconnected) {\n-      RaftUtil.errorResponse(header.apiKey, Errors.BROKER_NOT_AVAILABLE)\n-    } else {\n-      responseData(response.responseBody)\n-    }\n-    new RaftResponse.Inbound(header.correlationId, data, response.destination.toInt)\n-  }\n+    endpoints.get(request.destinationId) match {\n+      case Some(node) =>\n+        requestThread.sendRequest(RequestAndCompletionHandler(\n+          destination = node,\n+          request = buildRequest(request.data),\n+          handler = onComplete\n+        ))\n \n-  private def pollInboundResponses(timeoutMs: Long, inboundMessages: util.List[RaftMessage]): Unit = {\n-    val responses = client.poll(timeoutMs, time.milliseconds())\n-    for (response <- responses.asScala) {\n-      inboundMessages.add(buildInboundRaftResponse(response))\n+      case None =>\n+        completeFuture(errorResponse(request.data, Errors.BROKER_NOT_AVAILABLE))\n     }\n   }\n \n-  private def drainInboundRequests(inboundMessages: util.List[RaftMessage]): Unit = {\n-    undelivered.drainTo(inboundMessages)\n+  def pollOnce(): Unit = {", "originalCommit": "6533921245e4f7d858dd186b77e4130703fa2de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIxOTYyMg==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541219622", "bodyText": "Yeah, let me make that clearer.", "author": "hachikuji", "createdAt": "2020-12-11T19:52:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE4NjU0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE5MjI5OQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541192299", "bodyText": "Not needed here, but I wonder if we should just make this return an Option[RequestAndCompletionHandler]", "author": "mumrah", "createdAt": "2020-12-11T19:24:35Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManagerImpl.scala", "diffHunk": "@@ -164,13 +164,11 @@ class BrokerToControllerRequestThread(networkClient: KafkaClient,\n                                       listenerName: ListenerName,\n                                       time: Time,\n                                       threadName: String)\n-  extends InterBrokerSendThread(threadName, networkClient, time, isInterruptible = false) {\n+  extends InterBrokerSendThread(threadName, networkClient, config.controllerSocketTimeoutMs, time, isInterruptible = false) {\n \n   private var activeController: Option[Node] = None\n \n-  override def requestTimeoutMs: Int = config.controllerSocketTimeoutMs\n-\n-  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n+  def generateRequests(): Iterable[RequestAndCompletionHandler] = {", "originalCommit": "6533921245e4f7d858dd186b77e4130703fa2de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIyNTU3OQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541225579", "bodyText": "Can you clarify what the option would achieve over an empty collection?", "author": "hachikuji", "createdAt": "2020-12-11T19:59:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE5MjI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTI3NDQ5MA==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541274490", "bodyText": "I was just noticing that we only ever return a Queue with a single item. Optional seems to fit that case more cleanly. However (as we discussed offline), I wonder why we have the code like this in the first place. Maybe @abbccdda has some insight?", "author": "mumrah", "createdAt": "2020-12-11T20:49:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE5MjI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTM2ODMxMQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541368311", "bodyText": "Yeah, I agree that looks a bit odd. It looks like it was intended to be a loop.", "author": "hachikuji", "createdAt": "2020-12-11T22:32:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE5MjI5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIxNDQ5Nw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541214497", "bodyText": "Just a quick note: you had offer here before which has different behavior. It probably won't matter though, since the queue is unbounded.\n(I only noticed this because I had commented on the offer before your latest commit \ud83d\ude04 )", "author": "mumrah", "createdAt": "2020-12-11T19:47:37Z", "path": "core/src/main/scala/kafka/common/InterBrokerSendThread.scala", "diffHunk": "@@ -51,22 +53,34 @@ abstract class InterBrokerSendThread(name: String,\n     awaitShutdown()\n   }\n \n-  override def doWork(): Unit = {\n-    var now = time.milliseconds()\n+  def sendRequest(request: RequestAndCompletionHandler): Unit = {\n+    sendRequests(Seq(request))\n+  }\n \n-    generateRequests().foreach { request =>\n+  def sendRequests(requests: Iterable[RequestAndCompletionHandler]): Unit = {\n+    inboundQueue.addAll(requests.asJavaCollection)", "originalCommit": "b5e476b1a144aa8582b2738260c8ea32c89f71e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIyMTU1Mw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541221553", "bodyText": "Yeah, I was going to change this to use add anyway to make the expectation clearer.", "author": "hachikuji", "createdAt": "2020-12-11T19:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIxNDQ5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTI3NDgzMA==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541274830", "bodyText": "Ah, didn't see your earlier comment \ud83d\udc4d", "author": "mumrah", "createdAt": "2020-12-11T20:50:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIxNDQ5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIxNjk3Nw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541216977", "bodyText": "nit: indent misaligned", "author": "mumrah", "createdAt": "2020-12-11T19:50:16Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -135,7 +117,16 @@ class BrokerToControllerChannelManagerImpl(metadataCache: kafka.server.MetadataC\n       brokerToControllerListenerName, time, threadName)\n   }\n \n-  override def sendRequest(request: AbstractRequest.Builder[_ <: AbstractRequest],\n+  /**\n+   * Send request to the controller.\n+   *\n+   * @param request         The request to be sent.\n+   * @param callback        Request completion callback.\n+   * @param retryDeadlineMs The retry deadline which will only be checked after receiving a response.\n+   *                        This means that in the worst case, the total timeout would be twice of\n+   *                        the configured timeout.\n+   */\n+  def sendRequest(request: AbstractRequest.Builder[_ <: AbstractRequest],\n                            callback: ControllerRequestCompletionHandler,", "originalCommit": "b5e476b1a144aa8582b2738260c8ea32c89f71e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIyNzg0OQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541227849", "bodyText": "nit: should add something like \"timeout was reached or #wakeup() was called\"", "author": "mumrah", "createdAt": "2020-12-11T20:02:20Z", "path": "raft/src/main/java/org/apache/kafka/raft/RaftMessageQueue.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft;\n+\n+/**\n+ * This class is used to serialize inbound requests or responses to outbound requests.\n+ * It basically just allows us to wrap a blocking queue so that we can have a mocked\n+ * implementation which does not depend on system time.\n+ *\n+ * See {@link org.apache.kafka.raft.internals.BlockingMessageQueue}.\n+ */\n+public interface RaftMessageQueue {\n+\n+    /**\n+     * Block for the arrival of a new message.\n+     *\n+     * @param timeoutMs timeout in milliseconds to wait for a new event\n+     * @return the event or null if the timeout was reached", "originalCommit": "b5e476b1a144aa8582b2738260c8ea32c89f71e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIzMzg0Nw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541233847", "bodyText": "Could you use a sentinel RaftMessage object here instead? Might simplify this class a bit. Not a big deal either way", "author": "mumrah", "createdAt": "2020-12-11T20:08:50Z", "path": "raft/src/main/java/org/apache/kafka/raft/internals/BlockingMessageQueue.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft.internals;\n+\n+import org.apache.kafka.common.errors.InterruptException;\n+import org.apache.kafka.raft.RaftMessage;\n+import org.apache.kafka.raft.RaftMessageQueue;\n+\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class BlockingMessageQueue implements RaftMessageQueue {\n+    private final BlockingQueue<RaftEvent> queue = new LinkedBlockingQueue<>();\n+    private final AtomicInteger size = new AtomicInteger(0);\n+\n+    @Override\n+    public RaftMessage poll(long timeoutMs) {\n+        try {\n+            RaftEvent event = queue.poll(timeoutMs, TimeUnit.MILLISECONDS);\n+            if (event instanceof MessageReceived) {\n+                size.decrementAndGet();\n+                return ((MessageReceived) event).message;\n+            } else {\n+                return null;\n+            }\n+        } catch (InterruptedException e) {\n+            throw new InterruptException(e);\n+        }\n+\n+    }\n+\n+    @Override\n+    public void offer(RaftMessage message) {\n+        queue.add(new MessageReceived(message));\n+        size.incrementAndGet();\n+    }\n+\n+    @Override\n+    public boolean isEmpty() {\n+        return size.get() == 0;\n+    }\n+\n+    @Override\n+    public void wakeup() {\n+        queue.add(Wakeup.INSTANCE);\n+    }\n+\n+    public interface RaftEvent {", "originalCommit": "b5e476b1a144aa8582b2738260c8ea32c89f71e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTI5MTM1OQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r541291359", "bodyText": "That's a good idea.", "author": "hachikuji", "createdAt": "2020-12-11T21:06:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTIzMzg0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzUzMjc0OQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543532749", "bodyText": "style nit/question: I think we have a mixture of argument indentation for Scala classes/methods. Do we have an established style convention for this? Normally I follow the opening paren when breaking out arguments into their own line (though I'm not sure that's correct)", "author": "mumrah", "createdAt": "2020-12-15T17:16:24Z", "path": "core/src/main/scala/kafka/raft/KafkaNetworkChannel.scala", "diffHunk": "@@ -53,6 +54,41 @@ object KafkaNetworkChannel {\n \n }\n \n+private[raft] class RaftSendThread(", "originalCommit": "19e4fbf75b95c591aabdc562d60ff4386a91db27", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU2MTkzNQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543561935", "bodyText": "Not really as far as I know. This is my favored style of late because it results in consistent alignment of parameters. I get really annoyed when I see stuff like this:\ndef someMethodWithAnArguablyOverVerboseName(foo: String,\n                                            bar: Option[List[Int]]): (Option[String], List[String)\n\ndef concicseMethod(foo: String,\n                   bar: String): Unit = {\n\nNo matter how you look at it, it seems hideous.", "author": "hachikuji", "createdAt": "2020-12-15T17:55:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzUzMjc0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzUzMzUzNw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543533537", "bodyText": "\ud83d\udc4d", "author": "mumrah", "createdAt": "2020-12-15T17:17:23Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -149,29 +152,32 @@ case class BrokerToControllerQueueItem(request: AbstractRequest.Builder[_ <: Abs\n \n class BrokerToControllerRequestThread(networkClient: KafkaClient,\n                                       metadataUpdater: ManualMetadataUpdater,\n-                                      requestQueue: LinkedBlockingDeque[BrokerToControllerQueueItem],\n                                       metadataCache: kafka.server.MetadataCache,\n                                       config: KafkaConfig,\n                                       listenerName: ListenerName,\n                                       time: Time,\n                                       threadName: String)\n   extends InterBrokerSendThread(threadName, networkClient, config.controllerSocketTimeoutMs, time, isInterruptible = false) {\n \n+  private val requestQueue = new LinkedBlockingDeque[BrokerToControllerQueueItem]()\n   private var activeController: Option[Node] = None\n \n-  def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n-    val requestsToSend = new mutable.Queue[RequestAndCompletionHandler]\n-    val topRequest = requestQueue.poll()\n-    if (topRequest != null) {\n-      val request = RequestAndCompletionHandler(\n+  def enqueue(request: BrokerToControllerQueueItem): Unit = {\n+    requestQueue.add(request)\n+    if (activeController.isDefined) {\n+      wakeup()\n+    }\n+  }\n+\n+  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n+    Option(requestQueue.poll()).map { queueItem =>", "originalCommit": "19e4fbf75b95c591aabdc562d60ff4386a91db27", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzUzNzc4MQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543537781", "bodyText": "Is it worth adding a size or isEmpty to UnsentRequests?", "author": "mumrah", "createdAt": "2020-12-15T17:23:19Z", "path": "core/src/main/scala/kafka/common/InterBrokerSendThread.scala", "diffHunk": "@@ -32,17 +32,19 @@ import scala.jdk.CollectionConverters._\n /**\n  *  Class for inter-broker send thread that utilize a non-blocking network client.\n  */\n-abstract class InterBrokerSendThread(name: String,\n-                                     networkClient: KafkaClient,\n-                                     time: Time,\n-                                     isInterruptible: Boolean = true)\n-  extends ShutdownableThread(name, isInterruptible) {\n+abstract class InterBrokerSendThread(\n+  name: String,\n+  networkClient: KafkaClient,\n+  requestTimeoutMs: Int,\n+  time: Time,\n+  isInterruptible: Boolean = true\n+) extends ShutdownableThread(name, isInterruptible) {\n \n-  def generateRequests(): Iterable[RequestAndCompletionHandler]\n-  def requestTimeoutMs: Int\n   private val unsentRequests = new UnsentRequests\n \n-  def hasUnsentRequests = unsentRequests.iterator().hasNext\n+  def generateRequests(): Iterable[RequestAndCompletionHandler]\n+\n+  def hasUnsentRequests: Boolean = unsentRequests.iterator().hasNext", "originalCommit": "2e36873c2ab9850cde03c0e2c6a1dea3f10293dc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzUzOTk5MQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543539991", "bodyText": "nit: (related to style question elsewhere) if we want to change the style of these class definitions, can we do it as a separate PR? I always find it difficult when style changes are conflated with logical changes", "author": "mumrah", "createdAt": "2020-12-15T17:26:24Z", "path": "core/src/main/scala/kafka/coordinator/transaction/TransactionMarkerChannelManager.scala", "diffHunk": "@@ -127,11 +127,14 @@ class TxnMarkerQueue(@volatile var destination: Node) {\n   def totalNumMarkers(txnTopicPartition: Int): Int = markersPerTxnTopicPartition.get(txnTopicPartition).fold(0)(_.size)\n }\n \n-class TransactionMarkerChannelManager(config: KafkaConfig,\n-                                      metadataCache: MetadataCache,\n-                                      networkClient: NetworkClient,\n-                                      txnStateManager: TransactionStateManager,\n-                                      time: Time) extends InterBrokerSendThread(\"TxnMarkerSenderThread-\" + config.brokerId, networkClient, time) with Logging with KafkaMetricsGroup {\n+class TransactionMarkerChannelManager(", "originalCommit": "2e36873c2ab9850cde03c0e2c6a1dea3f10293dc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU2NzU0MQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543567541", "bodyText": "That's fair. I actually held myself back. I tried to only touch the cases that I was modifying anyway, but let me know if there are others. This one was especially obnoxious because of the long parameter list to InterBrokerSendThread.", "author": "hachikuji", "createdAt": "2020-12-15T18:03:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzUzOTk5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU1NDYzMA==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543554630", "bodyText": "Hmm, this seems strange, though maybe I'm missing something.\nIf we get here, activeController is not defined. If we then pollOnce it looks like the request produced by generateRequests will get an exception since the activeController Option is empty.\nPreviously, the backoff method was just pausing the thread for some time.", "author": "mumrah", "createdAt": "2020-12-15T17:46:01Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -221,7 +216,7 @@ class BrokerToControllerRequestThread(networkClient: KafkaClient,\n       } else {\n         // need to backoff to avoid tight loops\n         debug(\"No controller defined in metadata cache, retrying after backoff\")\n-        backoff()", "originalCommit": "2e36873c2ab9850cde03c0e2c6a1dea3f10293dc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU1NzQ0Mg==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543557442", "bodyText": "Also, if we don't need backoff anymore, we can remove it since this was the only usage", "author": "mumrah", "createdAt": "2020-12-15T17:49:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU1NDYzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU2ODgyOA==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543568828", "bodyText": "Good catch. Will fix. Let me check on test cases.", "author": "hachikuji", "createdAt": "2020-12-15T18:05:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU1NDYzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU4ODEwMQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543588101", "bodyText": "While addressing this issue, I realized the current timeout logic does not handle the case when the controller is not known. This will cause the requests to keep piling up until we find the controller.", "author": "hachikuji", "createdAt": "2020-12-15T18:34:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU1NDYzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU1NjM2OQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543556369", "bodyText": "nit: Maybe name this add so it aligns with the java.util.Queue method?", "author": "mumrah", "createdAt": "2020-12-15T17:48:20Z", "path": "raft/src/main/java/org/apache/kafka/raft/RaftMessageQueue.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft;\n+\n+/**\n+ * This class is used to serialize inbound requests or responses to outbound requests.\n+ * It basically just allows us to wrap a blocking queue so that we can have a mocked\n+ * implementation which does not depend on system time.\n+ *\n+ * See {@link org.apache.kafka.raft.internals.BlockingMessageQueue}.\n+ */\n+public interface RaftMessageQueue {\n+\n+    /**\n+     * Block for the arrival of a new message.\n+     *\n+     * @param timeoutMs timeout in milliseconds to wait for a new event\n+     * @return the event or null if either the timeout was reached or there was\n+     *     a call to {@link #wakeup()} before any events became available\n+     */\n+    RaftMessage poll(long timeoutMs);\n+\n+    /**\n+     * Offer a new message to the queue.\n+     *\n+     * @param message the message to deliver\n+     * @throws IllegalStateException if the queue cannot accept the message\n+     */\n+    void offer(RaftMessage message);", "originalCommit": "2e36873c2ab9850cde03c0e2c6a1dea3f10293dc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzU1NjU4OQ==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r543556589", "bodyText": "\ud83d\udc4d", "author": "mumrah", "createdAt": "2020-12-15T17:48:38Z", "path": "raft/src/main/java/org/apache/kafka/raft/internals/BlockingMessageQueue.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft.internals;\n+\n+import org.apache.kafka.common.errors.InterruptException;\n+import org.apache.kafka.common.protocol.ApiMessage;\n+import org.apache.kafka.raft.RaftMessage;\n+import org.apache.kafka.raft.RaftMessageQueue;\n+\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class BlockingMessageQueue implements RaftMessageQueue {\n+    private static final RaftMessage WAKEUP_MESSAGE = new RaftMessage() {", "originalCommit": "2e36873c2ab9850cde03c0e2c6a1dea3f10293dc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "74cbbf86e4b8f1d35c1ae380d63841677db9d6ad", "url": "https://github.com/apache/kafka/commit/74cbbf86e4b8f1d35c1ae380d63841677db9d6ad", "message": "Factor retry deadline out of `sendRequest`", "committedDate": "2020-12-15T22:22:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTk4NjcwMw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r545986703", "bodyText": "I guess we're not sharing these channel managers between anything. In that case, moving them into the classes that need them seems fine.", "author": "mumrah", "createdAt": "2020-12-18T17:40:44Z", "path": "core/src/main/scala/kafka/server/AlterIsrManager.scala", "diffHunk": "@@ -34,25 +35,58 @@ import scala.collection.mutable\n import scala.collection.mutable.ListBuffer\n import scala.jdk.CollectionConverters._\n \n+case class AlterIsrItem(topicPartition: TopicPartition, leaderAndIsr: LeaderAndIsr, callback: Either[Errors, LeaderAndIsr] => Unit)\n+\n /**\n  * Handles the sending of AlterIsr requests to the controller. Updating the ISR is an asynchronous operation,\n  * so partitions will learn about updates through LeaderAndIsr messages sent from the controller\n  */\n trait AlterIsrManager {\n-  def start(): Unit\n+  def start(): Unit = {}\n+\n+  def shutdown(): Unit = {}\n \n   def enqueue(alterIsrItem: AlterIsrItem): Boolean\n \n   def clearPending(topicPartition: TopicPartition): Unit\n }\n \n-case class AlterIsrItem(topicPartition: TopicPartition, leaderAndIsr: LeaderAndIsr, callback: Either[Errors, LeaderAndIsr] => Unit)\n+object AlterIsrManager {\n+  def apply(\n+    config: KafkaConfig,\n+    metadataCache: MetadataCache,\n+    scheduler: KafkaScheduler,\n+    time: Time,\n+    metrics: Metrics,\n+    threadNamePrefix: Option[String],\n+    brokerEpochSupplier: () => Long\n+  ): AlterIsrManager = {\n+    val channelManager = new BrokerToControllerChannelManager(", "originalCommit": "35a8d951134fd3ee33b9c8c3ad29c4536ec19702", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTk5MzQyMw==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r545993423", "bodyText": "Any reason to use Iterator here instead of queue methods (i.e., peek and remove). Is it to ensure a consistent view of the queue while we're going through it?", "author": "mumrah", "createdAt": "2020-12-18T17:53:23Z", "path": "core/src/main/scala/kafka/server/BrokerToControllerChannelManager.scala", "diffHunk": "@@ -152,76 +151,89 @@ abstract class ControllerRequestCompletionHandler extends RequestCompletionHandl\n   def onTimeout(): Unit\n }\n \n-case class BrokerToControllerQueueItem(request: AbstractRequest.Builder[_ <: AbstractRequest],\n-                                       callback: ControllerRequestCompletionHandler,\n-                                       deadlineMs: Long)\n-\n-class BrokerToControllerRequestThread(networkClient: KafkaClient,\n-                                      metadataUpdater: ManualMetadataUpdater,\n-                                      requestQueue: LinkedBlockingDeque[BrokerToControllerQueueItem],\n-                                      metadataCache: kafka.server.MetadataCache,\n-                                      config: KafkaConfig,\n-                                      listenerName: ListenerName,\n-                                      time: Time,\n-                                      threadName: String)\n-  extends InterBrokerSendThread(threadName, networkClient, time, isInterruptible = false) {\n-\n+case class BrokerToControllerQueueItem(\n+  createdTimeMs: Long,\n+  request: AbstractRequest.Builder[_ <: AbstractRequest],\n+  callback: ControllerRequestCompletionHandler\n+)\n+\n+class BrokerToControllerRequestThread(\n+  networkClient: KafkaClient,\n+  metadataUpdater: ManualMetadataUpdater,\n+  metadataCache: kafka.server.MetadataCache,\n+  config: KafkaConfig,\n+  listenerName: ListenerName,\n+  time: Time,\n+  threadName: String,\n+  retryTimeoutMs: Long\n+) extends InterBrokerSendThread(threadName, networkClient, config.controllerSocketTimeoutMs, time, isInterruptible = false) {\n+\n+  private val requestQueue = new LinkedBlockingDeque[BrokerToControllerQueueItem]()\n   private var activeController: Option[Node] = None\n \n-  override def requestTimeoutMs: Int = config.controllerSocketTimeoutMs\n+  def enqueue(request: BrokerToControllerQueueItem): Unit = {\n+    requestQueue.add(request)\n+    if (activeController.isDefined) {\n+      wakeup()\n+    }\n+  }\n \n-  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n-    val requestsToSend = new mutable.Queue[RequestAndCompletionHandler]\n-    val topRequest = requestQueue.poll()\n-    if (topRequest != null) {\n-      val request = RequestAndCompletionHandler(\n-        activeController.get,\n-        topRequest.request,\n-        handleResponse(topRequest)\n-      )\n+  def queueSize: Int = {\n+    requestQueue.size\n+  }\n \n-      requestsToSend.enqueue(request)\n+  override def generateRequests(): Iterable[RequestAndCompletionHandler] = {\n+    val currentTimeMs = time.milliseconds()\n+    val requestIter = requestQueue.iterator()", "originalCommit": "35a8d951134fd3ee33b9c8c3ad29c4536ec19702", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkwNTExMA==", "url": "https://github.com/apache/kafka/pull/9732#discussion_r546905110", "bodyText": "Yeah, I just thought it was a little simpler.", "author": "hachikuji", "createdAt": "2020-12-21T20:04:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTk5MzQyMw=="}], "type": "inlineReview"}, {"oid": "9ac6bb0650d4570ac052215297ab90a08bf8e7ea", "url": "https://github.com/apache/kafka/commit/9ac6bb0650d4570ac052215297ab90a08bf8e7ea", "message": "KAFKA-10842; Use `InterBrokerSendThread` for raft's outbound network channel", "committedDate": "2020-12-21T20:05:28Z", "type": "commit"}, {"oid": "065514e8e0caa9a5203a8364be11fde766b6ff0b", "url": "https://github.com/apache/kafka/commit/065514e8e0caa9a5203a8364be11fde766b6ff0b", "message": "Add batch send api to `InterBrokerSendThread`", "committedDate": "2020-12-21T20:05:28Z", "type": "commit"}, {"oid": "6eb4ef252cb271b89563f78b4de64bb649094d02", "url": "https://github.com/apache/kafka/commit/6eb4ef252cb271b89563f78b4de64bb649094d02", "message": "Walk back addition of queue in `InterBrokerSendThread`", "committedDate": "2020-12-21T20:07:48Z", "type": "commit"}, {"oid": "d0fd77f98411e1e28e113b04155c16ab42847879", "url": "https://github.com/apache/kafka/commit/d0fd77f98411e1e28e113b04155c16ab42847879", "message": "Use sentinel `RaftMessage` for wakeup", "committedDate": "2020-12-21T20:07:48Z", "type": "commit"}, {"oid": "53cf918db43b1178751fed1eaae20378c89dd289", "url": "https://github.com/apache/kafka/commit/53cf918db43b1178751fed1eaae20378c89dd289", "message": "Fix timeout logic in `BrokerToControllerChannelManager`", "committedDate": "2020-12-21T20:07:48Z", "type": "commit"}, {"oid": "2999fc7d174d24df9041ce86f1d599c2333a04b1", "url": "https://github.com/apache/kafka/commit/2999fc7d174d24df9041ce86f1d599c2333a04b1", "message": "Factor retry deadline out of `sendRequest`", "committedDate": "2020-12-21T20:16:28Z", "type": "commit"}, {"oid": "67633d5b4a9b5aaa99e390e242f3139d27220d25", "url": "https://github.com/apache/kafka/commit/67633d5b4a9b5aaa99e390e242f3139d27220d25", "message": "We should use `disconnect` so that we get responses", "committedDate": "2020-12-21T20:16:28Z", "type": "commit"}, {"oid": "e113993296e77b12fe0fcbd17ec73ba4ddff52ba", "url": "https://github.com/apache/kafka/commit/e113993296e77b12fe0fcbd17ec73ba4ddff52ba", "message": "Fix startup/send bugs", "committedDate": "2020-12-21T20:19:27Z", "type": "commit"}, {"oid": "e9574f3b1170653348a3d8f403d3b6a996ae91a3", "url": "https://github.com/apache/kafka/commit/e9574f3b1170653348a3d8f403d3b6a996ae91a3", "message": "Fix broken channel name", "committedDate": "2020-12-21T20:19:27Z", "type": "commit"}, {"oid": "c31ba33f2ffb1144e0acbe975ddf45cc5d4065bc", "url": "https://github.com/apache/kafka/commit/c31ba33f2ffb1144e0acbe975ddf45cc5d4065bc", "message": "Remove start() call in ReplicaManager", "committedDate": "2020-12-21T20:43:34Z", "type": "commit"}, {"oid": "c31ba33f2ffb1144e0acbe975ddf45cc5d4065bc", "url": "https://github.com/apache/kafka/commit/c31ba33f2ffb1144e0acbe975ddf45cc5d4065bc", "message": "Remove start() call in ReplicaManager", "committedDate": "2020-12-21T20:43:34Z", "type": "forcePushed"}]}