{"pr_number": 9434, "pr_title": "MINOR: Handle lastFetchedEpoch/divergingEpoch in FetchSession and DelayedFetch", "pr_createdAt": "2020-10-14T16:11:23Z", "pr_url": "https://github.com/apache/kafka/pull/9434", "timeline": [{"oid": "f4b48bc38d71af7fdf3bca38b19be63356208dd2", "url": "https://github.com/apache/kafka/commit/f4b48bc38d71af7fdf3bca38b19be63356208dd2", "message": "MINOR: Handle lastFetchedEpoch/divergingEpoch in FetchSession and DelayedFetch", "committedDate": "2020-10-14T16:05:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDgzOTE0Mg==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r504839142", "bodyText": "Hmm.. If the LogReadResult has a diverging epoch, wouldn't we want to respond immediately?", "author": "hachikuji", "createdAt": "2020-10-14T17:09:11Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1084,7 +1084,7 @@ class ReplicaManager(val config: KafkaConfig,\n       fetchInfos.foreach { case (topicPartition, partitionData) =>\n         logReadResultMap.get(topicPartition).foreach(logReadResult => {\n           val logOffsetMetadata = logReadResult.info.fetchOffsetMetadata\n-          fetchPartitionStatus += (topicPartition -> FetchPartitionStatus(logOffsetMetadata, partitionData))\n+          fetchPartitionStatus += (topicPartition -> FetchPartitionStatus(logOffsetMetadata, partitionData, logReadResult.divergingEpoch.nonEmpty))", "originalCommit": "f4b48bc38d71af7fdf3bca38b19be63356208dd2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDk1MjkwMw==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r504952903", "bodyText": "ah, yes, so we don't need to check the original result in DelayedFetch, we return immediately here. Updated.", "author": "rajinisivaram", "createdAt": "2020-10-14T20:28:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDgzOTE0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg0MTEyNA==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r504841124", "bodyText": "Here we are using the status from the original fetch. I am wondering if we need to recheck below since it is possible to get a truncation while a fetch is in purgatory.", "author": "hachikuji", "createdAt": "2020-10-14T17:12:50Z", "path": "core/src/main/scala/kafka/server/DelayedFetch.scala", "diffHunk": "@@ -88,6 +90,13 @@ class DelayedFetch(delayMs: Long,\n         try {\n           if (fetchOffset != LogOffsetMetadata.UnknownOffsetMetadata) {\n             val partition = replicaManager.getPartitionOrException(topicPartition)\n+\n+            // Case H: Return diverging epoch in response to trigger truncation\n+            if (fetchStatus.hasDivergingEpoch) {", "originalCommit": "f4b48bc38d71af7fdf3bca38b19be63356208dd2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDk1NDA0OQ==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r504954049", "bodyText": "@hachikuji Thanks for the review. Makes sense, I have added a new check at the end instead of this one, not sure if there is a better way to check.", "author": "rajinisivaram", "createdAt": "2020-10-14T20:30:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg0MTEyNA=="}], "type": "inlineReview"}, {"oid": "3d554d91fc2b1bbf1b38049d0b4b9d2c87e9b14a", "url": "https://github.com/apache/kafka/commit/3d554d91fc2b1bbf1b38049d0b4b9d2c87e9b14a", "message": "Address review comments", "committedDate": "2020-10-14T20:06:09Z", "type": "commit"}, {"oid": "38ce7eda1aab049d4008ba1881ea26ba1dac294d", "url": "https://github.com/apache/kafka/commit/38ce7eda1aab049d4008ba1881ea26ba1dac294d", "message": "Fix test to compile with scala 2.12", "committedDate": "2020-10-15T09:38:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY3MDgwMw==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r505670803", "bodyText": "nit: unneeded newline", "author": "hachikuji", "createdAt": "2020-10-15T16:16:21Z", "path": "core/src/main/scala/kafka/server/DelayedFetch.scala", "diffHunk": "@@ -96,6 +98,7 @@ class DelayedFetch(delayMs: Long,\n               case FetchTxnCommitted => offsetSnapshot.lastStableOffset\n             }\n \n+", "originalCommit": "38ce7eda1aab049d4008ba1881ea26ba1dac294d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY3ODM0NA==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r505678344", "bodyText": "Do we need to check the error? Or are you relying on the check below failing if UNDEFINED_EPOCH is returned?", "author": "hachikuji", "createdAt": "2020-10-15T16:28:14Z", "path": "core/src/main/scala/kafka/cluster/Partition.scala", "diffHunk": "@@ -1162,6 +1162,13 @@ class Partition(val topicPartition: TopicPartition,\n     localLog.fetchOffsetSnapshot\n   }\n \n+  def hasDivergingEpoch(currentLeaderEpoch: Optional[Integer],\n+                        lastFetchedEpoch: Int,\n+                        fetchOffset: Long): Boolean = {\n+    val epochEndOffset = lastOffsetForLeaderEpoch(currentLeaderEpoch, lastFetchedEpoch, fetchOnlyFromLeader = false)", "originalCommit": "38ce7eda1aab049d4008ba1881ea26ba1dac294d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY5ODE0Mw==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r505698143", "bodyText": "@hachikuji Thanks for the review. I took the check from Partition.readRecords, but we throw exceptions there to return appropriate errors. I was thinking we would return true here for undefined epochs because of the check below and that would go through the other code path to return the appropriate errors or diverging epoch. Do you think we should do the same error handling hchecks ere as in readRecords to make the flow more obvious?", "author": "rajinisivaram", "createdAt": "2020-10-15T16:58:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY3ODM0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcxNjgwMg==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r505716802", "bodyText": "As discussed offline, moved the check to DelayedFetch.", "author": "rajinisivaram", "createdAt": "2020-10-15T17:29:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY3ODM0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY3OTMxMw==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r505679313", "bodyText": "Do we need to provide a default here?", "author": "hachikuji", "createdAt": "2020-10-15T16:29:24Z", "path": "core/src/main/scala/kafka/server/FetchSession.scala", "diffHunk": "@@ -77,7 +77,8 @@ class CachedPartition(val topic: String,\n                       var highWatermark: Long,\n                       var leaderEpoch: Optional[Integer],\n                       var fetcherLogStartOffset: Long,\n-                      var localLogStartOffset: Long)\n+                      var localLogStartOffset: Long,\n+                      var lastFetchedEpoch: Optional[Integer] = Optional.empty[Integer])", "originalCommit": "38ce7eda1aab049d4008ba1881ea26ba1dac294d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcxNjk2MQ==", "url": "https://github.com/apache/kafka/pull/9434#discussion_r505716961", "bodyText": "removed", "author": "rajinisivaram", "createdAt": "2020-10-15T17:29:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTY3OTMxMw=="}], "type": "inlineReview"}, {"oid": "cda32dc16f228c2a1e90ad0a9d161b8cec6fd446", "url": "https://github.com/apache/kafka/commit/cda32dc16f228c2a1e90ad0a9d161b8cec6fd446", "message": "Address review comments", "committedDate": "2020-10-15T17:27:43Z", "type": "commit"}]}