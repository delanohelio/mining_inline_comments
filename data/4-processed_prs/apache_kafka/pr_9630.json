{"pr_number": 9630, "pr_title": "KAFKA-10739; Replace EpochEndOffset with automated protocol", "pr_createdAt": "2020-11-20T15:38:38Z", "pr_url": "https://github.com/apache/kafka/pull/9630", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NTU4OA==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528545588", "bodyText": "Could we avoid duplicate conversion between scala and java? It can be rewrite by java stream APIs so the  asScala  can be avoid.", "author": "chia7712", "createdAt": "2020-11-23T08:52:01Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>", "originalCommit": "ca51ce11e25da1385fdc239c204a0729242249bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEyMzM2MA==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r531123360", "bodyText": "asScala and asJava just wrap the collections to make it accessible from respectively Scala and Java. In that regards, I am not sure that we would gain much by using the stream API here as it also creates a Stream. It seems more natural to keep using Scala here. If you look in the API layer, we do this everywhere.", "author": "dajac", "createdAt": "2020-11-26T16:06:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NTU4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEyOTM0NA==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r531129344", "bodyText": "Make sense to me :)", "author": "chia7712", "createdAt": "2020-11-26T16:17:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NTU4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU0NjA4Mg==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528546082", "bodyText": "ditto", "author": "chia7712", "createdAt": "2020-11-23T08:52:56Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -2592,25 +2596,39 @@ class KafkaApis(val requestChannel: RequestChannel,\n \n   def handleOffsetForLeaderEpochRequest(request: RequestChannel.Request): Unit = {\n     val offsetForLeaderEpoch = request.body[OffsetsForLeaderEpochRequest]\n-    val requestInfo = offsetForLeaderEpoch.epochsByTopicPartition.asScala\n+    val topics = offsetForLeaderEpoch.data.topics.asScala.toSeq\n \n     // The OffsetsForLeaderEpoch API was initially only used for inter-broker communication and required\n     // cluster permission. With KIP-320, the consumer now also uses this API to check for log truncation\n     // following a leader change, so we also allow topic describe permission.\n-    val (authorizedPartitions, unauthorizedPartitions) =\n+    val (authorizedTopics, unauthorizedTopics) =\n       if (authorize(request.context, CLUSTER_ACTION, CLUSTER, CLUSTER_NAME, logIfDenied = false))\n-        (requestInfo, Map.empty[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData])\n-      else partitionMapByAuthorized(request.context, DESCRIBE, TOPIC, requestInfo)(_.topic)\n+        (topics, Seq.empty[OffsetForLeaderTopic])\n+      else partitionSeqByAuthorized(request.context, DESCRIBE, TOPIC, topics)(_.topic)\n+\n+    val endOffsetsForAuthorizedPartitions = replicaManager.lastOffsetForLeaderEpoch(authorizedTopics)\n+    val endOffsetsForUnauthorizedPartitions = unauthorizedTopics.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>", "originalCommit": "ca51ce11e25da1385fdc239c204a0729242249bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r528552473", "bodyText": "Should it be topic.partitions.add(offsetForLeaderPartition.duplicate())?", "author": "chia7712", "createdAt": "2020-11-23T09:05:02Z", "path": "core/src/test/scala/unit/kafka/server/epoch/util/ReplicaFetcherMockBlockingSend.scala", "diffHunk": "@@ -78,7 +80,19 @@ class ReplicaFetcherMockBlockingSend(offsets: java.util.Map[TopicPartition, Epoc\n         callback.foreach(_.apply())\n         epochFetchCount += 1\n         lastUsedOffsetForLeaderEpochVersion = requestBuilder.latestAllowedVersion()\n-        new OffsetsForLeaderEpochResponse(currentOffsets)\n+\n+        val data = new OffsetForLeaderEpochResponseData()\n+        currentOffsets.forEach((tp, offsetForLeaderPartition) => {\n+          var topic = data.topics.find(tp.topic)\n+          if (topic == null) {\n+            topic = new OffsetForLeaderTopicResult()\n+              .setTopic(tp.topic)\n+            data.topics.add(topic)\n+          }\n+          topic.partitions.add(offsetForLeaderPartition.setPartition(tp.partition))", "originalCommit": "ca51ce11e25da1385fdc239c204a0729242249bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEyMzc4MA==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r531123780", "bodyText": "Hum.. I am not sure to understand the duplicate suggestion here. Could you elaborate?", "author": "dajac", "createdAt": "2020-11-26T16:07:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTEzNzM5Nw==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r531137397", "bodyText": "oh, it is just personal taste. the code topic.partitions.add(offsetForLeaderPartition.setPartition(tp.partition)) adds inner mutable object (offsetForLeaderPartition) to returned response. I prefer to add a copy of offsetForLeaderPartition.", "author": "chia7712", "createdAt": "2020-11-26T16:33:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjQ0NDQyMQ==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r532444421", "bodyText": "Good point. Actually, setPartition(tp.partition) is not needed. Let me remove it.", "author": "dajac", "createdAt": "2020-11-30T09:13:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU1MjQ3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUzOTgxMg==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533539812", "bodyText": "I'm wondering if it is reasonable to rely on defaults for some of these. I guess there's value in being explicit, but it is a tad vexing to see the same code repeated for a few of these cases.", "author": "hachikuji", "createdAt": "2020-12-01T16:16:27Z", "path": "core/src/main/scala/kafka/server/ReplicaManager.scala", "diffHunk": "@@ -1862,23 +1864,51 @@ class ReplicaManager(val config: KafkaConfig,\n     }\n   }\n \n-  def lastOffsetForLeaderEpoch(requestedEpochInfo: Map[TopicPartition, OffsetsForLeaderEpochRequest.PartitionData]): Map[TopicPartition, EpochEndOffset] = {\n-    requestedEpochInfo.map { case (tp, partitionData) =>\n-      val epochEndOffset = getPartition(tp) match {\n-        case HostedPartition.Online(partition) =>\n-          partition.lastOffsetForLeaderEpoch(partitionData.currentLeaderEpoch, partitionData.leaderEpoch,\n-            fetchOnlyFromLeader = true)\n-\n-        case HostedPartition.Offline =>\n-          new EpochEndOffset(Errors.KAFKA_STORAGE_ERROR, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None if metadataCache.contains(tp) =>\n-          new EpochEndOffset(Errors.NOT_LEADER_OR_FOLLOWER, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n-\n-        case HostedPartition.None =>\n-          new EpochEndOffset(Errors.UNKNOWN_TOPIC_OR_PARTITION, UNDEFINED_EPOCH, UNDEFINED_EPOCH_OFFSET)\n+  def lastOffsetForLeaderEpoch(\n+    requestedEpochInfo: Seq[OffsetForLeaderTopic]\n+  ): Seq[OffsetForLeaderTopicResult] = {\n+    requestedEpochInfo.map { offsetForLeaderTopic =>\n+      val partitions = offsetForLeaderTopic.partitions.asScala.map { offsetForLeaderPartition =>\n+        val tp = new TopicPartition(offsetForLeaderTopic.topic, offsetForLeaderPartition.partition)\n+        getPartition(tp) match {\n+          case HostedPartition.Online(partition) =>\n+            val currentLeaderEpochOpt =\n+              if (offsetForLeaderPartition.currentLeaderEpoch == RecordBatch.NO_PARTITION_LEADER_EPOCH)\n+                Optional.empty[Integer]\n+              else\n+                Optional.of[Integer](offsetForLeaderPartition.currentLeaderEpoch)\n+\n+            partition.lastOffsetForLeaderEpoch(\n+              currentLeaderEpochOpt,\n+              offsetForLeaderPartition.leaderEpoch,\n+              fetchOnlyFromLeader = true)\n+\n+          case HostedPartition.Offline =>\n+            new OffsetForLeaderPartitionResult()\n+              .setPartition(offsetForLeaderPartition.partition)\n+              .setErrorCode(Errors.KAFKA_STORAGE_ERROR.code)\n+              .setLeaderEpoch(UNDEFINED_EPOCH)", "originalCommit": "7237f6ce11e4a7d75d929842a478a77695a6fe0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk3NTg0Mg==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533975842", "bodyText": "That makes sense. Let me use them where ever possible. I will also add a default value (-1) for EndOffset in the schema.", "author": "dajac", "createdAt": "2020-12-02T08:23:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUzOTgxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0MTczOQ==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533541739", "bodyText": "Maybe just me, but OffsetForLeaderPartitionResult seems more cumbersome and less descriptive than EpochEndOffset. Would it be worth changing the name in the generated schema?", "author": "hachikuji", "createdAt": "2020-12-01T16:18:59Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3727,15 +3733,24 @@ public void testOffsetValidationRequestGrouping() {\n             assertTrue(expectedPartitions.size() > 0);\n             allRequestedPartitions.addAll(expectedPartitions);\n \n-            Map<TopicPartition, EpochEndOffset> endOffsets = expectedPartitions.stream().collect(Collectors.toMap(\n-                Function.identity(),\n-                tp -> new EpochEndOffset(Errors.NONE, 4, 0)\n-            ));\n+            OffsetForLeaderEpochResponseData data = new OffsetForLeaderEpochResponseData();\n+            expectedPartitions.forEach(tp -> {\n+                OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+                if (topic == null) {\n+                    topic = new OffsetForLeaderTopicResult().setTopic(tp.topic());\n+                    data.topics().add(topic);\n+                }\n+                topic.partitions().add(new OffsetForLeaderPartitionResult()", "originalCommit": "7237f6ce11e4a7d75d929842a478a77695a6fe0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk4MDk0Mg==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533980942", "bodyText": "I do agree with you. Using EpochEndOffset sounds much better.", "author": "dajac", "createdAt": "2020-12-02T08:32:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0MTczOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0ODE5Ng==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533548196", "bodyText": "Not for this patch, but all of this boilerplate we need to build the topic groupings gets annoying. It is such a common case that it might be worth writing a special type that lets the parser construct Map<TopicPartition, Data> directly since that is really what the code wants. Alternatively, maybe we could flatten the schemas and introduce compression.", "author": "hachikuji", "createdAt": "2020-12-01T16:27:22Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -3727,15 +3733,24 @@ public void testOffsetValidationRequestGrouping() {\n             assertTrue(expectedPartitions.size() > 0);\n             allRequestedPartitions.addAll(expectedPartitions);\n \n-            Map<TopicPartition, EpochEndOffset> endOffsets = expectedPartitions.stream().collect(Collectors.toMap(\n-                Function.identity(),\n-                tp -> new EpochEndOffset(Errors.NONE, 4, 0)\n-            ));\n+            OffsetForLeaderEpochResponseData data = new OffsetForLeaderEpochResponseData();\n+            expectedPartitions.forEach(tp -> {\n+                OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+                if (topic == null) {", "originalCommit": "7237f6ce11e4a7d75d929842a478a77695a6fe0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk5OTcxNQ==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r533999715", "bodyText": "That would be nice, indeed! I have been thinking about this as well but did not have the time to tackle this yet. I have opened a JIRA to track this: https://issues.apache.org/jira/browse/KAFKA-10795.", "author": "dajac", "createdAt": "2020-12-02T09:03:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU0ODE5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM3OTM0OQ==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r534379349", "bodyText": "In the case of the error code, I think it might be better to be explicit.", "author": "hachikuji", "createdAt": "2020-12-02T18:13:18Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1839,20 +1839,17 @@ private OffsetsForLeaderEpochResponse createLeaderEpochResponse() {\n             .setPartitions(Arrays.asList(\n                 new OffsetForLeaderPartitionResult()\n                     .setPartition(0)\n-                    .setErrorCode(Errors.NONE.code())\n                     .setLeaderEpoch(1)\n                     .setEndOffset(0),\n                 new OffsetForLeaderPartitionResult()\n                     .setPartition(1)\n-                    .setErrorCode(Errors.NONE.code())", "originalCommit": "d192b83e0993500cd0345d3aea48a21cdc9ab190", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkwMDg3Mg==", "url": "https://github.com/apache/kafka/pull/9630#discussion_r534900872", "bodyText": "I don't feel strong either ways so I will follow your suggestion.", "author": "dajac", "createdAt": "2020-12-03T08:23:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM3OTM0OQ=="}], "type": "inlineReview"}, {"oid": "32329a384fc6f7679184e1337dd8bad803b53d71", "url": "https://github.com/apache/kafka/commit/32329a384fc6f7679184e1337dd8bad803b53d71", "message": "Migrate KafkaApis and ReplicaManager", "committedDate": "2020-12-03T10:14:40Z", "type": "commit"}, {"oid": "f7c0b25fa3ed1d3449aea60e13bb564a634430e3", "url": "https://github.com/apache/kafka/commit/f7c0b25fa3ed1d3449aea60e13bb564a634430e3", "message": "use OffsetForLeaderEpochResponseData.OffsetForLeaderPartitionResult in Partition and change all the related usages", "committedDate": "2020-12-03T10:39:33Z", "type": "commit"}, {"oid": "d7839109a8b9e6343403007bfc1bd139e0432ab7", "url": "https://github.com/apache/kafka/commit/d7839109a8b9e6343403007bfc1bd139e0432ab7", "message": "Remove OffsetsForLeaderEpochRequest#epochsByTopicPartition", "committedDate": "2020-12-03T10:39:33Z", "type": "commit"}, {"oid": "c70dd2a74e6c8fb5e5d8fc632fe2b8801cf71061", "url": "https://github.com/apache/kafka/commit/c70dd2a74e6c8fb5e5d8fc632fe2b8801cf71061", "message": "remove OffsetsForLeaderEpochResponse#responses", "committedDate": "2020-12-03T10:39:34Z", "type": "commit"}, {"oid": "d23fb390c7fd0beaabbd770ec32932b11b0f2e24", "url": "https://github.com/apache/kafka/commit/d23fb390c7fd0beaabbd770ec32932b11b0f2e24", "message": "remove old constructors in OffsetsForLeaderEpochResponse", "committedDate": "2020-12-03T10:39:34Z", "type": "commit"}, {"oid": "4a89452470216b6dc0574fe94442b577c1148e1e", "url": "https://github.com/apache/kafka/commit/4a89452470216b6dc0574fe94442b577c1148e1e", "message": "Migrate ReplicaFetcherMockBlockingSend", "committedDate": "2020-12-03T10:48:52Z", "type": "commit"}, {"oid": "549e6fc77532da5e9a0baaa749f646990f2eb120", "url": "https://github.com/apache/kafka/commit/549e6fc77532da5e9a0baaa749f646990f2eb120", "message": "fix ReplicaFetcherThreadBenchmark", "committedDate": "2020-12-03T10:48:52Z", "type": "commit"}, {"oid": "ae4479172a2897e716c3d6b78249f802e967e4d6", "url": "https://github.com/apache/kafka/commit/ae4479172a2897e716c3d6b78249f802e967e4d6", "message": "Move constants from EpochEndOffset to OffsetsForLeaderEpochResponse", "committedDate": "2020-12-03T10:56:34Z", "type": "commit"}, {"oid": "d39f87eaf56a922994d047e6ae0cc668e08a3008", "url": "https://github.com/apache/kafka/commit/d39f87eaf56a922994d047e6ae0cc668e08a3008", "message": "bye bye EpochEndOffset", "committedDate": "2020-12-03T10:56:34Z", "type": "commit"}, {"oid": "655885b14f4931a2c8660f30005d2e038da5b0d7", "url": "https://github.com/apache/kafka/commit/655885b14f4931a2c8660f30005d2e038da5b0d7", "message": "clean up the code", "committedDate": "2020-12-03T10:59:59Z", "type": "commit"}, {"oid": "71f139c7c01d032363a114c1def753a7e580252d", "url": "https://github.com/apache/kafka/commit/71f139c7c01d032363a114c1def753a7e580252d", "message": "address review", "committedDate": "2020-12-03T11:00:00Z", "type": "commit"}, {"oid": "4008993b492405e41378db53e8135a649f030307", "url": "https://github.com/apache/kafka/commit/4008993b492405e41378db53e8135a649f030307", "message": "Relies on default values in the schema whereever possible", "committedDate": "2020-12-03T11:03:27Z", "type": "commit"}, {"oid": "864644ab8dd06e0174010cf134437e5cc5224b50", "url": "https://github.com/apache/kafka/commit/864644ab8dd06e0174010cf134437e5cc5224b50", "message": "Rename OffsetForLeaderPartitionResult to EpochEndOffset", "committedDate": "2020-12-03T11:51:33Z", "type": "commit"}, {"oid": "2a9f87a118c051bfc6e6a944ef21db79db9b5068", "url": "https://github.com/apache/kafka/commit/2a9f87a118c051bfc6e6a944ef21db79db9b5068", "message": "address review", "committedDate": "2020-12-03T11:57:38Z", "type": "commit"}, {"oid": "2a9f87a118c051bfc6e6a944ef21db79db9b5068", "url": "https://github.com/apache/kafka/commit/2a9f87a118c051bfc6e6a944ef21db79db9b5068", "message": "address review", "committedDate": "2020-12-03T11:57:38Z", "type": "forcePushed"}]}