{"pr_number": 8119, "pr_title": "KAFKA-9558: Fixing retry logic for getListOffsetsCalls", "pr_createdAt": "2020-02-14T22:10:45Z", "pr_url": "https://github.com/apache/kafka/pull/8119", "timeline": [{"oid": "e3353db921c213b9e383d2c87ef25707d700e081", "url": "https://github.com/apache/kafka/commit/e3353db921c213b9e383d2c87ef25707d700e081", "message": "KAFKA-9558: Fixing retry logic for getListOffsetsCalls", "committedDate": "2020-02-14T22:07:54Z", "type": "commit"}, {"oid": "7a52e1bf412570603250f74b9ab3b37d19e13b89", "url": "https://github.com/apache/kafka/commit/7a52e1bf412570603250f74b9ab3b37d19e13b89", "message": "renaming tests for clarity and putting correct error in mock client response", "committedDate": "2020-02-15T07:00:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg0OTM2MA==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r379849360", "bodyText": "Hmm.. I don't think it's safe to modify topicPartitionOffsets. This is shared by multiple calls following the initial getListOffsetsCalls. It would be better to create a new map. It might bee worth having a test case which uses two partitions with different leaders to verify this case is handled correctly.", "author": "hachikuji", "createdAt": "2020-02-15T18:58:16Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3803,11 +3803,11 @@ void handleResponse(AbstractResponse abstractResponse) {\n                     }\n \n                     if (!partitionsWithErrors.isEmpty()) {\n-                        partitionsToQuery.keySet().retainAll(partitionsWithErrors);\n                         Set<String> retryTopics = partitionsWithErrors.stream().map(tp -> tp.topic()).collect(Collectors.toSet());\n+                        topicPartitionOffsets.keySet().retainAll(partitionsWithErrors);", "originalCommit": "7a52e1bf412570603250f74b9ab3b37d19e13b89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg4NTk1OQ==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r379885959", "bodyText": "That's a good point, there's a possibility of clobbering of data between calls. I just pushed a change for this as well as added a test as you suggested that starts out with partitions with the same leader, refreshes metadata, and moves to different leaders.", "author": "skaundinya15", "createdAt": "2020-02-16T08:48:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTg0OTM2MA=="}], "type": "inlineReview"}, {"oid": "161854296db3897472e766b965880a1b3ce2407f", "url": "https://github.com/apache/kafka/commit/161854296db3897472e766b965880a1b3ce2407f", "message": "addressing PR comments", "committedDate": "2020-02-16T08:46:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDgwNDMzOA==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380804338", "bodyText": "There's a bit of redundancy between this and partitionsWithErrors. Do we need both?", "author": "hachikuji", "createdAt": "2020-02-18T16:56:01Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3786,15 +3786,17 @@ public ListOffsetsResult listOffsets(Map<TopicPartition, OffsetSpec> topicPartit\n                 void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Set<TopicPartition> partitionsWithErrors = new HashSet<>();\n+                    Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();", "originalCommit": "161854296db3897472e766b965880a1b3ce2407f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDgzNDQ2MA==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380834460", "bodyText": "Good point, I think at this point it is redundant and can be removed - I'll remove it.", "author": "skaundinya15", "createdAt": "2020-02-18T17:48:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDgwNDMzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDgwNTc0OA==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380805748", "bodyText": "This code reads a bit awkwardly because we only have the check for the first branch. It seems like we are trying to handle the case that the broker has sent us responses for partitions that we did not ask for. Perhaps that should be a fatal error and we can call completeExceptionally?", "author": "hachikuji", "createdAt": "2020-02-18T16:58:20Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3786,15 +3786,17 @@ public ListOffsetsResult listOffsets(Map<TopicPartition, OffsetSpec> topicPartit\n                 void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n                     Set<TopicPartition> partitionsWithErrors = new HashSet<>();\n+                    Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n                     for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n                         TopicPartition tp = result.getKey();\n                         PartitionData partitionData = result.getValue();\n \n                         KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n                         Errors error = partitionData.error;\n-                        if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n+                        if (MetadataOperationContext.shouldRefreshMetadata(error) && topicPartitionOffsets.get(tp) != null) {", "originalCommit": "161854296db3897472e766b965880a1b3ce2407f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDgzNTU2MQ==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380835561", "bodyText": "Yeah I was trying to write the code so that we ignore any partitions we haven't asked for. Is it better behavior in this case to just silently ignore or raise an error and completeExceptionally? Thinking about this more I'm realizing it's probably better to raise an error and call completeExceptionally as we shouldn't be getting partitions we haven't asked for (considering the logic on how we pass the new partitions for metadata refreshes). I'll update the code to reflect that.", "author": "skaundinya15", "createdAt": "2020-02-18T17:50:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDgwNTc0OA=="}], "type": "inlineReview"}, {"oid": "01b4eedd6af9e61fa1e6488076855209c06c09c3", "url": "https://github.com/apache/kafka/commit/01b4eedd6af9e61fa1e6488076855209c06c09c3", "message": "addressing PR comments", "committedDate": "2020-02-18T20:57:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDkzOTExMw==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380939113", "bodyText": "Would this be any clearer?\nOffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\nif (offsetRequestSpec == null) {\n  future.completeExceptionally(error.exception());\n} else if (shouldRefreshMetadata(error) {\n  retryTopicPartitionOffsets.put(tp, offsetRequestSpec);\n} else {\n...\nAlso, in the case of that we got back an unexpected partition, I think we can raise a new KafkaException and provide a clear message indicating what happened.", "author": "hachikuji", "createdAt": "2020-02-18T21:15:30Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3794,8 +3793,11 @@ void handleResponse(AbstractResponse abstractResponse) {\n \n                         KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n                         Errors error = partitionData.error;\n-                        if (MetadataOperationContext.shouldRefreshMetadata(error) && topicPartitionOffsets.get(tp) != null) {\n-                            partitionsWithErrors.add(tp);\n+                        if (topicPartitionOffsets.get(tp) == null) {", "originalCommit": "01b4eedd6af9e61fa1e6488076855209c06c09c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk0MDQ1Mg==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380940452", "bodyText": "Yeah that's probably a better way of writing this. When you say raising a new KafkaException, do you mean throw it within the call or calling fail that raises a KafkaException here: https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L707)", "author": "skaundinya15", "createdAt": "2020-02-18T21:18:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDkzOTExMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk0NTk3MQ==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380945971", "bodyText": "Currently in this case, we do the following:\nfuture.completeExceptionally(error.exception());\n\nI am suggesting we do something like this:\nfuture.completeExceptionally(new KafkaException(\"Unexpected partition in response....\");", "author": "hachikuji", "createdAt": "2020-02-18T21:29:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDkzOTExMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk0OTEzMQ==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380949131", "bodyText": "Makes sense, just fixed that.", "author": "skaundinya15", "createdAt": "2020-02-18T21:36:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDkzOTExMw=="}], "type": "inlineReview"}, {"oid": "58a8d11bdfa0b95d00a497d305c0b3826088275a", "url": "https://github.com/apache/kafka/commit/58a8d11bdfa0b95d00a497d305c0b3826088275a", "message": "addressing PR comments", "committedDate": "2020-02-18T21:35:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1MjMyMQ==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380952321", "bodyText": "The slf4j {} placeholders will not work here since we are constructing the message ourselves.", "author": "hachikuji", "createdAt": "2020-02-18T21:42:41Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3785,29 +3785,34 @@ public ListOffsetsResult listOffsets(Map<TopicPartition, OffsetSpec> topicPartit\n                 @Override\n                 void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n-                    Set<TopicPartition> partitionsWithErrors = new HashSet<>();\n+                    Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n                     for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n                         TopicPartition tp = result.getKey();\n                         PartitionData partitionData = result.getValue();\n \n                         KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n                         Errors error = partitionData.error;\n-                        if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            partitionsWithErrors.add(tp);\n-                        } else if (error == Errors.NONE) {\n+                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                        if (offsetRequestSpec == null) {\n+                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition {} in broker response!\" + tp));", "originalCommit": "58a8d11bdfa0b95d00a497d305c0b3826088275a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1OTAwOQ==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380959009", "bodyText": "Ah I wasn't aware of that, just fixed it.", "author": "skaundinya15", "createdAt": "2020-02-18T21:55:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1MjMyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1MjgxMg==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380952812", "bodyText": "nit: conventionally, we put the else on the same level as the previous branch\n} else if (...", "author": "hachikuji", "createdAt": "2020-02-18T21:43:40Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -3785,29 +3785,34 @@ public ListOffsetsResult listOffsets(Map<TopicPartition, OffsetSpec> topicPartit\n                 @Override\n                 void handleResponse(AbstractResponse abstractResponse) {\n                     ListOffsetResponse response = (ListOffsetResponse) abstractResponse;\n-                    Set<TopicPartition> partitionsWithErrors = new HashSet<>();\n+                    Map<TopicPartition, OffsetSpec> retryTopicPartitionOffsets = new HashMap<>();\n \n                     for (Entry<TopicPartition, PartitionData> result : response.responseData().entrySet()) {\n                         TopicPartition tp = result.getKey();\n                         PartitionData partitionData = result.getValue();\n \n                         KafkaFutureImpl<ListOffsetsResultInfo> future = futures.get(tp);\n                         Errors error = partitionData.error;\n-                        if (MetadataOperationContext.shouldRefreshMetadata(error)) {\n-                            partitionsWithErrors.add(tp);\n-                        } else if (error == Errors.NONE) {\n+                        OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp);\n+                        if (offsetRequestSpec == null) {\n+                            future.completeExceptionally(new KafkaException(\"Unexpected topic partition {} in broker response!\" + tp));\n+                        }\n+                        else if (MetadataOperationContext.shouldRefreshMetadata(error)){", "originalCommit": "58a8d11bdfa0b95d00a497d305c0b3826088275a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1OTAxNg==", "url": "https://github.com/apache/kafka/pull/8119#discussion_r380959016", "bodyText": "Fixed.", "author": "skaundinya15", "createdAt": "2020-02-18T21:56:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1MjgxMg=="}], "type": "inlineReview"}, {"oid": "d5a8095c5b325c60512bfca4cb392e9ff222863e", "url": "https://github.com/apache/kafka/commit/d5a8095c5b325c60512bfca4cb392e9ff222863e", "message": "addressing PR comments", "committedDate": "2020-02-18T21:55:23Z", "type": "commit"}, {"oid": "f831fdac8787238674e96282ca77437c95c90a84", "url": "https://github.com/apache/kafka/commit/f831fdac8787238674e96282ca77437c95c90a84", "message": "fixing checkstyle issues", "committedDate": "2020-02-19T00:42:40Z", "type": "commit"}]}