{"pr_number": 8467, "pr_title": "MINOR: reduce allocations in log start and recovery checkpoints", "pr_createdAt": "2020-04-12T01:03:03Z", "pr_url": "https://github.com/apache/kafka/pull/8467", "timeline": [{"oid": "ebc5104a69bfeb20d7aebb7c00f202a3a5b034a1", "url": "https://github.com/apache/kafka/commit/ebc5104a69bfeb20d7aebb7c00f202a3a5b034a1", "message": "Reduce allocations in logsbydir", "committedDate": "2020-04-11T23:28:35Z", "type": "commit"}, {"oid": "ace92dd5b7227bb6906ae1d72f51979be9acf6cf", "url": "https://github.com/apache/kafka/commit/ace92dd5b7227bb6906ae1d72f51979be9acf6cf", "message": "Bring bench runs back in line", "committedDate": "2020-04-12T00:56:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUzNzkxOQ==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r409537919", "bodyText": "In the other PR we used AnyRefMap. Any reason why we are not doing that here?", "author": "ijuma", "createdAt": "2020-04-16T13:03:23Z", "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -1003,9 +1003,14 @@ class LogManager(logDirs: Seq[File],\n   /**\n    * Map of log dir to logs by topic and partitions in that dir\n    */\n-  private def logsByDir: Map[String, Map[TopicPartition, Log]] = {\n-    (this.currentLogs.toList ++ this.futureLogs.toList).toMap\n-      .groupBy { case (_, log) => log.parentDir }\n+  def logsByDir: Map[String, Map[TopicPartition, Log]] = {\n+    val byDir = new mutable.HashMap[String, mutable.HashMap[TopicPartition, Log]]()\n+    def addToDir(tp: TopicPartition, log: Log): Unit = {\n+      byDir.getOrElseUpdate(log.parentDir, new mutable.HashMap[TopicPartition, Log]()).put(tp, log)", "originalCommit": "ace92dd5b7227bb6906ae1d72f51979be9acf6cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUzODUwMg==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r409538502", "bodyText": "We should also add a comment about why we are writing non idiomatic code here to avoid reverts.", "author": "ijuma", "createdAt": "2020-04-16T13:04:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUzNzkxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU4MzgwNg==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r409583806", "bodyText": "Good point. I will try it and retest and add a comment to prevent regression.", "author": "lbradstreet", "createdAt": "2020-04-16T14:05:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUzNzkxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDk5NjY2Ng==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r410996666", "bodyText": "I have addressed this and it's ready for another review pass.", "author": "lbradstreet", "createdAt": "2020-04-19T21:36:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUzNzkxOQ=="}], "type": "inlineReview"}, {"oid": "b2e4221df073ff43dac16351e060a44f8c39748e", "url": "https://github.com/apache/kafka/commit/b2e4221df073ff43dac16351e060a44f8c39748e", "message": "Switch to AnyRefMap, add comment", "committedDate": "2020-04-19T21:35:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r413826884", "bodyText": "scala.collection.Map has a def foreachEntry[U](f: (K, V) => U): Unit method that avoids allocating tuples (it's a function with two parameters). If we want to avoid allocations, we should introduce a similar method to Pool and use it here.", "author": "ijuma", "createdAt": "2020-04-23T14:08:43Z", "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -1003,9 +1003,17 @@ class LogManager(logDirs: Seq[File],\n   /**\n    * Map of log dir to logs by topic and partitions in that dir\n    */\n-  private def logsByDir: Map[String, Map[TopicPartition, Log]] = {\n-    (this.currentLogs.toList ++ this.futureLogs.toList).toMap\n-      .groupBy { case (_, log) => log.parentDir }\n+  def logsByDir: Map[String, Map[TopicPartition, Log]] = {\n+    // This code is called often by checkpoint processes and is written in a way that reduces\n+    // allocations and CPU with many topic partitions.\n+    // When changing this code please measure the changes with org.apache.kafka.jmh.server.CheckpointBench\n+    val byDir = new mutable.AnyRefMap[String, mutable.AnyRefMap[TopicPartition, Log]]()\n+    def addToDir(tp: TopicPartition, log: Log): Unit = {\n+      byDir.getOrElseUpdate(log.parentDir, new mutable.AnyRefMap[TopicPartition, Log]()).put(tp, log)\n+    }\n+    currentLogs.foreach { case (tp, log) => addToDir(tp, log) }\n+    futureLogs.foreach { case (tp, log) => addToDir(tp, log) }", "originalCommit": "b2e4221df073ff43dac16351e060a44f8c39748e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDEwMDk0NA==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414100944", "bodyText": "I tried out your suggestion and interestingly saw more allocations. Note extreme use of the var item there in case there was an extra allocation there.\n--- a/core/src/main/scala/kafka/log/LogManager.scala\n+++ b/core/src/main/scala/kafka/log/LogManager.scala\n@@ -1011,8 +1011,8 @@ class LogManager(logDirs: Seq[File],\n     def addToDir(tp: TopicPartition, log: Log): Unit = {\n       byDir.getOrElseUpdate(log.parentDir, new mutable.AnyRefMap[TopicPartition, Log]()).put(tp, log)\n     }\n-    currentLogs.foreach { case (tp, log) => addToDir(tp, log) }\n-    futureLogs.foreach { case (tp, log) => addToDir(tp, log) }\n+    currentLogs.foreachEntry(addToDir)\n+    futureLogs.foreachEntry(addToDir)\n     byDir\n   }\n \ndiff --git a/core/src/main/scala/kafka/utils/Pool.scala b/core/src/main/scala/kafka/utils/Pool.scala\nindex 964de7eae2..450f90611b 100644\n--- a/core/src/main/scala/kafka/utils/Pool.scala\n+++ b/core/src/main/scala/kafka/utils/Pool.scala\n@@ -74,6 +74,15 @@ class Pool[K,V](valueFactory: Option[K => V] = None) extends Iterable[(K, V)] {\n   def values: Iterable[V] = pool.values.asScala\n \n   def clear(): Unit = { pool.clear() }\n+\n+  def foreachEntry(f: (K, V) => Unit): Unit = {\n+    val iter = iterator\n+    var item: (K, V) = null\n+    while(iter.hasNext) {\n+      item = iter.next()\n+      f(item._1, item._2)\n+    }\n+  }\n\nCheckpointBench.measureCheckpointLogStartOffsets:\u00b7gc.alloc.rate.norm                         3         2000  thrpt   15  1428889.965 \u00b1  75131.113    B/op\nvs this PR:\nCheckpointBench.measureCheckpointLogStartOffsets:\u00b7gc.alloc.rate.norm                         3         2000  thrpt   15  1284326.850 \u00b1  75148.430    B/op", "author": "lbradstreet", "createdAt": "2020-04-23T20:27:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDEwMTQzOA==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414101438", "bodyText": "^ updated text there to say \"this PR\" rather than trunk.", "author": "lbradstreet", "createdAt": "2020-04-23T20:28:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDEwNTkwMQ==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414105901", "bodyText": "I think the issue is that you're not using the underlying map iterator, right?", "author": "ijuma", "createdAt": "2020-04-23T20:35:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDEwNjM2Nw==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414106367", "bodyText": "You have to use the iterator of ConcurrentHashMap[K, V] which gives you Map.Entry instead of a tuple. Then you avoid it.", "author": "ijuma", "createdAt": "2020-04-23T20:36:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDEwNjgwNg==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414106806", "bodyText": "(or forEach in the ConcurrentHashMap)", "author": "ijuma", "createdAt": "2020-04-23T20:37:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE1MTcwNw==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414151707", "bodyText": "Duh, I was a bit hasty on that one. The fact that it was still a tuple was a dead give away...\nNew results are better, 18% reduction:\nCheckpointBench.measureCheckpointLogStartOffsets:\u00b7gc.alloc.rate.norm                         3         2000  thrpt   15  1044120.722 \u00b1  1676.137    B/op", "author": "lbradstreet", "createdAt": "2020-04-23T21:57:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE1MjM1Mg==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414152352", "bodyText": "Do you know what I'm doing wrong when I supply a lambda to the java .forEach? I know it works for consumers but in my brief effort improving this I couldn't make it work with the BiConsumer here and had to create a new one.\nI will update the body with the rerun jmh results.", "author": "lbradstreet", "createdAt": "2020-04-23T21:59:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE2MjI0Mg==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414162242", "bodyText": "What error are you getting?", "author": "ijuma", "createdAt": "2020-04-23T22:20:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE5MDIzMw==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414190233", "bodyText": "AFAICT, it easy enough to do something like this:\npool.forEach((k,v) => f(k,v))\n\nBut then we appear to be back to allocating tuples.\nIt doesn't appear easy to do something like:\npool.forEach(kv => f(kv.getKey, kv.getValue))\n\nsince it's not able to create a BiConsumer for you.", "author": "lbradstreet", "createdAt": "2020-04-23T23:28:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDI5NjYxMw==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414296613", "bodyText": "Why do you say that the following would allocate tuples?\ndef foreachEntry(f: (K, V) => Unit): Unit = {\n    pool.forEach((k, v) => f(k, v))\n  }\nDid you measure it? Looking at the code, I don't see any tuples.", "author": "ijuma", "createdAt": "2020-04-24T05:08:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDU5MjgxOA==", "url": "https://github.com/apache/kafka/pull/8467#discussion_r414592818", "bodyText": "@ijuma I had mistakenly thought it was taking a tuple there, and maybe that was just the way Scala converted a lambda to a BiConsumer, and the results had regressed back to close to what I was seeing with the iterator version.\nWhen I ran it, it returned saw:\n1140074.937 \u00b1 75151.914    B/op\ndef foreachEntry(f: (K, V) => Unit): Unit = {\n    pool.forEach((k, v) => f(k, v))\n  }\n\n1044120.722 \u00b1  1676.137    B/op (included in an above comment)   \npool.forEach(new BiConsumer[K,V] {\n      override def accept(t: K, u: V): Unit = f(t, u)\n    })\n\nStrangely I have just re-run the BiConsumer version and it returned 1188097.413 \u00b1  1639.537    B/op. I'm not sure why it's regressed from what I saw on a previous run. I am OK with using the version with a lambda if you are. I'm not sure I will have time to investigate it further, and it's still a good improvement compared to the version that used foreach.", "author": "lbradstreet", "createdAt": "2020-04-24T13:52:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgyNjg4NA=="}], "type": "inlineReview"}, {"oid": "2ce3e124ea55bf3ca1728fb234dc53e159a50b7b", "url": "https://github.com/apache/kafka/commit/2ce3e124ea55bf3ca1728fb234dc53e159a50b7b", "message": "Add foreachEntry to Pool", "committedDate": "2020-04-23T21:53:23Z", "type": "commit"}, {"oid": "4f67c6230ac6f79e39eb11e2ba80264af6a7f296", "url": "https://github.com/apache/kafka/commit/4f67c6230ac6f79e39eb11e2ba80264af6a7f296", "message": "Revert topic counts change", "committedDate": "2020-04-23T21:56:06Z", "type": "commit"}, {"oid": "d54ecb85f549c1555fbd63c65b8e97dace4e9c1d", "url": "https://github.com/apache/kafka/commit/d54ecb85f549c1555fbd63c65b8e97dace4e9c1d", "message": "Switch to using lambda with forEach", "committedDate": "2020-04-24T13:49:56Z", "type": "commit"}, {"oid": "409f4830d20d9c71abc402591395c6eac4231653", "url": "https://github.com/apache/kafka/commit/409f4830d20d9c71abc402591395c6eac4231653", "message": "Remove unused import", "committedDate": "2020-04-24T22:20:01Z", "type": "commit"}]}