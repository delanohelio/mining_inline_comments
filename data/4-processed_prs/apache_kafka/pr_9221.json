{"pr_number": 9221, "pr_title": "KAFKA-10436: Implement KIP-478 Topology changes", "pr_createdAt": "2020-08-26T01:25:52Z", "pr_url": "https://github.com/apache/kafka/pull/9221", "timeline": [{"oid": "8099dd0cf246b39710b94f0528f97c38bc542362", "url": "https://github.com/apache/kafka/commit/8099dd0cf246b39710b94f0528f97c38bc542362", "message": "Port addProcessor", "committedDate": "2020-08-25T22:33:49Z", "type": "commit"}, {"oid": "f58e275aaabdc6aeee531cb2102d62798746fab8", "url": "https://github.com/apache/kafka/commit/f58e275aaabdc6aeee531cb2102d62798746fab8", "message": "roll back statestore change", "committedDate": "2020-08-25T22:41:10Z", "type": "commit"}, {"oid": "de3fab16b6d91c363718dcfb0ab875853b2db75f", "url": "https://github.com/apache/kafka/commit/de3fab16b6d91c363718dcfb0ab875853b2db75f", "message": "cleanup", "committedDate": "2020-08-26T00:12:30Z", "type": "commit"}, {"oid": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "url": "https://github.com/apache/kafka/commit/f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "message": "fix", "committedDate": "2020-08-26T00:28:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1MTE2NA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476951164", "bodyText": "Since the new public API change is small, I also converted almost all of the usages of the old API to the new one.", "author": "vvcephei", "createdAt": "2020-08-26T01:27:50Z", "path": "streams/examples/src/test/java/org/apache/kafka/streams/examples/docs/DeveloperGuideTesting.java", "diffHunk": "@@ -145,24 +145,24 @@ public void shouldPunctuateIfWallClockTimeAdvances() {\n         assertThat(outputTopic.isEmpty(), is(true));\n     }\n \n-    public static class CustomMaxAggregatorSupplier implements ProcessorSupplier<String, Long> {\n+    public static class CustomMaxAggregatorSupplier implements ProcessorSupplier<String, Long, String, Long> {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1Mzc5Mw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476953793", "bodyText": "This is a small improvement I noticed; I'll mention this on the KIP discussion if you like it. I've changed the ProcessorContext getStateStore method so that we don't have to cast the store type anymore. The generic parameters to the method take care of casting now.", "author": "vvcephei", "createdAt": "2020-08-26T01:31:42Z", "path": "streams/examples/src/test/java/org/apache/kafka/streams/examples/docs/DeveloperGuideTesting.java", "diffHunk": "@@ -145,24 +145,24 @@ public void shouldPunctuateIfWallClockTimeAdvances() {\n         assertThat(outputTopic.isEmpty(), is(true));\n     }\n \n-    public static class CustomMaxAggregatorSupplier implements ProcessorSupplier<String, Long> {\n+    public static class CustomMaxAggregatorSupplier implements ProcessorSupplier<String, Long, String, Long> {\n         @Override\n-        public Processor<String, Long> get() {\n+        public Processor<String, Long, String, Long> get() {\n             return new CustomMaxAggregator();\n         }\n     }\n \n-    public static class CustomMaxAggregator implements Processor<String, Long> {\n-        ProcessorContext context;\n+    public static class CustomMaxAggregator implements Processor<String, Long, String, Long> {\n+        ProcessorContext<String, Long> context;\n         private KeyValueStore<String, Long> store;\n \n         @SuppressWarnings(\"unchecked\")\n         @Override\n-        public void init(final ProcessorContext context) {\n+        public void init(final ProcessorContext<String, Long> context) {\n             this.context = context;\n             context.schedule(Duration.ofSeconds(60), PunctuationType.WALL_CLOCK_TIME, time -> flushStore());\n             context.schedule(Duration.ofSeconds(10), PunctuationType.STREAM_TIME, time -> flushStore());\n-            store = (KeyValueStore<String, Long>) context.getStateStore(\"aggStore\");\n+            store = context.getStateStore(\"aggStore\");", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NDEwNg==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476954106", "bodyText": "It has default method in the new API.", "author": "vvcephei", "createdAt": "2020-08-26T01:32:08Z", "path": "streams/examples/src/test/java/org/apache/kafka/streams/examples/docs/DeveloperGuideTesting.java", "diffHunk": "@@ -180,8 +180,5 @@ private void flushStore() {\n                 context.forward(next.key, next.value);\n             }\n         }\n-\n-        @Override\n-        public void close() {}", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NDU1OA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476954558", "bodyText": "as in previous changes, delegating the old API to the new one.", "author": "vvcephei", "createdAt": "2020-08-26T01:32:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/Topology.java", "diffHunk": "@@ -658,8 +658,42 @@ public synchronized Topology addSink(final String name,\n      */\n     @SuppressWarnings(\"rawtypes\")\n     public synchronized Topology addProcessor(final String name,\n-                                              final ProcessorSupplier supplier,\n+                                              final org.apache.kafka.streams.processor.ProcessorSupplier supplier,\n                                               final String... parentNames) {\n+        return addProcessor(\n+            name,\n+            new ProcessorSupplier<Object, Object, Object, Object>() {\n+                @Override\n+                public Set<StoreBuilder<?>> stores() {\n+                    return supplier.stores();\n+                }\n+\n+                @Override\n+                public org.apache.kafka.streams.processor.api.Processor<Object, Object, Object, Object> get() {\n+                    return ProcessorAdapter.adaptRaw(supplier.get());\n+                }\n+            },\n+            parentNames\n+        );\n+    }", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NDcxNQ==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476954715", "bodyText": "new API", "author": "vvcephei", "createdAt": "2020-08-26T01:33:09Z", "path": "streams/src/main/java/org/apache/kafka/streams/Topology.java", "diffHunk": "@@ -658,8 +658,42 @@ public synchronized Topology addSink(final String name,\n      */\n     @SuppressWarnings(\"rawtypes\")\n     public synchronized Topology addProcessor(final String name,\n-                                              final ProcessorSupplier supplier,\n+                                              final org.apache.kafka.streams.processor.ProcessorSupplier supplier,\n                                               final String... parentNames) {\n+        return addProcessor(\n+            name,\n+            new ProcessorSupplier<Object, Object, Object, Object>() {\n+                @Override\n+                public Set<StoreBuilder<?>> stores() {\n+                    return supplier.stores();\n+                }\n+\n+                @Override\n+                public org.apache.kafka.streams.processor.api.Processor<Object, Object, Object, Object> get() {\n+                    return ProcessorAdapter.adaptRaw(supplier.get());\n+                }\n+            },\n+            parentNames\n+        );\n+    }\n+\n+    /**\n+     * Add a new processor node that receives and processes records output by one or more parent source or processor\n+     * node.\n+     * Any new record output by this processor will be forwarded to its child processor or sink nodes.\n+     * If {@code supplier} provides stores via {@link ConnectedStoreProvider#stores()}, the provided {@link StoreBuilder}s\n+     * will be added to the topology and connected to this processor automatically.\n+     *\n+     * @param name the unique name of the processor node\n+     * @param supplier the supplier used to obtain this node's {@link Processor} instance\n+     * @param parentNames the name of one or more source or processor nodes whose output records this processor should receive\n+     * and process\n+     * @return itself\n+     * @throws TopologyException if parent processor is not added yet, or if this processor's name is equal to the parent's name\n+     */\n+    public synchronized <KIn, VIn, KOut, VOut> Topology addProcessor(final String name,\n+                                                                     final ProcessorSupplier<KIn, VIn, KOut, VOut> supplier,\n+                                                                     final String... parentNames) {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NTc4Nw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476955787", "bodyText": "As in the other PRs, I inverted the imports, so the old API is fully qualified now, and the new API is imported.", "author": "vvcephei", "createdAt": "2020-08-26T01:34:47Z", "path": "streams/src/main/java/org/apache/kafka/streams/Topology.java", "diffHunk": "@@ -713,7 +747,7 @@ public synchronized Topology addStateStore(final StoreBuilder<?> storeBuilder,\n                                                        final Deserializer<V> valueDeserializer,\n                                                        final String topic,\n                                                        final String processorName,\n-                                                       final ProcessorSupplier<K, V> stateUpdateSupplier) {\n+                                                       final org.apache.kafka.streams.processor.ProcessorSupplier<K, V> stateUpdateSupplier) {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NTk2Nw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476955967", "bodyText": "new API", "author": "vvcephei", "createdAt": "2020-08-26T01:35:04Z", "path": "streams/src/main/java/org/apache/kafka/streams/Topology.java", "diffHunk": "@@ -772,6 +806,94 @@ public synchronized Topology addStateStore(final StoreBuilder<?> storeBuilder,\n         return this;\n     }\n \n+    /**\n+     * Adds a global {@link StateStore} to the topology.\n+     * The {@link StateStore} sources its data from all partitions of the provided input topic.\n+     * There will be exactly one instance of this {@link StateStore} per Kafka Streams instance.\n+     * <p>\n+     * A {@link SourceNode} with the provided sourceName will be added to consume the data arriving from the partitions\n+     * of the input topic.\n+     * <p>\n+     * The provided {@link ProcessorSupplier} will be used to create an {@link ProcessorNode} that will receive all\n+     * records forwarded from the {@link SourceNode}.\n+     * This {@link ProcessorNode} should be used to keep the {@link StateStore} up-to-date.\n+     * The default {@link TimestampExtractor} as specified in the {@link StreamsConfig config} is used.\n+     *\n+     * @param storeBuilder          user defined state store builder\n+     * @param sourceName            name of the {@link SourceNode} that will be automatically added\n+     * @param keyDeserializer       the {@link Deserializer} to deserialize keys with\n+     * @param valueDeserializer     the {@link Deserializer} to deserialize values with\n+     * @param topic                 the topic to source the data from\n+     * @param processorName         the name of the {@link ProcessorSupplier}\n+     * @param stateUpdateSupplier   the instance of {@link ProcessorSupplier}\n+     * @return itself\n+     * @throws TopologyException if the processor of state is already registered\n+     */\n+    public synchronized <KIn, VIn> Topology addGlobalStore(final StoreBuilder<?> storeBuilder,\n+                                                           final String sourceName,\n+                                                           final Deserializer<KIn> keyDeserializer,\n+                                                           final Deserializer<VIn> valueDeserializer,\n+                                                           final String topic,\n+                                                           final String processorName,\n+                                                           final ProcessorSupplier<KIn, VIn, Void, Void> stateUpdateSupplier) {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NjEzOQ==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476956139", "bodyText": "new API", "author": "vvcephei", "createdAt": "2020-08-26T01:35:20Z", "path": "streams/src/main/java/org/apache/kafka/streams/Topology.java", "diffHunk": "@@ -772,6 +806,94 @@ public synchronized Topology addStateStore(final StoreBuilder<?> storeBuilder,\n         return this;\n     }\n \n+    /**\n+     * Adds a global {@link StateStore} to the topology.\n+     * The {@link StateStore} sources its data from all partitions of the provided input topic.\n+     * There will be exactly one instance of this {@link StateStore} per Kafka Streams instance.\n+     * <p>\n+     * A {@link SourceNode} with the provided sourceName will be added to consume the data arriving from the partitions\n+     * of the input topic.\n+     * <p>\n+     * The provided {@link ProcessorSupplier} will be used to create an {@link ProcessorNode} that will receive all\n+     * records forwarded from the {@link SourceNode}.\n+     * This {@link ProcessorNode} should be used to keep the {@link StateStore} up-to-date.\n+     * The default {@link TimestampExtractor} as specified in the {@link StreamsConfig config} is used.\n+     *\n+     * @param storeBuilder          user defined state store builder\n+     * @param sourceName            name of the {@link SourceNode} that will be automatically added\n+     * @param keyDeserializer       the {@link Deserializer} to deserialize keys with\n+     * @param valueDeserializer     the {@link Deserializer} to deserialize values with\n+     * @param topic                 the topic to source the data from\n+     * @param processorName         the name of the {@link ProcessorSupplier}\n+     * @param stateUpdateSupplier   the instance of {@link ProcessorSupplier}\n+     * @return itself\n+     * @throws TopologyException if the processor of state is already registered\n+     */\n+    public synchronized <KIn, VIn> Topology addGlobalStore(final StoreBuilder<?> storeBuilder,\n+                                                           final String sourceName,\n+                                                           final Deserializer<KIn> keyDeserializer,\n+                                                           final Deserializer<VIn> valueDeserializer,\n+                                                           final String topic,\n+                                                           final String processorName,\n+                                                           final ProcessorSupplier<KIn, VIn, Void, Void> stateUpdateSupplier) {\n+        internalTopologyBuilder.addGlobalStore(\n+            storeBuilder,\n+            sourceName,\n+            null,\n+            keyDeserializer,\n+            valueDeserializer,\n+            topic,\n+            processorName,\n+            stateUpdateSupplier\n+        );\n+        return this;\n+    }\n+\n+    /**\n+     * Adds a global {@link StateStore} to the topology.\n+     * The {@link StateStore} sources its data from all partitions of the provided input topic.\n+     * There will be exactly one instance of this {@link StateStore} per Kafka Streams instance.\n+     * <p>\n+     * A {@link SourceNode} with the provided sourceName will be added to consume the data arriving from the partitions\n+     * of the input topic.\n+     * <p>\n+     * The provided {@link ProcessorSupplier} will be used to create an {@link ProcessorNode} that will receive all\n+     * records forwarded from the {@link SourceNode}.\n+     * This {@link ProcessorNode} should be used to keep the {@link StateStore} up-to-date.\n+     *\n+     * @param storeBuilder          user defined key value store builder\n+     * @param sourceName            name of the {@link SourceNode} that will be automatically added\n+     * @param timestampExtractor    the stateless timestamp extractor used for this source,\n+     *                              if not specified the default extractor defined in the configs will be used\n+     * @param keyDeserializer       the {@link Deserializer} to deserialize keys with\n+     * @param valueDeserializer     the {@link Deserializer} to deserialize values with\n+     * @param topic                 the topic to source the data from\n+     * @param processorName         the name of the {@link ProcessorSupplier}\n+     * @param stateUpdateSupplier   the instance of {@link ProcessorSupplier}\n+     * @return itself\n+     * @throws TopologyException if the processor of state is already registered\n+     */\n+    public synchronized <KIn, VIn> Topology addGlobalStore(final StoreBuilder<?> storeBuilder,\n+                                                           final String sourceName,\n+                                                           final TimestampExtractor timestampExtractor,\n+                                                           final Deserializer<KIn> keyDeserializer,\n+                                                           final Deserializer<VIn> valueDeserializer,\n+                                                           final String topic,\n+                                                           final String processorName,\n+                                                           final ProcessorSupplier<KIn, VIn, Void, Void> stateUpdateSupplier) {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MzUwOQ==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r485053509", "bodyText": "For consideration - maybe provide a builder for use as parameter.\nSomething like\nGlobalStoreBuilder.builder().addSource().addTimestampextractor().addTopic()...\nJust a thought, whenever I see long parameter lists I tend to look if there's a way to include a builder instead", "author": "bbejeck", "createdAt": "2020-09-08T16:35:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NjEzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTczMjEyNw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r485732127", "bodyText": "Yeah, this probably would have been a better design. I'm a little hesitant to make this change to the KIP right now, though. Subjectively, it seems more lightweight for users if they don't have to change much of their code to switch over to the new API. Also, maybe I have a little bit of emotional resistance to increasing the scope of this KIP because it's been taking so long to actually make progress on it.\nI've filed https://issues.apache.org/jira/browse/KAFKA-10472 to capture the thought, though.", "author": "vvcephei", "createdAt": "2020-09-09T16:07:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NjEzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NjQwNA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476956404", "bodyText": "referencing the new API", "author": "vvcephei", "createdAt": "2020-08-26T01:35:47Z", "path": "streams/src/main/java/org/apache/kafka/streams/TopologyDescription.java", "diffHunk": "@@ -37,8 +38,8 @@\n     /**\n      * A connected sub-graph of a {@link Topology}.\n      * <p>\n-     * Nodes of a {@code Subtopology} are connected {@link Topology#addProcessor(String,\n-     * org.apache.kafka.streams.processor.ProcessorSupplier, String...) directly} or indirectly via\n+     * Nodes of a {@code Subtopology} are connected\n+     * {@link Topology#addProcessor(String, ProcessorSupplier, String...) directly} or indirectly via", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1NzI5NA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476957294", "bodyText": "I've also converted ProcessorParameters to the new API, so you'll see a lot of changes like this. Many of them will eventually go away as individual processors are converted (such as, in this case, KTableSource).", "author": "vvcephei", "createdAt": "2020-08-26T01:37:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/InternalStreamsBuilder.java", "diffHunk": "@@ -127,7 +127,7 @@ public InternalStreamsBuilder(final InternalTopologyBuilder internalTopologyBuil\n             .orElseGenerateWithPrefix(this, KTableImpl.SOURCE_NAME);\n \n         final KTableSource<K, V> tableSource = new KTableSource<>(materialized.storeName(), materialized.queryableStoreName());\n-        final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(tableSource, tableSourceName);\n+        final ProcessorParameters<K, V, ?, ?> processorParameters = new ProcessorParameters<>(tableSource, tableSourceName);", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1ODMwNA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476958304", "bodyText": "Prototyping this KIP was actually how I discovered this conflation to begin with. Once we start converting Processors to the new API, the compiler will make this conflation impossible, and this method will eventually be unused.", "author": "vvcephei", "createdAt": "2020-08-26T01:38:39Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KTableImpl.java", "diffHunk": "@@ -851,12 +851,12 @@ boolean sendingOldValueEnabled() {\n     }\n \n     /**\n-     * We conflate V with Change<V> in many places. It might be nice to fix that eventually.\n+     * We conflate V with Change<V> in many places. This will get fixed in the implementation of KIP-478.", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk1OTUzOQ==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476959539", "bodyText": "You'll see in the ProcessorParameters class that I've captured both the old and new APIs and also internalized a few casts. This is all just an effort to limit the scope of this PR. It'll all come out in the wash once the KIP is completely implemented.", "author": "vvcephei", "createdAt": "2020-08-26T01:40:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/GraphGraceSearchUtil.java", "diffHunk": "@@ -70,7 +70,7 @@ private static long findAndVerifyWindowGrace(final StreamsGraphNode streamsGraph\n \n     private static Long extractGracePeriod(final StreamsGraphNode node) {\n         if (node instanceof StatefulProcessorNode) {\n-            final ProcessorSupplier processorSupplier = ((StatefulProcessorNode) node).processorParameters().processorSupplier();\n+            final ProcessorSupplier processorSupplier = ((StatefulProcessorNode) node).processorParameters().oldProcessorSupplier();", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MDA1MQ==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476960051", "bodyText": "An example of an internalized cast.", "author": "vvcephei", "createdAt": "2020-08-26T01:41:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/KTableKTableJoinNode.java", "diffHunk": "@@ -82,14 +81,18 @@\n     }\n \n     public String queryableStoreName() {\n-        return ((KTableKTableJoinMerger<K, VR>) mergeProcessorParameters().processorSupplier()).getQueryableName();\n+        return mergeProcessorParameters().kTableKTableJoinMergerProcessorSupplier().getQueryableName();", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MDg5NA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476960894", "bodyText": "Specifically, it'll get fixed when KTableKTableJoinMerger is converted.", "author": "vvcephei", "createdAt": "2020-08-26T01:42:21Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/KTableKTableJoinNode.java", "diffHunk": "@@ -82,14 +81,18 @@\n     }\n \n     public String queryableStoreName() {\n-        return ((KTableKTableJoinMerger<K, VR>) mergeProcessorParameters().processorSupplier()).getQueryableName();\n+        return mergeProcessorParameters().kTableKTableJoinMergerProcessorSupplier().getQueryableName();\n     }\n \n     /**\n      * The supplier which provides processor with KTable-KTable join merge functionality.\n      */\n+    @SuppressWarnings(\"unchecked\")\n     public KTableKTableJoinMerger<K, VR> joinMerger() {\n-        return (KTableKTableJoinMerger<K, VR>) mergeProcessorParameters().processorSupplier();\n+        final KTableKTableJoinMerger<K, Change<VR>> merger =\n+            mergeProcessorParameters().kTableKTableJoinMergerProcessorSupplier();\n+        // this incorrect cast should be corrected by the end of the KIP-478 implementation", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MTI1Nw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476961257", "bodyText": "Converted to the new API.", "author": "vvcephei", "createdAt": "2020-08-26T01:42:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/ProcessorParameters.java", "diffHunk": "@@ -26,22 +30,57 @@\n  * Used by the Join nodes as there are several parameters, this abstraction helps\n  * keep the number of arguments more reasonable.\n  */\n-public class ProcessorParameters<K, V> {\n+public class ProcessorParameters<KIn, VIn, KOut, VOut> {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MjI1Ng==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476962256", "bodyText": "The constructor for the old API is still present, and when you call it, we save a direct reference as well as adapting it to the new API. saving a direct reference dramatically simplifies the casts we've internalized below. Once everything is converted, we'll go back to just one reference saved.", "author": "vvcephei", "createdAt": "2020-08-26T01:44:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/ProcessorParameters.java", "diffHunk": "@@ -26,22 +30,57 @@\n  * Used by the Join nodes as there are several parameters, this abstraction helps\n  * keep the number of arguments more reasonable.\n  */\n-public class ProcessorParameters<K, V> {\n+public class ProcessorParameters<KIn, VIn, KOut, VOut> {\n \n-    private final ProcessorSupplier<K, V> processorSupplier;\n+    // During the transition to KIP-478, we capture arguments passed from the old API to simplify\n+    // the performance of casts that we still need to perform. This will eventually be removed.\n+    private final org.apache.kafka.streams.processor.ProcessorSupplier<KIn, VIn> oldProcessorSupplier;\n+    private final ProcessorSupplier<KIn, VIn, KOut, VOut> processorSupplier;\n     private final String processorName;\n \n-    public ProcessorParameters(final ProcessorSupplier<K, V> processorSupplier,\n+    public ProcessorParameters(final org.apache.kafka.streams.processor.ProcessorSupplier<KIn, VIn> processorSupplier,\n                                final String processorName) {\n+        oldProcessorSupplier = processorSupplier;\n+        this.processorSupplier = () -> ProcessorAdapter.adapt(processorSupplier.get());\n+        this.processorName = processorName;\n+    }", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MjgwMw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476962803", "bodyText": "This replaces a type check that was previously done elsewhere.", "author": "vvcephei", "createdAt": "2020-08-26T01:45:14Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/ProcessorParameters.java", "diffHunk": "@@ -26,22 +30,57 @@\n  * Used by the Join nodes as there are several parameters, this abstraction helps\n  * keep the number of arguments more reasonable.\n  */\n-public class ProcessorParameters<K, V> {\n+public class ProcessorParameters<KIn, VIn, KOut, VOut> {\n \n-    private final ProcessorSupplier<K, V> processorSupplier;\n+    // During the transition to KIP-478, we capture arguments passed from the old API to simplify\n+    // the performance of casts that we still need to perform. This will eventually be removed.\n+    private final org.apache.kafka.streams.processor.ProcessorSupplier<KIn, VIn> oldProcessorSupplier;\n+    private final ProcessorSupplier<KIn, VIn, KOut, VOut> processorSupplier;\n     private final String processorName;\n \n-    public ProcessorParameters(final ProcessorSupplier<K, V> processorSupplier,\n+    public ProcessorParameters(final org.apache.kafka.streams.processor.ProcessorSupplier<KIn, VIn> processorSupplier,\n                                final String processorName) {\n+        oldProcessorSupplier = processorSupplier;\n+        this.processorSupplier = () -> ProcessorAdapter.adapt(processorSupplier.get());\n+        this.processorName = processorName;\n+    }\n \n+    public ProcessorParameters(final ProcessorSupplier<KIn, VIn, KOut, VOut> processorSupplier,\n+                               final String processorName) {\n+        oldProcessorSupplier = null;\n         this.processorSupplier = processorSupplier;\n         this.processorName = processorName;\n     }\n \n-    public ProcessorSupplier<K, V> processorSupplier() {\n+    public ProcessorSupplier<KIn, VIn, KOut, VOut> processorSupplier() {\n         return processorSupplier;\n     }\n \n+    public org.apache.kafka.streams.processor.ProcessorSupplier<KIn, VIn> oldProcessorSupplier() {\n+        return oldProcessorSupplier;\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    KTableSource<KIn, VIn> kTableSourceSupplier() {\n+        // This cast always works because KTableSource hasn't been converted yet.\n+        return oldProcessorSupplier == null\n+            ? null\n+            : !(oldProcessorSupplier instanceof KTableSource)\n+              ? null\n+              : (KTableSource<KIn, VIn>) oldProcessorSupplier;\n+    }", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTY4NTIyNw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r485685227", "bodyText": "Just a minor thought here.  I'm wondering if these ktableX methods should go in a separate class, I feel like this is \"leaks\" a little bit. But I don't have a better idea ATM, so maybe we can revisit later.", "author": "bbejeck", "createdAt": "2020-09-09T15:04:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MjgwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTczNTE1Mg==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r485735152", "bodyText": "Thanks; yes, let's revisit it after the dust settles from KIP-478. These methods are for the most part temporary, since it's a real pain to do the cast when you have to deal with the current \"dual interface\" state in which processors might be old-style or new-style.\nI have a feeling I'll be able to eliminate these methods completely when I convert the relevant processors to the new API again.", "author": "vvcephei", "createdAt": "2020-09-09T16:10:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MjgwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2MzQ4OA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476963488", "bodyText": "This is kind of horrible, but it'll be gone soon enough.", "author": "vvcephei", "createdAt": "2020-08-26T01:46:11Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/StatefulProcessorNode.java", "diffHunk": "@@ -99,5 +99,14 @@ public void writeToTopology(final InternalTopologyBuilder topologyBuilder) {\n             }\n         }\n \n+        // temporary hack until KIP-478 is fully implemented", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2NDM2Mg==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476964362", "bodyText": "This is the type check that I internalized. Note, it becomes more complicated now that we also have to check whether or not the supplier is an \"old API\" supplier.", "author": "vvcephei", "createdAt": "2020-08-26T01:47:31Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/TableProcessorNode.java", "diffHunk": "@@ -67,8 +66,8 @@ public void writeToTopology(final InternalTopologyBuilder topologyBuilder) {\n             topologyBuilder.connectProcessorAndStateStores(processorName, storeNames);\n         }\n \n-        if (processorParameters.processorSupplier() instanceof KTableSource) {\n-            if (((KTableSource<?, ?>) processorParameters.processorSupplier()).materialized()) {\n+        if (processorParameters.kTableSourceSupplier() != null) {\n+            if (processorParameters.kTableSourceSupplier().materialized()) {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2NTE0OA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476965148", "bodyText": "This was a minor API design error. The intent was to document that we could throw the exception, but declaring a runtime exception in the method header doesn't do anything. The right way to do it is to put it in the javadoc.", "author": "vvcephei", "createdAt": "2020-08-26T01:48:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/ProcessorContext.java", "diffHunk": "@@ -159,10 +159,11 @@ Cancellable schedule(final long intervalMs,\n      * @param type one of: {@link PunctuationType#STREAM_TIME}, {@link PunctuationType#WALL_CLOCK_TIME}\n      * @param callback a function consuming timestamps representing the current stream or system time\n      * @return a handle allowing cancellation of the punctuation schedule established by this method\n+     * @throws IllegalArgumentException if the interval is not representable in milliseconds\n      */\n     Cancellable schedule(final Duration interval,\n                          final PunctuationType type,\n-                         final Punctuator callback) throws IllegalArgumentException;\n+                         final Punctuator callback);", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2NTk4Nw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476965987", "bodyText": "This is the small extension to the KIP that I mentioned, which means callers no longer have to cast the result to the store interface that they need (eg KeyValueStore).", "author": "vvcephei", "createdAt": "2020-08-26T01:49:54Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -102,7 +102,7 @@ void register(final StateStore store,\n      * @param name The store name\n      * @return The state store instance\n      */\n-    StateStore getStateStore(final String name);\n+    <S extends StateStore> S getStateStore(final String name);", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2Njg5NA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476966894", "bodyText": "Just converting the internal method, since we've introduced the new API in the public Topology.", "author": "vvcephei", "createdAt": "2020-08-26T01:51:08Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -482,9 +482,9 @@ public final void addSource(final Topology.AutoOffsetReset offsetReset,\n         nodeGroups = null;\n     }\n \n-    public final void addProcessor(final String name,\n-                                   final org.apache.kafka.streams.processor.ProcessorSupplier<?, ?> supplier,\n-                                   final String... predecessorNames) {\n+    public final <KIn, VIn, KOut, VOut> void addProcessor(final String name,\n+                                                          final ProcessorSupplier<KIn, VIn, KOut, VOut> supplier,\n+                                                          final String... predecessorNames) {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2NzI5Nw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476967297", "bodyText": "A minor, convenience adapter to avoid a rawtypes warning at the call site.", "author": "vvcephei", "createdAt": "2020-08-26T01:51:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorAdapter.java", "diffHunk": "@@ -31,6 +31,15 @@\n         }\n     }\n \n+    @SuppressWarnings({\"rawtypes\", \"unchecked\"})\n+    public static <KIn, VIn, KOut, VOut> Processor<KIn, VIn, KOut, VOut> adaptRaw(final org.apache.kafka.streams.processor.Processor delegate) {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2ODY1Mg==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476968652", "bodyText": "Converting to the new API. I didn't want to convert over the AbstractProcessor, since that would drag in more changes. I also didn't introduce a new abstract class, since the only thing it does is capture the context.", "author": "vvcephei", "createdAt": "2020-08-26T01:53:36Z", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -856,11 +857,18 @@ public void statelessTopologyShouldNotCreateStateDirectory() throws Exception {\n         final String outputTopic = safeTestName + \"-output\";\n         final Topology topology = new Topology();\n         topology.addSource(\"source\", Serdes.String().deserializer(), Serdes.String().deserializer(), inputTopic)\n-                .addProcessor(\"process\", () -> new AbstractProcessor<String, String>() {\n+                .addProcessor(\"process\", () -> new Processor<String, String, String, String>() {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2ODk2Nw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476968967", "bodyText": "Another example of how we don't need to cast anymore.", "author": "vvcephei", "createdAt": "2020-08-26T01:54:04Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsBuilderTest.java", "diffHunk": "@@ -102,7 +102,7 @@ public void shouldAddGlobalStore() {\n                 @SuppressWarnings(\"unchecked\")\n                 @Override\n                 public void init(final ProcessorContext<Void, Void> context) {\n-                    store = (KeyValueStore<String, String>) context.getStateStore(\"store\");\n+                    store = context.getStateStore(\"store\");", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2OTM3OA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476969378", "bodyText": "I've converted most of the tests to the new API, and just left behind a couple to make sure the delegation works properly.", "author": "vvcephei", "createdAt": "2020-08-26T01:54:39Z", "path": "streams/src/test/java/org/apache/kafka/streams/TopologyTest.java", "diffHunk": "@@ -87,12 +88,12 @@ public void shouldNotAllowZeroTopicsWhenAddingSource() {\n \n     @Test(expected = NullPointerException.class)\n     public void shouldNotAllowNullNameWhenAddingProcessor() {\n-        topology.addProcessor(null, () -> new MockProcessorSupplier<>().get());\n+        topology.addProcessor(null, () -> new MockApiProcessorSupplier<>().get());", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk2OTc1Mg==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476969752", "bodyText": "There are a few places where we have to cast null in order to resolve the right overload.", "author": "vvcephei", "createdAt": "2020-08-26T01:55:09Z", "path": "streams/src/test/java/org/apache/kafka/streams/TopologyTest.java", "diffHunk": "@@ -87,12 +88,12 @@ public void shouldNotAllowZeroTopicsWhenAddingSource() {\n \n     @Test(expected = NullPointerException.class)\n     public void shouldNotAllowNullNameWhenAddingProcessor() {\n-        topology.addProcessor(null, () -> new MockProcessorSupplier<>().get());\n+        topology.addProcessor(null, () -> new MockApiProcessorSupplier<>().get());\n     }\n \n     @Test(expected = NullPointerException.class)\n     public void shouldNotAllowNullProcessorSupplierWhenAddingProcessor() {\n-        topology.addProcessor(\"name\", null);\n+        topology.addProcessor(\"name\", (ProcessorSupplier<Object, Object, Object, Object>) null);", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk3MDgwOQ==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476970809", "bodyText": "Here's an example of a test I left in place to exercise the delegation mechanism (I renamed the \"old API\" version of the test).", "author": "vvcephei", "createdAt": "2020-08-26T01:56:37Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorTopologyTest.java", "diffHunk": "@@ -293,6 +293,37 @@ public void testDrivingConnectedStateStoreTopology() {\n         assertNull(store.get(\"key4\"));\n     }\n \n+    @Test\n+    public void testDrivingConnectedStateStoreInDifferentProcessorsTopologyWithOldAPI() {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk3MTQ5Nw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476971497", "bodyText": "Converted to the new API.", "author": "vvcephei", "createdAt": "2020-08-26T01:57:39Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorTopologyTest.java", "diffHunk": "@@ -735,58 +766,92 @@ private Topology createAddHeaderTopology() {\n     /**\n      * A processor that simply forwards all messages to all children.\n      */\n-    protected static class ForwardingProcessor extends AbstractProcessor<String, String> {\n+    protected static class ForwardingProcessor implements Processor<String, String, String, String> {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk3MjU4Nw==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476972587", "bodyText": "These are just convenience functions for defining ProcessorSuppliers (with and without stores attached). I've duplicated them for the old and new APIs.", "author": "vvcephei", "createdAt": "2020-08-26T01:59:17Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorTopologyTest.java", "diffHunk": "@@ -853,15 +918,56 @@ public void process(final String key, final String value) {\n         }\n     }\n \n-    private <K, V> ProcessorSupplier<K, V> define(final Processor<K, V> processor) {\n+    /**\n+     * A processor that stores each key-value pair in an in-memory key-value store registered with the context.\n+     */\n+    protected static class StatefulProcessor implements Processor<String, String, Void, Void> {\n+        private KeyValueStore<String, String> store;\n+        private final String storeName;\n+\n+        StatefulProcessor(final String storeName) {\n+            this.storeName = storeName;\n+        }\n+\n+        @Override\n+        public void init(final ProcessorContext<Void, Void> context) {\n+            store = context.getStateStore(storeName);\n+        }\n+\n+        @Override\n+        public void process(final String key, final String value) {\n+            store.put(key, value);\n+        }\n+    }\n+\n+    private <K, V> org.apache.kafka.streams.processor.ProcessorSupplier<K, V> define(final org.apache.kafka.streams.processor.Processor<K, V> processor) {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk3Mjk5Ng==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476972996", "bodyText": "Converted to the new API and cleaned up.", "author": "vvcephei", "createdAt": "2020-08-26T01:59:56Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -1196,33 +1195,25 @@ public void shouldReinitializeRevivedTasksInAnyState() {\n         internalTopologyBuilder.addSource(null, \"name\", null, null, null, topic1);\n         final AtomicBoolean shouldThrow = new AtomicBoolean(false);\n         final AtomicBoolean processed = new AtomicBoolean(false);\n-        internalTopologyBuilder.addProcessor(\"proc\", new ProcessorSupplier<Object, Object>() {\n-            @Override\n-            public Processor<Object, Object> get() {\n-                return new Processor<Object, Object>() {\n-                    private ProcessorContext context;\n-\n-                    @Override\n-                    public void init(final ProcessorContext context) {\n-                        this.context = context;\n-                    }\n+        internalTopologyBuilder.addProcessor(\n+            \"proc\",\n+            () -> new Processor<Object, Object, Object, Object>() {", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk3NTIyMg==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476975222", "bodyText": "Shockingly, the old test wasn't testing what it was supposed to test.\nIt's supposed to check and make sure the processor populates the global store, but it was actually just checking whether the mock captured the processed records. I changed the processor to actually do what it's supposed to, and then changed the assertion below to check what this test is really supposed to be checking.", "author": "vvcephei", "createdAt": "2020-08-26T02:03:14Z", "path": "streams/test-utils/src/test/java/org/apache/kafka/streams/TopologyTestDriverTest.java", "diffHunk": "@@ -390,7 +389,20 @@ private Topology setupGlobalStoreTopology(final String... sourceTopicNames) {\n                 null,\n                 sourceTopicName,\n                 sourceTopicName + \"-processor\",\n-                new MockProcessorSupplier()\n+                () -> new Processor<Object, Object, Void, Void>() {\n+                    KeyValueStore<Object, Object> store;\n+\n+                    @SuppressWarnings(\"unchecked\")\n+                    @Override\n+                    public void init(final ProcessorContext<Void, Void> context) {\n+                        store = context.getStateStore(sourceTopicName + \"-globalStore\");\n+                    }\n+\n+                    @Override\n+                    public void process(final Object key, final Object value) {\n+                        store.put(key, value);\n+                    }\n+                }", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk3NTUwNA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r476975504", "bodyText": "Just casting null to resolve the right overload.", "author": "vvcephei", "createdAt": "2020-08-26T02:03:37Z", "path": "streams/test-utils/src/test/java/org/apache/kafka/streams/TopologyTestDriverTest.java", "diffHunk": "@@ -996,7 +1003,7 @@ public void shouldPunctuateOnWallClockTime() {\n     @Test\n     public void shouldReturnAllStores() {\n         final Topology topology = setupSourceSinkTopology();\n-        topology.addProcessor(\"processor\", () -> null, \"source\");\n+        topology.addProcessor(\"processor\", (ProcessorSupplier<Object, Object, Object, Object>) () -> null, \"source\");", "originalCommit": "f77030c4b1ad8fabd1095b6e89b56590db6c53fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3b81208ebc9815179a6f764ee49bd30693109112", "url": "https://github.com/apache/kafka/commit/3b81208ebc9815179a6f764ee49bd30693109112", "message": "drop defaulted method", "committedDate": "2020-08-26T02:09:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTY5MTExMQ==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r485691111", "bodyText": "Could this cause a problem with lines 96-99 above? I could be missing something, but it looks like we could be attempting to add the same stores twice, which I think  will result in a runtime error building the topology.", "author": "bbejeck", "createdAt": "2020-09-09T15:12:22Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/graph/StatefulProcessorNode.java", "diffHunk": "@@ -99,5 +99,14 @@ public void writeToTopology(final InternalTopologyBuilder topologyBuilder) {\n             }\n         }\n \n+        // temporary hack until KIP-478 is fully implemented\n+        final org.apache.kafka.streams.processor.ProcessorSupplier<K, V> oldProcessorSupplier =\n+            processorParameters().oldProcessorSupplier();\n+        if (oldProcessorSupplier != null && oldProcessorSupplier.stores() != null) {\n+            for (final StoreBuilder<?> storeBuilder : oldProcessorSupplier.stores()) {\n+                topologyBuilder.addStateStore(storeBuilder, processorName);\n+            }\n+        }\n+", "originalCommit": "3b81208ebc9815179a6f764ee49bd30693109112", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc0Mjc2NQ==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r485742765", "bodyText": "It definitely looks that way, but I've just double-checked, and I think it's safe. The thing is that only a subclass of ProcessorSupplier (either the new or old one) could override the ConnectedStoreProvider#stores method. Unlike Processor and ProcessorContext, we haven't added adapters for ProcessorSupplier that could delegate the stores method from the new API to the old one, so only a proper direct instantiation of the new API ProcessorSupplier could return a non-null result from processorSupplier.stores() on L96. Likewise, oldProcessorSupplier is only non-null itself when the provided processor is only an old-api processorSupplier.\nSo, it seems like either L96-99 will add stores or L102-109 will (or neither), but never both. Does that reasoning seem legit to you?", "author": "vvcephei", "createdAt": "2020-09-09T16:18:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTY5MTExMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc1NDkzOA==", "url": "https://github.com/apache/kafka/pull/9221#discussion_r485754938", "bodyText": "That makes sense to me, thanks for the explanation.", "author": "bbejeck", "createdAt": "2020-09-09T16:32:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTY5MTExMQ=="}], "type": "inlineReview"}, {"oid": "c37687893a08e3bb056f99cc9927a5c679f80d5d", "url": "https://github.com/apache/kafka/commit/c37687893a08e3bb056f99cc9927a5c679f80d5d", "message": "Merge remote-tracking branch 'apache/trunk' into kip-478-part-3", "committedDate": "2020-09-09T17:18:08Z", "type": "commit"}]}