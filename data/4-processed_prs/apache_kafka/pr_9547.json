{"pr_number": 9547, "pr_title": "KAFKA-9630; Replace OffsetsForLeaderEpoch request/response with automated protocol", "pr_createdAt": "2020-11-03T08:45:39Z", "pr_url": "https://github.com/apache/kafka/pull/9547", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzIxMjAxMg==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r517212012", "bodyText": "Previous \"name\" is topic (https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/protocol/CommonFields.java#L25) and the \"name\" in auto-generated protocol is name. Does it break the compatibility? For example, a cluster mixed by auto-generated protocol and stale protocol.", "author": "chia7712", "createdAt": "2020-11-04T09:38:27Z", "path": "clients/src/main/resources/common/message/OffsetForLeaderEpochRequest.json", "diffHunk": "@@ -32,13 +32,13 @@\n     { \"name\": \"Topics\", \"type\": \"[]OffsetForLeaderTopic\", \"versions\": \"0+\",\n       \"about\": \"Each topic to get offsets for.\", \"fields\": [\n       { \"name\": \"Name\", \"type\": \"string\", \"versions\": \"0+\", \"entityType\": \"topicName\",", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA4MTMzMg==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r519081332", "bodyText": "Please ignore above comment. I misunderstood the protocol :(", "author": "chia7712", "createdAt": "2020-11-07T02:03:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzIxMjAxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NDY1OQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r525374659", "bodyText": "Wonder if it might be simpler to initialize partitionsToRetry from the request key set.", "author": "hachikuji", "createdAt": "2020-11-17T18:03:55Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/OffsetsForLeaderEpochClient.java", "diffHunk": "@@ -61,67 +77,76 @@ protected OffsetForEpochResult handleResponse(\n             Map<TopicPartition, SubscriptionState.FetchPosition> requestData,\n             OffsetsForLeaderEpochResponse response) {\n \n+        Set<TopicPartition> missingPartitions = new HashSet<>(requestData.keySet());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjIwNzEzNQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526207135", "bodyText": "The downside of relying on partitionsToRetry is that we can't differentiate the partitions to be retried due to an error from the missing partitions in the response. It may not be that important but we can't preserve the above log otherwise.\nlogger().warn(\"Missing partition {} from response, retrying.\", topicPartition);\n\nI suppose that this log entry is there for a reason so I went with preserving it. What do you think?", "author": "dajac", "createdAt": "2020-11-18T16:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NDY1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjI4MTM1Nw==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526281357", "bodyText": "No strong opinion. It's an unlikely case anyway, so I'm not sure it calls for special treatment.", "author": "hachikuji", "createdAt": "2020-11-18T17:34:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NDY1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM4MzEzOA==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526383138", "bodyText": "Yeah, you're right. Let me remove it.", "author": "dajac", "createdAt": "2020-11-18T20:02:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NDY1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTIyOQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r525379229", "bodyText": "We have similar logic in OffsetsForLeaderEpochClient.prepareRequest. Wonder if we should push it to the Builder?", "author": "hachikuji", "createdAt": "2020-11-17T18:10:53Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetsForLeaderEpochRequest.java", "diffHunk": "@@ -51,169 +47,120 @@\n      */\n     public static final int DEBUGGING_REPLICA_ID = -2;\n \n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"An array of topics to get epochs for\");\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"An array of partitions to get epochs for\");\n-\n-    private static final Field.Int32 LEADER_EPOCH = new Field.Int32(\"leader_epoch\",\n-            \"The epoch to lookup an offset for.\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            LEADER_EPOCH);\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 request is the same as v0. Per-partition leader epoch has been added to response\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V1 = OFFSET_FOR_LEADER_EPOCH_REQUEST_V0;\n-\n-    // V2 adds the current leader epoch to support fencing and the addition of the throttle time in the response\n-    private static final Field PARTITIONS_V2 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            CURRENT_LEADER_EPOCH,\n-            LEADER_EPOCH);\n-    private static final Field TOPICS_V2 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V2);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V2 = new Schema(\n-            TOPICS_V2);\n-\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V3 = new Schema(\n-            REPLICA_ID,\n-            TOPICS_V2);\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{OFFSET_FOR_LEADER_EPOCH_REQUEST_V0, OFFSET_FOR_LEADER_EPOCH_REQUEST_V1,\n-            OFFSET_FOR_LEADER_EPOCH_REQUEST_V2, OFFSET_FOR_LEADER_EPOCH_REQUEST_V3};\n-    }\n-\n-    private final Map<TopicPartition, PartitionData> epochsByPartition;\n-\n-    private final int replicaId;\n-\n-    public Map<TopicPartition, PartitionData> epochsByTopicPartition() {\n-        return epochsByPartition;\n-    }\n-\n-    public int replicaId() {\n-        return replicaId;\n-    }\n+    private final OffsetForLeaderEpochRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<OffsetsForLeaderEpochRequest> {\n-        private final Map<TopicPartition, PartitionData> epochsByPartition;\n-        private final int replicaId;\n+        private final OffsetForLeaderEpochRequestData data;\n \n-        Builder(short oldestAllowedVersion, short latestAllowedVersion, Map<TopicPartition, PartitionData> epochsByPartition, int replicaId) {\n+        Builder(short oldestAllowedVersion, short latestAllowedVersion, OffsetForLeaderEpochRequestData data) {\n             super(ApiKeys.OFFSET_FOR_LEADER_EPOCH, oldestAllowedVersion, latestAllowedVersion);\n-            this.epochsByPartition = epochsByPartition;\n-            this.replicaId = replicaId;\n+            this.data = data;\n         }\n \n-        public static Builder forConsumer(Map<TopicPartition, PartitionData> epochsByPartition) {\n+        public static Builder forConsumer(OffsetForLeaderTopicCollection epochsByPartition) {\n             // Old versions of this API require CLUSTER permission which is not typically granted\n             // to clients. Beginning with version 3, the broker requires only TOPIC Describe\n             // permission for the topic of each requested partition. In order to ensure client\n             // compatibility, we only send this request when we can guarantee the relaxed permissions.\n-            return new Builder((short) 3, ApiKeys.OFFSET_FOR_LEADER_EPOCH.latestVersion(),\n-                    epochsByPartition, CONSUMER_REPLICA_ID);\n+            OffsetForLeaderEpochRequestData data = new OffsetForLeaderEpochRequestData();\n+            data.setReplicaId(CONSUMER_REPLICA_ID);\n+            data.setTopics(epochsByPartition);\n+            return new Builder((short) 3, ApiKeys.OFFSET_FOR_LEADER_EPOCH.latestVersion(), data);\n         }\n \n         public static Builder forFollower(short version, Map<TopicPartition, PartitionData> epochsByPartition, int replicaId) {\n-            return new Builder(version, version, epochsByPartition, replicaId);\n+            OffsetForLeaderEpochRequestData data = new OffsetForLeaderEpochRequestData();\n+            data.setReplicaId(replicaId);\n+\n+            epochsByPartition.forEach((partitionKey, partitionValue) -> {\n+                OffsetForLeaderTopic topic = data.topics().find(partitionKey.topic());\n+                if (topic == null) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjIwNDE3OQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526204179", "bodyText": "That's a good question. Actually, I was hoping to push this one out of the builder while removing PartitionData in profit of using the internal data structure of the auto-generated protocol. I'd like to do this in a follow-up PR.", "author": "dajac", "createdAt": "2020-11-18T16:00:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTIyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjI4NzEyOQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526287129", "bodyText": "Sounds fine. Do you have a jira?", "author": "hachikuji", "createdAt": "2020-11-18T17:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTIyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM3Nzc1Mw==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526377753", "bodyText": "https://issues.apache.org/jira/browse/KAFKA-10740\nhttps://issues.apache.org/jira/browse/KAFKA-10739", "author": "dajac", "createdAt": "2020-11-18T19:53:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTIyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwMTEyMQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526301121", "bodyText": "not sure why this kind of method still exist in each request. It is not used anymore.", "author": "chia7712", "createdAt": "2020-11-18T17:52:52Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetsForLeaderEpochRequest.java", "diffHunk": "@@ -51,169 +47,120 @@\n      */\n     public static final int DEBUGGING_REPLICA_ID = -2;\n \n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"An array of topics to get epochs for\");\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"An array of partitions to get epochs for\");\n-\n-    private static final Field.Int32 LEADER_EPOCH = new Field.Int32(\"leader_epoch\",\n-            \"The epoch to lookup an offset for.\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            LEADER_EPOCH);\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 request is the same as v0. Per-partition leader epoch has been added to response\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V1 = OFFSET_FOR_LEADER_EPOCH_REQUEST_V0;\n-\n-    // V2 adds the current leader epoch to support fencing and the addition of the throttle time in the response\n-    private static final Field PARTITIONS_V2 = PARTITIONS.withFields(\n-            PARTITION_ID,\n-            CURRENT_LEADER_EPOCH,\n-            LEADER_EPOCH);\n-    private static final Field TOPICS_V2 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V2);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V2 = new Schema(\n-            TOPICS_V2);\n-\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_REQUEST_V3 = new Schema(\n-            REPLICA_ID,\n-            TOPICS_V2);\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{OFFSET_FOR_LEADER_EPOCH_REQUEST_V0, OFFSET_FOR_LEADER_EPOCH_REQUEST_V1,\n-            OFFSET_FOR_LEADER_EPOCH_REQUEST_V2, OFFSET_FOR_LEADER_EPOCH_REQUEST_V3};\n-    }\n-\n-    private final Map<TopicPartition, PartitionData> epochsByPartition;\n-\n-    private final int replicaId;\n-\n-    public Map<TopicPartition, PartitionData> epochsByTopicPartition() {\n-        return epochsByPartition;\n-    }\n-\n-    public int replicaId() {\n-        return replicaId;\n-    }\n+    private final OffsetForLeaderEpochRequestData data;\n \n     public static class Builder extends AbstractRequest.Builder<OffsetsForLeaderEpochRequest> {\n-        private final Map<TopicPartition, PartitionData> epochsByPartition;\n-        private final int replicaId;\n+        private final OffsetForLeaderEpochRequestData data;\n \n-        Builder(short oldestAllowedVersion, short latestAllowedVersion, Map<TopicPartition, PartitionData> epochsByPartition, int replicaId) {\n+        Builder(short oldestAllowedVersion, short latestAllowedVersion, OffsetForLeaderEpochRequestData data) {\n             super(ApiKeys.OFFSET_FOR_LEADER_EPOCH, oldestAllowedVersion, latestAllowedVersion);\n-            this.epochsByPartition = epochsByPartition;\n-            this.replicaId = replicaId;\n+            this.data = data;\n         }\n \n-        public static Builder forConsumer(Map<TopicPartition, PartitionData> epochsByPartition) {\n+        public static Builder forConsumer(OffsetForLeaderTopicCollection epochsByPartition) {\n             // Old versions of this API require CLUSTER permission which is not typically granted\n             // to clients. Beginning with version 3, the broker requires only TOPIC Describe\n             // permission for the topic of each requested partition. In order to ensure client\n             // compatibility, we only send this request when we can guarantee the relaxed permissions.\n-            return new Builder((short) 3, ApiKeys.OFFSET_FOR_LEADER_EPOCH.latestVersion(),\n-                    epochsByPartition, CONSUMER_REPLICA_ID);\n+            OffsetForLeaderEpochRequestData data = new OffsetForLeaderEpochRequestData();\n+            data.setReplicaId(CONSUMER_REPLICA_ID);\n+            data.setTopics(epochsByPartition);\n+            return new Builder((short) 3, ApiKeys.OFFSET_FOR_LEADER_EPOCH.latestVersion(), data);\n         }\n \n         public static Builder forFollower(short version, Map<TopicPartition, PartitionData> epochsByPartition, int replicaId) {\n-            return new Builder(version, version, epochsByPartition, replicaId);\n+            OffsetForLeaderEpochRequestData data = new OffsetForLeaderEpochRequestData();\n+            data.setReplicaId(replicaId);\n+\n+            epochsByPartition.forEach((partitionKey, partitionValue) -> {\n+                OffsetForLeaderTopic topic = data.topics().find(partitionKey.topic());\n+                if (topic == null) {\n+                    topic = new OffsetForLeaderTopic().setTopic(partitionKey.topic());\n+                    data.topics().add(topic);\n+                }\n+                topic.partitions().add(new OffsetForLeaderPartition()\n+                    .setPartition(partitionKey.partition())\n+                    .setLeaderEpoch(partitionValue.leaderEpoch)\n+                    .setCurrentLeaderEpoch(partitionValue.currentLeaderEpoch\n+                        .orElse(RecordBatch.NO_PARTITION_LEADER_EPOCH))\n+                );\n+            });\n+            return new Builder(version, version, data);\n         }\n \n         @Override\n         public OffsetsForLeaderEpochRequest build(short version) {\n             if (version < oldestAllowedVersion() || version > latestAllowedVersion())\n                 throw new UnsupportedVersionException(\"Cannot build \" + this + \" with version \" + version);\n-            return new OffsetsForLeaderEpochRequest(epochsByPartition, replicaId, version);\n-        }\n \n-        public static OffsetsForLeaderEpochRequest parse(ByteBuffer buffer, short version) {\n-            return new OffsetsForLeaderEpochRequest(ApiKeys.OFFSET_FOR_LEADER_EPOCH.parseRequest(version, buffer), version);\n+            return new OffsetsForLeaderEpochRequest(data, version);\n         }\n \n         @Override\n         public String toString() {\n-            StringBuilder bld = new StringBuilder();\n-            bld.append(\"OffsetsForLeaderEpochRequest(\").\n-                    append(\"epochsByPartition=\").append(epochsByPartition).\n-                    append(\")\");\n-            return bld.toString();\n+            return data.toString();\n         }\n     }\n \n-    public OffsetsForLeaderEpochRequest(Map<TopicPartition, PartitionData> epochsByPartition, int replicaId, short version) {\n+    public OffsetsForLeaderEpochRequest(OffsetForLeaderEpochRequestData data, short version) {\n         super(ApiKeys.OFFSET_FOR_LEADER_EPOCH, version);\n-        this.epochsByPartition = epochsByPartition;\n-        this.replicaId = replicaId;\n+        this.data = data;\n     }\n \n     public OffsetsForLeaderEpochRequest(Struct struct, short version) {\n         super(ApiKeys.OFFSET_FOR_LEADER_EPOCH, version);\n-        replicaId = struct.getOrElse(REPLICA_ID, DEBUGGING_REPLICA_ID);\n-        epochsByPartition = new HashMap<>();\n-        for (Object topicAndEpochsObj : struct.get(TOPICS)) {\n-            Struct topicAndEpochs = (Struct) topicAndEpochsObj;\n-            String topic = topicAndEpochs.get(TOPIC_NAME);\n-            for (Object partitionAndEpochObj : topicAndEpochs.get(PARTITIONS)) {\n-                Struct partitionAndEpoch = (Struct) partitionAndEpochObj;\n-                int partitionId = partitionAndEpoch.get(PARTITION_ID);\n-                int leaderEpoch = partitionAndEpoch.get(LEADER_EPOCH);\n-                Optional<Integer> currentEpoch = RequestUtils.getLeaderEpoch(partitionAndEpoch, CURRENT_LEADER_EPOCH);\n-                TopicPartition tp = new TopicPartition(topic, partitionId);\n-                epochsByPartition.put(tp, new PartitionData(currentEpoch, leaderEpoch));\n-            }\n-        }\n+        this.data = new OffsetForLeaderEpochRequestData(struct, version);\n     }\n \n-    public static OffsetsForLeaderEpochRequest parse(ByteBuffer buffer, short versionId) {\n-        return new OffsetsForLeaderEpochRequest(ApiKeys.OFFSET_FOR_LEADER_EPOCH.parseRequest(versionId, buffer), versionId);\n+    public OffsetForLeaderEpochRequestData data() {\n+        return data;\n+    }\n+\n+    public Map<TopicPartition, PartitionData> epochsByTopicPartition() {\n+        Map<TopicPartition, PartitionData> epochsByTopicPartition = new HashMap<>();\n+\n+        data.topics().forEach(topic ->\n+            topic.partitions().forEach(partition ->\n+                epochsByTopicPartition.put(\n+                    new TopicPartition(topic.topic(), partition.partition()),\n+                    new PartitionData(\n+                        RequestUtils.getLeaderEpoch(partition.currentLeaderEpoch()),\n+                        partition.leaderEpoch()))));\n+\n+        return epochsByTopicPartition;\n+    }\n+\n+    public int replicaId() {\n+        return data.replicaId();\n+    }\n+\n+    public static OffsetsForLeaderEpochRequest parse(ByteBuffer buffer, short version) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM3MzEyMQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526373121", "bodyText": "Good question. As we have kept them in other requests/responses, I will keep it for now. We should consider removing all of them.", "author": "dajac", "createdAt": "2020-11-18T19:45:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwMTEyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwOTI4NQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526509285", "bodyText": "I think these are still used in RequestResponseTest. There's probably a lot of cruft like this that we can start cleaning up though.", "author": "hachikuji", "createdAt": "2020-11-19T00:19:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwMTEyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwNjU4NQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526306585", "bodyText": "Is it worth using data rather than responses() to avoid extra conversion?", "author": "chia7712", "createdAt": "2020-11-18T17:59:02Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetsForLeaderEpochResponse.java", "diffHunk": "@@ -51,133 +41,82 @@\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n public class OffsetsForLeaderEpochResponse extends AbstractResponse {\n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"An array of topics for which we have leader offsets for some requested partition leader epoch\");\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"An array of offsets by partition\");\n-    private static final Field.Int64 END_OFFSET = new Field.Int64(\"end_offset\", \"The end offset\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            ERROR_CODE,\n-            PARTITION_ID,\n-            END_OFFSET);\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 added a per-partition leader epoch field which specifies which leader epoch the end offset belongs to\n-    private static final Field PARTITIONS_V1 = PARTITIONS.withFields(\n-            ERROR_CODE,\n-            PARTITION_ID,\n-            LEADER_EPOCH,\n-            END_OFFSET);\n-    private static final Field TOPICS_V1 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V1);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V1 = new Schema(\n-            TOPICS_V1);\n-\n-    // V2 bumped for addition of current leader epoch to the request schema and the addition of the throttle\n-    // time in the response\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2 = new Schema(\n-            THROTTLE_TIME_MS,\n-            TOPICS_V1);\n-\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V3 = OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2;\n-\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{OFFSET_FOR_LEADER_EPOCH_RESPONSE_V0, OFFSET_FOR_LEADER_EPOCH_RESPONSE_V1,\n-            OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2, OFFSET_FOR_LEADER_EPOCH_RESPONSE_V3};\n+\n+    private final OffsetForLeaderEpochResponseData data;\n+\n+    public OffsetsForLeaderEpochResponse(OffsetForLeaderEpochResponseData data) {\n+        this.data = data;\n     }\n \n-    private final int throttleTimeMs;\n-    private final Map<TopicPartition, EpochEndOffset> epochEndOffsetsByPartition;\n-\n-    public OffsetsForLeaderEpochResponse(Struct struct) {\n-        this.throttleTimeMs = struct.getOrElse(THROTTLE_TIME_MS, DEFAULT_THROTTLE_TIME);\n-        this.epochEndOffsetsByPartition = new HashMap<>();\n-        for (Object topicAndEpocsObj : struct.get(TOPICS)) {\n-            Struct topicAndEpochs = (Struct) topicAndEpocsObj;\n-            String topic = topicAndEpochs.get(TOPIC_NAME);\n-            for (Object partitionAndEpochObj : topicAndEpochs.get(PARTITIONS)) {\n-                Struct partitionAndEpoch = (Struct) partitionAndEpochObj;\n-                Errors error = Errors.forCode(partitionAndEpoch.get(ERROR_CODE));\n-                int partitionId = partitionAndEpoch.get(PARTITION_ID);\n-                TopicPartition tp = new TopicPartition(topic, partitionId);\n-                int leaderEpoch = partitionAndEpoch.getOrElse(LEADER_EPOCH, RecordBatch.NO_PARTITION_LEADER_EPOCH);\n-                long endOffset = partitionAndEpoch.get(END_OFFSET);\n-                epochEndOffsetsByPartition.put(tp, new EpochEndOffset(error, leaderEpoch, endOffset));\n-            }\n-        }\n+    public OffsetsForLeaderEpochResponse(Struct struct, short version) {\n+        data = new OffsetForLeaderEpochResponseData(struct, version);\n+    }\n+\n+    public OffsetsForLeaderEpochResponse(Map<TopicPartition, EpochEndOffset> offsets) {\n+        this(0, offsets);\n     }\n \n-    public OffsetsForLeaderEpochResponse(Map<TopicPartition, EpochEndOffset> epochsByTopic) {\n-        this(DEFAULT_THROTTLE_TIME, epochsByTopic);\n+    public OffsetsForLeaderEpochResponse(int throttleTimeMs, Map<TopicPartition, EpochEndOffset> offsets) {\n+        data = new OffsetForLeaderEpochResponseData();\n+        data.setThrottleTimeMs(throttleTimeMs);\n+\n+        offsets.forEach((tp, offset) -> {\n+            OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+            if (topic == null) {\n+                topic = new OffsetForLeaderTopicResult().setTopic(tp.topic());\n+                data.topics().add(topic);\n+            }\n+            topic.partitions().add(new OffsetForLeaderPartitionResult()\n+                .setPartition(tp.partition())\n+                .setErrorCode(offset.error().code())\n+                .setLeaderEpoch(offset.leaderEpoch())\n+                .setEndOffset(offset.endOffset()));\n+        });\n     }\n \n-    public OffsetsForLeaderEpochResponse(int throttleTimeMs, Map<TopicPartition, EpochEndOffset> epochsByTopic) {\n-        this.throttleTimeMs = throttleTimeMs;\n-        this.epochEndOffsetsByPartition = epochsByTopic;\n+    public OffsetForLeaderEpochResponseData data() {\n+        return data;\n     }\n \n     public Map<TopicPartition, EpochEndOffset> responses() {\n+        Map<TopicPartition, EpochEndOffset> epochEndOffsetsByPartition = new HashMap<>();\n+\n+        data.topics().forEach(topic ->\n+            topic.partitions().forEach(partition ->\n+                epochEndOffsetsByPartition.put(\n+                    new TopicPartition(topic.topic(), partition.partition()),\n+                    new EpochEndOffset(\n+                        Errors.forCode(partition.errorCode()),\n+                        partition.leaderEpoch(),\n+                        partition.endOffset()))));\n+\n         return epochEndOffsetsByPartition;\n     }\n \n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n-        epochEndOffsetsByPartition.values().forEach(response ->\n+        responses().values().forEach(response ->", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwNzI1OQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526307259", "bodyText": "I hope we can get rid of those conversion in the future :)", "author": "chia7712", "createdAt": "2020-11-18T18:00:00Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/OffsetsForLeaderEpochResponse.java", "diffHunk": "@@ -51,133 +41,82 @@\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n public class OffsetsForLeaderEpochResponse extends AbstractResponse {\n-    private static final Field.ComplexArray TOPICS = new Field.ComplexArray(\"topics\",\n-            \"An array of topics for which we have leader offsets for some requested partition leader epoch\");\n-    private static final Field.ComplexArray PARTITIONS = new Field.ComplexArray(\"partitions\",\n-            \"An array of offsets by partition\");\n-    private static final Field.Int64 END_OFFSET = new Field.Int64(\"end_offset\", \"The end offset\");\n-\n-    private static final Field PARTITIONS_V0 = PARTITIONS.withFields(\n-            ERROR_CODE,\n-            PARTITION_ID,\n-            END_OFFSET);\n-    private static final Field TOPICS_V0 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V0);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V0 = new Schema(\n-            TOPICS_V0);\n-\n-    // V1 added a per-partition leader epoch field which specifies which leader epoch the end offset belongs to\n-    private static final Field PARTITIONS_V1 = PARTITIONS.withFields(\n-            ERROR_CODE,\n-            PARTITION_ID,\n-            LEADER_EPOCH,\n-            END_OFFSET);\n-    private static final Field TOPICS_V1 = TOPICS.withFields(\n-            TOPIC_NAME,\n-            PARTITIONS_V1);\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V1 = new Schema(\n-            TOPICS_V1);\n-\n-    // V2 bumped for addition of current leader epoch to the request schema and the addition of the throttle\n-    // time in the response\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2 = new Schema(\n-            THROTTLE_TIME_MS,\n-            TOPICS_V1);\n-\n-    private static final Schema OFFSET_FOR_LEADER_EPOCH_RESPONSE_V3 = OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2;\n-\n-\n-    public static Schema[] schemaVersions() {\n-        return new Schema[]{OFFSET_FOR_LEADER_EPOCH_RESPONSE_V0, OFFSET_FOR_LEADER_EPOCH_RESPONSE_V1,\n-            OFFSET_FOR_LEADER_EPOCH_RESPONSE_V2, OFFSET_FOR_LEADER_EPOCH_RESPONSE_V3};\n+\n+    private final OffsetForLeaderEpochResponseData data;\n+\n+    public OffsetsForLeaderEpochResponse(OffsetForLeaderEpochResponseData data) {\n+        this.data = data;\n     }\n \n-    private final int throttleTimeMs;\n-    private final Map<TopicPartition, EpochEndOffset> epochEndOffsetsByPartition;\n-\n-    public OffsetsForLeaderEpochResponse(Struct struct) {\n-        this.throttleTimeMs = struct.getOrElse(THROTTLE_TIME_MS, DEFAULT_THROTTLE_TIME);\n-        this.epochEndOffsetsByPartition = new HashMap<>();\n-        for (Object topicAndEpocsObj : struct.get(TOPICS)) {\n-            Struct topicAndEpochs = (Struct) topicAndEpocsObj;\n-            String topic = topicAndEpochs.get(TOPIC_NAME);\n-            for (Object partitionAndEpochObj : topicAndEpochs.get(PARTITIONS)) {\n-                Struct partitionAndEpoch = (Struct) partitionAndEpochObj;\n-                Errors error = Errors.forCode(partitionAndEpoch.get(ERROR_CODE));\n-                int partitionId = partitionAndEpoch.get(PARTITION_ID);\n-                TopicPartition tp = new TopicPartition(topic, partitionId);\n-                int leaderEpoch = partitionAndEpoch.getOrElse(LEADER_EPOCH, RecordBatch.NO_PARTITION_LEADER_EPOCH);\n-                long endOffset = partitionAndEpoch.get(END_OFFSET);\n-                epochEndOffsetsByPartition.put(tp, new EpochEndOffset(error, leaderEpoch, endOffset));\n-            }\n-        }\n+    public OffsetsForLeaderEpochResponse(Struct struct, short version) {\n+        data = new OffsetForLeaderEpochResponseData(struct, version);\n+    }\n+\n+    public OffsetsForLeaderEpochResponse(Map<TopicPartition, EpochEndOffset> offsets) {\n+        this(0, offsets);\n     }\n \n-    public OffsetsForLeaderEpochResponse(Map<TopicPartition, EpochEndOffset> epochsByTopic) {\n-        this(DEFAULT_THROTTLE_TIME, epochsByTopic);\n+    public OffsetsForLeaderEpochResponse(int throttleTimeMs, Map<TopicPartition, EpochEndOffset> offsets) {\n+        data = new OffsetForLeaderEpochResponseData();\n+        data.setThrottleTimeMs(throttleTimeMs);\n+\n+        offsets.forEach((tp, offset) -> {\n+            OffsetForLeaderTopicResult topic = data.topics().find(tp.topic());\n+            if (topic == null) {\n+                topic = new OffsetForLeaderTopicResult().setTopic(tp.topic());\n+                data.topics().add(topic);\n+            }\n+            topic.partitions().add(new OffsetForLeaderPartitionResult()\n+                .setPartition(tp.partition())\n+                .setErrorCode(offset.error().code())\n+                .setLeaderEpoch(offset.leaderEpoch())\n+                .setEndOffset(offset.endOffset()));\n+        });\n     }\n \n-    public OffsetsForLeaderEpochResponse(int throttleTimeMs, Map<TopicPartition, EpochEndOffset> epochsByTopic) {\n-        this.throttleTimeMs = throttleTimeMs;\n-        this.epochEndOffsetsByPartition = epochsByTopic;\n+    public OffsetForLeaderEpochResponseData data() {\n+        return data;\n     }\n \n     public Map<TopicPartition, EpochEndOffset> responses() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM3MzQ0NQ==", "url": "https://github.com/apache/kafka/pull/9547#discussion_r526373445", "bodyText": "I will address this in a follow-up PR.", "author": "dajac", "createdAt": "2020-11-18T19:46:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMwNzI1OQ=="}], "type": "inlineReview"}, {"oid": "7a5d8c5440222955abe825c06b1e1fb380c22e6c", "url": "https://github.com/apache/kafka/commit/7a5d8c5440222955abe825c06b1e1fb380c22e6c", "message": "1 to 1 migration to auto generated protocol.", "committedDate": "2020-11-19T07:52:45Z", "type": "commit"}, {"oid": "6cbe529a89e4b3d0c19f2b60c00b9f81ac0a9dff", "url": "https://github.com/apache/kafka/commit/6cbe529a89e4b3d0c19f2b60c00b9f81ac0a9dff", "message": "Move `OffsetsForLeaderEpochRequest.Builder.forConsumer`", "committedDate": "2020-11-19T07:59:03Z", "type": "commit"}, {"oid": "c47fad6802a2547e33902fc699fe8485ded58644", "url": "https://github.com/apache/kafka/commit/c47fad6802a2547e33902fc699fe8485ded58644", "message": "refactor", "committedDate": "2020-11-19T07:59:03Z", "type": "commit"}, {"oid": "1ab26b1bc4361b6506cb83e2f1b4a543f09a9d23", "url": "https://github.com/apache/kafka/commit/1ab26b1bc4361b6506cb83e2f1b4a543f09a9d23", "message": "Migrate OffsetsForLeaderEpochClient to use OffsetForLeaderEpochResponseData directly.", "committedDate": "2020-11-19T07:59:03Z", "type": "commit"}, {"oid": "fc1bc36ad39e58719b858a7073b20ae34bcdbefe", "url": "https://github.com/apache/kafka/commit/fc1bc36ad39e58719b858a7073b20ae34bcdbefe", "message": "fixup", "committedDate": "2020-11-19T07:59:04Z", "type": "commit"}, {"oid": "29dc946e78427a910f366f87409d8b5a6c72a7dd", "url": "https://github.com/apache/kafka/commit/29dc946e78427a910f366f87409d8b5a6c72a7dd", "message": "Use OffsetForLeaderPartitionResult in OffsetsForLeaderEpochClient instead of EpochEndOffset.", "committedDate": "2020-11-19T07:59:04Z", "type": "commit"}, {"oid": "d77bf9987dd2d94488b3f4b5cc4e5dee952c5792", "url": "https://github.com/apache/kafka/commit/d77bf9987dd2d94488b3f4b5cc4e5dee952c5792", "message": "Rename fields", "committedDate": "2020-11-19T07:59:04Z", "type": "commit"}, {"oid": "554a686ba45676295a8d8a5f5b61a5d1c9ea4e1c", "url": "https://github.com/apache/kafka/commit/554a686ba45676295a8d8a5f5b61a5d1c9ea4e1c", "message": "fixup", "committedDate": "2020-11-19T07:59:04Z", "type": "commit"}, {"oid": "a15d435b47cf74dcfd465a9a2813b216dcfbe512", "url": "https://github.com/apache/kafka/commit/a15d435b47cf74dcfd465a9a2813b216dcfbe512", "message": "address reviews", "committedDate": "2020-11-19T07:59:04Z", "type": "commit"}, {"oid": "a15d435b47cf74dcfd465a9a2813b216dcfbe512", "url": "https://github.com/apache/kafka/commit/a15d435b47cf74dcfd465a9a2813b216dcfbe512", "message": "address reviews", "committedDate": "2020-11-19T07:59:04Z", "type": "forcePushed"}]}