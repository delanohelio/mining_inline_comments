{"pr_number": 9769, "pr_title": "KAFKA-10774; Support Describe topic using topic IDs", "pr_createdAt": "2020-12-19T10:42:50Z", "pr_url": "https://github.com/apache/kafka/pull/9769", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjI5MjUxMw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r546292513", "bodyText": "nit: typo \"dose\" -> \"does\" I also had a slightly different message in my PR that implements this error. Either one is fine. https://github.com/apache/kafka/pull/9684/files", "author": "jolshan", "createdAt": "2020-12-19T22:44:38Z", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Errors.java", "diffHunk": "@@ -343,7 +344,8 @@\n     INVALID_UPDATE_VERSION(95, \"The given update version was invalid.\", InvalidUpdateVersionException::new),\n     FEATURE_UPDATE_FAILED(96, \"Unable to update finalized features due to an unexpected server error.\", FeatureUpdateFailedException::new),\n     PRINCIPAL_DESERIALIZATION_FAILURE(97, \"Request principal deserialization failed during forwarding. \" +\n-         \"This indicates an internal error on the broker cluster security setup.\", PrincipalDeserializationException::new);\n+         \"This indicates an internal error on the broker cluster security setup.\", PrincipalDeserializationException::new),\n+    UNKNOWN_TOPIC_ID(98, \"The topic ID dose not exist\", UnknownTopicIdException::new);", "originalCommit": "e4c8a228182a54d07f9e3b6bd91cabf89b688b23", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjMwOTczOA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r546309738", "bodyText": "Thank you, I think your message may be more appropriate.", "author": "dengziming", "createdAt": "2020-12-20T02:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjI5MjUxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDA5MQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r546860091", "bodyText": "I think this parameterization is a pretty good idea, and I can add it to my delete topics PR. But if we are going to change the public API, we should update the KIP and potentially update the mailing list with the changes.", "author": "jolshan", "createdAt": "2020-12-21T18:24:28Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -31,29 +31,29 @@\n  * The API of this class is evolving, see {@link Admin} for details.\n  */\n @InterfaceStability.Evolving\n-public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+public class DescribeTopicsResult<T> {", "originalCommit": "6018b4b98bccad2d8507936e2f6af8441e5121c9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MTk5Nw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r546861997", "bodyText": "I'm also curious what implications there are for changing the original DescribeTopicsResult when using old clients.", "author": "jolshan", "createdAt": "2020-12-21T18:28:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDA5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzAyMTQ2Mg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r547021462", "bodyText": "I first tried a new class DescribeTopicsResultWithIds and find it's almost the same as DescribeTopicsResult, so I just use parameterization. We only need to change DescribeTopicsResult to DescribeTopicsResult<String> when using old clients.", "author": "dengziming", "createdAt": "2020-12-22T01:49:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDA5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTcyNTI2OQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555725269", "bodyText": "We need to keep the Admin API backwards compatible. An application that was written using the 2.7.0 should not break if it is compiled with a 2.8.0 clients jar. You can always add an internal class with shared code to avoid duplication, but the public API itself needs to remain compatible.", "author": "rajinisivaram", "createdAt": "2021-01-12T12:12:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDA5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE3NTgxNg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r556175816", "bodyText": "Thank you for your reminder, I have rollbacked all the public API change.", "author": "dengziming", "createdAt": "2021-01-13T00:02:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MDA5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MjcwMA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r546862700", "bodyText": "nit: javadoc comment missing", "author": "jolshan", "createdAt": "2020-12-21T18:30:00Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -287,7 +288,23 @@ default DescribeTopicsResult describeTopics(Collection<String> topicNames) {\n      * @param options    The options to use when describing the topic.\n      * @return The DescribeTopicsResult.\n      */\n-    DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options);\n+    DescribeTopicsResult<String> describeTopics(Collection<String> topicNames, DescribeTopicsOptions options);\n+\n+    /**\n+     * Describe some topics in the cluster by their topicId, with the default options.\n+     * <p>\n+     * This is a convenience method for {@link #describeTopicsWithIds(Collection, DescribeTopicsOptions)} with\n+     * default options. See the overload for more details.\n+     *\n+     * @param topicIds The topicIds of the topics to describe.\n+     * @return The DescribeTopicsResult.\n+     */\n+    default DescribeTopicsResult<Uuid> describeTopicsWithIds(Collection<Uuid> topicIds) {\n+        return describeTopicsWithIds(topicIds, new DescribeTopicsOptions());\n+    }\n+\n+    DescribeTopicsResult<Uuid> describeTopicsWithIds(Collection<Uuid> topicIds, DescribeTopicsOptions options);", "originalCommit": "6018b4b98bccad2d8507936e2f6af8441e5121c9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "url": "https://github.com/apache/kafka/commit/73a8ea197c261f7ef44d777665d0bc879e4e595e", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\n\nresolve edge conditions\n\nresolve edge conditions", "committedDate": "2021-01-02T01:22:47Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYwNzA2MQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r551607061", "bodyText": "Hey, with the new addition of gating topic IDs behind IBP 2.8, can we do a check of the interbroker protocol version in this method and if it is not at least 2.8, return with UNSUPPORTED_VERSION error. There is a method in the 2.8 PR to easily get this information: KafkaConfig.usesTopicId\nHere's the other PR for reference: #9814\nHere's the KIP with the updated error behavior: https://cwiki.apache.org/confluence/display/KAFKA/KIP-516%3A+Topic+Identifiers#KIP516:TopicIdentifiers-AdminandKafkaAdminClient\nI will update the delete topics logic to follow this behavior as well.", "author": "jolshan", "createdAt": "2021-01-04T22:28:50Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1238,8 +1239,21 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)", "originalCommit": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgxMDU4Nw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555810587", "bodyText": "OK, I will add these check after 9814 merged.", "author": "dengziming", "createdAt": "2021-01-12T14:27:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTYwNzA2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTczMDc1NQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555730755", "bodyText": "We seemed to have removed a constructor?", "author": "rajinisivaram", "createdAt": "2021-01-12T12:21:47Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java", "diffHunk": "@@ -62,25 +62,25 @@ public int hashCode() {\n      *                   leadership and replica information for that partition.\n      */\n     public TopicDescription(String name, boolean internal, List<TopicPartitionInfo> partitions) {\n-        this(name, internal, partitions, Collections.emptySet());\n+        this(name, Uuid.ZERO_UUID, internal, partitions);\n+    }\n+\n+    public TopicDescription(String name, Uuid topicId, boolean internal, List<TopicPartitionInfo> partitions) {\n+        this(name, topicId, internal, partitions, Collections.emptySet());\n     }\n \n     /**\n      * Create an instance with the specified parameters.\n      *\n      * @param name The topic name\n+     * @param topicId the topic id\n      * @param internal Whether the topic is internal to Kafka\n      * @param partitions A list of partitions where the index represents the partition id and the element contains\n      *                   leadership and replica information for that partition.\n      * @param authorizedOperations authorized operations for this topic, or null if this is not known.\n      */\n-    public TopicDescription(String name, boolean internal, List<TopicPartitionInfo> partitions,\n+    public TopicDescription(String name, Uuid topicId, boolean internal, List<TopicPartitionInfo> partitions,", "originalCommit": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE3NjM3Mw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r556176373", "bodyText": "This is also my mistake, I tried to add a constructor but remove one, I have rollbacked the removing.", "author": "dengziming", "createdAt": "2021-01-13T00:03:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTczMDc1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTczODUwOA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555738508", "bodyText": "Couldn't unsupported version mean that topic ids are not supported (rather than disablingTopicCreation)? In any case, you can't create topics with topic ids right?", "author": "rajinisivaram", "createdAt": "2021-01-12T12:36:03Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -1816,7 +1823,103 @@ void handleFailure(Throwable throwable) {\n         if (!topicNamesList.isEmpty()) {\n             runnable.call(call, now);\n         }\n-        return new DescribeTopicsResult(new HashMap<>(topicFutures));\n+        return new DescribeTopicsResult<>(new HashMap<>(topicFutures));\n+    }\n+\n+    @Override\n+    public DescribeTopicsResult<Uuid> describeTopicsWithIds(Collection<Uuid> topicIds, DescribeTopicsOptions options) {\n+\n+        final Map<Uuid, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicIds.size());\n+        final List<Uuid> topicIdsList = new ArrayList<>();\n+        for (Uuid topicId : topicIds) {\n+            if (topicIdIsUnrepresentable(topicId)) {\n+                KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n+                future.completeExceptionally(new InvalidTopicException(\"The given topic id '\" +\n+                        topicId + \"' cannot be represented in a request.\"));\n+                topicFutures.put(topicId, future);\n+            } else if (!topicFutures.containsKey(topicId)) {\n+                topicFutures.put(topicId, new KafkaFutureImpl<>());\n+                topicIdsList.add(topicId);\n+            }\n+        }\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeTopicsWithIds\", calcDeadlineMs(now, options.timeoutMs()),\n+                new LeastLoadedNodeProvider()) {\n+\n+            private boolean supportsDisablingTopicCreation = true;\n+\n+            @Override\n+            MetadataRequest.Builder createRequest(int timeoutMs) {\n+                if (supportsDisablingTopicCreation)\n+                    return new MetadataRequest.Builder(new MetadataRequestData()\n+                            .setTopics(convertTopicIdsToMetadataRequestTopic(topicIdsList))\n+                            .setAllowAutoTopicCreation(false)\n+                            .setIncludeTopicAuthorizedOperations(options.includeAuthorizedOperations()));\n+                else\n+                    return MetadataRequest.Builder.allTopics();\n+            }\n+\n+            @Override\n+            void handleResponse(AbstractResponse abstractResponse) {\n+                MetadataResponse response = (MetadataResponse) abstractResponse;\n+                // Handle server responses for particular topics.\n+                Cluster cluster = response.cluster();\n+                Map<String, Errors> errors = response.errors();\n+                for (Map.Entry<Uuid, KafkaFutureImpl<TopicDescription>> entry : topicFutures.entrySet()) {\n+                    Uuid topicId = entry.getKey();\n+                    KafkaFutureImpl<TopicDescription> future = entry.getValue();\n+\n+                    String topicName = cluster.topicName(topicId);\n+                    if (topicName == null) {\n+                        future.completeExceptionally(new UnknownTopicIdException(\"TopicId \" + topicId + \" not found.\"));\n+                        continue;\n+                    }\n+                    Errors topicError = errors.get(topicName);\n+                    if (topicError != null) {\n+                        future.completeExceptionally(topicError.exception());\n+                        continue;\n+                    }\n+\n+                    boolean isInternal = cluster.internalTopics().contains(topicName);\n+                    List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topicName);\n+                    List<TopicPartitionInfo> partitions = new ArrayList<>(partitionInfos.size());\n+                    for (PartitionInfo partitionInfo : partitionInfos) {\n+                        TopicPartitionInfo topicPartitionInfo = new TopicPartitionInfo(\n+                                partitionInfo.partition(), leader(partitionInfo), Arrays.asList(partitionInfo.replicas()),\n+                                Arrays.asList(partitionInfo.inSyncReplicas()));\n+                        partitions.add(topicPartitionInfo);\n+                    }\n+                    partitions.sort(Comparator.comparingInt(TopicPartitionInfo::partition));\n+                    TopicDescription topicDescription = new TopicDescription(topicName, topicId, isInternal, partitions,\n+                            validAclOperations(response.topicAuthorizedOperations(topicName).get()));\n+                    future.complete(topicDescription);\n+                }\n+            }\n+\n+            private Node leader(PartitionInfo partitionInfo) {\n+                if (partitionInfo.leader() == null || partitionInfo.leader().id() == Node.noNode().id())\n+                    return null;\n+                return partitionInfo.leader();\n+            }\n+\n+            @Override\n+            boolean handleUnsupportedVersionException(UnsupportedVersionException exception) {\n+                if (supportsDisablingTopicCreation) {\n+                    supportsDisablingTopicCreation = false;", "originalCommit": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkyMzA1NQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555923055", "bodyText": "For the second question, yes. Topics can not be created with metadata requests using topic IDs.", "author": "jolshan", "createdAt": "2021-01-12T16:52:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTczODUwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE3NjY0OQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r556176649", "bodyText": "Sorry, just removing those code and using default implement.", "author": "dengziming", "createdAt": "2021-01-13T00:04:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTczODUwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MDE5OQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555740199", "bodyText": "What happens if name is null - won't we quietly ignore? Would it be better to throw an exception since we don't want anyone using this with topic ids?", "author": "rajinisivaram", "createdAt": "2021-01-12T12:39:04Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,7 +91,7 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n-            if (metadata.errorCode() != Errors.NONE.code())\n+            if (metadata.errorCode() != Errors.NONE.code() && metadata.name() != null)", "originalCommit": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE3NzU0OA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r556177548", "bodyText": "Firstly I want to leave those check to callers, now I think it's better to throw an exception, So I add another method errorsByTopicId.", "author": "dengziming", "createdAt": "2021-01-13T00:07:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MDE5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MTAxMA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555741010", "bodyText": "Do we want the option to test with and without topic ids?", "author": "rajinisivaram", "createdAt": "2021-01-12T12:40:36Z", "path": "clients/src/test/java/org/apache/kafka/clients/admin/MockAdminClient.java", "diffHunk": "@@ -206,6 +209,8 @@ synchronized public void addTopic(boolean internal,\n                 logDirs.add(brokerLogDirs.get(partition.leader().id()).get(0));\n             }\n         }\n+        Uuid topicId = Uuid.randomUuid();\n+        topicIds.put(name, topicId);", "originalCommit": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjU2ODQwMA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r556568400", "bodyText": "Yes, I add a method with a usesTopicId parameter.", "author": "dengziming", "createdAt": "2021-01-13T14:40:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MTAxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MzM1Mg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555743352", "bodyText": "We have removed this check?", "author": "rajinisivaram", "createdAt": "2021-01-12T12:44:48Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -742,10 +760,16 @@ object TopicCommand extends Logging {\n       if (has(bootstrapServerOpt) == has(zkConnectOpt))\n         throw new IllegalArgumentException(\"Only one of --bootstrap-server or --zookeeper must be specified\")\n \n+      if (has(topicIdOpt) && has(zkConnectOpt)) {\n+        throw new IllegalArgumentException(\"--topic-id can used only with --bootstrap-server\")\n+      }\n+\n       if (!has(bootstrapServerOpt))\n         CommandLineUtils.checkRequiredArgs(parser, options, zkConnectOpt)\n-      if(has(describeOpt) && has(ifExistsOpt))\n-        CommandLineUtils.checkRequiredArgs(parser, options, topicOpt)", "originalCommit": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE3ODU5NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r556178594", "bodyText": "Yes, when we use --describe, --topic is not mandatory. I add a if(has(topicOpt) == has(topicIdOpt)) to ensure only one of --topic and --topic-id is used.", "author": "dengziming", "createdAt": "2021-01-13T00:10:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0MzM1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0NjcyMg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r555746722", "bodyText": "topics may also be empty?", "author": "rajinisivaram", "createdAt": "2021-01-12T12:50:45Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -313,42 +313,54 @@ object TopicCommand extends Logging {\n     }\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n-      val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+      val topicId = opts.topicId.map(Uuid.fromString).filter(_ != Uuid.ZERO_UUID)\n+      val topics = if (topicId.isEmpty)\n+        getTopics(opts.topic, opts.excludeInternalTopics)\n+      else\n+        Seq()\n \n-      if (topics.nonEmpty) {\n-        val allConfigs = adminClient.describeConfigs(topics.map(new ConfigResource(Type.TOPIC, _)).asJavaCollection).values()\n-        val liveBrokers = adminClient.describeCluster().nodes().get().asScala.map(_.id())\n-        val topicDescriptions = adminClient.describeTopics(topics.asJavaCollection).all().get().values().asScala\n-        val describeOptions = new DescribeOptions(opts, liveBrokers.toSet)\n-        val topicPartitions = topicDescriptions\n-          .flatMap(td => td.partitions.iterator().asScala.map(p => new TopicPartition(td.name(), p.partition())))\n-          .toSet.asJava\n-        val reassignments = listAllReassignments(topicPartitions)\n-\n-        for (td <- topicDescriptions) {\n-          val topicName = td.name\n-          val topicId = td.topicId()\n-          val config = allConfigs.get(new ConfigResource(Type.TOPIC, topicName)).get()\n-          val sortedPartitions = td.partitions.asScala.sortBy(_.partition)\n-\n-          if (describeOptions.describeConfigs) {\n-            val hasNonDefault = config.entries().asScala.exists(!_.isDefault)\n-            if (!opts.reportOverriddenConfigs || hasNonDefault) {\n-              val numPartitions = td.partitions().size\n-              val firstPartition = td.partitions.iterator.next()\n-              val reassignment = reassignments.get(new TopicPartition(td.name, firstPartition.partition))\n-              val topicDesc = TopicDescription(topicName, topicId, numPartitions, getReplicationFactor(firstPartition, reassignment), config, markedForDeletion = false)\n-              topicDesc.printDescription()\n-            }\n+      if (topicId.isEmpty)\n+        ensureTopicExists(topics, opts.topic, !opts.ifExists)", "originalCommit": "73a8ea197c261f7ef44d777665d0bc879e4e595e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE4MDExMQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r556180111", "bodyText": "Here, if topic is provided, we ensure topic exists since the given topic maybe a regular expr. should we also check the topicId exists? then we should add a listTopicId method listTopicIds in the AdminClient", "author": "dengziming", "createdAt": "2021-01-13T00:15:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0NjcyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0NDEyMw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562244123", "bodyText": "Since listTopics uses MetadataRequest, we just need to add topic ids from the MetadataResponse to TopicListing?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:39:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc0NjcyMg=="}], "type": "inlineReview"}, {"oid": "0e252600f78836a1fb48539f4d234fa78c01755f", "url": "https://github.com/apache/kafka/commit/0e252600f78836a1fb48539f4d234fa78c01755f", "message": "wip", "committedDate": "2021-01-13T00:00:08Z", "type": "forcePushed"}, {"oid": "5df1f32a45a7b4218631f750d56d431ad3e7e53f", "url": "https://github.com/apache/kafka/commit/5df1f32a45a7b4218631f750d56d431ad3e7e53f", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nfix", "committedDate": "2021-01-13T14:41:27Z", "type": "forcePushed"}, {"oid": "4e20a8d3550f7b0f0258dbea0ae310cf5bb70063", "url": "https://github.com/apache/kafka/commit/4e20a8d3550f7b0f0258dbea0ae310cf5bb70063", "message": "Gate  topic IDs behind IBP 2.8.1", "committedDate": "2021-01-21T03:58:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMTg4Nw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562231887", "bodyText": "Could we move the code shared between describeTopics and describeTopicsWithIds to a common private method?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:13:04Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -1822,6 +1829,88 @@ void handleFailure(Throwable throwable) {\n         return new DescribeTopicsResult(new HashMap<>(topicFutures));\n     }\n \n+    @Override\n+    public DescribeTopicsResultWithIds describeTopicsWithIds(Collection<Uuid> topicIds, DescribeTopicsOptions options) {\n+\n+        final Map<Uuid, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicIds.size());\n+        final List<Uuid> topicIdsList = new ArrayList<>();\n+        for (Uuid topicId : topicIds) {\n+            if (topicIdIsUnrepresentable(topicId)) {\n+                KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n+                future.completeExceptionally(new InvalidTopicException(\"The given topic id '\" +\n+                        topicId + \"' cannot be represented in a request.\"));\n+                topicFutures.put(topicId, future);\n+            } else if (!topicFutures.containsKey(topicId)) {\n+                topicFutures.put(topicId, new KafkaFutureImpl<>());\n+                topicIdsList.add(topicId);\n+            }\n+        }\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeTopicsWithIds\", calcDeadlineMs(now, options.timeoutMs()),\n+                new LeastLoadedNodeProvider()) {\n+\n+            @Override\n+            MetadataRequest.Builder createRequest(int timeoutMs) {\n+                return new MetadataRequest.Builder(new MetadataRequestData()\n+                        .setTopics(convertTopicIdsToMetadataRequestTopic(topicIdsList))\n+                        .setAllowAutoTopicCreation(false)\n+                        .setIncludeTopicAuthorizedOperations(options.includeAuthorizedOperations()));\n+            }\n+\n+            @Override\n+            void handleResponse(AbstractResponse abstractResponse) {\n+                MetadataResponse response = (MetadataResponse) abstractResponse;\n+                // Handle server responses for particular topics.\n+                Cluster cluster = response.cluster();\n+                Map<Uuid, Errors> errors = response.errorsByTopicId();\n+                for (Map.Entry<Uuid, KafkaFutureImpl<TopicDescription>> entry : topicFutures.entrySet()) {\n+                    Uuid topicId = entry.getKey();\n+                    KafkaFutureImpl<TopicDescription> future = entry.getValue();\n+\n+                    String topicName = cluster.topicName(topicId);\n+                    if (topicName == null) {\n+                        future.completeExceptionally(new UnknownTopicIdException(\"TopicId \" + topicId + \" not found.\"));\n+                        continue;\n+                    }\n+                    Errors topicError = errors.get(topicId);\n+                    if (topicError != null) {\n+                        future.completeExceptionally(topicError.exception());\n+                        continue;\n+                    }\n+\n+                    boolean isInternal = cluster.internalTopics().contains(topicName);\n+                    List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topicName);\n+                    List<TopicPartitionInfo> partitions = new ArrayList<>(partitionInfos.size());\n+                    for (PartitionInfo partitionInfo : partitionInfos) {\n+                        TopicPartitionInfo topicPartitionInfo = new TopicPartitionInfo(\n+                                partitionInfo.partition(), leader(partitionInfo), Arrays.asList(partitionInfo.replicas()),\n+                                Arrays.asList(partitionInfo.inSyncReplicas()));\n+                        partitions.add(topicPartitionInfo);\n+                    }\n+                    partitions.sort(Comparator.comparingInt(TopicPartitionInfo::partition));\n+                    TopicDescription topicDescription = new TopicDescription(topicName, isInternal, partitions,\n+                            validAclOperations(response.topicAuthorizedOperations(topicName).get()), topicId);\n+                    future.complete(topicDescription);", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjM5NDc0OQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562394749", "bodyText": "Thank you, I added a getTopicDescriptionFromCluster to do this.", "author": "dengziming", "createdAt": "2021-01-22T05:21:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMTg4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMjE4Mw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562232183", "bodyText": "This could be shared with describeTopics as well?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:13:42Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java", "diffHunk": "@@ -1822,6 +1829,88 @@ void handleFailure(Throwable throwable) {\n         return new DescribeTopicsResult(new HashMap<>(topicFutures));\n     }\n \n+    @Override\n+    public DescribeTopicsResultWithIds describeTopicsWithIds(Collection<Uuid> topicIds, DescribeTopicsOptions options) {\n+\n+        final Map<Uuid, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicIds.size());\n+        final List<Uuid> topicIdsList = new ArrayList<>();\n+        for (Uuid topicId : topicIds) {\n+            if (topicIdIsUnrepresentable(topicId)) {\n+                KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n+                future.completeExceptionally(new InvalidTopicException(\"The given topic id '\" +\n+                        topicId + \"' cannot be represented in a request.\"));\n+                topicFutures.put(topicId, future);\n+            } else if (!topicFutures.containsKey(topicId)) {\n+                topicFutures.put(topicId, new KafkaFutureImpl<>());\n+                topicIdsList.add(topicId);\n+            }\n+        }\n+        final long now = time.milliseconds();\n+        Call call = new Call(\"describeTopicsWithIds\", calcDeadlineMs(now, options.timeoutMs()),\n+                new LeastLoadedNodeProvider()) {\n+\n+            @Override\n+            MetadataRequest.Builder createRequest(int timeoutMs) {\n+                return new MetadataRequest.Builder(new MetadataRequestData()\n+                        .setTopics(convertTopicIdsToMetadataRequestTopic(topicIdsList))\n+                        .setAllowAutoTopicCreation(false)\n+                        .setIncludeTopicAuthorizedOperations(options.includeAuthorizedOperations()));\n+            }\n+\n+            @Override\n+            void handleResponse(AbstractResponse abstractResponse) {\n+                MetadataResponse response = (MetadataResponse) abstractResponse;\n+                // Handle server responses for particular topics.\n+                Cluster cluster = response.cluster();\n+                Map<Uuid, Errors> errors = response.errorsByTopicId();\n+                for (Map.Entry<Uuid, KafkaFutureImpl<TopicDescription>> entry : topicFutures.entrySet()) {\n+                    Uuid topicId = entry.getKey();\n+                    KafkaFutureImpl<TopicDescription> future = entry.getValue();\n+\n+                    String topicName = cluster.topicName(topicId);\n+                    if (topicName == null) {\n+                        future.completeExceptionally(new UnknownTopicIdException(\"TopicId \" + topicId + \" not found.\"));\n+                        continue;\n+                    }\n+                    Errors topicError = errors.get(topicId);\n+                    if (topicError != null) {\n+                        future.completeExceptionally(topicError.exception());\n+                        continue;\n+                    }\n+\n+                    boolean isInternal = cluster.internalTopics().contains(topicName);\n+                    List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topicName);\n+                    List<TopicPartitionInfo> partitions = new ArrayList<>(partitionInfos.size());\n+                    for (PartitionInfo partitionInfo : partitionInfos) {\n+                        TopicPartitionInfo topicPartitionInfo = new TopicPartitionInfo(\n+                                partitionInfo.partition(), leader(partitionInfo), Arrays.asList(partitionInfo.replicas()),\n+                                Arrays.asList(partitionInfo.inSyncReplicas()));\n+                        partitions.add(topicPartitionInfo);\n+                    }\n+                    partitions.sort(Comparator.comparingInt(TopicPartitionInfo::partition));\n+                    TopicDescription topicDescription = new TopicDescription(topicName, isInternal, partitions,\n+                            validAclOperations(response.topicAuthorizedOperations(topicName).get()), topicId);\n+                    future.complete(topicDescription);\n+                }\n+            }\n+\n+            private Node leader(PartitionInfo partitionInfo) {", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMzIzNQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562233235", "bodyText": "Do we really need this constructor in the public class? We could just use the one below?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:15:55Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java", "diffHunk": "@@ -65,6 +65,19 @@ public TopicDescription(String name, boolean internal, List<TopicPartitionInfo>\n         this(name, internal, partitions, Collections.emptySet());\n     }\n \n+    /**\n+     * Create an instance with the specified parameters.\n+     *\n+     * @param name The topic name\n+     * @param internal Whether the topic is internal to Kafka\n+     * @param partitions A list of partitions where the index represents the partition id and the element contains\n+     *                   leadership and replica information for that partition.\n+     * @param topicId the topic id\n+     */\n+    public TopicDescription(String name, boolean internal, List<TopicPartitionInfo> partitions, Uuid topicId) {", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzMzcxOA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562233718", "bodyText": "Looks like default is empty set rather than null?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:16:52Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java", "diffHunk": "@@ -79,6 +92,16 @@ public TopicDescription(String name, boolean internal, List<TopicPartitionInfo>\n         this(name, internal, partitions, authorizedOperations, Uuid.ZERO_UUID);\n     }\n \n+    /**\n+     * Create an instance with the specified parameters.\n+     *\n+     * @param name The topic name\n+     * @param internal Whether the topic is internal to Kafka\n+     * @param partitions A list of partitions where the index represents the partition id and the element contains\n+     *                   leadership and replica information for that partition.\n+     * @param authorizedOperations authorized operations for this topic, or null if this is not known.", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzNDMyNw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562234327", "bodyText": "super() is implied, so we can just leave the method empty?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:18:02Z", "path": "clients/src/main/java/org/apache/kafka/common/errors/UnknownTopicIdException.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.errors;\n+\n+public class UnknownTopicIdException extends ApiException {\n+    private static final long serialVersionUID = 1L;\n+    public UnknownTopicIdException() {\n+        super();", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzNDYwNA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562234604", "bodyText": "typo: does", "author": "rajinisivaram", "createdAt": "2021-01-21T22:18:30Z", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Errors.java", "diffHunk": "@@ -350,7 +351,8 @@\n     POSITION_OUT_OF_RANGE(\n         99,\n         \"Requested position is not greater than or equal to zero, and less than the size of the snapshot.\",\n-        PositionOutOfRangeException::new);\n+        PositionOutOfRangeException::new),\n+    UNKNOWN_TOPIC_ID(100, \"The topic ID dose not exist\", UnknownTopicIdException::new);", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzODU3Ng==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562238576", "bodyText": "We should never get here through the public APIs right? We could use IllegalStateException.", "author": "rajinisivaram", "createdAt": "2021-01-21T22:27:17Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,12 +91,31 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.name() == null) {\n+                throw new NullPointerException(\"Use errorsByTopicId() when manage topic using topic id\");", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjIzODg3OQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562238879", "bodyText": "As before, IllegalStateException?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:27:51Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,12 +91,31 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.name() == null) {\n+                throw new NullPointerException(\"Use errorsByTopicId() when manage topic using topic id\");\n+            }\n             if (metadata.errorCode() != Errors.NONE.code())\n                 errors.put(metadata.name(), Errors.forCode(metadata.errorCode()));\n         }\n         return errors;\n     }\n \n+    /**\n+     * Get a map of the topicIds which had metadata errors\n+     * @return the map\n+     */\n+    public Map<Uuid, Errors> errorsByTopicId() {\n+        Map<Uuid, Errors> errors = new HashMap<>();\n+        for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.topicId() == Uuid.ZERO_UUID) {\n+                throw new NullPointerException(\"Use errors() when manage topic using topic name\");", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0MTA3Mg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562241072", "bodyText": "we would fail if both are provided?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:32:43Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -313,42 +313,57 @@ object TopicCommand extends Logging {\n     }\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n-      val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+      val topicId = opts.topicId.map(Uuid.fromString).filter(_ != Uuid.ZERO_UUID)\n+      // if topicId is provided and not zero, will use topicId regardless of topic name", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjMzMzcyMw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562333723", "bodyText": "that's what I thought at the beginning, now I think it's better to use topicId and print a warning message if both are provided.", "author": "dengziming", "createdAt": "2021-01-22T02:20:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0MTA3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg2MTI1Nw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563861257", "bodyText": "I don't have an issue with this, but just curious why this was chosen over failing.", "author": "jolshan", "createdAt": "2021-01-25T16:30:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0MTA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0NTEwNQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562245105", "bodyText": "for manage topic => for describing topics?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:41:27Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -635,6 +650,11 @@ object TopicCommand extends Logging {\n                          .withRequiredArg\n                          .describedAs(\"topic\")\n                          .ofType(classOf[String])\n+    private val topicIdOpt = parser.accepts(\"topic-id\", \"The topic-id to describe.\" +\n+      \"This is used only with --bootstrap-server option for manage topic.\")", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI0NzUzNA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562247534", "bodyText": "unSupported => unsupported since it is one word (below as well)", "author": "rajinisivaram", "createdAt": "2021-01-21T22:47:10Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1190,8 +1192,31 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val supportedVersionTopicIds = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1) topicIds else Set.empty[Uuid]\n+\n+    val unSupportedVersionTopicIds = topicIds.diff(supportedVersionTopicIds)", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI1MTYyOQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562251629", "bodyText": "@jolshan Shouldn't we use KAFKA_2_8_IV1 for KafkaConfig.usesTopicId and use that here?", "author": "rajinisivaram", "createdAt": "2021-01-21T22:56:03Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1190,8 +1192,31 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val supportedVersionTopicIds = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1) topicIds else Set.empty[Uuid]", "originalCommit": "4091d1b9b8a52403648add5b06b422f9a0d252c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjUxMTk3NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r562511974", "bodyText": "Had a chat offline with Justine. Since KafkaConfig.usesTopicId is used only to decide whether to generate topic ids, 2_8_IV0 makes sense for that, and the check for KAFKA_2_8_IV1 here is the right one. Justine also mentioned:\n\nif we are in the process of bumping to 2_8_IV1, we could have a scenario where the controller is not yet bumped (and not sending topic IDs) but the broker serving the metadata is. In that case I think we would just get unknown topic ID errors and maybe that is ok. If the reverse is occurring, we could also have unsupported version exception when there are actually IDs.\n\nCan we add tests for these two cases?", "author": "rajinisivaram", "createdAt": "2021-01-22T09:48:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI1MTYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE2ODM3Mg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563168372", "bodyText": "Hello, I tried to add 2 test in MetadataRequestBetweenDifferentIbpTest to verify these 2 cases, this test will take probably 10 seconds since we need to constantly restart brokers to change the controller.", "author": "dengziming", "createdAt": "2021-01-23T15:59:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI1MTYyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzYyMDc5NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563620794", "bodyText": "Don't we need the config for the third broker?", "author": "rajinisivaram", "createdAt": "2021-01-25T10:37:48Z", "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,117 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_2_8_IV1}\n+import kafka.network.SocketServer\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_2_8_IV1)", "originalCommit": "e4ce3d77cbe1d46b1880d522de83bc4f1ffe3dc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzcwODg2NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563708864", "bodyText": "Firstly I add 2 brokers to ensure faster election after killing the broker, now I added a broker since we need not kill broker to trigger election.", "author": "dengziming", "createdAt": "2021-01-25T13:07:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzYyMDc5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzYyMjU0Mg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563622542", "bodyText": "Instead of restarting brokers, we could delete the controller node in ZK to force controller election. It doesn't guarantee that the expected broker id becomes the next controller, but it may still get there faster than broker restarts", "author": "rajinisivaram", "createdAt": "2021-01-25T10:40:34Z", "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,117 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_2_8_IV1}\n+import kafka.network.SocketServer\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_2_8_IV1)\n+    )\n+  }\n+\n+  @Test\n+  def testTopicIdUnsupported(): Unit = {\n+\n+    val topic = \"topic\"\n+\n+    // Ensure controller version = KAFKA_2_8_IV1, and then create a topic\n+    ensureControllerIn(Seq(1))\n+    createTopic(topic,  Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    // We can get topicId from the controller\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 10.toShort), brokerSocketServer(1))\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+    assertNotEquals(Uuid.ZERO_UUID, topicId)\n+    assertNotNull(topicId)\n+\n+    // Send request to a broker whose version=KAFKA_2_8_IV0\n+    val resp2 = sendMetadataRequest(new MetadataRequest(requestData(topic, topicId), 10.toShort), brokerSocketServer(0))\n+    assertEquals(Errors.UNSUPPORTED_VERSION, resp2.topicMetadata.iterator().next().error())\n+  }\n+\n+  @Test\n+  def testUnknownTopicId(): Unit = {\n+\n+    val topic = \"topic\"\n+\n+    // Kill controller and restart until broker 2 become controller\n+    ensureControllerIn(Seq(1))\n+    createTopic(topic, Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 10.toShort), brokerSocketServer(1))\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+\n+    // We could still get topic metadata by topicId\n+    val topicMetadata = sendMetadataRequest(new MetadataRequest(requestData(null, topicId), 10.toShort), brokerSocketServer(1))\n+      .topicMetadata.iterator().next()\n+    assertEquals(topicId, topicMetadata.topicId())\n+    assertEquals(topic, topicMetadata.topic())\n+\n+    // Make the broker whose version=KAFKA_2_8_IV0 controller\n+    ensureControllerIn(Seq(0))\n+\n+    // Restart the broker whose version=KAFKA_2_8_IV1, and the controller will send metadata request to it\n+    killBroker(1)\n+    restartDeadBrokers()\n+\n+    // Send request to a broker whose version=KAFKA_2_8_IV1\n+    val resp2 = sendMetadataRequest(new MetadataRequest(requestData(topic, topicId), 10.toShort), brokerSocketServer(1))\n+    assertEquals(Errors.UNKNOWN_TOPIC_ID, resp2.topicMetadata.iterator().next().error())\n+  }\n+\n+  private def ensureControllerIn(brokerIds: Seq[Int]): Unit = {\n+    while (!brokerIds.contains(controllerSocketServer.config.brokerId)) {\n+      killBroker(controllerSocketServer.config.brokerId)", "originalCommit": "e4ce3d77cbe1d46b1880d522de83bc4f1ffe3dc4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzcwOTI0NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563709244", "bodyText": "Good catch, updated.", "author": "dengziming", "createdAt": "2021-01-25T13:07:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzYyMjU0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg3MDMyNQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563870325", "bodyText": "I'm curious if this diff is needed. It seems that the above check will result in all topicIds being left out or all of them being included.", "author": "jolshan", "createdAt": "2021-01-25T16:42:37Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1190,8 +1192,31 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val supportedVersionTopicIds = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1) topicIds else Set.empty[Uuid]\n+\n+    val unsupportedVersionTopicIds = topicIds.diff(supportedVersionTopicIds)", "originalCommit": "c5d599617ebd049005f63b29165546862997907f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg3MjcwNQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563872705", "bodyText": "Does this potentially acknowledge a topic exists if we give a valid id?", "author": "jolshan", "createdAt": "2021-01-25T16:45:44Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1223,7 +1247,7 @@ class KafkaApis(val requestChannel: RequestChannel,\n         Set.empty[MetadataResponseTopic]\n       else\n         unauthorizedForDescribeTopics.map(topic =>\n-          metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, false, util.Collections.emptyList()))\n+          metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, metadataCache.getTopicId(topic), false, util.Collections.emptyList()))", "originalCommit": "c5d599617ebd049005f63b29165546862997907f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk2OTg0MA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563969840", "bodyText": "We should check some of the other error responses to make sure we use name/id appropriately", "author": "jolshan", "createdAt": "2021-01-25T19:00:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg3MjcwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDIyNDkxNg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564224916", "bodyText": "I checked the error responses and found that we should hide TopicId when error=TOPIC_AUTHORIZATION_FAILED, and we can respond topicId on other errors.", "author": "dengziming", "createdAt": "2021-01-26T05:32:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg3MjcwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDYzODI5MA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564638290", "bodyText": "Thanks for fixing this!", "author": "jolshan", "createdAt": "2021-01-26T16:13:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg3MjcwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg4MDczMg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563880732", "bodyText": "This test is super cool and will be very useful when testing other request types like fetch.", "author": "jolshan", "createdAt": "2021-01-25T16:56:11Z", "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,125 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_2_8_IV1}\n+import kafka.network.SocketServer\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import kafka.zk.ZkVersion\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {", "originalCommit": "c5d599617ebd049005f63b29165546862997907f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg5NDA1NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563894054", "bodyText": "This scenario is a bit of a corner case and maybe not a huge deal either way, but does it make more sense to respond with UNKNOWN_TOPIC_ID or UNSUPPORTED_VERSION here? Maybe either is fine since we can expect UNKNOWN_TOPIC_ID or UNSUPPORTED_VERSION during an upgrade like this anyway.", "author": "jolshan", "createdAt": "2021-01-25T17:13:33Z", "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,125 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package integration.kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_2_8_IV1}\n+import kafka.network.SocketServer\n+import kafka.server.{BaseRequestTest, KafkaConfig}\n+import kafka.utils.TestUtils\n+import kafka.zk.ZkVersion\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_2_8_IV1),\n+      createConfig(2, KAFKA_2_8_IV1)\n+    )\n+  }\n+\n+  @Test\n+  def testTopicIdUnsupported(): Unit = {\n+\n+    val topic = \"topic\"\n+\n+    // Ensure controller version = KAFKA_2_8_IV1, and then create a topic\n+    ensureControllerIn(Seq(1, 2))\n+    createTopic(topic,  Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    // We can get topicId from the controller\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 10.toShort), controllerSocketServer)\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+    assertNotEquals(Uuid.ZERO_UUID, topicId)\n+    assertNotNull(topicId)\n+\n+    // Send request to a broker whose version=KAFKA_2_8_IV0\n+    val resp2 = sendMetadataRequest(new MetadataRequest(requestData(topic, topicId), 10.toShort), brokerSocketServer(0))\n+    assertEquals(Errors.UNSUPPORTED_VERSION, resp2.topicMetadata.iterator().next().error())\n+  }\n+\n+  @Test\n+  def testUnknownTopicId(): Unit = {\n+\n+    val topic = \"topic\"\n+\n+    // Kill controller and restart until broker 2 become controller\n+    ensureControllerIn(Seq(1, 2))\n+    createTopic(topic, Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 10.toShort), controllerSocketServer)\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+\n+    // We could still get topic metadata by topicId\n+    val topicMetadata = sendMetadataRequest(new MetadataRequest(requestData(null, topicId), 10.toShort), controllerSocketServer)\n+      .topicMetadata.iterator().next()\n+    assertEquals(topicId, topicMetadata.topicId())\n+    assertEquals(topic, topicMetadata.topic())\n+\n+    // Make the broker whose version=KAFKA_2_8_IV0 controller\n+    ensureControllerIn(Seq(0))\n+\n+    // Restart the broker whose version=KAFKA_2_8_IV1, and the controller will send metadata request to it\n+    killBroker(1)\n+    restartDeadBrokers()\n+\n+    // Send request to a broker whose version=KAFKA_2_8_IV1 and restarted just now\n+    val resp2 = sendMetadataRequest(new MetadataRequest(requestData(topic, topicId), 10.toShort), brokerSocketServer(1))\n+    assertEquals(Errors.UNKNOWN_TOPIC_ID, resp2.topicMetadata.iterator().next().error())", "originalCommit": "c5d599617ebd049005f63b29165546862997907f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDIyMjc3OA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564222778", "bodyText": "Yes, both ERROR is ok here.", "author": "dengziming", "createdAt": "2021-01-26T05:24:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzg5NDA1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk1NTA5Mg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r563955092", "bodyText": "I think this usage is fine since we will only get here if use the topic name version of the request and the topic does not exist.", "author": "jolshan", "createdAt": "2021-01-25T18:37:27Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1213,8 +1238,7 @@ class KafkaApis(val requestChannel: RequestChannel,\n     }\n \n     val unauthorizedForCreateTopicMetadata = unauthorizedForCreateTopics.map(topic =>\n-      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, isInternal(topic), util.Collections.emptyList()))\n-\n+      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, metadataCache.getTopicId(topic), isInternal(topic), util.Collections.emptyList()))", "originalCommit": "c5d599617ebd049005f63b29165546862997907f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTkzODQxMQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r565938411", "bodyText": "@jolshan , Thank you, I misunderstood your comments before, I added the following changes:\n\nIf we are using topicId in metadataReq, we set topicName=null and error=UNKNOWN_TOPIC_ID on unauthorized error\nIf we are using topicName in metadataReq, we set topicId=ZERO and error=TOPIC_AUTHORIZATION_FAILED on unauthorized error.\nAdd a unit test for the above 2 cases.\n@rajinisivaram @jolshan , pleas take a look.", "author": "dengziming", "createdAt": "2021-01-28T09:24:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk1NTA5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjIyNzUyMA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r566227520", "bodyText": "LGTM", "author": "jolshan", "createdAt": "2021-01-28T16:23:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mzk1NTA5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDYzOTc3NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564639774", "bodyText": "nit: remove commented out line.", "author": "jolshan", "createdAt": "2021-01-26T16:15:08Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1194,9 +1194,13 @@ class KafkaApis(val requestChannel: RequestChannel,\n \n     // Check if topicId is presented firstly.\n     val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n-    val supportedVersionTopicIds = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1) topicIds else Set.empty[Uuid]\n \n-    val unsupportedVersionTopicIds = topicIds.diff(supportedVersionTopicIds)\n+    val (supportedVersionTopicIds, unsupportedVersionTopicIds) = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1)\n+      (topicIds, Set.empty[Uuid])\n+    else\n+      (Set.empty[Uuid], topicIds)\n+\n+    // val unsupportedVersionTopicIds = topicIds.diff(supportedVersionTopicIds)", "originalCommit": "3f363b9be4734f78219a5413fe379d32f7ae9b11", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDYzMDYwOA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564630608", "bodyText": "typo: should have been \"The id name of the topic\"", "author": "satishd", "createdAt": "2021-01-26T16:04:06Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicListing.java", "diffHunk": "@@ -17,24 +17,36 @@\n \n package org.apache.kafka.clients.admin;\n \n+import org.apache.kafka.common.Uuid;\n+\n /**\n  * A listing of a topic in the cluster.\n  */\n public class TopicListing {\n     private final String name;\n+    private final Uuid topicId;\n     private final boolean internal;\n \n     /**\n      * Create an instance with the specified parameters.\n      *\n      * @param name The topic name\n+     * @param topicId The topic id.\n      * @param internal Whether the topic is internal to Kafka\n      */\n-    public TopicListing(String name, boolean internal) {\n+    public TopicListing(String name, Uuid topicId, boolean internal) {\n+        this.topicId = topicId;\n         this.name = name;\n         this.internal = internal;\n     }\n \n+    /**\n+     * The name of the topic.", "originalCommit": "3f363b9be4734f78219a5413fe379d32f7ae9b11", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY0MTU5MQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564641591", "bodyText": "Based on the above comment, does not it need to handle UUID.ZERO_UUID too?", "author": "satishd", "createdAt": "2021-01-26T16:17:26Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -313,42 +314,59 @@ object TopicCommand extends Logging {\n     }\n \n     override def describeTopic(opts: TopicCommandOptions): Unit = {\n-      val topics = getTopics(opts.topic, opts.excludeInternalTopics)\n-      ensureTopicExists(topics, opts.topic, !opts.ifExists)\n+      // if topicId is provided and not zero, will use topicId regardless of topic name\n+      val useTopicId = opts.topicId.map(Uuid.fromString).nonEmpty", "originalCommit": "3f363b9be4734f78219a5413fe379d32f7ae9b11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY2NDA3Mw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564664073", "bodyText": "good point!", "author": "jolshan", "createdAt": "2021-01-26T16:45:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY0MTU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDk3OTU4Ng==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r564979586", "bodyText": "Thank you, I was careless about this case, I add the following fix:\n\nWhen --topic and --topic-id are both specified, I will print a warning message that saying that \"topicId will be used if both are specified and topicId is not zero\"\nFilter ZERO UUID before handling in TopicCommand.", "author": "dengziming", "createdAt": "2021-01-27T02:25:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDY0MTU5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTU3NTUzMg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r565575532", "bodyText": "So will we never reach this code path when using topic IDs? I think we are using topics to decide authorization. So in the case where we use ids and the name exists, then we will expose the name and return a zero ID? Might be useful to create an authorizer integration test with topic IDs to ensure correctness.", "author": "jolshan", "createdAt": "2021-01-27T19:27:11Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1223,7 +1251,7 @@ class KafkaApis(val requestChannel: RequestChannel,\n         Set.empty[MetadataResponseTopic]\n       else\n         unauthorizedForDescribeTopics.map(topic =>\n-          metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, false, util.Collections.emptyList()))\n+          metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, Uuid.ZERO_UUID, false, util.Collections.emptyList()))", "originalCommit": "3f363b9be4734f78219a5413fe379d32f7ae9b11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTYxNTYzOA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r565615638", "bodyText": "Good point. If not authorized for describe when using topic ids, we need to make sure we don't return the topic or information about existence of a topic - i.e we can't return TOPIC_AUTHORIZATION_FAILED. Perhaps UNKNOWN_TOPIC_ID would be more suitable.", "author": "rajinisivaram", "createdAt": "2021-01-27T20:35:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTU3NTUzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjIyMjMxOQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r566222319", "bodyText": "Looks good now. We will only get to this point with knownTopicNames, so the metadataCache will also have the topic ID. \ud83d\udc4d", "author": "jolshan", "createdAt": "2021-01-28T16:16:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTU3NTUzMg=="}], "type": "inlineReview"}, {"oid": "1854a1ad82310ec556bdccfbc2188295183e2aef", "url": "https://github.com/apache/kafka/commit/1854a1ad82310ec556bdccfbc2188295183e2aef", "message": "Add Unauthorized unit test", "committedDate": "2021-01-28T09:18:08Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMyNzMyNw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r566327327", "bodyText": "@dengziming Thanks for the test! This line and the line declaring metadataByTopicName below are failing the scala 2.12 build, can we rewrite without mapValues so that the Java8/Scala2.12 build passes? Thanks.", "author": "rajinisivaram", "createdAt": "2021-01-28T18:46:26Z", "path": "core/src/test/scala/unit/kafka/server/KafkaApisTest.scala", "diffHunk": "@@ -1879,6 +1879,109 @@ class KafkaApisTest {\n     assertTrue(response.topicsByError(Errors.UNKNOWN_TOPIC_OR_PARTITION).isEmpty)\n   }\n \n+  @Test\n+  def testUnauthorizedTopicMetadataRequest(): Unit = {\n+\n+    // 1. Set up broker information\n+    val plaintextListener = ListenerName.forSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+    val broker = new UpdateMetadataBroker()\n+      .setId(0)\n+      .setRack(\"rack\")\n+      .setEndpoints(Seq(\n+        new UpdateMetadataEndpoint()\n+          .setHost(\"broker0\")\n+          .setPort(9092)\n+          .setSecurityProtocol(SecurityProtocol.PLAINTEXT.id)\n+          .setListener(plaintextListener.value)\n+      ).asJava)\n+\n+    // 2. Set up authorizer\n+    val authorizer: Authorizer = EasyMock.niceMock(classOf[Authorizer])\n+    val unauthorizedTopic = \"unauthorized-topic\"\n+    val authorizedTopic = \"authorized-topic\"\n+\n+    val expectedActions = Seq(\n+      new Action(AclOperation.DESCRIBE, new ResourcePattern(ResourceType.TOPIC, unauthorizedTopic, PatternType.LITERAL), 1, true, true),\n+      new Action(AclOperation.DESCRIBE, new ResourcePattern(ResourceType.TOPIC, authorizedTopic, PatternType.LITERAL), 1, true, true)\n+    )\n+\n+    val expectedAuthorizeResult = Seq(AuthorizationResult.DENIED, AuthorizationResult.ALLOWED).asJava\n+\n+    EasyMock.expect(authorizer.authorize(anyObject[RequestContext], EasyMock.eq(expectedActions.asJava)))\n+      .andReturn(expectedAuthorizeResult)\n+      .times(2)\n+\n+    // 3. Set up MetadataCache\n+    val authorizedTopicId = Uuid.randomUuid();\n+    val unauthorizedTopicId = Uuid.randomUuid();\n+\n+    val topicIds = new util.HashMap[String, Uuid]()\n+    topicIds.put(authorizedTopic, authorizedTopicId)\n+    topicIds.put(unauthorizedTopic, unauthorizedTopicId)\n+\n+    def createDummyPartitionStates(topic: String) = {\n+      new UpdateMetadataPartitionState()\n+        .setTopicName(topic)\n+        .setPartitionIndex(0)\n+        .setControllerEpoch(1)\n+        .setLeader(0)\n+        .setLeaderEpoch(1)\n+        .setReplicas(Collections.singletonList(0))\n+        .setZkVersion(0)\n+        .setIsr(Collections.singletonList(0))\n+    }\n+\n+    // Send UpdateMetadataReq to update MetadataCache\n+    val partitionStates = Seq(unauthorizedTopic, authorizedTopic).map(createDummyPartitionStates)\n+\n+    val updateMetadataRequest = new UpdateMetadataRequest.Builder(ApiKeys.UPDATE_METADATA.latestVersion, 0,\n+      0, 0, partitionStates.asJava, Seq(broker).asJava, topicIds).build()\n+    metadataCache.updateMetadata(correlationId = 0, updateMetadataRequest)\n+\n+    // 4. Send TopicMetadataReq using topicId\n+    val capturedMetadataByTopicIdResp = expectNoThrottling()\n+    EasyMock.replay(clientRequestQuotaManager, requestChannel, authorizer)\n+\n+    val metadataReqByTopicId = new MetadataRequest.Builder(util.Arrays.asList(authorizedTopicId, unauthorizedTopicId)).build()\n+    createKafkaApis(authorizer = Some(authorizer)).handleTopicMetadataRequest(buildRequest(metadataReqByTopicId, plaintextListener))\n+    val metadataByTopicIdResp = readResponse(metadataReqByTopicId, capturedMetadataByTopicIdResp).asInstanceOf[MetadataResponse]\n+\n+    val metadataByTopicId = metadataByTopicIdResp.data().topics().asScala.groupBy(_.topicId()).view.mapValues(_.head).toMap", "originalCommit": "1854a1ad82310ec556bdccfbc2188295183e2aef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjU1MDYxMg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r566550612", "bodyText": "Thank you, Done.", "author": "dengziming", "createdAt": "2021-01-29T03:07:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjMyNzMyNw=="}], "type": "inlineReview"}, {"oid": "8a4bc643e4fb3176d6df54764922bbc2907f6572", "url": "https://github.com/apache/kafka/commit/8a4bc643e4fb3176d6df54764922bbc2907f6572", "message": "Add Unauthorized unit test\n\nFix scala 2.12 build problem", "committedDate": "2021-01-29T09:58:00Z", "type": "forcePushed"}, {"oid": "d179ba46568869a2b507cd2a3805f9ba3d1a7a27", "url": "https://github.com/apache/kafka/commit/d179ba46568869a2b507cd2a3805f9ba3d1a7a27", "message": "fix NEP", "committedDate": "2021-01-29T16:58:09Z", "type": "forcePushed"}, {"oid": "3b35d76eb8741bf4b5acbf843c76dd868f00e590", "url": "https://github.com/apache/kafka/commit/3b35d76eb8741bf4b5acbf843c76dd868f00e590", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP", "committedDate": "2021-01-30T00:04:28Z", "type": "forcePushed"}, {"oid": "9a3e53cb868814a68c02842eae29ee5f622c7599", "url": "https://github.com/apache/kafka/commit/9a3e53cb868814a68c02842eae29ee5f622c7599", "message": "fix NEP", "committedDate": "2021-01-30T00:00:54Z", "type": "forcePushed"}, {"oid": "3b35d76eb8741bf4b5acbf843c76dd868f00e590", "url": "https://github.com/apache/kafka/commit/3b35d76eb8741bf4b5acbf843c76dd868f00e590", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP", "committedDate": "2021-01-30T00:04:28Z", "type": "forcePushed"}, {"oid": "a48e9df0709576d0453bd897ede6c798d81500ad", "url": "https://github.com/apache/kafka/commit/a48e9df0709576d0453bd897ede6c798d81500ad", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown", "committedDate": "2021-01-30T04:35:28Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY1NTAyMg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567655022", "bodyText": "Could you add topic id to toString?", "author": "chia7712", "createdAt": "2021-02-01T08:57:15Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicListing.java", "diffHunk": "@@ -17,24 +17,36 @@\n \n package org.apache.kafka.clients.admin;\n \n+import org.apache.kafka.common.Uuid;\n+\n /**\n  * A listing of a topic in the cluster.\n  */\n public class TopicListing {\n     private final String name;\n+    private final Uuid topicId;\n     private final boolean internal;\n \n     /**\n      * Create an instance with the specified parameters.\n      *\n      * @param name The topic name\n+     * @param topicId The topic id.\n      * @param internal Whether the topic is internal to Kafka\n      */\n-    public TopicListing(String name, boolean internal) {\n+    public TopicListing(String name, Uuid topicId, boolean internal) {\n+        this.topicId = topicId;\n         this.name = name;\n         this.internal = internal;\n     }\n \n+    /**\n+     * The id of the topic.\n+     */\n+    public Uuid topicId() {", "originalCommit": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY2MTE3Mw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567661173", "bodyText": "val unsupportedVersionTopicMetadata = unsupportedVersionTopicIds.map(topicId =>\n        metadataResponseTopic(Errors.UNSUPPORTED_VERSION, null, topicId, false, util.Collections.emptyList())).toSeq\nIs above code more simple?", "author": "chia7712", "createdAt": "2021-02-01T09:07:36Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1191,8 +1192,35 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val useTopicId = topicIds.nonEmpty\n+\n+    val (supportedVersionTopicIds, unsupportedVersionTopicIds) = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1)\n+      (topicIds, Set.empty[Uuid])\n+    else\n+      (Set.empty[Uuid], topicIds)\n+\n+    val unsupportedVersionTopicMetadata = if (unsupportedVersionTopicIds.isEmpty)", "originalCommit": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY2MTgwMw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567661803", "bodyText": "val unknownTopicIdsTopicMetadata = unknownTopicIds.map(topicId =>\n        metadataResponseTopic(Errors.UNKNOWN_TOPIC_ID, null, topicId, false, util.Collections.emptyList())).toSeq\nIs above code more simple?", "author": "chia7712", "createdAt": "2021-02-01T09:08:35Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1191,8 +1192,35 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val useTopicId = topicIds.nonEmpty\n+\n+    val (supportedVersionTopicIds, unsupportedVersionTopicIds) = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1)\n+      (topicIds, Set.empty[Uuid])\n+    else\n+      (Set.empty[Uuid], topicIds)\n+\n+    val unsupportedVersionTopicMetadata = if (unsupportedVersionTopicIds.isEmpty)\n+      Seq.empty[MetadataResponseTopic]\n+    else\n+      unsupportedVersionTopicIds.map(topicId =>\n+        metadataResponseTopic(Errors.UNSUPPORTED_VERSION, null, topicId, false, util.Collections.emptyList())).toSeq\n+\n+    // Only get topicIds and topicNames when supporting topicId\n+    val unknownTopicIds = supportedVersionTopicIds.filter(metadataCache.getTopicName(_).isEmpty)\n+    val knownTopicNames = supportedVersionTopicIds.flatMap(metadataCache.getTopicName)\n+\n+    val unknownTopicIdsTopicMetadata = if (unknownTopicIds.isEmpty)", "originalCommit": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzcxOTcwMw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567719703", "bodyText": "Thanks, Done!", "author": "dengziming", "createdAt": "2021-02-01T10:36:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY2MTgwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY2MjIxMw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567662213", "bodyText": "Should we reject the requests carrying both topic id and topic name?", "author": "chia7712", "createdAt": "2021-02-01T09:09:13Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1191,8 +1192,35 @@ class KafkaApis(val requestChannel: RequestChannel,\n     val metadataRequest = request.body[MetadataRequest]\n     val requestVersion = request.header.apiVersion\n \n+    // Check if topicId is presented firstly.\n+    val topicIds = metadataRequest.topicIds.asScala.toSet.filterNot(_ == Uuid.ZERO_UUID)\n+    val useTopicId = topicIds.nonEmpty\n+\n+    val (supportedVersionTopicIds, unsupportedVersionTopicIds) = if (config.interBrokerProtocolVersion >= KAFKA_2_8_IV1)\n+      (topicIds, Set.empty[Uuid])\n+    else\n+      (Set.empty[Uuid], topicIds)\n+\n+    val unsupportedVersionTopicMetadata = if (unsupportedVersionTopicIds.isEmpty)\n+      Seq.empty[MetadataResponseTopic]\n+    else\n+      unsupportedVersionTopicIds.map(topicId =>\n+        metadataResponseTopic(Errors.UNSUPPORTED_VERSION, null, topicId, false, util.Collections.emptyList())).toSeq\n+\n+    // Only get topicIds and topicNames when supporting topicId\n+    val unknownTopicIds = supportedVersionTopicIds.filter(metadataCache.getTopicName(_).isEmpty)\n+    val knownTopicNames = supportedVersionTopicIds.flatMap(metadataCache.getTopicName)\n+\n+    val unknownTopicIdsTopicMetadata = if (unknownTopicIds.isEmpty)\n+      Seq.empty[MetadataResponseTopic]\n+    else\n+      unknownTopicIds.map(topicId =>\n+        metadataResponseTopic(Errors.UNKNOWN_TOPIC_ID, null, topicId, false, util.Collections.emptyList())).toSeq\n+\n     val topics = if (metadataRequest.isAllTopics)\n       metadataCache.getAllTopics()\n+    else if (useTopicId)", "originalCommit": "022a0eb4324d787a6a956599d3dc06a9d6eedc9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzcxODMxNw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r567718317", "bodyText": "According to KIP-516, we just ignore topic name if a none zero topic id is provided.", "author": "dengziming", "createdAt": "2021-02-01T10:34:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NzY2MjIxMw=="}], "type": "inlineReview"}, {"oid": "60616f56f39f7ec6ec2eea41dcf1061932cc8bd3", "url": "https://github.com/apache/kafka/commit/60616f56f39f7ec6ec2eea41dcf1061932cc8bd3", "message": "resolve comments", "committedDate": "2021-02-01T09:51:14Z", "type": "forcePushed"}, {"oid": "488debccc73c8ce0972e03adc112d2d3ee6a0539", "url": "https://github.com/apache/kafka/commit/488debccc73c8ce0972e03adc112d2d3ee6a0539", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown", "committedDate": "2021-02-01T12:28:09Z", "type": "forcePushed"}, {"oid": "3f3cd349e6235e444d618abe736c8639a9771700", "url": "https://github.com/apache/kafka/commit/3f3cd349e6235e444d618abe736c8639a9771700", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown", "committedDate": "2021-02-02T01:29:15Z", "type": "forcePushed"}, {"oid": "86fc15b86bc3d32137a3c1c7bcf3de38342f910d", "url": "https://github.com/apache/kafka/commit/86fc15b86bc3d32137a3c1c7bcf3de38342f910d", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk", "committedDate": "2021-03-25T03:17:24Z", "type": "forcePushed"}, {"oid": "603fe902adf08f6a32a0bd21fbfdd01302f22027", "url": "https://github.com/apache/kafka/commit/603fe902adf08f6a32a0bd21fbfdd01302f22027", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk", "committedDate": "2021-03-31T02:40:14Z", "type": "forcePushed"}, {"oid": "7fb8ea403cf4f8ea02c66835c46abe8e873c16ce", "url": "https://github.com/apache/kafka/commit/7fb8ea403cf4f8ea02c66835c46abe8e873c16ce", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\n\nadd ITCase of metadata request edge case between different ipb\n\nAdd Unauthorized unit test\n\nFix scala 2.12 build problem\n\nfix NEP\n\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\nmerge trunk", "committedDate": "2021-04-02T02:09:45Z", "type": "forcePushed"}, {"oid": "b2d1574760aadbfe626c98240097f4671ecae2e3", "url": "https://github.com/apache/kafka/commit/b2d1574760aadbfe626c98240097f4671ecae2e3", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nresolve comments\nresolve edge conditions\nGate  topic IDs behind IBP 2.8.1\nadd ITCase of metadata request edge case between different ipb\nAdd Unauthorized unit test\nFix scala 2.12 build problem\nfix NEP\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts", "committedDate": "2021-04-10T01:35:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxMTIxNDIwOQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r611214209", "bodyText": "In the time since we last looked at this, we decided that it is ok to acknowledge existence of the topic ID and return TOPIC_AUTHORIZATION_FAILED. This is so the client knows it is not a retriable error. Please see https://issues.apache.org/jira/browse/KAFKA-12394 for more details.", "author": "jolshan", "createdAt": "2021-04-11T16:38:44Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1165,16 +1189,23 @@ class KafkaApis(val requestChannel: RequestChannel,\n     }\n \n     val unauthorizedForCreateTopicMetadata = unauthorizedForCreateTopics.map(topic =>\n-      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, isInternal(topic), util.Collections.emptyList()))\n+      // Set topicId to zero since we will never create topic which topicId\n+      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, Uuid.ZERO_UUID, isInternal(topic), util.Collections.emptyList()))\n \n     // do not disclose the existence of topics unauthorized for Describe, so we've not even checked if they exist or not\n     val unauthorizedForDescribeTopicMetadata =\n       // In case of all topics, don't include topics unauthorized for Describe\n       if ((requestVersion == 0 && (metadataRequest.topics == null || metadataRequest.topics.isEmpty)) || metadataRequest.isAllTopics)\n         Set.empty[MetadataResponseTopic]\n-      else\n+      else if (useTopicId) {\n+        // We should not return information about existence of a topic on unauthorized error, so we return an UNKNOWN_TOPIC_ID\n+        unauthorizedForDescribeTopics.map(topic =>\n+          metadataResponseTopic(Errors.UNKNOWN_TOPIC_ID, null, metadataCache.getTopicId(topic), false, util.Collections.emptyList()))", "originalCommit": "b2d1574760aadbfe626c98240097f4671ecae2e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1a66be89f91b163fbd1ecf912fb49c0a8e199d6e", "url": "https://github.com/apache/kafka/commit/1a66be89f91b163fbd1ecf912fb49c0a8e199d6e", "message": "check KAFKA-12394", "committedDate": "2021-04-12T08:54:14Z", "type": "forcePushed"}, {"oid": "687aa318b58d0073c85b3f600168e6ce7e67d235", "url": "https://github.com/apache/kafka/commit/687aa318b58d0073c85b3f600168e6ce7e67d235", "message": "check KAFKA-12701", "committedDate": "2021-06-17T09:34:13Z", "type": "forcePushed"}, {"oid": "ec2a79bd743c17f48290db940d3373ee2839689a", "url": "https://github.com/apache/kafka/commit/ec2a79bd743c17f48290db940d3373ee2839689a", "message": "check KAFKA-12701", "committedDate": "2021-06-17T13:08:07Z", "type": "forcePushed"}, {"oid": "80e392990ae787a35a072db0a13c9143a30c2471", "url": "https://github.com/apache/kafka/commit/80e392990ae787a35a072db0a13c9143a30c2471", "message": "check KAFKA-12976", "committedDate": "2021-06-29T11:26:57Z", "type": "forcePushed"}, {"oid": "9e2f648f7cc7091b47ac86f7ac9b215bddca2ca6", "url": "https://github.com/apache/kafka/commit/9e2f648f7cc7091b47ac86f7ac9b215bddca2ca6", "message": "check KAFKA-13011: using TopicCollection", "committedDate": "2021-07-02T08:21:41Z", "type": "forcePushed"}, {"oid": "710276924ad313f0a7a5cb67637feff540c69398", "url": "https://github.com/apache/kafka/commit/710276924ad313f0a7a5cb67637feff540c69398", "message": "check KAFKA-13011: using TopicCollection", "committedDate": "2021-07-02T09:18:58Z", "type": "forcePushed"}, {"oid": "37f56f34a1cf8865537199e383dc2f1ca7b4181c", "url": "https://github.com/apache/kafka/commit/37f56f34a1cf8865537199e383dc2f1ca7b4181c", "message": "check KAFKA-13011: using TopicCollection", "committedDate": "2021-07-03T02:32:18Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NTgwNA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664075804", "bodyText": "We should deprecate this one too I believe.", "author": "jolshan", "createdAt": "2021-07-05T18:04:26Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,87 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n     }\n \n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n+    }\n+\n+\n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated\n     public Map<String, KafkaFuture<TopicDescription>> values() {\n-        return futures;\n+        return nameFutures;\n     }\n \n     /**\n      * Return a future which succeeds only if all the topic descriptions succeed.\n      */\n     public KafkaFuture<Map<String, TopicDescription>> all() {\n-        return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n+        return all(nameFutures);", "originalCommit": "37f56f34a1cf8865537199e383dc2f1ca7b4181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDMwOTg0Nw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664309847", "bodyText": "Done, and also change all usages to use allTopicNames().", "author": "dengziming", "createdAt": "2021-07-06T07:37:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NTgwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NjgzMw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664076833", "bodyText": "Is there a reason this is setting the name to empty and not null? (or no name set at all?)", "author": "jolshan", "createdAt": "2021-07-05T18:07:51Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataRequest.java", "diffHunk": "@@ -65,6 +65,20 @@ public Builder(List<String> topics, boolean allowAutoTopicCreation) {\n             this(topics, allowAutoTopicCreation, ApiKeys.METADATA.oldestVersion(),  ApiKeys.METADATA.latestVersion());\n         }\n \n+        public Builder(List<Uuid> topicIds) {\n+            super(ApiKeys.METADATA, ApiKeys.METADATA.oldestVersion(), ApiKeys.METADATA.latestVersion());\n+            MetadataRequestData data = new MetadataRequestData();\n+            if (topicIds == null)\n+                data.setTopics(null);\n+            else {\n+                topicIds.forEach(topicId -> data.topics().add(new MetadataRequestTopic().setTopicId(topicId).setName(\"\")));", "originalCommit": "37f56f34a1cf8865537199e383dc2f1ca7b4181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDMwODk1OQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664308959", "bodyText": "This is old code since we do not support null names firstly, now we can remove this useless code.", "author": "dengziming", "createdAt": "2021-07-06T07:36:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NjgzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NzM1NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664077354", "bodyText": "can we set a previous version to be nullable? Or does this need to be 12+", "author": "jolshan", "createdAt": "2021-07-05T18:09:30Z", "path": "clients/src/main/resources/common/message/MetadataResponse.json", "diffHunk": "@@ -65,7 +66,7 @@\n       \"about\": \"Each topic in the response.\", \"fields\": [\n       { \"name\": \"ErrorCode\", \"type\": \"int16\", \"versions\": \"0+\",\n         \"about\": \"The topic error, or 0 if there was no error.\" },\n-      { \"name\": \"Name\", \"type\": \"string\", \"versions\": \"0+\", \"mapKey\": true, \"entityType\": \"topicName\",\n+      { \"name\": \"Name\", \"type\": \"string\", \"versions\": \"0+\", \"mapKey\": true, \"entityType\": \"topicName\", \"nullableVersions\": \"10+\",", "originalCommit": "37f56f34a1cf8865537199e383dc2f1ca7b4181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDMwNjg5OA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664306898", "bodyText": "Yes, this should be 12+", "author": "dengziming", "createdAt": "2021-07-06T07:33:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3NzM1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3ODE2MQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664078161", "bodyText": "Why are we bumping IBP? Metadata is not an inter-broker protocol, so I think bumping the metadata protocol suffices.", "author": "jolshan", "createdAt": "2021-07-05T18:12:18Z", "path": "core/src/main/scala/kafka/api/ApiVersion.scala", "diffHunk": "@@ -116,7 +116,9 @@ object ApiVersion {\n     // Introduce AllocateProducerIds (KIP-730)\n     KAFKA_3_0_IV0,\n     // Introduce ListOffsets V7 which supports listing offsets by max timestamp (KIP-734)\n-    KAFKA_3_0_IV1\n+    KAFKA_3_0_IV1,\n+    // Introduced topic IDs to MetadataRequest", "originalCommit": "37f56f34a1cf8865537199e383dc2f1ca7b4181c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDMwNjU3Nw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r664306577", "bodyText": "You are right, we no longer need to check UNSUPPORTED_VERSION_ERROR, so it's unnecessary to bump IBP.", "author": "dengziming", "createdAt": "2021-07-06T07:33:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDA3ODE2MQ=="}], "type": "inlineReview"}, {"oid": "4074a215ecf284f64ab9f6fcbae96517ec1e8a41", "url": "https://github.com/apache/kafka/commit/4074a215ecf284f64ab9f6fcbae96517ec1e8a41", "message": "resolve comments", "committedDate": "2021-07-06T07:26:15Z", "type": "forcePushed"}, {"oid": "988c493be558b44d0dec97ca84a58ee3faea013a", "url": "https://github.com/apache/kafka/commit/988c493be558b44d0dec97ca84a58ee3faea013a", "message": "resolve comments", "committedDate": "2021-07-06T07:30:43Z", "type": "forcePushed"}, {"oid": "a94256dd75eb467c3d2b4435573621a4e83d3341", "url": "https://github.com/apache/kafka/commit/a94256dd75eb467c3d2b4435573621a4e83d3341", "message": "resolve comments and rebase trunk", "committedDate": "2021-07-07T01:56:08Z", "type": "forcePushed"}, {"oid": "7394bf8b95e057512e5836e1fe6b8b09093f5608", "url": "https://github.com/apache/kafka/commit/7394bf8b95e057512e5836e1fe6b8b09093f5608", "message": "rebase trunk and resolve conflicts", "committedDate": "2021-07-07T05:53:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTQ3NjIxOQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r665476219", "bodyText": "Since we are past the feature freeze date, I think this will need to be 3.1 now. Same above.", "author": "jolshan", "createdAt": "2021-07-07T15:22:28Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -303,7 +303,33 @@ default DescribeTopicsResult describeTopics(Collection<String> topicNames) {\n      * @param options    The options to use when describing the topic.\n      * @return The DescribeTopicsResult.\n      */\n-    DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options);\n+    default DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options) {\n+        return describeTopics(TopicCollection.ofTopicNames(topicNames), options);\n+    }\n+\n+    /**\n+     * This is a convenience method for {@link #describeTopics(TopicCollection, DescribeTopicsOptions)}\n+     * with default options. See the overload for more details.\n+     * <p>\n+     * When using topic IDs, this operation is supported by brokers with version 3.0.0 or higher.\n+     *\n+     * @param topics The topics to delete.\n+     * @return The DescribeTopicsResult.\n+     */\n+    default DescribeTopicsResult describeTopics(TopicCollection topics) {\n+        return describeTopics(topics, new DescribeTopicsOptions());\n+    }\n+\n+    /**\n+     * describe a batch of topics.\n+     *\n+     * When using topic IDs, this operation is supported by brokers with version 3.0.0 or higher.", "originalCommit": "7394bf8b95e057512e5836e1fe6b8b09093f5608", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTQ3OTk3Nw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r665479977", "bodyText": "I'm not sure this comment is correct since we don't use this version.\nJust to confirm my understanding, what is this test showing? First we can get description when controller is high enough IBP (2_8_IV1+) and then we can't when controller is lower than that?", "author": "jolshan", "createdAt": "2021-07-07T15:26:46Z", "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,103 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_3_0_IV1}\n+import kafka.network.SocketServer\n+import kafka.utils.TestUtils\n+import kafka.zk.ZkVersion\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_3_0_IV1),\n+      createConfig(2, KAFKA_3_0_IV1)\n+    )\n+  }\n+\n+  @Test\n+  def testUnknownTopicId(): Unit = {\n+    val topic = \"topic\"\n+\n+    // Kill controller and restart until broker 2 become controller\n+    ensureControllerIn(Seq(1, 2))\n+    createTopic(topic, Map(0 -> Seq(1, 2, 0), 1 -> Seq(2, 0, 1)))\n+\n+    val resp1 = sendMetadataRequest(new MetadataRequest(requestData(topic, Uuid.ZERO_UUID), 12.toShort), controllerSocketServer)\n+    val topicId = resp1.topicMetadata.iterator().next().topicId()\n+\n+    // We could still get topic metadata by topicId\n+   val topicMetadata = sendMetadataRequest(new MetadataRequest(requestData(null, topicId), 12.toShort), controllerSocketServer)\n+      .topicMetadata.iterator().next()\n+    assertEquals(topicId, topicMetadata.topicId())\n+    assertEquals(topic, topicMetadata.topic())\n+\n+    // Make the broker whose version=KAFKA_3_0_IV0 controller", "originalCommit": "7394bf8b95e057512e5836e1fe6b8b09093f5608", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTgxNDE4MQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r665814181", "bodyText": "This class is created to test the 2 cases here: #9769 (comment) , and now we only need to test the UNKNOWN_TOPIC_ID case since we do not need UNSUPPORTED_VERSION now.\nAnd this comment is wrong, I will fix it.", "author": "dengziming", "createdAt": "2021-07-08T01:52:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTQ3OTk3Nw=="}], "type": "inlineReview"}, {"oid": "6556a4572ab914df46f78ec8e72ca5d1f439c30d", "url": "https://github.com/apache/kafka/commit/6556a4572ab914df46f78ec8e72ca5d1f439c30d", "message": "more feedback from comments", "committedDate": "2021-07-08T02:24:27Z", "type": "forcePushed"}, {"oid": "ca32ef409673686ea3499eb359a1e631e698df4d", "url": "https://github.com/apache/kafka/commit/ca32ef409673686ea3499eb359a1e631e698df4d", "message": "more feedback from comments", "committedDate": "2021-07-10T05:23:42Z", "type": "forcePushed"}, {"oid": "3aa7a04096d2fe878578e54cbf6b9e513d8609b7", "url": "https://github.com/apache/kafka/commit/3aa7a04096d2fe878578e54cbf6b9e513d8609b7", "message": "more feedback from comments", "committedDate": "2021-07-13T01:40:26Z", "type": "forcePushed"}, {"oid": "3d7d81df30f9e5b7b3e656990d916d038404bf51", "url": "https://github.com/apache/kafka/commit/3d7d81df30f9e5b7b3e656990d916d038404bf51", "message": "more feedback from comments", "committedDate": "2021-07-23T13:39:12Z", "type": "forcePushed"}, {"oid": "83c3f0da62d5a983b678be1aa69669a2f285fb67", "url": "https://github.com/apache/kafka/commit/83c3f0da62d5a983b678be1aa69669a2f285fb67", "message": "remove usage of deprecated methods", "committedDate": "2021-07-24T12:49:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NzkzMjM2MQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r677932361", "bodyText": "nit: is there a reason we moved these imports?", "author": "jolshan", "createdAt": "2021-07-28T02:44:43Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -42,6 +34,14 @@\n import org.apache.kafka.common.quota.ClientQuotaFilter;\n import org.apache.kafka.common.requests.LeaveGroupResponse;\n \n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;", "originalCommit": "83c3f0da62d5a983b678be1aa69669a2f285fb67", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDMyNTgyMg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r680325822", "bodyText": "This is invoked by the IDE spotless plugin, but I think this is reasonable since we are going to add import order checkstyle here:https://github.com/apache/kafka/pull/10428/files#diff-49a96e7eea8a94af862798a45174e6ac43eb4f8b4bd40759b5da63ba31ec3ef7R615, and java.* will be put last.", "author": "dengziming", "createdAt": "2021-07-31T07:52:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NzkzMjM2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NzkzMjk1NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r677932954", "bodyText": "Can we adjust this javadoc to be Describe some topics in the cluster. like the previous API?", "author": "jolshan", "createdAt": "2021-07-28T02:46:32Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/Admin.java", "diffHunk": "@@ -303,7 +303,33 @@ default DescribeTopicsResult describeTopics(Collection<String> topicNames) {\n      * @param options    The options to use when describing the topic.\n      * @return The DescribeTopicsResult.\n      */\n-    DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options);\n+    default DescribeTopicsResult describeTopics(Collection<String> topicNames, DescribeTopicsOptions options) {\n+        return describeTopics(TopicCollection.ofTopicNames(topicNames), options);\n+    }\n+\n+    /**\n+     * This is a convenience method for {@link #describeTopics(TopicCollection, DescribeTopicsOptions)}\n+     * with default options. See the overload for more details.\n+     * <p>\n+     * When using topic IDs, this operation is supported by brokers with version 3.1.0 or higher.\n+     *\n+     * @param topics The topics to describe.\n+     * @return The DescribeTopicsResult.\n+     */\n+    default DescribeTopicsResult describeTopics(TopicCollection topics) {\n+        return describeTopics(topics, new DescribeTopicsOptions());\n+    }\n+\n+    /**\n+     * describe a batch of topics.", "originalCommit": "83c3f0da62d5a983b678be1aa69669a2f285fb67", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NzkzMzg4NQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r677933885", "bodyText": "nit: extra newline here", "author": "jolshan", "createdAt": "2021-07-28T02:49:15Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,87 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n     }\n \n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated\n     public Map<String, KafkaFuture<TopicDescription>> values() {\n-        return futures;\n+        return nameFutures;\n     }\n \n     /**\n      * Return a future which succeeds only if all the topic descriptions succeed.\n      */\n+    @Deprecated\n     public KafkaFuture<Map<String, TopicDescription>> all() {\n-        return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n+        return all(nameFutures);\n+    }\n+\n+    /**\n+     * Return a future which succeeds only if all the topic descriptions succeed.\n+     */\n+    public KafkaFuture<Map<String, TopicDescription>> allTopicNames() {\n+        return all(nameFutures);\n+    }\n+\n+    /**\n+     * Return a future which succeeds only if all the topic descriptions succeed.\n+     */\n+    public KafkaFuture<Map<Uuid, TopicDescription>> allTopicIds() {\n+        return all(topicIdFutures);\n+    }\n+\n+    /**\n+     * Return a future which succeeds only if all the topic descriptions succeed.\n+     */\n+    private static <T> KafkaFuture<Map<T, TopicDescription>> all(Map<T, KafkaFuture<TopicDescription>> futures) {\n+", "originalCommit": "83c3f0da62d5a983b678be1aa69669a2f285fb67", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3Nzk0MTAyNw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r677941027", "bodyText": "I think this was discussed briefly before, but is there a reason KAFKA_3_0_IV1 was chosen? Should we just use the most recent IBP? (meaning, not even specify in the properties -- just pick up the default?)", "author": "jolshan", "createdAt": "2021-07-28T03:12:02Z", "path": "core/src/test/scala/integration/kafka/server/MetadataRequestBetweenDifferentIbpTest.scala", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+  * Licensed to the Apache Software Foundation (ASF) under one or more\n+  * contributor license agreements.  See the NOTICE file distributed with\n+  * this work for additional information regarding copyright ownership.\n+  * The ASF licenses this file to You under the Apache License, Version 2.0\n+  * (the \"License\"); you may not use this file except in compliance with\n+  * the License.  You may obtain a copy of the License at\n+  *\n+  *    http://www.apache.org/licenses/LICENSE-2.0\n+  *\n+  * Unless required by applicable law or agreed to in writing, software\n+  * distributed under the License is distributed on an \"AS IS\" BASIS,\n+  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+  * See the License for the specific language governing permissions and\n+  * limitations under the License.\n+  */\n+\n+package kafka.server\n+\n+import kafka.api.{ApiVersion, KAFKA_2_8_IV0, KAFKA_3_0_IV1}\n+import kafka.network.SocketServer\n+import kafka.utils.TestUtils\n+import kafka.zk.ZkVersion\n+import org.apache.kafka.common.Uuid\n+import org.apache.kafka.common.message.MetadataRequestData\n+import org.apache.kafka.common.protocol.Errors\n+import org.apache.kafka.common.requests.{MetadataRequest, MetadataResponse}\n+import org.junit.jupiter.api.Assertions._\n+import org.junit.jupiter.api.Test\n+\n+import scala.collection.{Map, Seq}\n+\n+class MetadataRequestBetweenDifferentIbpTest extends BaseRequestTest {\n+\n+  override def brokerCount: Int = 3\n+  override def generateConfigs: Seq[KafkaConfig] = {\n+    Seq(\n+      createConfig(0, KAFKA_2_8_IV0),\n+      createConfig(1, KAFKA_3_0_IV1),", "originalCommit": "83c3f0da62d5a983b678be1aa69669a2f285fb67", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDMyODQ4Ng==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r680328486", "bodyText": "In fact, when I first change this to KAFKA_3_1_IV0, this test became a flaky test, and now I fixed it.", "author": "dengziming", "createdAt": "2021-07-31T08:19:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3Nzk0MTAyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDQwMTk4NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r680401984", "bodyText": "Ah ok. There were some issues with KAFKA_3_1_IV0. I fixed one of the issues that led to flaky tests. Hopefully that helped this too.", "author": "jolshan", "createdAt": "2021-07-31T19:50:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3Nzk0MTAyNw=="}], "type": "inlineReview"}, {"oid": "cedaec45b7ff0b679e50712b6475752b2d5e84dc", "url": "https://github.com/apache/kafka/commit/cedaec45b7ff0b679e50712b6475752b2d5e84dc", "message": "more feedbacks from comments", "committedDate": "2021-07-31T08:11:23Z", "type": "forcePushed"}, {"oid": "140ade867813302014765010cc78d9b1b92af821", "url": "https://github.com/apache/kafka/commit/140ade867813302014765010cc78d9b1b92af821", "message": "more feedbacks from comments", "committedDate": "2021-07-31T08:41:12Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIxNzY3MQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697217671", "bodyText": "Since this is a protected method in a public API, we should probably keep the method and deprecate. It can just invoke the method below.", "author": "rajinisivaram", "createdAt": "2021-08-27T07:31:03Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIxODA1Nw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697218057", "bodyText": "Make this package-private?", "author": "rajinisivaram", "createdAt": "2021-08-27T07:31:39Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzUzMTcyNQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697531725", "bodyText": "This is used in InternalTopicManagerTest so it should be protected, I just add a \"VisibleForTesting\" comment to it.", "author": "dengziming", "createdAt": "2021-08-27T15:28:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIxODA1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIyMDQ3OA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697220478", "bodyText": "Can we add  @deprecated Since 3.1. Use xxx in the javadoc above?", "author": "rajinisivaram", "createdAt": "2021-08-27T07:35:45Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n     }\n \n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIyMDU3MQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697220571", "bodyText": "Can we add  @deprecated Since 3.1. Use xxx in the javadoc above?", "author": "rajinisivaram", "createdAt": "2021-08-27T07:35:53Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n     }\n \n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated\n     public Map<String, KafkaFuture<TopicDescription>> values() {\n-        return futures;\n+        return nameFutures;\n     }\n \n     /**\n      * Return a future which succeeds only if all the topic descriptions succeed.\n      */\n+    @Deprecated", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzIyMjc4Mg==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697222782", "bodyText": "Also mention that this returns by topic name if the request used topic names. otherwise returns null.", "author": "rajinisivaram", "createdAt": "2021-08-27T07:39:39Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/DescribeTopicsResult.java", "diffHunk": "@@ -32,28 +34,86 @@\n  */\n @InterfaceStability.Evolving\n public class DescribeTopicsResult {\n-    private final Map<String, KafkaFuture<TopicDescription>> futures;\n+    private final Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures;\n+    private final Map<String, KafkaFuture<TopicDescription>> nameFutures;\n \n-    protected DescribeTopicsResult(Map<String, KafkaFuture<TopicDescription>> futures) {\n-        this.futures = futures;\n+    protected DescribeTopicsResult(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures, Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        if (topicIdFutures != null && nameFutures != null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be specified.\");\n+        if (topicIdFutures == null && nameFutures == null)\n+            throw new IllegalArgumentException(\"topicIdFutures and nameFutures cannot both be null.\");\n+        this.topicIdFutures = topicIdFutures;\n+        this.nameFutures = nameFutures;\n+    }\n+\n+    static DescribeTopicsResult ofTopicIds(Map<Uuid, KafkaFuture<TopicDescription>> topicIdFutures) {\n+        return new DescribeTopicsResult(topicIdFutures, null);\n+    }\n+\n+    static DescribeTopicsResult ofTopicNames(Map<String, KafkaFuture<TopicDescription>> nameFutures) {\n+        return new DescribeTopicsResult(null, nameFutures);\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicIdCollection\n+     *\n+     * @return a map from topic IDs to futures which can be used to check the status of\n+     *         individual topics if the request used topic IDs, otherwise return null.\n+     */\n+    public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n+        return topicIdFutures;\n+    }\n+\n+    /**\n+     * Use when {@link Admin#describeTopics(TopicCollection, DescribeTopicsOptions)} used a TopicNameCollection\n+     *\n+     * @return a map from topic names to futures which can be used to check the status of\n+     *         individual topics if the request used topic names, otherwise return null.\n+     */\n+    public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n+        return nameFutures;\n     }\n \n     /**\n      * Return a map from topic names to futures which can be used to check the status of\n      * individual topics.\n      */\n+    @Deprecated\n     public Map<String, KafkaFuture<TopicDescription>> values() {\n-        return futures;\n+        return nameFutures;\n     }\n \n     /**\n      * Return a future which succeeds only if all the topic descriptions succeed.\n      */\n+    @Deprecated\n     public KafkaFuture<Map<String, TopicDescription>> all() {\n-        return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n+        return all(nameFutures);\n+    }\n+\n+    /**\n+     * Return a future which succeeds only if all the topic descriptions succeed.", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM3MjkzMQ==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697372931", "bodyText": "Since this is part of the public API, we should keep the original constructor and deprecate.", "author": "rajinisivaram", "createdAt": "2021-08-27T11:39:51Z", "path": "clients/src/main/java/org/apache/kafka/clients/admin/TopicListing.java", "diffHunk": "@@ -17,24 +17,36 @@\n \n package org.apache.kafka.clients.admin;\n \n+import org.apache.kafka.common.Uuid;\n+\n /**\n  * A listing of a topic in the cluster.\n  */\n public class TopicListing {\n     private final String name;\n+    private final Uuid topicId;\n     private final boolean internal;\n \n     /**\n      * Create an instance with the specified parameters.\n      *\n      * @param name The topic name\n+     * @param topicId The topic id.\n      * @param internal Whether the topic is internal to Kafka\n      */\n-    public TopicListing(String name, boolean internal) {\n+    public TopicListing(String name, Uuid topicId, boolean internal) {", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM3NDI3OA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697374278", "bodyText": "when manage => when managing", "author": "rajinisivaram", "createdAt": "2021-08-27T11:42:24Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,12 +91,31 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.name() == null) {\n+                throw new IllegalStateException(\"Use errorsByTopicId() when manage topic using topic id\");", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM3NjMxOA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697376318", "bodyText": "As before, when manage =>when managing", "author": "rajinisivaram", "createdAt": "2021-08-27T11:46:20Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/MetadataResponse.java", "diffHunk": "@@ -91,12 +91,31 @@ public int throttleTimeMs() {\n     public Map<String, Errors> errors() {\n         Map<String, Errors> errors = new HashMap<>();\n         for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.name() == null) {\n+                throw new IllegalStateException(\"Use errorsByTopicId() when manage topic using topic id\");\n+            }\n             if (metadata.errorCode() != Errors.NONE.code())\n                 errors.put(metadata.name(), Errors.forCode(metadata.errorCode()));\n         }\n         return errors;\n     }\n \n+    /**\n+     * Get a map of the topicIds which had metadata errors\n+     * @return the map\n+     */\n+    public Map<Uuid, Errors> errorsByTopicId() {\n+        Map<Uuid, Errors> errors = new HashMap<>();\n+        for (MetadataResponseTopic metadata : data.topics()) {\n+            if (metadata.topicId() == Uuid.ZERO_UUID) {\n+                throw new IllegalStateException(\"Use errors() when manage topic using topic name\");", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM4MDU1OA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697380558", "bodyText": "we => returning?", "author": "rajinisivaram", "createdAt": "2021-08-27T11:53:56Z", "path": "core/src/main/scala/kafka/server/KafkaApis.scala", "diffHunk": "@@ -1222,16 +1238,23 @@ class KafkaApis(val requestChannel: RequestChannel,\n     }\n \n     val unauthorizedForCreateTopicMetadata = unauthorizedForCreateTopics.map(topic =>\n-      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, isInternal(topic), util.Collections.emptyList()))\n+      // Set topicId to zero since we will never create topic which topicId\n+      metadataResponseTopic(Errors.TOPIC_AUTHORIZATION_FAILED, topic, Uuid.ZERO_UUID, isInternal(topic), util.Collections.emptyList()))\n \n     // do not disclose the existence of topics unauthorized for Describe, so we've not even checked if they exist or not\n     val unauthorizedForDescribeTopicMetadata =\n       // In case of all topics, don't include topics unauthorized for Describe\n       if ((requestVersion == 0 && (metadataRequest.topics == null || metadataRequest.topics.isEmpty)) || metadataRequest.isAllTopics)\n         Set.empty[MetadataResponseTopic]\n-      else\n+      else if (useTopicId) {\n+        // Topic IDs are not considered sensitive information, so we TOPIC_AUTHORIZATION_FAILED is OK", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM4OTA5NA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697389094", "bodyText": "Maybe just say ZERO_UUID (Or change case to Uuid", "author": "rajinisivaram", "createdAt": "2021-08-27T12:08:54Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -568,6 +619,10 @@ object TopicCommand extends Logging {\n         throw new IllegalArgumentException(\"--bootstrap-server must be specified\")\n       if (has(describeOpt) && has(ifExistsOpt))\n         CommandLineUtils.checkRequiredArgs(parser, options, topicOpt)\n+      if(has(describeOpt) && has(ifExistsOpt)) {\n+        if (has(topicOpt) == has(topicIdOpt))\n+          println(\"Only topic id will be used when both --topic and --topic-id are specified and topicId is not UUID.ZERO_UUID\")", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM5MDYxNA==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697390614", "bodyText": "Should this be && since the error below refers to both being specified? And should there an error for both not being specified?", "author": "rajinisivaram", "createdAt": "2021-08-27T12:11:21Z", "path": "core/src/main/scala/kafka/admin/TopicCommand.scala", "diffHunk": "@@ -568,6 +619,10 @@ object TopicCommand extends Logging {\n         throw new IllegalArgumentException(\"--bootstrap-server must be specified\")\n       if (has(describeOpt) && has(ifExistsOpt))\n         CommandLineUtils.checkRequiredArgs(parser, options, topicOpt)\n+      if(has(describeOpt) && has(ifExistsOpt)) {\n+        if (has(topicOpt) == has(topicIdOpt))", "originalCommit": "140ade867813302014765010cc78d9b1b92af821", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzUzNTIzMw==", "url": "https://github.com/apache/kafka/pull/9769#discussion_r697535233", "bodyText": "Thank you for this reminding, I also fixed a bug when using --topic-id and --if-exists.", "author": "dengziming", "createdAt": "2021-08-27T15:33:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5NzM5MDYxNA=="}], "type": "inlineReview"}, {"oid": "562316205eab5f90f37626ea6e185f920423e450", "url": "https://github.com/apache/kafka/commit/562316205eab5f90f37626ea6e185f920423e450", "message": "KAFKA-10774;; Add topicNames in MetadataCache\nKAFKA-10774; add topicId in TopicCommand\nGate  topic IDs behind IBP 2.8.1\nadd ITCase of metadata request edge case between different ipb\nAdd Unauthorized unit test\nuse matchSameElements replace EasyMock.eq since the order of the request is unknown\nresolve conflicts\n\ncheck KAFKA-12394\n\ncheck KAFKA-12701", "committedDate": "2021-08-27T14:17:33Z", "type": "commit"}, {"oid": "605259eb30cabe505c908a882e66db4ab898e8a8", "url": "https://github.com/apache/kafka/commit/605259eb30cabe505c908a882e66db4ab898e8a8", "message": "check KAFKA-12976", "committedDate": "2021-08-27T14:17:33Z", "type": "commit"}, {"oid": "e3ae1b209efd98423417b4e964bd02fe949e9dca", "url": "https://github.com/apache/kafka/commit/e3ae1b209efd98423417b4e964bd02fe949e9dca", "message": "check KAFKA-13011: using TopicCollection", "committedDate": "2021-08-27T14:17:33Z", "type": "commit"}, {"oid": "97b45f64eaf931cf0ecd12c42f4a14dfef4fb5ec", "url": "https://github.com/apache/kafka/commit/97b45f64eaf931cf0ecd12c42f4a14dfef4fb5ec", "message": "resolve comments and rebase trunk", "committedDate": "2021-08-27T14:17:33Z", "type": "commit"}, {"oid": "0965346b078103da3ecd3f70d5cef75ada680dd1", "url": "https://github.com/apache/kafka/commit/0965346b078103da3ecd3f70d5cef75ada680dd1", "message": "rebase trunk and resolve conflicts", "committedDate": "2021-08-27T14:17:34Z", "type": "commit"}, {"oid": "ced95b09c0b581f35911b36944e00ba514fa1963", "url": "https://github.com/apache/kafka/commit/ced95b09c0b581f35911b36944e00ba514fa1963", "message": "more feedback from comments", "committedDate": "2021-08-27T14:17:34Z", "type": "commit"}, {"oid": "acc8ba9bcc77f280e33d68976cf0bf03456d65fc", "url": "https://github.com/apache/kafka/commit/acc8ba9bcc77f280e33d68976cf0bf03456d65fc", "message": "remove usage of deprecated methods", "committedDate": "2021-08-27T14:17:34Z", "type": "commit"}, {"oid": "9a7a3953d5ecb8b22082bbf38312a4866e340076", "url": "https://github.com/apache/kafka/commit/9a7a3953d5ecb8b22082bbf38312a4866e340076", "message": "more feedbacks from comments", "committedDate": "2021-08-27T14:17:34Z", "type": "commit"}, {"oid": "d0bc3cd349dcc356f90f343bb57c9e6ed478e62f", "url": "https://github.com/apache/kafka/commit/d0bc3cd349dcc356f90f343bb57c9e6ed478e62f", "message": "more feedbacks from rajinisivaram", "committedDate": "2021-08-27T15:22:52Z", "type": "commit"}, {"oid": "d0bc3cd349dcc356f90f343bb57c9e6ed478e62f", "url": "https://github.com/apache/kafka/commit/d0bc3cd349dcc356f90f343bb57c9e6ed478e62f", "message": "more feedbacks from rajinisivaram", "committedDate": "2021-08-27T15:22:52Z", "type": "forcePushed"}, {"oid": "a443b4f7fec883ecb9cb51fb919f910fc661344c", "url": "https://github.com/apache/kafka/commit/a443b4f7fec883ecb9cb51fb919f910fc661344c", "message": "fix error version", "committedDate": "2021-08-27T16:24:19Z", "type": "commit"}]}