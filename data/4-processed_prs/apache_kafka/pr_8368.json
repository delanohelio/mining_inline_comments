{"pr_number": 8368, "pr_title": "KAFKA-9770: Close underlying state store also when flush throws", "pr_createdAt": "2020-03-26T21:53:15Z", "pr_url": "https://github.com/apache/kafka/pull/8368", "timeline": [{"oid": "4f463fb4f5d442ab53f7c59df69d0f1179e93e8e", "url": "https://github.com/apache/kafka/commit/4f463fb4f5d442ab53f7c59df69d0f1179e93e8e", "message": "KAFKA-9770: Close underlying state store also when flush throws\n\nWhen a caching state store is closed it calls its flush() method.\nIf flush() throws an exception the underlying state store is not closed.\n\nThis commit ensures that state stores underlying a caching state store\nare closed even when flush() throws.", "committedDate": "2020-03-26T21:52:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkyOTg2NQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r398929865", "bodyText": "Why did you change the order of super.close() vs cache.close() ?", "author": "mjsax", "createdAt": "2020-03-26T22:27:05Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingSessionStore.java", "diffHunk": "@@ -232,9 +232,15 @@ public void flush() {\n     }\n \n     public void close() {\n-        flush();\n-        cache.close(cacheName);\n-        super.close();\n+        try {\n+            flush();\n+        } finally {\n+            try {\n+                super.close();\n+            } finally {\n+                cache.close(cacheName);", "originalCommit": "4f463fb4f5d442ab53f7c59df69d0f1179e93e8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzODI3MQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r398938271", "bodyText": "Looking at the implementation, I don't think the order matters. But IIRC, it's dubious to throw exceptions in a finally block because it creates ambiguity about which exception should ultimately get thrown.\nPerhaps we could instead just capture the exceptions like:\nfinal List<RuntimeException> suppressed = new LinkedList();\ncapture(this::flush, suppressed);\ncapture(() -> cache.close(cacheName), suppressed);\ncapture(wrapped::close, suppressed);\nif (suppressed.isEmpty()) {\n  return;\nelse {\n  final RuntimeException toThrow = new RuntimeException(\"Caught an exception while closing \" + storeName);\n  for(final RuntimeException e : suppressed) {\n    toThrow.addSuppressed(e);\n  }\n  throw toThrow;\n}\nWDYT?", "author": "vvcephei", "createdAt": "2020-03-26T22:49:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkyOTg2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTEyOTUzNA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399129534", "bodyText": "Why did you change the order of super.close() vs cache.close() ?\n\nIn CachingKeyValueStore, the order is as I did in this PR. So I wanted to make the order consistent across Caching*Store and thought this order is the one that makes more sense because I felt it is more important to close the underlying state store than the cache. But in the end, it doesn't make any difference.", "author": "cadonna", "createdAt": "2020-03-27T09:19:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkyOTg2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE0MDAwNw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399140007", "bodyText": "But IIRC, it's dubious to throw exceptions in a finally block because it creates ambiguity about which exception should ultimately get thrown.\n\nMakes sense.", "author": "cadonna", "createdAt": "2020-03-27T09:37:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkyOTg2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUxMzc3NA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399513774", "bodyText": "because it creates ambiguity\n\nAFAIK, it's not ambiguous: a later thrown exception would \"overwrite\" the former.\nBut it's better to collect all exceptions anyway.", "author": "mjsax", "createdAt": "2020-03-27T20:11:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkyOTg2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMDU1Ng==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r398930556", "bodyText": "Nit: Why not import Bytes?", "author": "mjsax", "createdAt": "2020-03-26T22:28:57Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/CachingSessionStoreTest.java", "diffHunk": "@@ -67,27 +70,30 @@\n     private static final int MAX_CACHE_SIZE_BYTES = 600;\n     private static final Long DEFAULT_TIMESTAMP = 10L;\n     private static final long SEGMENT_INTERVAL = 100L;\n+    private static final String TOPIC = \"topic\";\n+    private static final String CACHE_NAMESPACE = \"0_0-store-name\";\n+\n     private final Bytes keyA = Bytes.wrap(\"a\".getBytes());\n     private final Bytes keyAA = Bytes.wrap(\"aa\".getBytes());\n     private final Bytes keyB = Bytes.wrap(\"b\".getBytes());\n \n+    private SessionStore<org.apache.kafka.common.utils.Bytes, byte[]> sessionStore =", "originalCommit": "4f463fb4f5d442ab53f7c59df69d0f1179e93e8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE0Mjc2NA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399142764", "bodyText": "Because it was late and I missed it ;-)", "author": "cadonna", "createdAt": "2020-03-27T09:42:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMDU1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMjk3MQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r398932971", "bodyText": "Should we verify regardless of the NPE?", "author": "vvcephei", "createdAt": "2020-03-26T22:35:08Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java", "diffHunk": "@@ -107,32 +108,98 @@ public void shouldSetFlushListener() {\n     public void shouldAvoidFlushingDeletionsWithoutDirtyKeys() {\n         final int added = addItemsToCache();\n         // all dirty entries should have been flushed\n-        assertEquals(added, underlyingStore.approximateNumEntries());\n+        assertEquals(added, keyValueStore.approximateNumEntries());\n         assertEquals(added, cacheFlushListener.forwarded.size());\n \n         store.put(bytesKey(\"key\"), bytesValue(\"value\"));\n-        assertEquals(added, underlyingStore.approximateNumEntries());\n+        assertEquals(added, keyValueStore.approximateNumEntries());\n         assertEquals(added, cacheFlushListener.forwarded.size());\n \n         store.put(bytesKey(\"key\"), null);\n         store.flush();\n-        assertEquals(added, underlyingStore.approximateNumEntries());\n+        assertEquals(added, keyValueStore.approximateNumEntries());\n         assertEquals(added, cacheFlushListener.forwarded.size());\n     }\n \n+    @Test\n+    public void shouldCloseWrappedStoreAfterErrorDuringCacheFlush() {\n+        setUpCloseTests();\n+        cache.flush(CACHE_NAMESPACE);\n+        EasyMock.expectLastCall().andThrow(new NullPointerException(\"Simulating an error on flush\"));\n+        EasyMock.replay(cache);\n+        EasyMock.reset(keyValueStore);\n+        keyValueStore.close();\n+        EasyMock.replay(keyValueStore);\n+\n+        try {\n+            store.close();\n+        } catch (final NullPointerException npe) {\n+            EasyMock.verify(keyValueStore);", "originalCommit": "4f463fb4f5d442ab53f7c59df69d0f1179e93e8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE1MzcyMA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399153720", "bodyText": "I changed NullPointerException to RuntimeException (also due to the changes to not throw in a finally block). The test verifies that the underlying state store is closed if a runtime exception is thrown. I think that it is fine now.", "author": "cadonna", "createdAt": "2020-03-27T10:01:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMjk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM1OTE2OQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399359169", "bodyText": "Ok, I was just concerned that if the exception weren't thrown, we would be verifying nothing, and the test would pass silently, but if you prefer this structure, then I'm fine with it.", "author": "vvcephei", "createdAt": "2020-03-27T15:44:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMjk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQxMjg4Mg==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399412882", "bodyText": "The missing piece is a unit test that verifies that close() of the underlying store is called when close() of the caching store is called.", "author": "cadonna", "createdAt": "2020-03-27T17:04:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMjk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQxMzc1Ng==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399413756", "bodyText": "Wait, there are tests that do that indirectly.", "author": "cadonna", "createdAt": "2020-03-27T17:05:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMjk3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMzQxNQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r398933415", "bodyText": "Not sure about this variable rename, since the CachingKeyValueStore is also a \"keyValueStore\". I.e., the important thing about the one we're declaring here is that it's the \"underlying\" one.", "author": "vvcephei", "createdAt": "2020-03-26T22:36:20Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java", "diffHunk": "@@ -56,25 +57,25 @@\n \n public class CachingKeyValueStoreTest extends AbstractKeyValueStoreTest {\n \n+    private final static String TOPIC = \"topic\";\n+    private static final String CACHE_NAMESPACE = \"0_0-store-name\";\n     private final int maxCacheSizeBytes = 150;\n     private InternalMockProcessorContext context;\n     private CachingKeyValueStore store;\n-    private InMemoryKeyValueStore underlyingStore;\n+    private KeyValueStore<Bytes, byte[]> keyValueStore;", "originalCommit": "4f463fb4f5d442ab53f7c59df69d0f1179e93e8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTE0OTIzMA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399149230", "bodyText": "Ack", "author": "cadonna", "createdAt": "2020-03-27T09:53:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkzMzQxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODkxOTAyMg==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r398919022", "bodyText": "@guozhangwang  proposed just to call cache.flush() instead of flush(). I have not done that because in some caching state stores flush() is either synchronized or it contains locks or it neither the one nor the other. I wanted first to clarify on that before I make this change. So I guess flush() needs to be synchronized because of Interactive Queries on the underlying state store, right? Does the cache also need to be synchronized?", "author": "cadonna", "createdAt": "2020-03-26T22:01:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingSessionStore.java", "diffHunk": "@@ -232,9 +232,15 @@ public void flush() {\n     }\n \n     public void close() {\n-        flush();\n-        cache.close(cacheName);\n-        super.close();\n+        try {\n+            flush();", "originalCommit": "4f463fb4f5d442ab53f7c59df69d0f1179e93e8e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "31115b7dcdfc67dc23703a5884d19f74cad5e52f", "url": "https://github.com/apache/kafka/commit/31115b7dcdfc67dc23703a5884d19f74cad5e52f", "message": "Include feedback", "committedDate": "2020-03-27T10:34:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQwMzYxMQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399403611", "bodyText": "As we discussed offline, I think here we can just call cache.flush(cacheName) instead of this.flush right?", "author": "guozhangwang", "createdAt": "2020-03-27T16:49:55Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -278,14 +279,17 @@ public void flush() {\n \n     @Override\n     public void close() {\n-        try {\n-            flush();\n-        } finally {\n-            try {\n-                super.close();\n-            } finally {\n-                cache.close(cacheName);\n+        final List<RuntimeException> suppressed = new ArrayList<>();\n+        captureException(this::flush, suppressed);", "originalCommit": "31115b7dcdfc67dc23703a5884d19f74cad5e52f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQwODQ0OQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399408449", "bodyText": "See my comment #8368 (comment)", "author": "cadonna", "createdAt": "2020-03-27T16:57:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQwMzYxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUxNTMzNw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399515337", "bodyText": "Should we have a \"global utility\" class that unifies all helper methods we use throughout the whole code base? (Not in this PR thought, but as a follow up)", "author": "mjsax", "createdAt": "2020-03-27T20:14:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/WrappedStateStore.java", "diffHunk": "@@ -92,4 +94,12 @@ public void close() {\n     public S wrapped() {\n         return wrapped;\n     }\n+\n+    protected static void captureException(final Runnable action, final List<RuntimeException> suppressed) {", "originalCommit": "31115b7dcdfc67dc23703a5884d19f74cad5e52f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUyNDAwMQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399524001", "bodyText": "Yeah, I was thinking that, but didn't mention it for fear of expanding the scope of this PR. We could use such a utility all over the place when we need to capture exceptions in closing.\nI'll send a follow-up PR.", "author": "vvcephei", "createdAt": "2020-03-27T20:34:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUxNTMzNw=="}], "type": "inlineReview"}, {"oid": "cde84b2b86b21259e27516fc7c4bdf010206108f", "url": "https://github.com/apache/kafka/commit/cde84b2b86b21259e27516fc7c4bdf010206108f", "message": "CR comments and also fix and test bug for Metered stores", "committedDate": "2020-03-27T22:32:46Z", "type": "commit"}, {"oid": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "url": "https://github.com/apache/kafka/commit/c51b89b829dbd9f306f9c94e085f978155cc1eb3", "message": "null check", "committedDate": "2020-03-27T22:52:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU2OTk2OA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399569968", "bodyText": "I did this because I was trying to debug the \"remove all sensors\" method, and I needed to debug this method, but was unable to. I left the change here for the same reason.", "author": "vvcephei", "createdAt": "2020-03-27T22:41:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -402,11 +402,13 @@ public final Sensor storeLevelSensor(final String threadId,\n         final String key = storeSensorPrefix(threadId, taskId, storeName);\n         synchronized (storeLevelSensors) {\n             final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n-            return Optional.ofNullable(metrics.getSensor(fullSensorName))\n-                .orElseGet(() -> {\n-                    storeLevelSensors.computeIfAbsent(key, ignored -> new LinkedList<>()).push(fullSensorName);\n-                    return metrics.sensor(fullSensorName, recordingLevel, parents);\n-                });\n+            final Sensor sensor = metrics.getSensor(fullSensorName);\n+            if (sensor == null) {\n+                storeLevelSensors.computeIfAbsent(key, ignored -> new LinkedList<>()).push(fullSensorName);\n+                return metrics.sensor(fullSensorName, recordingLevel, parents);\n+            } else {\n+                return sensor;\n+            }", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NjQ2Ng==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399576466", "bodyText": "Ack. Works for me (in fact, is like the code better after you change anyway :) )", "author": "mjsax", "createdAt": "2020-03-27T23:06:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU2OTk2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDU1OQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399570559", "bodyText": "We need to check again after we grab the lock, otherwise the store might get closed after we check but before we grab the lock. Once we get the lock, we're guaranteed that this block is serialized wrt close(). But we can still check beforehand to avoid grabbing the lock if it is closed.", "author": "vvcephei", "createdAt": "2020-03-27T22:43:26Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -119,6 +123,7 @@ public void put(final Bytes key,\n         validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NjY3MA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399576670", "bodyText": "Why would it not be sufficient to only check after we got the lock?", "author": "mjsax", "createdAt": "2020-03-27T23:06:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDU1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MDM1MQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399580351", "bodyText": "It would be sufficient. I assumed that we were checking before the lock to avoid synchronization overhead, so I left that in place.", "author": "vvcephei", "createdAt": "2020-03-27T23:22:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDU1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDg5OQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399570899", "bodyText": "They do the same thing, but the majority of calls are on wrapped().", "author": "vvcephei", "createdAt": "2020-03-27T22:44:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -267,25 +277,32 @@ public long approximateNumEntries() {\n \n     @Override\n     public void flush() {\n+        validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();\n             cache.flush(cacheName);\n-            super.flush();\n+            wrapped().flush();", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTEwNw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399571107", "bodyText": "This check means we don't have to construct the exception message string if we're not going to throw.", "author": "vvcephei", "createdAt": "2020-03-27T22:45:20Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -267,25 +277,32 @@ public long approximateNumEntries() {\n \n     @Override\n     public void flush() {\n+        validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();\n             cache.flush(cacheName);\n-            super.flush();\n+            wrapped().flush();\n         } finally {\n             lock.writeLock().unlock();\n         }\n     }\n \n     @Override\n     public void close() {\n+        lock.writeLock().lock();\n         try {\n-            flush();\n-        } finally {\n-            try {\n-                super.close();\n-            } finally {\n-                cache.close(cacheName);\n+            final LinkedList<RuntimeException> suppressed = executeAll(\n+                () -> cache.flush(cacheName),\n+                () -> cache.close(cacheName),\n+                wrapped()::close\n+            );\n+            if (suppressed != null && !suppressed.isEmpty()) {", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NzU2NQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399577565", "bodyText": "The check itself (ie, for isEmpty() makes sense) but I would still try to avoid the null", "author": "mjsax", "createdAt": "2020-03-27T23:10:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTEwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTIzMw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399571233", "bodyText": "This is what @guozhangwang was asking for.", "author": "vvcephei", "createdAt": "2020-03-27T22:45:47Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -267,25 +277,32 @@ public long approximateNumEntries() {\n \n     @Override\n     public void flush() {\n+        validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();\n             cache.flush(cacheName);\n-            super.flush();\n+            wrapped().flush();\n         } finally {\n             lock.writeLock().unlock();\n         }\n     }\n \n     @Override\n     public void close() {\n+        lock.writeLock().lock();\n         try {\n-            flush();\n-        } finally {\n-            try {\n-                super.close();\n-            } finally {\n-                cache.close(cacheName);\n+            final LinkedList<RuntimeException> suppressed = executeAll(\n+                () -> cache.flush(cacheName),", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NzQxMQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399577411", "bodyText": "Like it!", "author": "mjsax", "createdAt": "2020-03-27T23:10:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTU0Nw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399571547", "bodyText": "I just plunked this class where it was needed right now; we can move it later if we want to use it elsewhere.", "author": "vvcephei", "createdAt": "2020-03-27T22:47:04Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ExceptionUtils.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.state.internals;", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3Nzc0MQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399577741", "bodyText": "Maybe we should a new package org.apache.kafka.streams.internals ?", "author": "mjsax", "createdAt": "2020-03-27T23:11:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTU0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTYwMDQ1Mw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399600453", "bodyText": "Yeah, something like that sounds good. Still, I'd like to select the right location after we need to use it from two or more different packages.", "author": "vvcephei", "createdAt": "2020-03-28T01:17:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTU0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTYzNg==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399571636", "bodyText": "The first exception will be the \"cause\"", "author": "vvcephei", "createdAt": "2020-03-27T22:47:27Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ExceptionUtils.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.state.internals;\n+\n+import java.util.LinkedList;\n+\n+final class ExceptionUtils {\n+    private ExceptionUtils() {}\n+\n+    static LinkedList<RuntimeException> executeAll(final Runnable... actions) {\n+        LinkedList<RuntimeException> suppressed = null;\n+        for (final Runnable action : actions) {\n+            try {\n+                action.run();\n+            } catch (final RuntimeException exception) {\n+                if (suppressed == null) {\n+                    suppressed = new LinkedList<>();\n+                }\n+                suppressed.add(exception);\n+            }\n+        }\n+        return suppressed;\n+    }\n+\n+    static void throwSuppressed(final String message, final LinkedList<RuntimeException> suppressed) {\n+        if (suppressed != null && !suppressed.isEmpty()) {\n+            final RuntimeException firstCause = suppressed.pollFirst();\n+            final RuntimeException toThrow = new RuntimeException(message, firstCause);", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTc1OQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399571759", "bodyText": "The rest of the exceptions are listed as \"suppressed by\" the exception we're throwing.", "author": "vvcephei", "createdAt": "2020-03-27T22:47:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ExceptionUtils.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.state.internals;\n+\n+import java.util.LinkedList;\n+\n+final class ExceptionUtils {\n+    private ExceptionUtils() {}\n+\n+    static LinkedList<RuntimeException> executeAll(final Runnable... actions) {\n+        LinkedList<RuntimeException> suppressed = null;\n+        for (final Runnable action : actions) {\n+            try {\n+                action.run();\n+            } catch (final RuntimeException exception) {\n+                if (suppressed == null) {\n+                    suppressed = new LinkedList<>();\n+                }\n+                suppressed.add(exception);\n+            }\n+        }\n+        return suppressed;\n+    }\n+\n+    static void throwSuppressed(final String message, final LinkedList<RuntimeException> suppressed) {\n+        if (suppressed != null && !suppressed.isEmpty()) {\n+            final RuntimeException firstCause = suppressed.pollFirst();\n+            final RuntimeException toThrow = new RuntimeException(message, firstCause);\n+            for (final RuntimeException e : suppressed) {\n+                toThrow.addSuppressed(e);", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MjE5Nw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399572197", "bodyText": "This is a related bug I fixed. It's basically the same thing, but for Metered store. There's no need to use the new util when we're just dealing with one potentially-throwing operation.", "author": "vvcephei", "createdAt": "2020-03-27T22:49:32Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStore.java", "diffHunk": "@@ -199,8 +199,11 @@ public long approximateNumEntries() {\n \n     @Override\n     public void close() {\n-        super.close();\n-        streamsMetrics.removeAllStoreLevelSensors(threadId, taskId, name());\n+        try {\n+            wrapped().close();\n+        } finally {\n+            streamsMetrics.removeAllStoreLevelSensors(threadId, taskId, name());\n+        }", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MzI5MA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399573290", "bodyText": "These tests were missing, so I added them.", "author": "vvcephei", "createdAt": "2020-03-27T22:53:24Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStoreTest.java", "diffHunk": "@@ -311,8 +311,44 @@ public void shouldNotSetFlushListenerOnWrappedNoneCachingStore() {\n         assertFalse(metered.setFlushListener(null, false));\n     }\n \n+    @Test\n+    public void shouldRemoveMetricsOnClose() {", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MzM5NQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399573395", "bodyText": "These tests are the ones that cover the bug I fixed.", "author": "vvcephei", "createdAt": "2020-03-27T22:53:47Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/MeteredKeyValueStoreTest.java", "diffHunk": "@@ -311,8 +311,44 @@ public void shouldNotSetFlushListenerOnWrappedNoneCachingStore() {\n         assertFalse(metered.setFlushListener(null, false));\n     }\n \n+    @Test\n+    public void shouldRemoveMetricsOnClose() {\n+        inner.close();\n+        expectLastCall();\n+        init(); // replays \"inner\"\n+\n+        // There's always a \"count\" metric registered\n+        assertThat(storeMetrics(), not(empty()));\n+        metered.close();\n+        assertThat(storeMetrics(), empty());\n+        verify(inner);\n+    }\n+\n+    @Test\n+    public void shouldRemoveMetricsEvenIfWrappedStoreThrowsOnClose() {", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MjczNw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399572737", "bodyText": "Why this rewrite?", "author": "mjsax", "createdAt": "2020-03-27T22:51:31Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -402,11 +402,13 @@ public final Sensor storeLevelSensor(final String threadId,\n         final String key = storeSensorPrefix(threadId, taskId, storeName);\n         synchronized (storeLevelSensors) {\n             final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n-            return Optional.ofNullable(metrics.getSensor(fullSensorName))\n-                .orElseGet(() -> {\n-                    storeLevelSensors.computeIfAbsent(key, ignored -> new LinkedList<>()).push(fullSensorName);\n-                    return metrics.sensor(fullSensorName, recordingLevel, parents);\n-                });\n+            final Sensor sensor = metrics.getSensor(fullSensorName);\n+            if (sensor == null) {\n+                storeLevelSensors.computeIfAbsent(key, ignored -> new LinkedList<>()).push(fullSensorName);\n+                return metrics.sensor(fullSensorName, recordingLevel, parents);\n+            } else {\n+                return sensor;\n+            }", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NTc1MA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399575750", "bodyText": "I did this because I was trying to debug the \"remove all sensors\" method, and I needed to debug this method, but was unable to. I left the change here for the same reason.", "author": "vvcephei", "createdAt": "2020-03-27T23:03:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MjczNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3Mjk0Mg==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399572942", "bodyText": "Why do we  call this a second time? Also, it seems to be a very generic pattern for all method calls -- can we extract this in some private helper method ?", "author": "mjsax", "createdAt": "2020-03-27T22:52:16Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -119,6 +123,7 @@ public void put(final Bytes key,\n         validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();", "originalCommit": "cde84b2b86b21259e27516fc7c4bdf010206108f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NTg2MA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399575860", "bodyText": "We need to check again after we grab the lock, otherwise the store might get closed after we check but before we grab the lock. Once we get the lock, we're guaranteed that this block is serialized wrt close(). But we can still check beforehand to avoid grabbing the lock if it is closed.", "author": "vvcephei", "createdAt": "2020-03-27T23:03:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3Mjk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NjEwNQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399576105", "bodyText": "We can extract a helper, but maybe we can do that in a follow-up at least, since the concurrency controls needs to be standardized across all the caching stores anyway.", "author": "vvcephei", "createdAt": "2020-03-27T23:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3Mjk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MTM4OA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399581388", "bodyText": "Ack.", "author": "mjsax", "createdAt": "2020-03-27T23:27:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3Mjk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3Mzg2NA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399573864", "bodyText": "Isn't this the same thing?", "author": "mjsax", "createdAt": "2020-03-27T22:55:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -267,25 +277,32 @@ public long approximateNumEntries() {\n \n     @Override\n     public void flush() {\n+        validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();\n             cache.flush(cacheName);\n-            super.flush();\n+            wrapped().flush();", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NjMxMg==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399576312", "bodyText": "They do the same thing, but the majority of calls are on wrapped().", "author": "vvcephei", "createdAt": "2020-03-27T23:05:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3Mzg2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NDAxOA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399574018", "bodyText": "Compare my comment below. We should avoid returning null to avoid the necessity of a null check.", "author": "mjsax", "createdAt": "2020-03-27T22:56:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -267,25 +277,32 @@ public long approximateNumEntries() {\n \n     @Override\n     public void flush() {\n+        validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();\n             cache.flush(cacheName);\n-            super.flush();\n+            wrapped().flush();\n         } finally {\n             lock.writeLock().unlock();\n         }\n     }\n \n     @Override\n     public void close() {\n+        lock.writeLock().lock();\n         try {\n-            flush();\n-        } finally {\n-            try {\n-                super.close();\n-            } finally {\n-                cache.close(cacheName);\n+            final LinkedList<RuntimeException> suppressed = executeAll(\n+                () -> cache.flush(cacheName),\n+                () -> cache.close(cacheName),\n+                wrapped()::close\n+            );\n+            if (suppressed != null && !suppressed.isEmpty()) {", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NDMwMg==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399574302", "bodyText": "Why not make it final and return an empty list? It seems better to avoid using null if possible", "author": "mjsax", "createdAt": "2020-03-27T22:57:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ExceptionUtils.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.state.internals;\n+\n+import java.util.LinkedList;\n+\n+final class ExceptionUtils {\n+    private ExceptionUtils() {}\n+\n+    static LinkedList<RuntimeException> executeAll(final Runnable... actions) {\n+        LinkedList<RuntimeException> suppressed = null;", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NTUzMQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399575531", "bodyText": "Just to avoid allocating an empty list in the common case where we don't throw any exceptions.", "author": "vvcephei", "createdAt": "2020-03-27T23:02:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NDMwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3ODMzMw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399578333", "bodyText": "Hmmm... I see your point, but such short living objects should not be much of an overhead? But forgetting to check for null caller side is a potential source for bugs?", "author": "mjsax", "createdAt": "2020-03-27T23:13:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NDMwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MDA3NA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399580074", "bodyText": "Sounds good. I prefer it the way you suggest anyway. I'll change it.", "author": "vvcephei", "createdAt": "2020-03-27T23:21:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NDMwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NDY5OQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399574699", "bodyText": "Same here: can we avoid potential null values?", "author": "mjsax", "createdAt": "2020-03-27T22:58:48Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ExceptionUtils.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.state.internals;\n+\n+import java.util.LinkedList;\n+\n+final class ExceptionUtils {\n+    private ExceptionUtils() {}\n+\n+    static LinkedList<RuntimeException> executeAll(final Runnable... actions) {\n+        LinkedList<RuntimeException> suppressed = null;\n+        for (final Runnable action : actions) {\n+            try {\n+                action.run();\n+            } catch (final RuntimeException exception) {\n+                if (suppressed == null) {\n+                    suppressed = new LinkedList<>();\n+                }\n+                suppressed.add(exception);\n+            }\n+        }\n+        return suppressed;\n+    }\n+\n+    static void throwSuppressed(final String message, final LinkedList<RuntimeException> suppressed) {\n+        if (suppressed != null && !suppressed.isEmpty()) {", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3ODg2MA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399578860", "bodyText": "Why not throw a general RuntimeException but a NPE?", "author": "mjsax", "createdAt": "2020-03-27T23:16:27Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java", "diffHunk": "@@ -121,21 +122,71 @@ public void shouldAvoidFlushingDeletionsWithoutDirtyKeys() {\n     }\n \n     @Test\n-    public void shouldCloseAfterErrorWithFlush() {\n+    public void shouldCloseWrappedStoreAfterErrorDuringCacheFlush() {\n+        setUpCloseTests();\n+        cache.flush(CACHE_NAMESPACE);\n+        EasyMock.expectLastCall().andThrow(new NullPointerException(\"Simulating an error on flush\"));", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3OTk4MQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399579981", "bodyText": "This was Bruno's test; I just left them alone.", "author": "vvcephei", "createdAt": "2020-03-27T23:20:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3ODg2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU5OTc0NA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399599744", "bodyText": "This was poorly stated, what I meant was that I was reluctant to change parts of the PR that had already been approved.", "author": "vvcephei", "createdAt": "2020-03-28T01:11:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3ODg2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3OTAyNA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399579024", "bodyText": "Why not use assertThrows ?", "author": "mjsax", "createdAt": "2020-03-27T23:17:13Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java", "diffHunk": "@@ -121,21 +122,71 @@ public void shouldAvoidFlushingDeletionsWithoutDirtyKeys() {\n     }\n \n     @Test\n-    public void shouldCloseAfterErrorWithFlush() {\n+    public void shouldCloseWrappedStoreAfterErrorDuringCacheFlush() {\n+        setUpCloseTests();\n+        cache.flush(CACHE_NAMESPACE);\n+        EasyMock.expectLastCall().andThrow(new NullPointerException(\"Simulating an error on flush\"));\n+        EasyMock.replay(cache);\n+        EasyMock.reset(underlyingStore);\n+        underlyingStore.close();\n+        EasyMock.replay(underlyingStore);\n+\n+        try {\n+            store.close();", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MDE4MQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399580181", "bodyText": "What do we actually test here? Closing the underlying store is the last thing we do, so it does not affect the happy path of flushing/closing the cache (what we verify at the end). Not sure what the value of this test is?", "author": "mjsax", "createdAt": "2020-03-27T23:21:54Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/CachingKeyValueStoreTest.java", "diffHunk": "@@ -121,21 +122,71 @@ public void shouldAvoidFlushingDeletionsWithoutDirtyKeys() {\n     }\n \n     @Test\n-    public void shouldCloseAfterErrorWithFlush() {\n+    public void shouldCloseWrappedStoreAfterErrorDuringCacheFlush() {\n+        setUpCloseTests();\n+        cache.flush(CACHE_NAMESPACE);\n+        EasyMock.expectLastCall().andThrow(new NullPointerException(\"Simulating an error on flush\"));\n+        EasyMock.replay(cache);\n+        EasyMock.reset(underlyingStore);\n+        underlyingStore.close();\n+        EasyMock.replay(underlyingStore);\n+\n+        try {\n+            store.close();\n+        } catch (final RuntimeException exception) {\n+            EasyMock.verify(underlyingStore);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldCloseWrappedStoreAfterErrorDuringCacheClose() {\n+        setUpCloseTests();\n+        cache.flush(CACHE_NAMESPACE);\n+        cache.close(CACHE_NAMESPACE);\n+        EasyMock.expectLastCall().andThrow(new NullPointerException(\"Simulating an error on close\"));\n+        EasyMock.replay(cache);\n+        EasyMock.reset(underlyingStore);\n+        underlyingStore.close();\n+        EasyMock.replay(underlyingStore);\n+\n         try {\n-            cache = EasyMock.niceMock(ThreadCache.class);\n-            context = new InternalMockProcessorContext(null, null, null, null, cache);\n-            context.setRecordContext(new ProcessorRecordContext(10, 0, 0, topic, null));\n-            store.init(context, null);\n-            cache.flush(\"0_0-store\");\n-            EasyMock.expectLastCall().andThrow(new NullPointerException(\"Simulating an error on flush\"));\n-            EasyMock.replay(cache);\n             store.close();\n-        } catch (final NullPointerException npe) {\n-            assertFalse(underlyingStore.isOpen());\n+        } catch (final RuntimeException exception) {\n+            EasyMock.verify(underlyingStore);\n         }\n     }\n \n+    @Test\n+    public void shouldCloseCacheAfterErrorDuringStateStoreClose() {", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDAzMDgzNA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r400030834", "bodyText": "I see what you mean. IMO we should test also this, because tests are also here to make refactoring safe. Let's assume somebody changes the order of the closes, we would still have a check.", "author": "cadonna", "createdAt": "2020-03-30T08:58:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MDE4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4NTUyMw==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399585523", "bodyText": "Do we need to validate twice before grabbing the lock? Maybe only the validation at line 283 is sufficient.", "author": "guozhangwang", "createdAt": "2020-03-27T23:46:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -267,25 +277,32 @@ public long approximateNumEntries() {\n \n     @Override\n     public void flush() {\n+        validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTYwMDMwNA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399600304", "bodyText": "Matthias felt the same, and I also agree, but I'd like to do it in a follow-on PR. I was just quickly fixing a concurrency bug on the side, since I added synchronization to close expressly for the purpose of serializing closing the store wrt these methods.\nhttps://github.com/apache/kafka/pull/8368/files/c51b89b829dbd9f306f9c94e085f978155cc1eb3#r399572942", "author": "vvcephei", "createdAt": "2020-03-28T01:16:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4NTUyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4NTg4NQ==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399585885", "bodyText": "If an exception is thrown in cache flush / close, it means we would not trigger wrapper#close, which is different from the current trunk. Is that intentional?", "author": "guozhangwang", "createdAt": "2020-03-27T23:48:20Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/CachingKeyValueStore.java", "diffHunk": "@@ -267,25 +277,32 @@ public long approximateNumEntries() {\n \n     @Override\n     public void flush() {\n+        validateStoreOpen();\n         lock.writeLock().lock();\n         try {\n+            validateStoreOpen();\n             cache.flush(cacheName);\n-            super.flush();\n+            wrapped().flush();\n         } finally {\n             lock.writeLock().unlock();\n         }\n     }\n \n     @Override\n     public void close() {\n+        lock.writeLock().lock();\n         try {\n-            flush();\n-        } finally {\n-            try {\n-                super.close();\n-            } finally {\n-                cache.close(cacheName);\n+            final LinkedList<RuntimeException> suppressed = executeAll(\n+                () -> cache.flush(cacheName),\n+                () -> cache.close(cacheName),\n+                wrapped()::close", "originalCommit": "c51b89b829dbd9f306f9c94e085f978155cc1eb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTYwMDA0Ng==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399600046", "bodyText": "iiuc, this is actually the bug that we are fixing here. On the current trunk, if flush or cache.close throws, we do not close the wrapped store. Now, with this change, we still call flush, cache.close, and wrapped().close, regardless if some of them throw.", "author": "vvcephei", "createdAt": "2020-03-28T01:14:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4NTg4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTYwNDQ5NA==", "url": "https://github.com/apache/kafka/pull/8368#discussion_r399604494", "bodyText": "Thx.", "author": "guozhangwang", "createdAt": "2020-03-28T01:52:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4NTg4NQ=="}], "type": "inlineReview"}, {"oid": "9d67f1a9b39ab41874c2c702eb4cce011afc2560", "url": "https://github.com/apache/kafka/commit/9d67f1a9b39ab41874c2c702eb4cce011afc2560", "message": "cr feedback", "committedDate": "2020-03-28T01:20:02Z", "type": "commit"}]}