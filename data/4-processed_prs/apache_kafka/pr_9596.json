{"pr_number": 9596, "pr_title": "KAFKA-10723: Fix LogManager shutdown error handling", "pr_createdAt": "2020-11-15T01:59:13Z", "pr_url": "https://github.com/apache/kafka/pull/9596", "timeline": [{"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "url": "https://github.com/apache/kafka/commit/3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "message": "KAFKA-10723: Fix LogManager shutdown error handling", "committedDate": "2020-11-15T01:59:21Z", "type": "commit"}, {"oid": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "url": "https://github.com/apache/kafka/commit/3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "message": "KAFKA-10723: Fix LogManager shutdown error handling", "committedDate": "2020-11-15T01:59:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDA1MzI5Mg==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524053292", "bodyText": "If the end user delete the log files Manually , the server cannot be stopped. and The cannot startup it again? so in this case ,how do they resolve it ?", "author": "lqjack", "createdAt": "2020-11-16T09:56:43Z", "path": "core/src/test/scala/unit/kafka/log/LogManagerTest.scala", "diffHunk": "@@ -83,6 +87,51 @@ class LogManagerTest {\n     log.appendAsLeader(TestUtils.singletonRecords(\"test\".getBytes()), leaderEpoch = 0)\n   }\n \n+  /**\n+   * Tests that all internal futures are completed before LogManager.shutdown() returns to the\n+   * caller during error situations.\n+   */\n+  @Test\n+  def testHandlingExceptionsDuringShutdown(): Unit = {\n+    logManager.shutdown()\n+\n+    // We create two directories logDir1 and logDir2 to help effectively test error handling\n+    // during LogManager.shutdown().\n+    val logDir1 = TestUtils.tempDir()\n+    val logDir2 = TestUtils.tempDir()\n+    logManager = createLogManager(Seq(logDir1, logDir2))\n+    assertEquals(2, logManager.liveLogDirs.size)\n+    logManager.startup()\n+\n+    val log1 = logManager.getOrCreateLog(new TopicPartition(name, 0), () => logConfig)\n+    val log2 = logManager.getOrCreateLog(new TopicPartition(name, 1), () => logConfig)\n+\n+    val logFile1 = new File(logDir1, name + \"-0\")\n+    assertTrue(logFile1.exists)\n+    val logFile2 = new File(logDir2, name + \"-1\")\n+    assertTrue(logFile2.exists)\n+\n+    log1.appendAsLeader(TestUtils.singletonRecords(\"test1\".getBytes()), leaderEpoch = 0)\n+    log1.takeProducerSnapshot()\n+    log1.appendAsLeader(TestUtils.singletonRecords(\"test1\".getBytes()), leaderEpoch = 0)\n+\n+    log2.appendAsLeader(TestUtils.singletonRecords(\"test2\".getBytes()), leaderEpoch = 0)\n+    log2.takeProducerSnapshot()\n+    log2.appendAsLeader(TestUtils.singletonRecords(\"test2\".getBytes()), leaderEpoch = 0)\n+\n+    // This should cause log1.close() to fail during LogManger shutdown sequence.\n+    FileUtils.deleteDirectory(logFile1)", "originalCommit": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0NTQ1OQ==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524345459", "bodyText": "Sorry I do not understand the question.", "author": "kowshik", "createdAt": "2020-11-16T15:19:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDA1MzI5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDkwNzQ3MA==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524907470", "bodyText": "What if error occur during the shutdown of the broker ?  should we log the error info to the log or just throw the exception ?", "author": "lqjack", "createdAt": "2020-11-17T06:17:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDA1MzI5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNzk4Mg==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525527982", "bodyText": "It depends on the kind of error, but we do log the error information to the log today from within KafkaServer.shutdown().", "author": "kowshik", "createdAt": "2020-11-17T21:13:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDA1MzI5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDY3MzczMg==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524673732", "bodyText": "Hmm, since we are about to shut down the JVM, should we just log a WARN here instead of throwing the exception?", "author": "junrao", "createdAt": "2020-11-16T22:22:04Z", "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -477,27 +477,41 @@ class LogManager(logDirs: Seq[File],\n       jobs(dir) = jobsForDir.map(pool.submit).toSeq\n     }\n \n+    var firstExceptionOpt: Option[Throwable] = Option.empty\n     try {\n       for ((dir, dirJobs) <- jobs) {\n-        dirJobs.foreach(_.get)\n+        val errorsForDirJobs = dirJobs.map {\n+          future =>\n+            try {\n+              future.get\n+              Option.empty\n+            } catch {\n+              case e: ExecutionException =>\n+                error(s\"There was an error in one of the threads during LogManager shutdown: ${e.getCause}\")\n+                Some(e.getCause)\n+            }\n+        }.filter{ e => e.isDefined }.map{ e => e.get }\n+\n+        if (firstExceptionOpt.isEmpty) {\n+          firstExceptionOpt = errorsForDirJobs.headOption\n+        }\n \n-        val logs = logsInDir(localLogsByDir, dir)\n+        if (errorsForDirJobs.isEmpty) {\n+          val logs = logsInDir(localLogsByDir, dir)\n \n-        // update the last flush point\n-        debug(s\"Updating recovery points at $dir\")\n-        checkpointRecoveryOffsetsInDir(dir, logs)\n+          // update the last flush point\n+          debug(s\"Updating recovery points at $dir\")\n+          checkpointRecoveryOffsetsInDir(dir, logs)\n \n-        debug(s\"Updating log start offsets at $dir\")\n-        checkpointLogStartOffsetsInDir(dir, logs)\n+          debug(s\"Updating log start offsets at $dir\")\n+          checkpointLogStartOffsetsInDir(dir, logs)\n \n-        // mark that the shutdown was clean by creating marker file\n-        debug(s\"Writing clean shutdown marker at $dir\")\n-        CoreUtils.swallow(Files.createFile(new File(dir, Log.CleanShutdownFile).toPath), this)\n+          // mark that the shutdown was clean by creating marker file\n+          debug(s\"Writing clean shutdown marker at $dir\")\n+          CoreUtils.swallow(Files.createFile(new File(dir, Log.CleanShutdownFile).toPath), this)\n+        }\n       }\n-    } catch {\n-      case e: ExecutionException =>\n-        error(s\"There was an error in one of the threads during LogManager shutdown: ${e.getCause}\")\n-        throw e.getCause\n+      firstExceptionOpt.foreach{ e => throw e}", "originalCommit": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDg0Nzg4OA==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524847888", "bodyText": "Great point. I've changed the code to do the same.\nMy understanding is that the exception swallow safety net exists inside KafkaServer.shutdown() today, but it makes sense to also just log a warning here instead instead of relying on the safety net: \n  \n    \n      kafka/core/src/main/scala/kafka/server/KafkaServer.scala\n    \n    \n         Line 732\n      in\n      bb34c5c\n    \n    \n    \n    \n\n        \n          \n           CoreUtils.swallow(logManager.shutdown(), this) \n        \n    \n  \n\n.", "author": "kowshik", "createdAt": "2020-11-17T02:40:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDY3MzczMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDY3NDYyOQ==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524674629", "bodyText": "Hmm, do we need this given that we do this in tearDown() already?", "author": "junrao", "createdAt": "2020-11-16T22:22:49Z", "path": "core/src/test/scala/unit/kafka/log/LogManagerTest.scala", "diffHunk": "@@ -83,6 +87,51 @@ class LogManagerTest {\n     log.appendAsLeader(TestUtils.singletonRecords(\"test\".getBytes()), leaderEpoch = 0)\n   }\n \n+  /**\n+   * Tests that all internal futures are completed before LogManager.shutdown() returns to the\n+   * caller during error situations.\n+   */\n+  @Test\n+  def testHandlingExceptionsDuringShutdown(): Unit = {\n+    logManager.shutdown()", "originalCommit": "3a36b54fe6f50e2538ff684be7ed626c3afe83f4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDg0ODU4NA==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524848584", "bodyText": "Yeah this explicit shutdown is needed to:\n\nRe-create a new LogManager instance with multiple logDirs for this test. This is different from the default one provided in setUp().\nHelp do some additional checks post shutdown (towards the end of this test).", "author": "kowshik", "createdAt": "2020-11-17T02:42:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDY3NDYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDg1MzIzMQ==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r524853231", "bodyText": "Thinking about it again, you are right. I have eliminated the need for the shutdown() now by using a LogManager instance specific to the test.", "author": "kowshik", "createdAt": "2020-11-17T02:58:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDY3NDYyOQ=="}], "type": "inlineReview"}, {"oid": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "url": "https://github.com/apache/kafka/commit/f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "message": "Address comments from Jun", "committedDate": "2020-11-17T02:51:50Z", "type": "commit"}, {"oid": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "url": "https://github.com/apache/kafka/commit/f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "message": "Address comments from Jun", "committedDate": "2020-11-17T02:51:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTA1NA==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525835054", "bodyText": "Nit: this should be in the previous line.", "author": "ijuma", "createdAt": "2020-11-18T06:06:57Z", "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -479,25 +479,33 @@ class LogManager(logDirs: Seq[File],\n \n     try {\n       for ((dir, dirJobs) <- jobs) {\n-        dirJobs.foreach(_.get)\n+        val hasErrors = dirJobs.exists {\n+          future =>", "originalCommit": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTg1MDA4Nw==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525850087", "bodyText": "Done.", "author": "kowshik", "createdAt": "2020-11-18T06:50:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTA1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTQ5NQ==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525835495", "bodyText": "This looks wrong. exists short-circuits. I think you want map followed by exists.", "author": "ijuma", "createdAt": "2020-11-18T06:08:16Z", "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -479,25 +479,33 @@ class LogManager(logDirs: Seq[File],\n \n     try {\n       for ((dir, dirJobs) <- jobs) {\n-        dirJobs.foreach(_.get)\n+        val hasErrors = dirJobs.exists {", "originalCommit": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTg1MDAzNw==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525850037", "bodyText": "Thats a really good point. Done.", "author": "kowshik", "createdAt": "2020-11-18T06:50:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTQ5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTc2OQ==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525835769", "bodyText": "You can use scala.util.Try to wrap the call and get a Success or Failure.", "author": "ijuma", "createdAt": "2020-11-18T06:09:09Z", "path": "core/src/main/scala/kafka/log/LogManager.scala", "diffHunk": "@@ -479,25 +479,33 @@ class LogManager(logDirs: Seq[File],\n \n     try {\n       for ((dir, dirJobs) <- jobs) {\n-        dirJobs.foreach(_.get)\n+        val hasErrors = dirJobs.exists {\n+          future =>\n+            try {", "originalCommit": "f917f0c24cebbb0fb5eb7029ccb6676734b60b3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTg1MDE1Ng==", "url": "https://github.com/apache/kafka/pull/9596#discussion_r525850156", "bodyText": "Good idea, done.", "author": "kowshik", "createdAt": "2020-11-18T06:51:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgzNTc2OQ=="}], "type": "inlineReview"}, {"oid": "8716429b48cad8af6ad73109c1d9f7442823c02f", "url": "https://github.com/apache/kafka/commit/8716429b48cad8af6ad73109c1d9f7442823c02f", "message": "Address comments from Ismael", "committedDate": "2020-11-18T06:46:45Z", "type": "commit"}]}