{"pr_number": 8318, "pr_title": "KAFKA-9451: Enable producer per thread for Streams EOS", "pr_createdAt": "2020-03-19T20:08:44Z", "pr_url": "https://github.com/apache/kafka/pull/8318", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MDk1OQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395290959", "bodyText": "This is a side improvement: add transactional.id to non-configurable parameters as we overwrite it anyway", "author": "mjsax", "createdAt": "2020-03-19T20:09:33Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -533,10 +571,16 @@\n         \" WARNING: This config is deprecated and will be removed in 3.0.0 release.\";\n \n \n-    private static final String[] NON_CONFIGURABLE_CONSUMER_DEFAULT_CONFIGS = new String[] {ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG};\n-    private static final String[] NON_CONFIGURABLE_CONSUMER_EOS_CONFIGS = new String[] {ConsumerConfig.ISOLATION_LEVEL_CONFIG};\n-    private static final String[] NON_CONFIGURABLE_PRODUCER_EOS_CONFIGS = new String[] {ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,\n-                                                                                        ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION};\n+    private static final String[] NON_CONFIGURABLE_CONSUMER_DEFAULT_CONFIGS =\n+        new String[] {ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG};\n+    private static final String[] NON_CONFIGURABLE_CONSUMER_EOS_CONFIGS =\n+        new String[] {ConsumerConfig.ISOLATION_LEVEL_CONFIG};\n+    private static final String[] NON_CONFIGURABLE_PRODUCER_EOS_CONFIGS =\n+        new String[] {\n+            ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,\n+            ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION,\n+            ProducerConfig.TRANSACTIONAL_ID_CONFIG", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MTY2MQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395291661", "bodyText": "For eos-beta, we just generate a random UUID suffix for the TxId for the thread producer.", "author": "mjsax", "createdAt": "2020-03-19T20:10:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -1220,6 +1269,9 @@ private void checkIfUnexpectedUserSpecifiedConsumerConfig(final Map<String, Obje\n \n         // generate producer configs from original properties and overridden maps\n         final Map<String, Object> props = new HashMap<>(eosEnabled ? PRODUCER_EOS_OVERRIDES : PRODUCER_DEFAULT_OVERRIDES);\n+        if (StreamThread.eosBetaEnabled(this) && !StreamThread.eosUpgradeModeEnabled(this)) {\n+            props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, getString(StreamsConfig.APPLICATION_ID_CONFIG) + \"-\" + UUID.randomUUID());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM1ODI3Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395358273", "bodyText": "Let's add this later in ActiveTaskCreator class instead of here, also I'd suggest we use the clientId + thread-id-suffix (the thread-name should be in the form of clientId + \"-StreamThread-\" + threadIdx so it's easy to parse out the middle -StreamThread- part) instead of UUID. In practice if client-Id is not set it would default to UUID-suffixIndex. But by comparing the log we have the clear clue which transaction id belongs to which thread, while just another random UUID did not reveal us anything.", "author": "guozhangwang", "createdAt": "2020-03-19T22:38:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MTY2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3MzIwMg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395373202", "bodyText": "Can we rely on clientId? From my understanding, clientId might be set to the same value for different KafkaStreams instances because quotas are based on clientId? For this case, we would get duplicate TxId? Thoughts?", "author": "mjsax", "createdAt": "2020-03-19T23:23:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MTY2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5MzAyNg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395393026", "bodyText": "Good point.\nLet's use the processId passed from thread -> task-manager then, since it is used in the subscription-info as well, and hence can also help with debugging as long as it is not another random UUID.\nMore specifically, we can use applicaiton-id-processId regardless of the clientId.", "author": "guozhangwang", "createdAt": "2020-03-20T00:39:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MTY2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQzNDY4OQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395434689", "bodyText": "ProcessId should be unique", "author": "abbccdda", "createdAt": "2020-03-20T04:27:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MTY2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MjIwNg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395292206", "bodyText": "Create single StreamsProducer that is shared over all tasks.", "author": "mjsax", "createdAt": "2020-03-19T20:12:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreator.java", "diffHunk": "@@ -94,17 +93,27 @@ private static String getTaskProducerClientId(final String threadClientId, final\n         createTaskSensor = ThreadMetrics.createTaskSensor(threadId, streamsMetrics);\n         applicationId = config.getString(StreamsConfig.APPLICATION_ID_CONFIG);\n \n-        if (EXACTLY_ONCE.equals(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG))) {\n+        if (StreamThread.eosAlphaEnabled(config) ||\n+            (StreamThread.eosBetaEnabled(config) && StreamThread.eosUpgradeModeEnabled(config))) {\n+\n             threadProducer = null;\n+            eosBetaStreamsProducer = null;\n             taskProducers = new HashMap<>();\n-        } else {\n+        } else { // non-eos and eos-beta\n             log.info(\"Creating thread producer client\");\n \n             final String threadProducerClientId = getThreadProducerClientId(threadId);\n             final Map<String, Object> producerConfigs = config.getProducerConfigs(threadProducerClientId);\n \n             threadProducer = clientSupplier.getProducer(producerConfigs);\n             taskProducers = Collections.emptyMap();\n+            if (StreamThread.eosBetaEnabled(config)) {\n+                final String threadIdPrefix = String.format(\"stream-thread [%s] \", Thread.currentThread().getName());\n+                final LogContext logContext = new LogContext(threadIdPrefix);\n+                 eosBetaStreamsProducer = new StreamsProducer(threadProducer, true, logContext);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MzE4Nw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395293187", "bodyText": "As we need to pass in ConsumerGroupMetadata on commitTx() for eos-beta, it's simpler to also pass in the application.id during commit to unify the logic.", "author": "mjsax", "createdAt": "2020-03-19T20:13:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "diffHunk": "@@ -51,22 +52,16 @@\n     private final String logPrefix;\n \n     private final Producer<byte[], byte[]> producer;\n-    private final String applicationId;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NDE0NQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395294145", "bodyText": "For eos-beta, we need to commit all tasks at once, hence, we prepare all non-suspended tasks for committing, too.", "author": "mjsax", "createdAt": "2020-03-19T20:15:36Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -377,13 +382,21 @@ void handleRevocation(final Collection<TopicPartition> revokedPartitions) {\n         final Set<TopicPartition> remainingPartitions = new HashSet<>(revokedPartitions);\n \n         final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadataPerTask = new HashMap<>();\n+        final Set<Task> suspended = new HashSet<>();\n         for (final Task task : tasks.values()) {\n             if (remainingPartitions.containsAll(task.inputPartitions())) {\n                 task.prepareSuspend();\n                 final Map<TopicPartition, OffsetAndMetadata> committableOffsets = task.committableOffsetsAndMetadata();\n                 if (!committableOffsets.isEmpty()) {\n                     consumedOffsetsAndMetadataPerTask.put(task.id(), committableOffsets);\n                 }\n+                suspended.add(task);\n+            } else if (eosBetaEnabled && !eosUpgradeModeEnabled) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2NzY1Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395367653", "bodyText": "Not for this PR: this is getting really messy here... instead of interleaving the suspending and committing logic, we should just do one loop over ALL tasks gathering their offsets, and then do another loop over the tasks from revokedPartitions doing a suspend.", "author": "guozhangwang", "createdAt": "2020-03-19T23:05:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NDE0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NDc1Ng==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395294756", "bodyText": "For eos-beta, if we find a single task that we need to commit, we fall back to commit all tasks.", "author": "mjsax", "createdAt": "2020-03-19T20:16:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -728,33 +745,57 @@ int maybeCommitActiveTasksPerUserRequested() {\n         if (rebalanceInProgress) {\n             return -1;\n         } else {\n-            final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadataPerTask = new HashMap<>();\n-            for (final Task task : activeTaskIterable()) {\n-                if (task.commitRequested() && task.commitNeeded()) {\n-                    task.prepareCommit();\n-                    final Map<TopicPartition, OffsetAndMetadata> offsetAndMetadata = task.committableOffsetsAndMetadata();\n-                    if (!offsetAndMetadata.isEmpty()) {\n-                        consumedOffsetsAndMetadataPerTask.put(task.id(), offsetAndMetadata);\n+            if (eosBetaEnabled && !eosUpgradeModeEnabled) {\n+                for (final Task task : activeTaskIterable()) {\n+                    if (task.commitRequested() && task.commitNeeded()) {\n+                        return commitAll();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2ODI2Nw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395368267", "bodyText": "I thought we agreed that we would always commitAll upon user requested in any task, in 2.6 and beyond, no matter of the eos config? Personally I think such if/else branching is not really worth the complexity itself..", "author": "guozhangwang", "createdAt": "2020-03-19T23:07:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NDc1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3NDE2Ng==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395374166", "bodyText": "My understanding was that we only do this for eos-beta? \\cc @abbccdda\nDon't really have a strong opinion what might be better.", "author": "mjsax", "createdAt": "2020-03-19T23:26:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NDc1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5MzI4Ng==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395393286", "bodyText": "If you guys are not feeling strong, then let's just do this :)", "author": "guozhangwang", "createdAt": "2020-03-20T00:40:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NDc1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQzOTY4Nw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395439687", "bodyText": "I would say we just fallback to commit all tasks as we agreed. This extra complexity is not necessary.", "author": "abbccdda", "createdAt": "2020-03-20T04:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NDc1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ1ODIyOA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395458228", "bodyText": "Ack", "author": "mjsax", "createdAt": "2020-03-20T06:40:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NDc1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NTE1Mg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395295152", "bodyText": "Eos-alpha: we just pass application.id during per-task tx-commit", "author": "mjsax", "createdAt": "2020-03-19T20:17:35Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -728,33 +745,57 @@ int maybeCommitActiveTasksPerUserRequested() {\n         if (rebalanceInProgress) {\n             return -1;\n         } else {\n-            final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadataPerTask = new HashMap<>();\n-            for (final Task task : activeTaskIterable()) {\n-                if (task.commitRequested() && task.commitNeeded()) {\n-                    task.prepareCommit();\n-                    final Map<TopicPartition, OffsetAndMetadata> offsetAndMetadata = task.committableOffsetsAndMetadata();\n-                    if (!offsetAndMetadata.isEmpty()) {\n-                        consumedOffsetsAndMetadataPerTask.put(task.id(), offsetAndMetadata);\n+            if (eosBetaEnabled && !eosUpgradeModeEnabled) {\n+                for (final Task task : activeTaskIterable()) {\n+                    if (task.commitRequested() && task.commitNeeded()) {\n+                        return commitAll();\n                     }\n                 }\n-            }\n \n-            commitOffsetsOrTransaction(consumedOffsetsAndMetadataPerTask);\n+                return 0;\n+            } else {\n+                final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadataPerTask = new HashMap<>();\n+\n+                for (final Task task : activeTaskIterable()) {\n+                    if (task.commitRequested() && task.commitNeeded()) {\n+                        task.prepareCommit();\n+                        final Map<TopicPartition, OffsetAndMetadata> offsetAndMetadata = task.committableOffsetsAndMetadata();\n+                        if (!offsetAndMetadata.isEmpty()) {\n+                            consumedOffsetsAndMetadataPerTask.put(task.id(), offsetAndMetadata);\n+                        }\n+                    }\n+                }\n \n-            for (final Task task : tasks.values()) {\n-                if (consumedOffsetsAndMetadataPerTask.containsKey(task.id())) {\n-                    task.postCommit();\n+                commitOffsetsOrTransaction(consumedOffsetsAndMetadataPerTask);\n+\n+                for (final Task task : tasks.values()) {\n+                    if (consumedOffsetsAndMetadataPerTask.containsKey(task.id())) {\n+                        task.postCommit();\n+                    }\n                 }\n-            }\n \n-            return consumedOffsetsAndMetadataPerTask.size();\n+                return consumedOffsetsAndMetadataPerTask.size();\n+            }\n         }\n     }\n \n     private void commitOffsetsOrTransaction(final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> offsetsPerTask) {\n-        if (eosEnabled) {\n+        if (eosAlphaEnabled) {\n             for (final Map.Entry<TaskId, Map<TopicPartition, OffsetAndMetadata>> taskToCommit : offsetsPerTask.entrySet()) {\n-                activeTaskCreator.streamsProducerForTask(taskToCommit.getKey()).commitTransaction(taskToCommit.getValue());\n+                activeTaskCreator.streamsProducerForTask(taskToCommit.getKey())\n+                    .commitTransaction(taskToCommit.getValue(), mainConsumer.groupMetadata().groupId());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2OTAzOQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395369039", "bodyText": "See my other comment: I think in 2.6+ we would always pass consumer metadata no matter of the eos mode.\nAnd a meta comment here: we should avoid unnecessary branches if their effects are minimal, to keep the logic simple and less error-prone.", "author": "guozhangwang", "createdAt": "2020-03-19T23:09:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NTE1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NTQ5Mg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395295492", "bodyText": "Eos-beta during upgrade: we just pass ConsumerGroupMetadata during per-task tx-commit to enable consumer side \"fetch offset blocking\"", "author": "mjsax", "createdAt": "2020-03-19T20:18:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -728,33 +745,57 @@ int maybeCommitActiveTasksPerUserRequested() {\n         if (rebalanceInProgress) {\n             return -1;\n         } else {\n-            final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadataPerTask = new HashMap<>();\n-            for (final Task task : activeTaskIterable()) {\n-                if (task.commitRequested() && task.commitNeeded()) {\n-                    task.prepareCommit();\n-                    final Map<TopicPartition, OffsetAndMetadata> offsetAndMetadata = task.committableOffsetsAndMetadata();\n-                    if (!offsetAndMetadata.isEmpty()) {\n-                        consumedOffsetsAndMetadataPerTask.put(task.id(), offsetAndMetadata);\n+            if (eosBetaEnabled && !eosUpgradeModeEnabled) {\n+                for (final Task task : activeTaskIterable()) {\n+                    if (task.commitRequested() && task.commitNeeded()) {\n+                        return commitAll();\n                     }\n                 }\n-            }\n \n-            commitOffsetsOrTransaction(consumedOffsetsAndMetadataPerTask);\n+                return 0;\n+            } else {\n+                final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadataPerTask = new HashMap<>();\n+\n+                for (final Task task : activeTaskIterable()) {\n+                    if (task.commitRequested() && task.commitNeeded()) {\n+                        task.prepareCommit();\n+                        final Map<TopicPartition, OffsetAndMetadata> offsetAndMetadata = task.committableOffsetsAndMetadata();\n+                        if (!offsetAndMetadata.isEmpty()) {\n+                            consumedOffsetsAndMetadataPerTask.put(task.id(), offsetAndMetadata);\n+                        }\n+                    }\n+                }\n \n-            for (final Task task : tasks.values()) {\n-                if (consumedOffsetsAndMetadataPerTask.containsKey(task.id())) {\n-                    task.postCommit();\n+                commitOffsetsOrTransaction(consumedOffsetsAndMetadataPerTask);\n+\n+                for (final Task task : tasks.values()) {\n+                    if (consumedOffsetsAndMetadataPerTask.containsKey(task.id())) {\n+                        task.postCommit();\n+                    }\n                 }\n-            }\n \n-            return consumedOffsetsAndMetadataPerTask.size();\n+                return consumedOffsetsAndMetadataPerTask.size();\n+            }\n         }\n     }\n \n     private void commitOffsetsOrTransaction(final Map<TaskId, Map<TopicPartition, OffsetAndMetadata>> offsetsPerTask) {\n-        if (eosEnabled) {\n+        if (eosAlphaEnabled) {\n             for (final Map.Entry<TaskId, Map<TopicPartition, OffsetAndMetadata>> taskToCommit : offsetsPerTask.entrySet()) {\n-                activeTaskCreator.streamsProducerForTask(taskToCommit.getKey()).commitTransaction(taskToCommit.getValue());\n+                activeTaskCreator.streamsProducerForTask(taskToCommit.getKey())\n+                    .commitTransaction(taskToCommit.getValue(), mainConsumer.groupMetadata().groupId());\n+            }\n+        } else if (eosBetaEnabled) {\n+            if (eosUpgradeModeEnabled) {\n+                for (final Map.Entry<TaskId, Map<TopicPartition, OffsetAndMetadata>> taskToCommit : offsetsPerTask.entrySet()) {\n+                    activeTaskCreator.streamsProducerForTask(taskToCommit.getKey())\n+                        .commitTransaction(taskToCommit.getValue(), mainConsumer.groupMetadata());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NTk4Nw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395295987", "bodyText": "We \"duplicate\" test for eos-alpha and eos-beta (similar pattern below for other tests)", "author": "mjsax", "createdAt": "2020-03-19T20:19:13Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java", "diffHunk": "@@ -518,8 +530,18 @@ public void shouldThrowIfBuiltInMetricsVersionInvalid() {\n     }\n \n     @Test\n-    public void shouldResetToDefaultIfConsumerIsolationLevelIsOverriddenIfEosEnabled() {\n+    public void shouldResetToDefaultIfConsumerIsolationLevelIsOverriddenIfEosAlphaEnabled() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NzIwMA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395297200", "bodyText": "If we are upgrading from a non-eos version to eos-beta, there is no need to do producer-per-task at all, and thus, we switch to producer per-thread directly. Strictly speaking, a two rolling bounce upgrade would be even be required for the eos-beta opt-in, but people might need to do a two rolling bounce upgrade for other reasons. (Similar pattern for other test)", "author": "mjsax", "createdAt": "2020-03-19T20:21:38Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java", "diffHunk": "@@ -564,12 +609,84 @@ public void shouldSetDifferentDefaultsIfEosEnabled() {\n         assertTrue((Boolean) producerConfigs.get(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG));\n         assertThat(producerConfigs.get(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG), equalTo(Integer.MAX_VALUE));\n         assertThat(streamsConfig.getLong(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG), equalTo(100L));\n+\n+        return producerConfigs;\n     }\n \n     @Test\n-    public void shouldNotOverrideUserConfigRetriesIfExactlyOnceEnabled() {\n-        final int numberOfRetries = 42;\n+    public void shouldOverrideUserConfigTransactionalIdIfEosAlphaEnabled() {\n         props.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, EXACTLY_ONCE);\n+        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"user-TxId\");\n+        final StreamsConfig streamsConfig = new StreamsConfig(props);\n+\n+        final Map<String, Object> producerConfigs = streamsConfig.getProducerConfigs(clientId);\n+\n+        assertThat(producerConfigs.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG), is(nullValue()));\n+    }\n+\n+    @Test\n+    public void shouldOverrideUserConfigTransactionalIdIfEosBetaEnabled() {\n+        props.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, EXACTLY_ONCE_BETA);\n+        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"user-TxId\");\n+        final StreamsConfig streamsConfig = new StreamsConfig(props);\n+\n+        final Map<String, Object> producerConfigs = streamsConfig.getProducerConfigs(clientId);\n+\n+        assertThat((String) producerConfigs.get(ProducerConfig.TRANSACTIONAL_ID_CONFIG), startsWith(applicationId + \"-\"));\n+    }\n+\n+    @Test\n+    public void shouldSetTransactionalIdIfEosBetaEnabledWhileUpgradingFromPreEosVersion() {\n+        props.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, EXACTLY_ONCE_BETA);\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5NzQxMQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395297411", "bodyText": "Side cleanup", "author": "mjsax", "createdAt": "2020-03-19T20:22:05Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java", "diffHunk": "@@ -780,25 +937,24 @@ public void shouldThrowConfigExceptionIfProbingRebalanceIntervalIsOutsideBounds(\n         assertThrows(ConfigException.class, () -> new StreamsConfig(props));\n     }\n \n-    static class MisconfiguredSerde implements Serde {\n+    static class MisconfiguredSerde implements Serde<Object> {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5ODY1Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395298653", "bodyText": "This test should no cover all required tests for ActiveTaskCreator and thus addressed  on half of https://issues.apache.org/jira/browse/KAFKA-9676", "author": "mjsax", "createdAt": "2020-03-19T20:24:30Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -67,40 +64,70 @@\n     @Mock(type = MockType.NICE)\n     private InternalTopologyBuilder builder;\n     @Mock(type = MockType.NICE)\n-    private StreamsConfig config;\n-    @Mock(type = MockType.NICE)\n     private StateDirectory stateDirectory;\n     @Mock(type = MockType.NICE)\n     private ChangelogReader changeLogReader;\n-    @Mock(type = MockType.NICE)\n-    private Consumer<byte[], byte[]> consumer;\n-    @Mock(type = MockType.NICE)\n-    private Admin adminClient;\n \n     private final MockClientSupplier mockClientSupplier = new MockClientSupplier();\n     final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(new Metrics(), \"clientId\", StreamsConfig.METRICS_LATEST);\n+    final Map<String, Object> properties = mkMap(\n+        mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\"),\n+        mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\")\n+    );\n \n     private ActiveTaskCreator activeTaskCreator;\n \n+\n+\n+    // non-EOS test\n+\n+    // functional test\n+\n     @Test\n-    public void shouldFailForNonEosOnStreamsProducerPerTask() {\n-        expect(config.getString(StreamsConfig.APPLICATION_ID_CONFIG)).andReturn(\"appId\");\n-        expect(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG)).andReturn(StreamsConfig.AT_LEAST_ONCE);\n-        expect(config.getProducerConfigs(anyString())).andReturn(Collections.emptyMap());\n-        replay(config);\n+    public void shouldCreateThreadProducerIfEosDisabled() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MjkwMQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395792901", "bodyText": "You mean now? :) If yes please feel free to resolve the ticket when you merge this.", "author": "guozhangwang", "createdAt": "2020-03-20T17:38:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5ODY1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgwMDYxNA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395800614", "bodyText": "Yes, it should now cover all required tests.\nWe still can't resolve KAFAK-9676 afterwards, because StandbyTaskCreatorTest is still lacking full test coverage.", "author": "mjsax", "createdAt": "2020-03-20T17:52:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5ODY1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5OTc1Ng==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395299756", "bodyText": "Just reordered the test to keep an overview -- this test is just moved (consider the renaming)", "author": "mjsax", "createdAt": "2020-03-19T20:26:33Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -111,25 +138,111 @@ public void shouldFailForNonEosOnStreamsProducerPerTask() {\n     }\n \n     @Test\n-    public void shouldFailForUnknownTaskOnStreamsProducerPerTask() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5OTk4NA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395299984", "bodyText": "Test moved", "author": "mjsax", "createdAt": "2020-03-19T20:27:01Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -141,118 +254,613 @@ public void shouldFailForUnknownTaskOnStreamsProducerPerTask() {\n         {\n             final IllegalStateException thrown = assertThrows(\n                 IllegalStateException.class,\n-                () -> activeTaskCreator.streamsProducerForTask(new TaskId(0, 0))\n+                () -> activeTaskCreator.streamsProducerForTask(new TaskId(0, 2))\n             );\n \n-            assertThat(thrown.getMessage(), is(\"Unknown TaskId: 0_0\"));\n+            assertThat(thrown.getMessage(), is(\"Unknown TaskId: 0_2\"));\n         }\n     }\n \n     @Test\n-    public void shouldReturnStreamsProducerPerTask() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NTA1OQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395795059", "bodyText": "It reminds me that sometimes I did the same thing of piggy-backing re-orging in the code base with actual changes that makes the reviewers life harder :P All of us should be careful in the future.\nThat being said, for this PR since Boyang and I have bite it already, I think we can save reverting the piggy-backed reordering and just merge as this.", "author": "guozhangwang", "createdAt": "2020-03-20T17:42:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5OTk4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgwMTUyMA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395801520", "bodyText": "I agree and I usually try to avoid re-ordering. However, because I added all missing test method it was required to keep an overview and to ensure we don't miss a case... Sorry for the mess.", "author": "mjsax", "createdAt": "2020-03-20T17:54:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5OTk4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMwMDMwNQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395300305", "bodyText": "moved", "author": "mjsax", "createdAt": "2020-03-19T20:27:39Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -141,118 +254,613 @@ public void shouldFailForUnknownTaskOnStreamsProducerPerTask() {\n         {\n             final IllegalStateException thrown = assertThrows(\n                 IllegalStateException.class,\n-                () -> activeTaskCreator.streamsProducerForTask(new TaskId(0, 0))\n+                () -> activeTaskCreator.streamsProducerForTask(new TaskId(0, 2))\n             );\n \n-            assertThat(thrown.getMessage(), is(\"Unknown TaskId: 0_0\"));\n+            assertThat(thrown.getMessage(), is(\"Unknown TaskId: 0_2\"));\n         }\n     }\n \n     @Test\n-    public void shouldReturnStreamsProducerPerTask() {\n-        final TaskId task00 = new TaskId(0, 0);\n-        final TaskId task01 = new TaskId(0, 1);\n-        final ProcessorTopology topology = mock(ProcessorTopology.class);\n+    public void shouldFailOnGetThreadProducerIfEosAlphaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n \n-        expect(config.getString(StreamsConfig.APPLICATION_ID_CONFIG)).andReturn(\"appId\");\n-        expect(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG)).andReturn(StreamsConfig.EXACTLY_ONCE);\n-        expect(config.getProducerConfigs(anyString())).andReturn(new HashMap<>()).anyTimes();\n-        expect(config.getLong(anyString())).andReturn(0L).anyTimes();\n-        expect(config.getInt(anyString())).andReturn(0).anyTimes();\n-        expect(builder.buildSubtopology(task00.topicGroupId)).andReturn(topology).anyTimes();\n-        expect(stateDirectory.directoryForTask(task00)).andReturn(new File(task00.toString()));\n-        expect(stateDirectory.directoryForTask(task01)).andReturn(new File(task01.toString()));\n-        expect(topology.storeToChangelogTopic()).andReturn(Collections.emptyMap()).anyTimes();\n-        expect(topology.source(\"topic\")).andReturn(mock(SourceNode.class)).andReturn(mock(SourceNode.class));\n-        expect(topology.globalStateStores()).andReturn(Collections.emptyList()).anyTimes();\n-        replay(config, builder, stateDirectory, topology);\n+        createTasks();\n+\n+        final IllegalStateException thrown = assertThrows(\n+            IllegalStateException.class,\n+            activeTaskCreator::threadProducer\n+        );\n \n+        assertThat(thrown.getMessage(), is(\"Exactly-once beta is not enabled.\"));\n+    }\n+\n+    @Test\n+    public void shouldThrowStreamsExceptionOnErrorCloseTaskProducerIfEosAlphaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE);\n         mockClientSupplier.setApplicationIdForProducer(\"appId\");\n-        activeTaskCreator = new ActiveTaskCreator(\n-            builder,\n-            config,\n-            streamsMetrics,\n-            stateDirectory,\n-            changeLogReader,\n-            new ThreadCache(new LogContext(), 0L, streamsMetrics),\n-            new MockTime(),\n-            mockClientSupplier,\n-            \"threadId\",\n-            new LogContext().logger(ActiveTaskCreator.class)\n+        createTasks();\n+        mockClientSupplier.producers.get(0).closeException = new RuntimeException(\"KABOOM!\");\n+\n+        final StreamsException thrown = assertThrows(\n+            StreamsException.class,\n+            () -> activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0))\n         );\n \n-        assertThat(\n-            activeTaskCreator.createTasks(\n-                null,\n-                mkMap(\n-                    mkEntry(task00, Collections.singleton(new TopicPartition(\"topic\", 0))),\n-                    mkEntry(task01, Collections.singleton(new TopicPartition(\"topic\", 1)))\n-                )\n-            ).stream().map(Task::id).collect(Collectors.toSet()),\n-            equalTo(mkSet(task00, task01))\n+        assertThat(thrown.getMessage(), is(\"[0_0] task producer encounter error trying to close.\"));\n+        assertThat(thrown.getCause().getMessage(), is(\"KABOOM!\"));\n+\n+        // should not throw again because producer should be removed\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+    }\n+\n+\n+\n+    // eos-beta test\n+\n+    // functional test\n+\n+    @Test\n+    public void shouldCreateThreadProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+        createTasks();\n+\n+        assertThat(mockClientSupplier.producers.size(), is(1));\n+    }\n+\n+    @Test\n+    public void shouldCreateThreadProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            assertThat(mockClientSupplier.producers.size(), is(1));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldCreateProducerPerTaskIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            assertThat(mockClientSupplier.producers.size(), is(2));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldReturnThreadProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        createTasks();\n+\n+        final StreamsProducer threadProducer = activeTaskCreator.threadProducer();\n+\n+        assertThat(mockClientSupplier.producers.size(), is(1));\n+        assertThat(threadProducer.kafkaProducer(), is(mockClientSupplier.producers.get(0)));\n+    }\n+\n+    @Test\n+    public void shouldReturnThreadProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            final StreamsProducer threadProducer = activeTaskCreator.threadProducer();\n+\n+            assertThat(mockClientSupplier.producers.size(), is(1));\n+            assertThat(threadProducer.kafkaProducer(), is(mockClientSupplier.producers.get(0)));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldReturnStreamsProducerPerTaskIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+\n+            shouldReturnStreamsProducerPerTask();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        shouldConstructThreadProducerMetric();\n+    }\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+\n+            shouldConstructThreadProducerMetric();\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+\n+            shouldConstructProducerMetricsPerTask();\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldConstructClientIdWithEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+        createTasks();\n+\n+        final Set<String> clientIds = activeTaskCreator.producerClientIds();\n+\n+        assertThat(clientIds, is(Collections.singleton(\"threadId-producer\")));\n+    }\n+\n+    @Test\n+    public void shouldConstructClientIdWithEosBetaEnabledAndUpgradingFromPreEosVerion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            final Set<String> clientIds = activeTaskCreator.producerClientIds();\n+\n+            assertThat(clientIds, is(Collections.singleton(\"threadId-producer\")));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldConstructClientIdWithEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            final Set<String> clientIds = activeTaskCreator.producerClientIds();\n+\n+            assertThat(clientIds, is(mkSet(\"threadId-0_0-producer\", \"threadId-0_1-producer\")));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldCloseThreadProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+        createTasks();\n+\n+        activeTaskCreator.closeThreadProducerIfNeeded();\n+\n+        assertThat(mockClientSupplier.producers.get(0).closed(), is(true));\n+    }\n+\n+    @Test\n+    public void shouldCloseThreadProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            activeTaskCreator.closeThreadProducerIfNeeded();\n+\n+            assertThat(mockClientSupplier.producers.get(0).closed(), is(true));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldNoOpCloseTaskProducerIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            activeTaskCreator.closeThreadProducerIfNeeded();\n+\n+            assertThat(mockClientSupplier.producers.get(0).closed(), is(false));\n+            assertThat(mockClientSupplier.producers.get(1).closed(), is(false));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldNoOpCloseTaskProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        createTasks();\n+\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 1));\n+\n+        assertThat(mockClientSupplier.producers.get(0).closed(), is(false));\n+    }\n+\n+    @Test\n+    public void shouldNoOpCloseTaskProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 1));\n+\n+            assertThat(mockClientSupplier.producers.get(0).closed(), is(false));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldCloseTaskProducerIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 1));\n+            // should no-op unknown task\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 2));\n+\n+            assertThat(mockClientSupplier.producers.get(0).closed(), is(true));\n+            assertThat(mockClientSupplier.producers.get(1).closed(), is(true));\n+\n+            // should not throw because producer should be removed\n+            mockClientSupplier.producers.get(0).closeException = new RuntimeException(\"KABOOM!\");\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    // error handling\n+\n+    @Test\n+    public void shouldFailOnStreamsProducerPerTaskIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        createTasks();\n+\n+        final IllegalStateException thrown = assertThrows(\n+            IllegalStateException.class,\n+            () -> activeTaskCreator.streamsProducerForTask(null)\n         );\n \n-        final StreamsProducer streamsProducer1 = activeTaskCreator.streamsProducerForTask(new TaskId(0, 0));\n-        final StreamsProducer streamsProducer2 = activeTaskCreator.streamsProducerForTask(new TaskId(0, 1));\n+        assertThat(thrown.getMessage(), is(\"Producer per thread is used\"));\n+    }\n+\n+    @Test\n+    public void shouldFailOnStreamsProducerPerTaskIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n \n-        assertThat(streamsProducer1, not(same(streamsProducer2)));\n+            final IllegalStateException thrown = assertThrows(\n+                IllegalStateException.class,\n+                () -> activeTaskCreator.streamsProducerForTask(null)\n+            );\n+\n+            assertThat(thrown.getMessage(), is(\"Producer per thread is used\"));\n+        }\n     }\n \n     @Test\n-    public void shouldConstructProducerMetricsWithoutEOS() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMwMDQzMg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395300432", "bodyText": "moved", "author": "mjsax", "createdAt": "2020-03-19T20:27:48Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -141,118 +254,613 @@ public void shouldFailForUnknownTaskOnStreamsProducerPerTask() {\n         {\n             final IllegalStateException thrown = assertThrows(\n                 IllegalStateException.class,\n-                () -> activeTaskCreator.streamsProducerForTask(new TaskId(0, 0))\n+                () -> activeTaskCreator.streamsProducerForTask(new TaskId(0, 2))\n             );\n \n-            assertThat(thrown.getMessage(), is(\"Unknown TaskId: 0_0\"));\n+            assertThat(thrown.getMessage(), is(\"Unknown TaskId: 0_2\"));\n         }\n     }\n \n     @Test\n-    public void shouldReturnStreamsProducerPerTask() {\n-        final TaskId task00 = new TaskId(0, 0);\n-        final TaskId task01 = new TaskId(0, 1);\n-        final ProcessorTopology topology = mock(ProcessorTopology.class);\n+    public void shouldFailOnGetThreadProducerIfEosAlphaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n \n-        expect(config.getString(StreamsConfig.APPLICATION_ID_CONFIG)).andReturn(\"appId\");\n-        expect(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG)).andReturn(StreamsConfig.EXACTLY_ONCE);\n-        expect(config.getProducerConfigs(anyString())).andReturn(new HashMap<>()).anyTimes();\n-        expect(config.getLong(anyString())).andReturn(0L).anyTimes();\n-        expect(config.getInt(anyString())).andReturn(0).anyTimes();\n-        expect(builder.buildSubtopology(task00.topicGroupId)).andReturn(topology).anyTimes();\n-        expect(stateDirectory.directoryForTask(task00)).andReturn(new File(task00.toString()));\n-        expect(stateDirectory.directoryForTask(task01)).andReturn(new File(task01.toString()));\n-        expect(topology.storeToChangelogTopic()).andReturn(Collections.emptyMap()).anyTimes();\n-        expect(topology.source(\"topic\")).andReturn(mock(SourceNode.class)).andReturn(mock(SourceNode.class));\n-        expect(topology.globalStateStores()).andReturn(Collections.emptyList()).anyTimes();\n-        replay(config, builder, stateDirectory, topology);\n+        createTasks();\n+\n+        final IllegalStateException thrown = assertThrows(\n+            IllegalStateException.class,\n+            activeTaskCreator::threadProducer\n+        );\n \n+        assertThat(thrown.getMessage(), is(\"Exactly-once beta is not enabled.\"));\n+    }\n+\n+    @Test\n+    public void shouldThrowStreamsExceptionOnErrorCloseTaskProducerIfEosAlphaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE);\n         mockClientSupplier.setApplicationIdForProducer(\"appId\");\n-        activeTaskCreator = new ActiveTaskCreator(\n-            builder,\n-            config,\n-            streamsMetrics,\n-            stateDirectory,\n-            changeLogReader,\n-            new ThreadCache(new LogContext(), 0L, streamsMetrics),\n-            new MockTime(),\n-            mockClientSupplier,\n-            \"threadId\",\n-            new LogContext().logger(ActiveTaskCreator.class)\n+        createTasks();\n+        mockClientSupplier.producers.get(0).closeException = new RuntimeException(\"KABOOM!\");\n+\n+        final StreamsException thrown = assertThrows(\n+            StreamsException.class,\n+            () -> activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0))\n         );\n \n-        assertThat(\n-            activeTaskCreator.createTasks(\n-                null,\n-                mkMap(\n-                    mkEntry(task00, Collections.singleton(new TopicPartition(\"topic\", 0))),\n-                    mkEntry(task01, Collections.singleton(new TopicPartition(\"topic\", 1)))\n-                )\n-            ).stream().map(Task::id).collect(Collectors.toSet()),\n-            equalTo(mkSet(task00, task01))\n+        assertThat(thrown.getMessage(), is(\"[0_0] task producer encounter error trying to close.\"));\n+        assertThat(thrown.getCause().getMessage(), is(\"KABOOM!\"));\n+\n+        // should not throw again because producer should be removed\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+    }\n+\n+\n+\n+    // eos-beta test\n+\n+    // functional test\n+\n+    @Test\n+    public void shouldCreateThreadProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+        createTasks();\n+\n+        assertThat(mockClientSupplier.producers.size(), is(1));\n+    }\n+\n+    @Test\n+    public void shouldCreateThreadProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            assertThat(mockClientSupplier.producers.size(), is(1));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldCreateProducerPerTaskIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            assertThat(mockClientSupplier.producers.size(), is(2));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldReturnThreadProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        createTasks();\n+\n+        final StreamsProducer threadProducer = activeTaskCreator.threadProducer();\n+\n+        assertThat(mockClientSupplier.producers.size(), is(1));\n+        assertThat(threadProducer.kafkaProducer(), is(mockClientSupplier.producers.get(0)));\n+    }\n+\n+    @Test\n+    public void shouldReturnThreadProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            final StreamsProducer threadProducer = activeTaskCreator.threadProducer();\n+\n+            assertThat(mockClientSupplier.producers.size(), is(1));\n+            assertThat(threadProducer.kafkaProducer(), is(mockClientSupplier.producers.get(0)));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldReturnStreamsProducerPerTaskIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+\n+            shouldReturnStreamsProducerPerTask();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        shouldConstructThreadProducerMetric();\n+    }\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+\n+            shouldConstructThreadProducerMetric();\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldConstructProducerMetricsWithEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+\n+            shouldConstructProducerMetricsPerTask();\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldConstructClientIdWithEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+        createTasks();\n+\n+        final Set<String> clientIds = activeTaskCreator.producerClientIds();\n+\n+        assertThat(clientIds, is(Collections.singleton(\"threadId-producer\")));\n+    }\n+\n+    @Test\n+    public void shouldConstructClientIdWithEosBetaEnabledAndUpgradingFromPreEosVerion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            final Set<String> clientIds = activeTaskCreator.producerClientIds();\n+\n+            assertThat(clientIds, is(Collections.singleton(\"threadId-producer\")));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldConstructClientIdWithEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            final Set<String> clientIds = activeTaskCreator.producerClientIds();\n+\n+            assertThat(clientIds, is(mkSet(\"threadId-0_0-producer\", \"threadId-0_1-producer\")));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldCloseThreadProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+        createTasks();\n+\n+        activeTaskCreator.closeThreadProducerIfNeeded();\n+\n+        assertThat(mockClientSupplier.producers.get(0).closed(), is(true));\n+    }\n+\n+    @Test\n+    public void shouldCloseThreadProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            activeTaskCreator.closeThreadProducerIfNeeded();\n+\n+            assertThat(mockClientSupplier.producers.get(0).closed(), is(true));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldNoOpCloseTaskProducerIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            activeTaskCreator.closeThreadProducerIfNeeded();\n+\n+            assertThat(mockClientSupplier.producers.get(0).closed(), is(false));\n+            assertThat(mockClientSupplier.producers.get(1).closed(), is(false));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldNoOpCloseTaskProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        createTasks();\n+\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 1));\n+\n+        assertThat(mockClientSupplier.producers.get(0).closed(), is(false));\n+    }\n+\n+    @Test\n+    public void shouldNoOpCloseTaskProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 1));\n+\n+            assertThat(mockClientSupplier.producers.get(0).closed(), is(false));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldCloseTaskProducerIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 1));\n+            // should no-op unknown task\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 2));\n+\n+            assertThat(mockClientSupplier.producers.get(0).closed(), is(true));\n+            assertThat(mockClientSupplier.producers.get(1).closed(), is(true));\n+\n+            // should not throw because producer should be removed\n+            mockClientSupplier.producers.get(0).closeException = new RuntimeException(\"KABOOM!\");\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    // error handling\n+\n+    @Test\n+    public void shouldFailOnStreamsProducerPerTaskIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        createTasks();\n+\n+        final IllegalStateException thrown = assertThrows(\n+            IllegalStateException.class,\n+            () -> activeTaskCreator.streamsProducerForTask(null)\n         );\n \n-        final StreamsProducer streamsProducer1 = activeTaskCreator.streamsProducerForTask(new TaskId(0, 0));\n-        final StreamsProducer streamsProducer2 = activeTaskCreator.streamsProducerForTask(new TaskId(0, 1));\n+        assertThat(thrown.getMessage(), is(\"Producer per thread is used\"));\n+    }\n+\n+    @Test\n+    public void shouldFailOnStreamsProducerPerTaskIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n \n-        assertThat(streamsProducer1, not(same(streamsProducer2)));\n+            final IllegalStateException thrown = assertThrows(\n+                IllegalStateException.class,\n+                () -> activeTaskCreator.streamsProducerForTask(null)\n+            );\n+\n+            assertThat(thrown.getMessage(), is(\"Producer per thread is used\"));\n+        }\n     }\n \n     @Test\n-    public void shouldConstructProducerMetricsWithoutEOS() {\n-        expect(config.getString(StreamsConfig.APPLICATION_ID_CONFIG)).andReturn(\"appId\");\n-        expect(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG)).andReturn(StreamsConfig.AT_LEAST_ONCE);\n-        expect(config.getProducerConfigs(anyString())).andReturn(Collections.emptyMap());\n-        replay(config);\n+    public void shouldFailOnGetThreadProducerIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n \n-        activeTaskCreator = new ActiveTaskCreator(\n-            builder,\n-            config,\n-            streamsMetrics,\n-            stateDirectory,\n-            changeLogReader,\n-            new ThreadCache(new LogContext(), 0L, streamsMetrics),\n-            new MockTime(),\n-            mockClientSupplier,\n-            \"threadId\",\n-            new LogContext().logger(ActiveTaskCreator.class)\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+\n+            final IllegalStateException thrown = assertThrows(\n+                IllegalStateException.class,\n+                activeTaskCreator::threadProducer\n+            );\n+\n+            assertThat(thrown.getMessage(), is(\"Exactly-once beta is not enabled.\"));\n+        }\n+    }\n+\n+    @Test\n+    public void shouldThrowStreamsExceptionOnErrorCloseThreadProducerIfEosBetaEnabled() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+        createTasks();\n+        mockClientSupplier.producers.get(0).closeException = new RuntimeException(\"KABOOM!\");\n+\n+        final StreamsException thrown = assertThrows(\n+            StreamsException.class,\n+            activeTaskCreator::closeThreadProducerIfNeeded\n         );\n \n+        assertThat(thrown.getMessage(), is(\"Thread producer encounter error trying to close.\"));\n+        assertThat(thrown.getCause().getMessage(), is(\"KABOOM!\"));\n+    }\n+\n+    @Test\n+    public void shouldThrowStreamsExceptionOnErrorCloseThreadProducerIfEosBetaEnabledAndUpgradingFromPreEosVersion() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0100,\n+            StreamsConfig.UPGRADE_FROM_0101,\n+            StreamsConfig.UPGRADE_FROM_0102)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+            mockClientSupplier.producers.get(0).closeException = new RuntimeException(\"KABOOM!\");\n+\n+            final StreamsException thrown = assertThrows(\n+                StreamsException.class,\n+                activeTaskCreator::closeThreadProducerIfNeeded\n+            );\n+\n+            assertThat(thrown.getMessage(), is(\"Thread producer encounter error trying to close.\"));\n+            assertThat(thrown.getCause().getMessage(), is(\"KABOOM!\"));\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    @Test\n+    public void shouldThrowStreamsExceptionOnErrorCloseTaskProducerIfEosBetaEnabledAndUpgradingFromEosAlpha() {\n+        properties.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_BETA);\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        for (final String upgradeFrom : mkSet(\n+            StreamsConfig.UPGRADE_FROM_0110,\n+            StreamsConfig.UPGRADE_FROM_10,\n+            StreamsConfig.UPGRADE_FROM_11,\n+            StreamsConfig.UPGRADE_FROM_20,\n+            StreamsConfig.UPGRADE_FROM_21,\n+            StreamsConfig.UPGRADE_FROM_22,\n+            StreamsConfig.UPGRADE_FROM_23,\n+            StreamsConfig.UPGRADE_FROM_24,\n+            StreamsConfig.UPGRADE_FROM_25)) {\n+\n+            properties.put(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFrom);\n+            createTasks();\n+            mockClientSupplier.producers.get(0).closeException = new RuntimeException(\"KABOOM!\");\n+\n+            final StreamsException thrown = assertThrows(\n+                StreamsException.class,\n+                () -> activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0))\n+            );\n+\n+            assertThat(thrown.getMessage(), is(\"[0_0] task producer encounter error trying to close.\"));\n+            assertThat(thrown.getCause().getMessage(), is(\"KABOOM!\"));\n+\n+            // should not throw again because producer should be removed\n+            activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(new TaskId(0, 0));\n+\n+            mockClientSupplier.producers.clear();\n+        }\n+    }\n+\n+    private void shouldReturnStreamsProducerPerTask() {\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        createTasks();\n+\n+        final StreamsProducer streamsProducer1 = activeTaskCreator.streamsProducerForTask(new TaskId(0, 0));\n+        final StreamsProducer streamsProducer2 = activeTaskCreator.streamsProducerForTask(new TaskId(0, 1));\n+\n+        assertThat(streamsProducer1, not(is(streamsProducer2)));\n+    }\n+\n+    private void shouldConstructProducerMetricsPerTask() {\n+        mockClientSupplier.setApplicationIdForProducer(\"appId\");\n+\n+        createTasks();\n+\n+        final MetricName testMetricName1 = new MetricName(\"test_metric_1\", \"\", \"\", new HashMap<>());\n+        final Metric testMetric1 = new KafkaMetric(\n+            new Object(),\n+            testMetricName1,\n+            (Measurable) (config, now) -> 0,\n+            null,\n+            new MockTime());\n+        mockClientSupplier.producers.get(0).setMockMetrics(testMetricName1, testMetric1);\n+        final MetricName testMetricName2 = new MetricName(\"test_metric_2\", \"\", \"\", new HashMap<>());\n+        final Metric testMetric2 = new KafkaMetric(\n+            new Object(),\n+            testMetricName2,\n+            (Measurable) (config, now) -> 0,\n+            null,\n+            new MockTime());\n+        mockClientSupplier.producers.get(0).setMockMetrics(testMetricName2, testMetric2);\n+\n+        final Map<MetricName, Metric> producerMetrics = activeTaskCreator.producerMetrics();\n+\n+        assertThat(producerMetrics, is(mkMap(mkEntry(testMetricName1, testMetric1), mkEntry(testMetricName2, testMetric2))));\n+    }\n+\n+    private void shouldConstructThreadProducerMetric() {\n+        createTasks();\n+\n         final MetricName testMetricName = new MetricName(\"test_metric\", \"\", \"\", new HashMap<>());\n         final Metric testMetric = new KafkaMetric(\n             new Object(),\n             testMetricName,\n             (Measurable) (config, now) -> 0,\n             null,\n             new MockTime());\n-\n         mockClientSupplier.producers.get(0).setMockMetrics(testMetricName, testMetric);\n+        assertThat(mockClientSupplier.producers.size(), is(1));\n+\n         final Map<MetricName, Metric> producerMetrics = activeTaskCreator.producerMetrics();\n-        assertEquals(testMetricName, producerMetrics.get(testMetricName).metricName());\n-    }\n \n-    @Test\n-    public void shouldConstructProducerMetricsWithEOS() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMwMDkyMA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395300920", "bodyText": "This test does not apply any longer, as we don't pass in application.id into the constructor any more.", "author": "mjsax", "createdAt": "2020-03-19T20:28:41Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamsProducerTest.java", "diffHunk": "@@ -351,22 +404,12 @@ public void shouldSkipAbortTxOnEosAbortIfNotTxInFlight() {\n \n     // error handling tests\n \n-    @Test\n-    public void shouldFailIfApplicationIdIsNullOnEos() {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMwMTQyMA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395301420", "bodyText": "Add a second task to allow testing per-task commit vs thread-producer commit", "author": "mjsax", "createdAt": "2020-03-19T20:29:39Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -1293,24 +1387,31 @@ public void shouldCommitViaProducerIfEosEnabled() {\n             topologyBuilder,\n             adminClient,\n             stateDirectory,\n-            true\n+            new StreamsConfig(mkMap(\n+                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\"),\n+                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\"),\n+                mkEntry(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, eosConfig),\n+                mkEntry(StreamsConfig.UPGRADE_FROM_CONFIG, upgradeFromConfig)\n+            ))\n         );\n         taskManager.setMainConsumer(consumer);\n \n         final StateMachineTask task01 = new StateMachineTask(taskId01, taskId01Partitions, true);\n-        final Map<TopicPartition, OffsetAndMetadata> offsets = singletonMap(t1p1, new OffsetAndMetadata(0L, null));\n-        task01.setCommittableOffsetsAndMetadata(offsets);\n+        task01.setCommittableOffsetsAndMetadata(offsetsT01);\n         task01.setCommitNeeded();\n         taskManager.tasks().put(taskId01, task01);\n+        final StateMachineTask task02 = new StateMachineTask(taskId02, taskId02Partitions, true);\n+        task02.setCommittableOffsetsAndMetadata(offsetsT02);\n+        task02.setCommitNeeded();\n+        taskManager.tasks().put(taskId02, task02);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMzMDQyOA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395330428", "bodyText": "nit: a producer per thread is a bit too much to understand for users since we do not expose it before; maybe just simplify it as \"uses less resources and fewer connections to brokers\"?", "author": "guozhangwang", "createdAt": "2020-03-19T21:29:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -283,10 +297,26 @@\n \n     /**\n      * Config value for parameter {@link #PROCESSING_GUARANTEE_CONFIG \"processing.guarantee\"} for exactly-once processing guarantees.\n+     * <p>\n+     * Enabling exactly-once processing semantics requires broker version 0.11.0 or higher.\n+     * If you enable this feature, Kafka Streams will use a producer per task\n+     * (instead a producer per thread as for the {@link #AT_LEAST_ONCE} case).\n+     *\n+     * @see #EXACTLY_ONCE_BETA\n      */\n     @SuppressWarnings(\"WeakerAccess\")\n     public static final String EXACTLY_ONCE = \"exactly_once\";\n \n+    /**\n+     * Config value for parameter {@link #PROCESSING_GUARANTEE_CONFIG \"processing.guarantee\"} for exactly-once processing guarantees.\n+     * <p>\n+     * Enabling exactly-once (beta) requires broker version 2.4 or higher.\n+     * In contrast to {@link #EXACTLY_ONCE} Kafka Streams uses a producer per thread model,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM1ODM5Ng==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395358396", "bodyText": "Should be 2.5, ditto elsewhere.", "author": "guozhangwang", "createdAt": "2020-03-19T22:38:49Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -450,8 +480,11 @@\n     /** {@code processing.guarantee} */\n     @SuppressWarnings(\"WeakerAccess\")\n     public static final String PROCESSING_GUARANTEE_CONFIG = \"processing.guarantee\";\n-    private static final String PROCESSING_GUARANTEE_DOC = \"The processing guarantee that should be used. Possible values are <code>\" + AT_LEAST_ONCE + \"</code> (default) and <code>\" + EXACTLY_ONCE + \"</code>. \" +\n-        \"Note that exactly-once processing requires a cluster of at least three brokers by default what is the recommended setting for production; for development you can change this, by adjusting broker setting \" +\n+    private static final String PROCESSING_GUARANTEE_DOC = \"The processing guarantee that should be used. \" +\n+        \"Possible values are <code>\" + AT_LEAST_ONCE + \"</code> (default), <code>\" + EXACTLY_ONCE + \"</code>, \" +\n+        \"and <code>\" + EXACTLY_ONCE_BETA + \"</code> (requires brokers version 2.4 or higher). \" +", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM1ODQ3Ng==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395358476", "bodyText": "I think we do not need a new value of upgrade.from here.", "author": "guozhangwang", "createdAt": "2020-03-19T22:39:09Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -515,8 +548,13 @@\n     public static final String UPGRADE_FROM_CONFIG = \"upgrade.from\";\n     private static final String UPGRADE_FROM_DOC = \"Allows upgrading in a backward compatible way. \" +\n         \"This is needed when upgrading from [0.10.0, 1.1] to 2.0+, or when upgrading from [2.0, 2.3] to 2.4+. \" +\n-        \"When upgrading from 2.4 to a newer version it is not required to specify this config. \" +\n-        \"Default is null. Accepted values are \\\"\" + UPGRADE_FROM_0100 + \"\\\", \\\"\" + UPGRADE_FROM_0101 + \"\\\", \\\"\" + UPGRADE_FROM_0102 + \"\\\", \\\"\" + UPGRADE_FROM_0110 + \"\\\", \\\"\" + UPGRADE_FROM_10 + \"\\\", \\\"\" + UPGRADE_FROM_11 + \"\\\", \\\"\" + UPGRADE_FROM_20 + \"\\\", \\\"\" + UPGRADE_FROM_21 + \"\\\", \\\"\" + UPGRADE_FROM_22 + \"\\\", \\\"\" + UPGRADE_FROM_23 + \"\\\" (for upgrading from the corresponding old version).\";\n+        \"When upgrading from [0.11, 2.5] to a newer version it is only required to specify this config if you want to \" +", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM1OTUwMw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395359503", "bodyText": "Not clear why we have to maintain a threadProducer plus a eosBetaStreamsProducer, instead of just a single StreamsProducer typed threadProducer?", "author": "guozhangwang", "createdAt": "2020-03-19T22:41:56Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreator.java", "diffHunk": "@@ -61,6 +59,7 @@\n     private final String applicationId;\n     private final Producer<byte[], byte[]> threadProducer;\n     private final Map<TaskId, StreamsProducer> taskProducers;\n+    private final StreamsProducer eosBetaStreamsProducer;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MDgyNw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395440827", "bodyText": "+1", "author": "abbccdda", "createdAt": "2020-03-20T05:06:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM1OTUwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2MTA4MA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395361080", "bodyText": "nit: Should we also check that taskProducers is empty if this is ever called?", "author": "guozhangwang", "createdAt": "2020-03-19T22:46:35Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreator.java", "diffHunk": "@@ -120,6 +129,13 @@ StreamsProducer streamsProducerForTask(final TaskId taskId) {\n         return taskProducer;\n     }\n \n+    StreamsProducer threadProducer() {\n+        if (eosBetaStreamsProducer == null) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2MjA1MQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395362051", "bodyText": "Not for this PR: I think a better place for these static methods is StreamsConfig.", "author": "guozhangwang", "createdAt": "2020-03-19T22:49:08Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -381,6 +382,33 @@ public static StreamThread create(final InternalTopologyBuilder builder,\n         return streamThread.updateThreadMetadata(getSharedAdminClientId(clientId));\n     }\n \n+    static boolean eosAlphaEnabled(final StreamsConfig config) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM3MTM4MQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395371381", "bodyText": "StreamsConfig is public API and IMHO we should not add those helpers method they as they are internal. Thoughts?", "author": "mjsax", "createdAt": "2020-03-19T23:17:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2MjA1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5MTA2Ng==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395391066", "bodyText": "Can we make it package-private?", "author": "guozhangwang", "createdAt": "2020-03-20T00:31:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2MjA1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5MjE2MQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395392161", "bodyText": "Unfortunately not, because StreamsConfig is in package o.a.k.streams but we use it in o.a.k.streams.processor", "author": "mjsax", "createdAt": "2020-03-20T00:35:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2MjA1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5NDExMw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395394113", "bodyText": "Fair enough, let's keep it inside StreamThread for now.\nIn a longer term refactoring, maybe we could have an StreamsUtil class where such static functions / fields can be stuffed in.", "author": "guozhangwang", "createdAt": "2020-03-20T00:45:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2MjA1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2NDI3Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395364273", "bodyText": "We should not rely on threadProducer == null etc conditions here any more: at the construction time of the TaskCreator, based on the config we already constructed one of the thread-producer, or the empty task producers.\nSo here we should just:\nif (eosAlpha)\n   create task producer and update the producers-map\n\nelse do nothing since we know the thread-producer should have been constructed.", "author": "guozhangwang", "createdAt": "2020-03-19T22:55:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreator.java", "diffHunk": "@@ -153,11 +169,12 @@ StreamsProducer streamsProducerForTask(final TaskId taskId) {\n                 streamsProducer = new StreamsProducer(\n                     clientSupplier.getProducer(producerConfigs),\n                     true,\n-                    applicationId,\n                     logContext);\n                 taskProducers.put(taskId, streamsProducer);\n+            } else if (eosBetaStreamsProducer == null) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2NTM0Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395365343", "bodyText": "Hmm.. I think we should always use the new overloaded function with group-metadata --- if the broker is on lower version the producer's network client would automatically downgrade.", "author": "guozhangwang", "createdAt": "2020-03-19T22:58:33Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "diffHunk": "@@ -161,13 +156,29 @@ private static boolean isRecoverable(final KafkaException uncaughtException) {\n      * @throws IllegalStateException if EOS is disabled\n      * @throws TaskMigratedException\n      */\n-    void commitTransaction(final Map<TopicPartition, OffsetAndMetadata> offsets) throws ProducerFencedException {\n+    void commitTransaction(final Map<TopicPartition, OffsetAndMetadata> offsets,\n+                           final String applicationId) throws ProducerFencedException {\n+        commitTransaction(offsets, applicationId, null);\n+    }\n+\n+    void commitTransaction(final Map<TopicPartition, OffsetAndMetadata> offsets,\n+                           final ConsumerGroupMetadata consumerGroupMetadata) throws ProducerFencedException {\n+        commitTransaction(offsets, null, consumerGroupMetadata);\n+    }\n+\n+    private void commitTransaction(final Map<TopicPartition, OffsetAndMetadata> offsets,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM2NTg4Mg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395365882", "bodyText": "Assuming we do not need eosUpgradeModeEnabled, I'd suggest not using multiple booleans to specify a single state as it is more error prone. Instead we can just have enum if we have to.", "author": "guozhangwang", "createdAt": "2020-03-19T22:59:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -73,7 +74,9 @@\n     private final InternalTopologyBuilder builder;\n     private final Admin adminClient;\n     private final StateDirectory stateDirectory;\n-    private final boolean eosEnabled;\n+    private final boolean eosAlphaEnabled;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQzMDk3Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395430973", "bodyText": "nit: extra space after =", "author": "abbccdda", "createdAt": "2020-03-20T04:04:31Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -988,40 +1017,19 @@ protected StreamsConfig(final Map<?, ?> props,\n         return consumerProps;\n     }\n \n-    private void checkIfUnexpectedUserSpecifiedConsumerConfig(final Map<String, Object> clientProvidedProps, final String[] nonConfigurableConfigs) {\n+    private void checkIfUnexpectedUserSpecifiedConsumerConfig(final Map<String, Object> clientProvidedProps,\n+                                                              final String[] nonConfigurableConfigs) {\n         // Streams does not allow users to configure certain consumer/producer configurations, for example,\n         // enable.auto.commit. In cases where user tries to override such non-configurable\n         // consumer/producer configurations, log a warning and remove the user defined value from the Map.\n         // Thus the default values for these consumer/producer configurations that are suitable for\n         // Streams will be used instead.\n \n-        if (eosEnabled) {\n-            final Object maxInFlightRequests = clientProvidedProps.get(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION);\n-\n-            if (maxInFlightRequests != null) {\n-                final int maxInFlightRequestsAsInteger;\n-                if (maxInFlightRequests instanceof Integer) {\n-                    maxInFlightRequestsAsInteger = (Integer) maxInFlightRequests;\n-                } else if (maxInFlightRequests instanceof String) {\n-                    try {\n-                        maxInFlightRequestsAsInteger = Integer.parseInt(((String) maxInFlightRequests).trim());\n-                    } catch (final NumberFormatException e) {\n-                        throw new ConfigException(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, maxInFlightRequests, \"String value could not be parsed as 32-bit integer\");\n-                    }\n-                } else {\n-                    throw new ConfigException(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, maxInFlightRequests, \"Expected value to be a 32-bit integer, but it was a \" + maxInFlightRequests.getClass().getName());\n-                }\n-\n-                if (maxInFlightRequestsAsInteger > 5) {\n-                    throw new ConfigException(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, maxInFlightRequestsAsInteger, \"Can't exceed 5 when exactly-once processing is enabled\");\n-                }\n-            }\n-        }\n+        final String nonConfigurableConfigMessage = \"Unexpected user-specified %s config: %s found. %sUser setting (%s) will be ignored and the Streams default setting (%s) will be used \";\n+        final String eosMessage =  PROCESSING_GUARANTEE_CONFIG + \" is set to \" + getString(PROCESSING_GUARANTEE_CONFIG) + \". Hence, \";", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQzMzYzMQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395433631", "bodyText": "Seems we could also refactor out a helper for this check as well?", "author": "abbccdda", "createdAt": "2020-03-20T04:21:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java", "diffHunk": "@@ -988,40 +1017,19 @@ protected StreamsConfig(final Map<?, ?> props,\n         return consumerProps;\n     }\n \n-    private void checkIfUnexpectedUserSpecifiedConsumerConfig(final Map<String, Object> clientProvidedProps, final String[] nonConfigurableConfigs) {\n+    private void checkIfUnexpectedUserSpecifiedConsumerConfig(final Map<String, Object> clientProvidedProps,\n+                                                              final String[] nonConfigurableConfigs) {\n         // Streams does not allow users to configure certain consumer/producer configurations, for example,\n         // enable.auto.commit. In cases where user tries to override such non-configurable\n         // consumer/producer configurations, log a warning and remove the user defined value from the Map.\n         // Thus the default values for these consumer/producer configurations that are suitable for\n         // Streams will be used instead.\n \n-        if (eosEnabled) {\n-            final Object maxInFlightRequests = clientProvidedProps.get(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION);\n-\n-            if (maxInFlightRequests != null) {\n-                final int maxInFlightRequestsAsInteger;\n-                if (maxInFlightRequests instanceof Integer) {\n-                    maxInFlightRequestsAsInteger = (Integer) maxInFlightRequests;\n-                } else if (maxInFlightRequests instanceof String) {\n-                    try {\n-                        maxInFlightRequestsAsInteger = Integer.parseInt(((String) maxInFlightRequests).trim());\n-                    } catch (final NumberFormatException e) {\n-                        throw new ConfigException(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, maxInFlightRequests, \"String value could not be parsed as 32-bit integer\");\n-                    }\n-                } else {\n-                    throw new ConfigException(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, maxInFlightRequests, \"Expected value to be a 32-bit integer, but it was a \" + maxInFlightRequests.getClass().getName());\n-                }\n-\n-                if (maxInFlightRequestsAsInteger > 5) {\n-                    throw new ConfigException(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, maxInFlightRequestsAsInteger, \"Can't exceed 5 when exactly-once processing is enabled\");\n-                }\n-            }\n-        }\n+        final String nonConfigurableConfigMessage = \"Unexpected user-specified %s config: %s found. %sUser setting (%s) will be ignored and the Streams default setting (%s) will be used \";\n+        final String eosMessage =  PROCESSING_GUARANTEE_CONFIG + \" is set to \" + getString(PROCESSING_GUARANTEE_CONFIG) + \". Hence, \";\n \n         for (final String config: nonConfigurableConfigs) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ1Nzg2NQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395457865", "bodyText": "Maybe -- I just extracted to other part to make checkstyle pass :)", "author": "mjsax", "createdAt": "2020-03-20T06:38:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQzMzYzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MDAxMA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395440010", "bodyText": "Could you elaborate what you mean here?", "author": "abbccdda", "createdAt": "2020-03-20T05:01:09Z", "path": "streams/src/test/java/org/apache/kafka/streams/StreamsConfigTest.java", "diffHunk": "@@ -480,6 +484,13 @@ public void shouldAcceptExactlyOnce() {\n         new StreamsConfig(props);\n     }\n \n+    @Test\n+    public void shouldAcceptExactlyOnceBeta() {\n+        // don't use `StreamsConfig.EXACLTY_ONCE_BETA` to actually do a useful test", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ1ODY0Mg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395458642", "bodyText": "If we would use EXACLTY_ONCE_BETA in this test, we would compare EXACLTY_ONCE_BETA == EXACLTY_ONCE_BETA what is not useful -- we should compare EXACLTY_ONCE_BETA == \"exactly_once_beta\" instead.", "author": "mjsax", "createdAt": "2020-03-20T06:42:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MDAxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MjQwNg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395792406", "bodyText": "Makes sense!", "author": "guozhangwang", "createdAt": "2020-03-20T17:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ0MDAxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTcyMTM2MQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395721361", "bodyText": "nit: move comment to next line of else", "author": "abbccdda", "createdAt": "2020-03-20T15:39:55Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreator.java", "diffHunk": "@@ -94,22 +94,34 @@ private static String getTaskProducerClientId(final String threadClientId, final\n         createTaskSensor = ThreadMetrics.createTaskSensor(threadId, streamsMetrics);\n         applicationId = config.getString(StreamsConfig.APPLICATION_ID_CONFIG);\n \n-        if (EXACTLY_ONCE.equals(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG))) {\n+        if (StreamThread.eosAlphaEnabled(config)) {\n+            processingMode = StreamThread.ProcessingMode.EXACTLY_ONCE_ALPHA;\n             threadProducer = null;\n             taskProducers = new HashMap<>();\n-        } else {\n+        } else { // non-eos and eos-beta", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTczMTgyMA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395731820", "bodyText": "Seems like we could extract the processingMode initialization logic to the StreamThread level to share between task creator and task manager", "author": "abbccdda", "createdAt": "2020-03-20T15:55:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreator.java", "diffHunk": "@@ -94,22 +94,34 @@ private static String getTaskProducerClientId(final String threadClientId, final\n         createTaskSensor = ThreadMetrics.createTaskSensor(threadId, streamsMetrics);\n         applicationId = config.getString(StreamsConfig.APPLICATION_ID_CONFIG);\n \n-        if (EXACTLY_ONCE.equals(config.getString(StreamsConfig.PROCESSING_GUARANTEE_CONFIG))) {\n+        if (StreamThread.eosAlphaEnabled(config)) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NDA2Ng==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395794066", "bodyText": "Maybe -- that would lead to more coupling or we need to pass more parameters around?", "author": "mjsax", "createdAt": "2020-03-20T17:41:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTczMTgyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0MDgzMg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395740832", "bodyText": "This could be named as commitInternal", "author": "abbccdda", "createdAt": "2020-03-20T16:09:55Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -692,12 +711,17 @@ Task taskForInputPartition(final TopicPartition partition) {\n      * @return number of committed offsets, or -1 if we are in the middle of a rebalance and cannot commit\n      */\n     int commitAll() {\n+        return commitAll(tasks.values());\n+    }\n+\n+    private int commitAll(final Collection<Task> tasks) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MTYwMA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395791600", "bodyText": "+1, it could make the reading a bit easier.", "author": "guozhangwang", "createdAt": "2020-03-20T17:36:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0MDgzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0Nzk4NQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395747985", "bodyText": "nit: is there a way to verify a function is never called? Like consumer.commit()", "author": "abbccdda", "createdAt": "2020-03-20T16:21:35Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -1293,24 +1335,30 @@ public void shouldCommitViaProducerIfEosEnabled() {\n             topologyBuilder,\n             adminClient,\n             stateDirectory,\n-            true\n+            new StreamsConfig(mkMap(\n+                mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, \"appId\"),\n+                mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"dummy:1234\"),\n+                mkEntry(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, eosConfig)\n+            ))\n         );\n         taskManager.setMainConsumer(consumer);\n \n         final StateMachineTask task01 = new StateMachineTask(taskId01, taskId01Partitions, true);\n-        final Map<TopicPartition, OffsetAndMetadata> offsets = singletonMap(t1p1, new OffsetAndMetadata(0L, null));\n-        task01.setCommittableOffsetsAndMetadata(offsets);\n+        task01.setCommittableOffsetsAndMetadata(offsetsT01);\n         task01.setCommitNeeded();\n         taskManager.tasks().put(taskId01, task01);\n+        final StateMachineTask task02 = new StateMachineTask(taskId02, taskId02Partitions, true);\n+        task02.setCommittableOffsetsAndMetadata(offsetsT02);\n+        task02.setCommitNeeded();\n+        taskManager.tasks().put(taskId02, task02);\n \n-        expect(activeTaskCreator.streamsProducerForTask(taskId01)).andReturn(producer);\n-        producer.commitTransaction(offsets);\n-        expectLastCall();\n-        replay(activeTaskCreator, producer);\n+        reset(consumer);\n+        expect(consumer.groupMetadata()).andReturn(new ConsumerGroupMetadata(\"appId\")).anyTimes();\n+        replay(activeTaskCreator, consumer, producer);\n \n         taskManager.commitAll();\n \n-        verify(producer);\n+        verify(producer, consumer);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NTI0NQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395795245", "bodyText": "This is verified automatically. As we don't register an expected call, the test would fail if it would be called.", "author": "mjsax", "createdAt": "2020-03-20T17:43:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0Nzk4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTcxMQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395749711", "bodyText": "What does task03 and task04 work for?", "author": "abbccdda", "createdAt": "2020-03-20T16:24:20Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -1482,38 +1530,42 @@ public void shouldMaybeCommitActiveTasks() {\n         final StateMachineTask task02 = new StateMachineTask(taskId02, taskId02Partitions, true);\n         final Map<TopicPartition, OffsetAndMetadata> offsets2 = singletonMap(t1p2, new OffsetAndMetadata(2L, null));\n         task02.setCommittableOffsetsAndMetadata(offsets2);\n-        final StateMachineTask task03 = new StateMachineTask(taskId03, taskId03Partitions, false);\n-        final Map<TopicPartition, OffsetAndMetadata> offsets3 = singletonMap(t1p3, new OffsetAndMetadata(3L, null));\n-        task03.setCommittableOffsetsAndMetadata(offsets3);\n+        final StateMachineTask task03 = new StateMachineTask(taskId03, taskId03Partitions, true);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NTk4Mg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395795982", "bodyText": "We have commitNeeded and commitRequested flags. To test all four possible combination how those flags can be set, we need 4 tasks, ie, we close missing test coverage adding new tasks for those cases.", "author": "mjsax", "createdAt": "2020-03-20T17:44:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTcxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NjQ1OQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395756459", "bodyText": "Out of curiosity, why do we add two {} around the code logic here\uff1f", "author": "abbccdda", "createdAt": "2020-03-20T16:35:01Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java", "diffHunk": "@@ -141,82 +255,191 @@ public void shouldFailForUnknownTaskOnStreamsProducerPerTask() {\n         {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5Nzc1OA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395797758", "bodyText": "I want to make variable thrown \"final\" and also not introduce thrown2 -- using two blocks allow to use the same name twice and to declare the variable \"final\". It also make it clear that it's basically two independent tests (we could also separate them into two test methods, but we test the same function and thus it seems better to do both cases in one test).", "author": "mjsax", "createdAt": "2020-03-20T17:47:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NjQ1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc4OTE1NA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395789154", "bodyText": "Not for this PR: FencedInstanceIdException should not be handled as a task-migration exception since it indicates some other instance with the same instance.id has started, and hence this instance should really be closed as a whole.\nJust to clarify your PR did the right thing to not capture it, I just set it as a reminder for myself since I found that some other places we capture FencedInstanceIdException incorrectly.", "author": "guozhangwang", "createdAt": "2020-03-20T17:31:56Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsProducer.java", "diffHunk": "@@ -161,16 +157,17 @@ private static boolean isRecoverable(final KafkaException uncaughtException) {\n      * @throws IllegalStateException if EOS is disabled\n      * @throws TaskMigratedException\n      */\n-    void commitTransaction(final Map<TopicPartition, OffsetAndMetadata> offsets) throws ProducerFencedException {\n+    void commitTransaction(final Map<TopicPartition, OffsetAndMetadata> offsets,\n+                           final ConsumerGroupMetadata consumerGroupMetadata) throws ProducerFencedException {\n         if (!eosEnabled) {\n             throw new IllegalStateException(formatException(\"EOS is disabled\"));\n         }\n         maybeBeginTransaction();\n         try {\n-            producer.sendOffsetsToTransaction(offsets, applicationId);\n+            producer.sendOffsetsToTransaction(offsets, consumerGroupMetadata);\n             producer.commitTransaction();\n             transactionInFlight = false;\n-        } catch (final ProducerFencedException error) {\n+        } catch (final ProducerFencedException | CommitFailedException error) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MTExMQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395791111", "bodyText": "We have duplicated logic here and in TaskCreator to define the processingMode, could we just let the thread decide and then pass the decision along in callee constructors?", "author": "guozhangwang", "createdAt": "2020-03-20T17:35:27Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -107,7 +108,13 @@\n         this.builder = builder;\n         this.adminClient = adminClient;\n         this.stateDirectory = stateDirectory;\n-        this.eosEnabled = eosEnabled;\n+        if (StreamThread.eosAlphaEnabled(config)) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5OTY1Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395799653", "bodyText": "Maybe -- that would lead to more coupling or we need to pass more parameters around? I like to reduce the number of parameters we need to forward and we have config already at hand for many other reasons. Strictly, we should never forward config, but extract the config we need and only pass those along -- but it blows up the code.\nThought?", "author": "mjsax", "createdAt": "2020-03-20T17:51:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MTExMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgzMTI0Nw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395831247", "bodyText": "For TaskCreator and TaskManager here's my thoughts: ideally the taskCreators could be constructed inside task-manager, but for unit testings we want to mock the creators sometimes so we create them outside of task-manager, inside stream-thread. So for this special case I think passing the ProcessMode into these two classes are okay, since for most other cases the hierarchy is natural and we would only see the construction of such parameters in a single place.", "author": "guozhangwang", "createdAt": "2020-03-20T18:52:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MTExMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NjU0Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395796543", "bodyText": "Could we add a few more unit tests for:\n\nWhen handling Revocation, we commit all tasks.\nWhen handling Assignment (where we may close some tasks), we commit all tasks.\nWhen committing upon user-requested, we commit all tasks.\n\nPardon me if they are already covered, and just lmk :)", "author": "guozhangwang", "createdAt": "2020-03-20T17:45:38Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -25,6 +25,7 @@\n import org.apache.kafka.clients.admin.RecordsToDelete;\n import org.apache.kafka.clients.consumer.CommitFailedException;\n import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerGroupMetadata;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgyMjM0OQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395822349", "bodyText": "Added new test for (1). Case (3) is covered by modified test shouldMaybeCommitAllActiveTasksThatNeedCommit (formally shouldMaybeCommitActiveTasks).\nFor case (2), I am not sure if we need to change anything? handleAssignment() is not changed in this PR, because we either resume a task or close it: if we resume a task there is nothing to be committed from my understanding and thus it seems sufficient to only commit tasks that we close?", "author": "mjsax", "createdAt": "2020-03-20T18:34:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NjU0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgyOTYwOA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395829608", "bodyText": "With 2) under eos-beta, when committing the txn we would avoidably commit the sent records from other tasks; so I'm wondering if we should also commit them as well, otherwise some outgoing records would be included in the txn while the incoming partition offsets would not be committed.", "author": "guozhangwang", "createdAt": "2020-03-20T18:49:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NjU0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg0MDQ1MA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395840450", "bodyText": "Ack. My miss-conception was that a task would be in SUSPENDED state when we resume it (and thus it would have been committed already). However, it seems that resume() can also happen for a RUNNING task, for which case it's a no-op. Will fix it.", "author": "mjsax", "createdAt": "2020-03-20T19:11:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NjU0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg0MTM2Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395841363", "bodyText": "Yeah with KIP-429, during the rebalance some tasks would still be processed and hence records being sent out; so the resuming tasks could be in RUNNING state as well.", "author": "guozhangwang", "createdAt": "2020-03-20T19:13:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NjU0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg5NTg3Mw==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395895873", "bodyText": "Ack. Fixed TaskManager#handleAssignment() and added new tests for case (2)", "author": "mjsax", "createdAt": "2020-03-20T21:22:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5NjU0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNTMxOA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395935318", "bodyText": "nit: we could use mkMap helper here as well.", "author": "abbccdda", "createdAt": "2020-03-20T23:50:23Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -727,6 +731,181 @@ public void shouldSuspendActiveTasks() {\n         assertThat(task00.state(), is(Task.State.SUSPENDED));\n     }\n \n+    @Test\n+    public void shouldCommitAllActiveTasksTheNeedCommittingOnHandleAssignmentIfOneTaskClosed() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+\n+        final StateMachineTask task01 = new StateMachineTask(taskId01, taskId01Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets01 = singletonMap(t1p1, new OffsetAndMetadata(1L, null));\n+        task01.setCommittableOffsetsAndMetadata(offsets01);\n+        task01.setCommitNeeded();\n+\n+        final StateMachineTask task02 = new StateMachineTask(taskId02, taskId02Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets02 = singletonMap(t1p2, new OffsetAndMetadata(2L, null));\n+        task02.setCommittableOffsetsAndMetadata(offsets02);\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TopicPartition, OffsetAndMetadata> expectedCommittedOffsets = new HashMap<>();\n+        expectedCommittedOffsets.putAll(offsets00);\n+        expectedCommittedOffsets.putAll(offsets01);\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentActive = mkMap(\n+            mkEntry(taskId00, taskId00Partitions),\n+            mkEntry(taskId01, taskId01Partitions),\n+            mkEntry(taskId02, taskId02Partitions)\n+        );\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentStandby = mkMap(\n+            mkEntry(taskId10, taskId10Partitions)\n+        );\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(assignmentActive)))\n+            .andReturn(asList(task00, task01, task02));\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(taskId00);\n+        expectLastCall();\n+        expect(standbyTaskCreator.createTasks(eq(assignmentStandby)))\n+            .andReturn(singletonList(task10));\n+        consumer.commitSync(expectedCommittedOffsets);\n+        expectLastCall();\n+\n+        replay(activeTaskCreator, standbyTaskCreator, consumer, changeLogReader);\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertThat(task01.state(), is(Task.State.RUNNING));\n+        assertThat(task02.state(), is(Task.State.RUNNING));\n+        assertThat(task10.state(), is(Task.State.RUNNING));\n+\n+        assignmentActive.remove(taskId00);\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+\n+        assertThat(task00.commitNeeded, is(false));\n+        assertThat(task01.commitNeeded, is(false));\n+        assertThat(task02.commitPrepared, is(false));\n+        assertThat(task10.commitPrepared, is(false));\n+    }\n+\n+    @Test\n+    public void shouldNotCommitOnHandleAssignmentIfNoTaskClosed() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+        task00.setCommitNeeded();\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentActive = singletonMap(taskId00, taskId00Partitions);\n+        final Map<TaskId, Set<TopicPartition>> assignmentStandby = singletonMap(taskId10, taskId10Partitions);\n+\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(assignmentActive))).andReturn(singleton(task00));\n+        expect(standbyTaskCreator.createTasks(eq(assignmentStandby))).andReturn(singletonList(task10));\n+\n+        replay(activeTaskCreator, standbyTaskCreator, consumer, changeLogReader);\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertThat(task10.state(), is(Task.State.RUNNING));\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+\n+        assertThat(task00.commitNeeded, is(true));\n+        assertThat(task10.commitPrepared, is(false));\n+    }\n+\n+    @Test\n+    public void shouldNotCommitOnHandleAssignmentIfOnlyStandbyTaskClosed() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+        task00.setCommitNeeded();\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentActive = singletonMap(taskId00, taskId00Partitions);\n+        final Map<TaskId, Set<TopicPartition>> assignmentStandby = singletonMap(taskId10, taskId10Partitions);\n+\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(assignmentActive))).andReturn(singleton(task00));\n+        expect(standbyTaskCreator.createTasks(eq(assignmentStandby))).andReturn(singletonList(task10));\n+\n+        replay(activeTaskCreator, standbyTaskCreator, consumer, changeLogReader);\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertThat(task10.state(), is(Task.State.RUNNING));\n+\n+        taskManager.handleAssignment(assignmentActive, Collections.emptyMap());\n+\n+        assertThat(task00.commitNeeded, is(true));\n+        assertThat(task10.commitPrepared, is(false));\n+    }\n+\n+    @Test\n+    public void shouldCommitAllActiveTasksTheNeedCommittingOnRevocation() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+\n+        final StateMachineTask task01 = new StateMachineTask(taskId01, taskId01Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets01 = singletonMap(t1p1, new OffsetAndMetadata(1L, null));\n+        task01.setCommittableOffsetsAndMetadata(offsets01);\n+        task01.setCommitNeeded();\n+\n+        final StateMachineTask task02 = new StateMachineTask(taskId02, taskId02Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets02 = singletonMap(t1p2, new OffsetAndMetadata(2L, null));\n+        task02.setCommittableOffsetsAndMetadata(offsets02);\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TopicPartition, OffsetAndMetadata> expectedCommittedOffsets = new HashMap<>();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MDA2NA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395950064", "bodyText": "What is the advantage as we only need a empty map?", "author": "mjsax", "createdAt": "2020-03-21T01:49:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNTMxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1NzQ4OQ==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395957489", "bodyText": "ah, sg", "author": "abbccdda", "createdAt": "2020-03-21T03:36:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNTMxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNjkzNA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395936934", "bodyText": "Could you elaborate why we check commitNeeded for task00 and task01, while check for commitPrepared for task02 and task10 here? I'm needing some clarification here.", "author": "abbccdda", "createdAt": "2020-03-20T23:59:33Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -727,6 +731,181 @@ public void shouldSuspendActiveTasks() {\n         assertThat(task00.state(), is(Task.State.SUSPENDED));\n     }\n \n+    @Test\n+    public void shouldCommitAllActiveTasksTheNeedCommittingOnHandleAssignmentIfOneTaskClosed() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+\n+        final StateMachineTask task01 = new StateMachineTask(taskId01, taskId01Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets01 = singletonMap(t1p1, new OffsetAndMetadata(1L, null));\n+        task01.setCommittableOffsetsAndMetadata(offsets01);\n+        task01.setCommitNeeded();\n+\n+        final StateMachineTask task02 = new StateMachineTask(taskId02, taskId02Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets02 = singletonMap(t1p2, new OffsetAndMetadata(2L, null));\n+        task02.setCommittableOffsetsAndMetadata(offsets02);\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TopicPartition, OffsetAndMetadata> expectedCommittedOffsets = new HashMap<>();\n+        expectedCommittedOffsets.putAll(offsets00);\n+        expectedCommittedOffsets.putAll(offsets01);\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentActive = mkMap(\n+            mkEntry(taskId00, taskId00Partitions),\n+            mkEntry(taskId01, taskId01Partitions),\n+            mkEntry(taskId02, taskId02Partitions)\n+        );\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentStandby = mkMap(\n+            mkEntry(taskId10, taskId10Partitions)\n+        );\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(assignmentActive)))\n+            .andReturn(asList(task00, task01, task02));\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(taskId00);\n+        expectLastCall();\n+        expect(standbyTaskCreator.createTasks(eq(assignmentStandby)))\n+            .andReturn(singletonList(task10));\n+        consumer.commitSync(expectedCommittedOffsets);\n+        expectLastCall();\n+\n+        replay(activeTaskCreator, standbyTaskCreator, consumer, changeLogReader);\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertThat(task01.state(), is(Task.State.RUNNING));\n+        assertThat(task02.state(), is(Task.State.RUNNING));\n+        assertThat(task10.state(), is(Task.State.RUNNING));\n+\n+        assignmentActive.remove(taskId00);\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+\n+        assertThat(task00.commitNeeded, is(false));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MDM0NA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395950344", "bodyText": "For task00 and task01 the commitNeeded flag is set to true. Both are committed, thus prepareCommit() should be called as well as postCommit() -- a check if commitNeeded was reset to false covers both.\nFor task02 and task03 the commitNeeded flag is false though and both should not be committed -- hence, we check of prepareCommit was not called.\nDoes this make sense?", "author": "mjsax", "createdAt": "2020-03-21T01:53:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNjkzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNzIwMg==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395937202", "bodyText": "Why we don't check task00 here?", "author": "abbccdda", "createdAt": "2020-03-21T00:00:49Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/TaskManagerTest.java", "diffHunk": "@@ -727,6 +731,181 @@ public void shouldSuspendActiveTasks() {\n         assertThat(task00.state(), is(Task.State.SUSPENDED));\n     }\n \n+    @Test\n+    public void shouldCommitAllActiveTasksTheNeedCommittingOnHandleAssignmentIfOneTaskClosed() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+\n+        final StateMachineTask task01 = new StateMachineTask(taskId01, taskId01Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets01 = singletonMap(t1p1, new OffsetAndMetadata(1L, null));\n+        task01.setCommittableOffsetsAndMetadata(offsets01);\n+        task01.setCommitNeeded();\n+\n+        final StateMachineTask task02 = new StateMachineTask(taskId02, taskId02Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets02 = singletonMap(t1p2, new OffsetAndMetadata(2L, null));\n+        task02.setCommittableOffsetsAndMetadata(offsets02);\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TopicPartition, OffsetAndMetadata> expectedCommittedOffsets = new HashMap<>();\n+        expectedCommittedOffsets.putAll(offsets00);\n+        expectedCommittedOffsets.putAll(offsets01);\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentActive = mkMap(\n+            mkEntry(taskId00, taskId00Partitions),\n+            mkEntry(taskId01, taskId01Partitions),\n+            mkEntry(taskId02, taskId02Partitions)\n+        );\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentStandby = mkMap(\n+            mkEntry(taskId10, taskId10Partitions)\n+        );\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(assignmentActive)))\n+            .andReturn(asList(task00, task01, task02));\n+        activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(taskId00);\n+        expectLastCall();\n+        expect(standbyTaskCreator.createTasks(eq(assignmentStandby)))\n+            .andReturn(singletonList(task10));\n+        consumer.commitSync(expectedCommittedOffsets);\n+        expectLastCall();\n+\n+        replay(activeTaskCreator, standbyTaskCreator, consumer, changeLogReader);\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertThat(task01.state(), is(Task.State.RUNNING));\n+        assertThat(task02.state(), is(Task.State.RUNNING));\n+        assertThat(task10.state(), is(Task.State.RUNNING));\n+\n+        assignmentActive.remove(taskId00);\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+\n+        assertThat(task00.commitNeeded, is(false));\n+        assertThat(task01.commitNeeded, is(false));\n+        assertThat(task02.commitPrepared, is(false));\n+        assertThat(task10.commitPrepared, is(false));\n+    }\n+\n+    @Test\n+    public void shouldNotCommitOnHandleAssignmentIfNoTaskClosed() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+        task00.setCommitNeeded();\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentActive = singletonMap(taskId00, taskId00Partitions);\n+        final Map<TaskId, Set<TopicPartition>> assignmentStandby = singletonMap(taskId10, taskId10Partitions);\n+\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(assignmentActive))).andReturn(singleton(task00));\n+        expect(standbyTaskCreator.createTasks(eq(assignmentStandby))).andReturn(singletonList(task10));\n+\n+        replay(activeTaskCreator, standbyTaskCreator, consumer, changeLogReader);\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertThat(task10.state(), is(Task.State.RUNNING));\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+\n+        assertThat(task00.commitNeeded, is(true));\n+        assertThat(task10.commitPrepared, is(false));\n+    }\n+\n+    @Test\n+    public void shouldNotCommitOnHandleAssignmentIfOnlyStandbyTaskClosed() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+        task00.setCommitNeeded();\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentActive = singletonMap(taskId00, taskId00Partitions);\n+        final Map<TaskId, Set<TopicPartition>> assignmentStandby = singletonMap(taskId10, taskId10Partitions);\n+\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(assignmentActive))).andReturn(singleton(task00));\n+        expect(standbyTaskCreator.createTasks(eq(assignmentStandby))).andReturn(singletonList(task10));\n+\n+        replay(activeTaskCreator, standbyTaskCreator, consumer, changeLogReader);\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertThat(task10.state(), is(Task.State.RUNNING));\n+\n+        taskManager.handleAssignment(assignmentActive, Collections.emptyMap());\n+\n+        assertThat(task00.commitNeeded, is(true));\n+        assertThat(task10.commitPrepared, is(false));\n+    }\n+\n+    @Test\n+    public void shouldCommitAllActiveTasksTheNeedCommittingOnRevocation() {\n+        final StateMachineTask task00 = new StateMachineTask(taskId00, taskId00Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets00 = singletonMap(t1p0, new OffsetAndMetadata(0L, null));\n+        task00.setCommittableOffsetsAndMetadata(offsets00);\n+\n+        final StateMachineTask task01 = new StateMachineTask(taskId01, taskId01Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets01 = singletonMap(t1p1, new OffsetAndMetadata(1L, null));\n+        task01.setCommittableOffsetsAndMetadata(offsets01);\n+        task01.setCommitNeeded();\n+\n+        final StateMachineTask task02 = new StateMachineTask(taskId02, taskId02Partitions, true);\n+        final Map<TopicPartition, OffsetAndMetadata> offsets02 = singletonMap(t1p2, new OffsetAndMetadata(2L, null));\n+        task02.setCommittableOffsetsAndMetadata(offsets02);\n+\n+        final StateMachineTask task10 = new StateMachineTask(taskId10, taskId10Partitions, false);\n+\n+        final Map<TopicPartition, OffsetAndMetadata> expectedCommittedOffsets = new HashMap<>();\n+        expectedCommittedOffsets.putAll(offsets00);\n+        expectedCommittedOffsets.putAll(offsets01);\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentActive = mkMap(\n+            mkEntry(taskId00, taskId00Partitions),\n+            mkEntry(taskId01, taskId01Partitions),\n+            mkEntry(taskId02, taskId02Partitions)\n+        );\n+\n+        final Map<TaskId, Set<TopicPartition>> assignmentStandby = mkMap(\n+            mkEntry(taskId10, taskId10Partitions)\n+        );\n+        expectRestoreToBeCompleted(consumer, changeLogReader);\n+\n+        expect(activeTaskCreator.createTasks(anyObject(), eq(assignmentActive)))\n+            .andReturn(asList(task00, task01, task02));\n+        expect(standbyTaskCreator.createTasks(eq(assignmentStandby)))\n+            .andReturn(singletonList(task10));\n+        consumer.commitSync(expectedCommittedOffsets);\n+        expectLastCall();\n+\n+        replay(activeTaskCreator, standbyTaskCreator, consumer, changeLogReader);\n+\n+        taskManager.handleAssignment(assignmentActive, assignmentStandby);\n+        assertThat(taskManager.tryToCompleteRestoration(), is(true));\n+        assertThat(task00.state(), is(Task.State.RUNNING));\n+        assertThat(task01.state(), is(Task.State.RUNNING));\n+        assertThat(task02.state(), is(Task.State.RUNNING));\n+        assertThat(task10.state(), is(Task.State.RUNNING));\n+\n+        taskManager.handleRevocation(taskId00Partitions);\n+\n+        assertThat(task01.commitPrepared, is(true));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTk1MDUyOA==", "url": "https://github.com/apache/kafka/pull/8318#discussion_r395950528", "bodyText": "Because task00 is the task that is revoked and thus closed -- hence, prepareCommit() is not called for task00 but only prepareClose(). We could add a check for prepareClose but it's a \"distraction\" as the test verifies that non-closed tasks are committed (there is another test that verifies that closed tasks are committed and closed already).\nDoes this make sense?", "author": "mjsax", "createdAt": "2020-03-21T01:55:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkzNzIwMg=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "38b32acf575f32462451c3f67da2742e5cbe1a2c", "url": "https://github.com/apache/kafka/commit/38b32acf575f32462451c3f67da2742e5cbe1a2c", "message": "KAFKA-9451: Enable producer per thread for Streams EOS\n\n- KIP-447\n- add new configs to enable producer per thread EOS\n- enables upgrade path from eos-alpha to eos-beta", "committedDate": "2020-03-21T18:49:38Z", "type": "commit"}, {"oid": "79ec69f3ece88d9405ba30f9ee3eca41d9fe2171", "url": "https://github.com/apache/kafka/commit/79ec69f3ece88d9405ba30f9ee3eca41d9fe2171", "message": "Fix checkstyle", "committedDate": "2020-03-21T18:49:38Z", "type": "commit"}, {"oid": "e982b0f8ae89909e04e79fc6bfddf706a8b27741", "url": "https://github.com/apache/kafka/commit/e982b0f8ae89909e04e79fc6bfddf706a8b27741", "message": "Simplify upgrade path", "committedDate": "2020-03-21T18:49:38Z", "type": "commit"}, {"oid": "b724be1c49c648fd0e1e9630141d6752f6b38f3c", "url": "https://github.com/apache/kafka/commit/b724be1c49c648fd0e1e9630141d6752f6b38f3c", "message": "Github comments", "committedDate": "2020-03-21T18:49:38Z", "type": "commit"}, {"oid": "59154ab4ee7c4f24706911fb37b8118510d1a3a1", "url": "https://github.com/apache/kafka/commit/59154ab4ee7c4f24706911fb37b8118510d1a3a1", "message": "Github comment", "committedDate": "2020-03-21T18:49:38Z", "type": "commit"}, {"oid": "59154ab4ee7c4f24706911fb37b8118510d1a3a1", "url": "https://github.com/apache/kafka/commit/59154ab4ee7c4f24706911fb37b8118510d1a3a1", "message": "Github comment", "committedDate": "2020-03-21T18:49:38Z", "type": "forcePushed"}]}