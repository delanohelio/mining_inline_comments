{"pr_number": 8661, "pr_title": "KAFKA-9603: Do not turn on bulk loading for segmented stores on stand-by tasks", "pr_createdAt": "2020-05-12T19:57:30Z", "pr_url": "https://github.com/apache/kafka/pull/8661", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r423998385", "bodyText": "This code is either redundant or wrong. If on an active task it is redundant because bulk loading is turned on and off by onRestoreStart() and onRestoreEnd() in RocksDBSegmentsBatchingRestoreCallback. If on a stand-by task it is wrong because bulk loading is turned on but never off leading to an ever increasing number of open file descriptors.", "author": "cadonna", "createdAt": "2020-05-12T20:00:55Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/AbstractRocksDBSegmentedBytesStore.java", "diffHunk": "@@ -248,17 +243,6 @@ void restoreAllInternal(final Collection<KeyValue<byte[], byte[]>> records) {\n             final long segmentId = segments.segmentId(timestamp);\n             final S segment = segments.getOrCreateSegmentIfLive(segmentId, context, observedStreamTime);\n             if (segment != null) {\n-                // This handles the case that state store is moved to a new client and does not\n-                // have the local RocksDB instance for the segment. In this case, toggleDBForBulkLoading\n-                // will only close the database and open it again with bulk loading enabled.\n-                if (!bulkLoadSegments.contains(segment)) {\n-                    segment.toggleDbForBulkLoading(true);\n-                    // If the store does not exist yet, the getOrCreateSegmentIfLive will call openDB that\n-                    // makes the open flag for the newly created store.\n-                    // if the store does exist already, then toggleDbForBulkLoading will make sure that\n-                    // the store is already open here.\n-                    bulkLoadSegments = new HashSet<>(segments.allSegments());\n-                }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDE5MzQzMw==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r424193433", "bodyText": "I think the original motivation is that what if the segment does not exist (e.g. its time range is old) yet when we turn on bulk loading for all. Would that be a problem?", "author": "guozhangwang", "createdAt": "2020-05-13T06:10:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDI0NTMyNQ==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r424245325", "bodyText": "As far as I understand, the removed code tries to optimize the loading of the segment if there is no data on the client (i.e. state directory for this segment does not exist or is empty). Looking at the code, this optimization is only done for segmented state stores. We never turn on bulk loading on stand-by tasks for other store types. In other words,  for stand-by tasks we do not use the restore callbacks onRestoreStart() and onRestoreEnd(), where bulk loading is turned on and off. If we did, the removed code would be redundant. Furthermore, segment.toggleDbForBulkLoading(true); is called here, but I could not find the corresponding segment.toggleDbForBulkLoading(false); which makes the code wrong.\nRegarding the effect of this \"optimization\" on active tasks, turning on bulk loading will close and open the segment. However, if the active task is in restore state (which it should be if there is no data on the client), the segment should already have bulk loading turned on. Thus, closing and opening the segment is useless.\nSo my conclusion is, that the removed code is either redundant or wrong. Let me know, if I missed anything.\nI run the code provided by https://github.com/lpandzic/kafka-9603 with and without this fix and the open file descriptors are not steadily increasing anymore with the fix.\nMaybe it would be possible to turn on bulk loading also for stand-by tasks, if we find good conditions that can be used to turn bulk loading on and off, but this is out of scope for this fix, IMO.", "author": "cadonna", "createdAt": "2020-05-13T07:59:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDYwNzIyMA==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r424607220", "bodyText": "From my understanding, we only want to use bulk loading for active tasks. However if the segmented store is empty, onRestoreStart() would not open anything in bulk loading mode, as there is nothing to be opened. During restore, we might create new segments and we want those segments to be opened in bulk load mode; this is what this code does. Later, onRestoreEnd() would switch off bulk loading for all previously existing and all newly created segments.\nThe bug seems to be, that we also open new segments in bulk load mode for standby tasks. Hence, instead of removing the code, the right fix seem to be to check if the task is active/restoring or a standby and keep the feature for active/restoring but disable it for standby tasks?", "author": "mjsax", "createdAt": "2020-05-13T17:24:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDYzMDU5Mg==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r424630592", "bodyText": "I agree. Nothing else in the bulk loading mode is particularly useful considering how we load standbys at the moment so we should just disable/skip this unless active.\nI only ask that we try and do so in a way that doesn't become a nightmare for the active <--> standby task conversion \ud83d\ude42", "author": "ableegoldman", "createdAt": "2020-05-13T18:03:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY0NTk4OQ==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r424645989", "bodyText": "OK, now I see what I missed. I should have known that it could not have been that easy. I need to think about a better fix. I will keep active <---> standby conversion in mind.", "author": "cadonna", "createdAt": "2020-05-13T18:29:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc2MTIxOQ==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r424761219", "bodyText": "Actually even for standby tasks, it should also be beneficial to use bulk-loading right (e.g. if the standby is far behind the active and has a large amount of records)?\nI'm thinking that in the long run, maybe we could optionally allow restore callbacks to be triggered for standby as well: we can use some simple heuristics such that if the changelog log-end offset - standby task's store offset > certain threshold, we trigger onRestoreStart(), and then we can goes back from the \"sprinting\" mode to normal mode after we've been close enough to the log-end offset.\nAt the mean time, we can maybe hack a bit so that when segment.toggleDbForBulkLoading we set a flag and in the other we reset the flag, then during restoreAll we check the flag to decide whether enable bulk loading for newly created segment.", "author": "guozhangwang", "createdAt": "2020-05-13T22:13:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc3MTc4Mw==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r424771783", "bodyText": "Here are the current bulk loading configs:\ndbOptions.setMaxBackgroundFlushes(4);\ncolumnFamilyOptions.setDisableAutoCompactions(true);\ncolumnFamilyOptions.setLevel0FileNumCompactionTrigger(1 << 30);\ncolumnFamilyOptions.setLevel0SlowdownWritesTrigger(1 << 30);\ncolumnFamilyOptions.setLevel0StopWritesTrigger(1 << 30);\n\nSetting aside the problems these are causing users even for active tasks, they basically mean \"shove everything into the lowest file level and never attempt to limit these writes\". This is useful if you're just trying to shove a lot of data into a store as fast as possible but not necessary need to use it immediately after, which is (debatably) the right thing for restoring tasks but definitely not appropriate for standbys*. We will attempt to restore a batch of records once per main thread loop, which means doing a lot of other stuff in between. There's no reason not to just use normal mode writing for standbys AFAICT -- also bulk loading will make IQ on standbys pretty annoying at best.\n*In the larger scope, perhaps when we move standbys to a separate thread, I'd say we actually should be turning on bulk loading. BUT we need to issue a manual compaction every so often, and ideally not flush them during every commit (related to KAFKA-9450", "author": "ableegoldman", "createdAt": "2020-05-13T22:41:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc5NjYyNQ==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r424796625", "bodyText": "Yup, that makes sense to me. I'm thinking about the world where standbys (and also restoring tasks) are executed on different threads. The concern about IQ are valid indeed that with a large set of un-compacted L0 files.\nIn the even larger scope, where we would have checkpoints I'd believe that bulk-loading would not be very necessary since we would not have a huge number of records to catch up any more :)", "author": "guozhangwang", "createdAt": "2020-05-13T23:57:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTU0OTk4MA==", "url": "https://github.com/apache/kafka/pull/8661#discussion_r425549980", "bodyText": "Actually, I'm now thinking that when we moved the ChangelogReader out of the stream thread, should we just consider removing the bulk loading logic for everyone.", "author": "guozhangwang", "createdAt": "2020-05-15T03:45:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzk5ODM4NQ=="}], "type": "inlineReview"}, {"oid": "8bdd278fa943ddf9d10b9910c0fb9aa8af10855d", "url": "https://github.com/apache/kafka/commit/8bdd278fa943ddf9d10b9910c0fb9aa8af10855d", "message": "KAFKA-9603: Do not turn on bulk loading for segmented stores on standby tasks\n\nSegmented state stores turn on bulk loading of the underlying RocksDB\nwhen restoring. This is correct for segmented state stores that\nare in restore mode on active tasks and the onRestoreStart() and\nonRestoreEnd() in RocksDBSegmentsBatchingRestoreCallback take care\nof toggling bulk loading mode on and off. However, restoreAll()\nin RocksDBSegmentsBatchingRestoreCallback might also turn on bulk loading\nmode. When this happens on a stand-by task bulk loading mode is never\nturned off. That leads to steadily increasing open file decriptors\nin RocksDB because in bulk loading mode RocksDB creates continuously new\nfiles but never compacts them (which is the intended behaviour).\n\nThis PR removes the code that turns on bulk loading mode in restoreAll()\nfor segemented state stores because it is redundant. If the state store\nis in restoring mode on an active task bulk loading is turned on and off\nanyways. On stand-by tasks bulk loading mode should never be turned on.", "committedDate": "2020-05-19T08:08:57Z", "type": "commit"}, {"oid": "1ae11cc84d8daa53cefe66e751feee8502c85d55", "url": "https://github.com/apache/kafka/commit/1ae11cc84d8daa53cefe66e751feee8502c85d55", "message": "Revert \"KAFKA-9603: Do not turn on bulk loading for segmented stores on standby tasks\"\n\nThis reverts commit 8bdd278fa943ddf9d10b9910c0fb9aa8af10855d.", "committedDate": "2020-05-19T08:11:32Z", "type": "commit"}, {"oid": "31707876d03eb2448189518ed4cf056ce4952a6b", "url": "https://github.com/apache/kafka/commit/31707876d03eb2448189518ed4cf056ce4952a6b", "message": "Use consolidated processor context to check for type of task", "committedDate": "2020-05-19T09:24:35Z", "type": "commit"}, {"oid": "31707876d03eb2448189518ed4cf056ce4952a6b", "url": "https://github.com/apache/kafka/commit/31707876d03eb2448189518ed4cf056ce4952a6b", "message": "Use consolidated processor context to check for type of task", "committedDate": "2020-05-19T09:24:35Z", "type": "forcePushed"}]}