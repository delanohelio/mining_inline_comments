{"pr_number": 8669, "pr_title": "MINOR: consolidate processor context for active/standby", "pr_createdAt": "2020-05-14T22:18:52Z", "pr_url": "https://github.com/apache/kafka/pull/8669", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTQ2NzA3NA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425467074", "bodyText": "I felt these were just cluttering up this class so I moved them to a new file", "author": "ableegoldman", "createdAt": "2020-05-14T22:31:27Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextImpl.java", "diffHunk": "@@ -198,433 +196,51 @@ public StateStore getStateStore(final String name) {\n \n     @Override\n     public void commit() {\n-        task.requestCommit();\n+        throwUnsupportedOperationExceptionIfStandby(\"commit\");\n+        applyStreamTaskOperation(StreamTask::requestCommit);\n     }\n \n     @Override\n     @Deprecated\n     public Cancellable schedule(final long intervalMs,\n                                 final PunctuationType type,\n                                 final Punctuator callback) {\n+        throwUnsupportedOperationExceptionIfStandby(\"schedule\");\n         if (intervalMs < 1) {\n             throw new IllegalArgumentException(\"The minimum supported scheduling interval is 1 millisecond.\");\n         }\n-        return task.schedule(intervalMs, type, callback);\n+        return returnStreamTaskOperation(t -> t.schedule(intervalMs, type, callback));\n     }\n \n     @SuppressWarnings(\"deprecation\") // removing #schedule(final long intervalMs,...) will fix this\n     @Override\n     public Cancellable schedule(final Duration interval,\n                                 final PunctuationType type,\n                                 final Punctuator callback) throws IllegalArgumentException {\n+        throwUnsupportedOperationExceptionIfStandby(\"schedule\");\n         final String msgPrefix = prepareMillisCheckFailMsgPrefix(interval, \"interval\");\n         return schedule(ApiUtils.validateMillisecondDuration(interval, msgPrefix), type, callback);\n     }\n \n-    private abstract static class StateStoreReadOnlyDecorator<T extends StateStore, K, V>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "10b206864874aa6f3eb58fa5e7a3fe2844960e84", "url": "https://github.com/apache/kafka/commit/10b206864874aa6f3eb58fa5e7a3fe2844960e84", "message": "add taskType method", "committedDate": "2020-05-15T00:09:23Z", "type": "commit"}, {"oid": "cbb68fdeba44b0dae6dc4fe8abc48bbf235d2a9f", "url": "https://github.com/apache/kafka/commit/cbb68fdeba44b0dae6dc4fe8abc48bbf235d2a9f", "message": "removed StandbyContextImpl", "committedDate": "2020-05-15T00:09:25Z", "type": "commit"}, {"oid": "0600e5c6294a09f2b31c26ffedc6be716673232e", "url": "https://github.com/apache/kafka/commit/0600e5c6294a09f2b31c26ffedc6be716673232e", "message": "checkstyle", "committedDate": "2020-05-15T00:09:25Z", "type": "commit"}, {"oid": "7aeaa20f14b60448eec98de9d820c8a3a2edc077", "url": "https://github.com/apache/kafka/commit/7aeaa20f14b60448eec98de9d820c8a3a2edc077", "message": "fix mocks", "committedDate": "2020-05-15T00:09:25Z", "type": "commit"}, {"oid": "2a506c44c19deee43eef65e0e18d6857a21e5843", "url": "https://github.com/apache/kafka/commit/2a506c44c19deee43eef65e0e18d6857a21e5843", "message": "return state store", "committedDate": "2020-05-15T00:09:25Z", "type": "commit"}, {"oid": "2a506c44c19deee43eef65e0e18d6857a21e5843", "url": "https://github.com/apache/kafka/commit/2a506c44c19deee43eef65e0e18d6857a21e5843", "message": "return state store", "committedDate": "2020-05-15T00:09:25Z", "type": "forcePushed"}, {"oid": "fe5182ed02c787c9f51dd34a72b47d13f28dd8f3", "url": "https://github.com/apache/kafka/commit/fe5182ed02c787c9f51dd34a72b47d13f28dd8f3", "message": "fix  stupid spotBugs nonsense >:(", "committedDate": "2020-05-15T00:36:59Z", "type": "commit"}, {"oid": "3bd771b040d4f22ace5775e1e0b07efb4733afcc", "url": "https://github.com/apache/kafka/commit/3bd771b040d4f22ace5775e1e0b07efb4733afcc", "message": "fix tests", "committedDate": "2020-05-15T00:50:30Z", "type": "commit"}, {"oid": "a5b4ceeae22b7be174e901e14b69e07872b2f52c", "url": "https://github.com/apache/kafka/commit/a5b4ceeae22b7be174e901e14b69e07872b2f52c", "message": "fix context tests", "committedDate": "2020-05-15T00:54:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTU0NDM3NA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425544374", "bodyText": "All of this (and the other new class below) was just copied over from ProcessorContextImpl. I changed the named to AbstractXXXDecorator since it's an abstract class but it's all otherwise unchanged", "author": "ableegoldman", "createdAt": "2020-05-15T03:21:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractReadOnlyDecorator.java", "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import java.util.List;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.state.KeyValueIterator;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+import org.apache.kafka.streams.state.SessionStore;\n+import org.apache.kafka.streams.state.TimestampedKeyValueStore;\n+import org.apache.kafka.streams.state.TimestampedWindowStore;\n+import org.apache.kafka.streams.state.ValueAndTimestamp;\n+import org.apache.kafka.streams.state.WindowStore;\n+import org.apache.kafka.streams.state.WindowStoreIterator;\n+import org.apache.kafka.streams.state.internals.WrappedStateStore;\n+\n+abstract class AbstractReadOnlyDecorator<T extends StateStore, K, V> extends WrappedStateStore<T, K, V> {", "originalCommit": "a5b4ceeae22b7be174e901e14b69e07872b2f52c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "url": "https://github.com/apache/kafka/commit/632617b7bd1cdcadfa6cd45407f02912ccc00604", "message": "further refactoring", "committedDate": "2020-05-15T04:35:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTU3NjY3NA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425576674", "bodyText": "No logical changes here, just added a check for any methods that were previously overridden in the standby context to throw UnsupportedOperation", "author": "ableegoldman", "createdAt": "2020-05-15T05:39:13Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractProcessorContext.java", "diffHunk": "@@ -113,10 +113,12 @@ public void register(final StateStore store,\n     }\n \n     /**\n+     * @throws UnsupportedOperationException if the current task type is standby", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTU3NzA5NA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425577094", "bodyText": "This class was the root cause of the processor context issue blocking the active <--> standby task conversion. I was taking pieces out of it bit by bit and by the end it seemed pointless to have at all", "author": "ableegoldman", "createdAt": "2020-05-15T05:40:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/StoreChangeLogger.java", "diffHunk": "@@ -1,71 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.streams.state.internals;\n-\n-import org.apache.kafka.common.serialization.Serializer;\n-import org.apache.kafka.streams.processor.ProcessorContext;\n-import org.apache.kafka.streams.processor.internals.ProcessorStateManager;\n-import org.apache.kafka.streams.processor.internals.RecordCollector;\n-import org.apache.kafka.streams.state.StateSerdes;\n-\n-/**\n- * Note that the use of array-typed keys is discouraged because they result in incorrect caching behavior.\n- * If you intend to work on byte arrays as key, for example, you may want to wrap them with the {@code Bytes} class,\n- * i.e. use {@code StoreChangeLogger<Bytes, ...>} rather than {@code StoreChangeLogger<byte[], ...>}.\n- *\n- * @param <K>\n- * @param <V>\n- */\n-class StoreChangeLogger<K, V> {\n-\n-    private final String topic;\n-    private final int partition;\n-    private final ProcessorContext context;\n-    private final RecordCollector collector;\n-    private final Serializer<K> keySerializer;\n-    private final Serializer<V> valueSerializer;\n-\n-    StoreChangeLogger(final String storeName,\n-                      final ProcessorContext context,\n-                      final StateSerdes<K, V> serialization) {\n-        this(storeName, context, context.taskId().partition, serialization);\n-    }\n-\n-    private StoreChangeLogger(final String storeName,\n-                              final ProcessorContext context,\n-                              final int partition,\n-                              final StateSerdes<K, V> serialization) {\n-        topic = ProcessorStateManager.storeChangelogTopic(context.applicationId(), storeName);\n-        this.context = context;\n-        this.partition = partition;\n-        this.collector = ((RecordCollector.Supplier) context).recordCollector();\n-        keySerializer = serialization.keySerializer();\n-        valueSerializer = serialization.valueSerializer();\n-    }\n-\n-    void logChange(final K key,\n-                   final V value) {\n-        logChange(key, value, context.timestamp());\n-    }\n-\n-    void logChange(final K key,", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjEwMTU1OQ==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426101559", "bodyText": "SGTM.", "author": "guozhangwang", "createdAt": "2020-05-16T01:03:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTU3NzA5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTU3NzMwNw==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425577307", "bodyText": "We now just delegate to the context to figure out how/what to log", "author": "ableegoldman", "createdAt": "2020-05-15T05:41:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/state/internals/ChangeLoggingWindowBytesStore.java", "diffHunk": "@@ -114,7 +105,7 @@ public void put(final Bytes key,\n \n     void log(final Bytes key,\n              final byte[] value) {\n-        changeLogger.logChange(key, value);\n+        context.logChange(name(), key, value, context.timestamp());", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg1OTEzNQ==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425859135", "bodyText": "Looks like this doesn't need to be defaulted here. If the logic doesn't apply to all the implementing classes, it's better not to define it in the abstract class.", "author": "vvcephei", "createdAt": "2020-05-15T14:57:01Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractProcessorContext.java", "diffHunk": "@@ -218,4 +230,16 @@ public void initialize() {\n     public void uninitialize() {\n         initialized = false;\n     }\n+\n+    @Override\n+    public TaskType taskType() {\n+        return stateManager.taskType();\n+    }", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk0MTMwOA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425941308", "bodyText": "Ah, actually it does. I should remove the override from the ProcessorContextImpl instead", "author": "ableegoldman", "createdAt": "2020-05-15T17:18:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTg1OTEzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDU4MA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425900580", "bodyText": "It doesn't seem like these need to be defined here, since they're only used outside of this interface.\nThey actually only have two, independent, usages, and it doesn't seem that important to de-duplicate the instances. Can we just copy them to separate constants in the classes that need them?", "author": "vvcephei", "createdAt": "2020-05-15T16:04:23Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/RecordCollector.java", "diffHunk": "@@ -19,13 +19,18 @@\n import org.apache.kafka.clients.producer.Producer;\n import org.apache.kafka.common.TopicPartition;\n import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.BytesSerializer;\n import org.apache.kafka.common.serialization.Serializer;\n import org.apache.kafka.streams.processor.StreamPartitioner;\n \n import java.util.Map;\n \n public interface RecordCollector {\n \n+    BytesSerializer BYTES_KEY_SERIALIZER = new BytesSerializer();\n+    ByteArraySerializer BYTE_ARRAY_VALUE_SERIALIZER = new ByteArraySerializer();\n+", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk0MTgwOQ==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425941809", "bodyText": "Yeah, this was part of a larger refactoring that I walked back. That sounds like a reasonable request \ud83d\udc4d", "author": "ableegoldman", "createdAt": "2020-05-15T17:19:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwMDU4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwNDQ1MA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425904450", "bodyText": "It seems like an abstraction error to have something like this in an abstract class. Much better to just move all the implementations that need it to the concrete classes.\nFor example, it's unclear whether the logic that's protected by this method should include global tasks or not. I.e., was it intended to \"throw if not Active\" (and we just forgot that there are also global tasks), or \"throw if not Active or Global\"? I'm not asking you to answer this question; I'm pointing out that putting this in the abstract class makes the code ambiguous. Even if the code is all correct right now, it's dangerous for maintenence because it would be easy to make the mistake of forgetting about global tasks at any point in the future and introducing a bug.\nOTOH, if all this logic gets pushed into the implementations, then the ProcessorContextImpl can assert that it only gets Active or Standby, and it can safely use this method, while the GlobalContext can take care of itself.", "author": "vvcephei", "createdAt": "2020-05-15T16:11:14Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractProcessorContext.java", "diffHunk": "@@ -218,4 +230,16 @@ public void initialize() {\n     public void uninitialize() {\n         initialized = false;\n     }\n+\n+    @Override\n+    public TaskType taskType() {\n+        return stateManager.taskType();\n+    }\n+\n+    void throwUnsupportedOperationExceptionIfStandby(final String operationName) {\n+        if (taskType() == TaskType.STANDBY) {\n+            throw new UnsupportedOperationException(\n+                \"this should not happen: \" + operationName + \"() is not supported in standby tasks.\");\n+        }\n+    }", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwODk4Mg==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425908982", "bodyText": "We don't need expectLastCall() on these (and everywhere else)?", "author": "vvcephei", "createdAt": "2020-05-15T16:19:07Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingWindowBytesStoreTest.java", "diffHunk": "@@ -113,24 +114,26 @@ public void shouldDelegateToUnderlyingStoreWhenFetchingRange() {\n     @SuppressWarnings(\"deprecation\")\n     public void shouldRetainDuplicatesWhenSet() {\n         store = new ChangeLoggingWindowBytesStore(inner, true);\n+\n         inner.put(bytesKey, value, 0);\n         EasyMock.expectLastCall().times(2);\n \n         init();\n-        store.put(bytesKey, value);\n-        store.put(bytesKey, value);\n \n         final Bytes key1 = WindowKeySchema.toStoreKeyBinary(bytesKey, 0, 1);\n         final Bytes key2 = WindowKeySchema.toStoreKeyBinary(bytesKey, 0, 2);\n-        assertThat(collector.collected().size(), equalTo(2));\n-        assertThat(collector.collected().get(0).key(), equalTo(key1));\n-        assertThat(collector.collected().get(0).value(), equalTo(value));\n-        assertThat(collector.collected().get(0).timestamp(), equalTo(0L));\n-        assertThat(collector.collected().get(1).key(), equalTo(key2));\n-        assertThat(collector.collected().get(1).value(), equalTo(value));\n-        assertThat(collector.collected().get(1).timestamp(), equalTo(0L));\n \n-        EasyMock.verify(inner);\n+        EasyMock.reset(context);\n+        EasyMock.expect(context.timestamp()).andStubReturn(0L);\n+        context.logChange(store.name(), key1, value, 0L);\n+        context.logChange(store.name(), key2, value, 0L);", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk1OTgxMg==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425959812", "bodyText": "The expectLastCall is redundant if you're not chaining it with something else (like expectLastCall().times(2))\nI verified this just to be sure by removing the invocation of context.logChange in this class and it did indeed fail", "author": "ableegoldman", "createdAt": "2020-05-15T17:55:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwODk4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTk2NTM1OQ==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425965359", "bodyText": "Ok, thanks!", "author": "vvcephei", "createdAt": "2020-05-15T18:06:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwODk4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkwOTcwMw==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425909703", "bodyText": "Looks like this is unused.", "author": "vvcephei", "createdAt": "2020-05-15T16:20:23Z", "path": "streams/src/test/java/org/apache/kafka/test/MockInternalProcessorContext.java", "diffHunk": "@@ -116,4 +119,20 @@ public void register(final StateStore store, final StateRestoreCallback stateRes\n     public StateRestoreCallback stateRestoreCallback(final String storeName) {\n         return restoreCallbacks.get(storeName);\n     }\n+\n+    @Override\n+    public TaskType taskType() {\n+        return taskType;\n+    }\n+\n+    public void setTaskType(final TaskType newType) {\n+        taskType = newType;\n+    }", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDA0MA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r425910040", "bodyText": "Not sure about this change ;)", "author": "vvcephei", "createdAt": "2020-05-15T16:20:59Z", "path": "streams/test-utils/src/main/java/org/apache/kafka/streams/processor/MockProcessorContext.java", "diffHunk": "@@ -75,6 +75,7 @@\n     private final List<CapturedForward> capturedForwards = new LinkedList<>();\n     private boolean committed = false;\n \n+", "originalCommit": "632617b7bd1cdcadfa6cd45407f02912ccc00604", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "efc5306c20303572f8b10a6cbadefa668d4746f2", "url": "https://github.com/apache/kafka/commit/efc5306c20303572f8b10a6cbadefa668d4746f2", "message": "github feedback", "committedDate": "2020-05-15T17:56:00Z", "type": "commit"}, {"oid": "a1e08429bc21bedb01c4c4d6f96d4689f60b59ee", "url": "https://github.com/apache/kafka/commit/a1e08429bc21bedb01c4c4d6f96d4689f60b59ee", "message": "checkstyle", "committedDate": "2020-05-15T17:59:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjEwMTA2NQ==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426101065", "bodyText": "nit: we can add a validation that if streamTask != null then stateMgr.taskType() == ACTIVE.", "author": "guozhangwang", "createdAt": "2020-05-16T00:59:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextImpl.java", "diffHunk": "@@ -16,87 +16,125 @@\n  */\n package org.apache.kafka.streams.processor.internals;\n \n-import org.apache.kafka.streams.KeyValue;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.BytesSerializer;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.common.utils.LogContext;\n import org.apache.kafka.streams.StreamsConfig;\n import org.apache.kafka.streams.errors.StreamsException;\n import org.apache.kafka.streams.internals.ApiUtils;\n-import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.processor.Cancellable;\n-import org.apache.kafka.streams.processor.ProcessorContext;\n import org.apache.kafka.streams.processor.PunctuationType;\n import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n import org.apache.kafka.streams.processor.StateStore;\n import org.apache.kafka.streams.processor.TaskId;\n import org.apache.kafka.streams.processor.To;\n+import org.apache.kafka.streams.processor.internals.Task.TaskType;\n import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n-import org.apache.kafka.streams.state.KeyValueIterator;\n-import org.apache.kafka.streams.state.KeyValueStore;\n-import org.apache.kafka.streams.state.SessionStore;\n-import org.apache.kafka.streams.state.TimestampedKeyValueStore;\n-import org.apache.kafka.streams.state.TimestampedWindowStore;\n-import org.apache.kafka.streams.state.ValueAndTimestamp;\n-import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.streams.state.WindowStoreIterator;\n import org.apache.kafka.streams.state.internals.ThreadCache;\n-import org.apache.kafka.streams.state.internals.WrappedStateStore;\n \n import java.time.Duration;\n import java.util.List;\n \n import static org.apache.kafka.streams.internals.ApiUtils.prepareMillisCheckFailMsgPrefix;\n+import static org.apache.kafka.streams.processor.internals.AbstractReadOnlyDecorator.getReadOnlyStore;\n+import static org.apache.kafka.streams.processor.internals.AbstractReadWriteDecorator.getReadWriteStore;\n \n public class ProcessorContextImpl extends AbstractProcessorContext implements RecordCollector.Supplier {\n+    public static final BytesSerializer KEY_SERIALIZER = new BytesSerializer();\n+    public static final ByteArraySerializer VALUE_SERIALIZER = new ByteArraySerializer();\n \n-    private final StreamTask task;\n+    // The below are both null for standby tasks\n+    private final StreamTask streamTask;\n     private final RecordCollector collector;\n+\n     private final ToInternal toInternal = new ToInternal();\n     private final static To SEND_TO_ALL = To.all();\n \n+    final Map<String, String> storeToChangelogTopic = new HashMap<>();\n+\n     ProcessorContextImpl(final TaskId id,\n-                         final StreamTask task,\n+                         final StreamTask streamTask,\n                          final StreamsConfig config,\n                          final RecordCollector collector,\n                          final ProcessorStateManager stateMgr,\n                          final StreamsMetricsImpl metrics,\n                          final ThreadCache cache) {\n         super(id, config, metrics, stateMgr, cache);\n-        this.task = task;\n+        this.streamTask = streamTask;", "originalCommit": "a1e08429bc21bedb01c4c4d6f96d4689f60b59ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjEwMTQ1Nw==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426101457", "bodyText": "When we merge the InternalMock with MockInternal would this be okay? cc @cadonna", "author": "guozhangwang", "createdAt": "2020-05-16T01:02:43Z", "path": "streams/src/test/java/org/apache/kafka/test/InternalMockProcessorContext.java", "diffHunk": "@@ -349,6 +353,27 @@ public Headers headers() {\n         return recordContext.headers();\n     }\n \n+    @Override\n+    public TaskType taskType() {\n+        return TaskType.ACTIVE;\n+    }\n+\n+    @Override\n+    public void logChange(final String storeName,\n+                          final Bytes key,\n+                          final byte[] value,\n+                          final long timestamp) {\n+        recordCollector().send(", "originalCommit": "a1e08429bc21bedb01c4c4d6f96d4689f60b59ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjEwMjYwOA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426102608", "bodyText": "I assumed this would be fine since it's pretty much what happened before (ie users of the context would get the record collector and then call send) but I'd like to get this confirmed", "author": "ableegoldman", "createdAt": "2020-05-16T01:14:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjEwMTQ1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY0MTc2NQ==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426641765", "bodyText": "Both, MockInternalProcessorContext and InternalMockProcessorContext currently implement RecordCollector.Supplier (i.e., recordCollector()). Of course, once rebased the consolidated mock needs to implement taskType() and logChange().\nSee also my comment above regarding KEY_SERIALIZER and VALUE_SERIALIZER.\n@guozhangwang did you have anything specific in mind that I did not cover here?", "author": "cadonna", "createdAt": "2020-05-18T13:52:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjEwMTQ1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjc1NDg5Mg==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426754892", "bodyText": "No I do not, just wanting to make sure we do not have any major conflicts when rebasing the other.", "author": "guozhangwang", "createdAt": "2020-05-18T16:34:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjEwMTQ1Nw=="}], "type": "inlineReview"}, {"oid": "94bc716ea7cd64434d6b2108b50f39891469ce93", "url": "https://github.com/apache/kafka/commit/94bc716ea7cd64434d6b2108b50f39891469ce93", "message": "github change", "committedDate": "2020-05-16T01:14:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjU5MjM2Mw==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426592363", "bodyText": "req: Please unit test a processor context for a standby with the unsupported methods. That is, all code paths that involve a call to throwUnsupportedOperationExceptionIfStandby().", "author": "cadonna", "createdAt": "2020-05-18T12:35:41Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextImpl.java", "diffHunk": "@@ -16,87 +16,129 @@\n  */\n package org.apache.kafka.streams.processor.internals;\n \n-import org.apache.kafka.streams.KeyValue;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.BytesSerializer;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.common.utils.LogContext;\n import org.apache.kafka.streams.StreamsConfig;\n import org.apache.kafka.streams.errors.StreamsException;\n import org.apache.kafka.streams.internals.ApiUtils;\n-import org.apache.kafka.streams.kstream.Windowed;\n import org.apache.kafka.streams.processor.Cancellable;\n-import org.apache.kafka.streams.processor.ProcessorContext;\n import org.apache.kafka.streams.processor.PunctuationType;\n import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n import org.apache.kafka.streams.processor.StateStore;\n import org.apache.kafka.streams.processor.TaskId;\n import org.apache.kafka.streams.processor.To;\n+import org.apache.kafka.streams.processor.internals.Task.TaskType;\n import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n-import org.apache.kafka.streams.state.KeyValueIterator;\n-import org.apache.kafka.streams.state.KeyValueStore;\n-import org.apache.kafka.streams.state.SessionStore;\n-import org.apache.kafka.streams.state.TimestampedKeyValueStore;\n-import org.apache.kafka.streams.state.TimestampedWindowStore;\n-import org.apache.kafka.streams.state.ValueAndTimestamp;\n-import org.apache.kafka.streams.state.WindowStore;\n-import org.apache.kafka.streams.state.WindowStoreIterator;\n import org.apache.kafka.streams.state.internals.ThreadCache;\n-import org.apache.kafka.streams.state.internals.WrappedStateStore;\n \n import java.time.Duration;\n import java.util.List;\n \n import static org.apache.kafka.streams.internals.ApiUtils.prepareMillisCheckFailMsgPrefix;\n+import static org.apache.kafka.streams.processor.internals.AbstractReadOnlyDecorator.getReadOnlyStore;\n+import static org.apache.kafka.streams.processor.internals.AbstractReadWriteDecorator.getReadWriteStore;\n \n public class ProcessorContextImpl extends AbstractProcessorContext implements RecordCollector.Supplier {\n+    public static final BytesSerializer KEY_SERIALIZER = new BytesSerializer();\n+    public static final ByteArraySerializer VALUE_SERIALIZER = new ByteArraySerializer();\n \n-    private final StreamTask task;\n+    // The below are both null for standby tasks\n+    private final StreamTask streamTask;\n     private final RecordCollector collector;\n+\n     private final ToInternal toInternal = new ToInternal();\n     private final static To SEND_TO_ALL = To.all();\n \n+    final Map<String, String> storeToChangelogTopic = new HashMap<>();\n+\n     ProcessorContextImpl(final TaskId id,\n-                         final StreamTask task,\n+                         final StreamTask streamTask,\n                          final StreamsConfig config,\n                          final RecordCollector collector,\n                          final ProcessorStateManager stateMgr,\n                          final StreamsMetricsImpl metrics,\n                          final ThreadCache cache) {\n         super(id, config, metrics, stateMgr, cache);\n-        this.task = task;\n+        this.streamTask = streamTask;\n         this.collector = collector;\n+\n+        if (streamTask == null && taskType() == TaskType.ACTIVE) {\n+            throw new IllegalStateException(\"Tried to create context for active task but the streamtask was null\");\n+        }\n+    }\n+\n+    ProcessorContextImpl(final TaskId id,\n+                         final StreamsConfig config,\n+                         final ProcessorStateManager stateMgr,\n+                         final StreamsMetricsImpl metrics) {\n+        this(\n+            id,\n+            null,\n+            config,\n+            null,\n+            stateMgr,\n+            metrics,\n+            new ThreadCache(\n+                new LogContext(String.format(\"stream-thread [%s] \", Thread.currentThread().getName())),\n+                0,\n+                metrics\n+            )\n+        );\n     }\n \n-    public ProcessorStateManager getStateMgr() {\n+    public ProcessorStateManager stateManager() {\n         return (ProcessorStateManager) stateManager;\n     }\n \n+    @Override\n+    public void register(final StateStore store,\n+                         final StateRestoreCallback stateRestoreCallback) {\n+        storeToChangelogTopic.put(store.name(), ProcessorStateManager.storeChangelogTopic(applicationId(), store.name()));\n+        super.register(store, stateRestoreCallback);\n+    }\n+\n     @Override\n     public RecordCollector recordCollector() {\n         return collector;\n     }\n \n+    @Override\n+    public void logChange(final String storeName,\n+                          final Bytes key,\n+                          final byte[] value,\n+                          final long timestamp) {\n+        throwUnsupportedOperationExceptionIfStandby(\"logChange\");", "originalCommit": "94bc716ea7cd64434d6b2108b50f39891469ce93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY0MDA5NA==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426640094", "bodyText": "prop: I think we should move those to InternalProcessorContext. IMO, it would be cleaner for a mock not to have a direct dependency to the class it mocks. The new consolidated mock for the internal processor context will not extend AbstractProcessorContext but only MockProcessorContext. Thus, the common ancestor will be InternalProcessorContext.\nSorry for bothering you because of those constants after that @vvcephei has already bothered you. :-)", "author": "cadonna", "createdAt": "2020-05-18T13:49:48Z", "path": "streams/src/test/java/org/apache/kafka/test/InternalMockProcessorContext.java", "diffHunk": "@@ -52,6 +54,8 @@\n import java.util.List;\n import java.util.Map;\n \n+import static org.apache.kafka.streams.processor.internals.ProcessorContextImpl.KEY_SERIALIZER;\n+import static org.apache.kafka.streams.processor.internals.ProcessorContextImpl.VALUE_SERIALIZER;", "originalCommit": "94bc716ea7cd64434d6b2108b50f39891469ce93", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjcwMDczNw==", "url": "https://github.com/apache/kafka/pull/8669#discussion_r426700737", "bodyText": "Ack", "author": "ableegoldman", "createdAt": "2020-05-18T15:14:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjY0MDA5NA=="}], "type": "inlineReview"}, {"oid": "ea029f2b2da721e76feb6df9e8083380df475be6", "url": "https://github.com/apache/kafka/commit/ea029f2b2da721e76feb6df9e8083380df475be6", "message": "add tests and move constants", "committedDate": "2020-05-18T16:00:45Z", "type": "commit"}, {"oid": "67c3e05174c172d6509098f4d0b17d2024bce73f", "url": "https://github.com/apache/kafka/commit/67c3e05174c172d6509098f4d0b17d2024bce73f", "message": "checkstyle", "committedDate": "2020-05-18T16:07:57Z", "type": "commit"}, {"oid": "f807b4f8da716905265a37eb0a2966496781cae4", "url": "https://github.com/apache/kafka/commit/f807b4f8da716905265a37eb0a2966496781cae4", "message": "fix standby test", "committedDate": "2020-05-18T16:57:40Z", "type": "commit"}]}