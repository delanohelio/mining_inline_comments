{"pr_number": 8508, "pr_title": "MINOR: Improve usage of LogCaptureAppender", "pr_createdAt": "2020-04-18T00:29:02Z", "pr_url": "https://github.com/apache/kafka/pull/8508", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUyNDc0Mg==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410524742", "bodyText": "This is an actual change -- in all other processor, we use the \"top level class\" for the logger and not the Processor class -- changing this for alignment.", "author": "mjsax", "createdAt": "2020-04-18T00:31:40Z", "path": "streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamKTableJoinProcessor.java", "diffHunk": "@@ -30,7 +30,7 @@\n import static org.apache.kafka.streams.state.ValueAndTimestamp.getValueOrNull;\n \n class KStreamKTableJoinProcessor<K1, K2, V1, V2, R> extends AbstractProcessor<K1, V1> {\n-    private static final Logger LOG = LoggerFactory.getLogger(KStreamKTableJoinProcessor.class);\n+    private static final Logger LOG = LoggerFactory.getLogger(KStreamKTableJoin.class);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUyNDgzMg==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410524832", "bodyText": "Removed because unused.", "author": "mjsax", "createdAt": "2020-04-18T00:32:13Z", "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KGroupedStreamImplTest.java", "diffHunk": "@@ -659,7 +657,6 @@ public void shouldCountWindowed() {\n     @Test\n     public void shouldCountWindowedWithInternalStoreName() {\n         final MockProcessorSupplier<Windowed<String>, Long> supplier = new MockProcessorSupplier<>();\n-        final List<KeyValue<Windowed<String>, KeyValue<Long, Long>>> results = new ArrayList<>();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUyNDg2Ng==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410524866", "bodyText": "Removed because unused.", "author": "mjsax", "createdAt": "2020-04-18T00:32:29Z", "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamKStreamJoinTest.java", "diffHunk": "@@ -186,15 +189,12 @@ public void shouldThrowExceptionWhenOtherJoinStoreSetsRetainDuplicatesFalse() {\n     @Test\n     public void shouldBuildJoinWithCustomStoresAndCorrectWindowSettings() {\n         //Case where everything matches up\n-        final WindowBytesStoreSupplier thisStoreSupplier = buildWindowBytesStoreSupplier(\"in-memory-join-store\", 150, 100, true);\n-        final WindowBytesStoreSupplier otherStoreSupplier = buildWindowBytesStoreSupplier(\"in-memory-join-store-other\", 150, 100, true);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUyNTI0MA==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410525240", "bodyText": "Removed because the parameter is variadic", "author": "mjsax", "createdAt": "2020-04-18T00:34:46Z", "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamWindowAggregateTest.java", "diffHunk": "@@ -189,8 +189,8 @@ public void testJoin() {\n                 new KeyValueTimestamp<>(new Windowed<>(\"A\", new TimeWindow(0, 10)),  \"0+1+1\",  9),\n                 new KeyValueTimestamp<>(new Windowed<>(\"A\", new TimeWindow(5, 15)),  \"0+1\",  9)\n             );\n-            processors.get(1).checkAndClearProcessResult(new KeyValueTimestamp[0]);\n-            processors.get(2).checkAndClearProcessResult(new KeyValueTimestamp[0]);\n+            processors.get(1).checkAndClearProcessResult();\n+            processors.get(2).checkAndClearProcessResult();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUyNTQ4Mg==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410525482", "bodyText": "This method is only called once and thus its merged into the main test method", "author": "mjsax", "createdAt": "2020-04-18T00:36:40Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -1812,13 +1809,14 @@ private void shouldLogAndRecordSkippedMetricForDeserializationException(final St\n             -1,\n             new byte[0],\n             \"I am not an integer.\".getBytes()));\n-        thread.runOnce();\n \n-        verifyLogMessagesSkippedRecordsForDeserializationException(appender);\n-    }\n+        final LogCaptureAppender appender = LogCaptureAppender.createAndRegister(RecordDeserializer.class);\n+        try {\n+            thread.runOnce();\n+        } finally {\n+            LogCaptureAppender.unregister(appender);\n+        }\n \n-    private void verifyLogMessagesSkippedRecordsForDeserializationException(final LogCaptureAppender appender) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUyNTY2NA==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410525664", "bodyText": "We don't capture any debug logs and thus it's getting removed", "author": "mjsax", "createdAt": "2020-04-18T00:38:07Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/AbstractSessionBytesStoreTest.java", "diffHunk": "@@ -80,8 +81,6 @@\n \n     abstract String getMetricsScope();\n \n-    abstract void setClassLoggerToDebug();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUyNjE3Mg==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410526172", "bodyText": "This method is only called once and thus its merged into the main test method", "author": "mjsax", "createdAt": "2020-04-18T00:41:38Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2020,40 +2016,41 @@ private void shouldLogAndRecordSkippedRecordsForInvalidTimestamps(final String b\n             assertEquals(0.0, metrics.metric(skippedRateMetric).metricValue());\n         }\n \n-        long offset = -1;\n-        addRecord(mockConsumer, ++offset);\n-        addRecord(mockConsumer, ++offset);\n-        thread.runOnce();\n+        final LogCaptureAppender appender = LogCaptureAppender.createAndRegister(RecordQueue.class);\n+        try {\n+            long offset = -1;\n+            addRecord(mockConsumer, ++offset);\n+            addRecord(mockConsumer, ++offset);\n+            thread.runOnce();\n \n-        if (StreamsConfig.METRICS_0100_TO_24.equals(builtInMetricsVersion)) {\n-            assertEquals(2.0, metrics.metric(skippedTotalMetric).metricValue());\n-            assertNotEquals(0.0, metrics.metric(skippedRateMetric).metricValue());\n-        }\n+            if (StreamsConfig.METRICS_0100_TO_24.equals(builtInMetricsVersion)) {\n+                assertEquals(2.0, metrics.metric(skippedTotalMetric).metricValue());\n+                assertNotEquals(0.0, metrics.metric(skippedRateMetric).metricValue());\n+            }\n \n-        addRecord(mockConsumer, ++offset);\n-        addRecord(mockConsumer, ++offset);\n-        addRecord(mockConsumer, ++offset);\n-        addRecord(mockConsumer, ++offset);\n-        thread.runOnce();\n+            addRecord(mockConsumer, ++offset);\n+            addRecord(mockConsumer, ++offset);\n+            addRecord(mockConsumer, ++offset);\n+            addRecord(mockConsumer, ++offset);\n+            thread.runOnce();\n \n-        if (StreamsConfig.METRICS_0100_TO_24.equals(builtInMetricsVersion)) {\n-            assertEquals(6.0, metrics.metric(skippedTotalMetric).metricValue());\n-            assertNotEquals(0.0, metrics.metric(skippedRateMetric).metricValue());\n-        }\n+            if (StreamsConfig.METRICS_0100_TO_24.equals(builtInMetricsVersion)) {\n+                assertEquals(6.0, metrics.metric(skippedTotalMetric).metricValue());\n+                assertNotEquals(0.0, metrics.metric(skippedRateMetric).metricValue());\n+            }\n \n-        addRecord(mockConsumer, ++offset, 1L);\n-        addRecord(mockConsumer, ++offset, 1L);\n-        thread.runOnce();\n+            addRecord(mockConsumer, ++offset, 1L);\n+            addRecord(mockConsumer, ++offset, 1L);\n+            thread.runOnce();\n+        } finally {\n+            LogCaptureAppender.unregister(appender);\n+        }\n \n         if (StreamsConfig.METRICS_0100_TO_24.equals(builtInMetricsVersion)) {\n             assertEquals(6.0, metrics.metric(skippedTotalMetric).metricValue());\n             assertNotEquals(0.0, metrics.metric(skippedRateMetric).metricValue());\n         }\n-        verifyLogMessagesForSkippedRecordsForInvalidTimestamps(appender);\n-    }\n \n-    private void verifyLogMessagesForSkippedRecordsForInvalidTimestamps(final LogCaptureAppender appender) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDc0MTA4Ng==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410741086", "bodyText": "Seems like this appender could also be scoped to the class that logs the message we want to capture, right?", "author": "vvcephei", "createdAt": "2020-04-18T19:33:50Z", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -801,8 +801,11 @@ public void shouldWarnAboutRocksDBConfigSetterIsNotGuaranteedToBeBackwardsCompat\n         props.setProperty(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG, TestRocksDbConfigSetter.class.getName());\n \n         final LogCaptureAppender appender = LogCaptureAppender.createAndRegister();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDgzNjMxMQ==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410836311", "bodyText": "Unfortunately not; I tied it and it fails. The issue is, we would want to register the LogCaptureAppender only for KafkaStreams.class but at this point in the test, the corresponding logger does not exist yet: it's only created in the constructor call, that we actually test. Does this make sense?", "author": "mjsax", "createdAt": "2020-04-19T07:07:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDc0MTA4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDc0MjY5NQ==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410742695", "bodyText": "Not a huge fan of this particular \"clean up\". We're trading a tightly defined scope for de-duplicating the trivial line results.add(deserialization). It doesn't seem like a good trade to me.", "author": "vvcephei", "createdAt": "2020-04-18T19:49:50Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/AbstractRocksDBSegmentedBytesStoreTest.java", "diffHunk": "@@ -512,19 +512,24 @@ private Bytes serializeKey(final Windowed<String> key) {\n         final StateSerdes<String, Long> stateSerdes = StateSerdes.withBuiltinTypes(\"dummy\", String.class, Long.class);\n         while (iterator.hasNext()) {\n             final KeyValue<Bytes, byte[]> next = iterator.next();\n+            final KeyValue<Windowed<String>, Long> deserialized;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDgzNTc0MQ==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r410835741", "bodyText": "I don't feel \"strong\" about it -- it was an IntelliJ warning/suggestion to \"share common code\".", "author": "mjsax", "createdAt": "2020-04-19T07:03:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDc0MjY5NQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "4b653333836d86b105961c0d611e849bbb4d4d8c", "url": "https://github.com/apache/kafka/commit/4b653333836d86b105961c0d611e849bbb4d4d8c", "message": "MINOR: Improve usage of LogCaptureAppender", "committedDate": "2020-04-20T05:50:46Z", "type": "commit"}, {"oid": "4b653333836d86b105961c0d611e849bbb4d4d8c", "url": "https://github.com/apache/kafka/commit/4b653333836d86b105961c0d611e849bbb4d4d8c", "message": "MINOR: Improve usage of LogCaptureAppender", "committedDate": "2020-04-20T05:50:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTY2NzMxMQ==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r411667311", "bodyText": "Hmm, this might be surprising. Won't this cause the test executor thread to be called \"threadName\" from now until the end of the build?\nDo you think we could instead get the currentThread's name and use that in the assertions? Or otherwise make the assertions agnostic to the name of the thread?", "author": "vvcephei", "createdAt": "2020-04-20T20:24:26Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/InternalTopicManagerTest.java", "diffHunk": "@@ -84,6 +87,10 @@\n \n     @Before\n     public void init() {\n+        // When executing on Jenkins, the thread name is set to an unknown value,\n+        // hence, we need to set it explicitly to make our log-assertions pass\n+        Thread.currentThread().setName(threadName);", "originalCommit": "4b653333836d86b105961c0d611e849bbb4d4d8c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTcxMjMxNA==", "url": "https://github.com/apache/kafka/pull/8508#discussion_r411712314", "bodyText": "Getting the name is much better! Should have done this for the beginning on...", "author": "mjsax", "createdAt": "2020-04-20T21:42:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTY2NzMxMQ=="}], "type": "inlineReview"}, {"oid": "8e72cdd476c8f733788238ed303056c7369f3441", "url": "https://github.com/apache/kafka/commit/8e72cdd476c8f733788238ed303056c7369f3441", "message": "Github comments", "committedDate": "2020-04-20T21:47:19Z", "type": "commit"}]}