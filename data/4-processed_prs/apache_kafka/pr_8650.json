{"pr_number": 8650, "pr_title": "MINOR: Added unit tests for ConnectionQuotas", "pr_createdAt": "2020-05-12T04:29:37Z", "pr_url": "https://github.com/apache/kafka/pull/8650", "timeline": [{"oid": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "url": "https://github.com/apache/kafka/commit/9252ff943909e07eb0c24bdd4ea8934636c212f3", "message": "MINOR: Added unit test for ConnectionQuotas", "committedDate": "2020-05-12T04:18:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0NjA3MQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423546071", "bodyText": "I think that intercept does not assert that the exception is thrown but return the intercepted exception. It would be better to use assertThrown here.\nDo we really need to use an executor here? It seems that inc should throw immediately if the listener does not exist.", "author": "dajac", "createdAt": "2020-05-12T08:14:39Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5Mzg5MA==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r424693890", "bodyText": "intercept also verifies the exception. For example, if the exception thrown is different, the test will fail with an error like this: Expected exception java.lang.IllegalArgumentException to be thrown, but kafka.network.TooManyConnectionsException was thrown. If if no exception is thrown, it will fail like this: Expected exception java.lang.IllegalArgumentException to be thrown, but no exception was thrown. From what I see, assertThrown achieves the same behavior as intercept.", "author": "apovzner", "createdAt": "2020-05-13T19:54:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0NjA3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDQ3Mg==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r424694472", "bodyText": "About using the executor -- you are right that inc should return immediately in this case. I still used the executor in case the behavior changes and inc blocks. I think it's better to protect the test from this scenario", "author": "apovzner", "createdAt": "2020-05-13T19:56:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0NjA3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0OTIzMw==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423549233", "bodyText": "nit: the space before listener is not needed. i would use curly braces here to stay consistent with the foreach below.", "author": "dajac", "createdAt": "2020-05-12T08:19:40Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0OTcxMA==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423549710", "bodyText": "nit: the space before the last closing parenthesis is not needed.", "author": "dajac", "createdAt": "2020-05-12T08:20:23Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1MjcyOQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423552729", "bodyText": "Number of connections on $listener: to stay consistent with the other tests?\nnit: a space is missing after the first coma.", "author": "dajac", "createdAt": "2020-05-12T08:25:02Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1MzQzMA==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423553430", "bodyText": "I think that this does not assert as mentioned earlier. Moreover, I think that this deserves its own unit test as it is not really related to the current one.", "author": "dajac", "createdAt": "2020-05-12T08:26:06Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcwMDA5MQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r424700091", "bodyText": "agreed, moved to a separate test", "author": "apovzner", "createdAt": "2020-05-13T20:06:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1MzQzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1ODkyOQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423558929", "bodyText": "What's the reason behind using an executor here? It seems that you always wait immediately get on the future thus we could directly do it in the main thread, isn't it? I would personally avoid them if not really necessary.", "author": "dajac", "createdAt": "2020-05-12T08:34:30Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcwNDQzNA==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r424704434", "bodyText": "the reason is to make sure that when inc blocks, it does not block the main thread where we cannot use a timeout. If it blocks on a separate thread, we make sure the test proceeds and fails (when it is not expected). Most of those are not supposed to block if the code works as we expect. I use the executor anyway, in case there is a bug or behavior changes and it unexpectedly blocks. In which case the whole test will hang for a long time (I guess till the build times out)", "author": "apovzner", "createdAt": "2020-05-13T20:14:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1ODkyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcwNjEzOA==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r424706138", "bodyText": "Basically, the test does not assume that the code behaves correctly.", "author": "apovzner", "createdAt": "2020-05-13T20:17:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1ODkyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2MzY4MQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423563681", "bodyText": "You may want to assert here.\nI would reduce the waiting time to 10ms (or 100ms) to avoid always waiting 1s.", "author": "dajac", "createdAt": "2020-05-12T08:41:46Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2NTUwMQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423565501", "bodyText": "nit: extra space after the last dot.", "author": "dajac", "createdAt": "2020-05-12T08:44:36Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2NTkwOQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423565909", "bodyText": "Same comment as before.", "author": "dajac", "createdAt": "2020-05-12T08:45:13Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2OTE3NA==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423569174", "bodyText": "nit: I would use curly braces here to stay consistent with the foreach below.", "author": "dajac", "createdAt": "2020-05-12T08:49:48Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2OTgwMQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423569801", "bodyText": "Number of connections on $listener: to stay consistent with other tests?", "author": "dajac", "createdAt": "2020-05-12T08:50:35Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\", listenerMaxConnections, connectionQuotas.get(listener.defaultClientIp))", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MDAxNQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423570015", "bodyText": "nit: curly braces.", "author": "dajac", "createdAt": "2020-05-12T08:50:59Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\", listenerMaxConnections, connectionQuotas.get(listener.defaultClientIp))\n+        assertFalse(s\"Total number of connections on $listener should be exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listener.listenerName))\n+      }\n+\n+      // since every listener has exactly the max number of listener connections,\n+      // every listener should block on the next connection creation, even the inter-broker listener\n+      val futures2 = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, 1)): Runnable) )", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MDQxMw==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423570413", "bodyText": "you may want to assert here.", "author": "dajac", "createdAt": "2020-05-12T08:51:34Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\", listenerMaxConnections, connectionQuotas.get(listener.defaultClientIp))\n+        assertFalse(s\"Total number of connections on $listener should be exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listener.listenerName))\n+      }\n+\n+      // since every listener has exactly the max number of listener connections,\n+      // every listener should block on the next connection creation, even the inter-broker listener\n+      val futures2 = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, 1)): Runnable) )\n+      futures2.foreach { future =>\n+        intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDcwNzQ5NQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r424707495", "bodyText": "see my comment that intercept does assert on both wrong exception or no exception, similar to assertThrown", "author": "apovzner", "createdAt": "2020-05-13T20:20:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MDQxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MTQyNA==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423571424", "bodyText": "Could we assert the number of connections after this line?", "author": "dajac", "createdAt": "2020-05-12T08:53:02Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // remove two \"rejected\" connections and remove 2 more connections to free up the space for another 2 connections\n+      for (_ <- 0 until 4) connectionQuotas.dec(externalListener.listenerName, externalListener.defaultClientIp)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp - 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxBrokerWideConnectionLimit(): Unit = {\n+    val maxConnections = 800\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // the metric should be 0, because we did not advance the time yet\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // verify that ConnectionQuota can give all connections to one listener\n+      // also add connections with a time interval between connections to make sure that time gets advanced\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), maxConnections, 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // the blocked percent should still be 0, because there should be no wait for a connection slot\n+      assertEquals(0, blockedPercentMeters(\"EXTERNAL\").count())\n+\n+      // the number of connections should be above max for maxConnectionsExceeded to return true\n+      assertFalse(\"Total number of connections is exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection will block ConnectionQuota.inc()\n+      val future = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"EXTERNAL\"), 1)): Runnable)\n+      intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      // advance time by 3ms so that when the waiting connection gets accepted, the blocked percent is non-zero\n+      time.sleep(3)\n+\n+      // removing one connection should make the waiting connection to succeed\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future.get(1, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on ${listeners(\"EXTERNAL\")}:\", maxConnections, connectionQuotas.get(listeners(\"EXTERNAL\").defaultClientIp))\n+      // metric is recorded in nanoseconds\n+      assertTrue(\"Expected BlockedPercentMeter metric to be recorded\", blockedPercentMeters(\"EXTERNAL\").count() > 0)\n+\n+      // adding inter-broker connections should succeed even when the total number of connections reached the max\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertTrue(\"Expected the number of connections to exceed the maximum.\", connectionQuotas.maxConnectionsExceeded(listeners(\"EXTERNAL\").listenerName))\n+\n+      // adding one more connection on another non-inter-broker will block ConnectionQuota.inc()\n+      val future1 = executor.submit((() => acceptConnections(connectionQuotas, listeners(\"ADMIN\"), 1)): Runnable)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+\n+      // adding inter-broker connection should still succeed, even though a connection from another listener is waiting\n+      executor.submit((() => acceptConnections(connectionQuotas, listeners(\"REPLICATION\"), 1)): Runnable).get(5, TimeUnit.SECONDS)\n+\n+      // at this point, we need to remove 3 connections for the waiting connection to succeed\n+      // remove 2 first -- should not be enough to accept the waiting connection\n+      for (_ <- 0 until 2) connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\"). defaultClientIp)\n+      intercept[TimeoutException](future1.get(1, TimeUnit.SECONDS))\n+      connectionQuotas.dec(listeners(\"EXTERNAL\").listenerName, listeners(\"EXTERNAL\").defaultClientIp)\n+      future1.get(1, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxListenerConnectionLimits(): Unit = {\n+    val maxConnections = 800\n+    // sum of per-listener connection limits is below total connection limit\n+    val listenerMaxConnections = 200\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsProp, maxConnections.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val listenerConfig = Map(KafkaConfig.MaxConnectionsProp -> listenerMaxConnections.toString).asJava\n+    listeners.values.foreach { listener =>\n+      connectionQuotas.maxConnectionsPerListener(listener.listenerName).configure(listenerConfig)\n+    }\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify each listener can create up to max connections configured for that listener\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, listenerMaxConnections)): Runnable) )\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\", listenerMaxConnections, connectionQuotas.get(listener.defaultClientIp))\n+        assertFalse(s\"Total number of connections on $listener should be exactly the maximum.\", connectionQuotas.maxConnectionsExceeded(listener.listenerName))\n+      }\n+\n+      // since every listener has exactly the max number of listener connections,\n+      // every listener should block on the next connection creation, even the inter-broker listener\n+      val futures2 = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, 1)): Runnable) )\n+      futures2.foreach { future =>\n+        intercept[TimeoutException](future.get(1, TimeUnit.SECONDS))\n+      }\n+      listeners.values.foreach { listener =>\n+        // free up one connection slot\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+      }\n+      // all connections should get added\n+      futures.foreach(_.get(5, TimeUnit.SECONDS))", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3Mjc5MQ==", "url": "https://github.com/apache/kafka/pull/8650#discussion_r423572791", "bodyText": "A general comment. It would be great if we could break long lines in order to keep them under a reasonable size. I don't know if we have a strict guideline on this but we tend to do it.", "author": "dajac", "createdAt": "2020-05-12T08:55:06Z", "path": "core/src/test/scala/unit/kafka/network/ConnectionQuotasTest.scala", "diffHunk": "@@ -0,0 +1,307 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package kafka.network\n+\n+import java.net.InetAddress\n+import java.util.concurrent.{Executors, TimeUnit}\n+import java.util.Properties\n+\n+import com.yammer.metrics.core.Meter\n+import kafka.metrics.KafkaMetricsGroup\n+import kafka.network.Processor.ListenerMetricTag\n+import kafka.server.KafkaConfig\n+import kafka.utils.TestUtils\n+import org.apache.kafka.common.network._\n+import org.apache.kafka.common.utils.MockTime\n+import org.junit.Assert._\n+import org.junit._\n+import org.scalatest.Assertions.intercept\n+\n+import scala.jdk.CollectionConverters._\n+import scala.collection.{Map, mutable}\n+import scala.concurrent.TimeoutException\n+\n+class ConnectionQuotasTest {\n+  private val time = new MockTime\n+  private val listeners = Map(\n+    \"EXTERNAL\" -> ListenerDesc(new ListenerName(\"EXTERNAL\"), InetAddress.getByName(\"192.168.1.1\")),\n+    \"ADMIN\" -> ListenerDesc(new ListenerName(\"ADMIN\"), InetAddress.getByName(\"192.168.1.2\")),\n+    \"REPLICATION\" -> ListenerDesc(new ListenerName(\"REPLICATION\"), InetAddress.getByName(\"192.168.1.3\")))\n+  private val blockedPercentMeters = mutable.Map[String, Meter]()\n+  private val knownHost = InetAddress.getByName(\"192.168.10.0\")\n+  private val unknownHost = InetAddress.getByName(\"192.168.2.0\")\n+\n+  case class ListenerDesc(listenerName: ListenerName, defaultClientIp: InetAddress) {\n+    override def toString: String = {\n+      s\"(listener=${listenerName.value}, client=${defaultClientIp.getHostAddress})\"\n+    }\n+  }\n+\n+  def brokerPropsWithDefaultConnectionLimits: Properties = {\n+    val props = TestUtils.createBrokerConfig(0, TestUtils.MockZkConnect, port = 0)\n+    props.put(KafkaConfig.ListenersProp, \"EXTERNAL://localhost:0,REPLICATION://localhost:1,ADMIN://localhost:2\")\n+    // ConnectionQuotas does not limit inter-broker listener even when broker-wide connection limit is reached\n+    props.put(KafkaConfig.InterBrokerListenerNameProp, \"REPLICATION\")\n+    props.put(KafkaConfig.ListenerSecurityProtocolMapProp, \"EXTERNAL:PLAINTEXT,REPLICATION:PLAINTEXT,ADMIN:PLAINTEXT\")\n+    props\n+  }\n+\n+  @Before\n+  def setUp(): Unit = {\n+    // Clean-up any metrics left around by previous tests\n+    TestUtils.clearYammerMetrics()\n+\n+    listeners.keys.foreach { name =>\n+        blockedPercentMeters.put(name, KafkaMetricsGroup.newMeter(\n+          s\"${name}BlockedPercent\", \"blocked time\", TimeUnit.NANOSECONDS, Map(ListenerMetricTag -> name)))\n+    }\n+  }\n+\n+  @After\n+  def tearDown(): Unit = {\n+    TestUtils.clearYammerMetrics()\n+    blockedPercentMeters.clear()\n+  }\n+\n+  @Test\n+  def testFailWhenNoListeners(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    val executor = Executors.newSingleThreadExecutor\n+    try {\n+      // inc() on a separate thread in case it blocks\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() =>\n+        intercept[RuntimeException](connectionQuotas.inc(externalListener.listenerName, externalListener.defaultClientIp, blockedPercentMeters(\"EXTERNAL\")))): Runnable\n+      ).get(5, TimeUnit.SECONDS)\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testNoConnectionLimitsByDefault(): Unit = {\n+    val config = KafkaConfig.fromProps(brokerPropsWithDefaultConnectionLimits)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      // verify there is no limit by accepting 10000 connections as fast as possible\n+      val numConnections = 10000\n+      val futures = listeners.values.map( listener =>\n+        executor.submit((() => acceptConnections(connectionQuotas, listener, numConnections)): Runnable) )\n+      futures.foreach(_.get(10, TimeUnit.SECONDS))\n+      listeners.values.foreach { listener =>\n+        assertEquals(s\"${listener.listenerName.value()}\",numConnections, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // verify removing one connection\n+        connectionQuotas.dec(listener.listenerName, listener.defaultClientIp)\n+        assertEquals(s\"Number of connections on $listener:\", numConnections - 1, connectionQuotas.get(listener.defaultClientIp))\n+\n+        // calling dec() for an IP for which we didn't call inc() should throw an exception\n+        intercept[IllegalArgumentException](connectionQuotas.dec(listener.listenerName, unknownHost))\n+      }\n+    } finally {\n+      executor.shutdownNow()\n+    }\n+  }\n+\n+  @Test\n+  def testMaxConnectionsPerIp(): Unit = {\n+    val maxConnectionsPerIp = 17\n+    val props = brokerPropsWithDefaultConnectionLimits\n+    props.put(KafkaConfig.MaxConnectionsPerIpProp, maxConnectionsPerIp.toString)\n+    val config = KafkaConfig.fromProps(props)\n+    val connectionQuotas = new ConnectionQuotas(config, time)\n+\n+    addListenersAndVerify(config, connectionQuotas)\n+\n+    val executor = Executors.newFixedThreadPool(listeners.size)\n+    try {\n+      val externalListener = listeners(\"EXTERNAL\")\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener, maxConnectionsPerIp)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // all subsequent connections will be added to the counters, but inc() will throw TooManyConnectionsException for each of them\n+      executor.submit((() => acceptConnectionsAboveIpLimit(connectionQuotas, externalListener, 2)): Runnable).get(5, TimeUnit.SECONDS)\n+      assertEquals(s\"Number of connections on $externalListener:\", maxConnectionsPerIp + 2, connectionQuotas.get(externalListener.defaultClientIp))\n+\n+      // connections on the same listener but from a different IP should be accepted\n+      executor.submit((() => acceptConnections(connectionQuotas, externalListener.listenerName, knownHost, maxConnectionsPerIp, 0)): Runnable).get(5, TimeUnit.SECONDS)", "originalCommit": "9252ff943909e07eb0c24bdd4ea8934636c212f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "117200f87ab443c88dd9e1a6f52ac7ffe357b196", "url": "https://github.com/apache/kafka/commit/117200f87ab443c88dd9e1a6f52ac7ffe357b196", "message": "addressed review comments", "committedDate": "2020-05-13T20:39:49Z", "type": "commit"}, {"oid": "df9fd8b79c22337a6b14c6c1c092a03008eddc99", "url": "https://github.com/apache/kafka/commit/df9fd8b79c22337a6b14c6c1c092a03008eddc99", "message": "fixed test that was waiting on wrong future", "committedDate": "2020-05-20T20:07:59Z", "type": "commit"}, {"oid": "ff2e473fa7eb203c04b56a0d9dc549cf78ed3cdc", "url": "https://github.com/apache/kafka/commit/ff2e473fa7eb203c04b56a0d9dc549cf78ed3cdc", "message": "changed variable name in test so it is easier to differentiate", "committedDate": "2020-05-20T20:13:58Z", "type": "commit"}]}