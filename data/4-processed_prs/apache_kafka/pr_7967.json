{"pr_number": 7967, "pr_title": "KAFKA-9449: Adds support for closing the producer's BufferPool.", "pr_createdAt": "2020-01-15T18:59:26Z", "pr_url": "https://github.com/apache/kafka/pull/7967", "timeline": [{"oid": "3c92c5786a0a1548607579a85b892412aeb90734", "url": "https://github.com/apache/kafka/commit/3c92c5786a0a1548607579a85b892412aeb90734", "message": "MINOR: Adds support for closing the producer's BufferPool.", "committedDate": "2020-01-15T18:57:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODAyNTIxMA==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368025210", "bodyText": "nit: use assertThrows?", "author": "hachikuji", "createdAt": "2020-01-17T16:30:52Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/BufferPoolTest.java", "diffHunk": "@@ -377,4 +378,58 @@ public void run() {\n         }\n     }\n \n+    @Test\n+    public void testCloseAllocations() throws Exception {\n+        BufferPool pool = new BufferPool(10, 1, metrics, Time.SYSTEM, metricGroup);\n+        ByteBuffer buffer = pool.allocate(1, maxBlockTimeMs);\n+\n+        // Close the buffer pool. This should prevent any further allocations.\n+        pool.close();\n+\n+        try {\n+            pool.allocate(1, maxBlockTimeMs);", "originalCommit": "3c92c5786a0a1548607579a85b892412aeb90734", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA1NTYxNw==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368055617", "bodyText": "Done.", "author": "bdbyrne", "createdAt": "2020-01-17T17:39:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODAyNTIxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODAyNzg4NA==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368027884", "bodyText": "If we used an executor with callables, we could propagate this directly to a future, which could be awaited in the test case.", "author": "hachikuji", "createdAt": "2020-01-17T16:36:07Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/BufferPoolTest.java", "diffHunk": "@@ -377,4 +378,58 @@ public void run() {\n         }\n     }\n \n+    @Test\n+    public void testCloseAllocations() throws Exception {\n+        BufferPool pool = new BufferPool(10, 1, metrics, Time.SYSTEM, metricGroup);\n+        ByteBuffer buffer = pool.allocate(1, maxBlockTimeMs);\n+\n+        // Close the buffer pool. This should prevent any further allocations.\n+        pool.close();\n+\n+        try {\n+            pool.allocate(1, maxBlockTimeMs);\n+            fail(\"Should have thrown KafkaException\");\n+        } catch (KafkaException e) {\n+            // Expected.\n+        }\n+\n+        // Ensure deallocation still works.\n+        pool.deallocate(buffer);\n+    }\n+\n+    @Test\n+    public void testCloseNotifyWaiters() throws Exception {\n+        BufferPool pool = new BufferPool(10, 1, metrics, Time.SYSTEM, metricGroup);\n+        ByteBuffer buffer = pool.allocate(10, Long.MAX_VALUE);\n+\n+        CountDownLatch waiter1 = asyncAllocateClose(pool, 10);\n+        CountDownLatch waiter2 = asyncAllocateClose(pool, 10);\n+\n+        assertEquals(\"Allocation shouldn't have happened yet, waiting on memory\", 2L, waiter1.getCount() + waiter2.getCount());\n+\n+        // Close the buffer pool. This should notify all waiters.\n+        pool.close();\n+\n+        assertTrue(\"Allocation should fail soon after close\", waiter1.await(1, TimeUnit.SECONDS) && waiter2.await(1, TimeUnit.SECONDS));\n+\n+        pool.deallocate(buffer);\n+    }\n+\n+    private CountDownLatch asyncAllocateClose(final BufferPool pool, final int size) {\n+        final CountDownLatch completed = new CountDownLatch(1);\n+        Thread thread = new Thread() {\n+            public void run() {\n+                try {\n+                    pool.allocate(size, maxBlockTimeMs);\n+                    fail(\"Unexpected allocation\");\n+                } catch (KafkaException e) {\n+                    completed.countDown();\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();", "originalCommit": "3c92c5786a0a1548607579a85b892412aeb90734", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2Mjk5Nw==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368062997", "bodyText": "Done. Please verify I have it simplified.", "author": "bdbyrne", "createdAt": "2020-01-17T17:58:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODAyNzg4NA=="}], "type": "inlineReview"}, {"oid": "caed6c2ff8713f875e805ba1b947fdb37083ffb8", "url": "https://github.com/apache/kafka/commit/caed6c2ff8713f875e805ba1b947fdb37083ffb8", "message": "Address review comments.", "committedDate": "2020-01-17T17:57:49Z", "type": "commit"}, {"oid": "5c7f6760cc9180f207858200656c902c164954ed", "url": "https://github.com/apache/kafka/commit/5c7f6760cc9180f207858200656c902c164954ed", "message": "Simplify test.", "committedDate": "2020-01-17T18:04:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MjI1Nw==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368072257", "bodyText": "I'm a bit concerned that this timeout might be too tight for the shaky jenkins build environment. I think there's no harm increasing to 15s or so to be one the safe side.", "author": "hachikuji", "createdAt": "2020-01-17T18:21:56Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/BufferPoolTest.java", "diffHunk": "@@ -377,4 +382,48 @@ public void run() {\n         }\n     }\n \n+    @Test\n+    public void testCloseAllocations() throws Exception {\n+        BufferPool pool = new BufferPool(10, 1, metrics, Time.SYSTEM, metricGroup);\n+        ByteBuffer buffer = pool.allocate(1, maxBlockTimeMs);\n+\n+        // Close the buffer pool. This should prevent any further allocations.\n+        pool.close();\n+\n+        assertThrows(KafkaException.class, () -> pool.allocate(1, maxBlockTimeMs));\n+\n+        // Ensure deallocation still works.\n+        pool.deallocate(buffer);\n+    }\n+\n+    @Test\n+    public void testCloseNotifyWaiters() throws Exception {\n+        final int numWorkers = 2;\n+\n+        BufferPool pool = new BufferPool(1, 1, metrics, Time.SYSTEM, metricGroup);\n+        ByteBuffer buffer = pool.allocate(1, Long.MAX_VALUE);\n+\n+        CountDownLatch completed = new CountDownLatch(numWorkers);\n+        ExecutorService executor = Executors.newFixedThreadPool(numWorkers);\n+        Callable<Void> work = new Callable<Void>() {\n+                public Void call() throws Exception {\n+                    assertThrows(KafkaException.class, () -> pool.allocate(1, maxBlockTimeMs));\n+                    completed.countDown();\n+                    return null;\n+                }\n+            };\n+        for (int i = 0; i < numWorkers; ++i) {\n+            executor.submit(work);\n+        }\n+\n+        assertEquals(\"Allocation shouldn't have happened yet, waiting on memory\", numWorkers, completed.getCount());\n+\n+        // Close the buffer pool. This should notify all waiters.\n+        pool.close();\n+\n+        completed.await(200, TimeUnit.MILLISECONDS);", "originalCommit": "5c7f6760cc9180f207858200656c902c164954ed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MzUxOA==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368073518", "bodyText": "Done.", "author": "bdbyrne", "createdAt": "2020-01-17T18:25:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MjI1Nw=="}], "type": "inlineReview"}, {"oid": "4c63d11596d51b9ddd8907fc23eefdb1f0588306", "url": "https://github.com/apache/kafka/commit/4c63d11596d51b9ddd8907fc23eefdb1f0588306", "message": "Increase timeouts.", "committedDate": "2020-01-17T18:24:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIzMzAyNw==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368233027", "bodyText": "I stepped through this test a few times.\n                public Void call() throws Exception {\n                    System.out.println(\"allocating\");\n                    assertThrows(KafkaException.class, () -> pool.allocate(1, Long.MAX_VALUE));\n                    System.out.println(\"allocated\");\n\nBufferPool is already closed by the time work#call is executed:\nclosing\nallocating\nallocating\nallocated\nallocated\n\nSo the test doesn't exercise line 150 in BufferPool.", "author": "tedyu", "createdAt": "2020-01-18T15:40:16Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/BufferPoolTest.java", "diffHunk": "@@ -377,4 +382,48 @@ public void run() {\n         }\n     }\n \n+    @Test\n+    public void testCloseAllocations() throws Exception {\n+        BufferPool pool = new BufferPool(10, 1, metrics, Time.SYSTEM, metricGroup);\n+        ByteBuffer buffer = pool.allocate(1, maxBlockTimeMs);\n+\n+        // Close the buffer pool. This should prevent any further allocations.\n+        pool.close();\n+\n+        assertThrows(KafkaException.class, () -> pool.allocate(1, maxBlockTimeMs));\n+\n+        // Ensure deallocation still works.\n+        pool.deallocate(buffer);\n+    }\n+\n+    @Test\n+    public void testCloseNotifyWaiters() throws Exception {\n+        final int numWorkers = 2;\n+\n+        BufferPool pool = new BufferPool(1, 1, metrics, Time.SYSTEM, metricGroup);\n+        ByteBuffer buffer = pool.allocate(1, Long.MAX_VALUE);\n+\n+        CountDownLatch completed = new CountDownLatch(numWorkers);\n+        ExecutorService executor = Executors.newFixedThreadPool(numWorkers);\n+        Callable<Void> work = new Callable<Void>() {\n+                public Void call() throws Exception {\n+                    assertThrows(KafkaException.class, () -> pool.allocate(1, Long.MAX_VALUE));\n+                    completed.countDown();\n+                    return null;\n+                }\n+            };\n+        for (int i = 0; i < numWorkers; ++i) {\n+            executor.submit(work);\n+        }\n+\n+        assertEquals(\"Allocation shouldn't have happened yet, waiting on memory\", numWorkers, completed.getCount());\n+\n+        // Close the buffer pool. This should notify all waiters.", "originalCommit": "4c63d11596d51b9ddd8907fc23eefdb1f0588306", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIzODIwNg==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368238206", "bodyText": "Good find, thank you. I've opened #7982 to resolve this.", "author": "bdbyrne", "createdAt": "2020-01-18T17:26:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODIzMzAyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMxODQzMg==", "url": "https://github.com/apache/kafka/pull/7967#discussion_r368318432", "bodyText": "@bdbyrne @hachikuji Currently on Producer.send our javadoc mentioned \"If a Kafka related error occurs that does not belong to the public API exceptions.\" for KafkaException and most callers default it to fatal. However if we consider the pattern where thread A blocked on send#bufferPool, and then thread B calls producer.close which would cause thread A to be unblocked by throwing a KafkaException to be a recommended pattern, should we use a different exception than KafkaException to differentiate it with other other fatal exceptions?\nI'm thinking for Streams if we eventually want to move to this pattern, i.e. the stream thread blocked on producer.send while the closing thread calls producer.close then stream thread would throw KafkaException that in turn would be interpreted as fatal and then the stream thread tries to shutdown itself as \"shutdown unclean\" whereas here since we are indeed closing we should just proceed with \"shutdown clean\" --- of course this is still doable with some extra check but I'm wondering if such complexity would be universal for any callers like Streams.", "author": "guozhangwang", "createdAt": "2020-01-19T20:08:02Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/BufferPool.java", "diffHunk": "@@ -138,6 +147,9 @@ public ByteBuffer allocate(int size, long maxTimeToBlockMs) throws InterruptedEx\n                             recordWaitTime(timeNs);\n                         }\n \n+                        if (this.closed)\n+                            throw new KafkaException(\"Producer closed while allocating memory\");", "originalCommit": "4c63d11596d51b9ddd8907fc23eefdb1f0588306", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}