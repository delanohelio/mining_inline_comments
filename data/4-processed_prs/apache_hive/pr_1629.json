{"pr_number": 1629, "pr_title": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)", "pr_createdAt": "2020-10-30T02:15:14Z", "pr_url": "https://github.com/apache/hive/pull/1629", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4OTQyNA==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520689424", "bodyText": "This is nice because it has been moved outside the lock scope.  I was double-checking if this variable can safely be examined outside the scope of the lock, and I noted that driverContext can never be null.  It is defined as final and set in the constructor.  Please remove this check.", "author": "belugabehr", "createdAt": "2020-11-10T16:17:06Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -149,207 +149,64 @@ private CommandProcessorResponse run(String command, boolean alreadyCompiled) th\n       runInternal(command, alreadyCompiled);\n       return new CommandProcessorResponse(getSchema(), null);\n     } catch (CommandProcessorException cpe) {\n-      SessionState ss = SessionState.get();\n-      if (ss == null) {\n-        throw cpe;\n-      }\n-      MetaDataFormatter mdf = MetaDataFormatUtils.getFormatter(ss.getConf());\n-      if (!(mdf instanceof JsonMetaDataFormatter)) {\n-        throw cpe;\n-      }\n-      /*Here we want to encode the error in machine readable way (e.g. JSON)\n-       * Ideally, errorCode would always be set to a canonical error defined in ErrorMsg.\n-       * In practice that is rarely the case, so the messy logic below tries to tease\n-       * out canonical error code if it can.  Exclude stack trace from output when\n-       * the error is a specific/expected one.\n-       * It's written to stdout for backward compatibility (WebHCat consumes it).*/\n-      try {\n-        if (cpe.getCause() == null) {\n-          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState());\n-          throw cpe;\n-        }\n-        ErrorMsg canonicalErr = ErrorMsg.getErrorMsg(cpe.getResponseCode());\n-        if (canonicalErr != null && canonicalErr != ErrorMsg.GENERIC_ERROR) {\n-          /*Some HiveExceptions (e.g. SemanticException) don't set\n-            canonical ErrorMsg explicitly, but there is logic\n-            (e.g. #compile()) to find an appropriate canonical error and\n-            return its code as error code. In this case we want to\n-            preserve it for downstream code to interpret*/\n-          mdf.error(ss.out, cpe.getMessage(), cpe.getResponseCode(), cpe.getSqlState(), null);\n-          throw cpe;\n-        }\n-        if (cpe.getCause() instanceof HiveException) {\n-          HiveException rc = (HiveException)cpe.getCause();\n-          mdf.error(ss.out, cpe.getMessage(), rc.getCanonicalErrorMsg().getErrorCode(), cpe.getSqlState(),\n-              rc.getCanonicalErrorMsg() == ErrorMsg.GENERIC_ERROR ? StringUtils.stringifyException(rc) : null);\n-        } else {\n-          ErrorMsg canonicalMsg = ErrorMsg.getErrorMsg(cpe.getCause().getMessage());\n-          mdf.error(ss.out, cpe.getMessage(), canonicalMsg.getErrorCode(), cpe.getSqlState(),\n-              StringUtils.stringifyException(cpe.getCause()));\n-        }\n-      } catch (HiveException ex) {\n-        CONSOLE.printError(\"Unable to JSON-encode the error\", StringUtils.stringifyException(ex));\n-      }\n+      processRunException(cpe);\n       throw cpe;\n     }\n   }\n \n   private void runInternal(String command, boolean alreadyCompiled) throws CommandProcessorException {\n     DriverState.setDriverState(driverState);\n \n-    driverState.lock();\n-    try {\n-      if (driverContext != null && driverContext.getPlan() != null\n-          && driverContext.getPlan().isPrepareQuery()\n-          && !driverContext.getPlan().isExplain()) {\n-        LOG.info(\"Skip running tasks for prepare plan\");\n-        return;\n-      }\n-      if (alreadyCompiled) {\n-        if (driverState.isCompiled()) {\n-          driverState.executing();\n-        } else {\n-          String errorMessage = \"FAILED: Precompiled query has been cancelled or closed.\";\n-          CONSOLE.printError(errorMessage);\n-          throw DriverUtils.createProcessorException(driverContext, 12, errorMessage, null, null);\n-        }\n-      } else {\n-        driverState.compiling();\n-      }\n-    } finally {\n-      driverState.unlock();\n+    if (driverContext != null && driverContext.getPlan() != null &&", "originalCommit": "7316cc96b7042a6227e6507e4cd265f97d91c93d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5MzQxOQ==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520693419", "bodyText": "I do see that the driverContext plan is set in a few different places.  I'm not sure if this can be checked outside of a lock.  At the very least, I would minimize the risk a bit:\nQueryPlan plan = driverContext.getPlan();\nif (plan != null\n          && plan.isPrepareQuery()\n          && !plan.isExplain()) {\n\nAt least you know that the value of plan cannot possibly change between calls.", "author": "belugabehr", "createdAt": "2020-11-10T16:22:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4OTQyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc3MjQxMA==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520772410", "bodyText": "Agree, nice catch, fixed.", "author": "miklosgergely", "createdAt": "2020-11-10T18:17:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY4OTQyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5OTc2NQ==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520699765", "bodyText": "Since you are slicing and dicing things, you may want to look at breaking this out a bit.\nIt is bad form to throw and exception, and then handle it, within the same method.\nI think this should be moved out of this try block.\n      if (retryShapshotCount > maxRetrySnapshotCount) {\n        // Throw exception\n        HiveException e = new HiveException(\n            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n        DriverUtils.handleHiveException(driverContext, e, 14, null);\n      }\n  if (retryShapshotCount != 0) {\n        // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n        // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n        context.setHiveTxnManager(driverContext.getTxnManager());\n        return true;\n    }\n    return false;", "author": "belugabehr", "createdAt": "2020-11-10T16:30:47Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -359,6 +216,101 @@ private void runInternal(String command, boolean alreadyCompiled) throws Command\n     SessionState.getPerfLogger().cleanupPerfLogMetrics();\n   }\n \n+  /**\n+   * @return If the perfLogger should be reseted.\n+   */\n+  private boolean validateTxnList() throws CommandProcessorException {\n+    int retryShapshotCount = 0;\n+    int maxRetrySnapshotCount = HiveConf.getIntVar(driverContext.getConf(),\n+        HiveConf.ConfVars.HIVE_TXN_MAX_RETRYSNAPSHOT_COUNT);\n+\n+    try {\n+      do {\n+        driverContext.setOutdatedTxn(false);\n+        // Inserts will not invalidate the snapshot, that could cause duplicates.\n+        if (!driverTxnHandler.isValidTxnListState()) {\n+          LOG.info(\"Re-compiling after acquiring locks, attempt #\" + retryShapshotCount);\n+          // Snapshot was outdated when locks were acquired, hence regenerate context, txn list and retry.\n+          // TODO: Lock acquisition should be moved before analyze, this is a bit hackish.\n+          // Currently, we acquire a snapshot, compile the query with that snapshot, and then - acquire locks.\n+          // If snapshot is still valid, we continue as usual.\n+          // But if snapshot is not valid, we recompile the query.\n+          if (driverContext.isOutdatedTxn()) {\n+            // Later transaction invalidated the snapshot, a new transaction is required\n+            LOG.info(\"Snapshot is outdated, re-initiating transaction ...\");\n+            driverContext.getTxnManager().rollbackTxn();\n+\n+            String userFromUGI = DriverUtils.getUserFromUGI(driverContext);\n+            driverContext.getTxnManager().openTxn(context, userFromUGI, driverContext.getTxnType());\n+            lockAndRespond();\n+          }\n+          driverContext.setRetrial(true);\n+          driverContext.getBackupContext().addSubContext(context);\n+          driverContext.getBackupContext().setHiveLocks(context.getHiveLocks());\n+          context = driverContext.getBackupContext();\n+\n+          driverContext.getConf().set(ValidTxnList.VALID_TXNS_KEY,\n+              driverContext.getTxnManager().getValidTxns().toString());\n+\n+          if (driverContext.getPlan().hasAcidResourcesInQuery()) {\n+            compileInternal(context.getCmd(), true);\n+            driverTxnHandler.recordValidWriteIds();\n+            driverTxnHandler.setWriteIdForAcidFileSinks();\n+          }\n+          // Since we're reusing the compiled plan, we need to update its start time for current run\n+          driverContext.getPlan().setQueryStartTime(driverContext.getQueryDisplay().getQueryStartTime());\n+        }\n+        // Re-check snapshot only in case we had to release locks and open a new transaction,\n+        // otherwise exclusive locks should protect output tables/partitions in snapshot from concurrent writes.\n+      } while (driverContext.isOutdatedTxn() && ++retryShapshotCount <= maxRetrySnapshotCount);\n+\n+      if (retryShapshotCount > maxRetrySnapshotCount) {\n+        // Throw exception\n+        HiveException e = new HiveException(\n+            \"Operation could not be executed, \" + SNAPSHOT_WAS_OUTDATED_WHEN_LOCKS_WERE_ACQUIRED + \".\");\n+        DriverUtils.handleHiveException(driverContext, e, 14, null);\n+      } else if (retryShapshotCount != 0) {\n+        // the reason that we set the txn manager for the cxt here is because each query has its own ctx object.\n+        // The txn mgr is shared across the same instance of Driver, which can run multiple queries.\n+        context.setHiveTxnManager(driverContext.getTxnManager());\n+      }", "originalCommit": "7316cc96b7042a6227e6507e4cd265f97d91c93d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcwMTA5Nw==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520701097", "bodyText": "It is probably overwriting the error code of '14' with the outer-try-catch code of '13'.", "author": "belugabehr", "createdAt": "2020-11-10T16:32:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5OTc2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcwNzY0Nw==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520707647", "bodyText": "DriverUtils.handleHiveException throws a CommandProcessorException which is not caught, as it is neither a LockException nor a SemanticException. Still the block that you've mentioned can be moved to a separate method, but I don't see the meaning of the returned boolean. What would that be used for?", "author": "miklosgergely", "createdAt": "2020-11-10T16:41:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5OTc2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcwOTUzNQ==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520709535", "bodyText": "oh, I see the meaning of the return value, it is what needs to b returned from the original method. Sure, I can move this to a separate method, do you have a suggestion for the name?", "author": "miklosgergely", "createdAt": "2020-11-10T16:44:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDY5OTc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcwNzk5NQ==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520707995", "bodyText": "This is a little hard to follow.  Perhaps something like:\n    if (driverContext.getResStream() == null) {\n       // If the driver does not have a stream and neither does the context, return\n       Stream contextStream = context.getStream();\n       if (contextStream == null) {\n         return false;\n       }\n       driverContext.setResStream(contextStream);\n      }\n    }", "author": "belugabehr", "createdAt": "2020-11-10T16:42:13Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -638,46 +654,28 @@ public boolean getResults(List results) throws IOException {\n     }\n \n     if (isFetchingTable()) {\n-      /**\n-       * If resultset serialization to thrift object is enabled, and if the destination table is\n-       * indeed written using ThriftJDBCBinarySerDe, read one row from the output sequence file,\n-       * since it is a blob of row batches.\n-       */\n-      if (driverContext.getFetchTask().getWork().isUsingThriftJDBCBinarySerDe()) {\n-        maxRows = 1;\n-      }\n-      driverContext.getFetchTask().setMaxRows(maxRows);\n-      return driverContext.getFetchTask().fetch(results);\n+      return getFetchingTableResults(results);\n     }\n \n     if (driverContext.getResStream() == null) {\n       driverContext.setResStream(context.getStream());\n-    }\n-    if (driverContext.getResStream() == null) {\n-      return false;\n+      if (driverContext.getResStream() == null) {\n+        return false;\n+      }\n     }", "originalCommit": "7316cc96b7042a6227e6507e4cd265f97d91c93d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc3MzE5MQ==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520773191", "bodyText": "I agree, it's nicer like this, fixed.", "author": "miklosgergely", "createdAt": "2020-11-10T18:19:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcwNzk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMDYzMw==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520710633", "bodyText": "nit: Safer to make this final to ensure that there aren't multiple paths later if this code changes.", "author": "belugabehr", "createdAt": "2020-11-10T16:45:50Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/Driver.java", "diffHunk": "@@ -687,13 +685,36 @@ public boolean getResults(List results) throws IOException {\n         return false;\n       }\n \n-      if (ss == Utilities.StreamStatus.EOF) {\n+      if (streamStatus == Utilities.StreamStatus.EOF) {\n         driverContext.setResStream(context.getStream());\n       }\n     }\n     return true;\n   }\n \n+  @SuppressWarnings(\"rawtypes\")\n+  private boolean getFetchingTableResults(List results) throws IOException {\n+    // If result set serialization to thrift object is enabled, and if the destination table is indeed written using\n+    // ThriftJDBCBinarySerDe, read one row from the output sequence file, since it is a blob of row batches.\n+    if (driverContext.getFetchTask().getWork().isUsingThriftJDBCBinarySerDe()) {\n+      maxRows = 1;\n+    }\n+    driverContext.getFetchTask().setMaxRows(maxRows);\n+    return driverContext.getFetchTask().fetch(results);\n+  }\n+\n+  private String getRow(ByteStream.Output bos, Utilities.StreamStatus streamStatus) {\n+    String row;", "originalCommit": "7316cc96b7042a6227e6507e4cd265f97d91c93d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc3MjUwMQ==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520772501", "bodyText": "final added.", "author": "miklosgergely", "createdAt": "2020-11-10T18:17:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMDYzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMjc5Nw==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520712797", "bodyText": "This is a good change, but please revert for this PR to keep it focused on the Driver classes.", "author": "belugabehr", "createdAt": "2020-11-10T16:48:44Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/DriverFactory.java", "diffHunk": "@@ -73,7 +73,7 @@ private static IReExecutionPlugin buildReExecPlugin(String name) throws RuntimeE\n     if(\"reexecute_lost_am\".equals(name)) {\n       return new ReExecuteLostAMQueryPlugin();\n     }\n-    if (name.equals(\"dagsubmit\")) {\n+    if (\"dagsubmit\".equals(name)) {", "originalCommit": "7316cc96b7042a6227e6507e4cd265f97d91c93d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc3MjA4Mg==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520772082", "bodyText": "OK, removed.", "author": "miklosgergely", "createdAt": "2020-11-10T18:17:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMjc5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMjg3Mw==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520712873", "bodyText": "This is a good change, but please revert for this PR to keep it focused on the Driver classes.", "author": "belugabehr", "createdAt": "2020-11-10T16:48:50Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/DriverTxnHandler.java", "diffHunk": "@@ -67,7 +67,6 @@\n import org.apache.hadoop.hive.ql.session.SessionState.LogHelper;\n import org.apache.hadoop.util.StringUtils;\n import org.apache.hive.common.util.ShutdownHookManager;\n-import org.apache.hive.common.util.TxnIdUtils;", "originalCommit": "7316cc96b7042a6227e6507e4cd265f97d91c93d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDc3MjE5Mw==", "url": "https://github.com/apache/hive/pull/1629#discussion_r520772193", "bodyText": "OK, removed.", "author": "miklosgergely", "createdAt": "2020-11-10T18:17:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDcxMjg3Mw=="}], "type": "inlineReview"}, {"oid": "8c33879faa9538712811b5057c7808b233d68a8e", "url": "https://github.com/apache/hive/commit/8c33879faa9538712811b5057c7808b233d68a8e", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)", "committedDate": "2020-11-10T18:16:32Z", "type": "forcePushed"}, {"oid": "4e7e1d8fbeb52cc550789c6ac258b6008be0bc59", "url": "https://github.com/apache/hive/commit/4e7e1d8fbeb52cc550789c6ac258b6008be0bc59", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)", "committedDate": "2020-11-10T18:18:53Z", "type": "forcePushed"}, {"oid": "76ce45dd0316f18f6329e7ff3d8069cfe2f7042c", "url": "https://github.com/apache/hive/commit/76ce45dd0316f18f6329e7ff3d8069cfe2f7042c", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)", "committedDate": "2020-11-26T11:53:01Z", "type": "commit"}, {"oid": "76ce45dd0316f18f6329e7ff3d8069cfe2f7042c", "url": "https://github.com/apache/hive/commit/76ce45dd0316f18f6329e7ff3d8069cfe2f7042c", "message": "HIVE-24333 Cut long methods in Driver to smaller, more manageable pieces (Miklos Gergely)", "committedDate": "2020-11-26T11:53:01Z", "type": "forcePushed"}]}