{"pr_number": 1472, "pr_title": "HIVE-24009 Support partition pruning, vectorization and other physical transformations for EXECUTE statement", "pr_createdAt": "2020-09-05T01:06:39Z", "pr_url": "https://github.com/apache/hive/pull/1472", "timeline": [{"oid": "4cdb2b27312c095956177586ee7df46b5a023ee8", "url": "https://github.com/apache/hive/commit/4cdb2b27312c095956177586ee7df46b5a023ee8", "message": "HIVE-24009: Support partition pruning and other physical transformations for EXECUTE statement", "committedDate": "2020-09-14T20:36:26Z", "type": "commit"}, {"oid": "4cdb2b27312c095956177586ee7df46b5a023ee8", "url": "https://github.com/apache/hive/commit/4cdb2b27312c095956177586ee7df46b5a023ee8", "message": "HIVE-24009: Support partition pruning and other physical transformations for EXECUTE statement", "committedDate": "2020-09-14T20:36:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODIwNzAyOA==", "url": "https://github.com/apache/hive/pull/1472#discussion_r488207028", "bodyText": "This query no longer fails. I have opened a follow-up to fix this https://issues.apache.org/jira/browse/HIVE-24164", "author": "vineetgarg02", "createdAt": "2020-09-14T20:40:51Z", "path": "ql/src/test/queries/clientnegative/prepare_execute_1.q", "diffHunk": "@@ -1,3 +0,0 @@\n---! qt:dataset:src\n-prepare query1 from select count(*) from src where key > ? and value < ? group by ?;\n-execute query1 using 1,100,1;", "originalCommit": "4cdb2b27312c095956177586ee7df46b5a023ee8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6420acfd5f1dfc7bfebb4f83241184e84b6066ff", "url": "https://github.com/apache/hive/commit/6420acfd5f1dfc7bfebb4f83241184e84b6066ff", "message": "fixing test failures", "committedDate": "2020-09-15T20:40:01Z", "type": "commit"}, {"oid": "bdff173ee3142a459c70ccadbfa82b3d594aeaa5", "url": "https://github.com/apache/hive/commit/bdff173ee3142a459c70ccadbfa82b3d594aeaa5", "message": "test fix", "committedDate": "2020-09-16T19:48:14Z", "type": "commit"}, {"oid": "893e49ad481089b2ce37e369c44c3b3427bdf018", "url": "https://github.com/apache/hive/commit/893e49ad481089b2ce37e369c44c3b3427bdf018", "message": "Merge remote-tracking branch 'upstream/master' into HIVE-24009", "committedDate": "2020-09-16T19:56:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0ODU3OQ==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491748579", "bodyText": "Do we need to keep all these fields for the plan cache in the operator, table, etc.? I am wondering about the implications of keeping them when the operator plan is serialized (i.e., whether that could have an performance impact). @t3rmin4t0r , @rbalamohan , could you comment on this?", "author": "jcamachor", "createdAt": "2020-09-20T23:36:21Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java", "diffHunk": "@@ -63,19 +63,19 @@\n \n   private VectorizationContext taskVectorizationContext;\n \n-  protected transient JobConf jc;\n-  private transient boolean inputFileChanged = false;\n+  protected JobConf jc;", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyNDU2MQ==", "url": "https://github.com/apache/hive/pull/1472#discussion_r492224561", "bodyText": "I actually tried not keeping these fields but I was running into all sorts of issues like unable to serialize/de-serialize or plan generating without metadata etc.\nI am not sure if we need to keep all of these fields or we can selectively choose, I went by almost all in interest of time. If Gopal or Rajesh thinks that this may cause performance issue I can open a follow-up to investigate and choose fields selectively.", "author": "vineetgarg02", "createdAt": "2020-09-21T17:21:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0ODU3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUzOTAxMg==", "url": "https://github.com/apache/hive/pull/1472#discussion_r492539012", "bodyText": "Let's create a follow-up to explore whether some of them may be made transient again and discuss over there.", "author": "jcamachor", "createdAt": "2020-09-22T07:54:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0ODU3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc5MzQ0NA==", "url": "https://github.com/apache/hive/pull/1472#discussion_r493793444", "bodyText": "I have updated HIVE-24005 to investigate this.", "author": "vineetgarg02", "createdAt": "2020-09-23T18:14:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0ODU3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MTI3Mw==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491751273", "bodyText": "Can remove line commented out.", "author": "jcamachor", "createdAt": "2020-09-21T00:03:09Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/ExecuteStatementAnalyzer.java", "diffHunk": "@@ -253,14 +191,17 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n     String queryName = getQueryName(root);\n     if (ss.getPreparePlans().containsKey(queryName)) {\n       // retrieve cached plan from session state\n-      BaseSemanticAnalyzer cachedPlan = ss.getPreparePlans().get(queryName);\n+      SemanticAnalyzer cachedPlan = ss.getPreparePlans().get(queryName);\n \n       // make copy of the plan\n-      createTaskCopy(cachedPlan);\n+      //createTaskCopy(cachedPlan);", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MTMxMQ==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491751311", "bodyText": "Same, can be removed?", "author": "jcamachor", "createdAt": "2020-09-21T00:03:35Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/ExecuteStatementAnalyzer.java", "diffHunk": "@@ -286,6 +227,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n       this.acidFileSinks.addAll(cachedPlan.getAcidFileSinks());\n       this.initCtx(cachedPlan.getCtx());\n       this.ctx.setCboInfo(cachedPlan.getCboInfo());\n+      this.setLoadFileWork(cachedPlan.getLoadFileWork());\n+      this.setLoadTableWork(cachedPlan.getLoadTableWork());\n+\n+      this.setQB(cachedPlan.getQB());\n+\n+      ParseContext pctxt = this.getParseContext();\n+      // partition pruner\n+      Transform ppr = new PartitionPruner();\n+      ppr.transform(pctxt);\n+\n+      //pctxt.setQueryProperties(this.queryProperties);", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MTMzMQ==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491751331", "bodyText": "This comment too.", "author": "jcamachor", "createdAt": "2020-09-21T00:03:54Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/ExecuteStatementAnalyzer.java", "diffHunk": "@@ -286,6 +227,24 @@ public void analyzeInternal(ASTNode root) throws SemanticException {\n       this.acidFileSinks.addAll(cachedPlan.getAcidFileSinks());\n       this.initCtx(cachedPlan.getCtx());\n       this.ctx.setCboInfo(cachedPlan.getCboInfo());\n+      this.setLoadFileWork(cachedPlan.getLoadFileWork());\n+      this.setLoadTableWork(cachedPlan.getLoadTableWork());\n+\n+      this.setQB(cachedPlan.getQB());\n+\n+      ParseContext pctxt = this.getParseContext();\n+      // partition pruner\n+      Transform ppr = new PartitionPruner();\n+      ppr.transform(pctxt);\n+\n+      //pctxt.setQueryProperties(this.queryProperties);\n+      if (!ctx.getExplainLogical()) {\n+        TaskCompiler compiler = TaskCompilerFactory.getCompiler(conf, pctxt);\n+        compiler.init(queryState, console, db);\n+        compiler.compile(pctxt, rootTasks, inputs, outputs);\n+        fetchTask = pctxt.getFetchTask();\n+        //fetchTask = makeCopy(cachedPlan.getFetchTask(), cachedPlan.getFetchTask().getClass());", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MjIzMg==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491752232", "bodyText": "Can we leave a comment on this method to understand what it is trying to do?", "author": "jcamachor", "createdAt": "2020-09-21T00:11:56Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/PrepareStatementAnalyzer.java", "diffHunk": "@@ -54,6 +58,21 @@ private void savePlan(String queryName) throws SemanticException{\n     ss.getPreparePlans().put(queryName, this);\n   }\n \n+  private <T> T makeCopy(final Object task, Class<T> objClass) {\n+    ByteArrayOutputStream baos = new ByteArrayOutputStream();", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MjM5MQ==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491752391", "bodyText": "Why do you need to keep a copy instead of using the original operators? Could you leave a comment on that?", "author": "jcamachor", "createdAt": "2020-09-21T00:13:33Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java", "diffHunk": "@@ -387,6 +387,12 @@\n   protected volatile boolean disableJoinMerge = false;\n   protected final boolean defaultJoinMerge;\n \n+  /*\n+   * This is used by prepare/execute statement\n+   * Prepare/Execute requires operators to be copied and cached\n+   */\n+  protected Map<String, TableScanOperator> topOpsCopy = null;", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyOTA2Nw==", "url": "https://github.com/apache/hive/pull/1472#discussion_r492229067", "bodyText": "Original operator tree shape is changed when going through physical transformations and task generation (don't know why though), as a result this operator tree can not be used later to regenerate tasks or re-running physical transformations. Therefore we make a copy and cache it after operator tree is generated.\nI will leave a comment.", "author": "vineetgarg02", "createdAt": "2020-09-21T17:29:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MjM5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MjY0NA==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491752644", "bodyText": "I guess this was actually unrelated to current patch? Probably due to some data structure not being serialized when different union branches are copied?", "author": "jcamachor", "createdAt": "2020-09-21T00:15:37Z", "path": "ql/src/test/results/clientpositive/llap/constprog_dpp.q.out", "diffHunk": "@@ -84,12 +84,13 @@ Stage-0\n                         Select Operator [SEL_40] (rows=1 width=4)\n                           Output:[\"_col0\"]\n                           TableScan [TS_24] (rows=1 width=4)\n-                            Output:[\"id\"]\n+                            default@tb2,tb2,Tbl:COMPLETE,Col:NONE,Output:[\"id\"]", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIyOTc1OA==", "url": "https://github.com/apache/hive/pull/1472#discussion_r492229758", "bodyText": "Yeah I think this is likely side effect of some changes in w.r.t serialization/de-serialization. Although this is positive side effect now that we have more information in explain plan.", "author": "vineetgarg02", "createdAt": "2020-09-21T17:30:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MjY0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MjczOA==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491752738", "bodyText": "This seems different than the stats above. Do you know if it is expected? May be worth checking in a follow-up.", "author": "jcamachor", "createdAt": "2020-09-21T00:16:36Z", "path": "ql/src/test/results/clientpositive/llap/constprog_dpp.q.out", "diffHunk": "@@ -84,12 +84,13 @@ Stage-0\n                         Select Operator [SEL_40] (rows=1 width=4)\n                           Output:[\"_col0\"]\n                           TableScan [TS_24] (rows=1 width=4)\n-                            Output:[\"id\"]\n+                            default@tb2,tb2,Tbl:COMPLETE,Col:NONE,Output:[\"id\"]\n                   <-Map 6 [CONTAINS] vectorized, llap\n                     Reduce Output Operator [RS_45]\n                       Limit [LIM_44] (rows=1 width=2)\n                         Number of rows:1\n                         Select Operator [SEL_43] (rows=1 width=0)\n                           Output:[\"_col0\"]\n                           TableScan [TS_29] (rows=1 width=0)\n+                            default@tb2,tb2,Tbl:PARTIAL,Col:COMPLETE", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI0MDExNQ==", "url": "https://github.com/apache/hive/pull/1472#discussion_r492240115", "bodyText": "I confirmed that this is expected. I compared this plan against master (with explain.user set to false) and there is no difference in the plan.", "author": "vineetgarg02", "createdAt": "2020-09-21T17:48:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1MjczOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1NDEzNw==", "url": "https://github.com/apache/hive/pull/1472#discussion_r491754137", "bodyText": "Nice!", "author": "jcamachor", "createdAt": "2020-09-21T00:30:20Z", "path": "ql/src/test/results/clientpositive/llap/prepare_plan.q.out", "diffHunk": "@@ -170,10 +170,10 @@ STAGE PLANS:\n                           sort order: \n                           Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE\n                           value expressions: _col0 (type: bigint)\n-            Execution mode: llap\n+            Execution mode: vectorized, llap", "originalCommit": "893e49ad481089b2ce37e369c44c3b3427bdf018", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7ec26dcabc3320e892f8c27cfc151db8bcda9894", "url": "https://github.com/apache/hive/commit/7ec26dcabc3320e892f8c27cfc151db8bcda9894", "message": "addressing review comments", "committedDate": "2020-09-21T17:33:29Z", "type": "commit"}, {"oid": "4b3ee2024d9c24b5b7313f1c6d742252d9f7571f", "url": "https://github.com/apache/hive/commit/4b3ee2024d9c24b5b7313f1c6d742252d9f7571f", "message": "Merge remote-tracking branch 'upstream/master' into HIVE-24009", "committedDate": "2020-09-21T17:48:30Z", "type": "commit"}, {"oid": "ced93ad0d4cdd508b0a17afa410183626cd739fe", "url": "https://github.com/apache/hive/commit/ced93ad0d4cdd508b0a17afa410183626cd739fe", "message": "fixing test failures", "committedDate": "2020-09-23T00:05:28Z", "type": "commit"}]}