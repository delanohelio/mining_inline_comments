{"pr_number": 1324, "pr_title": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans", "pr_createdAt": "2020-07-27T16:55:14Z", "pr_url": "https://github.com/apache/hive/pull/1324", "timeline": [{"oid": "53d0f2b8c3d38a458ff7a743246ac4df8c3861b2", "url": "https://github.com/apache/hive/commit/53d0f2b8c3d38a458ff7a743246ac4df8c3861b2", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans", "committedDate": "2020-07-29T13:56:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDQ4MQ==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463040481", "bodyText": "Can we move the new call before the if(pctx.getConf().getBoolVar(ConfVars.HIVE_SHARED_WORK_REUSE_MAPJOIN_CACHE)) { block? It makes sense to trigger that block at the very end in case we continue adding phases.", "author": "jcamachor", "createdAt": "2020-07-30T14:32:12Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {", "originalCommit": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4Nzk0Mg==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463487942", "bodyText": "fixed", "author": "kasakrisz", "createdAt": "2020-07-31T08:52:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDQ4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDY1OA==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463040658", "bodyText": "Can we put this additional step under a new flag (true by default)?", "author": "jcamachor", "createdAt": "2020-07-30T14:32:28Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));\n+    }\n+\n+    // Execute shared work optimization\n+    new BaseSharedWorkOptimizer().sharedWorkOptimization(", "originalCommit": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4ODEzMQ==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463488131", "bodyText": "fixed", "author": "kasakrisz", "createdAt": "2020-07-31T08:52:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MDY1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTEyNA==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463041124", "bodyText": "This is the same as After SharedWorkSJOptimizer, no need to print it again.", "author": "jcamachor", "createdAt": "2020-07-30T14:33:08Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));", "originalCommit": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4ODIyMg==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463488222", "bodyText": "fixed", "author": "kasakrisz", "createdAt": "2020-07-31T08:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTEyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTczOA==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463041738", "bodyText": "After SharedWorkOptimizer merging TS schema?", "author": "jcamachor", "createdAt": "2020-07-30T14:33:58Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -247,6 +249,18 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n       }\n     }\n \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Before SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));\n+    }\n+\n+    // Execute shared work optimization\n+    new BaseSharedWorkOptimizer().sharedWorkOptimization(\n+        pctx, optimizerCache, tableNameToOps, sortedTables, false);\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"After SharedWorkOptimizer #2:\\n\" + Operator.toString(pctx.getTopOps().values()));", "originalCommit": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4ODMxOQ==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463488319", "bodyText": "fixed", "author": "kasakrisz", "createdAt": "2020-07-31T08:52:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MTczOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MjM3Mw==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463042373", "bodyText": "Can we add a clarifying comment to the new internal classes with the difference between both of them?", "author": "jcamachor", "createdAt": "2020-07-30T14:34:47Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/optimizer/SharedWorkOptimizer.java", "diffHunk": "@@ -273,258 +287,332 @@ public ParseContext transform(ParseContext pctx) throws SemanticException {\n     return pctx;\n   }\n \n-  private static boolean sharedWorkOptimization(ParseContext pctx, SharedWorkOptimizerCache optimizerCache,\n-      ArrayListMultimap<String, TableScanOperator> tableNameToOps, List<Entry<String, Long>> sortedTables,\n-      boolean removeSemijoin) throws SemanticException {\n-    // Boolean to keep track of whether this method actually merged any TS operators\n-    boolean mergedExecuted = false;\n-\n-    Multimap<String, TableScanOperator> existingOps = ArrayListMultimap.create();\n-    Set<Operator<?>> removedOps = new HashSet<>();\n-    for (Entry<String, Long> tablePair : sortedTables) {\n-      String tableName = tablePair.getKey();\n-      for (TableScanOperator discardableTsOp : tableNameToOps.get(tableName)) {\n-        if (removedOps.contains(discardableTsOp)) {\n-          LOG.debug(\"Skip {} as it has already been removed\", discardableTsOp);\n-          continue;\n-        }\n-        Collection<TableScanOperator> prevTsOps = existingOps.get(tableName);\n-        for (TableScanOperator retainableTsOp : prevTsOps) {\n-          if (removedOps.contains(retainableTsOp)) {\n-            LOG.debug(\"Skip {} as it has already been removed\", retainableTsOp);\n+  private static class BaseSharedWorkOptimizer {", "originalCommit": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ4ODQwNA==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463488404", "bodyText": "fixed", "author": "kasakrisz", "createdAt": "2020-07-31T08:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0MjM3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0NTIzOA==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463045238", "bodyText": "I do not see projected columns, so it is difficult to confirm whether this is because of the schema. Is it?", "author": "jcamachor", "createdAt": "2020-07-30T14:38:30Z", "path": "ql/src/test/results/clientpositive/llap/annotate_stats_join_pkfk.q.out", "diffHunk": "@@ -1191,14 +1191,6 @@ STAGE PLANS:\n                         sort order: +\n                         Map-reduce partition columns: _col0 (type: int)\n                         Statistics: Num rows: 12 Data size: 48 Basic stats: COMPLETE Column stats: COMPLETE\n-            Execution mode: vectorized, llap", "originalCommit": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQxNTgzNA==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463415834", "bodyText": "I checked this with the debugger:\nTS[6]\ndbName = \"default\"\ntableName = \"store_n0\"\nneededColumns = {ArrayList@24024}  size = 1\n 0 = \"s_store_sk\"\n\nTS[3]\ndbName = \"default\"\ntableName = \"store_n0\"\nneededColumns = {ArrayList@24053}  size = 2\n 0 = \"s_store_sk\"\n 1 = \"s_floor_space\"", "author": "kasakrisz", "createdAt": "2020-07-31T05:43:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0NTIzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0ODE4Mg==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463048182", "bodyText": "Why is this projection changing? Is this correct? I do not see the branch with date column.", "author": "jcamachor", "createdAt": "2020-07-30T14:42:28Z", "path": "ql/src/test/results/clientpositive/llap/auto_join_reordering_values.q.out", "diffHunk": "@@ -144,122 +144,30 @@ STAGE PLANS:\n                         tag: 0\n                         value expressions: _col0 (type: int), _col2 (type: int), _col3 (type: int)\n                         auto parallelism: true\n-            Execution mode: vectorized, llap\n-            LLAP IO: no inputs\n-            Path -> Alias:\n-#### A masked pattern was here ####\n-            Path -> Partition:\n-#### A masked pattern was here ####\n-                Partition\n-                  base file name: orderpayment_small\n-                  input format: org.apache.hadoop.mapred.TextInputFormat\n-                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n-                  properties:\n-                    bucket_count -1\n-                    bucketing_version 2\n-                    column.name.delimiter ,\n-                    columns dealid,date,time,cityid,userid\n-                    columns.types int:string:string:int:int\n-#### A masked pattern was here ####\n-                    name default.orderpayment_small\n-                    serialization.format 1\n-                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                \n-                    input format: org.apache.hadoop.mapred.TextInputFormat\n-                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat\n-                    properties:\n-                      bucketing_version 2\n-                      column.name.delimiter ,\n-                      columns dealid,date,time,cityid,userid\n-                      columns.comments \n-                      columns.types int:string:string:int:int\n-#### A masked pattern was here ####\n-                      name default.orderpayment_small\n-                      serialization.format 1\n-                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe\n-                    name: default.orderpayment_small\n-                  name: default.orderpayment_small\n-            Truncated Path -> Alias:\n-              /orderpayment_small [orderpayment]\n-        Map 6 \n-            Map Operator Tree:\n-                TableScan\n-                  alias: dim_pay_date\n-                  filterExpr: date is not null (type: boolean)\n-                  Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE\n-                  GatherStats: false\n                   Filter Operator\n                     isSamplingPred: false\n-                    predicate: date is not null (type: boolean)\n-                    Statistics: Num rows: 1 Data size: 94 Basic stats: COMPLETE Column stats: COMPLETE\n+                    predicate: dealid is not null (type: boolean)\n+                    Statistics: Num rows: 1 Data size: 4 Basic stats: COMPLETE Column stats: COMPLETE\n                     Select Operator\n-                      expressions: date (type: string)", "originalCommit": "aa2199d2c129b8b6e7e19f00962acfa0f9eb3380", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQzMDk0Mg==", "url": "https://github.com/apache/hive/pull/1324#discussion_r463430942", "bodyText": "The TS pulls the column date only was not merged due to validPreConditions failed:\n2020-07-30T23:20:32,796 DEBUG [a51ac124-5fb2-43bc-a0fc-f27099762584 main] optimizer.SharedWorkOptimizer: After SharedWorkSJOptimizer:\nTS[0]-FIL[44]-SEL[2]-RS[15]-MERGEJOIN[89]-RS[18]-MERGEJOIN[90]-RS[21]-MERGEJOIN[91]-RS[24]-MERGEJOIN[92]-SEL[27]-LIM[28]-FS[29]\nTS[3]-FIL[45]-SEL[5]-RS[16]-MERGEJOIN[89]\nTS[6]-FIL[46]-SEL[8]-RS[19]-MERGEJOIN[90]\nTS[9]-FIL[47]-SEL[11]-RS[22]-MERGEJOIN[91]\nTS[12]-FIL[48]-SEL[14]-RS[25]-MERGEJOIN[92]\n\nBoth has the same output works:\nTS[0] \nalias = \"orderpayment\"\ndbName = \"default\"\ntableName = \"orderpayment_small\"\nneededColumns = {ArrayList@24085}  size = 4\n 0 = \"dealid\"\n 1 = \"date\"\n 2 = \"cityid\"\n 3 = \"userid\"\noutputWorksOps1 = {HashSet@24017}  size = 2\n 0 = {ReduceSinkOperator@24028} \"RS[18]\"\n 1 = {CommonMergeJoinOperator@24029} \"MERGEJOIN[89]\"\n\nTS[3]\nalias = \"dim_pay_date\"\ndbName = \"default\"\ntableName = \"orderpayment_small\"\nneededColumns = {ArrayList@23791}  size = 1\n 0 = \"date\"\noutputWorksOps2 = {HashSet@24022}  size = 2\n 0 = {ReduceSinkOperator@24028} \"RS[18]\"\n 1 = {CommonMergeJoinOperator@24029} \"MERGEJOIN[89]\"", "author": "kasakrisz", "createdAt": "2020-07-31T06:36:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0ODE4Mg=="}], "type": "inlineReview"}, {"oid": "f195a5435aef9bf7c13b4e68dbb0ee0664062a2d", "url": "https://github.com/apache/hive/commit/f195a5435aef9bf7c13b4e68dbb0ee0664062a2d", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans", "committedDate": "2020-07-31T04:02:01Z", "type": "commit"}, {"oid": "d6602742be7ec984623d9dc35e1549414a393e03", "url": "https://github.com/apache/hive/commit/d6602742be7ec984623d9dc35e1549414a393e03", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans - update q9, q64 out", "committedDate": "2020-07-31T04:02:01Z", "type": "commit"}, {"oid": "9179b150a8519baf825c0b36150488af67f57ea5", "url": "https://github.com/apache/hive/commit/9179b150a8519baf825c0b36150488af67f57ea5", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans - address review comments", "committedDate": "2020-07-31T07:23:35Z", "type": "commit"}, {"oid": "9179b150a8519baf825c0b36150488af67f57ea5", "url": "https://github.com/apache/hive/commit/9179b150a8519baf825c0b36150488af67f57ea5", "message": "HIVE-23939: SharedWorkOptimizer: take the union of columns in mergeable TableScans - address review comments", "committedDate": "2020-07-31T07:23:35Z", "type": "forcePushed"}]}