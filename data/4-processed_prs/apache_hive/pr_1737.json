{"pr_number": 1737, "pr_title": "HIVE-24482: Set advanced write Id during add constraint DDL tasks", "pr_createdAt": "2020-12-03T16:33:24Z", "pr_url": "https://github.com/apache/hive/pull/1737", "timeline": [{"oid": "f837699a3d78c643969508cb27a076690394659b", "url": "https://github.com/apache/hive/commit/f837699a3d78c643969508cb27a076690394659b", "message": "Set advanced write Id during add constraint DDL tasks", "committedDate": "2020-12-03T16:28:55Z", "type": "commit"}, {"oid": "5c7c9a0b069384548bd2a3728498d95d84e34fc7", "url": "https://github.com/apache/hive/commit/5c7c9a0b069384548bd2a3728498d95d84e34fc7", "message": "Fix test cases", "committedDate": "2020-12-04T09:24:38Z", "type": "commit"}, {"oid": "261a8f822ac2260970dd70a5394d8d087e70f37a", "url": "https://github.com/apache/hive/commit/261a8f822ac2260970dd70a5394d8d087e70f37a", "message": "Add unit tests", "committedDate": "2020-12-08T09:30:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTE3NjI1Mg==", "url": "https://github.com/apache/hive/pull/1737#discussion_r539176252", "bodyText": "What is the reason for introducing this abstract class? Is there any plan for having multiple classes extending it? Why don't you just simply add the necessary changes to the AlterTableAddConstraintAnalyzer?", "author": "miklosgergely", "createdAt": "2020-12-09T10:11:18Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/add/AbstractAddConstraintAnalyzer.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.ddl.table.constraint.add;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.metastore.api.SQLCheckConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLForeignKey;\n+import org.apache.hadoop.hive.metastore.api.SQLPrimaryKey;\n+import org.apache.hadoop.hive.metastore.api.SQLUniqueConstraint;\n+import org.apache.hadoop.hive.ql.ErrorMsg;\n+import org.apache.hadoop.hive.ql.QueryState;\n+import org.apache.hadoop.hive.ql.ddl.DDLDesc.DDLDescWithWriteId;\n+import org.apache.hadoop.hive.ql.ddl.DDLWork;\n+import org.apache.hadoop.hive.ql.ddl.DDLSemanticAnalyzerFactory.DDLType;\n+import org.apache.hadoop.hive.ql.ddl.table.AbstractAlterTableAnalyzer;\n+import org.apache.hadoop.hive.ql.ddl.table.constraint.Constraints;\n+import org.apache.hadoop.hive.ql.ddl.table.constraint.ConstraintsUtils;\n+import org.apache.hadoop.hive.ql.ddl.table.partition.add.AlterTableAddPartitionDesc;\n+import org.apache.hadoop.hive.ql.exec.Task;\n+import org.apache.hadoop.hive.ql.exec.TaskFactory;\n+import org.apache.hadoop.hive.ql.metadata.Table;\n+import org.apache.hadoop.hive.ql.parse.ASTNode;\n+import org.apache.hadoop.hive.ql.parse.HiveParser;\n+import org.apache.hadoop.hive.ql.parse.SemanticException;\n+\n+/**\n+ * Analyzer for add constraint commands.\n+ */\n+public abstract class AbstractAddConstraintAnalyzer extends AbstractAlterTableAnalyzer {", "originalCommit": "261a8f822ac2260970dd70a5394d8d087e70f37a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU3NjAwNw==", "url": "https://github.com/apache/hive/pull/1737#discussion_r539576007", "bodyText": "That is just to be consistent with how it's done in other similar classes.", "author": "kishendas", "createdAt": "2020-12-09T19:14:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTE3NjI1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTc3NDIwNQ==", "url": "https://github.com/apache/hive/pull/1737#discussion_r539774205", "bodyText": "In other cases there are abstract classes because there are multiple classes extending them, and the common parts are moved to their abstract ancestor. Here there is no reason to do that.", "author": "miklosgergely", "createdAt": "2020-12-10T01:29:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTE3NjI1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTgwMTM3OA==", "url": "https://github.com/apache/hive/pull/1737#discussion_r539801378", "bodyText": "I created a separate ticket for advancing the write ID during drop Constraint -> https://issues.apache.org/jira/browse/HIVE-24513 .  I have changed the abstract class name to \"AbstractConstraintAnalyzer\". AbstractDropConstraintAnalyzer would also have to extend it.", "author": "kishendas", "createdAt": "2020-12-10T02:41:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTE3NjI1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU0NjAyOQ==", "url": "https://github.com/apache/hive/pull/1737#discussion_r539546029", "bodyText": "Can we add the test for unique and check constraints as well for completeness?", "author": "vihangk1", "createdAt": "2020-12-09T18:29:20Z", "path": "ql/src/test/org/apache/hadoop/hive/ql/TestTxnCommands.java", "diffHunk": "@@ -378,6 +378,33 @@ private IMetaStoreClient prepareParallelTest(String tableName, int val)\n     return msClient;\n   }\n \n+  @Test\n+  public void testAddConstraintAdvancingWriteIds() throws Exception {\n+\n+    String tableName = \"constraints_table\";\n+    hiveConf.setBoolean(\"hive.stats.autogather\", true);\n+    hiveConf.setBoolean(\"hive.stats.column.autogather\", true);\n+    // Need to close the thread local Hive object so that configuration change is reflected to HMS.\n+    Hive.closeCurrent();\n+    runStatementOnDriver(\"drop table if exists \" + tableName);\n+    runStatementOnDriver(String.format(\"create table %s (a int, b string) stored as orc \" +\n+        \"TBLPROPERTIES ('transactional'='true', 'transactional_properties'='insert_only')\",\n+        tableName));\n+    runStatementOnDriver(String.format(\"insert into %s (a) values (0)\", tableName));\n+    IMetaStoreClient msClient = new HiveMetaStoreClient(hiveConf);\n+    String validWriteIds = msClient.getValidWriteIds(\"default.\" + tableName).toString();\n+    LOG.info(\"ValidWriteIds before add constraint::\"+ validWriteIds);\n+    Assert.assertEquals(\"default.constraints_table:1:9223372036854775807::\", validWriteIds);\n+    runStatementOnDriver(String.format(\"alter table %s  ADD CONSTRAINT a_PK PRIMARY KEY (`a`) DISABLE NOVALIDATE\", tableName));\n+    validWriteIds  = msClient.getValidWriteIds(\"default.\" + tableName).toString();\n+    LOG.info(\"ValidWriteIds after add constraint primary key::\"+ validWriteIds);\n+    Assert.assertEquals(\"default.constraints_table:2:9223372036854775807::\", validWriteIds);\n+    runStatementOnDriver(String.format(\"alter table %s CHANGE COLUMN b b STRING NOT NULL\", tableName));\n+    validWriteIds  = msClient.getValidWriteIds(\"default.\" + tableName).toString();", "originalCommit": "261a8f822ac2260970dd70a5394d8d087e70f37a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcyMzY3Mw==", "url": "https://github.com/apache/hive/pull/1737#discussion_r539723673", "bodyText": "Added unique and check constraints. Please review.", "author": "kishendas", "createdAt": "2020-12-09T23:24:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU0NjAyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTM2MjA3NQ==", "url": "https://github.com/apache/hive/pull/1737#discussion_r541362075", "bodyText": "Thanks. Looks good!", "author": "vihangk1", "createdAt": "2020-12-11T22:25:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU0NjAyOQ=="}], "type": "inlineReview"}, {"oid": "914b9d17ea24c345048f4e8473cbfbea4f97c671", "url": "https://github.com/apache/hive/commit/914b9d17ea24c345048f4e8473cbfbea4f97c671", "message": "Add more tests", "committedDate": "2020-12-09T23:23:58Z", "type": "commit"}, {"oid": "0dc3c33169befaf12e83265f203765b13f3e4cbd", "url": "https://github.com/apache/hive/commit/0dc3c33169befaf12e83265f203765b13f3e4cbd", "message": "Modify class name", "committedDate": "2020-12-10T02:36:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NDQwMA==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540074400", "bodyText": "No need to modify the indentation of this annotation", "author": "miklosgergely", "createdAt": "2020-12-10T10:59:36Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/add/AlterTableAddConstraintAnalyzer.java", "diffHunk": "@@ -43,12 +48,12 @@\n  * Analyzer for add constraint commands.\n  */\n @DDLType(types = HiveParser.TOK_ALTERTABLE_ADDCONSTRAINT)\n-public class AlterTableAddConstraintAnalyzer extends AbstractAlterTableAnalyzer {\n+public class AlterTableAddConstraintAnalyzer extends AbstractConstraintAnalyzer {\n   public AlterTableAddConstraintAnalyzer(QueryState queryState) throws SemanticException {\n     super(queryState);\n   }\n \n-  @Override\n+    @Override", "originalCommit": "0dc3c33169befaf12e83265f203765b13f3e4cbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ0NjE1Ng==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540446156", "bodyText": "Done", "author": "kishendas", "createdAt": "2020-12-10T19:41:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NDQwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NDc2OQ==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540074769", "bodyText": "According to the Hive checkstyle, the max line length is 120, please format the code according to that.", "author": "miklosgergely", "createdAt": "2020-12-10T11:00:14Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/add/AlterTableAddConstraintAnalyzer.java", "diffHunk": "@@ -77,9 +82,23 @@ protected void analyzeCommand(TableName tableName, Map<String, String> partition\n       throw new SemanticException(ErrorMsg.NOT_RECOGNIZED_CONSTRAINT.getMsg(constraintNode.getToken().getText()));\n     }\n \n-    Constraints constraints = new Constraints(primaryKeys, foreignKeys, null, uniqueConstraints, null,", "originalCommit": "0dc3c33169befaf12e83265f203765b13f3e4cbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQyMDk5NQ==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540420995", "bodyText": "Don't see any line more than 90 in this class.", "author": "kishendas", "createdAt": "2020-12-10T19:00:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NDc2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ2OTQ3Mw==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540469473", "bodyText": "True, but I don't see the reason for this very change here, where you broke a line that was not longer than 120", "author": "miklosgergely", "createdAt": "2020-12-10T20:19:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NDc2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUyNDYyNQ==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540524625", "bodyText": "My formatter uses 90. Will undo this change.", "author": "kishendas", "createdAt": "2020-12-10T21:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NDc2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NTY5Mg==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540075692", "bodyText": "As this class will be extended by both the add and drop constraint analyzer, it should be in the org.apache.hadoop.hive.ql.ddl.table.constraint package.", "author": "miklosgergely", "createdAt": "2020-12-10T11:01:37Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/add/AbstractConstraintAnalyzer.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.ddl.table.constraint.add;", "originalCommit": "0dc3c33169befaf12e83265f203765b13f3e4cbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQyMDMyNA==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540420324", "bodyText": "Makes sense", "author": "kishendas", "createdAt": "2020-12-10T18:59:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDA3NTY5Mg=="}], "type": "inlineReview"}, {"oid": "22b5539518a8ad7c29ddd1bcf98ac72339f0dc6a", "url": "https://github.com/apache/hive/commit/22b5539518a8ad7c29ddd1bcf98ac72339f0dc6a", "message": "Address Miklos feedback", "committedDate": "2020-12-10T19:39:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ3MjIwNg==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540472206", "bodyText": "Actually I don't see anything constraint specific in this class. I'd suggest to just add the ddlDescWithWriteId and it's getter and setter to the AbstractAlterTableAnalyzer.", "author": "miklosgergely", "createdAt": "2020-12-10T20:24:20Z", "path": "ql/src/java/org/apache/hadoop/hive/ql/ddl/table/constraint/AbstractConstraintAnalyzer.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.hive.ql.ddl.table.constraint;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hive.common.TableName;\n+import org.apache.hadoop.hive.metastore.api.SQLCheckConstraint;\n+import org.apache.hadoop.hive.metastore.api.SQLForeignKey;\n+import org.apache.hadoop.hive.metastore.api.SQLPrimaryKey;\n+import org.apache.hadoop.hive.metastore.api.SQLUniqueConstraint;\n+import org.apache.hadoop.hive.ql.ErrorMsg;\n+import org.apache.hadoop.hive.ql.QueryState;\n+import org.apache.hadoop.hive.ql.ddl.DDLDesc.DDLDescWithWriteId;\n+import org.apache.hadoop.hive.ql.ddl.DDLWork;\n+import org.apache.hadoop.hive.ql.ddl.DDLSemanticAnalyzerFactory.DDLType;\n+import org.apache.hadoop.hive.ql.ddl.table.AbstractAlterTableAnalyzer;\n+import org.apache.hadoop.hive.ql.ddl.table.constraint.Constraints;\n+import org.apache.hadoop.hive.ql.ddl.table.constraint.ConstraintsUtils;\n+import org.apache.hadoop.hive.ql.ddl.table.partition.add.AlterTableAddPartitionDesc;\n+import org.apache.hadoop.hive.ql.exec.Task;\n+import org.apache.hadoop.hive.ql.exec.TaskFactory;\n+import org.apache.hadoop.hive.ql.metadata.Table;\n+import org.apache.hadoop.hive.ql.parse.ASTNode;\n+import org.apache.hadoop.hive.ql.parse.HiveParser;\n+import org.apache.hadoop.hive.ql.parse.SemanticException;\n+\n+/**\n+ * Analyzer for add constraint commands.\n+ */\n+public abstract class AbstractConstraintAnalyzer extends AbstractAlterTableAnalyzer {\n+  public AbstractConstraintAnalyzer(QueryState queryState) throws SemanticException {", "originalCommit": "22b5539518a8ad7c29ddd1bcf98ac72339f0dc6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ3OTgwMg==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540479802", "bodyText": "No need for that, AbstractAlterTableAnalyzer extends AbstractBaseAlterTableAnalyzer which already has the very same thing in it.", "author": "miklosgergely", "createdAt": "2020-12-10T20:37:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ3MjIwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ4NDk5Mw==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540484993", "bodyText": "So in conclusion I don't think that you need this class at all, just call setAcidDdlDesc at the end of the analyzeCommand in AlterTableAddConstraintAnalyzer, if it is a transactional table.", "author": "miklosgergely", "createdAt": "2020-12-10T20:46:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ3MjIwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUyNTkyOA==", "url": "https://github.com/apache/hive/pull/1737#discussion_r540525928", "bodyText": "Great catch ! Thank you.", "author": "kishendas", "createdAt": "2020-12-10T21:56:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDQ3MjIwNg=="}], "type": "inlineReview"}, {"oid": "037f971687a7091d98a1b4792f80cdc451cb6357", "url": "https://github.com/apache/hive/commit/037f971687a7091d98a1b4792f80cdc451cb6357", "message": "Address Miklos feedback", "committedDate": "2020-12-10T22:43:05Z", "type": "commit"}]}