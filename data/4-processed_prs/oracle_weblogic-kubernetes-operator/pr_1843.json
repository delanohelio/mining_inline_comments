{"pr_number": 1843, "pr_title": "Changed release tag for WDT releases", "pr_createdAt": "2020-07-31T14:35:18Z", "pr_url": "https://github.com/oracle/weblogic-kubernetes-operator/pull/1843", "timeline": [{"oid": "f13ab2e369955394eb412f31b8b5a4c6146bb571", "url": "https://github.com/oracle/weblogic-kubernetes-operator/commit/f13ab2e369955394eb412f31b8b5a4c6146bb571", "message": "changed WDT release URL for latest release", "committedDate": "2020-07-31T14:32:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTA1Nzk3OQ==", "url": "https://github.com/oracle/weblogic-kubernetes-operator/pull/1843#discussion_r465057979", "bodyText": "Was it intentional to update the documentation for earlier releases? (I'm not opposed; it's just not obvious that it was intentional). Also, I'm having a hard time finding the actual diff.", "author": "rjeberhard", "createdAt": "2020-08-04T13:41:19Z", "path": "docs/2.5.0/index.json", "diffHunk": "@@ -410,7 +410,7 @@\n \t\"title\": \"Model in image\",\n \t\"tags\": [],\n \t\"description\": \"Sample for supplying a WebLogic Deploy Tooling (WDT) model that the operator expands into a full domain home during runtime.\",\n-\t\"content\": \" This feature is supported only in 3.0.0-rc1.\\n Contents  Introduction  Model in Image domain types (WLS, JRF, and Restricted JRF) Use cases Sample directory structure   Prerequisites for all domain types Additional prerequisites for JRF domains Initial use case: An initial WebLogic domain Update1 use case: Dynamically adding a data source using a model ConfigMap Cleanup References  Introduction This sample demonstrates deploying a Model in Image domain home source type. Unlike Domain in PV and Domain in Image, Model in Image eliminates the need to pre-create your WebLogic domain home prior to deploying your domain resource. Instead, Model in Image uses a WebLogic Deploy Tooling (WDT) model to specify your WebLogic configuration.\\nWDT models are a convenient and simple alternative to WebLogic WLST configuration scripts and templates. They compactly define a WebLogic domain using YAML files and support including application archives in a ZIP file. The WDT model format is described in the open source, WebLogic Deploy Tooling GitHub project, and the required directory structure for a WDT archive is specifically discussed here.\\nFor more information on Model in Image, see the Model in Image user guide. For a comparison of Model in Image to other domain home source types, see Choose a domain home source type.\\nModel in Image domain types (WLS, JRF, and Restricted JRF) There are three types of domains supported by Model in Image: a standard WLS domain, an Oracle Fusion Middleware Infrastructure Java Required Files (JRF) domain, and a RestrictedJRF domain. This sample demonstrates the WLS and JRF types.\\nThe JRF domain path through the sample includes additional steps required for JRF: deploying an infrastructure database, initializing the database using the Repository Creation Utility (RCU) tool, referencing the infrastructure database from the WebLogic configuration, setting an Oracle Platform Security Services (OPSS) wallet password, and exporting/importing an OPSS wallet file. JRF domains may be used by Oracle products that layer on top of WebLogic Server, such as SOA and OSB. Similarly, RestrictedJRF domains may be used by Oracle layered products, such as Oracle Communications products.\\nUse cases This sample demonstrates two Model in Image use cases:\\n  Initial: An initial WebLogic domain with the following characteristics:\\n Image model-in-image:WLS-v1 with:  A WebLogic installation A WebLogic Deploy Tooling (WDT) installation A WDT archive with version v1 of an exploded Java EE web application A WDT model with:  A WebLogic Administration Server A WebLogic cluster A reference to the web application     Kubernetes Secrets:  WebLogic credentials Required WDT runtime password   A domain resource with:  spec.domainHomeSourceType: FromModel spec.image: model-in-image:WLS-v1 References to the secrets      Update1: Demonstrates udpating the initial domain by dynamically adding a data source using a model ConfigMap:\\n Image model-in-image:WLS-v1:  Same image as Initial use case   Kubernetes Secrets:  Same as Initial use case plus secrets for data source credentials and URL   Kubernetes ConfigMap with:  A WDT model for a data source targeted to the cluster   A domain resource with:  Same as Initial use case plus:  spec.model.configMap referencing the ConfigMap References to data source secrets        Sample directory structure The sample contains the following files and directories:\\n   Location Description     domain-resources JRF and WLS domain resources.   archives Source code location for WebLogic Deploy Tooling application ZIP archives.   model-images Staging for each model image\\u0026rsquo;s WDT YAML, WDT properties, and WDT archive ZIP files. The directories in model images are named for their respective images.   model-configmaps Staging files for a model ConfigMap that configures a data source.   ingresses Ingress resources.   utils/wl-pod-wait.sh Utility for watching the pods in a domain reach their expected restartVersion, image name, and ready state.   utils/patch-restart-version.sh Utility for updating a running domain spec.restartVersion field (which causes it to \\u0026lsquo;re-instrospect\\u0026rsquo; and \\u0026lsquo;roll\\u0026rsquo;).   utils/opss-wallet.sh Utility for exporting or importing a JRF domain OPSS wallet file.    Prerequisites for all domain types   Choose the type of domain you\\u0026rsquo;re going to use throughout the sample, WLS or JRF.\\n The first time you try this sample, we recommend that you choose WLS even if you\\u0026rsquo;re familiar with JRF. This is because WLS is simpler and will more easily familiarize you with Model in Image concepts. We recommend choosing JRF only if you are already familiar with JRF, you have already tried the WLS path through this sample, and you have a definite use case where you need to use JRF.    The JAVA_HOME environment variable must be set and must reference a valid JDK 8 or 11 installation.\\n  Get the operator source from the release/3.0.0-rc1 branch and put it in /tmp/operator-source.\\nFor example:\\n$ mkdir /tmp/operator-source $ cd /tmp/operator-source $ git clone https://github.com/oracle/weblogic-kubernetes-operator.git $ git checkout release/3.0.0-rc1  Note: We will refer to the top directory of the operator source tree as /tmp/operator-source; however, you can use a different location.\\n For additional information about obtaining the operator source, see the Developer Guide Requirements.\\n  Copy the sample to a new directory; for example, use directory /tmp/mii-sample.\\n$ mkdir /tmp/mii-sample $ cp -r /tmp/operator-source/kubernetes/samples/scripts/create-weblogic-domain/model-in-image/* /tmp/mii-sample  Note: We will refer to this working copy of the sample as /tmp/mii-sample; however, you can use a different location.     Make sure an operator is set up to manage namespace sample-domain1-ns. Also, make sure a Traefik ingress controller is managing the same namespace and listening on port 30305.\\nFor example, follow the same steps as the Quick Start guide from the beginning through to the Prepare for a domain step.\\nMake sure you stop when you complete the \\u0026ldquo;Prepare for a domain\\u0026rdquo; step and then resume following these instructions.\\n   Set up ingresses that will redirect HTTP from Traefik port 30305 to the clusters in this sample\\u0026rsquo;s WebLogic domains.\\n  Option 1: To create the ingresses, use the following YAML to create a file called /tmp/mii-sample/ingresses/myingresses.yaml and then call kubectl apply -f /tmp/mii-sample/ingresses/myingresses.yaml:\\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress-sample-domain1-admin-server namespace: sample-domain1-ns labels: weblogic.domainUID: sample-domain1 annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: http: paths: - path: /console backend: serviceName: sample-domain1-admin-server servicePort: 7001 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress-sample-domain1-cluster-cluster-1 namespace: sample-domain1-ns labels: weblogic.domainUID: sample-domain1 annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: sample-domain1-cluster-cluster-1.mii-sample.org http: paths: - path: backend: serviceName: sample-domain1-cluster-cluster-1 servicePort: 8001 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress-sample-domain1-cluster-cluster-2 namespace: sample-domain1-ns labels: weblogic.domainUID: sample-domain1 annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: sample-domain1-cluster-cluster-2.mii-sample.org http: paths: - path: backend: serviceName: sample-domain1-cluster-cluster-2 servicePort: 8001 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress-sample-domain2-cluster-cluster-1 namespace: sample-domain1-ns labels: weblogic.domainUID: sample-domain2 annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: sample-domain2-cluster-cluster-1.mii-sample.org http: paths: - path: backend: serviceName: sample-domain2-cluster-cluster-1 servicePort: 8001   Option 2: Run kubectl apply -f on each of the ingress YAML files that are already included in the sample source /tmp/mii-sample/ingresses directory:\\n  $ cd /tmp/mii-sample/ingresses $ kubectl apply -f traefik-ingress-sample-domain1-admin-server.yaml $ kubectl apply -f traefik-ingress-sample-domain1-cluster-cluster-1.yaml $ kubectl apply -f traefik-ingress-sample-domain1-cluster-cluster-2.yaml $ kubectl apply -f traefik-ingress-sample-domain2-cluster-cluster-1.yaml $ kubectl apply -f traefik-ingress-sample-domain2-cluster-cluster-2.yaml  NOTE: We give each cluster ingress a different host name that is decorated using both its operator domain UID and its cluster name. This makes each cluster uniquely addressable even when cluster names are the same across different clusters. When using curl to access the WebLogic domain through the ingress, you will need to supply a host name header that matches the host names in the ingress.\\n For more on information ingresses and load balancers, see Ingress.\\n  Obtain the WebLogic 12.2.1.4 image that is required to create the sample\\u0026rsquo;s model images.\\na. Use a browser to access Oracle Container Registry.\\nb. Choose an image location: for JRF domains, select Middleware, then fmw-infrastructure; for WLS domains, select Middleware, then weblogic.\\nc. Select Sign In and accept the license agreement.\\nd. Use your terminal to log in to Docker locally: docker login container-registry.oracle.com.\\ne. Later in this sample, when you run WebLogic Image Tool commands, the tool will use the image as a base image for creating model images. Specifically, the tool will implicitly call docker pull for one of the above licensed images as specified in the tool\\u0026rsquo;s command line using the --fromImage parameter. For JRF, this sample specifies container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4, and for WLS, the sample specifies container-registry.oracle.com/middleware/weblogic:12.2.1.4.\\nIf you prefer, you can create your own base image and then substitute this image name in the WebLogic Image Tool --fromImage parameter throughout this sample. See Preparing a Base Image.\\n   Download the latest WebLogic Deploying Tooling and WebLogic Image Tool installer ZIP files to your /tmp/mii-sample/model-images directory.\\nBoth WDT and WIT are required to create your Model in Image Docker images. Download the latest version of each tool\\u0026rsquo;s installer ZIP file to the /tmp/mii-sample/model-images directory.\\nFor example, visit the GitHub WebLogic Deploy Tooling Releses and WebLogic Image Tool Releases web pages to determine the latest release version for each, and then, assuming the version numbers are 1.8.0 and 1.8.4 respectively, call:\\n$ curl -m 30 -fL https://github.com/oracle/weblogic-deploy-tooling/releases/download/weblogic-deploy-tooling-1.8.0/weblogic-deploy.zip \\\\ -o /tmp/mii-sample/model-images/weblogic-deploy.zip $ curl -m 30 -fL https://github.com/oracle/weblogic-image-tool/releases/download/release-1.8.4/imagetool.zip \\\\ -o /tmp/mii-sample/model-images/imagetool.zip   Set up the WebLogic Image Tool.\\nRun the following commands:\\n$ cd /tmp/mii-sample/model-images $ unzip imagetool.zip $ ./imagetool/bin/imagetool.sh cache addInstaller \\\\ --type wdt \\\\ --version latest \\\\ --path /tmp/mii-sample/model-images/weblogic-deploy.zip These steps will install WIT to the /tmp/mii-sample/model-images/imagetool directory, plus put a wdt_latest entry in the tool\\u0026rsquo;s cache which points to the WDT ZIP installer. We will use WIT later in the sample for creating model images.\\n  Additional prerequisites for JRF domains  NOTE: If you\\u0026rsquo;re using a WLS domain type, skip this section and continue here.\\n JRF Prerequisites Contents  Introduction to JRF setups Set up and initialize an infrastructure database Increase introspection job timeout Important considerations for RCU model attributes, domain resource attributes, and secrets  Introduction to JRF setups  NOTE: The requirements in this section are in addition to Prerequisites for all domain types.\\n A JRF domain requires an infrastructure database, initializing this database with RCU, and configuring your domain to access this database. All of these steps must occur before you create your domain.\\nSet up and initialize an infrastructure database A JRF domain requires an infrastructure database and also requires initializing this database with a schema and a set of tables. The following example shows how to set up a database and use the RCU tool to create the infrastructure schema for a JRF domain. The database is set up with the following attributes:\\n   Attribute Value     database Kubernetes namespace default   database Kubernetes pod oracle-db   database image container-registry.oracle.com/database/enterprise:12.2.0.1-slim   database password Oradoc_db1   infrastructure schema prefix FMW1   infrastructure schema password Oradoc_db1   database URL oracle-db.default.svc.cluster.local:1521/devpdb.k8s      Ensure that you have access to the database image, and then create a deployment using it:\\n  Use a browser to log in to https://container-registry.oracle.com, select database-\\u0026gt;enterprise and accept the license agreement.\\n  Get the database image:\\n In the local shell, docker login container-registry.oracle.com. In the local shell, docker pull container-registry.oracle.com/database/enterprise:12.2.0.1-slim.    Use the sample script in /tmp/operator-source/kubernetes/samples/scripts/create-oracle-db-service to create an Oracle database running in the pod, oracle-db.\\n$ cd /tmp/operator-source/kubernetes/samples/scripts/create-oracle-db-service $ start-db-service.sh This script will deploy a database in the default namespace with the connect string oracle-db.default.svc.cluster.local:1521/devpdb.k8s, and administration password Oradoc_db1.\\nThis step is based on the steps documented in Run a Database.\\nWARNING: The Oracle Database Docker images are supported only for non-production use. For more details, see My Oracle Support note: Oracle Support for Database Running on Docker (Doc ID 2216342.1).\\n    Use the sample script in /tmp/operator-source/kubernetes/samples/scripts/create-rcu-schema to create the RCU schema with the schema prefix FMW1.\\nNote that this script assumes Oradoc_db1 is the DBA password, Oradoc_db1 is the schema password, and that the database URL is oracle-db.default.svc.cluster.local:1521/devpdb.k8s.\\n$ cd /tmp/operator-source/kubernetes/samples/scripts/create-rcu-schema $ ./create-rcu-schema.sh -s FMW1 -i container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4 NOTE: If you need to drop the repository, use this command:\\n$ drop-rcu-schema.sh -s FMW1   Increase introspection job timeout The JRF domain home creation can take more time than the introspection job\\u0026rsquo;s default timeout. You should increase the timeout for the introspection job. Use the configuration.introspectorJobActiveDeadlineSeconds in your domain resource to override the default with a value of at least 300 seconds (the default is 120 seconds). Note that the JRF versions of the domain resource files that are provided in /tmp/mii-sample/domain-resources already set this value.\\nImportant considerations for RCU model attributes, domain resource attributes, and secrets To allow Model in Image to access the database and OPSS wallet, you must create an RCU access secret containing the database connect string, user name, and password that\\u0026rsquo;s referenced from your model and an OPSS wallet password secret that\\u0026rsquo;s referenced from your domain resource before deploying your domain. It\\u0026rsquo;s also necessary to define an RCUDbInfo stanza in your model.\\nThe sample includes examples of JRF models and domain resources in the /tmp/mii-sample/model-images and /tmp/mii-sample/domain-resources directories, and instructions in the following sections will describe setting up the RCU and OPSS secrets.\\nWhen you follow the instructions later in this sample, avoid instructions that are WLS only, and substitute JRF for WLS in the corresponding model image tags and domain resource file names.\\nFor example:\\n  JRF domain resources in this sample have an opss.walletPasswordSecret field that references a secret named sample-domain1-opss-wallet-password-secret, with password=welcome1.\\n  JRF image models in this sample have a domainInfo -\\u0026gt; RCUDbInfo stanza that reference a sample-domain1-rcu-access secret with appropriate values for attributes rcu_prefix, rcu_schema_password, and rcu_db_conn_string for accessing the Oracle database that you deployed to the default namespace as one of the prerequisite steps.\\n  Important considerations for reusing or sharing OPSS tables We do not recommend that most users share OPSS tables. Extreme caution is required when sharing OPSS tables between domains.\\n When you successfully deploy your JRF domain resource for the first time, the introspector job will initialize the OPSS tables for the domain using the domainInfo -\\u0026gt; RCUDbInfo stanza in the WDT model plus the configuration.opss.walletPasswordSecret specified in the domain resource. The job will also create a new domain home. Finally, the operator will also capture an OPSS wallet file from the new domain\\u0026rsquo;s local directory and place this file in a new Kubernetes ConfigMap.\\nThere are scenarios when the domain needs to be recreated between updates, such as when WebLogic credentials are changed, security roles defined in the WDT model have been changed, or you want to share the same infrastructure tables with different domains. In these scenarios, the operator needs the walletPasswordSecret as well as the OPSS wallet file, together with the exact information in domainInfo -\\u0026gt; RCUDbInfo so that the domain can be recreated and access the same set of tables. Without the wallet file and wallet password, you will not be able to recreate a domain accessing the same set of tables, therefore we strongly recommend that you back up the wallet file.\\nTo recover a domain\\u0026rsquo;s OPSS tables between domain restarts or to share an OPSS schema between different domains, it is necessary to extract this wallet file from the domain\\u0026rsquo;s automatically deployed introspector ConfigMap and save the OPSS wallet password secret that was used for the original domain. The wallet password and wallet file are needed again when you recreate the domain or share the database with other domains.\\nTo save the wallet file, assuming that your namespace is sample-domain1-ns and your domain UID is sample-domain1:\\n $ kubectl -n sample-domain1-ns \\\\ get configmap sample-domain1-weblogic-domain-introspect-cm \\\\ -o jsonpath='{.data.ewallet\\\\.p12}' \\\\ \\u0026gt; ./ewallet.p12 Alternatively, you can save the file using the sample\\u0026rsquo;s wallet utility:\\n $ /tmp/mii-sample/utils/opss-wallet.sh -n sample-domain1-ns -d sample-domain1 -wf ./ewallet.p12 # For help: /tmp/mii-sample/utils/opss-wallet.sh -? Important! Back up your wallet file to a safe location that can be retrieved later.\\nTo reuse the wallet file in subsequent redeployments or to share the domain\\u0026rsquo;s OPSS tables between different domains:\\n Load the saved wallet file into a secret with a key named walletFile (again, assuming that your domain UID is sample-domain1 and your namespace is sample-domain1-ns):   $ kubectl -n sample-domain1-ns create secret generic sample-domain1-opss-walletfile-secret \\\\ --from-file=walletFile=./ewallet.p12 $ kubectl -n sample-domain1-ns label secret sample-domain1-opss-walletfile-secret \\\\ weblogic.domainUID=`sample-domain1` Alternatively, use the sample\\u0026rsquo;s wallet utility:\\n $ /tmp/mii-sample/utils/opss-wallet.sh -n sample-domain1-ns -d sample-domain1 -wf ./ewallet.p12 -ws sample-domain1-opss-walletfile-secret # For help: /tmp/mii-sample/utils/opss-wallet.sh -? Modify your domain resource JRF YAML files to provide the wallet file secret name, for example:   configuration: opss: # Name of secret with walletPassword for extracting the wallet walletPasswordSecret: sample-domain1-opss-wallet-password-secret # Name of secret with walletFile containing base64 encoded opss wallet walletFileSecret: sample-domain1-opss-walletfile-secret  Note: The sample JRF domain resource files included in /tmp/mii-sample/domain-resources already have the above YAML stanza.\\n Initial use case Contents  Overview Image creation  Image creation - Introduction Understanding our first archive Staging a ZIP file of the archive Staging model files Creating the image with WIT   Deploy resources  Deploy resources - Introduction Secrets Domain resource    Overview In this use case, we set up an initial WebLogic domain. This involves:\\n A WDT archive ZIP file that contains your applications. A WDT model that describes your WebLogic configuration. A Docker image that contains your WDT model files and archive. Creating secrets for the domain. Creating a domain resource for the domain that references your secrets and image.  After the domain resource is deployed, the WebLogic operator will start an \\u0026lsquo;introspector job\\u0026rsquo; that converts your models into a WebLogic configuration, and then the operator will pass this configuration to each WebLogic Server in the domain.\\nPerform the steps in Prerequisites for all domain types before performing the steps in this use case.\\nIf you are taking the JRF path through the sample, then substitute JRF for WLS in your image names and directory paths. Also note that the JRF-v1 model YAML differs from the WLS-v1 YAML file (it contains an additional domainInfo -\\u0026gt; RCUDbInfo stanza).\\n Image creation - Introduction The goal of the initial use case \\u0026lsquo;image creation\\u0026rsquo; is to demonstrate using the WebLogic Image Tool to create an image named model-in-image:WLS-v1 from files that we will stage to /tmp/mii-sample/model-images/model-in-image:WLS-v1/. The staged files will contain a web application in a WDT archive, and WDT model configuration for a WebLogic Administration Server called admin-server and a WebLogic cluster called cluster-1.\\nOverall, a Model in Image image must contain a WebLogic installation and also a WebLogic Deploy Tooling installation in its /u01/wdt/weblogic-deploy directory. In addition, if you have WDT model archive files, then the image must also contain these files in its /u01/wdt/models directory. Finally, an image may optionally also contain your WDT model YAML and properties files in the same /u01/wdt/models directory. If you do not specify WDT model YAML in your /u01/wdt/models directory, then the model YAML must be supplied dynamically using a Kubernetes ConfigMap that is referenced by your domain resource spec.model.configMap attribute. We will provide an example of using a model ConfigMap later in this sample.\\nLet\\u0026rsquo;s walk through the steps for creating the image model-in-image:WLS-v1:\\n Understanding our first archive Staging a ZIP file of the archive Staging model files Creating the image with WIT  Understanding our first archive The sample includes a predefined archive directory in /tmp/mii-sample/archives/archive-v1 that we will use to create an archive ZIP file for the image.\\nThe archive top directory, named wlsdeploy, contains a directory named applications, which includes an \\u0026lsquo;exploded\\u0026rsquo; sample JSP web application in the directory, myapp-v1. Three useful aspects to remember about WDT archives are:\\n A model image can contain multiple WDT archives. WDT archives can contain multiple applications, libraries, and other components. WDT archives have a well defined directory structure, which always has wlsdeploy as the top directory.    If you are interested in the web application source, click here to see the JSP code.   \\u0026lt;%-- Copyright (c) 2019, 2020, Oracle Corporation and/or its affiliates. --%\\u0026gt; \\u0026lt;%-- Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. --%\\u0026gt; \\u0026lt;%@ page import=\\u0026quot;javax.naming.InitialContext\\u0026quot; %\\u0026gt; \\u0026lt;%@ page import=\\u0026quot;javax.management.*\\u0026quot; %\\u0026gt; \\u0026lt;%@ page import=\\u0026quot;java.io.*\\u0026quot; %\\u0026gt; \\u0026lt;% InitialContext ic = null; try { ic = new InitialContext(); String srName=System.getProperty(\\u0026quot;weblogic.Name\\u0026quot;); String domainUID=System.getenv(\\u0026quot;DOMAIN_UID\\u0026quot;); String domainName=System.getenv(\\u0026quot;CUSTOM_DOMAIN_NAME\\u0026quot;); out.println(\\u0026quot;\\u0026lt;html\\u0026gt;\\u0026lt;body\\u0026gt;\\u0026lt;pre\\u0026gt;\\u0026quot;); out.println(\\u0026quot;*****************************************************************\\u0026quot;); out.println(); out.println(\\u0026quot;Hello World! This is version 'v1' of the mii-sample JSP web-app.\\u0026quot;); out.println(); out.println(\\u0026quot;Welcome to WebLogic server '\\u0026quot; + srName + \\u0026quot;'!\\u0026quot;); out.println(); out.println(\\u0026quot; domain UID = '\\u0026quot; + domainUID +\\u0026quot;'\\u0026quot;); out.println(\\u0026quot; domain name = '\\u0026quot; + domainName +\\u0026quot;'\\u0026quot;); out.println(); MBeanServer mbs = (MBeanServer)ic.lookup(\\u0026quot;java:comp/env/jmx/runtime\\u0026quot;); // display the current server's cluster name Set\\u0026lt;ObjectInstance\\u0026gt; clusterRuntimes = mbs.queryMBeans(new ObjectName(\\u0026quot;*:Type=ClusterRuntime,*\\u0026quot;), null); out.println(\\u0026quot;Found \\u0026quot; + clusterRuntimes.size() + \\u0026quot; local cluster runtime\\u0026quot; + (String)((clusterRuntimes.size()!=1)?\\u0026quot;s:\\u0026quot;:\\u0026quot;:\\u0026quot;)); for (ObjectInstance clusterRuntime : clusterRuntimes) { String cName = (String)mbs.getAttribute(clusterRuntime.getObjectName(), \\u0026quot;Name\\u0026quot;); out.println(\\u0026quot; Cluster '\\u0026quot; + cName + \\u0026quot;'\\u0026quot;); } out.println(); // display local data sources ObjectName jdbcRuntime = new ObjectName(\\u0026quot;com.bea:ServerRuntime=\\u0026quot; + srName + \\u0026quot;,Name=\\u0026quot; + srName + \\u0026quot;,Type=JDBCServiceRuntime\\u0026quot;); ObjectName[] dataSources = (ObjectName[])mbs.getAttribute(jdbcRuntime, \\u0026quot;JDBCDataSourceRuntimeMBeans\\u0026quot;); out.println(\\u0026quot;Found \\u0026quot; + dataSources.length + \\u0026quot; local data source\\u0026quot; + (String)((dataSources.length!=1)?\\u0026quot;s:\\u0026quot;:\\u0026quot;:\\u0026quot;)); for (ObjectName dataSource : dataSources) { String dsName = (String)mbs.getAttribute(dataSource, \\u0026quot;Name\\u0026quot;); String dsState = (String)mbs.getAttribute(dataSource, \\u0026quot;State\\u0026quot;); out.println(\\u0026quot; Datasource '\\u0026quot; + dsName + \\u0026quot;': State='\\u0026quot; + dsState +\\u0026quot;'\\u0026quot;); } out.println(); out.println(\\u0026quot;*****************************************************************\\u0026quot;); } catch (Throwable t) { t.printStackTrace(new PrintStream(response.getOutputStream())); } finally { out.println(\\u0026quot;\\u0026lt;/pre\\u0026gt;\\u0026lt;/body\\u0026gt;\\u0026lt;/html\\u0026gt;\\u0026quot;); if (ic != null) ic.close(); } %\\u0026gt;    The application displays important details about the WebLogic Server that it\\u0026rsquo;s running on: namely its domain name, cluster name, and server name, as well as the names of any data sources that are targeted to the server. You can also see that application output reports that it\\u0026rsquo;s at version v1; we will update this to v2 in a future use case to demonstrate upgrading the application.\\nStaging a ZIP file of the archive When we create our image, we will use the files in staging directory /tmp/mii-sample/model-in-image__WLS-v1. In preparation, we need it to contain a ZIP file of the WDT application archive.\\nRun the following commands to create your application archive ZIP file and put it in the expected directory:\\n# Delete existing archive.zip in case we have an old leftover version $ rm -f /tmp/mii-sample/model-images/model-in-image__WLS-v1/archive.zip # Move to the directory which contains the source files for our archive $ cd /tmp/mii-sample/archives/archive-v1 # Zip the archive to the location will later use when we run the WebLogic Image Tool $ zip -r /tmp/mii-sample/model-images/model-in-image__WLS-v1/archive.zip wlsdeploy Staging model files In this step, we explore the staged WDT model YAML file and properties in directory /tmp/mii-sample/model-in-image__WLS-v1. The model in this directory references the web application in our archive, configures a WebLogic Administration Server, and configures a WebLogic cluster. It consists of only two files, model.10.properties, a file with a single property, and, model.10.yaml, a YAML file with our WebLogic configuration model.10.yaml.\\nCLUSTER_SIZE=5 Here is the WLS model.10.yaml:\\ndomainInfo: AdminUserName: '@@SECRET:__weblogic-credentials__:username@@' AdminPassword: '@@SECRET:__weblogic-credentials__:password@@' ServerStartMode: 'prod' topology: Name: '@@ENV:CUSTOM_DOMAIN_NAME@@' AdminServerName: 'admin-server' Cluster: 'cluster-1': DynamicServers: ServerTemplate: 'cluster-1-template' ServerNamePrefix: 'managed-server' DynamicClusterSize: '@@PROP:CLUSTER_SIZE@@' MaxDynamicClusterSize: '@@PROP:CLUSTER_SIZE@@' MinDynamicClusterSize: '0' CalculatedListenPorts: false Server: 'admin-server': ListenPort: 7001 ServerTemplate: 'cluster-1-template': Cluster: 'cluster-1' ListenPort: 8001 appDeployments: Application: myapp: SourcePath: 'wlsdeploy/applications/myapp-v1' ModuleType: ear Target: 'cluster-1'    Click here to expand the JRF `model.10.yaml`, and note the RCUDbInfo stanza and its references to a DOMAIN_UID-rcu-access secret.   domainInfo: AdminUserName: '@@SECRET:__weblogic-credentials__:username@@' AdminPassword: '@@SECRET:__weblogic-credentials__:password@@' ServerStartMode: 'prod' RCUDbInfo: rcu_prefix: '@@SECRET:@@ENV:DOMAIN_UID@@-rcu-access:rcu_prefix@@' rcu_schema_password: '@@SECRET:@@ENV:DOMAIN_UID@@-rcu-access:rcu_schema_password@@' rcu_db_conn_string: '@@SECRET:@@ENV:DOMAIN_UID@@-rcu-access:rcu_db_conn_string@@' topology: AdminServerName: 'admin-server' Name: '@@ENV:CUSTOM_DOMAIN_NAME@@' Cluster: 'cluster-1': Server: 'admin-server': ListenPort: 7001 'managed-server1-c1-': Cluster: 'cluster-1' ListenPort: 8001 'managed-server2-c1-': Cluster: 'cluster-1' ListenPort: 8001 'managed-server3-c1-': Cluster: 'cluster-1' ListenPort: 8001 'managed-server4-c1-': Cluster: 'cluster-1' ListenPort: 8001 appDeployments: Application: myapp: SourcePath: 'wlsdeploy/applications/myapp-v1' ModuleType: ear Target: 'cluster-1'    The model files:\\n  Define a WebLogic domain with:\\n Cluster cluster-1 Administration Server admin-server A cluster-1 targeted ear application that\\u0026rsquo;s located in the WDT archive ZIP file at wlsdeploy/applications/myapp-v1    Leverage macros to inject external values:\\n The property file CLUSTER_SIZE property is referenced in the model YAML DynamicClusterSize and MaxDynamicClusterSize fields using a PROP macro. The model file domain name is injected using a custom environment variable named CUSTOM_DOMAIN_NAME using an ENV macro.  We set this environment variable later in this sample using an env field in its domain resource. This conveniently provides a simple way to deploy multiple differently named domains using the same model image.   The model file administrator user name and password are set using a weblogic-credentials secret macro reference to the WebLogic credential secret.  This secret is in turn referenced using the weblogicCredentialsSecret field in the domain resource. The weblogic-credentials is a reserved name that always dereferences to the owning domain resource actual WebLogic credentials secret name.      A Model in Image image can contain multiple properties files, archive ZIP files, and YAML files, but in this sample we use just one of each. For a full discussion of Model in Images model file naming conventions, file loading order, and macro syntax, see Model files in the Model in Image user documentation.\\nCreating the image with WIT  Note: If you are using JRF in this sample, substitute JRF for each occurrence of WLS in the imagetool command line below, plus substitute container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4 for the --fromImage value.\\n At this point, we have staged all of the files needed for image model-in-image:WLS-v1, they include:\\n /tmp/mii-sample/model-images/weblogic-deploy.zip /tmp/mii-sample/model-images/model-in-image__WLS-v1/model.10.yaml /tmp/mii-sample/model-images/model-in-image__WLS-v1/model.10.properties /tmp/mii-sample/model-images/model-in-image__WLS-v1/archive.zip  If you don\\u0026rsquo;t see the weblogic-deploy.zip file, then it means that you missed a step in the prerequisites.\\nNow let\\u0026rsquo;s use the Image Tool to create an image named model-in-image:WLS-v1 that\\u0026rsquo;s layered on a base WebLogic image. We\\u0026rsquo;ve already set up this tool during the prerequisite steps at the beginning of this sample.\\nRun the following commands to create the model image and verify that it worked:\\n$ cd /tmp/mii-sample/model-images $ ./imagetool/bin/imagetool.sh update \\\\ --tag model-in-image:WLS-v1 \\\\ --fromImage container-registry.oracle.com/middleware/weblogic:12.2.1.4 \\\\ --wdtModel ./model-in-image__WLS-v1/model.10.yaml \\\\ --wdtVariables ./model-in-image__WLS-v1/model.10.properties \\\\ --wdtArchive ./model-in-image__WLS-v1/archive.zip \\\\ --wdtModelOnly \\\\ --wdtDomainType WLS If you don\\u0026rsquo;t see the imagetool directory, then it means that you missed a step in the prerequisites.\\nThis command runs the WebLogic Image Tool in its Model in Image mode, and does the following:\\n Builds the final Docker image as a layer on the container-registry.oracle.com/middleware/weblogic:12.2.1.4 base image. Copies the WDT ZIP file that\\u0026rsquo;s referenced in the WIT cache into the image.  Note that we cached WDT in WIT using the keyword latest when we set up the cache during the sample prerequisites steps. This lets WIT implicitly assume its the desired WDT version and removes the need to pass a -wdtVersion flag.   Copies the specified WDT model, properties, and application archives to image location /u01/wdt/models.  When the command succeeds, it should end with output like:\\n[INFO ] Build successful. Build time=36s. Image tag=model-in-image:WLS-v1 Also, if you run the docker images command, then you should see a Docker image named model-in-image:WLS-v1.\\nDeploy resources - Introduction In this section we will deploy our new image to namespace sample-domain1-ns, including the following steps:\\n Create a secret containing your WebLogic administrator user name and password. Create a secret containing your Model in Image runtime encryption password:  All Model in Image domains must supply a runtime encryption secret with a password value. It is used to encrypt configuration that is passed around internally by the operator. The value must be kept private but can be arbitrary; you can optionally supply a different secret value every time you restart the domain.   If your domain type is JRF, create secrets containing your RCU access URL, credentials, and prefix. Deploy a domain resource YAML file that references the new image. Wait for the domain\\u0026rsquo;s pods to start and reach their ready state.  Secrets First, create the secrets needed by both WLS and JRF type model domains. In this case, we have two secrets.\\nRun the following kubectl commands to deploy the required secrets:\\n$ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-weblogic-credentials \\\\ --from-literal=username=weblogic --from-literal=password=welcome1 $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-weblogic-credentials \\\\ weblogic.domainUID=sample-domain1 $ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-runtime-encryption-secret \\\\ --from-literal=password=my_runtime_password $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-runtime-encryption-secret \\\\ weblogic.domainUID=sample-domain1 Some important details about these secrets:\\n  The WebLogic credentials secret:\\n It is required and must contain username and password fields. It must be referenced by the spec.weblogicCredentialsSecret field in your domain resource. It also must be referenced by macros in the domainInfo.AdminUserName and domainInfo.AdminPassWord fields in your model YAML file.    The Model WDT runtime secret:\\n This is a special secret required by Model in Image. It must contain a password field. It must be referenced using the spec.model.runtimeEncryptionSecret attribute in its domain resource. It must remain the same for as long as the domain is deployed to Kubernetes, but can be changed between deployments. It is used to encrypt data as it\\u0026rsquo;s internally passed using log files from the domain\\u0026rsquo;s introspector job and on to its WebLogic Server pods.    Deleting and recreating the secrets:\\n We delete a secret before creating it, otherwise the create command will fail if the secret already exists. This allows us to change the secret when using the kubectl create secret command.    We name and label secrets using their associated domain UID for two reasons:\\n To make it obvious which secrets belong to which domains. To make it easier to clean up a domain. Typical cleanup scripts use the weblogic.domainUID label as a convenience for finding all resources associated with a domain.    If you\\u0026rsquo;re following the JRF path through the sample, then you also need to deploy the additional secret referenced by macros in the JRF model RCUDbInfo clause, plus an OPSS wallet password secret. For details about the uses of these secrets, see the Model in Image user documentation.\\n  Click here for the commands for deploying additional secrets for JRF.   $ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-rcu-access \\\\ --from-literal=rcu_prefix=FMW1 \\\\ --from-literal=rcu_schema_password=Oradoc_db1 \\\\ --from-literal=rcu_db_conn_string=oracle-db.default.svc.cluster.local:1521/devpdb.k8s $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-rcu-access \\\\ weblogic.domainUID=sample-domain1 $ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-opss-wallet-password-secret \\\\ --from-literal=walletPassword=welcome1 $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-opss-wallet-password-secret \\\\ weblogic.domainUID=sample-domain1    Domain resource Now let\\u0026rsquo;s create a domain resource. A domain resource is the key resource that tells the operator how to deploy a WebLogic domain.\\nCopy the following to a file called /tmp/mii-sample/mii-initial.yaml or similar, or use the file /tmp/mii-sample/domain-resources/WLS/mii-initial-d1-WLS-v1.yaml that is included in the sample source.\\n  Click here to expand the WLS domain resource YAML.    # # This is an example of how to define a Domain resource. # # If you are using 3.0.0-rc1, then the version on the following line # should be `v7` not `v6`. apiVersion: \\u0026quot;weblogic.oracle/v6\\u0026quot; kind: Domain metadata: name: sample-domain1 namespace: sample-domain1-ns labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: sample-domain1 spec: # Set to 'FromModel' to indicate 'Model in Image'. domainHomeSourceType: FromModel # The WebLogic Domain Home, this must be a location within # the image for 'Model in Image' domains. domainHome: /u01/domains/sample-domain1 # The WebLogic Server Docker image that the Operator uses to start the domain image: \\u0026quot;model-in-image:WLS-v1\\u0026quot; # Defaults to \\u0026quot;Always\\u0026quot; if image tag (version) is ':latest' imagePullPolicy: \\u0026quot;IfNotPresent\\u0026quot; # Identify which Secret contains the credentials for pulling an image #imagePullSecrets: #- name: regsecret # Identify which Secret contains the WebLogic Admin credentials, # the secret must contain 'username' and 'password' fields. webLogicCredentialsSecret: name: sample-domain1-weblogic-credentials # Whether to include the WebLogic server stdout in the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable overriding your log file location, see also 'logHome' #logHomeEnabled: false # The location for domain log, server logs, server out, and Node Manager log files # see also 'logHomeEnabled', 'volumes', and 'volumeMounts'. #logHome: /shared/logs/sample-domain1 # Set which WebLogic servers the Operator will start # - \\u0026quot;NEVER\\u0026quot; will not start any server in the domain # - \\u0026quot;ADMIN_ONLY\\u0026quot; will start up only the administration server (no managed servers will be started) # - \\u0026quot;IF_NEEDED\\u0026quot; will start all non-clustered servers, including the administration server, and clustered servers up to their replica count. serverStartPolicy: \\u0026quot;IF_NEEDED\\u0026quot; # Settings for all server pods in the domain including the introspector job pod serverPod: # Optional new or overridden environment variables for the domain's pods # - This sample uses CUSTOM_DOMAIN_NAME in its image model file # to set the Weblogic domain name env: - name: CUSTOM_DOMAIN_NAME value: \\u0026quot;domain1\\u0026quot; - name: JAVA_OPTIONS value: \\u0026quot;-Dweblogic.StdoutDebugEnabled=false\\u0026quot; - name: USER_MEM_ARGS value: \\u0026quot;-XX:+UseContainerSupport -Djava.security.egd=file:/dev/./urandom \\u0026quot; # Optional volumes and mounts for the domain's pods. See also 'logHome'. #volumes: #- name: weblogic-domain-storage-volume # persistentVolumeClaim: # claimName: sample-domain1-weblogic-sample-pvc #volumeMounts: #- mountPath: /shared # name: weblogic-domain-storage-volume # The desired behavior for starting the domain's administration server. adminServer: # The serverStartState legal values are \\u0026quot;RUNNING\\u0026quot; or \\u0026quot;ADMIN\\u0026quot; # \\u0026quot;RUNNING\\u0026quot; means the listed server will be started up to \\u0026quot;RUNNING\\u0026quot; mode # \\u0026quot;ADMIN\\u0026quot; means the listed server will be start up to \\u0026quot;ADMIN\\u0026quot; mode serverStartState: \\u0026quot;RUNNING\\u0026quot; # Setup a Kubernetes node port for the administration server default channel #adminService: # channels: # - channelName: default # nodePort: 30701 # The number of managed servers to start for unlisted clusters replicas: 1 # The desired behavior for starting a specific cluster's member servers clusters: - clusterName: cluster-1 serverStartState: \\u0026quot;RUNNING\\u0026quot; replicas: 2 # Change the `restartVersion` to force the introspector job to rerun # and apply any new model configuration, to also force a subsequent # roll of your domain's WebLogic pods. restartVersion: '1' configuration: # Settings for domainHomeSourceType 'FromModel' model: # Valid model domain types are 'WLS', 'JRF', and 'RestrictedJRF', default is 'WLS' domainType: \\u0026quot;WLS\\u0026quot; # Optional configmap for additional models and variable files #configMap: sample-domain1-wdt-config-map # All 'FromModel' domains require a runtimeEncryptionSecret with a 'password' field runtimeEncryptionSecret: sample-domain1-runtime-encryption-secret # Secrets that are referenced by model yaml macros # (the model yaml in the optional configMap or in the image) #secrets: #- sample-domain1-datasource-secret      Click here to expand the JRF domain resource YAML.   # Copyright (c) 2020, Oracle Corporation and/or its affiliates. # Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl. # # This is an example of how to define a Domain resource. # # If you are using 3.0.0-rc1, then the version on the following line # should be `v7` not `v6`. apiVersion: \\u0026quot;weblogic.oracle/v6\\u0026quot; kind: Domain metadata: name: sample-domain1 namespace: sample-domain1-ns labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: sample-domain1 spec: # Set to 'FromModel' to indicate 'Model in Image'. domainHomeSourceType: FromModel # The WebLogic Domain Home, this must be a location within # the image for 'Model in Image' domains. domainHome: /u01/domains/sample-domain1 # The WebLogic Server Docker image that the Operator uses to start the domain image: \\u0026quot;model-in-image:JRF-v1\\u0026quot; # Defaults to \\u0026quot;Always\\u0026quot; if image tag (version) is ':latest' imagePullPolicy: \\u0026quot;IfNotPresent\\u0026quot; # Identify which Secret contains the credentials for pulling an image #imagePullSecrets: #- name: regsecret # Identify which Secret contains the WebLogic Admin credentials, # the secret must contain 'username' and 'password' fields. webLogicCredentialsSecret: name: sample-domain1-weblogic-credentials # Whether to include the WebLogic server stdout in the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable overriding your log file location, see also 'logHome' #logHomeEnabled: false # The location for domain log, server logs, server out, and Node Manager log files # see also 'logHomeEnabled', 'volumes', and 'volumeMounts'. #logHome: /shared/logs/sample-domain1 # Set which WebLogic servers the Operator will start # - \\u0026quot;NEVER\\u0026quot; will not start any server in the domain # - \\u0026quot;ADMIN_ONLY\\u0026quot; will start up only the administration server (no managed servers will be started) # - \\u0026quot;IF_NEEDED\\u0026quot; will start all non-clustered servers, including the administration server, and clustered servers up to their replica count. serverStartPolicy: \\u0026quot;IF_NEEDED\\u0026quot; # Settings for all server pods in the domain including the introspector job pod serverPod: # Optional new or overridden environment variables for the domain's pods # - This sample uses CUSTOM_DOMAIN_NAME in its image model file # to set the Weblogic domain name env: - name: CUSTOM_DOMAIN_NAME value: \\u0026quot;domain1\\u0026quot; - name: JAVA_OPTIONS value: \\u0026quot;-Dweblogic.StdoutDebugEnabled=false\\u0026quot; - name: USER_MEM_ARGS value: \\u0026quot;-XX:+UseContainerSupport -Djava.security.egd=file:/dev/./urandom \\u0026quot; # Optional volumes and mounts for the domain's pods. See also 'logHome'. #volumes: #- name: weblogic-domain-storage-volume # persistentVolumeClaim: # claimName: sample-domain1-weblogic-sample-pvc #volumeMounts: #- mountPath: /shared # name: weblogic-domain-storage-volume # The desired behavior for starting the domain's administration server. adminServer: # The serverStartState legal values are \\u0026quot;RUNNING\\u0026quot; or \\u0026quot;ADMIN\\u0026quot; # \\u0026quot;RUNNING\\u0026quot; means the listed server will be started up to \\u0026quot;RUNNING\\u0026quot; mode # \\u0026quot;ADMIN\\u0026quot; means the listed server will be start up to \\u0026quot;ADMIN\\u0026quot; mode serverStartState: \\u0026quot;RUNNING\\u0026quot; # Setup a Kubernetes node port for the administration server default channel #adminService: # channels: # - channelName: default # nodePort: 30701 # The number of managed servers to start for unlisted clusters replicas: 1 # The desired behavior for starting a specific cluster's member servers clusters: - clusterName: cluster-1 serverStartState: \\u0026quot;RUNNING\\u0026quot; replicas: 2 # Change the restartVersion to force the introspector job to rerun # and apply any new model configuration, to also force a subsequent # roll of your domain's WebLogic pods. restartVersion: '1' configuration: # Settings for domainHomeSourceType 'FromModel' model: # Valid model domain types are 'WLS', 'JRF', and 'RestrictedJRF', default is 'WLS' domainType: \\u0026quot;JRF\\u0026quot; # Optional configmap for additional models and variable files #configMap: sample-domain1-wdt-config-map # All 'FromModel' domains require a runtimeEncryptionSecret with a 'password' field runtimeEncryptionSecret: sample-domain1-runtime-encryption-secret # Secrets that are referenced by model yaml macros # (the model yaml in the optional configMap or in the image) secrets: #- sample-domain1-datasource-secret - sample-domain1-rcu-access # Increase the introspector job active timeout value for JRF use cases introspectorJobActiveDeadlineSeconds: 300 opss: # Name of secret with walletPassword for extracting the wallet, used for JRF domains walletPasswordSecret: sample-domain1-opss-wallet-password-secret # Name of secret with walletFile containing base64 encoded opss wallet, used for JRF domains #walletFileSecret: sample-domain1-opss-walletfile-secret    Run the following command to create the domain custom resource:\\n$ kubectl apply -f /tmp/mii-sample/domain-resources/WLS/mii-initial-d1-WLS-v1.yaml  Note: If you are choosing not to use the predefined domain resource YAML file and instead created your own domain resource file earlier, then substitute your custom file name in the above command. You might recall that we suggested naming it /tmp/mii-sample/mii-initial.yaml.\\n If you run kubectl get pods -n sample-domain1-ns --watch, then you should see the introspector job run and your WebLogic Server pods start. The output should look something like this:\\n  Click here to expand.   $ kubectl get pods -n sample-domain1-ns --watch NAME READY STATUS RESTARTS AGE sample-domain1-introspect-domain-job-lqqj9 0/1 Pending 0 0s sample-domain1-introspect-domain-job-lqqj9 0/1 ContainerCreating 0 0s sample-domain1-introspect-domain-job-lqqj9 1/1 Running 0 1s sample-domain1-introspect-domain-job-lqqj9 0/1 Completed 0 65s sample-domain1-introspect-domain-job-lqqj9 0/1 Terminating 0 65s sample-domain1-admin-server 0/1 Pending 0 0s sample-domain1-admin-server 0/1 ContainerCreating 0 0s sample-domain1-admin-server 0/1 Running 0 1s sample-domain1-admin-server 1/1 Running 0 32s sample-domain1-managed-server1 0/1 Pending 0 0s sample-domain1-managed-server2 0/1 Pending 0 0s sample-domain1-managed-server1 0/1 ContainerCreating 0 0s sample-domain1-managed-server2 0/1 ContainerCreating 0 0s sample-domain1-managed-server1 0/1 Running 0 2s sample-domain1-managed-server2 0/1 Running 0 2s sample-domain1-managed-server1 1/1 Running 0 43s sample-domain1-managed-server2 1/1 Running 0 42s    Alternatively, you can run /tmp/mii-sample/utils/wl-pod-wait.sh -p 3. This is a utility script that provides useful information about a domain\\u0026rsquo;s pods and waits for them to reach a ready state, reach their target restartVersion, and reach their target image before exiting.\\n  Click here to expand the `wl-pod-wait.sh` usage.   $ ./wl-pod-wait.sh -? Usage: wl-pod-wait.sh [-n mynamespace] [-d mydomainuid] \\\\ [-p expected_pod_count] \\\\ [-t timeout_secs] \\\\ [-q] Exits non-zero if 'timeout_secs' is reached before 'pod_count' is reached. Parameters: -d \\u0026lt;domain_uid\\u0026gt; : Defaults to 'sample-domain1'. -n \\u0026lt;namespace\\u0026gt; : Defaults to 'sample-domain1-ns'. pod_count \\u0026gt; 0 : Wait until exactly 'pod_count' WebLogic server pods for a domain all (a) are ready, (b) have the same 'domainRestartVersion' label value as the current domain resource's 'spec.restartVersion, and (c) have the same image as the current domain resource's image. pod_count = 0 : Wait until there are no running WebLogic server pods for a domain. The default. -t \\u0026lt;timeout\\u0026gt; : Timeout in seconds. Defaults to '600'. -q : Quiet mode. Show only a count of wl pods that have reached the desired criteria. -? : This help.      Click here to expand sample output from `wl-pod-wait.sh`.   @@ [2020-04-30T13:50:42][seconds=0] Info: Waiting up to 600 seconds for exactly '3' WebLogic server pods to reach the following criteria: @@ [2020-04-30T13:50:42][seconds=0] Info: ready='true' @@ [2020-04-30T13:50:42][seconds=0] Info: image='model-in-image:WLS-v1' @@ [2020-04-30T13:50:42][seconds=0] Info: domainRestartVersion='1' @@ [2020-04-30T13:50:42][seconds=0] Info: namespace='sample-domain1-ns' @@ [2020-04-30T13:50:42][seconds=0] Info: domainUID='sample-domain1' @@ [2020-04-30T13:50:42][seconds=0] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:50:42][seconds=0] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----- ----- --------- 'sample-domain1-introspect-domain-job-rkdkg' '' '' '' 'Pending' @@ [2020-04-30T13:50:45][seconds=3] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:50:45][seconds=3] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----- ----- --------- 'sample-domain1-introspect-domain-job-rkdkg' '' '' '' 'Running' @@ [2020-04-30T13:51:50][seconds=68] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:51:50][seconds=68] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE ---- ------- ----- ----- ----- @@ [2020-04-30T13:51:59][seconds=77] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:51:59][seconds=77] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE ----------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'false' 'Pending' @@ [2020-04-30T13:52:02][seconds=80] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:52:02][seconds=80] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE ----------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'false' 'Running' @@ [2020-04-30T13:52:32][seconds=110] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:52:32][seconds=110] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'false' 'Pending' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'false' 'Pending' @@ [2020-04-30T13:52:34][seconds=112] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:52:34][seconds=112] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'false' 'Running' @@ [2020-04-30T13:53:14][seconds=152] Info: '3' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:53:14][seconds=152] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:53:14][seconds=152] Info: Success!    If you see an error, then consult Debugging in the Model in Image user guide.\\nInvoke the web application Now that all the initial use case resources have been deployed, you can invoke the sample web application through the Traefik ingress controller\\u0026rsquo;s NodePort. Note: The web application will display a list of any data sources it finds, but we don\\u0026rsquo;t expect it to find any because the model doesn\\u0026rsquo;t contain any at this point.\\nSend a web application request to the load balancer:\\n$ curl -s -S -m 10 -H 'host: sample-domain1-cluster-cluster-1.mii-sample.org' \\\\ http://localhost:30305/myapp_war/index.jsp Or, if Traefik is unavailable and your Administration Server pod is running, you can use kubectl exec:\\n$ kubectl exec -n sample-domain1-ns sample-domain1-admin-server -- bash -c \\\\ \\u0026quot;curl -s -S -m 10 http://sample-domain1-cluster-cluster-1:8001/myapp_war/index.jsp\\u0026quot; You should see output like the following:\\n$ curl -s -S -m 10 -H 'host: sample-domain1-cluster-cluster-1.mii-sample.org' \\\\ http://localhost:30305/myapp_war/index.jsp \\u0026lt;html\\u0026gt;\\u0026lt;body\\u0026gt;\\u0026lt;pre\\u0026gt; ***************************************************************** Hello World! This is version 'v1' of the mii-sample JSP web-app. Welcome to WebLogic server 'managed-server2'! domain UID = 'sample-domain1' domain name = 'domain1' Found 1 local cluster runtime: Cluster 'cluster-1' Found 0 local data sources: ***************************************************************** \\u0026lt;/pre\\u0026gt;\\u0026lt;/body\\u0026gt;\\u0026lt;/html\\u0026gt; Note: If you\\u0026rsquo;re running your curl commands on a remote machine, then substitute localhost with an external address suitable for contacting your Kubernetes cluster. A Kubernetes cluster address that often works can be obtained by using the address just after https:// in the KubeDNS line of the output from the kubectl cluster-info command.\\nIf you want to continue to the next use case, then leave your domain running.\\nUpdate1 use case This use case demonstrates dynamically adding a data source to your running domain. It demonstrates several features of WDT and Model in Image:\\n The syntax used for updating a model is exactly the same syntax you use for creating the original model. A domain\\u0026rsquo;s model can be updated dynamically by supplying a model update in a file in a Kubernetes ConfigMap. Model updates can be as simple as changing the value of a single attribute, or more complex, such as adding a JMS Server.  For a detailed discussion of model updates, see Runtime Updates in the Model in Image user guide.\\nThe operator does not support all possible dynamic model updates. For model update limitations, consult Runtime Updates in the Model in Image user docs, and carefully test any model update before attempting a dynamic update in production.\\n Here are the steps:\\n  Ensure that you have a running domain.\\nMake sure you have deployed the domain from the Initial use case.\\n  Create a data source model YAML file.\\nCreate a WDT model snippet for a data source (or use the example provided). Make sure that its target is set to cluster-1, and that its initial capacity is set to 0.\\nThe reason for the latter is to prevent the data source from causing a WebLogic Server startup failure if it can\\u0026rsquo;t find the database, which would be likely to happen because we haven\\u0026rsquo;t deployed one (unless you\\u0026rsquo;re using the JRF path through the sample).\\nHere\\u0026rsquo;s an example data source model configuration that meets these criteria:\\nresources: JDBCSystemResource: mynewdatasource: Target: 'cluster-1' JdbcResource: JDBCDataSourceParams: JNDIName: [ jdbc/mydatasource1, jdbc/mydatasource2 ] GlobalTransactionsProtocol: TwoPhaseCommit JDBCDriverParams: DriverName: oracle.jdbc.xa.client.OracleXADataSource URL: '@@SECRET:@@ENV:DOMAIN_UID@@-datasource-secret:url@@' PasswordEncrypted: '@@SECRET:@@ENV:DOMAIN_UID@@-datasource-secret:password@@' Properties: user: Value: 'sys as sysdba' oracle.net.CONNECT_TIMEOUT: Value: 5000 oracle.jdbc.ReadTimeout: Value: 30000 JDBCConnectionPoolParams: InitialCapacity: 0 MaxCapacity: 1 TestTableName: SQL ISVALID TestConnectionsOnReserve: true Place the above model snippet in a file named /tmp/mii-sample/mydatasource.yaml and then use it in the later step where we deploy the model ConfigMap, or alternatively, use the same data source that\\u0026rsquo;s provided in /tmp/mii-sample/model-configmaps/datasource/model.20.datasource.yaml.\\n  Create the data source secret.\\nThe data source references a new secret that needs to be created. Run the following commands to create the secret:\\n$ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-datasource-secret \\\\ --from-literal=password=Oradoc_db1 \\\\ --from-literal=url=jdbc:oracle:thin:@oracle-db.default.svc.cluster.local:1521/devpdb.k8s $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-datasource-secret \\\\ weblogic.domainUID=sample-domain1 We name and label secrets using their associated domain UID for two reasons:\\n To make it obvious which secret belongs to which domains. To make it easier to clean up a domain. Typical cleanup scripts use the weblogic.domainUID label as a convenience for finding all the resources associated with a domain.    Create a ConfigMap with the WDT model that contains the data source definition.\\nRun the following commands:\\n$ kubectl -n sample-domain1-ns create configmap sample-domain1-wdt-config-map \\\\ --from-file=/tmp/mii-sample/model-configmaps/datasource $ kubectl -n sample-domain1-ns label configmap sample-domain1-wdt-config-map \\\\ weblogic.domainUID=sample-domain1  If you\\u0026rsquo;ve created your own data source file, then substitute the file name in the --from-file= parameter (we suggested /tmp/mii-sample/mydatasource.yaml earlier). Note that the -from-file= parameter can reference a single file, in which case it puts the designated file in the ConfigMap, or it can reference a directory, in which case it populates the ConfigMap with all of the files in the designated directory.  We name and label ConfigMap using their associated domain UID for two reasons:\\n To make it obvious which ConfigMap belong to which domains. To make it easier to cleanup a domain. Typical cleanup scripts use the weblogic.domainUID label as a convenience for finding all resources associated with a domain.    Update your domain resource to refer to the ConfigMap and secret.\\n  Option 1: Update your current domain resource file from the \\u0026ldquo;Initial\\u0026rdquo; use case.\\n  Add the secret to its spec.configuration.secrets stanza:\\nspec: ... configuration: ... secrets: - sample-domain1-datasource-secret (Leave any existing secrets in place.)\\n  Change its spec.configuration.model.configMap to look like:\\nspec: ... configuration: ... model: ... configMap: sample-domain1-wdt-config-map   Apply your changed domain resource:\\n$ kubectl apply -f your-domain-resource.yaml     Option 2: Use the updated domain resource file that is supplied with the sample:\\n$ kubectl apply -f /tmp/miisample/domain-resources/mii-update1-d1-WLS-v1-ds.yaml     Restart (\\u0026lsquo;roll\\u0026rsquo;) the domain.\\nNow that the data source is deployed in a ConfigMap and its secret is also deployed, and we have applied an updated domain resource with its spec.configuration.model.configMap and spec.configuration.secrets referencing the ConfigMap and secret, let\\u0026rsquo;s tell the operator to roll the domain.\\nWhen a model domain restarts, it will rerun its introspector job in order to regenerate its configuration, and it will also pass the configuration changes found by the introspector to each restarted server. One way to cause a running domain to restart is to change the domain\\u0026rsquo;s spec.restartVersion. To do this:\\n  Option 1: Edit your domain custom resource.\\n Call kubectl -n sample-domain1-ns edit domain sample-domain1. Edit the value of the spec.restartVersion field and save.  The field is a string; typically, you use a number in this field and increment it with each restart.      Option 2: Dynamically change your domain using kubectl patch.\\n  To get the current restartVersion call:\\n$ kubectl -n sample-domain1-ns get domain sample-domain1 '-o=jsonpath={.spec.restartVersion}'   Choose a new restart version that\\u0026rsquo;s different from the current restart version.\\n The field is a string; typically, you use a number in this field and increment it with each restart.    Use kubectl patch to set the new value. For example, assuming the new restart version is 2:\\n$ kubectl -n sample-domain1-ns patch domain sample-domain1 --type=json '-p=[{\\u0026quot;op\\u0026quot;: \\u0026quot;replace\\u0026quot;, \\u0026quot;path\\u0026quot;: \\u0026quot;/spec/restartVersion\\u0026quot;, \\u0026quot;value\\u0026quot;: \\u0026quot;2\\u0026quot; }]'     Option 3: Use the sample helper script.\\n Call /tmp/mii-sample/utils/patch-restart-version.sh -n sample-domain1-ns -d sample-domain1. This will perform the same kubectl get and kubectl patch commands as Option 2.      Wait for the roll to complete.\\nNow that you\\u0026rsquo;ve started a domain roll, you\\u0026rsquo;ll need to wait for it to complete if you want to verify that the data source was deployed.\\n  One way to do this is to call kubectl get pods -n sample-domain1-ns --watch and wait for the pods to cycle back to their ready state.\\n  Alternatively, you can run /tmp/mii-sample/utils/wl-pod-wait.sh -p 3. This is a utility script that provides useful information about a domain\\u0026rsquo;s pods and waits for them to reach a ready state, reach their target restartVersion, and reach their target image before exiting.\\n  Click here to expand the `wl-pod-wait.sh` usage.    $ ./wl-pod-wait.sh -? Usage: wl-pod-wait.sh [-n mynamespace] [-d mydomainuid] \\\\ [-p expected_pod_count] \\\\ [-t timeout_secs] \\\\ [-q] Exits non-zero if 'timeout_secs' is reached before 'pod_count' is reached. Parameters: -d \\u0026lt;domain_uid\\u0026gt; : Defaults to 'sample-domain1'. -n \\u0026lt;namespace\\u0026gt; : Defaults to 'sample-domain1-ns'. pod_count \\u0026gt; 0 : Wait until exactly 'pod_count' WebLogic server pods for a domain all (a) are ready, (b) have the same 'domainRestartVersion' label value as the current domain resource's 'spec.restartVersion, and (c) have the same image as the current domain resource's image. pod_count = 0 : Wait until there are no running WebLogic server pods for a domain. The default. -t \\u0026lt;timeout\\u0026gt; : Timeout in seconds. Defaults to '600'. -q : Quiet mode. Show only a count of wl pods that have reached the desired criteria. -? : This help.      Click here to expand sample output from `wl-pod-wait.sh` that shows a rolling domain.    @@ [2020-04-30T13:53:19][seconds=0] Info: Waiting up to 600 seconds for exactly '3' WebLogic server pods to reach the following criteria: @@ [2020-04-30T13:53:19][seconds=0] Info: ready='true' @@ [2020-04-30T13:53:19][seconds=0] Info: image='model-in-image:WLS-v1' @@ [2020-04-30T13:53:19][seconds=0] Info: domainRestartVersion='2' @@ [2020-04-30T13:53:19][seconds=0] Info: namespace='sample-domain1-ns' @@ [2020-04-30T13:53:19][seconds=0] Info: domainUID='sample-domain1' @@ [2020-04-30T13:53:19][seconds=0] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:53:19][seconds=0] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-introspect-domain-job-wlkpr' '' '' '' 'Pending' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:53:20][seconds=1] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:53:20][seconds=1] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-introspect-domain-job-wlkpr' '' '' '' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:18][seconds=59] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:18][seconds=59] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----------------------- ------ ----------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-introspect-domain-job-wlkpr' '' '' '' 'Succeeded' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:19][seconds=60] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:19][seconds=60] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:31][seconds=72] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:31][seconds=72] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:40][seconds=81] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:40][seconds=81] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:52][seconds=93] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:52][seconds=93] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:58][seconds=99] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:58][seconds=99] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'false' 'Pending' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:00][seconds=101] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:00][seconds=101] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:12][seconds=113] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:12][seconds=113] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:24][seconds=125] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:24][seconds=125] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:33][seconds=134] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:33][seconds=134] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:34][seconds=135] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:34][seconds=135] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'false' 'Pending' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:40][seconds=141] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:40][seconds=141] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:44][seconds=145] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:44][seconds=145] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:56:25][seconds=186] Info: '2' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:56:25][seconds=186] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:56:26][seconds=187] Info: '2' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:56:26][seconds=187] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'false' 'Pending' @@ [2020-04-30T13:56:30][seconds=191] Info: '2' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:56:30][seconds=191] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:56:34][seconds=195] Info: '2' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:56:34][seconds=195] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '2' 'model-in-image:WLS-v1' 'false' 'Pending' @@ [2020-04-30T13:57:09][seconds=230] Info: '3' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:57:09][seconds=230] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '2' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:57:09][seconds=230] Info: Success!        After your domain is running, you can call the sample web application to determine if the data source was deployed.\\nSend a web application request to the ingress controller:\\n$ curl -s -S -m 10 -H 'host: sample-domain1-cluster-cluster-1.mii-sample.org' \\\\ http://localhost:30305/myapp_war/index.jsp Or, if Traefik is unavailable and your Administration Server pod is running, you can run kubectl exec:\\n$ kubectl exec -n sample-domain1-ns sample-domain1-admin-server -- bash -c \\\\ \\u0026quot;curl -s -S -m 10 http://sample-domain1-cluster-cluster-1:8001/myapp_war/index.jsp\\u0026quot; You should see something like the following:\\n  Click here to see the expected web application output.   $ curl -s -S -m 10 -H 'host: sample-domain1-cluster-cluster-1.mii-sample.org' \\\\ http://localhost:30305/myapp_war/index.jsp \\u0026lt;html\\u0026gt;\\u0026lt;body\\u0026gt;\\u0026lt;pre\\u0026gt; ***************************************************************** Hello World! This is version 'v1' of the mii-sample JSP web-app. Welcome to WebLogic server 'managed-server1'! domain UID = 'sample-domain1' domain name = 'domain1' Found 1 local cluster runtime: Cluster 'cluster-1' Found 1 local data source: Datasource 'mynewdatasource': State='Running' ***************************************************************** \\u0026lt;/pre\\u0026gt;\\u0026lt;/body\\u0026gt;\\u0026lt;/html\\u0026gt;      If you see an error, then consult Debugging in the Model in Image user guide.\\nThis completes the sample scenarios.\\nCleanup To remove the resources you have created in these samples:\\n  Delete the domain resources.\\n$ /tmp/operator-source/kubernetes/samples/scripts/delete-domain/delete-weblogic-domain-resources.sh -d sample-domain1 $ /tmp/operator-source/kubernetes/samples/scripts/delete-domain/delete-weblogic-domain-resources.sh -d sample-domain2 This deletes the domain and any related resources that are labeled with the domain UID sample-domain1 and sample-domain2.\\nIt leaves the namespace intact, the operator running, the load balancer running (if installed), and the database running (if installed).\\n Note: When you delete a domain, the operator should detect your domain deletion and shut down its pods. Wait for these pods to exit before deleting the operator that monitors the sample-domain1-ns namespace. You can monitor this process using the command kubectl get pods -n sample-domain1-ns --watch (ctrl-c to exit).\\n   If you set up the Traefik ingress controller:\\n$ helm delete --purge traefik-operator $ kubectl delete namespace traefik   If you set up a database for JRF:\\n$ /tmp/operator-source/kubernetes/samples/scripts/create-oracle-db-service/stop-db-service.sh   Delete the operator and its namespace:\\n$ helm delete --purge sample-weblogic-operator $ kubectl delete namespace sample-weblogic-operator-ns   Delete the domain\\u0026rsquo;s namespace:\\n$ kubectl delete namespace sample-domain1-ns   Delete the images you may have created in this sample:\\n$ docker image rm model-in-image:WLS-v1 $ docker image rm model-in-image:WLS-v2 $ docker image rm model-in-image:JRF-v1 $ docker image rm model-in-image:JRF-v2   References For references to the relevant user documentation, see:\\n Model in Image user documentation Oracle WebLogic Server Deploy Tooling Oracle WebLogic Image Tool  \"\n+\t\"content\": \" This feature is supported only in 3.0.0-rc1.\\n Contents  Introduction  Model in Image domain types (WLS, JRF, and Restricted JRF) Use cases Sample directory structure   Prerequisites for all domain types Additional prerequisites for JRF domains Initial use case: An initial WebLogic domain Update1 use case: Dynamically adding a data source using a model ConfigMap Cleanup References  Introduction This sample demonstrates deploying a Model in Image domain home source type. Unlike Domain in PV and Domain in Image, Model in Image eliminates the need to pre-create your WebLogic domain home prior to deploying your domain resource. Instead, Model in Image uses a WebLogic Deploy Tooling (WDT) model to specify your WebLogic configuration.\\nWDT models are a convenient and simple alternative to WebLogic WLST configuration scripts and templates. They compactly define a WebLogic domain using YAML files and support including application archives in a ZIP file. The WDT model format is described in the open source, WebLogic Deploy Tooling GitHub project, and the required directory structure for a WDT archive is specifically discussed here.\\nFor more information on Model in Image, see the Model in Image user guide. For a comparison of Model in Image to other domain home source types, see Choose a domain home source type.\\nModel in Image domain types (WLS, JRF, and Restricted JRF) There are three types of domains supported by Model in Image: a standard WLS domain, an Oracle Fusion Middleware Infrastructure Java Required Files (JRF) domain, and a RestrictedJRF domain. This sample demonstrates the WLS and JRF types.\\nThe JRF domain path through the sample includes additional steps required for JRF: deploying an infrastructure database, initializing the database using the Repository Creation Utility (RCU) tool, referencing the infrastructure database from the WebLogic configuration, setting an Oracle Platform Security Services (OPSS) wallet password, and exporting/importing an OPSS wallet file. JRF domains may be used by Oracle products that layer on top of WebLogic Server, such as SOA and OSB. Similarly, RestrictedJRF domains may be used by Oracle layered products, such as Oracle Communications products.\\nUse cases This sample demonstrates two Model in Image use cases:\\n  Initial: An initial WebLogic domain with the following characteristics:\\n Image model-in-image:WLS-v1 with:  A WebLogic installation A WebLogic Deploy Tooling (WDT) installation A WDT archive with version v1 of an exploded Java EE web application A WDT model with:  A WebLogic Administration Server A WebLogic cluster A reference to the web application     Kubernetes Secrets:  WebLogic credentials Required WDT runtime password   A domain resource with:  spec.domainHomeSourceType: FromModel spec.image: model-in-image:WLS-v1 References to the secrets      Update1: Demonstrates udpating the initial domain by dynamically adding a data source using a model ConfigMap:\\n Image model-in-image:WLS-v1:  Same image as Initial use case   Kubernetes Secrets:  Same as Initial use case plus secrets for data source credentials and URL   Kubernetes ConfigMap with:  A WDT model for a data source targeted to the cluster   A domain resource with:  Same as Initial use case plus:  spec.model.configMap referencing the ConfigMap References to data source secrets        Sample directory structure The sample contains the following files and directories:\\n   Location Description     domain-resources JRF and WLS domain resources.   archives Source code location for WebLogic Deploy Tooling application ZIP archives.   model-images Staging for each model image\\u0026rsquo;s WDT YAML, WDT properties, and WDT archive ZIP files. The directories in model images are named for their respective images.   model-configmaps Staging files for a model ConfigMap that configures a data source.   ingresses Ingress resources.   utils/wl-pod-wait.sh Utility for watching the pods in a domain reach their expected restartVersion, image name, and ready state.   utils/patch-restart-version.sh Utility for updating a running domain spec.restartVersion field (which causes it to \\u0026lsquo;re-instrospect\\u0026rsquo; and \\u0026lsquo;roll\\u0026rsquo;).   utils/opss-wallet.sh Utility for exporting or importing a JRF domain OPSS wallet file.    Prerequisites for all domain types   Choose the type of domain you\\u0026rsquo;re going to use throughout the sample, WLS or JRF.\\n The first time you try this sample, we recommend that you choose WLS even if you\\u0026rsquo;re familiar with JRF. This is because WLS is simpler and will more easily familiarize you with Model in Image concepts. We recommend choosing JRF only if you are already familiar with JRF, you have already tried the WLS path through this sample, and you have a definite use case where you need to use JRF.    The JAVA_HOME environment variable must be set and must reference a valid JDK 8 or 11 installation.\\n  Get the operator source from the release/3.0.0-rc1 branch and put it in /tmp/operator-source.\\nFor example:\\n$ mkdir /tmp/operator-source $ cd /tmp/operator-source $ git clone https://github.com/oracle/weblogic-kubernetes-operator.git $ git checkout release/3.0.0-rc1  Note: We will refer to the top directory of the operator source tree as /tmp/operator-source; however, you can use a different location.\\n For additional information about obtaining the operator source, see the Developer Guide Requirements.\\n  Copy the sample to a new directory; for example, use directory /tmp/mii-sample.\\n$ mkdir /tmp/mii-sample $ cp -r /tmp/operator-source/kubernetes/samples/scripts/create-weblogic-domain/model-in-image/* /tmp/mii-sample  Note: We will refer to this working copy of the sample as /tmp/mii-sample; however, you can use a different location.     Make sure an operator is set up to manage namespace sample-domain1-ns. Also, make sure a Traefik ingress controller is managing the same namespace and listening on port 30305.\\nFor example, follow the same steps as the Quick Start guide from the beginning through to the Prepare for a domain step.\\nMake sure you stop when you complete the \\u0026ldquo;Prepare for a domain\\u0026rdquo; step and then resume following these instructions.\\n   Set up ingresses that will redirect HTTP from Traefik port 30305 to the clusters in this sample\\u0026rsquo;s WebLogic domains.\\n  Option 1: To create the ingresses, use the following YAML to create a file called /tmp/mii-sample/ingresses/myingresses.yaml and then call kubectl apply -f /tmp/mii-sample/ingresses/myingresses.yaml:\\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress-sample-domain1-admin-server namespace: sample-domain1-ns labels: weblogic.domainUID: sample-domain1 annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: http: paths: - path: /console backend: serviceName: sample-domain1-admin-server servicePort: 7001 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress-sample-domain1-cluster-cluster-1 namespace: sample-domain1-ns labels: weblogic.domainUID: sample-domain1 annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: sample-domain1-cluster-cluster-1.mii-sample.org http: paths: - path: backend: serviceName: sample-domain1-cluster-cluster-1 servicePort: 8001 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress-sample-domain1-cluster-cluster-2 namespace: sample-domain1-ns labels: weblogic.domainUID: sample-domain1 annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: sample-domain1-cluster-cluster-2.mii-sample.org http: paths: - path: backend: serviceName: sample-domain1-cluster-cluster-2 servicePort: 8001 --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-ingress-sample-domain2-cluster-cluster-1 namespace: sample-domain1-ns labels: weblogic.domainUID: sample-domain2 annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: sample-domain2-cluster-cluster-1.mii-sample.org http: paths: - path: backend: serviceName: sample-domain2-cluster-cluster-1 servicePort: 8001   Option 2: Run kubectl apply -f on each of the ingress YAML files that are already included in the sample source /tmp/mii-sample/ingresses directory:\\n  $ cd /tmp/mii-sample/ingresses $ kubectl apply -f traefik-ingress-sample-domain1-admin-server.yaml $ kubectl apply -f traefik-ingress-sample-domain1-cluster-cluster-1.yaml $ kubectl apply -f traefik-ingress-sample-domain1-cluster-cluster-2.yaml $ kubectl apply -f traefik-ingress-sample-domain2-cluster-cluster-1.yaml $ kubectl apply -f traefik-ingress-sample-domain2-cluster-cluster-2.yaml  NOTE: We give each cluster ingress a different host name that is decorated using both its operator domain UID and its cluster name. This makes each cluster uniquely addressable even when cluster names are the same across different clusters. When using curl to access the WebLogic domain through the ingress, you will need to supply a host name header that matches the host names in the ingress.\\n For more on information ingresses and load balancers, see Ingress.\\n  Obtain the WebLogic 12.2.1.4 image that is required to create the sample\\u0026rsquo;s model images.\\na. Use a browser to access Oracle Container Registry.\\nb. Choose an image location: for JRF domains, select Middleware, then fmw-infrastructure; for WLS domains, select Middleware, then weblogic.\\nc. Select Sign In and accept the license agreement.\\nd. Use your terminal to log in to Docker locally: docker login container-registry.oracle.com.\\ne. Later in this sample, when you run WebLogic Image Tool commands, the tool will use the image as a base image for creating model images. Specifically, the tool will implicitly call docker pull for one of the above licensed images as specified in the tool\\u0026rsquo;s command line using the --fromImage parameter. For JRF, this sample specifies container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4, and for WLS, the sample specifies container-registry.oracle.com/middleware/weblogic:12.2.1.4.\\nIf you prefer, you can create your own base image and then substitute this image name in the WebLogic Image Tool --fromImage parameter throughout this sample. See Preparing a Base Image.\\n   Download the latest WebLogic Deploying Tooling and WebLogic Image Tool installer ZIP files to your /tmp/mii-sample/model-images directory.\\nBoth WDT and WIT are required to create your Model in Image Docker images. Download the latest version of each tool\\u0026rsquo;s installer ZIP file to the /tmp/mii-sample/model-images directory.\\nFor example, visit the GitHub WebLogic Deploy Tooling Releses and WebLogic Image Tool Releases web pages to determine the latest release version for each, and then, assuming the version numbers are 1.9.3 and 1.8.4 respectively, call:\\n$ curl -m 30 -fL https://github.com/oracle/weblogic-deploy-tooling/releases/download/release-1.9.3/weblogic-deploy.zip \\\\ -o /tmp/mii-sample/model-images/weblogic-deploy.zip $ curl -m 30 -fL https://github.com/oracle/weblogic-image-tool/releases/download/release-1.8.4/imagetool.zip \\\\ -o /tmp/mii-sample/model-images/imagetool.zip   Set up the WebLogic Image Tool.\\nRun the following commands:\\n$ cd /tmp/mii-sample/model-images $ unzip imagetool.zip $ ./imagetool/bin/imagetool.sh cache addInstaller \\\\ --type wdt \\\\ --version latest \\\\ --path /tmp/mii-sample/model-images/weblogic-deploy.zip These steps will install WIT to the /tmp/mii-sample/model-images/imagetool directory, plus put a wdt_latest entry in the tool\\u0026rsquo;s cache which points to the WDT ZIP installer. We will use WIT later in the sample for creating model images.\\n  Additional prerequisites for JRF domains  NOTE: If you\\u0026rsquo;re using a WLS domain type, skip this section and continue here.\\n JRF Prerequisites Contents  Introduction to JRF setups Set up and initialize an infrastructure database Increase introspection job timeout Important considerations for RCU model attributes, domain resource attributes, and secrets  Introduction to JRF setups  NOTE: The requirements in this section are in addition to Prerequisites for all domain types.\\n A JRF domain requires an infrastructure database, initializing this database with RCU, and configuring your domain to access this database. All of these steps must occur before you create your domain.\\nSet up and initialize an infrastructure database A JRF domain requires an infrastructure database and also requires initializing this database with a schema and a set of tables. The following example shows how to set up a database and use the RCU tool to create the infrastructure schema for a JRF domain. The database is set up with the following attributes:\\n   Attribute Value     database Kubernetes namespace default   database Kubernetes pod oracle-db   database image container-registry.oracle.com/database/enterprise:12.2.0.1-slim   database password Oradoc_db1   infrastructure schema prefix FMW1   infrastructure schema password Oradoc_db1   database URL oracle-db.default.svc.cluster.local:1521/devpdb.k8s      Ensure that you have access to the database image, and then create a deployment using it:\\n  Use a browser to log in to https://container-registry.oracle.com, select database-\\u0026gt;enterprise and accept the license agreement.\\n  Get the database image:\\n In the local shell, docker login container-registry.oracle.com. In the local shell, docker pull container-registry.oracle.com/database/enterprise:12.2.0.1-slim.    Use the sample script in /tmp/operator-source/kubernetes/samples/scripts/create-oracle-db-service to create an Oracle database running in the pod, oracle-db.\\n$ cd /tmp/operator-source/kubernetes/samples/scripts/create-oracle-db-service $ start-db-service.sh This script will deploy a database in the default namespace with the connect string oracle-db.default.svc.cluster.local:1521/devpdb.k8s, and administration password Oradoc_db1.\\nThis step is based on the steps documented in Run a Database.\\nWARNING: The Oracle Database Docker images are supported only for non-production use. For more details, see My Oracle Support note: Oracle Support for Database Running on Docker (Doc ID 2216342.1).\\n    Use the sample script in /tmp/operator-source/kubernetes/samples/scripts/create-rcu-schema to create the RCU schema with the schema prefix FMW1.\\nNote that this script assumes Oradoc_db1 is the DBA password, Oradoc_db1 is the schema password, and that the database URL is oracle-db.default.svc.cluster.local:1521/devpdb.k8s.\\n$ cd /tmp/operator-source/kubernetes/samples/scripts/create-rcu-schema $ ./create-rcu-schema.sh -s FMW1 -i container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4 NOTE: If you need to drop the repository, use this command:\\n$ drop-rcu-schema.sh -s FMW1   Increase introspection job timeout The JRF domain home creation can take more time than the introspection job\\u0026rsquo;s default timeout. You should increase the timeout for the introspection job. Use the configuration.introspectorJobActiveDeadlineSeconds in your domain resource to override the default with a value of at least 300 seconds (the default is 120 seconds). Note that the JRF versions of the domain resource files that are provided in /tmp/mii-sample/domain-resources already set this value.\\nImportant considerations for RCU model attributes, domain resource attributes, and secrets To allow Model in Image to access the database and OPSS wallet, you must create an RCU access secret containing the database connect string, user name, and password that\\u0026rsquo;s referenced from your model and an OPSS wallet password secret that\\u0026rsquo;s referenced from your domain resource before deploying your domain. It\\u0026rsquo;s also necessary to define an RCUDbInfo stanza in your model.\\nThe sample includes examples of JRF models and domain resources in the /tmp/mii-sample/model-images and /tmp/mii-sample/domain-resources directories, and instructions in the following sections will describe setting up the RCU and OPSS secrets.\\nWhen you follow the instructions later in this sample, avoid instructions that are WLS only, and substitute JRF for WLS in the corresponding model image tags and domain resource file names.\\nFor example:\\n  JRF domain resources in this sample have an opss.walletPasswordSecret field that references a secret named sample-domain1-opss-wallet-password-secret, with password=welcome1.\\n  JRF image models in this sample have a domainInfo -\\u0026gt; RCUDbInfo stanza that reference a sample-domain1-rcu-access secret with appropriate values for attributes rcu_prefix, rcu_schema_password, and rcu_db_conn_string for accessing the Oracle database that you deployed to the default namespace as one of the prerequisite steps.\\n  Important considerations for reusing or sharing OPSS tables We do not recommend that most users share OPSS tables. Extreme caution is required when sharing OPSS tables between domains.\\n When you successfully deploy your JRF domain resource for the first time, the introspector job will initialize the OPSS tables for the domain using the domainInfo -\\u0026gt; RCUDbInfo stanza in the WDT model plus the configuration.opss.walletPasswordSecret specified in the domain resource. The job will also create a new domain home. Finally, the operator will also capture an OPSS wallet file from the new domain\\u0026rsquo;s local directory and place this file in a new Kubernetes ConfigMap.\\nThere are scenarios when the domain needs to be recreated between updates, such as when WebLogic credentials are changed, security roles defined in the WDT model have been changed, or you want to share the same infrastructure tables with different domains. In these scenarios, the operator needs the walletPasswordSecret as well as the OPSS wallet file, together with the exact information in domainInfo -\\u0026gt; RCUDbInfo so that the domain can be recreated and access the same set of tables. Without the wallet file and wallet password, you will not be able to recreate a domain accessing the same set of tables, therefore we strongly recommend that you back up the wallet file.\\nTo recover a domain\\u0026rsquo;s OPSS tables between domain restarts or to share an OPSS schema between different domains, it is necessary to extract this wallet file from the domain\\u0026rsquo;s automatically deployed introspector ConfigMap and save the OPSS wallet password secret that was used for the original domain. The wallet password and wallet file are needed again when you recreate the domain or share the database with other domains.\\nTo save the wallet file, assuming that your namespace is sample-domain1-ns and your domain UID is sample-domain1:\\n $ kubectl -n sample-domain1-ns \\\\ get configmap sample-domain1-weblogic-domain-introspect-cm \\\\ -o jsonpath='{.data.ewallet\\\\.p12}' \\\\ \\u0026gt; ./ewallet.p12 Alternatively, you can save the file using the sample\\u0026rsquo;s wallet utility:\\n $ /tmp/mii-sample/utils/opss-wallet.sh -n sample-domain1-ns -d sample-domain1 -wf ./ewallet.p12 # For help: /tmp/mii-sample/utils/opss-wallet.sh -? Important! Back up your wallet file to a safe location that can be retrieved later.\\nTo reuse the wallet file in subsequent redeployments or to share the domain\\u0026rsquo;s OPSS tables between different domains:\\n Load the saved wallet file into a secret with a key named walletFile (again, assuming that your domain UID is sample-domain1 and your namespace is sample-domain1-ns):   $ kubectl -n sample-domain1-ns create secret generic sample-domain1-opss-walletfile-secret \\\\ --from-file=walletFile=./ewallet.p12 $ kubectl -n sample-domain1-ns label secret sample-domain1-opss-walletfile-secret \\\\ weblogic.domainUID=`sample-domain1` Alternatively, use the sample\\u0026rsquo;s wallet utility:\\n $ /tmp/mii-sample/utils/opss-wallet.sh -n sample-domain1-ns -d sample-domain1 -wf ./ewallet.p12 -ws sample-domain1-opss-walletfile-secret # For help: /tmp/mii-sample/utils/opss-wallet.sh -? Modify your domain resource JRF YAML files to provide the wallet file secret name, for example:   configuration: opss: # Name of secret with walletPassword for extracting the wallet walletPasswordSecret: sample-domain1-opss-wallet-password-secret # Name of secret with walletFile containing base64 encoded opss wallet walletFileSecret: sample-domain1-opss-walletfile-secret  Note: The sample JRF domain resource files included in /tmp/mii-sample/domain-resources already have the above YAML stanza.\\n Initial use case Contents  Overview Image creation  Image creation - Introduction Understanding our first archive Staging a ZIP file of the archive Staging model files Creating the image with WIT   Deploy resources  Deploy resources - Introduction Secrets Domain resource    Overview In this use case, we set up an initial WebLogic domain. This involves:\\n A WDT archive ZIP file that contains your applications. A WDT model that describes your WebLogic configuration. A Docker image that contains your WDT model files and archive. Creating secrets for the domain. Creating a domain resource for the domain that references your secrets and image.  After the domain resource is deployed, the WebLogic operator will start an \\u0026lsquo;introspector job\\u0026rsquo; that converts your models into a WebLogic configuration, and then the operator will pass this configuration to each WebLogic Server in the domain.\\nPerform the steps in Prerequisites for all domain types before performing the steps in this use case.\\nIf you are taking the JRF path through the sample, then substitute JRF for WLS in your image names and directory paths. Also note that the JRF-v1 model YAML differs from the WLS-v1 YAML file (it contains an additional domainInfo -\\u0026gt; RCUDbInfo stanza).\\n Image creation - Introduction The goal of the initial use case \\u0026lsquo;image creation\\u0026rsquo; is to demonstrate using the WebLogic Image Tool to create an image named model-in-image:WLS-v1 from files that we will stage to /tmp/mii-sample/model-images/model-in-image:WLS-v1/. The staged files will contain a web application in a WDT archive, and WDT model configuration for a WebLogic Administration Server called admin-server and a WebLogic cluster called cluster-1.\\nOverall, a Model in Image image must contain a WebLogic installation and also a WebLogic Deploy Tooling installation in its /u01/wdt/weblogic-deploy directory. In addition, if you have WDT model archive files, then the image must also contain these files in its /u01/wdt/models directory. Finally, an image may optionally also contain your WDT model YAML and properties files in the same /u01/wdt/models directory. If you do not specify WDT model YAML in your /u01/wdt/models directory, then the model YAML must be supplied dynamically using a Kubernetes ConfigMap that is referenced by your domain resource spec.model.configMap attribute. We will provide an example of using a model ConfigMap later in this sample.\\nLet\\u0026rsquo;s walk through the steps for creating the image model-in-image:WLS-v1:\\n Understanding our first archive Staging a ZIP file of the archive Staging model files Creating the image with WIT  Understanding our first archive The sample includes a predefined archive directory in /tmp/mii-sample/archives/archive-v1 that we will use to create an archive ZIP file for the image.\\nThe archive top directory, named wlsdeploy, contains a directory named applications, which includes an \\u0026lsquo;exploded\\u0026rsquo; sample JSP web application in the directory, myapp-v1. Three useful aspects to remember about WDT archives are:\\n A model image can contain multiple WDT archives. WDT archives can contain multiple applications, libraries, and other components. WDT archives have a well defined directory structure, which always has wlsdeploy as the top directory.    If you are interested in the web application source, click here to see the JSP code.   \\u0026lt;%-- Copyright (c) 2019, 2020, Oracle Corporation and/or its affiliates. --%\\u0026gt; \\u0026lt;%-- Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl. --%\\u0026gt; \\u0026lt;%@ page import=\\u0026quot;javax.naming.InitialContext\\u0026quot; %\\u0026gt; \\u0026lt;%@ page import=\\u0026quot;javax.management.*\\u0026quot; %\\u0026gt; \\u0026lt;%@ page import=\\u0026quot;java.io.*\\u0026quot; %\\u0026gt; \\u0026lt;% InitialContext ic = null; try { ic = new InitialContext(); String srName=System.getProperty(\\u0026quot;weblogic.Name\\u0026quot;); String domainUID=System.getenv(\\u0026quot;DOMAIN_UID\\u0026quot;); String domainName=System.getenv(\\u0026quot;CUSTOM_DOMAIN_NAME\\u0026quot;); out.println(\\u0026quot;\\u0026lt;html\\u0026gt;\\u0026lt;body\\u0026gt;\\u0026lt;pre\\u0026gt;\\u0026quot;); out.println(\\u0026quot;*****************************************************************\\u0026quot;); out.println(); out.println(\\u0026quot;Hello World! This is version 'v1' of the mii-sample JSP web-app.\\u0026quot;); out.println(); out.println(\\u0026quot;Welcome to WebLogic server '\\u0026quot; + srName + \\u0026quot;'!\\u0026quot;); out.println(); out.println(\\u0026quot; domain UID = '\\u0026quot; + domainUID +\\u0026quot;'\\u0026quot;); out.println(\\u0026quot; domain name = '\\u0026quot; + domainName +\\u0026quot;'\\u0026quot;); out.println(); MBeanServer mbs = (MBeanServer)ic.lookup(\\u0026quot;java:comp/env/jmx/runtime\\u0026quot;); // display the current server's cluster name Set\\u0026lt;ObjectInstance\\u0026gt; clusterRuntimes = mbs.queryMBeans(new ObjectName(\\u0026quot;*:Type=ClusterRuntime,*\\u0026quot;), null); out.println(\\u0026quot;Found \\u0026quot; + clusterRuntimes.size() + \\u0026quot; local cluster runtime\\u0026quot; + (String)((clusterRuntimes.size()!=1)?\\u0026quot;s:\\u0026quot;:\\u0026quot;:\\u0026quot;)); for (ObjectInstance clusterRuntime : clusterRuntimes) { String cName = (String)mbs.getAttribute(clusterRuntime.getObjectName(), \\u0026quot;Name\\u0026quot;); out.println(\\u0026quot; Cluster '\\u0026quot; + cName + \\u0026quot;'\\u0026quot;); } out.println(); // display local data sources ObjectName jdbcRuntime = new ObjectName(\\u0026quot;com.bea:ServerRuntime=\\u0026quot; + srName + \\u0026quot;,Name=\\u0026quot; + srName + \\u0026quot;,Type=JDBCServiceRuntime\\u0026quot;); ObjectName[] dataSources = (ObjectName[])mbs.getAttribute(jdbcRuntime, \\u0026quot;JDBCDataSourceRuntimeMBeans\\u0026quot;); out.println(\\u0026quot;Found \\u0026quot; + dataSources.length + \\u0026quot; local data source\\u0026quot; + (String)((dataSources.length!=1)?\\u0026quot;s:\\u0026quot;:\\u0026quot;:\\u0026quot;)); for (ObjectName dataSource : dataSources) { String dsName = (String)mbs.getAttribute(dataSource, \\u0026quot;Name\\u0026quot;); String dsState = (String)mbs.getAttribute(dataSource, \\u0026quot;State\\u0026quot;); out.println(\\u0026quot; Datasource '\\u0026quot; + dsName + \\u0026quot;': State='\\u0026quot; + dsState +\\u0026quot;'\\u0026quot;); } out.println(); out.println(\\u0026quot;*****************************************************************\\u0026quot;); } catch (Throwable t) { t.printStackTrace(new PrintStream(response.getOutputStream())); } finally { out.println(\\u0026quot;\\u0026lt;/pre\\u0026gt;\\u0026lt;/body\\u0026gt;\\u0026lt;/html\\u0026gt;\\u0026quot;); if (ic != null) ic.close(); } %\\u0026gt;    The application displays important details about the WebLogic Server that it\\u0026rsquo;s running on: namely its domain name, cluster name, and server name, as well as the names of any data sources that are targeted to the server. You can also see that application output reports that it\\u0026rsquo;s at version v1; we will update this to v2 in a future use case to demonstrate upgrading the application.\\nStaging a ZIP file of the archive When we create our image, we will use the files in staging directory /tmp/mii-sample/model-in-image__WLS-v1. In preparation, we need it to contain a ZIP file of the WDT application archive.\\nRun the following commands to create your application archive ZIP file and put it in the expected directory:\\n# Delete existing archive.zip in case we have an old leftover version $ rm -f /tmp/mii-sample/model-images/model-in-image__WLS-v1/archive.zip # Move to the directory which contains the source files for our archive $ cd /tmp/mii-sample/archives/archive-v1 # Zip the archive to the location will later use when we run the WebLogic Image Tool $ zip -r /tmp/mii-sample/model-images/model-in-image__WLS-v1/archive.zip wlsdeploy Staging model files In this step, we explore the staged WDT model YAML file and properties in directory /tmp/mii-sample/model-in-image__WLS-v1. The model in this directory references the web application in our archive, configures a WebLogic Administration Server, and configures a WebLogic cluster. It consists of only two files, model.10.properties, a file with a single property, and, model.10.yaml, a YAML file with our WebLogic configuration model.10.yaml.\\nCLUSTER_SIZE=5 Here is the WLS model.10.yaml:\\ndomainInfo: AdminUserName: '@@SECRET:__weblogic-credentials__:username@@' AdminPassword: '@@SECRET:__weblogic-credentials__:password@@' ServerStartMode: 'prod' topology: Name: '@@ENV:CUSTOM_DOMAIN_NAME@@' AdminServerName: 'admin-server' Cluster: 'cluster-1': DynamicServers: ServerTemplate: 'cluster-1-template' ServerNamePrefix: 'managed-server' DynamicClusterSize: '@@PROP:CLUSTER_SIZE@@' MaxDynamicClusterSize: '@@PROP:CLUSTER_SIZE@@' MinDynamicClusterSize: '0' CalculatedListenPorts: false Server: 'admin-server': ListenPort: 7001 ServerTemplate: 'cluster-1-template': Cluster: 'cluster-1' ListenPort: 8001 appDeployments: Application: myapp: SourcePath: 'wlsdeploy/applications/myapp-v1' ModuleType: ear Target: 'cluster-1'    Click here to expand the JRF `model.10.yaml`, and note the RCUDbInfo stanza and its references to a DOMAIN_UID-rcu-access secret.   domainInfo: AdminUserName: '@@SECRET:__weblogic-credentials__:username@@' AdminPassword: '@@SECRET:__weblogic-credentials__:password@@' ServerStartMode: 'prod' RCUDbInfo: rcu_prefix: '@@SECRET:@@ENV:DOMAIN_UID@@-rcu-access:rcu_prefix@@' rcu_schema_password: '@@SECRET:@@ENV:DOMAIN_UID@@-rcu-access:rcu_schema_password@@' rcu_db_conn_string: '@@SECRET:@@ENV:DOMAIN_UID@@-rcu-access:rcu_db_conn_string@@' topology: AdminServerName: 'admin-server' Name: '@@ENV:CUSTOM_DOMAIN_NAME@@' Cluster: 'cluster-1': Server: 'admin-server': ListenPort: 7001 'managed-server1-c1-': Cluster: 'cluster-1' ListenPort: 8001 'managed-server2-c1-': Cluster: 'cluster-1' ListenPort: 8001 'managed-server3-c1-': Cluster: 'cluster-1' ListenPort: 8001 'managed-server4-c1-': Cluster: 'cluster-1' ListenPort: 8001 appDeployments: Application: myapp: SourcePath: 'wlsdeploy/applications/myapp-v1' ModuleType: ear Target: 'cluster-1'    The model files:\\n  Define a WebLogic domain with:\\n Cluster cluster-1 Administration Server admin-server A cluster-1 targeted ear application that\\u0026rsquo;s located in the WDT archive ZIP file at wlsdeploy/applications/myapp-v1    Leverage macros to inject external values:\\n The property file CLUSTER_SIZE property is referenced in the model YAML DynamicClusterSize and MaxDynamicClusterSize fields using a PROP macro. The model file domain name is injected using a custom environment variable named CUSTOM_DOMAIN_NAME using an ENV macro.  We set this environment variable later in this sample using an env field in its domain resource. This conveniently provides a simple way to deploy multiple differently named domains using the same model image.   The model file administrator user name and password are set using a weblogic-credentials secret macro reference to the WebLogic credential secret.  This secret is in turn referenced using the weblogicCredentialsSecret field in the domain resource. The weblogic-credentials is a reserved name that always dereferences to the owning domain resource actual WebLogic credentials secret name.      A Model in Image image can contain multiple properties files, archive ZIP files, and YAML files, but in this sample we use just one of each. For a full discussion of Model in Images model file naming conventions, file loading order, and macro syntax, see Model files in the Model in Image user documentation.\\nCreating the image with WIT  Note: If you are using JRF in this sample, substitute JRF for each occurrence of WLS in the imagetool command line below, plus substitute container-registry.oracle.com/middleware/fmw-infrastructure:12.2.1.4 for the --fromImage value.\\n At this point, we have staged all of the files needed for image model-in-image:WLS-v1, they include:\\n /tmp/mii-sample/model-images/weblogic-deploy.zip /tmp/mii-sample/model-images/model-in-image__WLS-v1/model.10.yaml /tmp/mii-sample/model-images/model-in-image__WLS-v1/model.10.properties /tmp/mii-sample/model-images/model-in-image__WLS-v1/archive.zip  If you don\\u0026rsquo;t see the weblogic-deploy.zip file, then it means that you missed a step in the prerequisites.\\nNow let\\u0026rsquo;s use the Image Tool to create an image named model-in-image:WLS-v1 that\\u0026rsquo;s layered on a base WebLogic image. We\\u0026rsquo;ve already set up this tool during the prerequisite steps at the beginning of this sample.\\nRun the following commands to create the model image and verify that it worked:\\n$ cd /tmp/mii-sample/model-images $ ./imagetool/bin/imagetool.sh update \\\\ --tag model-in-image:WLS-v1 \\\\ --fromImage container-registry.oracle.com/middleware/weblogic:12.2.1.4 \\\\ --wdtModel ./model-in-image__WLS-v1/model.10.yaml \\\\ --wdtVariables ./model-in-image__WLS-v1/model.10.properties \\\\ --wdtArchive ./model-in-image__WLS-v1/archive.zip \\\\ --wdtModelOnly \\\\ --wdtDomainType WLS If you don\\u0026rsquo;t see the imagetool directory, then it means that you missed a step in the prerequisites.\\nThis command runs the WebLogic Image Tool in its Model in Image mode, and does the following:\\n Builds the final Docker image as a layer on the container-registry.oracle.com/middleware/weblogic:12.2.1.4 base image. Copies the WDT ZIP file that\\u0026rsquo;s referenced in the WIT cache into the image.  Note that we cached WDT in WIT using the keyword latest when we set up the cache during the sample prerequisites steps. This lets WIT implicitly assume its the desired WDT version and removes the need to pass a -wdtVersion flag.   Copies the specified WDT model, properties, and application archives to image location /u01/wdt/models.  When the command succeeds, it should end with output like:\\n[INFO ] Build successful. Build time=36s. Image tag=model-in-image:WLS-v1 Also, if you run the docker images command, then you should see a Docker image named model-in-image:WLS-v1.\\nDeploy resources - Introduction In this section we will deploy our new image to namespace sample-domain1-ns, including the following steps:\\n Create a secret containing your WebLogic administrator user name and password. Create a secret containing your Model in Image runtime encryption password:  All Model in Image domains must supply a runtime encryption secret with a password value. It is used to encrypt configuration that is passed around internally by the operator. The value must be kept private but can be arbitrary; you can optionally supply a different secret value every time you restart the domain.   If your domain type is JRF, create secrets containing your RCU access URL, credentials, and prefix. Deploy a domain resource YAML file that references the new image. Wait for the domain\\u0026rsquo;s pods to start and reach their ready state.  Secrets First, create the secrets needed by both WLS and JRF type model domains. In this case, we have two secrets.\\nRun the following kubectl commands to deploy the required secrets:\\n$ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-weblogic-credentials \\\\ --from-literal=username=weblogic --from-literal=password=welcome1 $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-weblogic-credentials \\\\ weblogic.domainUID=sample-domain1 $ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-runtime-encryption-secret \\\\ --from-literal=password=my_runtime_password $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-runtime-encryption-secret \\\\ weblogic.domainUID=sample-domain1 Some important details about these secrets:\\n  The WebLogic credentials secret:\\n It is required and must contain username and password fields. It must be referenced by the spec.weblogicCredentialsSecret field in your domain resource. It also must be referenced by macros in the domainInfo.AdminUserName and domainInfo.AdminPassWord fields in your model YAML file.    The Model WDT runtime secret:\\n This is a special secret required by Model in Image. It must contain a password field. It must be referenced using the spec.model.runtimeEncryptionSecret attribute in its domain resource. It must remain the same for as long as the domain is deployed to Kubernetes, but can be changed between deployments. It is used to encrypt data as it\\u0026rsquo;s internally passed using log files from the domain\\u0026rsquo;s introspector job and on to its WebLogic Server pods.    Deleting and recreating the secrets:\\n We delete a secret before creating it, otherwise the create command will fail if the secret already exists. This allows us to change the secret when using the kubectl create secret command.    We name and label secrets using their associated domain UID for two reasons:\\n To make it obvious which secrets belong to which domains. To make it easier to clean up a domain. Typical cleanup scripts use the weblogic.domainUID label as a convenience for finding all resources associated with a domain.    If you\\u0026rsquo;re following the JRF path through the sample, then you also need to deploy the additional secret referenced by macros in the JRF model RCUDbInfo clause, plus an OPSS wallet password secret. For details about the uses of these secrets, see the Model in Image user documentation.\\n  Click here for the commands for deploying additional secrets for JRF.   $ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-rcu-access \\\\ --from-literal=rcu_prefix=FMW1 \\\\ --from-literal=rcu_schema_password=Oradoc_db1 \\\\ --from-literal=rcu_db_conn_string=oracle-db.default.svc.cluster.local:1521/devpdb.k8s $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-rcu-access \\\\ weblogic.domainUID=sample-domain1 $ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-opss-wallet-password-secret \\\\ --from-literal=walletPassword=welcome1 $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-opss-wallet-password-secret \\\\ weblogic.domainUID=sample-domain1    Domain resource Now let\\u0026rsquo;s create a domain resource. A domain resource is the key resource that tells the operator how to deploy a WebLogic domain.\\nCopy the following to a file called /tmp/mii-sample/mii-initial.yaml or similar, or use the file /tmp/mii-sample/domain-resources/WLS/mii-initial-d1-WLS-v1.yaml that is included in the sample source.\\n  Click here to expand the WLS domain resource YAML.    # # This is an example of how to define a Domain resource. # # If you are using 3.0.0-rc1, then the version on the following line # should be `v7` not `v6`. apiVersion: \\u0026quot;weblogic.oracle/v6\\u0026quot; kind: Domain metadata: name: sample-domain1 namespace: sample-domain1-ns labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: sample-domain1 spec: # Set to 'FromModel' to indicate 'Model in Image'. domainHomeSourceType: FromModel # The WebLogic Domain Home, this must be a location within # the image for 'Model in Image' domains. domainHome: /u01/domains/sample-domain1 # The WebLogic Server Docker image that the Operator uses to start the domain image: \\u0026quot;model-in-image:WLS-v1\\u0026quot; # Defaults to \\u0026quot;Always\\u0026quot; if image tag (version) is ':latest' imagePullPolicy: \\u0026quot;IfNotPresent\\u0026quot; # Identify which Secret contains the credentials for pulling an image #imagePullSecrets: #- name: regsecret # Identify which Secret contains the WebLogic Admin credentials, # the secret must contain 'username' and 'password' fields. webLogicCredentialsSecret: name: sample-domain1-weblogic-credentials # Whether to include the WebLogic server stdout in the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable overriding your log file location, see also 'logHome' #logHomeEnabled: false # The location for domain log, server logs, server out, and Node Manager log files # see also 'logHomeEnabled', 'volumes', and 'volumeMounts'. #logHome: /shared/logs/sample-domain1 # Set which WebLogic servers the Operator will start # - \\u0026quot;NEVER\\u0026quot; will not start any server in the domain # - \\u0026quot;ADMIN_ONLY\\u0026quot; will start up only the administration server (no managed servers will be started) # - \\u0026quot;IF_NEEDED\\u0026quot; will start all non-clustered servers, including the administration server, and clustered servers up to their replica count. serverStartPolicy: \\u0026quot;IF_NEEDED\\u0026quot; # Settings for all server pods in the domain including the introspector job pod serverPod: # Optional new or overridden environment variables for the domain's pods # - This sample uses CUSTOM_DOMAIN_NAME in its image model file # to set the Weblogic domain name env: - name: CUSTOM_DOMAIN_NAME value: \\u0026quot;domain1\\u0026quot; - name: JAVA_OPTIONS value: \\u0026quot;-Dweblogic.StdoutDebugEnabled=false\\u0026quot; - name: USER_MEM_ARGS value: \\u0026quot;-XX:+UseContainerSupport -Djava.security.egd=file:/dev/./urandom \\u0026quot; # Optional volumes and mounts for the domain's pods. See also 'logHome'. #volumes: #- name: weblogic-domain-storage-volume # persistentVolumeClaim: # claimName: sample-domain1-weblogic-sample-pvc #volumeMounts: #- mountPath: /shared # name: weblogic-domain-storage-volume # The desired behavior for starting the domain's administration server. adminServer: # The serverStartState legal values are \\u0026quot;RUNNING\\u0026quot; or \\u0026quot;ADMIN\\u0026quot; # \\u0026quot;RUNNING\\u0026quot; means the listed server will be started up to \\u0026quot;RUNNING\\u0026quot; mode # \\u0026quot;ADMIN\\u0026quot; means the listed server will be start up to \\u0026quot;ADMIN\\u0026quot; mode serverStartState: \\u0026quot;RUNNING\\u0026quot; # Setup a Kubernetes node port for the administration server default channel #adminService: # channels: # - channelName: default # nodePort: 30701 # The number of managed servers to start for unlisted clusters replicas: 1 # The desired behavior for starting a specific cluster's member servers clusters: - clusterName: cluster-1 serverStartState: \\u0026quot;RUNNING\\u0026quot; replicas: 2 # Change the `restartVersion` to force the introspector job to rerun # and apply any new model configuration, to also force a subsequent # roll of your domain's WebLogic pods. restartVersion: '1' configuration: # Settings for domainHomeSourceType 'FromModel' model: # Valid model domain types are 'WLS', 'JRF', and 'RestrictedJRF', default is 'WLS' domainType: \\u0026quot;WLS\\u0026quot; # Optional configmap for additional models and variable files #configMap: sample-domain1-wdt-config-map # All 'FromModel' domains require a runtimeEncryptionSecret with a 'password' field runtimeEncryptionSecret: sample-domain1-runtime-encryption-secret # Secrets that are referenced by model yaml macros # (the model yaml in the optional configMap or in the image) #secrets: #- sample-domain1-datasource-secret      Click here to expand the JRF domain resource YAML.   # Copyright (c) 2020, Oracle Corporation and/or its affiliates. # Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl. # # This is an example of how to define a Domain resource. # # If you are using 3.0.0-rc1, then the version on the following line # should be `v7` not `v6`. apiVersion: \\u0026quot;weblogic.oracle/v6\\u0026quot; kind: Domain metadata: name: sample-domain1 namespace: sample-domain1-ns labels: weblogic.resourceVersion: domain-v2 weblogic.domainUID: sample-domain1 spec: # Set to 'FromModel' to indicate 'Model in Image'. domainHomeSourceType: FromModel # The WebLogic Domain Home, this must be a location within # the image for 'Model in Image' domains. domainHome: /u01/domains/sample-domain1 # The WebLogic Server Docker image that the Operator uses to start the domain image: \\u0026quot;model-in-image:JRF-v1\\u0026quot; # Defaults to \\u0026quot;Always\\u0026quot; if image tag (version) is ':latest' imagePullPolicy: \\u0026quot;IfNotPresent\\u0026quot; # Identify which Secret contains the credentials for pulling an image #imagePullSecrets: #- name: regsecret # Identify which Secret contains the WebLogic Admin credentials, # the secret must contain 'username' and 'password' fields. webLogicCredentialsSecret: name: sample-domain1-weblogic-credentials # Whether to include the WebLogic server stdout in the pod's stdout, default is true includeServerOutInPodLog: true # Whether to enable overriding your log file location, see also 'logHome' #logHomeEnabled: false # The location for domain log, server logs, server out, and Node Manager log files # see also 'logHomeEnabled', 'volumes', and 'volumeMounts'. #logHome: /shared/logs/sample-domain1 # Set which WebLogic servers the Operator will start # - \\u0026quot;NEVER\\u0026quot; will not start any server in the domain # - \\u0026quot;ADMIN_ONLY\\u0026quot; will start up only the administration server (no managed servers will be started) # - \\u0026quot;IF_NEEDED\\u0026quot; will start all non-clustered servers, including the administration server, and clustered servers up to their replica count. serverStartPolicy: \\u0026quot;IF_NEEDED\\u0026quot; # Settings for all server pods in the domain including the introspector job pod serverPod: # Optional new or overridden environment variables for the domain's pods # - This sample uses CUSTOM_DOMAIN_NAME in its image model file # to set the Weblogic domain name env: - name: CUSTOM_DOMAIN_NAME value: \\u0026quot;domain1\\u0026quot; - name: JAVA_OPTIONS value: \\u0026quot;-Dweblogic.StdoutDebugEnabled=false\\u0026quot; - name: USER_MEM_ARGS value: \\u0026quot;-XX:+UseContainerSupport -Djava.security.egd=file:/dev/./urandom \\u0026quot; # Optional volumes and mounts for the domain's pods. See also 'logHome'. #volumes: #- name: weblogic-domain-storage-volume # persistentVolumeClaim: # claimName: sample-domain1-weblogic-sample-pvc #volumeMounts: #- mountPath: /shared # name: weblogic-domain-storage-volume # The desired behavior for starting the domain's administration server. adminServer: # The serverStartState legal values are \\u0026quot;RUNNING\\u0026quot; or \\u0026quot;ADMIN\\u0026quot; # \\u0026quot;RUNNING\\u0026quot; means the listed server will be started up to \\u0026quot;RUNNING\\u0026quot; mode # \\u0026quot;ADMIN\\u0026quot; means the listed server will be start up to \\u0026quot;ADMIN\\u0026quot; mode serverStartState: \\u0026quot;RUNNING\\u0026quot; # Setup a Kubernetes node port for the administration server default channel #adminService: # channels: # - channelName: default # nodePort: 30701 # The number of managed servers to start for unlisted clusters replicas: 1 # The desired behavior for starting a specific cluster's member servers clusters: - clusterName: cluster-1 serverStartState: \\u0026quot;RUNNING\\u0026quot; replicas: 2 # Change the restartVersion to force the introspector job to rerun # and apply any new model configuration, to also force a subsequent # roll of your domain's WebLogic pods. restartVersion: '1' configuration: # Settings for domainHomeSourceType 'FromModel' model: # Valid model domain types are 'WLS', 'JRF', and 'RestrictedJRF', default is 'WLS' domainType: \\u0026quot;JRF\\u0026quot; # Optional configmap for additional models and variable files #configMap: sample-domain1-wdt-config-map # All 'FromModel' domains require a runtimeEncryptionSecret with a 'password' field runtimeEncryptionSecret: sample-domain1-runtime-encryption-secret # Secrets that are referenced by model yaml macros # (the model yaml in the optional configMap or in the image) secrets: #- sample-domain1-datasource-secret - sample-domain1-rcu-access # Increase the introspector job active timeout value for JRF use cases introspectorJobActiveDeadlineSeconds: 300 opss: # Name of secret with walletPassword for extracting the wallet, used for JRF domains walletPasswordSecret: sample-domain1-opss-wallet-password-secret # Name of secret with walletFile containing base64 encoded opss wallet, used for JRF domains #walletFileSecret: sample-domain1-opss-walletfile-secret    Run the following command to create the domain custom resource:\\n$ kubectl apply -f /tmp/mii-sample/domain-resources/WLS/mii-initial-d1-WLS-v1.yaml  Note: If you are choosing not to use the predefined domain resource YAML file and instead created your own domain resource file earlier, then substitute your custom file name in the above command. You might recall that we suggested naming it /tmp/mii-sample/mii-initial.yaml.\\n If you run kubectl get pods -n sample-domain1-ns --watch, then you should see the introspector job run and your WebLogic Server pods start. The output should look something like this:\\n  Click here to expand.   $ kubectl get pods -n sample-domain1-ns --watch NAME READY STATUS RESTARTS AGE sample-domain1-introspect-domain-job-lqqj9 0/1 Pending 0 0s sample-domain1-introspect-domain-job-lqqj9 0/1 ContainerCreating 0 0s sample-domain1-introspect-domain-job-lqqj9 1/1 Running 0 1s sample-domain1-introspect-domain-job-lqqj9 0/1 Completed 0 65s sample-domain1-introspect-domain-job-lqqj9 0/1 Terminating 0 65s sample-domain1-admin-server 0/1 Pending 0 0s sample-domain1-admin-server 0/1 ContainerCreating 0 0s sample-domain1-admin-server 0/1 Running 0 1s sample-domain1-admin-server 1/1 Running 0 32s sample-domain1-managed-server1 0/1 Pending 0 0s sample-domain1-managed-server2 0/1 Pending 0 0s sample-domain1-managed-server1 0/1 ContainerCreating 0 0s sample-domain1-managed-server2 0/1 ContainerCreating 0 0s sample-domain1-managed-server1 0/1 Running 0 2s sample-domain1-managed-server2 0/1 Running 0 2s sample-domain1-managed-server1 1/1 Running 0 43s sample-domain1-managed-server2 1/1 Running 0 42s    Alternatively, you can run /tmp/mii-sample/utils/wl-pod-wait.sh -p 3. This is a utility script that provides useful information about a domain\\u0026rsquo;s pods and waits for them to reach a ready state, reach their target restartVersion, and reach their target image before exiting.\\n  Click here to expand the `wl-pod-wait.sh` usage.   $ ./wl-pod-wait.sh -? Usage: wl-pod-wait.sh [-n mynamespace] [-d mydomainuid] \\\\ [-p expected_pod_count] \\\\ [-t timeout_secs] \\\\ [-q] Exits non-zero if 'timeout_secs' is reached before 'pod_count' is reached. Parameters: -d \\u0026lt;domain_uid\\u0026gt; : Defaults to 'sample-domain1'. -n \\u0026lt;namespace\\u0026gt; : Defaults to 'sample-domain1-ns'. pod_count \\u0026gt; 0 : Wait until exactly 'pod_count' WebLogic server pods for a domain all (a) are ready, (b) have the same 'domainRestartVersion' label value as the current domain resource's 'spec.restartVersion, and (c) have the same image as the current domain resource's image. pod_count = 0 : Wait until there are no running WebLogic server pods for a domain. The default. -t \\u0026lt;timeout\\u0026gt; : Timeout in seconds. Defaults to '600'. -q : Quiet mode. Show only a count of wl pods that have reached the desired criteria. -? : This help.      Click here to expand sample output from `wl-pod-wait.sh`.   @@ [2020-04-30T13:50:42][seconds=0] Info: Waiting up to 600 seconds for exactly '3' WebLogic server pods to reach the following criteria: @@ [2020-04-30T13:50:42][seconds=0] Info: ready='true' @@ [2020-04-30T13:50:42][seconds=0] Info: image='model-in-image:WLS-v1' @@ [2020-04-30T13:50:42][seconds=0] Info: domainRestartVersion='1' @@ [2020-04-30T13:50:42][seconds=0] Info: namespace='sample-domain1-ns' @@ [2020-04-30T13:50:42][seconds=0] Info: domainUID='sample-domain1' @@ [2020-04-30T13:50:42][seconds=0] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:50:42][seconds=0] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----- ----- --------- 'sample-domain1-introspect-domain-job-rkdkg' '' '' '' 'Pending' @@ [2020-04-30T13:50:45][seconds=3] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:50:45][seconds=3] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----- ----- --------- 'sample-domain1-introspect-domain-job-rkdkg' '' '' '' 'Running' @@ [2020-04-30T13:51:50][seconds=68] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:51:50][seconds=68] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE ---- ------- ----- ----- ----- @@ [2020-04-30T13:51:59][seconds=77] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:51:59][seconds=77] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE ----------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'false' 'Pending' @@ [2020-04-30T13:52:02][seconds=80] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:52:02][seconds=80] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE ----------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'false' 'Running' @@ [2020-04-30T13:52:32][seconds=110] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:52:32][seconds=110] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'false' 'Pending' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'false' 'Pending' @@ [2020-04-30T13:52:34][seconds=112] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:52:34][seconds=112] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'false' 'Running' @@ [2020-04-30T13:53:14][seconds=152] Info: '3' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:53:14][seconds=152] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:53:14][seconds=152] Info: Success!    If you see an error, then consult Debugging in the Model in Image user guide.\\nInvoke the web application Now that all the initial use case resources have been deployed, you can invoke the sample web application through the Traefik ingress controller\\u0026rsquo;s NodePort. Note: The web application will display a list of any data sources it finds, but we don\\u0026rsquo;t expect it to find any because the model doesn\\u0026rsquo;t contain any at this point.\\nSend a web application request to the load balancer:\\n$ curl -s -S -m 10 -H 'host: sample-domain1-cluster-cluster-1.mii-sample.org' \\\\ http://localhost:30305/myapp_war/index.jsp Or, if Traefik is unavailable and your Administration Server pod is running, you can use kubectl exec:\\n$ kubectl exec -n sample-domain1-ns sample-domain1-admin-server -- bash -c \\\\ \\u0026quot;curl -s -S -m 10 http://sample-domain1-cluster-cluster-1:8001/myapp_war/index.jsp\\u0026quot; You should see output like the following:\\n$ curl -s -S -m 10 -H 'host: sample-domain1-cluster-cluster-1.mii-sample.org' \\\\ http://localhost:30305/myapp_war/index.jsp \\u0026lt;html\\u0026gt;\\u0026lt;body\\u0026gt;\\u0026lt;pre\\u0026gt; ***************************************************************** Hello World! This is version 'v1' of the mii-sample JSP web-app. Welcome to WebLogic server 'managed-server2'! domain UID = 'sample-domain1' domain name = 'domain1' Found 1 local cluster runtime: Cluster 'cluster-1' Found 0 local data sources: ***************************************************************** \\u0026lt;/pre\\u0026gt;\\u0026lt;/body\\u0026gt;\\u0026lt;/html\\u0026gt; Note: If you\\u0026rsquo;re running your curl commands on a remote machine, then substitute localhost with an external address suitable for contacting your Kubernetes cluster. A Kubernetes cluster address that often works can be obtained by using the address just after https:// in the KubeDNS line of the output from the kubectl cluster-info command.\\nIf you want to continue to the next use case, then leave your domain running.\\nUpdate1 use case This use case demonstrates dynamically adding a data source to your running domain. It demonstrates several features of WDT and Model in Image:\\n The syntax used for updating a model is exactly the same syntax you use for creating the original model. A domain\\u0026rsquo;s model can be updated dynamically by supplying a model update in a file in a Kubernetes ConfigMap. Model updates can be as simple as changing the value of a single attribute, or more complex, such as adding a JMS Server.  For a detailed discussion of model updates, see Runtime Updates in the Model in Image user guide.\\nThe operator does not support all possible dynamic model updates. For model update limitations, consult Runtime Updates in the Model in Image user docs, and carefully test any model update before attempting a dynamic update in production.\\n Here are the steps:\\n  Ensure that you have a running domain.\\nMake sure you have deployed the domain from the Initial use case.\\n  Create a data source model YAML file.\\nCreate a WDT model snippet for a data source (or use the example provided). Make sure that its target is set to cluster-1, and that its initial capacity is set to 0.\\nThe reason for the latter is to prevent the data source from causing a WebLogic Server startup failure if it can\\u0026rsquo;t find the database, which would be likely to happen because we haven\\u0026rsquo;t deployed one (unless you\\u0026rsquo;re using the JRF path through the sample).\\nHere\\u0026rsquo;s an example data source model configuration that meets these criteria:\\nresources: JDBCSystemResource: mynewdatasource: Target: 'cluster-1' JdbcResource: JDBCDataSourceParams: JNDIName: [ jdbc/mydatasource1, jdbc/mydatasource2 ] GlobalTransactionsProtocol: TwoPhaseCommit JDBCDriverParams: DriverName: oracle.jdbc.xa.client.OracleXADataSource URL: '@@SECRET:@@ENV:DOMAIN_UID@@-datasource-secret:url@@' PasswordEncrypted: '@@SECRET:@@ENV:DOMAIN_UID@@-datasource-secret:password@@' Properties: user: Value: 'sys as sysdba' oracle.net.CONNECT_TIMEOUT: Value: 5000 oracle.jdbc.ReadTimeout: Value: 30000 JDBCConnectionPoolParams: InitialCapacity: 0 MaxCapacity: 1 TestTableName: SQL ISVALID TestConnectionsOnReserve: true Place the above model snippet in a file named /tmp/mii-sample/mydatasource.yaml and then use it in the later step where we deploy the model ConfigMap, or alternatively, use the same data source that\\u0026rsquo;s provided in /tmp/mii-sample/model-configmaps/datasource/model.20.datasource.yaml.\\n  Create the data source secret.\\nThe data source references a new secret that needs to be created. Run the following commands to create the secret:\\n$ kubectl -n sample-domain1-ns create secret generic \\\\ sample-domain1-datasource-secret \\\\ --from-literal=password=Oradoc_db1 \\\\ --from-literal=url=jdbc:oracle:thin:@oracle-db.default.svc.cluster.local:1521/devpdb.k8s $ kubectl -n sample-domain1-ns label secret \\\\ sample-domain1-datasource-secret \\\\ weblogic.domainUID=sample-domain1 We name and label secrets using their associated domain UID for two reasons:\\n To make it obvious which secret belongs to which domains. To make it easier to clean up a domain. Typical cleanup scripts use the weblogic.domainUID label as a convenience for finding all the resources associated with a domain.    Create a ConfigMap with the WDT model that contains the data source definition.\\nRun the following commands:\\n$ kubectl -n sample-domain1-ns create configmap sample-domain1-wdt-config-map \\\\ --from-file=/tmp/mii-sample/model-configmaps/datasource $ kubectl -n sample-domain1-ns label configmap sample-domain1-wdt-config-map \\\\ weblogic.domainUID=sample-domain1  If you\\u0026rsquo;ve created your own data source file, then substitute the file name in the --from-file= parameter (we suggested /tmp/mii-sample/mydatasource.yaml earlier). Note that the -from-file= parameter can reference a single file, in which case it puts the designated file in the ConfigMap, or it can reference a directory, in which case it populates the ConfigMap with all of the files in the designated directory.  We name and label ConfigMap using their associated domain UID for two reasons:\\n To make it obvious which ConfigMap belong to which domains. To make it easier to cleanup a domain. Typical cleanup scripts use the weblogic.domainUID label as a convenience for finding all resources associated with a domain.    Update your domain resource to refer to the ConfigMap and secret.\\n  Option 1: Update your current domain resource file from the \\u0026ldquo;Initial\\u0026rdquo; use case.\\n  Add the secret to its spec.configuration.secrets stanza:\\nspec: ... configuration: ... secrets: - sample-domain1-datasource-secret (Leave any existing secrets in place.)\\n  Change its spec.configuration.model.configMap to look like:\\nspec: ... configuration: ... model: ... configMap: sample-domain1-wdt-config-map   Apply your changed domain resource:\\n$ kubectl apply -f your-domain-resource.yaml     Option 2: Use the updated domain resource file that is supplied with the sample:\\n$ kubectl apply -f /tmp/miisample/domain-resources/mii-update1-d1-WLS-v1-ds.yaml     Restart (\\u0026lsquo;roll\\u0026rsquo;) the domain.\\nNow that the data source is deployed in a ConfigMap and its secret is also deployed, and we have applied an updated domain resource with its spec.configuration.model.configMap and spec.configuration.secrets referencing the ConfigMap and secret, let\\u0026rsquo;s tell the operator to roll the domain.\\nWhen a model domain restarts, it will rerun its introspector job in order to regenerate its configuration, and it will also pass the configuration changes found by the introspector to each restarted server. One way to cause a running domain to restart is to change the domain\\u0026rsquo;s spec.restartVersion. To do this:\\n  Option 1: Edit your domain custom resource.\\n Call kubectl -n sample-domain1-ns edit domain sample-domain1. Edit the value of the spec.restartVersion field and save.  The field is a string; typically, you use a number in this field and increment it with each restart.      Option 2: Dynamically change your domain using kubectl patch.\\n  To get the current restartVersion call:\\n$ kubectl -n sample-domain1-ns get domain sample-domain1 '-o=jsonpath={.spec.restartVersion}'   Choose a new restart version that\\u0026rsquo;s different from the current restart version.\\n The field is a string; typically, you use a number in this field and increment it with each restart.    Use kubectl patch to set the new value. For example, assuming the new restart version is 2:\\n$ kubectl -n sample-domain1-ns patch domain sample-domain1 --type=json '-p=[{\\u0026quot;op\\u0026quot;: \\u0026quot;replace\\u0026quot;, \\u0026quot;path\\u0026quot;: \\u0026quot;/spec/restartVersion\\u0026quot;, \\u0026quot;value\\u0026quot;: \\u0026quot;2\\u0026quot; }]'     Option 3: Use the sample helper script.\\n Call /tmp/mii-sample/utils/patch-restart-version.sh -n sample-domain1-ns -d sample-domain1. This will perform the same kubectl get and kubectl patch commands as Option 2.      Wait for the roll to complete.\\nNow that you\\u0026rsquo;ve started a domain roll, you\\u0026rsquo;ll need to wait for it to complete if you want to verify that the data source was deployed.\\n  One way to do this is to call kubectl get pods -n sample-domain1-ns --watch and wait for the pods to cycle back to their ready state.\\n  Alternatively, you can run /tmp/mii-sample/utils/wl-pod-wait.sh -p 3. This is a utility script that provides useful information about a domain\\u0026rsquo;s pods and waits for them to reach a ready state, reach their target restartVersion, and reach their target image before exiting.\\n  Click here to expand the `wl-pod-wait.sh` usage.    $ ./wl-pod-wait.sh -? Usage: wl-pod-wait.sh [-n mynamespace] [-d mydomainuid] \\\\ [-p expected_pod_count] \\\\ [-t timeout_secs] \\\\ [-q] Exits non-zero if 'timeout_secs' is reached before 'pod_count' is reached. Parameters: -d \\u0026lt;domain_uid\\u0026gt; : Defaults to 'sample-domain1'. -n \\u0026lt;namespace\\u0026gt; : Defaults to 'sample-domain1-ns'. pod_count \\u0026gt; 0 : Wait until exactly 'pod_count' WebLogic server pods for a domain all (a) are ready, (b) have the same 'domainRestartVersion' label value as the current domain resource's 'spec.restartVersion, and (c) have the same image as the current domain resource's image. pod_count = 0 : Wait until there are no running WebLogic server pods for a domain. The default. -t \\u0026lt;timeout\\u0026gt; : Timeout in seconds. Defaults to '600'. -q : Quiet mode. Show only a count of wl pods that have reached the desired criteria. -? : This help.      Click here to expand sample output from `wl-pod-wait.sh` that shows a rolling domain.    @@ [2020-04-30T13:53:19][seconds=0] Info: Waiting up to 600 seconds for exactly '3' WebLogic server pods to reach the following criteria: @@ [2020-04-30T13:53:19][seconds=0] Info: ready='true' @@ [2020-04-30T13:53:19][seconds=0] Info: image='model-in-image:WLS-v1' @@ [2020-04-30T13:53:19][seconds=0] Info: domainRestartVersion='2' @@ [2020-04-30T13:53:19][seconds=0] Info: namespace='sample-domain1-ns' @@ [2020-04-30T13:53:19][seconds=0] Info: domainUID='sample-domain1' @@ [2020-04-30T13:53:19][seconds=0] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:53:19][seconds=0] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-introspect-domain-job-wlkpr' '' '' '' 'Pending' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:53:20][seconds=1] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:53:20][seconds=1] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-introspect-domain-job-wlkpr' '' '' '' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:18][seconds=59] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:18][seconds=59] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------------------- ------- ----------------------- ------ ----------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-introspect-domain-job-wlkpr' '' '' '' 'Succeeded' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:19][seconds=60] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:19][seconds=60] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:31][seconds=72] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:31][seconds=72] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '1' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:40][seconds=81] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:40][seconds=81] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:52][seconds=93] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:52][seconds=93] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:54:58][seconds=99] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:54:58][seconds=99] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'false' 'Pending' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:00][seconds=101] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:00][seconds=101] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:12][seconds=113] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:12][seconds=113] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:24][seconds=125] Info: '0' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:24][seconds=125] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:33][seconds=134] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:33][seconds=134] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:34][seconds=135] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:34][seconds=135] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '1' 'model-in-image:WLS-v1' 'false' 'Pending' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:40][seconds=141] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:40][seconds=141] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:55:44][seconds=145] Info: '1' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:55:44][seconds=145] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'false' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:56:25][seconds=186] Info: '2' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:56:25][seconds=186] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:56:26][seconds=187] Info: '2' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:56:26][seconds=187] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '1' 'model-in-image:WLS-v1' 'false' 'Pending' @@ [2020-04-30T13:56:30][seconds=191] Info: '2' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:56:30][seconds=191] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:56:34][seconds=195] Info: '2' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:56:34][seconds=195] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------- --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '2' 'model-in-image:WLS-v1' 'false' 'Pending' @@ [2020-04-30T13:57:09][seconds=230] Info: '3' WebLogic pods currently match all criteria, expecting '3'. @@ [2020-04-30T13:57:09][seconds=230] Info: Introspector and WebLogic pods with same namespace and domain-uid: NAME VERSION IMAGE READY PHASE -------------------------------- ------- ----------------------- ------ --------- 'sample-domain1-admin-server' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server1' '2' 'model-in-image:WLS-v1' 'true' 'Running' 'sample-domain1-managed-server2' '2' 'model-in-image:WLS-v1' 'true' 'Running' @@ [2020-04-30T13:57:09][seconds=230] Info: Success!        After your domain is running, you can call the sample web application to determine if the data source was deployed.\\nSend a web application request to the ingress controller:\\n$ curl -s -S -m 10 -H 'host: sample-domain1-cluster-cluster-1.mii-sample.org' \\\\ http://localhost:30305/myapp_war/index.jsp Or, if Traefik is unavailable and your Administration Server pod is running, you can run kubectl exec:\\n$ kubectl exec -n sample-domain1-ns sample-domain1-admin-server -- bash -c \\\\ \\u0026quot;curl -s -S -m 10 http://sample-domain1-cluster-cluster-1:8001/myapp_war/index.jsp\\u0026quot; You should see something like the following:\\n  Click here to see the expected web application output.   $ curl -s -S -m 10 -H 'host: sample-domain1-cluster-cluster-1.mii-sample.org' \\\\ http://localhost:30305/myapp_war/index.jsp \\u0026lt;html\\u0026gt;\\u0026lt;body\\u0026gt;\\u0026lt;pre\\u0026gt; ***************************************************************** Hello World! This is version 'v1' of the mii-sample JSP web-app. Welcome to WebLogic server 'managed-server1'! domain UID = 'sample-domain1' domain name = 'domain1' Found 1 local cluster runtime: Cluster 'cluster-1' Found 1 local data source: Datasource 'mynewdatasource': State='Running' ***************************************************************** \\u0026lt;/pre\\u0026gt;\\u0026lt;/body\\u0026gt;\\u0026lt;/html\\u0026gt;      If you see an error, then consult Debugging in the Model in Image user guide.\\nThis completes the sample scenarios.\\nCleanup To remove the resources you have created in these samples:\\n  Delete the domain resources.\\n$ /tmp/operator-source/kubernetes/samples/scripts/delete-domain/delete-weblogic-domain-resources.sh -d sample-domain1 $ /tmp/operator-source/kubernetes/samples/scripts/delete-domain/delete-weblogic-domain-resources.sh -d sample-domain2 This deletes the domain and any related resources that are labeled with the domain UID sample-domain1 and sample-domain2.\\nIt leaves the namespace intact, the operator running, the load balancer running (if installed), and the database running (if installed).\\n Note: When you delete a domain, the operator should detect your domain deletion and shut down its pods. Wait for these pods to exit before deleting the operator that monitors the sample-domain1-ns namespace. You can monitor this process using the command kubectl get pods -n sample-domain1-ns --watch (ctrl-c to exit).\\n   If you set up the Traefik ingress controller:\\n$ helm delete --purge traefik-operator $ kubectl delete namespace traefik   If you set up a database for JRF:\\n$ /tmp/operator-source/kubernetes/samples/scripts/create-oracle-db-service/stop-db-service.sh   Delete the operator and its namespace:\\n$ helm delete --purge sample-weblogic-operator $ kubectl delete namespace sample-weblogic-operator-ns   Delete the domain\\u0026rsquo;s namespace:\\n$ kubectl delete namespace sample-domain1-ns   Delete the images you may have created in this sample:\\n$ docker image rm model-in-image:WLS-v1 $ docker image rm model-in-image:WLS-v2 $ docker image rm model-in-image:JRF-v1 $ docker image rm model-in-image:JRF-v2   References For references to the relevant user documentation, see:\\n Model in Image user documentation Oracle WebLogic Server Deploy Tooling Oracle WebLogic Image Tool  \"", "originalCommit": "f13ab2e369955394eb412f31b8b5a4c6146bb571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}