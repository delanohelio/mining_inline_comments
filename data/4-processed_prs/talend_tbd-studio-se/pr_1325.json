{"pr_number": 1325, "pr_title": "patch(TPS-3778): Sqoop issue with parquet/avro format with HDP 2.6 (TBD-9956)", "pr_createdAt": "2020-03-20T09:37:44Z", "pr_url": "https://github.com/Talend/tbd-studio-se/pull/1325", "timeline": [{"oid": "73a87c4aef335583b7fa30c41e48c1bcfe3cc72e", "url": "https://github.com/Talend/tbd-studio-se/commit/73a87c4aef335583b7fa30c41e48c1bcfe3cc72e", "message": "fix(TPS-3778): fix dependency for tSqooImport", "committedDate": "2020-03-20T09:09:45Z", "type": "commit"}, {"oid": "5c1b4c8885fc25180991737626ce1436921e7f86", "url": "https://github.com/Talend/tbd-studio-se/commit/5c1b4c8885fc25180991737626ce1436921e7f86", "message": "fix(TBD-9956): Sqoop issue with parquet/avro format with HDP 2.6", "committedDate": "2020-03-20T09:30:01Z", "type": "commit"}, {"oid": "d9272fdd85c3f53d28340ccf5c34f8af7455c0fa", "url": "https://github.com/Talend/tbd-studio-se/commit/d9272fdd85c3f53d28340ccf5c34f8af7455c0fa", "message": "fix(TBD-9956): update hdpx 'build-in' (#1293)", "committedDate": "2020-03-20T09:30:36Z", "type": "commit"}, {"oid": "efccd2fe680dd89a86d639d4ae241679dbddbbe3", "url": "https://github.com/Talend/tbd-studio-se/commit/efccd2fe680dd89a86d639d4ae241679dbddbbe3", "message": "fix(TBD-9956): fix for avro format (#1307)", "committedDate": "2020-03-20T09:31:04Z", "type": "commit"}, {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3", "url": "https://github.com/Talend/tbd-studio-se/commit/631883aa4c7b0d837411dcc8ccbab278701c3fb3", "message": "fix(TBD-9956):Sqoop issue with Java API/parquet format/HDP 2.6 (#1313)", "committedDate": "2020-03-20T09:31:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NDU3Nw==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395544577", "bodyText": "I haven't seen such modifications in TBD-9956 related PRs", "author": "lbourgeois", "createdAt": "2020-03-20T10:19:35Z", "path": "main/plugins/org.talend.designer.components.bigdata/components/tSqoopImport/tSqoopImport_java.xml", "diffHunk": "@@ -1777,10 +1777,14 @@\n \t\t\t\tUrlPath=\"platform:/plugin/org.talend.libraries.hadoop.cloudera.cdh5/lib/avro-1.7.5-cdh5.0.4.jar\"\n \t\t\t\tREQUIRED_IF=\"(USE_JAVAAPI=='true' AND DB_VERSION=='APACHE_2_4_0_EMR') AND (DISTRIBUTION!='CUSTOM')\" />\n \n-\t\t\t<IMPORT NAME=\"avro-mapred-1.5.4.jar\" MODULE=\"avro-mapred-1.5.4.jar\"\n-\t\t\t\tUrlPath=\"platform:/plugin/org.talend.libraries.apache/lib/avro-mapred-1.5.4.jar\"\n-\t\t\t\tMVN=\"mvn:org.talend.libraries/avro-mapred-1.5.4/6.0.0\"\n+\t\t\t<IMPORT NAME=\"avro-mapred-1.8.1.jar\" MODULE=\"avro-mapred-1.8.1.jar\"", "originalCommit": "631883aa4c7b0d837411dcc8ccbab278701c3fb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNjcxOQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395616719", "bodyText": "Those changes are from TBD-10095. However, without them it might be lib conflict between  older version of avro-mapred (1.5.4) on the component side and newer one on distribution.\nI would include them if you don't mind, @lbourgeois ?", "author": "sponomarova", "createdAt": "2020-03-20T12:55:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NDU3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY1ODEzNQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395658135", "bodyText": "Agree", "author": "lbourgeois", "createdAt": "2020-03-20T14:04:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NDU3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NjIyNA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395546224", "bodyText": "Can you clarify why do we impact HBase in scope of this Sqoop fix. Havent seen such modifications in master PRs for TBD-9956", "author": "lbourgeois", "createdAt": "2020-03-20T10:22:53Z", "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java", "diffHunk": "@@ -1,117 +1,138 @@\n-// ============================================================================\r\n-//\r\n-// Copyright (C) 2006-2019 Talend Inc. - www.talend.com\r\n-//\r\n-// This source code is available under agreement available at\r\n-// %InstallDIR%\\features\\org.talend.rcp.branding.%PRODUCTNAME%\\%PRODUCTNAME%license.txt\r\n-//\r\n-// You should have received a copy of the agreement\r\n-// along with this program; if not, write to Talend SA\r\n-// 9 rue Pages 92150 Suresnes, France\r\n-//\r\n-// ============================================================================\r\n-package org.talend.hadoop.distribution.dynamic.template.modulegroup.hdp;\r\n-\r\n-import java.util.HashSet;\r\n-import java.util.Set;\r\n-\r\n-import org.apache.commons.lang.StringUtils;\r\n-import org.talend.hadoop.distribution.DistributionModuleGroup;\r\n-import org.talend.hadoop.distribution.ESparkVersion;\r\n-import org.talend.hadoop.distribution.condition.BasicExpression;\r\n-import org.talend.hadoop.distribution.condition.BooleanOperator;\r\n-import org.talend.hadoop.distribution.condition.ComponentCondition;\r\n-import org.talend.hadoop.distribution.condition.EqualityOperator;\r\n-import org.talend.hadoop.distribution.condition.MultiComponentCondition;\r\n-import org.talend.hadoop.distribution.condition.SimpleComponentCondition;\r\n-import org.talend.hadoop.distribution.constants.MRConstant;\r\n-import org.talend.hadoop.distribution.dynamic.adapter.DynamicPluginAdapter;\r\n-import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicModuleGroupConstant;\r\n-import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicSparkBatchModuleGroup;\r\n-\r\n-\r\n-/**\r\n- * DOC cmeng  class global comment. Detailled comment\r\n- */\r\n-public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGroup {\r\n-\r\n-    protected ComponentCondition conditionNotSpark16;\r\n-\r\n-    public DynamicHDPSparkBatchModuleGroup(DynamicPluginAdapter pluginAdapter) {\r\n-        super(pluginAdapter);\r\n-    }\r\n-\r\n-    @Override\r\n-    protected void initConditions() {\r\n-        super.initConditions();\r\n-        conditionNotSpark16 = new SimpleComponentCondition(\r\n-                new BasicExpression(\"SUPPORTED_SPARK_VERSION\", EqualityOperator.NOT_EQ, ESparkVersion.SPARK_1_6.getSparkVersion())); //$NON-NLS-1$\r\n-    }\r\n-\r\n-    @Override\r\n-    public Set<DistributionModuleGroup> getModuleGroups() throws Exception {\r\n-        Set<DistributionModuleGroup> moduleGroups = new HashSet<>();\r\n-        Set<DistributionModuleGroup> moduleGroupsFromSuper = super.getModuleGroups();\r\n-        if (moduleGroupsFromSuper != null && !moduleGroupsFromSuper.isEmpty()) {\r\n-            moduleGroups.addAll(moduleGroupsFromSuper);\r\n-        }\r\n-        DynamicPluginAdapter pluginAdapter = getPluginAdapter();\r\n-\r\n-        String spark2RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK2_MODULE_GROUP.getModuleName());\r\n-        String sparkMRRequiredRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK_MRREQUIRED_MODULE_GROUP.getModuleName());\r\n-        String hdfsRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_MODULE_GROUP.getModuleName());\r\n-        String hdfsNotSpark16RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\r\n-        String tezNotSpark16RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.TEZ_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\r\n-        String mapReduceRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.MAPREDUCE_MODULE_GROUP.getModuleName());\r\n-        String atlasSpark1RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_1_MODULE_GROUP.getModuleName());\r\n-        String atlasSpark2RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_2_MODULE_GROUP.getModuleName());\r\n-\r\n-        checkRuntimeId(spark2RuntimeId);\r\n-        checkRuntimeId(sparkMRRequiredRuntimeId);\r\n-        checkRuntimeId(hdfsRuntimeId);\r\n-        checkRuntimeId(hdfsNotSpark16RuntimeId);\r\n-        checkRuntimeId(tezNotSpark16RuntimeId);\r\n-        checkRuntimeId(mapReduceRuntimeId);\r\n-        checkRuntimeId(atlasSpark1RuntimeId);\r\n-        checkRuntimeId(atlasSpark2RuntimeId);\r\n-\r\n-        ComponentCondition useAtlas = new SimpleComponentCondition(new BasicExpression(MRConstant.USE_ATLAS));\r\n-        ComponentCondition atlasSpark1x = new MultiComponentCondition(useAtlas, BooleanOperator.AND, conditionSpark1);\r\n-        ComponentCondition atlasSpark2x = new MultiComponentCondition(useAtlas, BooleanOperator.AND, conditionSpark2);\r\n-\r\n-        if (StringUtils.isNotBlank(sparkMRRequiredRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(sparkMRRequiredRuntimeId, true, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(sparkMRRequiredRuntimeId, true, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(hdfsRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsRuntimeId, false, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsRuntimeId, false, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(hdfsNotSpark16RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsNotSpark16RuntimeId, false, conditionNotSpark16));\r\n-        }\r\n-        if (StringUtils.isNotBlank(tezNotSpark16RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(tezNotSpark16RuntimeId, false, conditionNotSpark16));\r\n-        }\r\n-        if (StringUtils.isNotBlank(mapReduceRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(mapReduceRuntimeId, false, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(mapReduceRuntimeId, false, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(atlasSpark1RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(atlasSpark1RuntimeId, true, atlasSpark1x));\r\n-        }\r\n-        if (StringUtils.isNotBlank(atlasSpark2RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(atlasSpark2RuntimeId, true, atlasSpark2x));\r\n-        }\r\n-\r\n-        return moduleGroups;\r\n-    }\r\n-}\r\n+// ============================================================================\n+//\n+// Copyright (C) 2006-2019 Talend Inc. - www.talend.com\n+//\n+// This source code is available under agreement available at\n+// %InstallDIR%\\features\\org.talend.rcp.branding.%PRODUCTNAME%\\%PRODUCTNAME%license.txt\n+//\n+// You should have received a copy of the agreement\n+// along with this program; if not, write to Talend SA\n+// 9 rue Pages 92150 Suresnes, France\n+//\n+// ============================================================================\n+package org.talend.hadoop.distribution.dynamic.template.modulegroup.hdp;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.talend.hadoop.distribution.DistributionModuleGroup;\n+import org.talend.hadoop.distribution.ESparkVersion;\n+import org.talend.hadoop.distribution.condition.BasicExpression;\n+import org.talend.hadoop.distribution.condition.BooleanOperator;\n+import org.talend.hadoop.distribution.condition.ComponentCondition;\n+import org.talend.hadoop.distribution.condition.EqualityOperator;\n+import org.talend.hadoop.distribution.condition.MultiComponentCondition;\n+import org.talend.hadoop.distribution.condition.SimpleComponentCondition;\n+import org.talend.hadoop.distribution.constants.MRConstant;\n+import org.talend.hadoop.distribution.dynamic.adapter.DynamicPluginAdapter;\n+import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicModuleGroupConstant;\n+import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicSparkBatchModuleGroup;\n+\n+\n+/**\n+ * DOC cmeng  class global comment. Detailled comment\n+ */\n+public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGroup {\n+\n+    protected ComponentCondition conditionNotSpark16;\n+\n+    public DynamicHDPSparkBatchModuleGroup(DynamicPluginAdapter pluginAdapter) {\n+        super(pluginAdapter);\n+    }\n+\n+    @Override\n+    protected void initConditions() {\n+        super.initConditions();\n+        conditionNotSpark16 = new SimpleComponentCondition(\n+                new BasicExpression(\"SUPPORTED_SPARK_VERSION\", EqualityOperator.NOT_EQ, ESparkVersion.SPARK_1_6.getSparkVersion())); //$NON-NLS-1$\n+    }\n+\n+    @Override\n+    public Set<DistributionModuleGroup> getModuleGroups() throws Exception {\n+        Set<DistributionModuleGroup> moduleGroups = new HashSet<>();\n+        Set<DistributionModuleGroup> moduleGroupsFromSuper = super.getModuleGroups();\n+        if (moduleGroupsFromSuper != null && !moduleGroupsFromSuper.isEmpty()) {\n+            moduleGroups.addAll(moduleGroupsFromSuper);\n+        }\n+        DynamicPluginAdapter pluginAdapter = getPluginAdapter();\n+\n+        String spark2RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK2_MODULE_GROUP.getModuleName());\n+        String sparkMRRequiredRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK_MRREQUIRED_MODULE_GROUP.getModuleName());\n+        String hdfsRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_MODULE_GROUP.getModuleName());\n+        String hdfsNotSpark16RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\n+        String tezNotSpark16RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.TEZ_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\n+        String mapReduceRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.MAPREDUCE_MODULE_GROUP.getModuleName());\n+        String atlasSpark1RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_1_MODULE_GROUP.getModuleName());\n+        String atlasSpark2RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_2_MODULE_GROUP.getModuleName());\n+        String sqoopRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_MODULE_GROUP.getModuleName());\n+        String sqoopParquetRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_PARQUET_MODULE_GROUP.getModuleName());\n+        String hBaseRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HBASE_MODULE_GROUP.getModuleName());", "originalCommit": "631883aa4c7b0d837411dcc8ccbab278701c3fb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNDk2NQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395614965", "bodyText": "hbase modifications shouldn't be here. Will revert that.", "author": "sponomarova", "createdAt": "2020-03-20T12:51:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NjIyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NzQwMA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395547400", "bodyText": "Why does this file appear all modified ?", "author": "lbourgeois", "createdAt": "2020-03-20T10:25:17Z", "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdpx/Hortonworks_HDP_2_6_0_3_8.json", "diffHunk": "@@ -0,0 +1,10537 @@\n+{", "originalCommit": "631883aa4c7b0d837411dcc8ccbab278701c3fb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNTYyNg==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395615626", "bodyText": "No, only part of this file but it was re-written when I did \"cherry-pick\". Maybe will revert that and apply changes manually.", "author": "sponomarova", "createdAt": "2020-03-20T12:53:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NzQwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY2NDA1MQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395664051", "bodyText": "Found the root cause : hdp2x folder in 7.2 was renamed hdpx in 7.3 (because it started to include hdp 3.1)", "author": "lbourgeois", "createdAt": "2020-03-20T14:14:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NzQwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY2NTYyNQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395665625", "bodyText": "This file should be moved to hdp2xx folder or deleted if modifications on hdp2xx folder already reported", "author": "lbourgeois", "createdAt": "2020-03-20T14:17:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NzQwMA=="}], "type": "inlineReview"}, {"oid": "94def8f3eb8ff0ae9c321df291f8b02924a2d172", "url": "https://github.com/Talend/tbd-studio-se/commit/94def8f3eb8ff0ae9c321df291f8b02924a2d172", "message": "fix(TBD-9956): add sqoop to DynamicHDPSparkBatchModuleGroup", "committedDate": "2020-03-20T13:18:42Z", "type": "commit"}, {"oid": "d1ddd4b76ab2a2a6a21ae74f30dff9dba8714fd0", "url": "https://github.com/Talend/tbd-studio-se/commit/d1ddd4b76ab2a2a6a21ae74f30dff9dba8714fd0", "message": "fix(TBD-9956): modify 'build-in' for hsp 2.6", "committedDate": "2020-03-20T13:42:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY2ODIwNw==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395668207", "bodyText": "this file should be moved to hdp2xx folder", "author": "lbourgeois", "createdAt": "2020-03-20T14:21:10Z", "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdpx/hdp2xxTemplate.json", "diffHunk": "@@ -0,0 +1,1460 @@\n+{", "originalCommit": "d1ddd4b76ab2a2a6a21ae74f30dff9dba8714fd0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "122a01be6c34380d89e170ef5ccd5e8312286654", "url": "https://github.com/Talend/tbd-studio-se/commit/122a01be6c34380d89e170ef5ccd5e8312286654", "message": "fix(TPS-3778): fix hdp 'build-in'/teplate location", "committedDate": "2020-03-20T14:55:42Z", "type": "commit"}, {"oid": "36bd57b5397cbe62881dd08804ba341ea4a89c36", "url": "https://github.com/Talend/tbd-studio-se/commit/36bd57b5397cbe62881dd08804ba341ea4a89c36", "message": "fix(TPS-3778): fix hdp", "committedDate": "2020-03-20T15:06:01Z", "type": "commit"}, {"oid": "ae6d8d479056c39adca0414725e6a2a0400a6d14", "url": "https://github.com/Talend/tbd-studio-se/commit/ae6d8d479056c39adca0414725e6a2a0400a6d14", "message": "fix(TPS-3778): modify template", "committedDate": "2020-03-20T15:25:08Z", "type": "commit"}, {"oid": "26e324c23abd1643fb467caf188dfd54832b09da", "url": "https://github.com/Talend/tbd-studio-se/commit/26e324c23abd1643fb467caf188dfd54832b09da", "message": "fix(TPS-3778): fix 'build-in'", "committedDate": "2020-03-20T15:35:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTk2MA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395751960", "bodyText": "I am not confident with those changes as I see that in master we have Spark 1.6 and 2.1 : https://github.com/Talend/tbd-studio-se/blob/master/main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdpx/hdp2xxTemplate.json#L14", "author": "lbourgeois", "createdAt": "2020-03-20T16:27:43Z", "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdp2xx/hdp2xxTemplate.json", "diffHunk": "@@ -1,489 +1,491 @@\n {\n-  \"id\": \"HDP2.X.X\",\n-  \"name\": \"Hortonworks HDP2.X.X template\",\n-  \"distribution\": \"HORTONWORKS\",\n-  \"templateId\": \"HDP2xxDistributionTemplate\",\n-  \"baseVersion\": \"2.5.0\",\n-  \"topVersion\": \"3.0.0\",\n-  \"dynamicVersion\": \"will be filled during runtime\",\n-  \"properties\": {\n-    \"context\": \"plugin:org.talend.hadoop.distribution.hdpx\"\n-  },\n-  \"description\": \"\",\n-  \"supportedSparkVersions\": [\n-    \"SPARK_1_6\",\n-    \"SPARK_2_1\"\n-  ],\n-  \"modules\": [\n-    {\n-      \"id\": \"commons-lang3-3.5\",\n-      \"type\": \"STANDARD\",\n-      \"context\": \"{properties.context}\",\n-      \"jarName\": \"commons-lang3-3.5.jar\",\n-      \"mvnUri\": \"mvn:org.talend.libraries/commons-lang3-3.5/6.2.0\",\n-      \"useStudioRepository\": \"true\",\n-      \"supportedSparkVersions\": [\n+\t\"id\": \"HDP2.X.X\",\n+\t\"name\": \"Hortonworks HDP2.X.X template\",\n+\t\"distribution\": \"HORTONWORKS\",\n+\t\"templateId\": \"HDP2xxDistributionTemplate\",\n+\t\"baseVersion\": \"2.5.0\",\n+\t\"topVersion\": \"3.0.3\",\n+\t\"dynamicVersion\": \"will be filled during runtime\",\n+\t\"properties\": {\n+\t\t\"context\": \"plugin:org.talend.hadoop.distribution.hdpx\"\n+\t},\n+\t\"description\": \"\",\n+\t\"supportedSparkVersions\": [\n+        \"SPARK_2_0\",", "originalCommit": "26e324c23abd1643fb467caf188dfd54832b09da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc2NDA0OQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395764049", "bodyText": "Agree. Not quite clear but that's how it is on patch/7.2.1 at the moment:\n\n  \n    \n      tbd-studio-se/main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdp2xx/hdp2xxTemplate.json\n    \n    \n         Line 14\n      in\n      8524abb\n    \n    \n    \n    \n\n        \n          \n           \"SPARK_2_0\",", "author": "sponomarova", "createdAt": "2020-03-20T16:47:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTk2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc3NzMxMA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395777310", "bodyText": "Indeed no reason to change that in scope of TBD-9956 but not clear why we have such diffs + official doc says 1.6 and 2.1 https://docs.cloudera.com/HDPDocuments/HDPforCloud/HDPforCloud-2.6.5/hdp-release-notes/content/hdp_comp_versions.html", "author": "lbourgeois", "createdAt": "2020-03-20T17:10:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTk2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc4MzM0Mg==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395783342", "bodyText": "Can't see addition of parquet-avro-1.4.1 added in https://github.com/Talend/tbd-studio-se/pull/1313/files", "author": "lbourgeois", "createdAt": "2020-03-20T17:21:33Z", "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdp2xx/Hortonworks_HDP_2_6_0_3_8.json", "diffHunk": "@@ -6380,6 +6380,18 @@\n         \"childNodes\" : [ ],", "originalCommit": "26e324c23abd1643fb467caf188dfd54832b09da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MTQzOA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395791438", "bodyText": "Not included for some reason. Will re-generate build-in.", "author": "sponomarova", "createdAt": "2020-03-20T17:36:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc4MzM0Mg=="}], "type": "inlineReview"}, {"oid": "ce0158e170f93e310a8fd19ee1d74f35a68e9bb3", "url": "https://github.com/Talend/tbd-studio-se/commit/ce0158e170f93e310a8fd19ee1d74f35a68e9bb3", "message": "fix(TPS-3778): fix 'build-in'", "committedDate": "2020-03-20T18:00:22Z", "type": "commit"}, {"oid": "f486addce932d408f75517c83ffb9c1d71aee378", "url": "https://github.com/Talend/tbd-studio-se/commit/f486addce932d408f75517c83ffb9c1d71aee378", "message": "TBD-10095: fixed (#1294)", "committedDate": "2020-03-26T23:55:25Z", "type": "commit"}, {"oid": "32e97637e1de2794acc6012b2d73ada763089f36", "url": "https://github.com/Talend/tbd-studio-se/commit/32e97637e1de2794acc6012b2d73ada763089f36", "message": "add Hadoop prop to avoid avro conflict", "committedDate": "2020-03-27T08:26:05Z", "type": "commit"}, {"oid": "3bf3e9f7b13b9da20936ebd69f3e7e9b6f12523f", "url": "https://github.com/Talend/tbd-studio-se/commit/3bf3e9f7b13b9da20936ebd69f3e7e9b6f12523f", "message": "change hadoop prop to support all cases", "committedDate": "2020-03-27T17:12:55Z", "type": "commit"}, {"oid": "34297fd1573495ca299acb23ac9912bd2a95c8e8", "url": "https://github.com/Talend/tbd-studio-se/commit/34297fd1573495ca299acb23ac9912bd2a95c8e8", "message": "Merge branch 'patch/7.2.1' of github.com:Talend/tbd-studio-se into fix/TPS-3778", "committedDate": "2020-03-27T17:19:04Z", "type": "commit"}]}