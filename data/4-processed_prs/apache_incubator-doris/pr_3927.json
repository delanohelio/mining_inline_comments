{"pr_number": 3927, "pr_title": "Add spark etl job main class", "pr_createdAt": "2020-06-22T17:57:17Z", "pr_url": "https://github.com/apache/incubator-doris/pull/3927", "timeline": [{"oid": "ca08acbe52b32611b9c3fc21b34acbf97af1175a", "url": "https://github.com/apache/incubator-doris/commit/ca08acbe52b32611b9c3fc21b34acbf97af1175a", "message": "Add spark etl job main class and remove DppResult comment", "committedDate": "2020-06-23T01:28:47Z", "type": "commit"}, {"oid": "ca08acbe52b32611b9c3fc21b34acbf97af1175a", "url": "https://github.com/apache/incubator-doris/commit/ca08acbe52b32611b9c3fc21b34acbf97af1175a", "message": "Add spark etl job main class and remove DppResult comment", "committedDate": "2020-06-23T01:28:47Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzkyNDI4MQ==", "url": "https://github.com/apache/incubator-doris/pull/3927#discussion_r443924281", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private void initHiveConfigs(Map<String, String> hiveProperties) {\n          \n          \n            \n                private void iniSparkConfigs(Map<String, String> sparkProperties) {", "author": "wangbo", "createdAt": "2020-06-23T02:21:38Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/SparkEtlJob.java", "diffHunk": "@@ -0,0 +1,241 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import org.apache.doris.load.loadv2.dpp.GlobalDictBuilder;\n+import org.apache.doris.load.loadv2.dpp.SparkDpp;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig.EtlColumn;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig.EtlColumnMapping;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig.EtlFileGroup;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig.EtlIndex;\n+import org.apache.doris.load.loadv2.etl.EtlJobConfig.EtlTable;\n+\n+import org.apache.commons.collections.map.MultiValueMap;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.functions;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import com.google.common.collect.Sets;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/**\n+ * SparkEtlJob is responsible for global dict building, data partition, data sort and data aggregation.\n+ * 1. init job config\n+ * 2. check if job has bitmap_dict function columns\n+ * 3. build global dict if step 2 is true\n+ * 4. dpp (data partition, data sort and data aggregation)\n+ */\n+public class SparkEtlJob {\n+    private static final Logger LOG = LogManager.getLogger(SparkEtlJob.class);\n+\n+    private static final String BITMAP_DICT_FUNC = \"bitmap_dict\";\n+    private static final String TO_BITMAP_FUNC = \"to_bitmap\";\n+\n+    private String jobConfigFilePath;\n+    private EtlJobConfig etlJobConfig;\n+    private Set<Long> hiveSourceTables;\n+    private Map<Long, Set<String>> tableToBitmapDictColumns;\n+    private SparkSession spark;\n+\n+    private SparkEtlJob(String jobConfigFilePath) {\n+        this.jobConfigFilePath = jobConfigFilePath;\n+        this.etlJobConfig = null;\n+        this.hiveSourceTables = Sets.newHashSet();\n+        this.tableToBitmapDictColumns = Maps.newHashMap();\n+    }\n+\n+    private void initSparkEnvironment() {\n+        spark = SparkSession.builder().enableHiveSupport().getOrCreate();\n+    }\n+\n+    private void initHiveConfigs(Map<String, String> hiveProperties) {", "originalCommit": "ca08acbe52b32611b9c3fc21b34acbf97af1175a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "939d4b7f8b833665c1b4928a1399f45ec0f7112c", "url": "https://github.com/apache/incubator-doris/commit/939d4b7f8b833665c1b4928a1399f45ec0f7112c", "message": "Using kryo serialization", "committedDate": "2020-06-23T02:36:39Z", "type": "commit"}, {"oid": "dcc40cececc49d5bd9bedb15485586dc81ed69ec", "url": "https://github.com/apache/incubator-doris/commit/dcc40cececc49d5bd9bedb15485586dc81ed69ec", "message": "Add spark.serializer conf", "committedDate": "2020-06-23T03:22:59Z", "type": "commit"}, {"oid": "1b1bd979d0b0535452f8c91c77f06ec5f8b86f20", "url": "https://github.com/apache/incubator-doris/commit/1b1bd979d0b0535452f8c91c77f06ec5f8b86f20", "message": "Add spark load persist log", "committedDate": "2020-06-23T04:31:35Z", "type": "commit"}, {"oid": "d7b70b1976412ec740d113dddf20a6931e41e9c3", "url": "https://github.com/apache/incubator-doris/commit/d7b70b1976412ec740d113dddf20a6931e41e9c3", "message": "Update get meta version func", "committedDate": "2020-06-23T04:36:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExNjEwMg==", "url": "https://github.com/apache/incubator-doris/pull/3927#discussion_r444116102", "bodyText": "Do not import static", "author": "morningman", "createdAt": "2020-06-23T10:14:47Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/BrokerLoadJob.java", "diffHunk": "@@ -17,6 +17,8 @@\n \n package org.apache.doris.load.loadv2;\n \n+import static org.apache.doris.common.DataQualityException.QUALITY_FAIL_MSG;", "originalCommit": "d7b70b1976412ec740d113dddf20a6931e41e9c3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b89fe3fcba33f1cf4d199bf3ac13c5e2464d741a", "url": "https://github.com/apache/incubator-doris/commit/b89fe3fcba33f1cf4d199bf3ac13c5e2464d741a", "message": "Update resource persist log and remove static import", "committedDate": "2020-06-23T11:00:55Z", "type": "commit"}, {"oid": "0b34a3914372fc0acc914cba3569830eed7fd03b", "url": "https://github.com/apache/incubator-doris/commit/0b34a3914372fc0acc914cba3569830eed7fd03b", "message": "Add ResourceOperationLog", "committedDate": "2020-06-23T11:04:57Z", "type": "commit"}, {"oid": "314473ec0b5c8ddff5335ee409115c78f5bf4b5c", "url": "https://github.com/apache/incubator-doris/commit/314473ec0b5c8ddff5335ee409115c78f5bf4b5c", "message": "Rename drop resource operation log", "committedDate": "2020-06-23T15:10:52Z", "type": "commit"}, {"oid": "b0c19d3b644f320be3ce82cd77bb08c87b522e16", "url": "https://github.com/apache/incubator-doris/commit/b0c19d3b644f320be3ce82cd77bb08c87b522e16", "message": "Fix bug", "committedDate": "2020-06-23T15:28:26Z", "type": "commit"}, {"oid": "b92182d3c75f9cdd60a6c56e9a744b4dc27bb90b", "url": "https://github.com/apache/incubator-doris/commit/b92182d3c75f9cdd60a6c56e9a744b4dc27bb90b", "message": "Fix push unique ptr bug", "committedDate": "2020-06-24T02:12:54Z", "type": "commit"}]}