{"pr_number": 4383, "pr_title": "[SparkLoad]Use the yarn command to get status and kill the application", "pr_createdAt": "2020-08-18T08:07:16Z", "pr_url": "https://github.com/apache/incubator-doris/pull/4383", "timeline": [{"oid": "9e3f0fedd25ea52eccdbb4eb1820a7753cb7a853", "url": "https://github.com/apache/incubator-doris/commit/9e3f0fedd25ea52eccdbb4eb1820a7753cb7a853", "message": "save code", "committedDate": "2020-08-17T13:29:37Z", "type": "commit"}, {"oid": "b806b0b93add0f96c2f85ad989fe12d9fe2c1113", "url": "https://github.com/apache/incubator-doris/commit/b806b0b93add0f96c2f85ad989fe12d9fe2c1113", "message": "save code", "committedDate": "2020-08-18T07:52:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MDc0NQ==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r472090745", "bodyText": "Preconditions.checkState(entry.size() <= 2, line);", "author": "morningman", "createdAt": "2020-08-18T10:55:03Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/YarnApplicationReport.java", "diffHunk": "@@ -0,0 +1,121 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import org.apache.doris.common.LoadException;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.collect.Maps;\n+\n+import org.apache.hadoop.yarn.api.records.ApplicationReport;\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n+import org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl;\n+import org.apache.hadoop.yarn.util.ConverterUtils;\n+\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Covert output string of command `yarn application -status` to application report.\n+ * Input sample:\n+ * -------------------\n+ * Application Report :\n+ * \tApplication-Id : application_1573630236805_6763648\n+ * \tApplication-Name : doris_label_test\n+ * \tApplication-Type : SPARK-2.4.1\n+ * \tUser : test\n+ * \tQueue : test-queue\n+ * \tStart-Time : 1597654469958\n+ * \tFinish-Time : 1597654801939\n+ * \tProgress : 100%\n+ * \tState : FINISHED\n+ * \tFinal-State : SUCCEEDED\n+ * \tTracking-URL : 127.0.0.1:8004/history/application_1573630236805_6763648/1\n+ * \tRPC Port : 40236\n+ * \tAM Host : host-name\n+ * \t------------------\n+ *\n+ * \tOutput:\n+ * \tApplicationReport\n+ */\n+public class YarnApplicationReport {\n+    private static final String APPLICATION_ID = \"Application-Id\";\n+    private static final String APPLICATION_TYPE = \"Application-Type\";\n+    private static final String APPLICATION_NAME = \"Application-Name\";\n+    private static final String USER = \"User\";\n+    private static final String QUEUE = \"Queue\";\n+    private static final String START_TIME = \"Start-Time\";\n+    private static final String FINISH_TIME = \"Finish-Time\";\n+    private static final String PROGRESS = \"Progress\";\n+    private static final String STATE = \"State\";\n+    private static final String FINAL_STATE = \"Final-State\";\n+    private static final String TRACKING_URL = \"Tracking-URL\";\n+    private static final String RPC_PORT = \"RPC Port\";\n+    private static final String AM_HOST = \"AM Host\";\n+    private static final String DIAGNOSTICS = \"Diagnostics\";\n+\n+    private ApplicationReport report;\n+\n+    public YarnApplicationReport(String output) throws LoadException {\n+        this.report = new ApplicationReportPBImpl();\n+        parseFromOutput(output);\n+    }\n+\n+    public ApplicationReport getReport() {\n+        return report;\n+    }\n+\n+    private void parseFromOutput(String output) throws LoadException {\n+        Map<String, String> reportMap = Maps.newHashMap();\n+        List<String> lines = Splitter.onPattern(\"\\n\").trimResults().splitToList(output);\n+        // Application-Id : application_1573630236805_6763648 ==> (Application-Id, application_1573630236805_6763648)\n+        for (String line : lines) {\n+            List<String> entry = Splitter.onPattern(\":\").limit(2).trimResults().splitToList(line);\n+            Preconditions.checkState(entry.size() <= 2);", "originalCommit": "b806b0b93add0f96c2f85ad989fe12d9fe2c1113", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjcxNQ==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r472836715", "bodyText": "changed", "author": "xy720", "createdAt": "2020-08-19T08:05:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA5MDc0NQ=="}], "type": "inlineReview"}, {"oid": "6ea1493fa405059ba4a1dce8f0574326e25e7c61", "url": "https://github.com/apache/incubator-doris/commit/6ea1493fa405059ba4a1dce8f0574326e25e7c61", "message": "add ut", "committedDate": "2020-08-19T08:03:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzUxNjA3NA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r473516074", "bodyText": "immutable", "author": "morningman", "createdAt": "2020-08-20T01:36:50Z", "path": "fe/fe-core/src/main/java/org/apache/doris/common/Config.java", "diffHunk": "@@ -543,6 +543,15 @@\n     @ConfField\n     public static String spark_resource_path = \"\";\n \n+    /**\n+     * Default yarn client path\n+     */\n+    @ConfField(mutable = true, masterOnly = true)", "originalCommit": "6ea1493fa405059ba4a1dce8f0574326e25e7c61", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzUxNzI0OA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r473517248", "bodyText": "Better to create a function called getYarnClienthPath() and check if the binary file exist in that function.", "author": "morningman", "createdAt": "2020-08-20T01:38:32Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "diffHunk": "@@ -262,19 +273,22 @@ public EtlStatus getEtlJobStatus(SparkAppHandle handle, String appId, long loadJ\n         return status;\n     }\n \n-    public void killEtlJob(SparkAppHandle handle, String appId, long loadJobId, SparkResource resource) {\n+    public void killEtlJob(SparkAppHandle handle, String appId, long loadJobId, SparkResource resource) throws LoadException {\n         if (resource.isYarnMaster()) {\n             Preconditions.checkNotNull(appId);\n-            YarnClient client = startYarnClient(resource);\n-            try {\n-                try {\n-                    client.killApplication(ConverterUtils.toApplicationId(appId));\n-                    LOG.info(\"yarn application -kill {}\", appId);\n-                } catch (YarnException | IOException e) {\n-                    LOG.warn(\"yarn application kill failed. app id: {}, load job id: {}\", appId, loadJobId, e);\n-                }\n-            } finally {\n-                stopYarnClient(client);\n+            // prepare yarn config\n+            String configDir = resource.prepareYarnConfig();\n+            // yarn client path\n+            String yarnClient = Config.yarn_client_path;", "originalCommit": "6ea1493fa405059ba4a1dce8f0574326e25e7c61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE1MjQxNA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477152414", "bodyText": "ok", "author": "xy720", "createdAt": "2020-08-26T09:10:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzUxNzI0OA=="}], "type": "inlineReview"}, {"oid": "c7f00c00bd736231392289d8db7712a86114f068", "url": "https://github.com/apache/incubator-doris/commit/c7f00c00bd736231392289d8db7712a86114f068", "message": "save code", "committedDate": "2020-08-25T10:26:08Z", "type": "commit"}, {"oid": "635e1152170e14daec5170b79607beb3f93a6d97", "url": "https://github.com/apache/incubator-doris/commit/635e1152170e14daec5170b79607beb3f93a6d97", "message": "license", "committedDate": "2020-08-25T10:36:35Z", "type": "commit"}, {"oid": "1eb1a7143a58f5257066180a7f036b7ad54917a3", "url": "https://github.com/apache/incubator-doris/commit/1eb1a7143a58f5257066180a7f036b7ad54917a3", "message": "save code", "committedDate": "2020-08-25T10:49:34Z", "type": "commit"}, {"oid": "f85f6926f33caf0b0297180466ec98b5ff8176e0", "url": "https://github.com/apache/incubator-doris/commit/f85f6926f33caf0b0297180466ec98b5ff8176e0", "message": "save code", "committedDate": "2020-08-25T11:06:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ0NjQwNg==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r476446406", "bodyText": "Remove unused code", "author": "morningman", "createdAt": "2020-08-25T13:26:26Z", "path": "fe/fe-core/src/test/java/org/apache/doris/load/loadv2/SparkEtlJobHandlerTest.java", "diffHunk": "@@ -95,94 +132,103 @@ public void setUp() {\n                 .SparkLibrary(\"\", \"\", SparkRepository.SparkLibrary.LibType.SPARK2X, 0L));\n     }\n \n-    @Test\n-    public void testSubmitEtlJob(@Mocked BrokerUtil brokerUtil, @Mocked SparkLauncher launcher,\n-                                 @Injectable SparkAppHandle handle) throws IOException, LoadException {\n-        new Expectations() {\n-            {\n-                launcher.startApplication((SparkAppHandle.Listener) any);\n-                result = handle;\n-                handle.getAppId();\n-                returns(null, null, appId);\n-                handle.getState();\n-                returns(State.CONNECTED, State.SUBMITTED, State.RUNNING);\n-            }\n-        };\n-\n-        EtlJobConfig etlJobConfig = new EtlJobConfig(Maps.newHashMap(), etlOutputPath, label, null);\n-        SparkResource resource = new SparkResource(resourceName);\n-        new Expectations(resource) {\n-            {\n-                resource.prepareArchive();\n-                result = archive;\n-            }\n-        };\n+//    @Test", "originalCommit": "f85f6926f33caf0b0297180466ec98b5ff8176e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ0NjU0Mg==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r476446542", "bodyText": "Remove unused code", "author": "morningman", "createdAt": "2020-08-25T13:26:38Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "diffHunk": "@@ -140,93 +136,96 @@ public void submitEtlJob(long loadJobId, String loadLabel, EtlJobConfig etlJobCo\n                 .setAppName(String.format(ETL_JOB_NAME, loadLabel))\n                 .setSparkHome(sparkHome)\n                 .addAppArgs(jobConfigHdfsPath)\n-                .redirectError()\n-                .redirectOutput(new File(Config.sys_log_dir + \"/spark-submitter.log\"));\n+                .redirectError();\n+                //.redirectOutput(new File(Config.sys_log_dir + \"/spark-submitter.log\"));", "originalCommit": "f85f6926f33caf0b0297180466ec98b5ff8176e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ1NDU1OA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r476454558", "bodyText": "How to make sure the process is still alive here?", "author": "morningman", "createdAt": "2020-08-25T13:37:45Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkLauncherMonitors.java", "diffHunk": "@@ -0,0 +1,216 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Strings;\n+\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+public class SparkLauncherMonitors {\n+    private static final Logger LOG = LogManager.getLogger(SparkLauncherMonitors.class);\n+    // 5min\n+    private static final long SUBMIT_APP_TIMEOUT_MS = 300 * 1000;\n+\n+    private LogMonitor logMonitor;\n+\n+    public static LogMonitor createLogMonitor(SparkLoadAppHandle handle) {\n+        return new LogMonitor(handle);\n+    }\n+\n+    private static SparkLoadAppHandle.State fromYarnState(YarnApplicationState yarnState) {\n+        switch (yarnState) {\n+            case SUBMITTED:\n+            case ACCEPTED:\n+                return SparkLoadAppHandle.State.SUBMITTED;\n+            case RUNNING:\n+                return SparkLoadAppHandle.State.RUNNING;\n+            case FINISHED:\n+                return SparkLoadAppHandle.State.FINISHED;\n+            case FAILED:\n+                return SparkLoadAppHandle.State.FAILED;\n+            case KILLED:\n+                return SparkLoadAppHandle.State.KILLED;\n+            default:\n+                // NEW NEW_SAVING\n+                return SparkLoadAppHandle.State.UNKNOWN;\n+        }\n+    }\n+\n+    public static class LogMonitor extends Thread {\n+        private final Process process;\n+        private SparkLoadAppHandle handle;\n+        private long submitTimeoutMs;\n+        private boolean isStop;\n+\n+        private static final String STATE = \"state\";\n+        private static final String QUEUE = \"queue\";\n+        private static final String START_TIME = \"start time\";\n+        private static final String FINAL_STATUS = \"final status\";\n+        private static final String URL = \"tracking URL\";\n+        private static final String USER = \"user\";\n+\n+        public LogMonitor(SparkLoadAppHandle handle) {\n+            this.handle = handle;\n+            this.process = handle.getProcess();\n+            this.isStop = false;\n+        }\n+\n+        public void setSubmitTimeoutMs(long submitTimeoutMs) {\n+            this.submitTimeoutMs = submitTimeoutMs;\n+        }\n+\n+        // Monitor the process's output\n+        @Override\n+        public void run() {\n+            BufferedReader outReader = null;\n+            String line = null;\n+            long startTime = System.currentTimeMillis();\n+            try {\n+                Preconditions.checkState(process.isAlive());", "originalCommit": "f85f6926f33caf0b0297180466ec98b5ff8176e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE1MjkwNw==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477152907", "bodyText": "No need to make sure the process is alive. We can get output even if the process is not alive.", "author": "xy720", "createdAt": "2020-08-26T09:11:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ1NDU1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ1NjA3Ng==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r476456076", "bodyText": "You can add an example output line here, so that the reviewer can know what the line looks like.", "author": "morningman", "createdAt": "2020-08-25T13:39:53Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkLauncherMonitors.java", "diffHunk": "@@ -0,0 +1,216 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Strings;\n+\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+public class SparkLauncherMonitors {\n+    private static final Logger LOG = LogManager.getLogger(SparkLauncherMonitors.class);\n+    // 5min\n+    private static final long SUBMIT_APP_TIMEOUT_MS = 300 * 1000;\n+\n+    private LogMonitor logMonitor;\n+\n+    public static LogMonitor createLogMonitor(SparkLoadAppHandle handle) {\n+        return new LogMonitor(handle);\n+    }\n+\n+    private static SparkLoadAppHandle.State fromYarnState(YarnApplicationState yarnState) {\n+        switch (yarnState) {\n+            case SUBMITTED:\n+            case ACCEPTED:\n+                return SparkLoadAppHandle.State.SUBMITTED;\n+            case RUNNING:\n+                return SparkLoadAppHandle.State.RUNNING;\n+            case FINISHED:\n+                return SparkLoadAppHandle.State.FINISHED;\n+            case FAILED:\n+                return SparkLoadAppHandle.State.FAILED;\n+            case KILLED:\n+                return SparkLoadAppHandle.State.KILLED;\n+            default:\n+                // NEW NEW_SAVING\n+                return SparkLoadAppHandle.State.UNKNOWN;\n+        }\n+    }\n+\n+    public static class LogMonitor extends Thread {\n+        private final Process process;\n+        private SparkLoadAppHandle handle;\n+        private long submitTimeoutMs;\n+        private boolean isStop;\n+\n+        private static final String STATE = \"state\";\n+        private static final String QUEUE = \"queue\";\n+        private static final String START_TIME = \"start time\";\n+        private static final String FINAL_STATUS = \"final status\";\n+        private static final String URL = \"tracking URL\";\n+        private static final String USER = \"user\";\n+\n+        public LogMonitor(SparkLoadAppHandle handle) {\n+            this.handle = handle;\n+            this.process = handle.getProcess();\n+            this.isStop = false;\n+        }\n+\n+        public void setSubmitTimeoutMs(long submitTimeoutMs) {\n+            this.submitTimeoutMs = submitTimeoutMs;\n+        }\n+\n+        // Monitor the process's output\n+        @Override\n+        public void run() {\n+            BufferedReader outReader = null;\n+            String line = null;\n+            long startTime = System.currentTimeMillis();\n+            try {\n+                Preconditions.checkState(process.isAlive());\n+                outReader = new BufferedReader(new InputStreamReader(process.getInputStream()));\n+                while (!isStop && (line = outReader.readLine()) != null) {\n+                    LOG.info(\"Monitor Log: \" + line);\n+                    // parse state and appId\n+                    if (line.contains(STATE)) {", "originalCommit": "f85f6926f33caf0b0297180466ec98b5ff8176e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE1MzE0OA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477153148", "bodyText": "done", "author": "xy720", "createdAt": "2020-08-26T09:11:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ1NjA3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ1ODU3NQ==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r476458575", "bodyText": "Add comment to explain the function of this class", "author": "morningman", "createdAt": "2020-08-25T13:43:24Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkLauncherMonitors.java", "diffHunk": "@@ -0,0 +1,216 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Strings;\n+\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+public class SparkLauncherMonitors {", "originalCommit": "f85f6926f33caf0b0297180466ec98b5ff8176e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ2NTE0Mg==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r476465142", "bodyText": "if the line contains \"STATE\", the while loop may be broken. So how to guarantee that this else if block can be ran?", "author": "morningman", "createdAt": "2020-08-25T13:52:07Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkLauncherMonitors.java", "diffHunk": "@@ -0,0 +1,216 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Strings;\n+\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+public class SparkLauncherMonitors {\n+    private static final Logger LOG = LogManager.getLogger(SparkLauncherMonitors.class);\n+    // 5min\n+    private static final long SUBMIT_APP_TIMEOUT_MS = 300 * 1000;\n+\n+    private LogMonitor logMonitor;\n+\n+    public static LogMonitor createLogMonitor(SparkLoadAppHandle handle) {\n+        return new LogMonitor(handle);\n+    }\n+\n+    private static SparkLoadAppHandle.State fromYarnState(YarnApplicationState yarnState) {\n+        switch (yarnState) {\n+            case SUBMITTED:\n+            case ACCEPTED:\n+                return SparkLoadAppHandle.State.SUBMITTED;\n+            case RUNNING:\n+                return SparkLoadAppHandle.State.RUNNING;\n+            case FINISHED:\n+                return SparkLoadAppHandle.State.FINISHED;\n+            case FAILED:\n+                return SparkLoadAppHandle.State.FAILED;\n+            case KILLED:\n+                return SparkLoadAppHandle.State.KILLED;\n+            default:\n+                // NEW NEW_SAVING\n+                return SparkLoadAppHandle.State.UNKNOWN;\n+        }\n+    }\n+\n+    public static class LogMonitor extends Thread {\n+        private final Process process;\n+        private SparkLoadAppHandle handle;\n+        private long submitTimeoutMs;\n+        private boolean isStop;\n+\n+        private static final String STATE = \"state\";\n+        private static final String QUEUE = \"queue\";\n+        private static final String START_TIME = \"start time\";\n+        private static final String FINAL_STATUS = \"final status\";\n+        private static final String URL = \"tracking URL\";\n+        private static final String USER = \"user\";\n+\n+        public LogMonitor(SparkLoadAppHandle handle) {\n+            this.handle = handle;\n+            this.process = handle.getProcess();\n+            this.isStop = false;\n+        }\n+\n+        public void setSubmitTimeoutMs(long submitTimeoutMs) {\n+            this.submitTimeoutMs = submitTimeoutMs;\n+        }\n+\n+        // Monitor the process's output\n+        @Override\n+        public void run() {\n+            BufferedReader outReader = null;\n+            String line = null;\n+            long startTime = System.currentTimeMillis();\n+            try {\n+                Preconditions.checkState(process.isAlive());\n+                outReader = new BufferedReader(new InputStreamReader(process.getInputStream()));\n+                while (!isStop && (line = outReader.readLine()) != null) {\n+                    LOG.info(\"Monitor Log: \" + line);\n+                    // parse state and appId\n+                    if (line.contains(STATE)) {\n+                        SparkLoadAppHandle.State oldState = handle.getState();\n+                        SparkLoadAppHandle.State newState = oldState;\n+                        // 1. state\n+                        String state = regexGetState(line);\n+                        if (state != null) {\n+                            YarnApplicationState yarnState = YarnApplicationState.valueOf(state);\n+                            newState = fromYarnState(yarnState);\n+                            if (newState != oldState) {\n+                                handle.setState(newState);\n+                            }\n+                        }\n+                        // 2. appId\n+                        String appId = regexGetAppId(line);\n+                        if (appId != null) {\n+                            if (!appId.equals(handle.getAppId())) {\n+                                handle.setAppId(appId);\n+                            }\n+                        }\n+\n+                        LOG.info(\"spark appId that handle get is {}, state: {}\", handle.getAppId(), handle.getState().toString());\n+                        switch (newState) {\n+                            case UNKNOWN:\n+                            case CONNECTED:\n+                            case SUBMITTED:\n+                                // If the app stays in the UNKNOWN/CONNECTED/SUBMITTED state for more than submitTimeoutMs\n+                                // stop monitoring and kill the process\n+                                if (System.currentTimeMillis() - startTime > submitTimeoutMs) {\n+                                    isStop = true;\n+                                    handle.kill();\n+                                }\n+                                break;\n+                            case RUNNING:\n+                            case FINISHED:\n+                                // There's no need to parse all logs of handle process to get all the information.\n+                                // As soon as the state changes to RUNNING/KILLED/FAILED/FINISHED/LOST,\n+                                // stop monitoring but keep the process alive.\n+                                isStop = true;\n+                                break;\n+                            case KILLED:\n+                            case FAILED:\n+                            case LOST:\n+                                // If the state changes to KILLED/FAILED/LOST,\n+                                // stop monitoring and kill the process\n+                                isStop = true;\n+                                handle.kill();\n+                                break;\n+                            default:\n+                                Preconditions.checkState(false, \"wrong spark app state\");\n+                        }\n+                    }\n+                    // parse other values\n+                    else if (line.contains(QUEUE) || line.contains(START_TIME) || line.contains(FINAL_STATUS) ||", "originalCommit": "f85f6926f33caf0b0297180466ec98b5ff8176e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE2NTIxMg==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477165212", "bodyText": "The state's changing follows the rule of\n\nsubmited > running > finished / failed\nsubmitted > killed\nsubmitted > running > killed\nNormally, the laucher will periodically print the queue\u3001start time\u3001final status\u3001tracking url\u3001user logs in state submitted/runnning. So in case 2, the else if block may still not be ran when the while loop be broken.\nBut it's not very terrible that this else if block not be ran, beacuse the necessary value we need only contains appId and state. In this case, queue\u3001start time\u3001final status\u3001tracking url\u3001user is just missing.", "author": "xy720", "createdAt": "2020-08-26T09:28:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ2NTE0Mg=="}], "type": "inlineReview"}, {"oid": "77deaef42479f84d2b3ee4240e541036996455c3", "url": "https://github.com/apache/incubator-doris/commit/77deaef42479f84d2b3ee4240e541036996455c3", "message": "add ut", "committedDate": "2020-08-26T09:08:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE1NzIwOQ==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477157209", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Map<String, String> sparkConfigs = Maps.newHashMap();\n          \n          \n            \n                    Map<String, String> sparkConfig = Maps.newHashMap();", "author": "wuyunfeng", "createdAt": "2020-08-26T09:16:21Z", "path": "fe/fe-core/src/main/java/org/apache/doris/catalog/SparkResource.java", "diffHunk": "@@ -243,6 +264,16 @@ protected void setProperties(Map<String, String> properties) throws DdlException\n         return sparkConfigs;\n     }\n \n+    private Map<String, String> getSparkHadoopConfigs(Map<String, String> properties) {\n+        Map<String, String> sparkConfigs = Maps.newHashMap();", "originalCommit": "77deaef42479f84d2b3ee4240e541036996455c3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE1OTE2MA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477159160", "bodyText": "Can you add some comment ?", "author": "wuyunfeng", "createdAt": "2020-08-26T09:17:58Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/ConfigFile.java", "diffHunk": "@@ -0,0 +1,25 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import org.apache.doris.common.LoadException;\n+\n+public interface ConfigFile {", "originalCommit": "77deaef42479f84d2b3ee4240e541036996455c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE4MjIwNA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477182204", "bodyText": "ok", "author": "xy720", "createdAt": "2020-08-26T09:56:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE1OTE2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE2MDQ5Mw==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477160493", "bodyText": "Maybe put statement Preconditions.checkState  outer the if statement?", "author": "wuyunfeng", "createdAt": "2020-08-26T09:20:15Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "diffHunk": "@@ -140,93 +137,98 @@ public void submitEtlJob(long loadJobId, String loadLabel, EtlJobConfig etlJobCo\n                 .setAppName(String.format(ETL_JOB_NAME, loadLabel))\n                 .setSparkHome(sparkHome)\n                 .addAppArgs(jobConfigHdfsPath)\n-                .redirectError()\n-                .redirectOutput(new File(Config.sys_log_dir + \"/spark-submitter.log\"));\n+                .redirectError();\n \n         // spark configs\n         for (Map.Entry<String, String> entry : resource.getSparkConfigs().entrySet()) {\n             launcher.setConf(entry.getKey(), entry.getValue());\n         }\n \n         // start app\n-        SparkAppHandle handle = null;\n+        SparkLoadAppHandle handle = null;\n         State state = null;\n         String appId = null;\n-        int retry = 0;\n         String errMsg = \"start spark app failed. error: \";\n         try {\n-            handle = launcher.startApplication(new SparkAppListener());\n+            Process process = launcher.launch();\n+            handle = new SparkLoadAppHandle(process);\n+            handle.addListener(new SparkAppListener());\n+            if (!FeConstants.runningUnitTest) {\n+                SparkLauncherMonitors.LogMonitor logMonitor = SparkLauncherMonitors.createLogMonitor(handle);\n+                logMonitor.setSubmitTimeoutMs(GET_APPID_TIMEOUT_MS);\n+                logMonitor.start();\n+                try {\n+                    logMonitor.join();\n+                } catch (InterruptedException e) {\n+                    logMonitor.interrupt();\n+                    throw new LoadException(errMsg + e.getMessage());\n+                }\n+            }\n+            appId = handle.getAppId();\n+            state = handle.getState();\n         } catch (IOException e) {\n             LOG.warn(errMsg, e);\n             throw new LoadException(errMsg + e.getMessage());\n         }\n \n-        while (retry++ < GET_APPID_MAX_RETRY_TIMES) {\n-            appId = handle.getAppId();\n-            if (appId != null) {\n-                break;\n-            }\n-\n-            // check state and retry\n-            state = handle.getState();\n-            if (fromSparkState(state) == TEtlState.CANCELLED) {\n-                throw new LoadException(errMsg + \"spark app state: \" + state.toString());\n-            }\n-            if (retry >= GET_APPID_MAX_RETRY_TIMES) {\n-                throw new LoadException(errMsg + \"wait too much time for getting appid. spark app state: \"\n-                                                + state.toString());\n-            }\n+        if (fromSparkState(state) == TEtlState.CANCELLED) {\n+            throw new LoadException(errMsg + \"spark app state: \" + state.toString() + \", loadJobId:\" + loadJobId);\n+        }\n \n-            // log\n-            if (retry % 10 == 0) {\n-                LOG.info(\"spark appid that handle get is null. load job id: {}, state: {}, retry times: {}\",\n-                         loadJobId, state.toString(), retry);\n-            }\n-            try {\n-                Thread.sleep(GET_APPID_SLEEP_MS);\n-            } catch (InterruptedException e) {\n-                LOG.warn(e.getMessage());\n-            }\n+        if (appId == null) {\n+            throw new LoadException(errMsg + \"Failed to get appId from handle. spark app state: \"\n+                    + state.toString() + \", loadJobId:\" + loadJobId);\n         }\n \n         // success\n         attachment.setAppId(appId);\n         attachment.setHandle(handle);\n     }\n \n-    public EtlStatus getEtlJobStatus(SparkAppHandle handle, String appId, long loadJobId, String etlOutputPath,\n-                                     SparkResource resource, BrokerDesc brokerDesc) {\n+    public EtlStatus getEtlJobStatus(SparkLoadAppHandle handle, String appId, long loadJobId, String etlOutputPath,\n+                                     SparkResource resource, BrokerDesc brokerDesc) throws LoadException {\n         EtlStatus status = new EtlStatus();\n \n         if (resource.isYarnMaster()) {\n-            // state from yarn\n             Preconditions.checkState(appId != null && !appId.isEmpty());", "originalCommit": "77deaef42479f84d2b3ee4240e541036996455c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE4MjQ0Ng==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477182446", "bodyText": "done", "author": "xy720", "createdAt": "2020-08-26T09:57:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE2MDQ5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE2MTY1OA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477161658", "bodyText": "I do not like the xxxxs", "author": "wuyunfeng", "createdAt": "2020-08-26T09:22:14Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkLauncherMonitors.java", "diffHunk": "@@ -0,0 +1,231 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.base.Strings;\n+\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.List;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+public class SparkLauncherMonitors {", "originalCommit": "77deaef42479f84d2b3ee4240e541036996455c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE4NTkyOA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477185928", "bodyText": "How about SparkLauncherMonitor?", "author": "xy720", "createdAt": "2020-08-26T10:03:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE2MTY1OA=="}], "type": "inlineReview"}, {"oid": "fefbf7c860ac3584f59cb7974e86641dcac1533b", "url": "https://github.com/apache/incubator-doris/commit/fefbf7c860ac3584f59cb7974e86641dcac1533b", "message": "add comments", "committedDate": "2020-08-26T09:56:04Z", "type": "commit"}, {"oid": "0b77bab05dd9fc99bca5f5d9c43136e9c5fe5983", "url": "https://github.com/apache/incubator-doris/commit/0b77bab05dd9fc99bca5f5d9c43136e9c5fe5983", "message": "remove s", "committedDate": "2020-08-26T10:02:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzE5OTg2OA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477199868", "bodyText": "@ConfField", "author": "morningman", "createdAt": "2020-08-26T10:29:58Z", "path": "fe/fe-core/src/main/java/org/apache/doris/common/Config.java", "diffHunk": "@@ -543,6 +543,14 @@\n     @ConfField\n     public static String spark_resource_path = \"\";\n \n+    /**\n+     * Default yarn client path\n+     */\n+    public static String yarn_client_path = PaloFe.DORIS_HOME_DIR + \"/lib/yarn-client/hadoop/bin/yarn\";", "originalCommit": "0b77bab05dd9fc99bca5f5d9c43136e9c5fe5983", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwMDE1Ng==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477200156", "bodyText": "Not used?", "author": "morningman", "createdAt": "2020-08-26T10:30:31Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/SparkEtlJobHandler.java", "diffHunk": "@@ -74,17 +67,21 @@\n     private static final String JOB_CONFIG_DIR = \"configs\";\n     private static final String ETL_JOB_NAME = \"doris__%s\";\n     // 5min\n-    private static final int GET_APPID_MAX_RETRY_TIMES = 300;\n-    private static final int GET_APPID_SLEEP_MS = 1000;\n-\n-    class SparkAppListener implements Listener {\n+    private static final long GET_APPID_TIMEOUT_MS = 300000L;\n+    // 30s\n+    private static final long EXEC_CMD_TIMEOUT_MS = 30000L;\n+    // yarn command\n+    private static final String YARN_STATUS_CMD = \"%s --config %s application -status %s\";\n+    private static final String YARN_KILL_CMD = \"%s --config %s application -kill %s\";\n+\n+    class SparkAppListener implements SparkLoadAppHandle.Listener {", "originalCommit": "0b77bab05dd9fc99bca5f5d9c43136e9c5fe5983", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "86077e20b5056dd86b45f8e21c4b80e1dfa6063f", "url": "https://github.com/apache/incubator-doris/commit/86077e20b5056dd86b45f8e21c4b80e1dfa6063f", "message": "save code", "committedDate": "2020-08-26T10:44:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIwOTE4MA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477209180", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return sparkConfigs;\n          \n          \n            \n                    return sparkConfig;\n          \n      \n    \n    \n  \n\nThe method name also need changed?", "author": "wuyunfeng", "createdAt": "2020-08-26T10:49:11Z", "path": "fe/fe-core/src/main/java/org/apache/doris/catalog/SparkResource.java", "diffHunk": "@@ -243,6 +264,16 @@ protected void setProperties(Map<String, String> properties) throws DdlException\n         return sparkConfigs;", "originalCommit": "86077e20b5056dd86b45f8e21c4b80e1dfa6063f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7f9651688bae81bcc0978b4c2148716322c6beb2", "url": "https://github.com/apache/incubator-doris/commit/7f9651688bae81bcc0978b4c2148716322c6beb2", "message": "add comments", "committedDate": "2020-08-26T11:01:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzIxNjM1NA==", "url": "https://github.com/apache/incubator-doris/pull/4383#discussion_r477216354", "bodyText": "format seems to wrong?", "author": "wuyunfeng", "createdAt": "2020-08-26T11:03:48Z", "path": "fe/fe-core/src/main/java/org/apache/doris/load/loadv2/YarnApplicationReport.java", "diffHunk": "@@ -0,0 +1,121 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2;\n+\n+import org.apache.doris.common.LoadException;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n+import com.google.common.collect.Maps;\n+\n+import org.apache.hadoop.yarn.api.records.ApplicationReport;\n+import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;\n+import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n+import org.apache.hadoop.yarn.api.records.impl.pb.ApplicationReportPBImpl;\n+import org.apache.hadoop.yarn.util.ConverterUtils;\n+\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Covert output string of command `yarn application -status` to application report.\n+ * Input sample:\n+ * -------------------\n+ * Application Report :\n+ * \tApplication-Id : application_1573630236805_6763648\n+ * \tApplication-Name : doris_label_test\n+ * \tApplication-Type : SPARK-2.4.1\n+ * \tUser : test\n+ * \tQueue : test-queue\n+ * \tStart-Time : 1597654469958\n+ * \tFinish-Time : 1597654801939\n+ * \tProgress : 100%\n+ * \tState : FINISHED\n+ * \tFinal-State : SUCCEEDED\n+ * \tTracking-URL : 127.0.0.1:8004/history/application_1573630236805_6763648/1\n+ * \tRPC Port : 40236\n+ * \tAM Host : host-name\n+ * \t------------------\n+ *\n+ * \tOutput:\n+ * \tApplicationReport\n+ */\n+public class YarnApplicationReport {\n+    private static final String APPLICATION_ID = \"Application-Id\";\n+    private static final String APPLICATION_TYPE = \"Application-Type\";\n+    private static final String APPLICATION_NAME = \"Application-Name\";\n+    private static final String USER = \"User\";\n+    private static final String QUEUE = \"Queue\";\n+    private static final String START_TIME = \"Start-Time\";\n+    private static final String FINISH_TIME = \"Finish-Time\";\n+    private static final String PROGRESS = \"Progress\";\n+    private static final String STATE = \"State\";\n+    private static final String FINAL_STATE = \"Final-State\";\n+    private static final String TRACKING_URL = \"Tracking-URL\";\n+    private static final String RPC_PORT = \"RPC Port\";\n+    private static final String AM_HOST = \"AM Host\";\n+    private static final String DIAGNOSTICS = \"Diagnostics\";\n+\n+    private ApplicationReport report;\n+\n+    public YarnApplicationReport(String output) throws LoadException {\n+        this.report = new ApplicationReportPBImpl();\n+        parseFromOutput(output);\n+    }\n+\n+    public ApplicationReport getReport() {\n+        return report;\n+    }\n+\n+    private void parseFromOutput(String output) throws LoadException {\n+        Map<String, String> reportMap = Maps.newHashMap();\n+        List<String> lines = Splitter.onPattern(\"\\n\").trimResults().splitToList(output);\n+        // Application-Id : application_1573630236805_6763648 ==> (Application-Id, application_1573630236805_6763648)\n+        for (String line : lines) {\n+            List<String> entry = Splitter.onPattern(\":\").limit(2).trimResults().splitToList(line);\n+            Preconditions.checkState(entry.size() <= 2, line);\n+            if (entry.size() > 1) {\n+                reportMap.put(entry.get(0), entry.get(1));\n+            } else {\n+                reportMap.put(entry.get(0), \"\");\n+            }\n+        }\n+\n+        try {\n+            report.setApplicationId(ConverterUtils.toApplicationId(reportMap.get(APPLICATION_ID)));", "originalCommit": "86077e20b5056dd86b45f8e21c4b80e1dfa6063f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f5fc44f863a70fc5040ee8c6438c6dd4af007ab2", "url": "https://github.com/apache/incubator-doris/commit/f5fc44f863a70fc5040ee8c6438c6dd4af007ab2", "message": "remove s", "committedDate": "2020-08-26T11:12:27Z", "type": "commit"}, {"oid": "f3b51caeaa2da9b19784769f2fc01518e33ca397", "url": "https://github.com/apache/incubator-doris/commit/f3b51caeaa2da9b19784769f2fc01518e33ca397", "message": "save code", "committedDate": "2020-08-26T11:45:21Z", "type": "commit"}]}