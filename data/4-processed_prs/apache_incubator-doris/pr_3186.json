{"pr_number": 3186, "pr_title": "Support convert  Arrow data to RowBatch asynchronously in Spark-Doris-Connector", "pr_createdAt": "2020-03-24T10:08:01Z", "pr_url": "https://github.com/apache/incubator-doris/pull/3186", "timeline": [{"oid": "c8551eebce34c787d49191d6a8916869e8c6a52e", "url": "https://github.com/apache/incubator-doris/commit/c8551eebce34c787d49191d6a8916869e8c6a52e", "message": "support convert arrow to rowbatch async", "committedDate": "2020-03-24T09:22:34Z", "type": "commit"}, {"oid": "90aed3643bca7c0331e59573a46c9768f0294cdc", "url": "https://github.com/apache/incubator-doris/commit/90aed3643bca7c0331e59573a46c9768f0294cdc", "message": "fix", "committedDate": "2020-03-24T10:29:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzIwNjEwNQ==", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397206105", "bodyText": "whether we can use a fixed array which size = rowCount or batch_size with a size flag?", "author": "wuyunfeng", "createdAt": "2020-03-24T14:42:33Z", "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -70,7 +70,8 @@ public void put(Object o) {\n         }\n     }\n \n-    private int offsetInOneBatch = 0;\n+    // offset for iterate the rowBatch\n+    private int offsetInRowBatch = 0;\n     private int rowCountInOneBatch = 0;\n     private int readRowCount = 0;\n     private List<Row> rowBatch = new ArrayList<>();", "originalCommit": "90aed3643bca7c0331e59573a46c9768f0294cdc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU3NjU5NA==", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397576594", "bodyText": "We could get the fixed array size by add all rows of Arrow batch through arrowStreamReader.loadNextBatch(), in this case, we might as well use List as we do now", "author": "Youngwb", "createdAt": "2020-03-25T02:36:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzIwNjEwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5MDM2OA==", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397590368", "bodyText": "function close could be removed and move its content to finally, since read all data from arrow here.", "author": "vinson0526", "createdAt": "2020-03-25T03:29:40Z", "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -87,50 +88,39 @@ public RowBatch(TScanBatchResult nextResult, Schema schema) throws DorisExceptio\n                 new ByteArrayInputStream(nextResult.getRows()),\n                 rootAllocator\n                 );\n+        this.offsetInRowBatch = 0;\n         try {\n             this.root = arrowStreamReader.getVectorSchemaRoot();\n+            while (arrowStreamReader.loadNextBatch()) {\n+                fieldVectors = root.getFieldVectors();\n+                if (fieldVectors.size() != schema.size()) {\n+                    logger.error(\"Schema size '{}' is not equal to arrow field size '{}'.\",\n+                            fieldVectors.size(), schema.size());\n+                    throw new DorisException(\"Load Doris data failed, schema size of fetch data is wrong.\");\n+                }\n+                if (fieldVectors.size() == 0 || root.getRowCount() == 0) {\n+                    logger.debug(\"One batch in arrow has no data.\");\n+                    continue;\n+                }\n+                rowCountInOneBatch = root.getRowCount();\n+                // init the rowBatch\n+                for (int i = 0; i < rowCountInOneBatch; ++i) {\n+                    rowBatch.add(new Row(fieldVectors.size()));\n+                }\n+                convertArrowToRowBatch();\n+                readRowCount += root.getRowCount();", "originalCommit": "90aed3643bca7c0331e59573a46c9768f0294cdc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxNzU4NA==", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397717584", "bodyText": "OK,Done", "author": "Youngwb", "createdAt": "2020-03-25T09:36:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5MDM2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5MjI4NA==", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397592284", "bodyText": "rowCountInOneBatch could be a local variable\uff1f", "author": "vinson0526", "createdAt": "2020-03-25T03:37:56Z", "path": "extension/spark-doris-connector/src/main/java/org/apache/doris/spark/serialization/RowBatch.java", "diffHunk": "@@ -70,7 +70,8 @@ public void put(Object o) {\n         }\n     }\n \n-    private int offsetInOneBatch = 0;\n+    // offset for iterate the rowBatch\n+    private int offsetInRowBatch = 0;\n     private int rowCountInOneBatch = 0;", "originalCommit": "90aed3643bca7c0331e59573a46c9768f0294cdc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcxMjY1MA==", "url": "https://github.com/apache/incubator-doris/pull/3186#discussion_r397712650", "bodyText": "rowCountInOneBatch is also used in addValueToRow and convertArrowToRowBatch, so I think this is better for now", "author": "Youngwb", "createdAt": "2020-03-25T09:28:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU5MjI4NA=="}], "type": "inlineReview"}, {"oid": "c11d4441d671bbd405f2419c5908fb8893022ea7", "url": "https://github.com/apache/incubator-doris/commit/c11d4441d671bbd405f2419c5908fb8893022ea7", "message": "fix", "committedDate": "2020-03-25T09:35:09Z", "type": "commit"}]}