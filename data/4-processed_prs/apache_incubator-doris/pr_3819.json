{"pr_number": 3819, "pr_title": "[Spark load][Fe 4/6] Add hive external table and update hive table syntax in loadstmt", "pr_createdAt": "2020-06-10T08:38:56Z", "pr_url": "https://github.com/apache/incubator-doris/pull/3819", "timeline": [{"oid": "4c2e73a5fef1dd44682701a64a27c08f616f3914", "url": "https://github.com/apache/incubator-doris/commit/4c2e73a5fef1dd44682701a64a27c08f616f3914", "message": "Add hive external table and update hive table syntax in loadstmt", "committedDate": "2020-06-10T08:32:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODE3ODIwOA==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r438178208", "bodyText": "Doris", "author": "imay", "createdAt": "2020-06-10T14:42:56Z", "path": "docs/zh-CN/sql-reference/sql-statements/Data Definition/CREATE TABLE.md", "diffHunk": "@@ -131,7 +131,7 @@ under the License.\n     \n     \u5728 Palo \u521b\u5efa mysql \u8868\u7684\u76ee\u7684\u662f\u53ef\u4ee5\u901a\u8fc7 Palo \u8bbf\u95ee mysql \u6570\u636e\u5e93\u3002", "originalCommit": "4c2e73a5fef1dd44682701a64a27c08f616f3914", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODE4OTM2NA==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r438189364", "bodyText": "You can do it in  fromClause_.analyze(analyzer);", "author": "imay", "createdAt": "2020-06-10T14:57:10Z", "path": "fe/src/main/java/org/apache/doris/analysis/SelectStmt.java", "diffHunk": "@@ -341,6 +375,8 @@ public void analyze(Analyzer analyzer) throws AnalysisException, UserException {\n \n         fromClause_.setNeedToSql(needToSql);\n         fromClause_.analyze(analyzer);\n+        // TODO: remove when query from hive table is supported\n+        checkFromHiveTable(analyzer);", "originalCommit": "4c2e73a5fef1dd44682701a64a27c08f616f3914", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIwMjAzNg==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r438202036", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                \u6ce8\u610f\uff1a\u76ee\u524dhive\u5916\u90e8\u8868\u4ec5\u7528\u4e8eSpark Load\u4f7f\u7528\u3002\n          \n          \n            \n                \u6ce8\u610f\uff1a\u76ee\u524d hive \u5916\u90e8\u8868\u4ec5\u7528\u4e8e Spark Load", "author": "morningman", "createdAt": "2020-06-10T15:14:28Z", "path": "docs/zh-CN/sql-reference/sql-statements/Data Definition/CREATE TABLE.md", "diffHunk": "@@ -152,6 +152,18 @@ under the License.\n         \"path\" \u4e2d\u5982\u679c\u6709\u591a\u4e2a\u6587\u4ef6\uff0c\u7528\u9017\u53f7[,]\u5206\u5272\u3002\u5982\u679c\u6587\u4ef6\u540d\u4e2d\u5305\u542b\u9017\u53f7\uff0c\u90a3\u4e48\u4f7f\u7528 %2c \u6765\u66ff\u4ee3\u3002\u5982\u679c\u6587\u4ef6\u540d\u4e2d\u5305\u542b %\uff0c\u4f7f\u7528 %25 \u4ee3\u66ff\n         \u73b0\u5728\u6587\u4ef6\u5185\u5bb9\u683c\u5f0f\u652f\u6301CSV\uff0c\u652f\u6301GZ\uff0cBZ2\uff0cLZ4\uff0cLZO(LZOP) \u538b\u7f29\u683c\u5f0f\u3002\n \n+    3) \u5982\u679c\u662fhive\uff0c\u5219\u9700\u8981\u5728properties\u63d0\u4f9b\u4ee5\u4e0b\u4fe1\u606f\uff1a\n+    ```\n+    PROPERTIES (\n+        \"database\" = \"hive_db_name\",\n+        \"table\" = \"hive_table_name\",\n+        \"hive.metastore.uris\" = \"thrift://127.0.0.1:9083\"\n+    )\n+\n+    ```\n+    \u5176\u4e2ddatabase\u662fhive\u8868\u5bf9\u5e94\u7684\u5e93\u540d\u5b57\uff0ctable\u662fhive\u8868\u7684\u540d\u5b57\uff0chive.metastore.uris\u662fhive metastore\u670d\u52a1\u5730\u5740\u3002\n+    \u6ce8\u610f\uff1a\u76ee\u524dhive\u5916\u90e8\u8868\u4ec5\u7528\u4e8eSpark Load\u4f7f\u7528\u3002", "originalCommit": "4c2e73a5fef1dd44682701a64a27c08f616f3914", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIwNTY4OQ==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r438205689", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    long tableId = Catalog.getCurrentCatalog().getNextId();\n          \n          \n            \n                    long tableId = getNextId();", "author": "morningman", "createdAt": "2020-06-10T15:19:27Z", "path": "fe/src/main/java/org/apache/doris/catalog/Catalog.java", "diffHunk": "@@ -3908,6 +3911,18 @@ private void createBrokerTable(Database db, CreateTableStmt stmt) throws DdlExce\n         return;\n     }\n \n+    private void createHiveTable(Database db, CreateTableStmt stmt) throws DdlException {\n+        String tableName = stmt.getTableName();\n+        List<Column> columns = stmt.getColumns();\n+        long tableId = Catalog.getCurrentCatalog().getNextId();", "originalCommit": "4c2e73a5fef1dd44682701a64a27c08f616f3914", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIwOTc3Nw==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r438209777", "bodyText": "Is this necessary?\nI think we can support that some of olap table's column does not exist in HIVE table, and can be filled by default value or null?", "author": "morningman", "createdAt": "2020-06-10T15:23:46Z", "path": "fe/src/main/java/org/apache/doris/load/BrokerFileGroup.java", "diffHunk": "@@ -165,6 +170,33 @@ public void parse(Database db, DataDescription dataDescription) throws DdlExcept\n \n         // FilePath\n         filePaths = dataDescription.getFilePaths();\n+\n+        if (dataDescription.isLoadFromTable()) {\n+            String srcTableName = dataDescription.getSrcTableName();\n+            // src table should be hive table\n+            Table srcTable = db.getTable(srcTableName);\n+            if (srcTable == null) {\n+                throw new DdlException(\"Unknown table \" + srcTableName + \" in database \" + db.getFullName());\n+            }\n+            if (!(srcTable instanceof HiveTable)) {\n+                throw new DdlException(\"Source table \" + srcTableName + \" is not HiveTable\");\n+            }\n+            // src table columns should include all columns of loaded table", "originalCommit": "4c2e73a5fef1dd44682701a64a27c08f616f3914", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI4OTc5Mw==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r439289793", "bodyText": "Support later", "author": "wyb", "createdAt": "2020-06-12T08:45:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIwOTc3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIxOTk0Ng==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r438219946", "bodyText": "How to map the hive table's columns to olap table's columns?\nWhat if column's name is same in two tables?\nHow about reference to the DeltaLake COPY INTO stmt by using a SELECT statement?\nDATA AS (SELECT xxx FROM hive_table WHERE xxx)\nINTO TABLE olap_table\nPARTITION(p1, p2, ...)\n(k1, k2, k3, v1, v2)   /* indicate the columns of olap table which will be loaded */\n\nFirst, SQL is more flexible, and can be easily used by Spark to read from a hive table.", "author": "morningman", "createdAt": "2020-06-10T15:37:26Z", "path": "fe/src/main/cup/sql_parser.cup", "diffHunk": "@@ -1244,6 +1244,15 @@ data_desc ::=\n         RESULT = new DataDescription(tableName, partitionNames, files, colList, colSep, fileFormat,\n         columnsFromPath, isNeg, colMappingList, whereExpr);\n     :}\n+    | KW_DATA KW_FROM KW_TABLE ident:srcTableName\n+    opt_negative:isNeg\n+    KW_INTO KW_TABLE ident:tableName\n+    opt_partition_names:partitionNames\n+    opt_col_mapping_list:colMappingList", "originalCommit": "4c2e73a5fef1dd44682701a64a27c08f616f3914", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI4Njg4Ng==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r439286886", "bodyText": "@morningman\nWhat you suggested seems more flexible. however I think it is a more complex feature.\nIn my opinion, we can only support table directlly to fulfill 80% user requirements.\nAnd we can implement what your suggest later when it is needed.\nAnd we can keep the same with load file in column mapping by column_lists and SET clause.", "author": "imay", "createdAt": "2020-06-12T08:39:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIxOTk0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTI4OTg5NQ==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r439289895", "bodyText": "Support later", "author": "wyb", "createdAt": "2020-06-12T08:45:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIxOTk0Ng=="}], "type": "inlineReview"}, {"oid": "7f7ee63723ed4d1391537e20052b52761b8d6fb7", "url": "https://github.com/apache/incubator-doris/commit/7f7ee63723ed4d1391537e20052b52761b8d6fb7", "message": "Move check hive table from SelectStmt to FromClause and update doc", "committedDate": "2020-06-11T08:53:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM5NzkzMg==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r439397932", "bodyText": "Lock db before getting table", "author": "morningman", "createdAt": "2020-06-12T12:48:45Z", "path": "fe/src/main/java/org/apache/doris/analysis/FromClause.java", "diffHunk": "@@ -72,6 +78,39 @@ public int compare(TableRef tableref1, TableRef tableref2) {\n         });\n     }\n \n+    private void checkFromHiveTable(Analyzer analyzer) throws AnalysisException {\n+        for (TableRef tblRef : tableRefs_) {\n+            if (!(tblRef instanceof BaseTableRef)) {\n+                continue;\n+            }\n+\n+            TableName tableName = tblRef.getName();\n+            String dbName = tableName.getDb();\n+            if (Strings.isNullOrEmpty(dbName)) {\n+                dbName = analyzer.getDefaultDb();\n+            } else {\n+                dbName = ClusterNamespace.getFullName(analyzer.getClusterName(), tblRef.getName().getDb());\n+            }\n+            if (Strings.isNullOrEmpty(dbName)) {\n+                ErrorReport.reportAnalysisException(ErrorCode.ERR_NO_DB_ERROR);\n+            }\n+\n+            Database db = analyzer.getCatalog().getDb(dbName);\n+            if (db == null) {\n+                ErrorReport.reportAnalysisException(ErrorCode.ERR_BAD_DB_ERROR, dbName);\n+            }\n+\n+            String tblName = tableName.getTbl();\n+            Table table = db.getTable(tblName);", "originalCommit": "7f7ee63723ed4d1391537e20052b52761b8d6fb7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQyNDc2NQ==", "url": "https://github.com/apache/incubator-doris/pull/3819#discussion_r439424765", "bodyText": "Lock is acquired in StmtExecutor.analyze function.", "author": "wyb", "createdAt": "2020-06-12T13:41:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTM5NzkzMg=="}], "type": "inlineReview"}, {"oid": "44dbdf49861bf6b1d8d0ba8fefce0f3653506014", "url": "https://github.com/apache/incubator-doris/commit/44dbdf49861bf6b1d8d0ba8fefce0f3653506014", "message": "Update hive external table en sql reference", "committedDate": "2020-06-12T13:38:05Z", "type": "commit"}]}